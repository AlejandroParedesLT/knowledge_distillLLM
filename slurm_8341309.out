gpu-compute5
Sun Apr  6 08:45:46 PM EDT 2025
torchrun --nproc_per_node 1 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2012 ./finetune.py --base-path . --model-path ./checkpoints/gpt2-base/ --ckpt-name gpt2-base --n-gpu 1 --data-dir ./processed_data/bugnet_python/full/gpt2/ --num-workers 0 --dev-num 1000 --lr 0.0005 --batch-size 2 --eval-batch-size 8 --gradient-accumulation-steps 1 --warmup-iters 0 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --epochs 10 --max-length 512 --max-prompt-length 256 --do-train --do-valid --eval-gen --save-interval 4000 --eval-interval 4000 --log-interval 4 --mid-log-num 4 --save ./results/gpt2/train/sft/gpt2-base/ --seed 10 --deepspeed --deepspeed_config ./configs/deepspeed/ds_config_zero1_fp16.json --type lm --do-sample --top-k 0 --top-p 1.0 --temperature 1.0
PYTHONPATH=.
[2025-04-06 20:45:52,988] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
[2025-04-06 20:45:59,456] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-04-06 20:45:59,457] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_path ................... ./checkpoints/gpt2-base/
  ckpt_name .................... gpt2-base
  model_type ................... gpt2
  teacher_model_type ........... None
  n_gpu ........................ 1
  n_nodes ...................... 1
  teacher_model_path ........... None
  teacher_ckpt_name ............ None
  teacher_model_fp16 ........... False
  model_parallel ............... False
  model_parallel_size .......... None
  no_value ..................... False
  dropout_path_rate ............ None
  dtype ........................ torch.float16
  type ......................... lm
  do_train ..................... True
  do_valid ..................... True
  do_eval ...................... False
  base_path .................... .
  load ......................... None
  save ......................... ./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
  log_interval ................. 4
  mid_log_num .................. 4
  save_interval ................ 4000
  eval_interval ................ 4000
  local_rank ................... 0
  save_additional_suffix ....... 
  save_rollout ................. False
  eb_sample_times .............. 3
  data_dir ..................... ./processed_data/bugnet_python/full/gpt2/
  processed_data_dir ........... None
  force_process ................ False
  force_process_demo ........... False
  data_process_workers ......... -1
  train_num .................... -1
  train_ratio .................. 1
  dev_num ...................... 1000
  dev_ratio .................... 1
  gen_num ...................... -1
  data_names ................... None
  prompt_type .................. None
  num_workers .................. 0
  max_prompt_length ............ 256
  min_prompt_length ............ 128
  json_data .................... False
  bin_data ..................... False
  txt_data ..................... False
  prompt_data_dir .............. None
  lm_data_dir .................. None
  eval_ppl ..................... False
  eval_rw ...................... False
  eval_gen ..................... True
  only_prompt .................. False
  batch_size ................... 2
  eval_batch_size .............. 8
  clip_grad .................... 1.0
  total_iters .................. None
  train_iters_per_epoch ........ -1
  max_length ................... 512
  seed ......................... 10
  seed_order ................... 42
  seed_data .................... 42
  seed_ppo ..................... 42
  seed_lm ...................... 7
  epochs ....................... 10
  training_epochs .............. 10000
  gradient_accumulation_steps .. 1
  gradient_checkpointing ....... False
  attn_dtype ................... None
  lr ........................... 0.0005
  lr_min ....................... 1e-07
  weight_decay ................. 0.01
  loss_scale ................... 65536
  kd_ratio ..................... None
  warmup_iters ................. 0
  lr_decay_iters ............... None
  lr_decay_style ............... cosine
  scheduler_name ............... constant_trm
  reward_scaling ............... None
  cliprange_reward ............. 1
  ppo_epochs ................... None
  num_rollouts ................. 256
  num_rollouts_per_device ...... None
  cliprange .................... 0.2
  chunk_size ................... None
  gamma ........................ 0.95
  length_norm .................. False
  single_step_reg .............. False
  teacher_mixed_alpha .......... None
  lm_coef ...................... 1
  top_k ........................ 0
  top_p ........................ 1.0
  do_sample .................... True
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  num_beams .................... 1
  temperature .................. 1.0
  peft ......................... None
  peft_lora_r .................. 8
  peft_lora_alpha .............. 32
  peft_lora_dropout ............ 0.1
  peft_name .................... None
  peft_path .................... None
  teacher_peft_name ............ None
  teacher_peft_path ............ None
  deepspeed .................... True
  deepspeed_config ............. ./configs/deepspeed/ds_config_zero1_fp16.json
  deepscale .................... False
  deepscale_config ............. None
  rank ......................... 0
  world_size ................... 1
Probing Dataset
Probing end. Max data state 1, total length 1693
1693
Num LM instances: 1693
train num 1693
Probing Dataset
Probing end. Max data state 1, total length 596
596
Num LM instances: 596
Train iters per epoch 846
total_iters 8460
 > number of parameters: 124439808
Model load time: 2.1480114459991455s
Optimizer = AdamW
[2025-04-06 20:46:01,834] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed info: version=0.16.4, git-hash=unknown, git-branch=unknown
[2025-04-06 20:46:01,834] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 1
[2025-04-06 20:46:02,151] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-04-06 20:46:02,152] [INFO] [logging.py:128:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2025-04-06 20:46:02,152] [INFO] [logging.py:128:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-04-06 20:46:02,155] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2025-04-06 20:46:02,155] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2025-04-06 20:46:02,155] [INFO] [logging.py:128:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 1 optimizer
[2025-04-06 20:46:02,155] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 500000000
[2025-04-06 20:46:02,155] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 500000000
[2025-04-06 20:46:02,155] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2025-04-06 20:46:02,156] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2025-04-06 20:46:03,046] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[2025-04-06 20:46:03,047] [INFO] [utils.py:782:see_memory_usage] MA 0.94 GB         Max_MA 0.94 GB         CA 0.94 GB         Max_CA 1 GB 
[2025-04-06 20:46:03,047] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 53.27 GB, percent = 21.2%
[2025-04-06 20:46:03,215] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[2025-04-06 20:46:03,216] [INFO] [utils.py:782:see_memory_usage] MA 0.94 GB         Max_MA 1.4 GB         CA 1.41 GB         Max_CA 1 GB 
[2025-04-06 20:46:03,216] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 53.27 GB, percent = 21.2%
[2025-04-06 20:46:03,217] [INFO] [stage_1_and_2.py:550:__init__] optimizer state initialized
[2025-04-06 20:46:03,379] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[2025-04-06 20:46:03,380] [INFO] [utils.py:782:see_memory_usage] MA 0.94 GB         Max_MA 0.94 GB         CA 1.41 GB         Max_CA 1 GB 
[2025-04-06 20:46:03,381] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 53.28 GB, percent = 21.2%
[2025-04-06 20:46:03,384] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer
[2025-04-06 20:46:03,384] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2025-04-06 20:46:03,385] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7fb6ea793c40>
[2025-04-06 20:46:03,385] [INFO] [logging.py:128:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0005, 0.0005], mom=[(0.9, 0.999), (0.9, 0.999)]
[2025-04-06 20:46:03,385] [INFO] [config.py:1001:print] DeepSpeedEngine configuration:
[2025-04-06 20:46:03,386] [INFO] [config.py:1005:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-04-06 20:46:03,386] [INFO] [config.py:1005:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-04-06 20:46:03,386] [INFO] [config.py:1005:print]   amp_enabled .................. False
[2025-04-06 20:46:03,386] [INFO] [config.py:1005:print]   amp_params ................... False
[2025-04-06 20:46:03,387] [INFO] [config.py:1005:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-04-06 20:46:03,387] [INFO] [config.py:1005:print]   bfloat16_enabled ............. False
[2025-04-06 20:46:03,387] [INFO] [config.py:1005:print]   bfloat16_immediate_grad_update  False
[2025-04-06 20:46:03,387] [INFO] [config.py:1005:print]   checkpoint_parallel_write_pipeline  False
[2025-04-06 20:46:03,387] [INFO] [config.py:1005:print]   checkpoint_tag_validation_enabled  True
[2025-04-06 20:46:03,387] [INFO] [config.py:1005:print]   checkpoint_tag_validation_fail  False
[2025-04-06 20:46:03,387] [INFO] [config.py:1005:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fb6e83385e0>
[2025-04-06 20:46:03,387] [INFO] [config.py:1005:print]   communication_data_type ...... None
[2025-04-06 20:46:03,387] [INFO] [config.py:1005:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-04-06 20:46:03,388] [INFO] [config.py:1005:print]   curriculum_enabled_legacy .... False
[2025-04-06 20:46:03,388] [INFO] [config.py:1005:print]   curriculum_params_legacy ..... False
[2025-04-06 20:46:03,388] [INFO] [config.py:1005:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-04-06 20:46:03,388] [INFO] [config.py:1005:print]   data_efficiency_enabled ...... False
[2025-04-06 20:46:03,388] [INFO] [config.py:1005:print]   dataloader_drop_last ......... False
[2025-04-06 20:46:03,388] [INFO] [config.py:1005:print]   disable_allgather ............ False
[2025-04-06 20:46:03,388] [INFO] [config.py:1005:print]   dump_state ................... False
[2025-04-06 20:46:03,388] [INFO] [config.py:1005:print]   dynamic_loss_scale_args ...... None
[2025-04-06 20:46:03,388] [INFO] [config.py:1005:print]   eigenvalue_enabled ........... False
[2025-04-06 20:46:03,389] [INFO] [config.py:1005:print]   eigenvalue_gas_boundary_resolution  1
[2025-04-06 20:46:03,389] [INFO] [config.py:1005:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-04-06 20:46:03,389] [INFO] [config.py:1005:print]   eigenvalue_layer_num ......... 0
[2025-04-06 20:46:03,389] [INFO] [config.py:1005:print]   eigenvalue_max_iter .......... 100
[2025-04-06 20:46:03,389] [INFO] [config.py:1005:print]   eigenvalue_stability ......... 1e-06
[2025-04-06 20:46:03,389] [INFO] [config.py:1005:print]   eigenvalue_tol ............... 0.01
[2025-04-06 20:46:03,389] [INFO] [config.py:1005:print]   eigenvalue_verbose ........... False
[2025-04-06 20:46:03,389] [INFO] [config.py:1005:print]   elasticity_enabled ........... False
[2025-04-06 20:46:03,389] [INFO] [config.py:1005:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-04-06 20:46:03,389] [INFO] [config.py:1005:print]   fp16_auto_cast ............... None
[2025-04-06 20:46:03,390] [INFO] [config.py:1005:print]   fp16_enabled ................. False
[2025-04-06 20:46:03,390] [INFO] [config.py:1005:print]   fp16_master_weights_and_gradients  False
[2025-04-06 20:46:03,390] [INFO] [config.py:1005:print]   global_rank .................. 0
[2025-04-06 20:46:03,390] [INFO] [config.py:1005:print]   grad_accum_dtype ............. None
[2025-04-06 20:46:03,390] [INFO] [config.py:1005:print]   gradient_accumulation_steps .. 1
[2025-04-06 20:46:03,390] [INFO] [config.py:1005:print]   gradient_clipping ............ 1.0
[2025-04-06 20:46:03,390] [INFO] [config.py:1005:print]   gradient_predivide_factor .... 1.0
[2025-04-06 20:46:03,390] [INFO] [config.py:1005:print]   graph_harvesting ............. False
[2025-04-06 20:46:03,390] [INFO] [config.py:1005:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-04-06 20:46:03,391] [INFO] [config.py:1005:print]   initial_dynamic_scale ........ 65536
[2025-04-06 20:46:03,391] [INFO] [config.py:1005:print]   load_universal_checkpoint .... False
[2025-04-06 20:46:03,391] [INFO] [config.py:1005:print]   loss_scale ................... 0
[2025-04-06 20:46:03,391] [INFO] [config.py:1005:print]   memory_breakdown ............. False
[2025-04-06 20:46:03,391] [INFO] [config.py:1005:print]   mics_hierarchial_params_gather  False
[2025-04-06 20:46:03,391] [INFO] [config.py:1005:print]   mics_shard_size .............. -1
[2025-04-06 20:46:03,391] [INFO] [config.py:1005:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2025-04-06 20:46:03,391] [INFO] [config.py:1005:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-04-06 20:46:03,391] [INFO] [config.py:1005:print]   optimizer_legacy_fusion ...... False
[2025-04-06 20:46:03,392] [INFO] [config.py:1005:print]   optimizer_name ............... None
[2025-04-06 20:46:03,392] [INFO] [config.py:1005:print]   optimizer_params ............. None
[2025-04-06 20:46:03,392] [INFO] [config.py:1005:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-04-06 20:46:03,392] [INFO] [config.py:1005:print]   pld_enabled .................. False
[2025-04-06 20:46:03,392] [INFO] [config.py:1005:print]   pld_params ................... False
[2025-04-06 20:46:03,392] [INFO] [config.py:1005:print]   prescale_gradients ........... False
[2025-04-06 20:46:03,392] [INFO] [config.py:1005:print]   scheduler_name ............... None
[2025-04-06 20:46:03,392] [INFO] [config.py:1005:print]   scheduler_params ............. None
[2025-04-06 20:46:03,392] [INFO] [config.py:1005:print]   seq_parallel_communication_data_type  torch.float32
[2025-04-06 20:46:03,393] [INFO] [config.py:1005:print]   sparse_attention ............. None
[2025-04-06 20:46:03,393] [INFO] [config.py:1005:print]   sparse_gradients_enabled ..... False
[2025-04-06 20:46:03,393] [INFO] [config.py:1005:print]   steps_per_print .............. 10000000
[2025-04-06 20:46:03,393] [INFO] [config.py:1005:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False
[2025-04-06 20:46:03,393] [INFO] [config.py:1005:print]   timers_config ................ enabled=True synchronized=True
[2025-04-06 20:46:03,393] [INFO] [config.py:1005:print]   train_batch_size ............. 2
[2025-04-06 20:46:03,393] [INFO] [config.py:1005:print]   train_micro_batch_size_per_gpu  2
[2025-04-06 20:46:03,393] [INFO] [config.py:1005:print]   use_data_before_expert_parallel_  False
[2025-04-06 20:46:03,393] [INFO] [config.py:1005:print]   use_node_local_storage ....... False
[2025-04-06 20:46:03,394] [INFO] [config.py:1005:print]   wall_clock_breakdown ......... False
[2025-04-06 20:46:03,394] [INFO] [config.py:1005:print]   weight_quantization_config ... None
[2025-04-06 20:46:03,394] [INFO] [config.py:1005:print]   world_size ................... 1
[2025-04-06 20:46:03,394] [INFO] [config.py:1005:print]   zero_allow_untested_optimizer  True
[2025-04-06 20:46:03,394] [INFO] [config.py:1005:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False
[2025-04-06 20:46:03,394] [INFO] [config.py:1005:print]   zero_enabled ................. True
[2025-04-06 20:46:03,394] [INFO] [config.py:1005:print]   zero_force_ds_cpu_optimizer .. True
[2025-04-06 20:46:03,394] [INFO] [config.py:1005:print]   zero_optimization_stage ...... 1
[2025-04-06 20:46:03,395] [INFO] [config.py:991:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 2, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 1
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": false, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1.000000e+07
}
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    961 MiB |    961 MiB |   1911 MiB |    950 MiB |
|       from large pool |    948 MiB |    948 MiB |   1897 MiB |    949 MiB |
|       from small pool |     12 MiB |     12 MiB |     13 MiB |      0 MiB |
|---------------------------------------------------------------------------|
| Active memory         |    961 MiB |    961 MiB |   1911 MiB |    950 MiB |
|       from large pool |    948 MiB |    948 MiB |   1897 MiB |    949 MiB |
|       from small pool |     12 MiB |     12 MiB |     13 MiB |      0 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |    961 MiB |    961 MiB |   1910 MiB |    949 MiB |
|       from large pool |    948 MiB |    948 MiB |   1896 MiB |    948 MiB |
|       from small pool |     12 MiB |     12 MiB |     13 MiB |      0 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   1442 MiB |   1442 MiB |   1970 MiB | 540672 KiB |
|       from large pool |   1428 MiB |   1428 MiB |   1956 MiB | 540672 KiB |
|       from small pool |     14 MiB |     14 MiB |     14 MiB |      0 KiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   4704 KiB |   4704 KiB | 455964 KiB | 451260 KiB |
|       from large pool |   3610 KiB |   3610 KiB | 446759 KiB | 443149 KiB |
|       from small pool |   1094 KiB |   1094 KiB |   9205 KiB |   8111 KiB |
|---------------------------------------------------------------------------|
| Allocations           |      28    |      28    |     326    |     298    |
|       from large pool |       2    |       2    |      53    |      51    |
|       from small pool |      26    |      26    |     273    |     247    |
|---------------------------------------------------------------------------|
| Active allocs         |      28    |      28    |     326    |     298    |
|       from large pool |       2    |       2    |      53    |      51    |
|       from small pool |      26    |      26    |     273    |     247    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      10    |      10    |      30    |      20    |
|       from large pool |       3    |       3    |      23    |      20    |
|       from small pool |       7    |       7    |       7    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       5    |       5    |      89    |      84    |
|       from large pool |       2    |       2    |      40    |      38    |
|       from small pool |       3    |       3    |      49    |      46    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Start Fine-tuning
Sun Apr  6 20:46:03 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla P100-PCIE-12GB           Off |   00000000:81:00.0 Off |                    0 |
| N/A   36C    P0             29W /  250W |    2039MiB /  12288MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A    244677      C   ...project_distillLLM/venv/bin/python3       2036MiB |
+-----------------------------------------------------------------------------------------+

dp size 1
0/125
1/125
2/125
3/125
4/125
5/125
6/125
7/125
8/125
9/125
10/125
11/125
12/125
13/125
14/125
15/125
Evaluating:   0%|          | 0/125 [00:00<?, ?it/s]Evaluating:   1%|          | 1/125 [00:03<06:54,  3.34s/it]Evaluating:   2%|▏         | 2/125 [00:06<06:13,  3.04s/it]Evaluating:   2%|▏         | 3/125 [00:08<05:58,  2.94s/it]Evaluating:   3%|▎         | 4/125 [00:11<05:49,  2.89s/it]Evaluating:   4%|▍         | 5/125 [00:14<05:44,  2.87s/it]Evaluating:   5%|▍         | 6/125 [00:17<05:39,  2.85s/it]Evaluating:   6%|▌         | 7/125 [00:20<05:35,  2.84s/it]Evaluating:   6%|▋         | 8/125 [00:23<05:31,  2.83s/it]Evaluating:   7%|▋         | 9/125 [00:25<05:29,  2.84s/it]Evaluating:   8%|▊         | 10/125 [00:28<05:25,  2.83s/it]Evaluating:   9%|▉         | 11/125 [00:31<05:22,  2.83s/it]Evaluating:  10%|▉         | 12/125 [00:34<05:19,  2.83s/it]Evaluating:  10%|█         | 13/125 [00:37<05:16,  2.83s/it]Evaluating:  11%|█         | 14/125 [00:40<05:14,  2.83s/it]Evaluating:  12%|█▏        | 15/125 [00:42<05:11,  2.83s/it]Evaluating:  13%|█▎        | 1616/125
17/125
18/125
19/125
20/125
21/125
22/125
23/125
24/125
25/125
26/125
27/125
28/125
29/125
30/125
31/125
/125 [00:45<05:09,  2.84s/it]Evaluating:  14%|█▎        | 17/125 [00:48<05:06,  2.84s/it]Evaluating:  14%|█▍        | 18/125 [00:51<05:02,  2.83s/it]Evaluating:  15%|█▌        | 19/125 [00:54<04:59,  2.82s/it]Evaluating:  16%|█▌        | 20/125 [00:57<04:55,  2.82s/it]Evaluating:  17%|█▋        | 21/125 [00:59<04:52,  2.81s/it]Evaluating:  18%|█▊        | 22/125 [01:02<04:49,  2.81s/it]Evaluating:  18%|█▊        | 23/125 [01:05<04:48,  2.83s/it]Evaluating:  19%|█▉        | 24/125 [01:08<04:44,  2.82s/it]Evaluating:  20%|██        | 25/125 [01:11<04:41,  2.82s/it]Evaluating:  21%|██        | 26/125 [01:13<04:38,  2.82s/it]Evaluating:  22%|██▏       | 27/125 [01:16<04:35,  2.81s/it]Evaluating:  22%|██▏       | 28/125 [01:19<04:32,  2.81s/it]Evaluating:  23%|██▎       | 29/125 [01:22<04:29,  2.81s/it]Evaluating:  24%|██▍       | 30/125 [01:25<04:27,  2.82s/it]Evaluating:  25%|██▍       | 31/125 [01:27<04:24,  2.82s/it]Evaluatin32/125
33/125
34/125
35/125
36/125
37/125
38/125
39/125
40/125
41/125
42/125
43/125
44/125
45/125
46/125
g:  26%|██▌       | 32/125 [01:30<04:21,  2.81s/it]Evaluating:  26%|██▋       | 33/125 [01:33<04:17,  2.80s/it]Evaluating:  27%|██▋       | 34/125 [01:36<04:14,  2.80s/it]Evaluating:  28%|██▊       | 35/125 [01:39<04:11,  2.80s/it]Evaluating:  29%|██▉       | 36/125 [01:41<04:08,  2.80s/it]Evaluating:  30%|██▉       | 37/125 [01:44<04:06,  2.80s/it]Evaluating:  30%|███       | 38/125 [01:47<04:05,  2.82s/it]Evaluating:  31%|███       | 39/125 [01:50<04:01,  2.81s/it]Evaluating:  32%|███▏      | 40/125 [01:53<03:58,  2.81s/it]Evaluating:  33%|███▎      | 41/125 [01:56<03:55,  2.80s/it]Evaluating:  34%|███▎      | 42/125 [01:58<03:52,  2.80s/it]Evaluating:  34%|███▍      | 43/125 [02:01<03:49,  2.80s/it]Evaluating:  35%|███▌      | 44/125 [02:04<03:46,  2.80s/it]Evaluating:  36%|███▌      | 45/125 [02:07<03:45,  2.81s/it]Evaluating:  37%|███▋      | 46/125 [02:10<03:42,  2.81s/it]Evaluating:  347/125
48/125
49/125
50/125
51/125
52/125
53/125
54/125
55/125
56/125
57/125
58/125
59/125
60/125
8%|███▊      | 47/125 [02:12<03:39,  2.81s/it]Evaluating:  38%|███▊      | 48/125 [02:15<03:36,  2.81s/it]Evaluating:  39%|███▉      | 49/125 [02:18<03:33,  2.81s/it]Evaluating:  40%|████      | 50/125 [02:21<03:30,  2.81s/it]Evaluating:  41%|████      | 51/125 [02:24<03:28,  2.81s/it]Evaluating:  42%|████▏     | 52/125 [02:26<03:25,  2.81s/it]Evaluating:  42%|████▏     | 53/125 [02:29<03:24,  2.83s/it]Evaluating:  43%|████▎     | 54/125 [02:32<03:20,  2.82s/it]Evaluating:  44%|████▍     | 55/125 [02:35<03:17,  2.82s/it]Evaluating:  45%|████▍     | 56/125 [02:38<03:14,  2.81s/it]Evaluating:  46%|████▌     | 57/125 [02:41<03:11,  2.81s/it]Evaluating:  46%|████▋     | 58/125 [02:43<03:08,  2.82s/it]Evaluating:  47%|████▋     | 59/125 [02:46<03:05,  2.82s/it]Evaluating:  48%|████▊     | 60/125 [02:49<03:04,  2.84s/it]Evaluating:  49%|████▉     | 61/125 [02:52<061/125
62/125
63/125
64/125
65/125
66/125
67/125
68/125
69/125
70/125
71/125
72/125
73/125
Distributed index stop interation. Idx: 596 Total_length: 596
3:01,  2.83s/it]Evaluating:  50%|████▉     | 62/125 [02:55<02:58,  2.83s/it]Evaluating:  50%|█████     | 63/125 [02:58<02:55,  2.83s/it]Evaluating:  51%|█████     | 64/125 [03:00<02:52,  2.83s/it]Evaluating:  52%|█████▏    | 65/125 [03:03<02:49,  2.82s/it]Evaluating:  53%|█████▎    | 66/125 [03:06<02:46,  2.82s/it]Evaluating:  54%|█████▎    | 67/125 [03:09<02:44,  2.84s/it]Evaluating:  54%|█████▍    | 68/125 [03:12<02:41,  2.83s/it]Evaluating:  55%|█████▌    | 69/125 [03:14<02:38,  2.83s/it]Evaluating:  56%|█████▌    | 70/125 [03:17<02:35,  2.82s/it]Evaluating:  57%|█████▋    | 71/125 [03:20<02:32,  2.82s/it]Evaluating:  58%|█████▊    | 72/125 [03:23<02:29,  2.82s/it]Evaluating:  58%|█████▊    | 73/125 [03:26<02:26,  2.82s/it]Evaluating:  59%|█████▉    | 74/125 [03:29<02:24,  2.83s/it]Evaluating:  59%|█████▉    | 74/125 [03:29<02:24,  2.83s/it]
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1/eval/0
dev | avg_loss: 2.242730201901616 | {'exact_match': 0.0, 'rougeL': 5.0513}
Sun Apr  6 20:49:34 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla P100-PCIE-12GB           Off |   00000000:81:00.0 Off |                    0 |
| N/A   51C    P0             38W /  250W |    4959MiB /  12288MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A    244677      C   ...project_distillLLM/venv/bin/python3       4956MiB |
+-----------------------------------------------------------------------------------------+

train | epoch   0 | Iter:      1/  8460 | global iter:      1/  8460 | loss: 1.8024 | ds_loss: 0.0000 | lr: 5.0000e-04 | scale:     1.0000 | micro time: 0.619 | step time: 0.000
train | epoch   0 | Iter:      2/  8460 | global iter:      2/  8460 | loss: 4.2148 | ds_loss: 0.0000 | lr: 5.0000e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:      3/  8460 | global iter:      3/  8460 | loss: 5.0820 | ds_loss: 0.0000 | lr: 5.0000e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:      4/  8460 | global iter:      4/  8460 | loss: 3.1982 | ds_loss: 0.0000 | lr: 5.0000e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:      4/  8460 | global iter:      4/  8460 | loss: 3.5744 | ds_loss: 0.0000 | lr: 5.0000e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.476
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:      5/  8460 | global iter:      5/  8460 | loss: 2.2457 | ds_loss: 0.0000 | lr: 5.0000e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:      6/  8460 | global iter:      6/  8460 | loss: 2.5419 | ds_loss: 0.0000 | lr: 5.0000e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:      7/  8460 | global iter:      7/  8460 | loss: 2.4031 | ds_loss: 0.0000 | lr: 5.0000e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:      8/  8460 | global iter:      8/  8460 | loss: 2.6150 | ds_loss: 0.0000 | lr: 5.0000e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:      8/  8460 | global iter:      8/  8460 | loss: 2.4514 | ds_loss: 0.0000 | lr: 5.0000e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:      9/  8460 | global iter:      9/  8460 | loss: 1.8935 | ds_loss: 0.0000 | lr: 5.0000e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:     10/  8460 | global iter:     10/  8460 | loss: 1.2385 | ds_loss: 0.0000 | lr: 5.0000e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:     11/  8460 | global iter:     11/  8460 | loss: 1.4584 | ds_loss: 0.0000 | lr: 5.0000e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:     12/  8460 | global iter:     12/  8460 | loss: 2.2344 | ds_loss: 0.0000 | lr: 5.0000e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     12/  8460 | global iter:     12/  8460 | loss: 1.7062 | ds_loss: 0.0000 | lr: 5.0000e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:     13/  8460 | global iter:     13/  8460 | loss: 1.6037 | ds_loss: 0.0000 | lr: 5.0000e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     14/  8460 | global iter:     14/  8460 | loss: 1.2413 | ds_loss: 0.0000 | lr: 5.0000e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     15/  8460 | global iter:     15/  8460 | loss: 1.6502 | ds_loss: 0.0000 | lr: 5.0000e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     16/  8460 | global iter:     16/  8460 | loss: 0.7505 | ds_loss: 0.0000 | lr: 5.0000e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     16/  8460 | global iter:     16/  8460 | loss: 1.3114 | ds_loss: 0.0000 | lr: 5.0000e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:     17/  8460 | global iter:     17/  8460 | loss: 2.1340 | ds_loss: 0.0000 | lr: 5.0000e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:     18/  8460 | global iter:     18/  8460 | loss: 1.5193 | ds_loss: 0.0000 | lr: 4.9999e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     19/  8460 | global iter:     19/  8460 | loss: 1.7980 | ds_loss: 0.0000 | lr: 4.9999e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     20/  8460 | global iter:     20/  8460 | loss: 1.7150 | ds_loss: 0.0000 | lr: 4.9999e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     20/  8460 | global iter:     20/  8460 | loss: 1.7916 | ds_loss: 0.0000 | lr: 4.9999e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:     21/  8460 | global iter:     21/  8460 | loss: 1.8947 | ds_loss: 0.0000 | lr: 4.9999e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     22/  8460 | global iter:     22/  8460 | loss: 1.4613 | ds_loss: 0.0000 | lr: 4.9999e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:     23/  8460 | global iter:     23/  8460 | loss: 1.6847 | ds_loss: 0.0000 | lr: 4.9999e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:     24/  8460 | global iter:     24/  8460 | loss: 1.1535 | ds_loss: 0.0000 | lr: 4.9999e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     24/  8460 | global iter:     24/  8460 | loss: 1.5485 | ds_loss: 0.0000 | lr: 4.9999e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:     25/  8460 | global iter:     25/  8460 | loss: 1.7703 | ds_loss: 0.0000 | lr: 4.9999e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     26/  8460 | global iter:     26/  8460 | loss: 1.5246 | ds_loss: 0.0000 | lr: 4.9999e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     27/  8460 | global iter:     27/  8460 | loss: 1.8603 | ds_loss: 0.0000 | lr: 4.9999e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     28/  8460 | global iter:     28/  8460 | loss: 0.9313 | ds_loss: 0.0000 | lr: 4.9999e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     28/  8460 | global iter:     28/  8460 | loss: 1.5216 | ds_loss: 0.0000 | lr: 4.9999e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:     29/  8460 | global iter:     29/  8460 | loss: 0.8800 | ds_loss: 0.0000 | lr: 4.9999e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     30/  8460 | global iter:     30/  8460 | loss: 1.4670 | ds_loss: 0.0000 | lr: 4.9998e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:     31/  8460 | global iter:     31/  8460 | loss: 1.0061 | ds_loss: 0.0000 | lr: 4.9998e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:     32/  8460 | global iter:     32/  8460 | loss: 1.3507 | ds_loss: 0.0000 | lr: 4.9998e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     32/  8460 | global iter:     32/  8460 | loss: 1.1760 | ds_loss: 0.0000 | lr: 4.9998e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:     33/  8460 | global iter:     33/  8460 | loss: 2.1591 | ds_loss: 0.0000 | lr: 4.9998e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:     34/  8460 | global iter:     34/  8460 | loss: 1.6042 | ds_loss: 0.0000 | lr: 4.9998e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:     35/  8460 | global iter:     35/  8460 | loss: 0.8221 | ds_loss: 0.0000 | lr: 4.9998e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     36/  8460 | global iter:     36/  8460 | loss: 1.2165 | ds_loss: 0.0000 | lr: 4.9998e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     36/  8460 | global iter:     36/  8460 | loss: 1.4505 | ds_loss: 0.0000 | lr: 4.9998e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:     37/  8460 | global iter:     37/  8460 | loss: 0.9549 | ds_loss: 0.0000 | lr: 4.9998e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     38/  8460 | global iter:     38/  8460 | loss: 1.1027 | ds_loss: 0.0000 | lr: 4.9998e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     39/  8460 | global iter:     39/  8460 | loss: 1.3856 | ds_loss: 0.0000 | lr: 4.9997e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     40/  8460 | global iter:     40/  8460 | loss: 1.3269 | ds_loss: 0.0000 | lr: 4.9997e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     40/  8460 | global iter:     40/  8460 | loss: 1.1925 | ds_loss: 0.0000 | lr: 4.9997e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:     41/  8460 | global iter:     41/  8460 | loss: 1.2621 | ds_loss: 0.0000 | lr: 4.9997e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     42/  8460 | global iter:     42/  8460 | loss: 1.0353 | ds_loss: 0.0000 | lr: 4.9997e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     43/  8460 | global iter:     43/  8460 | loss: 1.8351 | ds_loss: 0.0000 | lr: 4.9997e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     44/  8460 | global iter:     44/  8460 | loss: 1.1069 | ds_loss: 0.0000 | lr: 4.9997e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     44/  8460 | global iter:     44/  8460 | loss: 1.3099 | ds_loss: 0.0000 | lr: 4.9997e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:     45/  8460 | global iter:     45/  8460 | loss: 0.9222 | ds_loss: 0.0000 | lr: 4.9997e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     46/  8460 | global iter:     46/  8460 | loss: 2.5529 | ds_loss: 0.0000 | lr: 4.9996e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:     47/  8460 | global iter:     47/  8460 | loss: 1.9199 | ds_loss: 0.0000 | lr: 4.9996e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     48/  8460 | global iter:     48/  8460 | loss: 2.0076 | ds_loss: 0.0000 | lr: 4.9996e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     48/  8460 | global iter:     48/  8460 | loss: 1.8507 | ds_loss: 0.0000 | lr: 4.9996e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:     49/  8460 | global iter:     49/  8460 | loss: 0.6862 | ds_loss: 0.0000 | lr: 4.9996e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     50/  8460 | global iter:     50/  8460 | loss: 0.4284 | ds_loss: 0.0000 | lr: 4.9996e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     51/  8460 | global iter:     51/  8460 | loss: 1.6842 | ds_loss: 0.0000 | lr: 4.9996e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     52/  8460 | global iter:     52/  8460 | loss: 0.8625 | ds_loss: 0.0000 | lr: 4.9995e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     52/  8460 | global iter:     52/  8460 | loss: 0.9153 | ds_loss: 0.0000 | lr: 4.9995e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:     53/  8460 | global iter:     53/  8460 | loss: 1.3005 | ds_loss: 0.0000 | lr: 4.9995e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     54/  8460 | global iter:     54/  8460 | loss: 1.4852 | ds_loss: 0.0000 | lr: 4.9995e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:     55/  8460 | global iter:     55/  8460 | loss: 1.1252 | ds_loss: 0.0000 | lr: 4.9995e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     56/  8460 | global iter:     56/  8460 | loss: 0.5484 | ds_loss: 0.0000 | lr: 4.9995e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     56/  8460 | global iter:     56/  8460 | loss: 1.1148 | ds_loss: 0.0000 | lr: 4.9995e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:     57/  8460 | global iter:     57/  8460 | loss: 1.1184 | ds_loss: 0.0000 | lr: 4.9994e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     58/  8460 | global iter:     58/  8460 | loss: 0.8894 | ds_loss: 0.0000 | lr: 4.9994e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:     59/  8460 | global iter:     59/  8460 | loss: 0.6223 | ds_loss: 0.0000 | lr: 4.9994e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     60/  8460 | global iter:     60/  8460 | loss: 1.8914 | ds_loss: 0.0000 | lr: 4.9994e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     60/  8460 | global iter:     60/  8460 | loss: 1.1304 | ds_loss: 0.0000 | lr: 4.9994e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:     61/  8460 | global iter:     61/  8460 | loss: 0.9449 | ds_loss: 0.0000 | lr: 4.9994e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     62/  8460 | global iter:     62/  8460 | loss: 1.2295 | ds_loss: 0.0000 | lr: 4.9993e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     63/  8460 | global iter:     63/  8460 | loss: 0.6771 | ds_loss: 0.0000 | lr: 4.9993e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     64/  8460 | global iter:     64/  8460 | loss: 0.6843 | ds_loss: 0.0000 | lr: 4.9993e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     64/  8460 | global iter:     64/  8460 | loss: 0.8840 | ds_loss: 0.0000 | lr: 4.9993e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:     65/  8460 | global iter:     65/  8460 | loss: 1.6822 | ds_loss: 0.0000 | lr: 4.9993e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     66/  8460 | global iter:     66/  8460 | loss: 1.4862 | ds_loss: 0.0000 | lr: 4.9992e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     67/  8460 | global iter:     67/  8460 | loss: 1.1170 | ds_loss: 0.0000 | lr: 4.9992e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:     68/  8460 | global iter:     68/  8460 | loss: 0.9573 | ds_loss: 0.0000 | lr: 4.9992e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     68/  8460 | global iter:     68/  8460 | loss: 1.3107 | ds_loss: 0.0000 | lr: 4.9992e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:     69/  8460 | global iter:     69/  8460 | loss: 0.7148 | ds_loss: 0.0000 | lr: 4.9992e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     70/  8460 | global iter:     70/  8460 | loss: 1.2890 | ds_loss: 0.0000 | lr: 4.9992e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:     71/  8460 | global iter:     71/  8460 | loss: 1.2254 | ds_loss: 0.0000 | lr: 4.9991e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     72/  8460 | global iter:     72/  8460 | loss: 0.7657 | ds_loss: 0.0000 | lr: 4.9991e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     72/  8460 | global iter:     72/  8460 | loss: 0.9987 | ds_loss: 0.0000 | lr: 4.9991e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:     73/  8460 | global iter:     73/  8460 | loss: 0.7064 | ds_loss: 0.0000 | lr: 4.9991e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     74/  8460 | global iter:     74/  8460 | loss: 0.9158 | ds_loss: 0.0000 | lr: 4.9991e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     75/  8460 | global iter:     75/  8460 | loss: 1.0517 | ds_loss: 0.0000 | lr: 4.9990e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     76/  8460 | global iter:     76/  8460 | loss: 0.4310 | ds_loss: 0.0000 | lr: 4.9990e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     76/  8460 | global iter:     76/  8460 | loss: 0.7762 | ds_loss: 0.0000 | lr: 4.9990e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:     77/  8460 | global iter:     77/  8460 | loss: 1.2696 | ds_loss: 0.0000 | lr: 4.9990e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:     78/  8460 | global iter:     78/  8460 | loss: 1.7104 | ds_loss: 0.0000 | lr: 4.9990e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:     79/  8460 | global iter:     79/  8460 | loss: 1.4757 | ds_loss: 0.0000 | lr: 4.9989e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:     80/  8460 | global iter:     80/  8460 | loss: 1.0640 | ds_loss: 0.0000 | lr: 4.9989e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     80/  8460 | global iter:     80/  8460 | loss: 1.3799 | ds_loss: 0.0000 | lr: 4.9989e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:     81/  8460 | global iter:     81/  8460 | loss: 1.2654 | ds_loss: 0.0000 | lr: 4.9989e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:     82/  8460 | global iter:     82/  8460 | loss: 0.6971 | ds_loss: 0.0000 | lr: 4.9988e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     83/  8460 | global iter:     83/  8460 | loss: 1.4022 | ds_loss: 0.0000 | lr: 4.9988e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     84/  8460 | global iter:     84/  8460 | loss: 1.5822 | ds_loss: 0.0000 | lr: 4.9988e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     84/  8460 | global iter:     84/  8460 | loss: 1.2367 | ds_loss: 0.0000 | lr: 4.9988e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:     85/  8460 | global iter:     85/  8460 | loss: 0.8015 | ds_loss: 0.0000 | lr: 4.9988e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     86/  8460 | global iter:     86/  8460 | loss: 1.5350 | ds_loss: 0.0000 | lr: 4.9987e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     87/  8460 | global iter:     87/  8460 | loss: 0.9552 | ds_loss: 0.0000 | lr: 4.9987e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:     88/  8460 | global iter:     88/  8460 | loss: 1.8643 | ds_loss: 0.0000 | lr: 4.9987e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     88/  8460 | global iter:     88/  8460 | loss: 1.2890 | ds_loss: 0.0000 | lr: 4.9987e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:     89/  8460 | global iter:     89/  8460 | loss: 0.7436 | ds_loss: 0.0000 | lr: 4.9986e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     90/  8460 | global iter:     90/  8460 | loss: 1.8723 | ds_loss: 0.0000 | lr: 4.9986e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:     91/  8460 | global iter:     91/  8460 | loss: 0.5017 | ds_loss: 0.0000 | lr: 4.9986e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:     92/  8460 | global iter:     92/  8460 | loss: 1.0076 | ds_loss: 0.0000 | lr: 4.9985e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     92/  8460 | global iter:     92/  8460 | loss: 1.0313 | ds_loss: 0.0000 | lr: 4.9985e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:     93/  8460 | global iter:     93/  8460 | loss: 1.2293 | ds_loss: 0.0000 | lr: 4.9985e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     94/  8460 | global iter:     94/  8460 | loss: 0.8576 | ds_loss: 0.0000 | lr: 4.9985e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:     95/  8460 | global iter:     95/  8460 | loss: 1.0992 | ds_loss: 0.0000 | lr: 4.9984e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     96/  8460 | global iter:     96/  8460 | loss: 1.8207 | ds_loss: 0.0000 | lr: 4.9984e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     96/  8460 | global iter:     96/  8460 | loss: 1.2517 | ds_loss: 0.0000 | lr: 4.9984e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:     97/  8460 | global iter:     97/  8460 | loss: 1.4796 | ds_loss: 0.0000 | lr: 4.9984e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     98/  8460 | global iter:     98/  8460 | loss: 0.8428 | ds_loss: 0.0000 | lr: 4.9983e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:     99/  8460 | global iter:     99/  8460 | loss: 1.9406 | ds_loss: 0.0000 | lr: 4.9983e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    100/  8460 | global iter:    100/  8460 | loss: 1.0199 | ds_loss: 0.0000 | lr: 4.9983e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    100/  8460 | global iter:    100/  8460 | loss: 1.3207 | ds_loss: 0.0000 | lr: 4.9983e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    101/  8460 | global iter:    101/  8460 | loss: 1.8570 | ds_loss: 0.0000 | lr: 4.9982e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    102/  8460 | global iter:    102/  8460 | loss: 1.0683 | ds_loss: 0.0000 | lr: 4.9982e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    103/  8460 | global iter:    103/  8460 | loss: 1.3082 | ds_loss: 0.0000 | lr: 4.9982e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    104/  8460 | global iter:    104/  8460 | loss: 1.4899 | ds_loss: 0.0000 | lr: 4.9981e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    104/  8460 | global iter:    104/  8460 | loss: 1.4309 | ds_loss: 0.0000 | lr: 4.9981e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    105/  8460 | global iter:    105/  8460 | loss: 1.5581 | ds_loss: 0.0000 | lr: 4.9981e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    106/  8460 | global iter:    106/  8460 | loss: 0.9092 | ds_loss: 0.0000 | lr: 4.9981e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    107/  8460 | global iter:    107/  8460 | loss: 1.4509 | ds_loss: 0.0000 | lr: 4.9980e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    108/  8460 | global iter:    108/  8460 | loss: 0.8253 | ds_loss: 0.0000 | lr: 4.9980e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    108/  8460 | global iter:    108/  8460 | loss: 1.1859 | ds_loss: 0.0000 | lr: 4.9980e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    109/  8460 | global iter:    109/  8460 | loss: 0.9854 | ds_loss: 0.0000 | lr: 4.9980e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    110/  8460 | global iter:    110/  8460 | loss: 0.7789 | ds_loss: 0.0000 | lr: 4.9979e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    111/  8460 | global iter:    111/  8460 | loss: 1.3728 | ds_loss: 0.0000 | lr: 4.9979e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    112/  8460 | global iter:    112/  8460 | loss: 0.5907 | ds_loss: 0.0000 | lr: 4.9978e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    112/  8460 | global iter:    112/  8460 | loss: 0.9320 | ds_loss: 0.0000 | lr: 4.9978e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    113/  8460 | global iter:    113/  8460 | loss: 1.6599 | ds_loss: 0.0000 | lr: 4.9978e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    114/  8460 | global iter:    114/  8460 | loss: 1.1542 | ds_loss: 0.0000 | lr: 4.9978e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    115/  8460 | global iter:    115/  8460 | loss: 0.3462 | ds_loss: 0.0000 | lr: 4.9977e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    116/  8460 | global iter:    116/  8460 | loss: 0.9430 | ds_loss: 0.0000 | lr: 4.9977e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    116/  8460 | global iter:    116/  8460 | loss: 1.0258 | ds_loss: 0.0000 | lr: 4.9977e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    117/  8460 | global iter:    117/  8460 | loss: 1.8765 | ds_loss: 0.0000 | lr: 4.9976e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    118/  8460 | global iter:    118/  8460 | loss: 1.6236 | ds_loss: 0.0000 | lr: 4.9976e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    119/  8460 | global iter:    119/  8460 | loss: 1.2902 | ds_loss: 0.0000 | lr: 4.9976e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    120/  8460 | global iter:    120/  8460 | loss: 1.1466 | ds_loss: 0.0000 | lr: 4.9975e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    120/  8460 | global iter:    120/  8460 | loss: 1.4842 | ds_loss: 0.0000 | lr: 4.9975e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    121/  8460 | global iter:    121/  8460 | loss: 0.8125 | ds_loss: 0.0000 | lr: 4.9975e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    122/  8460 | global iter:    122/  8460 | loss: 0.8973 | ds_loss: 0.0000 | lr: 4.9974e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    123/  8460 | global iter:    123/  8460 | loss: 0.7311 | ds_loss: 0.0000 | lr: 4.9974e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    124/  8460 | global iter:    124/  8460 | loss: 0.9398 | ds_loss: 0.0000 | lr: 4.9974e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    124/  8460 | global iter:    124/  8460 | loss: 0.8452 | ds_loss: 0.0000 | lr: 4.9974e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    125/  8460 | global iter:    125/  8460 | loss: 1.2689 | ds_loss: 0.0000 | lr: 4.9973e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    126/  8460 | global iter:    126/  8460 | loss: 0.7817 | ds_loss: 0.0000 | lr: 4.9973e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    127/  8460 | global iter:    127/  8460 | loss: 0.7526 | ds_loss: 0.0000 | lr: 4.9972e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    128/  8460 | global iter:    128/  8460 | loss: 0.8726 | ds_loss: 0.0000 | lr: 4.9972e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    128/  8460 | global iter:    128/  8460 | loss: 0.9190 | ds_loss: 0.0000 | lr: 4.9972e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    129/  8460 | global iter:    129/  8460 | loss: 0.8887 | ds_loss: 0.0000 | lr: 4.9971e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    130/  8460 | global iter:    130/  8460 | loss: 1.2796 | ds_loss: 0.0000 | lr: 4.9971e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    131/  8460 | global iter:    131/  8460 | loss: 1.1490 | ds_loss: 0.0000 | lr: 4.9970e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    132/  8460 | global iter:    132/  8460 | loss: 1.4114 | ds_loss: 0.0000 | lr: 4.9970e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    132/  8460 | global iter:    132/  8460 | loss: 1.1822 | ds_loss: 0.0000 | lr: 4.9970e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    133/  8460 | global iter:    133/  8460 | loss: 1.2144 | ds_loss: 0.0000 | lr: 4.9970e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    134/  8460 | global iter:    134/  8460 | loss: 0.9073 | ds_loss: 0.0000 | lr: 4.9969e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    135/  8460 | global iter:    135/  8460 | loss: 0.7568 | ds_loss: 0.0000 | lr: 4.9969e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    136/  8460 | global iter:    136/  8460 | loss: 0.7242 | ds_loss: 0.0000 | lr: 4.9968e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    136/  8460 | global iter:    136/  8460 | loss: 0.9007 | ds_loss: 0.0000 | lr: 4.9968e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    137/  8460 | global iter:    137/  8460 | loss: 0.8700 | ds_loss: 0.0000 | lr: 4.9968e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    138/  8460 | global iter:    138/  8460 | loss: 1.4222 | ds_loss: 0.0000 | lr: 4.9967e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    139/  8460 | global iter:    139/  8460 | loss: 0.9180 | ds_loss: 0.0000 | lr: 4.9967e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    140/  8460 | global iter:    140/  8460 | loss: 1.1357 | ds_loss: 0.0000 | lr: 4.9966e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    140/  8460 | global iter:    140/  8460 | loss: 1.0865 | ds_loss: 0.0000 | lr: 4.9966e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    141/  8460 | global iter:    141/  8460 | loss: 0.7758 | ds_loss: 0.0000 | lr: 4.9966e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    142/  8460 | global iter:    142/  8460 | loss: 1.2009 | ds_loss: 0.0000 | lr: 4.9965e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    143/  8460 | global iter:    143/  8460 | loss: 0.9149 | ds_loss: 0.0000 | lr: 4.9965e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    144/  8460 | global iter:    144/  8460 | loss: 0.5670 | ds_loss: 0.0000 | lr: 4.9964e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    144/  8460 | global iter:    144/  8460 | loss: 0.8646 | ds_loss: 0.0000 | lr: 4.9964e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    145/  8460 | global iter:    145/  8460 | loss: 0.9625 | ds_loss: 0.0000 | lr: 4.9964e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    146/  8460 | global iter:    146/  8460 | loss: 0.7362 | ds_loss: 0.0000 | lr: 4.9963e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    147/  8460 | global iter:    147/  8460 | loss: 0.8032 | ds_loss: 0.0000 | lr: 4.9963e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    148/  8460 | global iter:    148/  8460 | loss: 1.4543 | ds_loss: 0.0000 | lr: 4.9962e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    148/  8460 | global iter:    148/  8460 | loss: 0.9891 | ds_loss: 0.0000 | lr: 4.9962e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    149/  8460 | global iter:    149/  8460 | loss: 2.2974 | ds_loss: 0.0000 | lr: 4.9962e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    150/  8460 | global iter:    150/  8460 | loss: 1.4763 | ds_loss: 0.0000 | lr: 4.9961e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    151/  8460 | global iter:    151/  8460 | loss: 0.6905 | ds_loss: 0.0000 | lr: 4.9961e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    152/  8460 | global iter:    152/  8460 | loss: 0.6777 | ds_loss: 0.0000 | lr: 4.9960e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    152/  8460 | global iter:    152/  8460 | loss: 1.2855 | ds_loss: 0.0000 | lr: 4.9960e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    153/  8460 | global iter:    153/  8460 | loss: 1.6509 | ds_loss: 0.0000 | lr: 4.9960e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    154/  8460 | global iter:    154/  8460 | loss: 1.0114 | ds_loss: 0.0000 | lr: 4.9959e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    155/  8460 | global iter:    155/  8460 | loss: 0.7751 | ds_loss: 0.0000 | lr: 4.9959e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    156/  8460 | global iter:    156/  8460 | loss: 0.8130 | ds_loss: 0.0000 | lr: 4.9958e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    156/  8460 | global iter:    156/  8460 | loss: 1.0626 | ds_loss: 0.0000 | lr: 4.9958e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    157/  8460 | global iter:    157/  8460 | loss: 1.0600 | ds_loss: 0.0000 | lr: 4.9958e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    158/  8460 | global iter:    158/  8460 | loss: 0.7433 | ds_loss: 0.0000 | lr: 4.9957e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    159/  8460 | global iter:    159/  8460 | loss: 1.8854 | ds_loss: 0.0000 | lr: 4.9956e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    160/  8460 | global iter:    160/  8460 | loss: 1.5202 | ds_loss: 0.0000 | lr: 4.9956e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    160/  8460 | global iter:    160/  8460 | loss: 1.3022 | ds_loss: 0.0000 | lr: 4.9956e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    161/  8460 | global iter:    161/  8460 | loss: 0.6609 | ds_loss: 0.0000 | lr: 4.9955e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    162/  8460 | global iter:    162/  8460 | loss: 0.8793 | ds_loss: 0.0000 | lr: 4.9955e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    163/  8460 | global iter:    163/  8460 | loss: 1.1751 | ds_loss: 0.0000 | lr: 4.9954e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    164/  8460 | global iter:    164/  8460 | loss: 1.4159 | ds_loss: 0.0000 | lr: 4.9954e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    164/  8460 | global iter:    164/  8460 | loss: 1.0328 | ds_loss: 0.0000 | lr: 4.9954e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    165/  8460 | global iter:    165/  8460 | loss: 1.4179 | ds_loss: 0.0000 | lr: 4.9953e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    166/  8460 | global iter:    166/  8460 | loss: 0.5671 | ds_loss: 0.0000 | lr: 4.9953e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    167/  8460 | global iter:    167/  8460 | loss: 1.9725 | ds_loss: 0.0000 | lr: 4.9952e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    168/  8460 | global iter:    168/  8460 | loss: 1.0484 | ds_loss: 0.0000 | lr: 4.9951e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    168/  8460 | global iter:    168/  8460 | loss: 1.2515 | ds_loss: 0.0000 | lr: 4.9951e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    169/  8460 | global iter:    169/  8460 | loss: 1.1368 | ds_loss: 0.0000 | lr: 4.9951e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    170/  8460 | global iter:    170/  8460 | loss: 0.9098 | ds_loss: 0.0000 | lr: 4.9950e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    171/  8460 | global iter:    171/  8460 | loss: 0.9836 | ds_loss: 0.0000 | lr: 4.9950e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    172/  8460 | global iter:    172/  8460 | loss: 0.7756 | ds_loss: 0.0000 | lr: 4.9949e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    172/  8460 | global iter:    172/  8460 | loss: 0.9515 | ds_loss: 0.0000 | lr: 4.9949e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    173/  8460 | global iter:    173/  8460 | loss: 1.2013 | ds_loss: 0.0000 | lr: 4.9948e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    174/  8460 | global iter:    174/  8460 | loss: 1.6063 | ds_loss: 0.0000 | lr: 4.9948e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    175/  8460 | global iter:    175/  8460 | loss: 0.9799 | ds_loss: 0.0000 | lr: 4.9947e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    176/  8460 | global iter:    176/  8460 | loss: 2.4094 | ds_loss: 0.0000 | lr: 4.9947e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    176/  8460 | global iter:    176/  8460 | loss: 1.5492 | ds_loss: 0.0000 | lr: 4.9947e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    177/  8460 | global iter:    177/  8460 | loss: 0.8140 | ds_loss: 0.0000 | lr: 4.9946e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    178/  8460 | global iter:    178/  8460 | loss: 1.2979 | ds_loss: 0.0000 | lr: 4.9945e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    179/  8460 | global iter:    179/  8460 | loss: 0.5890 | ds_loss: 0.0000 | lr: 4.9945e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    180/  8460 | global iter:    180/  8460 | loss: 1.4597 | ds_loss: 0.0000 | lr: 4.9944e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    180/  8460 | global iter:    180/  8460 | loss: 1.0401 | ds_loss: 0.0000 | lr: 4.9944e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    181/  8460 | global iter:    181/  8460 | loss: 1.6536 | ds_loss: 0.0000 | lr: 4.9944e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    182/  8460 | global iter:    182/  8460 | loss: 1.1488 | ds_loss: 0.0000 | lr: 4.9943e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    183/  8460 | global iter:    183/  8460 | loss: 1.7640 | ds_loss: 0.0000 | lr: 4.9942e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    184/  8460 | global iter:    184/  8460 | loss: 1.0739 | ds_loss: 0.0000 | lr: 4.9942e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    184/  8460 | global iter:    184/  8460 | loss: 1.4101 | ds_loss: 0.0000 | lr: 4.9942e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    185/  8460 | global iter:    185/  8460 | loss: 1.2462 | ds_loss: 0.0000 | lr: 4.9941e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    186/  8460 | global iter:    186/  8460 | loss: 0.6188 | ds_loss: 0.0000 | lr: 4.9940e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    187/  8460 | global iter:    187/  8460 | loss: 0.6838 | ds_loss: 0.0000 | lr: 4.9940e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    188/  8460 | global iter:    188/  8460 | loss: 0.6333 | ds_loss: 0.0000 | lr: 4.9939e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    188/  8460 | global iter:    188/  8460 | loss: 0.7955 | ds_loss: 0.0000 | lr: 4.9939e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    189/  8460 | global iter:    189/  8460 | loss: 0.5775 | ds_loss: 0.0000 | lr: 4.9938e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    190/  8460 | global iter:    190/  8460 | loss: 0.8793 | ds_loss: 0.0000 | lr: 4.9938e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    191/  8460 | global iter:    191/  8460 | loss: 0.9311 | ds_loss: 0.0000 | lr: 4.9937e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    192/  8460 | global iter:    192/  8460 | loss: 0.8007 | ds_loss: 0.0000 | lr: 4.9936e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    192/  8460 | global iter:    192/  8460 | loss: 0.7972 | ds_loss: 0.0000 | lr: 4.9936e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    193/  8460 | global iter:    193/  8460 | loss: 0.8088 | ds_loss: 0.0000 | lr: 4.9936e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    194/  8460 | global iter:    194/  8460 | loss: 0.4654 | ds_loss: 0.0000 | lr: 4.9935e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    195/  8460 | global iter:    195/  8460 | loss: 1.1306 | ds_loss: 0.0000 | lr: 4.9934e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    196/  8460 | global iter:    196/  8460 | loss: 1.5392 | ds_loss: 0.0000 | lr: 4.9934e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    196/  8460 | global iter:    196/  8460 | loss: 0.9860 | ds_loss: 0.0000 | lr: 4.9934e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    197/  8460 | global iter:    197/  8460 | loss: 1.4474 | ds_loss: 0.0000 | lr: 4.9933e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    198/  8460 | global iter:    198/  8460 | loss: 1.7428 | ds_loss: 0.0000 | lr: 4.9932e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    199/  8460 | global iter:    199/  8460 | loss: 1.4096 | ds_loss: 0.0000 | lr: 4.9932e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    200/  8460 | global iter:    200/  8460 | loss: 1.2791 | ds_loss: 0.0000 | lr: 4.9931e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    200/  8460 | global iter:    200/  8460 | loss: 1.4697 | ds_loss: 0.0000 | lr: 4.9931e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    201/  8460 | global iter:    201/  8460 | loss: 2.3347 | ds_loss: 0.0000 | lr: 4.9930e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    202/  8460 | global iter:    202/  8460 | loss: 0.8879 | ds_loss: 0.0000 | lr: 4.9930e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    203/  8460 | global iter:    203/  8460 | loss: 1.1083 | ds_loss: 0.0000 | lr: 4.9929e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    204/  8460 | global iter:    204/  8460 | loss: 1.4346 | ds_loss: 0.0000 | lr: 4.9928e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    204/  8460 | global iter:    204/  8460 | loss: 1.4414 | ds_loss: 0.0000 | lr: 4.9928e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    205/  8460 | global iter:    205/  8460 | loss: 0.6321 | ds_loss: 0.0000 | lr: 4.9928e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    206/  8460 | global iter:    206/  8460 | loss: 0.7970 | ds_loss: 0.0000 | lr: 4.9927e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    207/  8460 | global iter:    207/  8460 | loss: 0.7257 | ds_loss: 0.0000 | lr: 4.9926e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    208/  8460 | global iter:    208/  8460 | loss: 0.7376 | ds_loss: 0.0000 | lr: 4.9925e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    208/  8460 | global iter:    208/  8460 | loss: 0.7231 | ds_loss: 0.0000 | lr: 4.9925e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    209/  8460 | global iter:    209/  8460 | loss: 0.6440 | ds_loss: 0.0000 | lr: 4.9925e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    210/  8460 | global iter:    210/  8460 | loss: 0.5317 | ds_loss: 0.0000 | lr: 4.9924e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    211/  8460 | global iter:    211/  8460 | loss: 1.4750 | ds_loss: 0.0000 | lr: 4.9923e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    212/  8460 | global iter:    212/  8460 | loss: 0.4105 | ds_loss: 0.0000 | lr: 4.9923e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    212/  8460 | global iter:    212/  8460 | loss: 0.7653 | ds_loss: 0.0000 | lr: 4.9923e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    213/  8460 | global iter:    213/  8460 | loss: 1.7810 | ds_loss: 0.0000 | lr: 4.9922e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    214/  8460 | global iter:    214/  8460 | loss: 1.4446 | ds_loss: 0.0000 | lr: 4.9921e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    215/  8460 | global iter:    215/  8460 | loss: 1.9489 | ds_loss: 0.0000 | lr: 4.9920e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    216/  8460 | global iter:    216/  8460 | loss: 0.9893 | ds_loss: 0.0000 | lr: 4.9920e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    216/  8460 | global iter:    216/  8460 | loss: 1.5409 | ds_loss: 0.0000 | lr: 4.9920e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    217/  8460 | global iter:    217/  8460 | loss: 0.5655 | ds_loss: 0.0000 | lr: 4.9919e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    218/  8460 | global iter:    218/  8460 | loss: 0.6736 | ds_loss: 0.0000 | lr: 4.9918e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    219/  8460 | global iter:    219/  8460 | loss: 1.7904 | ds_loss: 0.0000 | lr: 4.9917e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    220/  8460 | global iter:    220/  8460 | loss: 0.3490 | ds_loss: 0.0000 | lr: 4.9917e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    220/  8460 | global iter:    220/  8460 | loss: 0.8446 | ds_loss: 0.0000 | lr: 4.9917e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    221/  8460 | global iter:    221/  8460 | loss: 0.9436 | ds_loss: 0.0000 | lr: 4.9916e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    222/  8460 | global iter:    222/  8460 | loss: 0.3978 | ds_loss: 0.0000 | lr: 4.9915e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    223/  8460 | global iter:    223/  8460 | loss: 0.5763 | ds_loss: 0.0000 | lr: 4.9914e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    224/  8460 | global iter:    224/  8460 | loss: 1.2205 | ds_loss: 0.0000 | lr: 4.9914e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    224/  8460 | global iter:    224/  8460 | loss: 0.7845 | ds_loss: 0.0000 | lr: 4.9914e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    225/  8460 | global iter:    225/  8460 | loss: 0.9817 | ds_loss: 0.0000 | lr: 4.9913e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    226/  8460 | global iter:    226/  8460 | loss: 1.1640 | ds_loss: 0.0000 | lr: 4.9912e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    227/  8460 | global iter:    227/  8460 | loss: 0.4546 | ds_loss: 0.0000 | lr: 4.9911e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    228/  8460 | global iter:    228/  8460 | loss: 0.4531 | ds_loss: 0.0000 | lr: 4.9910e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    228/  8460 | global iter:    228/  8460 | loss: 0.7633 | ds_loss: 0.0000 | lr: 4.9910e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    229/  8460 | global iter:    229/  8460 | loss: 1.3134 | ds_loss: 0.0000 | lr: 4.9910e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    230/  8460 | global iter:    230/  8460 | loss: 0.6031 | ds_loss: 0.0000 | lr: 4.9909e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    231/  8460 | global iter:    231/  8460 | loss: 0.6961 | ds_loss: 0.0000 | lr: 4.9908e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    232/  8460 | global iter:    232/  8460 | loss: 1.1153 | ds_loss: 0.0000 | lr: 4.9907e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    232/  8460 | global iter:    232/  8460 | loss: 0.9320 | ds_loss: 0.0000 | lr: 4.9907e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    233/  8460 | global iter:    233/  8460 | loss: 1.1507 | ds_loss: 0.0000 | lr: 4.9906e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    234/  8460 | global iter:    234/  8460 | loss: 1.2073 | ds_loss: 0.0000 | lr: 4.9906e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    235/  8460 | global iter:    235/  8460 | loss: 0.8592 | ds_loss: 0.0000 | lr: 4.9905e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    236/  8460 | global iter:    236/  8460 | loss: 0.9844 | ds_loss: 0.0000 | lr: 4.9904e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    236/  8460 | global iter:    236/  8460 | loss: 1.0504 | ds_loss: 0.0000 | lr: 4.9904e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    237/  8460 | global iter:    237/  8460 | loss: 1.9590 | ds_loss: 0.0000 | lr: 4.9903e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    238/  8460 | global iter:    238/  8460 | loss: 1.9470 | ds_loss: 0.0000 | lr: 4.9902e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    239/  8460 | global iter:    239/  8460 | loss: 1.3640 | ds_loss: 0.0000 | lr: 4.9902e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    240/  8460 | global iter:    240/  8460 | loss: 0.7565 | ds_loss: 0.0000 | lr: 4.9901e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    240/  8460 | global iter:    240/  8460 | loss: 1.5066 | ds_loss: 0.0000 | lr: 4.9901e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    241/  8460 | global iter:    241/  8460 | loss: 1.0870 | ds_loss: 0.0000 | lr: 4.9900e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    242/  8460 | global iter:    242/  8460 | loss: 1.2003 | ds_loss: 0.0000 | lr: 4.9899e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    243/  8460 | global iter:    243/  8460 | loss: 1.1234 | ds_loss: 0.0000 | lr: 4.9898e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    244/  8460 | global iter:    244/  8460 | loss: 0.6874 | ds_loss: 0.0000 | lr: 4.9897e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    244/  8460 | global iter:    244/  8460 | loss: 1.0245 | ds_loss: 0.0000 | lr: 4.9897e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    245/  8460 | global iter:    245/  8460 | loss: 0.9205 | ds_loss: 0.0000 | lr: 4.9897e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    246/  8460 | global iter:    246/  8460 | loss: 0.5710 | ds_loss: 0.0000 | lr: 4.9896e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    247/  8460 | global iter:    247/  8460 | loss: 0.8065 | ds_loss: 0.0000 | lr: 4.9895e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    248/  8460 | global iter:    248/  8460 | loss: 1.4494 | ds_loss: 0.0000 | lr: 4.9894e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    248/  8460 | global iter:    248/  8460 | loss: 0.9368 | ds_loss: 0.0000 | lr: 4.9894e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    249/  8460 | global iter:    249/  8460 | loss: 0.9488 | ds_loss: 0.0000 | lr: 4.9893e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    250/  8460 | global iter:    250/  8460 | loss: 0.6866 | ds_loss: 0.0000 | lr: 4.9892e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    251/  8460 | global iter:    251/  8460 | loss: 0.9567 | ds_loss: 0.0000 | lr: 4.9892e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    252/  8460 | global iter:    252/  8460 | loss: 0.8727 | ds_loss: 0.0000 | lr: 4.9891e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    252/  8460 | global iter:    252/  8460 | loss: 0.8662 | ds_loss: 0.0000 | lr: 4.9891e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    253/  8460 | global iter:    253/  8460 | loss: 1.5369 | ds_loss: 0.0000 | lr: 4.9890e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    254/  8460 | global iter:    254/  8460 | loss: 2.1988 | ds_loss: 0.0000 | lr: 4.9889e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    255/  8460 | global iter:    255/  8460 | loss: 0.7767 | ds_loss: 0.0000 | lr: 4.9888e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    256/  8460 | global iter:    256/  8460 | loss: 0.6125 | ds_loss: 0.0000 | lr: 4.9887e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    256/  8460 | global iter:    256/  8460 | loss: 1.2812 | ds_loss: 0.0000 | lr: 4.9887e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    257/  8460 | global iter:    257/  8460 | loss: 0.9566 | ds_loss: 0.0000 | lr: 4.9886e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    258/  8460 | global iter:    258/  8460 | loss: 1.1027 | ds_loss: 0.0000 | lr: 4.9885e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    259/  8460 | global iter:    259/  8460 | loss: 0.7596 | ds_loss: 0.0000 | lr: 4.9884e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    260/  8460 | global iter:    260/  8460 | loss: 0.6946 | ds_loss: 0.0000 | lr: 4.9884e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    260/  8460 | global iter:    260/  8460 | loss: 0.8784 | ds_loss: 0.0000 | lr: 4.9884e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    261/  8460 | global iter:    261/  8460 | loss: 0.6767 | ds_loss: 0.0000 | lr: 4.9883e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    262/  8460 | global iter:    262/  8460 | loss: 1.1135 | ds_loss: 0.0000 | lr: 4.9882e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    263/  8460 | global iter:    263/  8460 | loss: 0.5135 | ds_loss: 0.0000 | lr: 4.9881e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    264/  8460 | global iter:    264/  8460 | loss: 0.7901 | ds_loss: 0.0000 | lr: 4.9880e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    264/  8460 | global iter:    264/  8460 | loss: 0.7734 | ds_loss: 0.0000 | lr: 4.9880e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    265/  8460 | global iter:    265/  8460 | loss: 1.0456 | ds_loss: 0.0000 | lr: 4.9879e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    266/  8460 | global iter:    266/  8460 | loss: 2.2938 | ds_loss: 0.0000 | lr: 4.9878e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    267/  8460 | global iter:    267/  8460 | loss: 0.8687 | ds_loss: 0.0000 | lr: 4.9877e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    268/  8460 | global iter:    268/  8460 | loss: 0.7322 | ds_loss: 0.0000 | lr: 4.9876e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    268/  8460 | global iter:    268/  8460 | loss: 1.2351 | ds_loss: 0.0000 | lr: 4.9876e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    269/  8460 | global iter:    269/  8460 | loss: 1.5979 | ds_loss: 0.0000 | lr: 4.9875e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    270/  8460 | global iter:    270/  8460 | loss: 0.9753 | ds_loss: 0.0000 | lr: 4.9874e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    271/  8460 | global iter:    271/  8460 | loss: 0.9968 | ds_loss: 0.0000 | lr: 4.9874e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    272/  8460 | global iter:    272/  8460 | loss: 0.5986 | ds_loss: 0.0000 | lr: 4.9873e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    272/  8460 | global iter:    272/  8460 | loss: 1.0421 | ds_loss: 0.0000 | lr: 4.9873e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    273/  8460 | global iter:    273/  8460 | loss: 0.9250 | ds_loss: 0.0000 | lr: 4.9872e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    274/  8460 | global iter:    274/  8460 | loss: 0.8923 | ds_loss: 0.0000 | lr: 4.9871e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    275/  8460 | global iter:    275/  8460 | loss: 0.3154 | ds_loss: 0.0000 | lr: 4.9870e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    276/  8460 | global iter:    276/  8460 | loss: 0.8891 | ds_loss: 0.0000 | lr: 4.9869e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    276/  8460 | global iter:    276/  8460 | loss: 0.7554 | ds_loss: 0.0000 | lr: 4.9869e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    277/  8460 | global iter:    277/  8460 | loss: 1.3040 | ds_loss: 0.0000 | lr: 4.9868e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    278/  8460 | global iter:    278/  8460 | loss: 0.9277 | ds_loss: 0.0000 | lr: 4.9867e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    279/  8460 | global iter:    279/  8460 | loss: 1.0797 | ds_loss: 0.0000 | lr: 4.9866e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    280/  8460 | global iter:    280/  8460 | loss: 0.8961 | ds_loss: 0.0000 | lr: 4.9865e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    280/  8460 | global iter:    280/  8460 | loss: 1.0519 | ds_loss: 0.0000 | lr: 4.9865e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    281/  8460 | global iter:    281/  8460 | loss: 0.6320 | ds_loss: 0.0000 | lr: 4.9864e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    282/  8460 | global iter:    282/  8460 | loss: 0.9686 | ds_loss: 0.0000 | lr: 4.9863e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    283/  8460 | global iter:    283/  8460 | loss: 0.5719 | ds_loss: 0.0000 | lr: 4.9862e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    284/  8460 | global iter:    284/  8460 | loss: 0.7580 | ds_loss: 0.0000 | lr: 4.9861e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    284/  8460 | global iter:    284/  8460 | loss: 0.7326 | ds_loss: 0.0000 | lr: 4.9861e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    285/  8460 | global iter:    285/  8460 | loss: 0.7525 | ds_loss: 0.0000 | lr: 4.9860e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    286/  8460 | global iter:    286/  8460 | loss: 1.3206 | ds_loss: 0.0000 | lr: 4.9859e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    287/  8460 | global iter:    287/  8460 | loss: 2.2617 | ds_loss: 0.0000 | lr: 4.9858e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    288/  8460 | global iter:    288/  8460 | loss: 1.0144 | ds_loss: 0.0000 | lr: 4.9857e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    288/  8460 | global iter:    288/  8460 | loss: 1.3373 | ds_loss: 0.0000 | lr: 4.9857e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    289/  8460 | global iter:    289/  8460 | loss: 0.8540 | ds_loss: 0.0000 | lr: 4.9856e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    290/  8460 | global iter:    290/  8460 | loss: 0.7825 | ds_loss: 0.0000 | lr: 4.9855e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    291/  8460 | global iter:    291/  8460 | loss: 1.6085 | ds_loss: 0.0000 | lr: 4.9854e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    292/  8460 | global iter:    292/  8460 | loss: 1.9411 | ds_loss: 0.0000 | lr: 4.9853e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    292/  8460 | global iter:    292/  8460 | loss: 1.2965 | ds_loss: 0.0000 | lr: 4.9853e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    293/  8460 | global iter:    293/  8460 | loss: 0.8717 | ds_loss: 0.0000 | lr: 4.9852e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    294/  8460 | global iter:    294/  8460 | loss: 0.7264 | ds_loss: 0.0000 | lr: 4.9851e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    295/  8460 | global iter:    295/  8460 | loss: 1.3668 | ds_loss: 0.0000 | lr: 4.9850e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    296/  8460 | global iter:    296/  8460 | loss: 1.3643 | ds_loss: 0.0000 | lr: 4.9849e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    296/  8460 | global iter:    296/  8460 | loss: 1.0823 | ds_loss: 0.0000 | lr: 4.9849e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    297/  8460 | global iter:    297/  8460 | loss: 1.7503 | ds_loss: 0.0000 | lr: 4.9848e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    298/  8460 | global iter:    298/  8460 | loss: 0.8301 | ds_loss: 0.0000 | lr: 4.9847e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    299/  8460 | global iter:    299/  8460 | loss: 0.7312 | ds_loss: 0.0000 | lr: 4.9846e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    300/  8460 | global iter:    300/  8460 | loss: 1.6503 | ds_loss: 0.0000 | lr: 4.9845e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    300/  8460 | global iter:    300/  8460 | loss: 1.2405 | ds_loss: 0.0000 | lr: 4.9845e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    301/  8460 | global iter:    301/  8460 | loss: 0.6726 | ds_loss: 0.0000 | lr: 4.9844e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    302/  8460 | global iter:    302/  8460 | loss: 1.8483 | ds_loss: 0.0000 | lr: 4.9843e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    303/  8460 | global iter:    303/  8460 | loss: 1.0269 | ds_loss: 0.0000 | lr: 4.9842e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    304/  8460 | global iter:    304/  8460 | loss: 0.5866 | ds_loss: 0.0000 | lr: 4.9841e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    304/  8460 | global iter:    304/  8460 | loss: 1.0336 | ds_loss: 0.0000 | lr: 4.9841e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    305/  8460 | global iter:    305/  8460 | loss: 1.0118 | ds_loss: 0.0000 | lr: 4.9840e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    306/  8460 | global iter:    306/  8460 | loss: 1.0364 | ds_loss: 0.0000 | lr: 4.9839e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    307/  8460 | global iter:    307/  8460 | loss: 0.4213 | ds_loss: 0.0000 | lr: 4.9838e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    308/  8460 | global iter:    308/  8460 | loss: 1.0704 | ds_loss: 0.0000 | lr: 4.9837e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    308/  8460 | global iter:    308/  8460 | loss: 0.8850 | ds_loss: 0.0000 | lr: 4.9837e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    309/  8460 | global iter:    309/  8460 | loss: 1.3138 | ds_loss: 0.0000 | lr: 4.9836e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    310/  8460 | global iter:    310/  8460 | loss: 0.7927 | ds_loss: 0.0000 | lr: 4.9835e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    311/  8460 | global iter:    311/  8460 | loss: 0.4322 | ds_loss: 0.0000 | lr: 4.9833e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    312/  8460 | global iter:    312/  8460 | loss: 0.7048 | ds_loss: 0.0000 | lr: 4.9832e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    312/  8460 | global iter:    312/  8460 | loss: 0.8109 | ds_loss: 0.0000 | lr: 4.9832e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    313/  8460 | global iter:    313/  8460 | loss: 0.9498 | ds_loss: 0.0000 | lr: 4.9831e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    314/  8460 | global iter:    314/  8460 | loss: 1.7123 | ds_loss: 0.0000 | lr: 4.9830e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    315/  8460 | global iter:    315/  8460 | loss: 0.7697 | ds_loss: 0.0000 | lr: 4.9829e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    316/  8460 | global iter:    316/  8460 | loss: 0.7857 | ds_loss: 0.0000 | lr: 4.9828e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    316/  8460 | global iter:    316/  8460 | loss: 1.0544 | ds_loss: 0.0000 | lr: 4.9828e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    317/  8460 | global iter:    317/  8460 | loss: 1.1952 | ds_loss: 0.0000 | lr: 4.9827e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    318/  8460 | global iter:    318/  8460 | loss: 1.0631 | ds_loss: 0.0000 | lr: 4.9826e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    319/  8460 | global iter:    319/  8460 | loss: 0.3506 | ds_loss: 0.0000 | lr: 4.9825e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    320/  8460 | global iter:    320/  8460 | loss: 2.4088 | ds_loss: 0.0000 | lr: 4.9824e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    320/  8460 | global iter:    320/  8460 | loss: 1.2544 | ds_loss: 0.0000 | lr: 4.9824e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    321/  8460 | global iter:    321/  8460 | loss: 0.9373 | ds_loss: 0.0000 | lr: 4.9823e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    322/  8460 | global iter:    322/  8460 | loss: 1.3743 | ds_loss: 0.0000 | lr: 4.9822e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    323/  8460 | global iter:    323/  8460 | loss: 0.9541 | ds_loss: 0.0000 | lr: 4.9820e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    324/  8460 | global iter:    324/  8460 | loss: 1.2651 | ds_loss: 0.0000 | lr: 4.9819e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    324/  8460 | global iter:    324/  8460 | loss: 1.1327 | ds_loss: 0.0000 | lr: 4.9819e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    325/  8460 | global iter:    325/  8460 | loss: 0.5527 | ds_loss: 0.0000 | lr: 4.9818e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    326/  8460 | global iter:    326/  8460 | loss: 1.1865 | ds_loss: 0.0000 | lr: 4.9817e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    327/  8460 | global iter:    327/  8460 | loss: 0.6470 | ds_loss: 0.0000 | lr: 4.9816e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    328/  8460 | global iter:    328/  8460 | loss: 0.4784 | ds_loss: 0.0000 | lr: 4.9815e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    328/  8460 | global iter:    328/  8460 | loss: 0.7162 | ds_loss: 0.0000 | lr: 4.9815e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    329/  8460 | global iter:    329/  8460 | loss: 0.3644 | ds_loss: 0.0000 | lr: 4.9814e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    330/  8460 | global iter:    330/  8460 | loss: 0.4755 | ds_loss: 0.0000 | lr: 4.9813e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    331/  8460 | global iter:    331/  8460 | loss: 0.7743 | ds_loss: 0.0000 | lr: 4.9811e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    332/  8460 | global iter:    332/  8460 | loss: 0.7600 | ds_loss: 0.0000 | lr: 4.9810e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    332/  8460 | global iter:    332/  8460 | loss: 0.5936 | ds_loss: 0.0000 | lr: 4.9810e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    333/  8460 | global iter:    333/  8460 | loss: 0.5352 | ds_loss: 0.0000 | lr: 4.9809e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    334/  8460 | global iter:    334/  8460 | loss: 0.7259 | ds_loss: 0.0000 | lr: 4.9808e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    335/  8460 | global iter:    335/  8460 | loss: 0.7450 | ds_loss: 0.0000 | lr: 4.9807e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    336/  8460 | global iter:    336/  8460 | loss: 0.7401 | ds_loss: 0.0000 | lr: 4.9806e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    336/  8460 | global iter:    336/  8460 | loss: 0.6866 | ds_loss: 0.0000 | lr: 4.9806e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    337/  8460 | global iter:    337/  8460 | loss: 1.4351 | ds_loss: 0.0000 | lr: 4.9805e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    338/  8460 | global iter:    338/  8460 | loss: 0.4795 | ds_loss: 0.0000 | lr: 4.9803e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    339/  8460 | global iter:    339/  8460 | loss: 0.9255 | ds_loss: 0.0000 | lr: 4.9802e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    340/  8460 | global iter:    340/  8460 | loss: 0.7898 | ds_loss: 0.0000 | lr: 4.9801e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    340/  8460 | global iter:    340/  8460 | loss: 0.9075 | ds_loss: 0.0000 | lr: 4.9801e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    341/  8460 | global iter:    341/  8460 | loss: 1.3940 | ds_loss: 0.0000 | lr: 4.9800e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    342/  8460 | global iter:    342/  8460 | loss: 0.9583 | ds_loss: 0.0000 | lr: 4.9799e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    343/  8460 | global iter:    343/  8460 | loss: 1.5361 | ds_loss: 0.0000 | lr: 4.9798e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    344/  8460 | global iter:    344/  8460 | loss: 0.7082 | ds_loss: 0.0000 | lr: 4.9796e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    344/  8460 | global iter:    344/  8460 | loss: 1.1492 | ds_loss: 0.0000 | lr: 4.9796e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    345/  8460 | global iter:    345/  8460 | loss: 1.0403 | ds_loss: 0.0000 | lr: 4.9795e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    346/  8460 | global iter:    346/  8460 | loss: 1.6135 | ds_loss: 0.0000 | lr: 4.9794e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    347/  8460 | global iter:    347/  8460 | loss: 0.3717 | ds_loss: 0.0000 | lr: 4.9793e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    348/  8460 | global iter:    348/  8460 | loss: 0.6202 | ds_loss: 0.0000 | lr: 4.9792e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    348/  8460 | global iter:    348/  8460 | loss: 0.9114 | ds_loss: 0.0000 | lr: 4.9792e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    349/  8460 | global iter:    349/  8460 | loss: 0.3672 | ds_loss: 0.0000 | lr: 4.9790e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    350/  8460 | global iter:    350/  8460 | loss: 0.9652 | ds_loss: 0.0000 | lr: 4.9789e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    351/  8460 | global iter:    351/  8460 | loss: 0.3114 | ds_loss: 0.0000 | lr: 4.9788e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    352/  8460 | global iter:    352/  8460 | loss: 1.7715 | ds_loss: 0.0000 | lr: 4.9787e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    352/  8460 | global iter:    352/  8460 | loss: 0.8538 | ds_loss: 0.0000 | lr: 4.9787e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    353/  8460 | global iter:    353/  8460 | loss: 1.6026 | ds_loss: 0.0000 | lr: 4.9786e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    354/  8460 | global iter:    354/  8460 | loss: 1.5995 | ds_loss: 0.0000 | lr: 4.9784e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    355/  8460 | global iter:    355/  8460 | loss: 0.5387 | ds_loss: 0.0000 | lr: 4.9783e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    356/  8460 | global iter:    356/  8460 | loss: 0.7597 | ds_loss: 0.0000 | lr: 4.9782e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    356/  8460 | global iter:    356/  8460 | loss: 1.1251 | ds_loss: 0.0000 | lr: 4.9782e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    357/  8460 | global iter:    357/  8460 | loss: 1.0715 | ds_loss: 0.0000 | lr: 4.9781e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    358/  8460 | global iter:    358/  8460 | loss: 0.4725 | ds_loss: 0.0000 | lr: 4.9779e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    359/  8460 | global iter:    359/  8460 | loss: 0.7801 | ds_loss: 0.0000 | lr: 4.9778e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    360/  8460 | global iter:    360/  8460 | loss: 0.6632 | ds_loss: 0.0000 | lr: 4.9777e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    360/  8460 | global iter:    360/  8460 | loss: 0.7468 | ds_loss: 0.0000 | lr: 4.9777e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    361/  8460 | global iter:    361/  8460 | loss: 1.1116 | ds_loss: 0.0000 | lr: 4.9776e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    362/  8460 | global iter:    362/  8460 | loss: 0.8814 | ds_loss: 0.0000 | lr: 4.9775e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    363/  8460 | global iter:    363/  8460 | loss: 0.7877 | ds_loss: 0.0000 | lr: 4.9773e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    364/  8460 | global iter:    364/  8460 | loss: 1.1822 | ds_loss: 0.0000 | lr: 4.9772e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    364/  8460 | global iter:    364/  8460 | loss: 0.9907 | ds_loss: 0.0000 | lr: 4.9772e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    365/  8460 | global iter:    365/  8460 | loss: 1.1081 | ds_loss: 0.0000 | lr: 4.9771e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    366/  8460 | global iter:    366/  8460 | loss: 1.5765 | ds_loss: 0.0000 | lr: 4.9769e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    367/  8460 | global iter:    367/  8460 | loss: 0.8448 | ds_loss: 0.0000 | lr: 4.9768e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    368/  8460 | global iter:    368/  8460 | loss: 1.0293 | ds_loss: 0.0000 | lr: 4.9767e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    368/  8460 | global iter:    368/  8460 | loss: 1.1397 | ds_loss: 0.0000 | lr: 4.9767e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    369/  8460 | global iter:    369/  8460 | loss: 0.9240 | ds_loss: 0.0000 | lr: 4.9766e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    370/  8460 | global iter:    370/  8460 | loss: 1.6878 | ds_loss: 0.0000 | lr: 4.9764e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    371/  8460 | global iter:    371/  8460 | loss: 0.9544 | ds_loss: 0.0000 | lr: 4.9763e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    372/  8460 | global iter:    372/  8460 | loss: 1.2674 | ds_loss: 0.0000 | lr: 4.9762e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    372/  8460 | global iter:    372/  8460 | loss: 1.2084 | ds_loss: 0.0000 | lr: 4.9762e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    373/  8460 | global iter:    373/  8460 | loss: 1.4143 | ds_loss: 0.0000 | lr: 4.9761e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    374/  8460 | global iter:    374/  8460 | loss: 1.1315 | ds_loss: 0.0000 | lr: 4.9759e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    375/  8460 | global iter:    375/  8460 | loss: 0.9190 | ds_loss: 0.0000 | lr: 4.9758e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    376/  8460 | global iter:    376/  8460 | loss: 1.0057 | ds_loss: 0.0000 | lr: 4.9757e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    376/  8460 | global iter:    376/  8460 | loss: 1.1176 | ds_loss: 0.0000 | lr: 4.9757e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    377/  8460 | global iter:    377/  8460 | loss: 0.5855 | ds_loss: 0.0000 | lr: 4.9755e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    378/  8460 | global iter:    378/  8460 | loss: 0.4756 | ds_loss: 0.0000 | lr: 4.9754e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    379/  8460 | global iter:    379/  8460 | loss: 1.6004 | ds_loss: 0.0000 | lr: 4.9753e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    380/  8460 | global iter:    380/  8460 | loss: 0.6154 | ds_loss: 0.0000 | lr: 4.9752e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    380/  8460 | global iter:    380/  8460 | loss: 0.8192 | ds_loss: 0.0000 | lr: 4.9752e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    381/  8460 | global iter:    381/  8460 | loss: 0.9796 | ds_loss: 0.0000 | lr: 4.9750e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    382/  8460 | global iter:    382/  8460 | loss: 0.7579 | ds_loss: 0.0000 | lr: 4.9749e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    383/  8460 | global iter:    383/  8460 | loss: 0.6924 | ds_loss: 0.0000 | lr: 4.9748e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    384/  8460 | global iter:    384/  8460 | loss: 0.8471 | ds_loss: 0.0000 | lr: 4.9746e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    384/  8460 | global iter:    384/  8460 | loss: 0.8192 | ds_loss: 0.0000 | lr: 4.9746e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    385/  8460 | global iter:    385/  8460 | loss: 0.4347 | ds_loss: 0.0000 | lr: 4.9745e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    386/  8460 | global iter:    386/  8460 | loss: 1.2882 | ds_loss: 0.0000 | lr: 4.9744e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    387/  8460 | global iter:    387/  8460 | loss: 0.7783 | ds_loss: 0.0000 | lr: 4.9742e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    388/  8460 | global iter:    388/  8460 | loss: 0.5360 | ds_loss: 0.0000 | lr: 4.9741e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    388/  8460 | global iter:    388/  8460 | loss: 0.7593 | ds_loss: 0.0000 | lr: 4.9741e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    389/  8460 | global iter:    389/  8460 | loss: 0.9473 | ds_loss: 0.0000 | lr: 4.9740e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    390/  8460 | global iter:    390/  8460 | loss: 1.9412 | ds_loss: 0.0000 | lr: 4.9738e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    391/  8460 | global iter:    391/  8460 | loss: 1.4757 | ds_loss: 0.0000 | lr: 4.9737e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    392/  8460 | global iter:    392/  8460 | loss: 1.1430 | ds_loss: 0.0000 | lr: 4.9736e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    392/  8460 | global iter:    392/  8460 | loss: 1.3768 | ds_loss: 0.0000 | lr: 4.9736e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    393/  8460 | global iter:    393/  8460 | loss: 1.1089 | ds_loss: 0.0000 | lr: 4.9734e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    394/  8460 | global iter:    394/  8460 | loss: 0.6753 | ds_loss: 0.0000 | lr: 4.9733e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    395/  8460 | global iter:    395/  8460 | loss: 0.5843 | ds_loss: 0.0000 | lr: 4.9732e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    396/  8460 | global iter:    396/  8460 | loss: 0.6276 | ds_loss: 0.0000 | lr: 4.9730e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    396/  8460 | global iter:    396/  8460 | loss: 0.7490 | ds_loss: 0.0000 | lr: 4.9730e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    397/  8460 | global iter:    397/  8460 | loss: 0.6670 | ds_loss: 0.0000 | lr: 4.9729e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    398/  8460 | global iter:    398/  8460 | loss: 1.5146 | ds_loss: 0.0000 | lr: 4.9728e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    399/  8460 | global iter:    399/  8460 | loss: 1.1840 | ds_loss: 0.0000 | lr: 4.9726e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    400/  8460 | global iter:    400/  8460 | loss: 0.4562 | ds_loss: 0.0000 | lr: 4.9725e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    400/  8460 | global iter:    400/  8460 | loss: 0.9554 | ds_loss: 0.0000 | lr: 4.9725e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    401/  8460 | global iter:    401/  8460 | loss: 1.2658 | ds_loss: 0.0000 | lr: 4.9723e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    402/  8460 | global iter:    402/  8460 | loss: 0.8824 | ds_loss: 0.0000 | lr: 4.9722e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    403/  8460 | global iter:    403/  8460 | loss: 0.9378 | ds_loss: 0.0000 | lr: 4.9721e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    404/  8460 | global iter:    404/  8460 | loss: 0.6854 | ds_loss: 0.0000 | lr: 4.9719e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    404/  8460 | global iter:    404/  8460 | loss: 0.9428 | ds_loss: 0.0000 | lr: 4.9719e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    405/  8460 | global iter:    405/  8460 | loss: 0.9260 | ds_loss: 0.0000 | lr: 4.9718e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    406/  8460 | global iter:    406/  8460 | loss: 0.7790 | ds_loss: 0.0000 | lr: 4.9716e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    407/  8460 | global iter:    407/  8460 | loss: 0.4687 | ds_loss: 0.0000 | lr: 4.9715e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    408/  8460 | global iter:    408/  8460 | loss: 1.3796 | ds_loss: 0.0000 | lr: 4.9714e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    408/  8460 | global iter:    408/  8460 | loss: 0.8883 | ds_loss: 0.0000 | lr: 4.9714e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    409/  8460 | global iter:    409/  8460 | loss: 0.4861 | ds_loss: 0.0000 | lr: 4.9712e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    410/  8460 | global iter:    410/  8460 | loss: 1.2036 | ds_loss: 0.0000 | lr: 4.9711e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    411/  8460 | global iter:    411/  8460 | loss: 0.7639 | ds_loss: 0.0000 | lr: 4.9709e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    412/  8460 | global iter:    412/  8460 | loss: 1.3592 | ds_loss: 0.0000 | lr: 4.9708e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    412/  8460 | global iter:    412/  8460 | loss: 0.9532 | ds_loss: 0.0000 | lr: 4.9708e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    413/  8460 | global iter:    413/  8460 | loss: 1.5586 | ds_loss: 0.0000 | lr: 4.9707e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    414/  8460 | global iter:    414/  8460 | loss: 0.8521 | ds_loss: 0.0000 | lr: 4.9705e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    415/  8460 | global iter:    415/  8460 | loss: 0.5532 | ds_loss: 0.0000 | lr: 4.9704e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    416/  8460 | global iter:    416/  8460 | loss: 1.7684 | ds_loss: 0.0000 | lr: 4.9702e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    416/  8460 | global iter:    416/  8460 | loss: 1.1831 | ds_loss: 0.0000 | lr: 4.9702e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    417/  8460 | global iter:    417/  8460 | loss: 0.8631 | ds_loss: 0.0000 | lr: 4.9701e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    418/  8460 | global iter:    418/  8460 | loss: 0.6208 | ds_loss: 0.0000 | lr: 4.9699e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    419/  8460 | global iter:    419/  8460 | loss: 0.4809 | ds_loss: 0.0000 | lr: 4.9698e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    420/  8460 | global iter:    420/  8460 | loss: 1.1925 | ds_loss: 0.0000 | lr: 4.9697e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    420/  8460 | global iter:    420/  8460 | loss: 0.7893 | ds_loss: 0.0000 | lr: 4.9697e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    421/  8460 | global iter:    421/  8460 | loss: 1.3400 | ds_loss: 0.0000 | lr: 4.9695e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    422/  8460 | global iter:    422/  8460 | loss: 0.9385 | ds_loss: 0.0000 | lr: 4.9694e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    423/  8460 | global iter:    423/  8460 | loss: 1.3465 | ds_loss: 0.0000 | lr: 4.9692e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    424/  8460 | global iter:    424/  8460 | loss: 1.7008 | ds_loss: 0.0000 | lr: 4.9691e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    424/  8460 | global iter:    424/  8460 | loss: 1.3314 | ds_loss: 0.0000 | lr: 4.9691e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    425/  8460 | global iter:    425/  8460 | loss: 0.7964 | ds_loss: 0.0000 | lr: 4.9689e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    426/  8460 | global iter:    426/  8460 | loss: 0.5014 | ds_loss: 0.0000 | lr: 4.9688e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    427/  8460 | global iter:    427/  8460 | loss: 1.6750 | ds_loss: 0.0000 | lr: 4.9686e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    428/  8460 | global iter:    428/  8460 | loss: 0.7965 | ds_loss: 0.0000 | lr: 4.9685e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    428/  8460 | global iter:    428/  8460 | loss: 0.9423 | ds_loss: 0.0000 | lr: 4.9685e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    429/  8460 | global iter:    429/  8460 | loss: 1.0405 | ds_loss: 0.0000 | lr: 4.9683e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    430/  8460 | global iter:    430/  8460 | loss: 0.6483 | ds_loss: 0.0000 | lr: 4.9682e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    431/  8460 | global iter:    431/  8460 | loss: 1.0208 | ds_loss: 0.0000 | lr: 4.9681e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    432/  8460 | global iter:    432/  8460 | loss: 0.5334 | ds_loss: 0.0000 | lr: 4.9679e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    432/  8460 | global iter:    432/  8460 | loss: 0.8107 | ds_loss: 0.0000 | lr: 4.9679e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    433/  8460 | global iter:    433/  8460 | loss: 0.6034 | ds_loss: 0.0000 | lr: 4.9678e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    434/  8460 | global iter:    434/  8460 | loss: 1.6575 | ds_loss: 0.0000 | lr: 4.9676e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    435/  8460 | global iter:    435/  8460 | loss: 1.3768 | ds_loss: 0.0000 | lr: 4.9675e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    436/  8460 | global iter:    436/  8460 | loss: 1.4889 | ds_loss: 0.0000 | lr: 4.9673e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    436/  8460 | global iter:    436/  8460 | loss: 1.2816 | ds_loss: 0.0000 | lr: 4.9673e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    437/  8460 | global iter:    437/  8460 | loss: 0.4737 | ds_loss: 0.0000 | lr: 4.9672e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    438/  8460 | global iter:    438/  8460 | loss: 0.5941 | ds_loss: 0.0000 | lr: 4.9670e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    439/  8460 | global iter:    439/  8460 | loss: 0.5633 | ds_loss: 0.0000 | lr: 4.9669e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    440/  8460 | global iter:    440/  8460 | loss: 1.1078 | ds_loss: 0.0000 | lr: 4.9667e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    440/  8460 | global iter:    440/  8460 | loss: 0.6847 | ds_loss: 0.0000 | lr: 4.9667e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    441/  8460 | global iter:    441/  8460 | loss: 1.1310 | ds_loss: 0.0000 | lr: 4.9666e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    442/  8460 | global iter:    442/  8460 | loss: 1.1393 | ds_loss: 0.0000 | lr: 4.9664e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    443/  8460 | global iter:    443/  8460 | loss: 0.6493 | ds_loss: 0.0000 | lr: 4.9663e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    444/  8460 | global iter:    444/  8460 | loss: 0.7193 | ds_loss: 0.0000 | lr: 4.9661e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    444/  8460 | global iter:    444/  8460 | loss: 0.9097 | ds_loss: 0.0000 | lr: 4.9661e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    445/  8460 | global iter:    445/  8460 | loss: 1.2710 | ds_loss: 0.0000 | lr: 4.9660e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    446/  8460 | global iter:    446/  8460 | loss: 0.5402 | ds_loss: 0.0000 | lr: 4.9658e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    447/  8460 | global iter:    447/  8460 | loss: 0.3258 | ds_loss: 0.0000 | lr: 4.9656e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    448/  8460 | global iter:    448/  8460 | loss: 0.8400 | ds_loss: 0.0000 | lr: 4.9655e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    448/  8460 | global iter:    448/  8460 | loss: 0.7443 | ds_loss: 0.0000 | lr: 4.9655e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    449/  8460 | global iter:    449/  8460 | loss: 0.3764 | ds_loss: 0.0000 | lr: 4.9653e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    450/  8460 | global iter:    450/  8460 | loss: 0.9587 | ds_loss: 0.0000 | lr: 4.9652e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    451/  8460 | global iter:    451/  8460 | loss: 0.8581 | ds_loss: 0.0000 | lr: 4.9650e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    452/  8460 | global iter:    452/  8460 | loss: 0.9654 | ds_loss: 0.0000 | lr: 4.9649e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    452/  8460 | global iter:    452/  8460 | loss: 0.7896 | ds_loss: 0.0000 | lr: 4.9649e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    453/  8460 | global iter:    453/  8460 | loss: 0.9100 | ds_loss: 0.0000 | lr: 4.9647e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    454/  8460 | global iter:    454/  8460 | loss: 1.4634 | ds_loss: 0.0000 | lr: 4.9646e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    455/  8460 | global iter:    455/  8460 | loss: 0.5433 | ds_loss: 0.0000 | lr: 4.9644e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    456/  8460 | global iter:    456/  8460 | loss: 0.7779 | ds_loss: 0.0000 | lr: 4.9643e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    456/  8460 | global iter:    456/  8460 | loss: 0.9236 | ds_loss: 0.0000 | lr: 4.9643e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    457/  8460 | global iter:    457/  8460 | loss: 0.4153 | ds_loss: 0.0000 | lr: 4.9641e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    458/  8460 | global iter:    458/  8460 | loss: 1.2336 | ds_loss: 0.0000 | lr: 4.9639e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    459/  8460 | global iter:    459/  8460 | loss: 0.7512 | ds_loss: 0.0000 | lr: 4.9638e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    460/  8460 | global iter:    460/  8460 | loss: 1.3133 | ds_loss: 0.0000 | lr: 4.9636e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    460/  8460 | global iter:    460/  8460 | loss: 0.9284 | ds_loss: 0.0000 | lr: 4.9636e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    461/  8460 | global iter:    461/  8460 | loss: 0.7556 | ds_loss: 0.0000 | lr: 4.9635e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    462/  8460 | global iter:    462/  8460 | loss: 1.0948 | ds_loss: 0.0000 | lr: 4.9633e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    463/  8460 | global iter:    463/  8460 | loss: 0.4414 | ds_loss: 0.0000 | lr: 4.9631e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    464/  8460 | global iter:    464/  8460 | loss: 1.2071 | ds_loss: 0.0000 | lr: 4.9630e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    464/  8460 | global iter:    464/  8460 | loss: 0.8747 | ds_loss: 0.0000 | lr: 4.9630e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    465/  8460 | global iter:    465/  8460 | loss: 0.6281 | ds_loss: 0.0000 | lr: 4.9628e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    466/  8460 | global iter:    466/  8460 | loss: 0.8017 | ds_loss: 0.0000 | lr: 4.9627e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    467/  8460 | global iter:    467/  8460 | loss: 0.9020 | ds_loss: 0.0000 | lr: 4.9625e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    468/  8460 | global iter:    468/  8460 | loss: 0.9792 | ds_loss: 0.0000 | lr: 4.9623e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    468/  8460 | global iter:    468/  8460 | loss: 0.8277 | ds_loss: 0.0000 | lr: 4.9623e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    469/  8460 | global iter:    469/  8460 | loss: 0.5119 | ds_loss: 0.0000 | lr: 4.9622e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    470/  8460 | global iter:    470/  8460 | loss: 0.8361 | ds_loss: 0.0000 | lr: 4.9620e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    471/  8460 | global iter:    471/  8460 | loss: 0.6819 | ds_loss: 0.0000 | lr: 4.9619e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    472/  8460 | global iter:    472/  8460 | loss: 1.5675 | ds_loss: 0.0000 | lr: 4.9617e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    472/  8460 | global iter:    472/  8460 | loss: 0.8993 | ds_loss: 0.0000 | lr: 4.9617e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    473/  8460 | global iter:    473/  8460 | loss: 0.5817 | ds_loss: 0.0000 | lr: 4.9615e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    474/  8460 | global iter:    474/  8460 | loss: 1.0067 | ds_loss: 0.0000 | lr: 4.9614e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    475/  8460 | global iter:    475/  8460 | loss: 0.9610 | ds_loss: 0.0000 | lr: 4.9612e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    476/  8460 | global iter:    476/  8460 | loss: 1.0317 | ds_loss: 0.0000 | lr: 4.9611e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    476/  8460 | global iter:    476/  8460 | loss: 0.8953 | ds_loss: 0.0000 | lr: 4.9611e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    477/  8460 | global iter:    477/  8460 | loss: 0.9835 | ds_loss: 0.0000 | lr: 4.9609e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    478/  8460 | global iter:    478/  8460 | loss: 1.3431 | ds_loss: 0.0000 | lr: 4.9607e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    479/  8460 | global iter:    479/  8460 | loss: 0.9054 | ds_loss: 0.0000 | lr: 4.9606e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    480/  8460 | global iter:    480/  8460 | loss: 0.8096 | ds_loss: 0.0000 | lr: 4.9604e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    480/  8460 | global iter:    480/  8460 | loss: 1.0104 | ds_loss: 0.0000 | lr: 4.9604e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    481/  8460 | global iter:    481/  8460 | loss: 0.5887 | ds_loss: 0.0000 | lr: 4.9602e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    482/  8460 | global iter:    482/  8460 | loss: 0.6329 | ds_loss: 0.0000 | lr: 4.9601e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    483/  8460 | global iter:    483/  8460 | loss: 0.5778 | ds_loss: 0.0000 | lr: 4.9599e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    484/  8460 | global iter:    484/  8460 | loss: 0.4938 | ds_loss: 0.0000 | lr: 4.9597e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    484/  8460 | global iter:    484/  8460 | loss: 0.5733 | ds_loss: 0.0000 | lr: 4.9597e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    485/  8460 | global iter:    485/  8460 | loss: 0.4346 | ds_loss: 0.0000 | lr: 4.9596e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    486/  8460 | global iter:    486/  8460 | loss: 1.2495 | ds_loss: 0.0000 | lr: 4.9594e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    487/  8460 | global iter:    487/  8460 | loss: 0.7797 | ds_loss: 0.0000 | lr: 4.9592e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    488/  8460 | global iter:    488/  8460 | loss: 1.2326 | ds_loss: 0.0000 | lr: 4.9591e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    488/  8460 | global iter:    488/  8460 | loss: 0.9241 | ds_loss: 0.0000 | lr: 4.9591e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    489/  8460 | global iter:    489/  8460 | loss: 1.0778 | ds_loss: 0.0000 | lr: 4.9589e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    490/  8460 | global iter:    490/  8460 | loss: 0.7111 | ds_loss: 0.0000 | lr: 4.9587e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    491/  8460 | global iter:    491/  8460 | loss: 0.4873 | ds_loss: 0.0000 | lr: 4.9586e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    492/  8460 | global iter:    492/  8460 | loss: 0.3440 | ds_loss: 0.0000 | lr: 4.9584e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    492/  8460 | global iter:    492/  8460 | loss: 0.6551 | ds_loss: 0.0000 | lr: 4.9584e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    493/  8460 | global iter:    493/  8460 | loss: 1.1329 | ds_loss: 0.0000 | lr: 4.9582e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    494/  8460 | global iter:    494/  8460 | loss: 0.9403 | ds_loss: 0.0000 | lr: 4.9581e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    495/  8460 | global iter:    495/  8460 | loss: 0.7366 | ds_loss: 0.0000 | lr: 4.9579e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    496/  8460 | global iter:    496/  8460 | loss: 1.0219 | ds_loss: 0.0000 | lr: 4.9577e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    496/  8460 | global iter:    496/  8460 | loss: 0.9579 | ds_loss: 0.0000 | lr: 4.9577e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    497/  8460 | global iter:    497/  8460 | loss: 1.0203 | ds_loss: 0.0000 | lr: 4.9576e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    498/  8460 | global iter:    498/  8460 | loss: 0.5145 | ds_loss: 0.0000 | lr: 4.9574e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    499/  8460 | global iter:    499/  8460 | loss: 0.7000 | ds_loss: 0.0000 | lr: 4.9572e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    500/  8460 | global iter:    500/  8460 | loss: 0.6464 | ds_loss: 0.0000 | lr: 4.9570e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    500/  8460 | global iter:    500/  8460 | loss: 0.7203 | ds_loss: 0.0000 | lr: 4.9570e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    501/  8460 | global iter:    501/  8460 | loss: 0.6285 | ds_loss: 0.0000 | lr: 4.9569e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    502/  8460 | global iter:    502/  8460 | loss: 0.8253 | ds_loss: 0.0000 | lr: 4.9567e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    503/  8460 | global iter:    503/  8460 | loss: 1.3105 | ds_loss: 0.0000 | lr: 4.9565e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    504/  8460 | global iter:    504/  8460 | loss: 0.7231 | ds_loss: 0.0000 | lr: 4.9564e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    504/  8460 | global iter:    504/  8460 | loss: 0.8718 | ds_loss: 0.0000 | lr: 4.9564e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    505/  8460 | global iter:    505/  8460 | loss: 0.6448 | ds_loss: 0.0000 | lr: 4.9562e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    506/  8460 | global iter:    506/  8460 | loss: 0.8369 | ds_loss: 0.0000 | lr: 4.9560e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    507/  8460 | global iter:    507/  8460 | loss: 0.2180 | ds_loss: 0.0000 | lr: 4.9558e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    508/  8460 | global iter:    508/  8460 | loss: 0.4053 | ds_loss: 0.0000 | lr: 4.9557e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    508/  8460 | global iter:    508/  8460 | loss: 0.5262 | ds_loss: 0.0000 | lr: 4.9557e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    509/  8460 | global iter:    509/  8460 | loss: 0.6295 | ds_loss: 0.0000 | lr: 4.9555e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    510/  8460 | global iter:    510/  8460 | loss: 1.1049 | ds_loss: 0.0000 | lr: 4.9553e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    511/  8460 | global iter:    511/  8460 | loss: 0.8655 | ds_loss: 0.0000 | lr: 4.9551e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    512/  8460 | global iter:    512/  8460 | loss: 0.9288 | ds_loss: 0.0000 | lr: 4.9550e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    512/  8460 | global iter:    512/  8460 | loss: 0.8822 | ds_loss: 0.0000 | lr: 4.9550e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    513/  8460 | global iter:    513/  8460 | loss: 0.5712 | ds_loss: 0.0000 | lr: 4.9548e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    514/  8460 | global iter:    514/  8460 | loss: 0.6415 | ds_loss: 0.0000 | lr: 4.9546e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    515/  8460 | global iter:    515/  8460 | loss: 1.4295 | ds_loss: 0.0000 | lr: 4.9544e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    516/  8460 | global iter:    516/  8460 | loss: 1.0672 | ds_loss: 0.0000 | lr: 4.9543e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    516/  8460 | global iter:    516/  8460 | loss: 0.9273 | ds_loss: 0.0000 | lr: 4.9543e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    517/  8460 | global iter:    517/  8460 | loss: 1.6587 | ds_loss: 0.0000 | lr: 4.9541e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    518/  8460 | global iter:    518/  8460 | loss: 0.4865 | ds_loss: 0.0000 | lr: 4.9539e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    519/  8460 | global iter:    519/  8460 | loss: 0.2820 | ds_loss: 0.0000 | lr: 4.9537e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    520/  8460 | global iter:    520/  8460 | loss: 0.5332 | ds_loss: 0.0000 | lr: 4.9535e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    520/  8460 | global iter:    520/  8460 | loss: 0.7401 | ds_loss: 0.0000 | lr: 4.9535e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    521/  8460 | global iter:    521/  8460 | loss: 0.7171 | ds_loss: 0.0000 | lr: 4.9534e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    522/  8460 | global iter:    522/  8460 | loss: 0.5720 | ds_loss: 0.0000 | lr: 4.9532e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    523/  8460 | global iter:    523/  8460 | loss: 0.9280 | ds_loss: 0.0000 | lr: 4.9530e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    524/  8460 | global iter:    524/  8460 | loss: 1.0833 | ds_loss: 0.0000 | lr: 4.9528e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    524/  8460 | global iter:    524/  8460 | loss: 0.8251 | ds_loss: 0.0000 | lr: 4.9528e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    525/  8460 | global iter:    525/  8460 | loss: 0.6390 | ds_loss: 0.0000 | lr: 4.9526e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    526/  8460 | global iter:    526/  8460 | loss: 1.1221 | ds_loss: 0.0000 | lr: 4.9525e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    527/  8460 | global iter:    527/  8460 | loss: 0.9520 | ds_loss: 0.0000 | lr: 4.9523e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    528/  8460 | global iter:    528/  8460 | loss: 0.7547 | ds_loss: 0.0000 | lr: 4.9521e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    528/  8460 | global iter:    528/  8460 | loss: 0.8670 | ds_loss: 0.0000 | lr: 4.9521e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    529/  8460 | global iter:    529/  8460 | loss: 0.8403 | ds_loss: 0.0000 | lr: 4.9519e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    530/  8460 | global iter:    530/  8460 | loss: 0.6197 | ds_loss: 0.0000 | lr: 4.9517e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    531/  8460 | global iter:    531/  8460 | loss: 0.8241 | ds_loss: 0.0000 | lr: 4.9516e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    532/  8460 | global iter:    532/  8460 | loss: 0.3275 | ds_loss: 0.0000 | lr: 4.9514e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    532/  8460 | global iter:    532/  8460 | loss: 0.6529 | ds_loss: 0.0000 | lr: 4.9514e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    533/  8460 | global iter:    533/  8460 | loss: 0.5600 | ds_loss: 0.0000 | lr: 4.9512e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    534/  8460 | global iter:    534/  8460 | loss: 0.3747 | ds_loss: 0.0000 | lr: 4.9510e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    535/  8460 | global iter:    535/  8460 | loss: 0.3776 | ds_loss: 0.0000 | lr: 4.9508e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    536/  8460 | global iter:    536/  8460 | loss: 1.2285 | ds_loss: 0.0000 | lr: 4.9507e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    536/  8460 | global iter:    536/  8460 | loss: 0.6352 | ds_loss: 0.0000 | lr: 4.9507e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    537/  8460 | global iter:    537/  8460 | loss: 1.7377 | ds_loss: 0.0000 | lr: 4.9505e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    538/  8460 | global iter:    538/  8460 | loss: 0.4034 | ds_loss: 0.0000 | lr: 4.9503e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    539/  8460 | global iter:    539/  8460 | loss: 0.3973 | ds_loss: 0.0000 | lr: 4.9501e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    540/  8460 | global iter:    540/  8460 | loss: 0.6736 | ds_loss: 0.0000 | lr: 4.9499e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    540/  8460 | global iter:    540/  8460 | loss: 0.8030 | ds_loss: 0.0000 | lr: 4.9499e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    541/  8460 | global iter:    541/  8460 | loss: 0.8472 | ds_loss: 0.0000 | lr: 4.9497e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    542/  8460 | global iter:    542/  8460 | loss: 0.3820 | ds_loss: 0.0000 | lr: 4.9495e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    543/  8460 | global iter:    543/  8460 | loss: 0.8440 | ds_loss: 0.0000 | lr: 4.9494e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    544/  8460 | global iter:    544/  8460 | loss: 0.5265 | ds_loss: 0.0000 | lr: 4.9492e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    544/  8460 | global iter:    544/  8460 | loss: 0.6499 | ds_loss: 0.0000 | lr: 4.9492e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    545/  8460 | global iter:    545/  8460 | loss: 0.8917 | ds_loss: 0.0000 | lr: 4.9490e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    546/  8460 | global iter:    546/  8460 | loss: 0.8245 | ds_loss: 0.0000 | lr: 4.9488e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    547/  8460 | global iter:    547/  8460 | loss: 1.8447 | ds_loss: 0.0000 | lr: 4.9486e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    548/  8460 | global iter:    548/  8460 | loss: 0.5414 | ds_loss: 0.0000 | lr: 4.9484e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    548/  8460 | global iter:    548/  8460 | loss: 1.0256 | ds_loss: 0.0000 | lr: 4.9484e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    549/  8460 | global iter:    549/  8460 | loss: 0.5340 | ds_loss: 0.0000 | lr: 4.9482e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    550/  8460 | global iter:    550/  8460 | loss: 0.7672 | ds_loss: 0.0000 | lr: 4.9480e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    551/  8460 | global iter:    551/  8460 | loss: 0.6494 | ds_loss: 0.0000 | lr: 4.9479e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    552/  8460 | global iter:    552/  8460 | loss: 1.7934 | ds_loss: 0.0000 | lr: 4.9477e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    552/  8460 | global iter:    552/  8460 | loss: 0.9360 | ds_loss: 0.0000 | lr: 4.9477e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    553/  8460 | global iter:    553/  8460 | loss: 1.0737 | ds_loss: 0.0000 | lr: 4.9475e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.000
train | epoch   0 | Iter:    554/  8460 | global iter:    554/  8460 | loss: 0.5429 | ds_loss: 0.0000 | lr: 4.9473e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    555/  8460 | global iter:    555/  8460 | loss: 0.8692 | ds_loss: 0.0000 | lr: 4.9471e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    556/  8460 | global iter:    556/  8460 | loss: 0.4616 | ds_loss: 0.0000 | lr: 4.9469e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    556/  8460 | global iter:    556/  8460 | loss: 0.7369 | ds_loss: 0.0000 | lr: 4.9469e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    557/  8460 | global iter:    557/  8460 | loss: 0.7094 | ds_loss: 0.0000 | lr: 4.9467e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    558/  8460 | global iter:    558/  8460 | loss: 1.0139 | ds_loss: 0.0000 | lr: 4.9465e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    559/  8460 | global iter:    559/  8460 | loss: 0.7307 | ds_loss: 0.0000 | lr: 4.9463e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    560/  8460 | global iter:    560/  8460 | loss: 2.8080 | ds_loss: 0.0000 | lr: 4.9461e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    560/  8460 | global iter:    560/  8460 | loss: 1.3155 | ds_loss: 0.0000 | lr: 4.9461e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    561/  8460 | global iter:    561/  8460 | loss: 0.7222 | ds_loss: 0.0000 | lr: 4.9460e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    562/  8460 | global iter:    562/  8460 | loss: 1.1530 | ds_loss: 0.0000 | lr: 4.9458e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    563/  8460 | global iter:    563/  8460 | loss: 0.2504 | ds_loss: 0.0000 | lr: 4.9456e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    564/  8460 | global iter:    564/  8460 | loss: 0.9681 | ds_loss: 0.0000 | lr: 4.9454e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    564/  8460 | global iter:    564/  8460 | loss: 0.7734 | ds_loss: 0.0000 | lr: 4.9454e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    565/  8460 | global iter:    565/  8460 | loss: 0.7833 | ds_loss: 0.0000 | lr: 4.9452e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    566/  8460 | global iter:    566/  8460 | loss: 1.1234 | ds_loss: 0.0000 | lr: 4.9450e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    567/  8460 | global iter:    567/  8460 | loss: 0.4900 | ds_loss: 0.0000 | lr: 4.9448e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    568/  8460 | global iter:    568/  8460 | loss: 0.7561 | ds_loss: 0.0000 | lr: 4.9446e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    568/  8460 | global iter:    568/  8460 | loss: 0.7882 | ds_loss: 0.0000 | lr: 4.9446e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    569/  8460 | global iter:    569/  8460 | loss: 0.3174 | ds_loss: 0.0000 | lr: 4.9444e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    570/  8460 | global iter:    570/  8460 | loss: 0.6221 | ds_loss: 0.0000 | lr: 4.9442e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    571/  8460 | global iter:    571/  8460 | loss: 0.7441 | ds_loss: 0.0000 | lr: 4.9440e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    572/  8460 | global iter:    572/  8460 | loss: 1.2668 | ds_loss: 0.0000 | lr: 4.9438e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    572/  8460 | global iter:    572/  8460 | loss: 0.7376 | ds_loss: 0.0000 | lr: 4.9438e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    573/  8460 | global iter:    573/  8460 | loss: 0.9259 | ds_loss: 0.0000 | lr: 4.9436e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    574/  8460 | global iter:    574/  8460 | loss: 0.8386 | ds_loss: 0.0000 | lr: 4.9434e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    575/  8460 | global iter:    575/  8460 | loss: 1.0181 | ds_loss: 0.0000 | lr: 4.9432e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    576/  8460 | global iter:    576/  8460 | loss: 0.8812 | ds_loss: 0.0000 | lr: 4.9430e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    576/  8460 | global iter:    576/  8460 | loss: 0.9160 | ds_loss: 0.0000 | lr: 4.9430e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    577/  8460 | global iter:    577/  8460 | loss: 0.6672 | ds_loss: 0.0000 | lr: 4.9428e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    578/  8460 | global iter:    578/  8460 | loss: 1.3778 | ds_loss: 0.0000 | lr: 4.9426e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    579/  8460 | global iter:    579/  8460 | loss: 1.7041 | ds_loss: 0.0000 | lr: 4.9424e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    580/  8460 | global iter:    580/  8460 | loss: 0.7135 | ds_loss: 0.0000 | lr: 4.9422e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    580/  8460 | global iter:    580/  8460 | loss: 1.1157 | ds_loss: 0.0000 | lr: 4.9422e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    581/  8460 | global iter:    581/  8460 | loss: 0.2552 | ds_loss: 0.0000 | lr: 4.9421e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    582/  8460 | global iter:    582/  8460 | loss: 1.1185 | ds_loss: 0.0000 | lr: 4.9419e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    583/  8460 | global iter:    583/  8460 | loss: 1.6316 | ds_loss: 0.0000 | lr: 4.9417e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    584/  8460 | global iter:    584/  8460 | loss: 1.6270 | ds_loss: 0.0000 | lr: 4.9415e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    584/  8460 | global iter:    584/  8460 | loss: 1.1581 | ds_loss: 0.0000 | lr: 4.9415e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    585/  8460 | global iter:    585/  8460 | loss: 0.5708 | ds_loss: 0.0000 | lr: 4.9413e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    586/  8460 | global iter:    586/  8460 | loss: 1.6192 | ds_loss: 0.0000 | lr: 4.9411e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    587/  8460 | global iter:    587/  8460 | loss: 0.3747 | ds_loss: 0.0000 | lr: 4.9409e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    588/  8460 | global iter:    588/  8460 | loss: 0.3567 | ds_loss: 0.0000 | lr: 4.9407e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    588/  8460 | global iter:    588/  8460 | loss: 0.7303 | ds_loss: 0.0000 | lr: 4.9407e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    589/  8460 | global iter:    589/  8460 | loss: 0.8490 | ds_loss: 0.0000 | lr: 4.9405e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    590/  8460 | global iter:    590/  8460 | loss: 0.6408 | ds_loss: 0.0000 | lr: 4.9402e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    591/  8460 | global iter:    591/  8460 | loss: 1.0909 | ds_loss: 0.0000 | lr: 4.9400e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    592/  8460 | global iter:    592/  8460 | loss: 0.4300 | ds_loss: 0.0000 | lr: 4.9398e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    592/  8460 | global iter:    592/  8460 | loss: 0.7527 | ds_loss: 0.0000 | lr: 4.9398e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    593/  8460 | global iter:    593/  8460 | loss: 0.5944 | ds_loss: 0.0000 | lr: 4.9396e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    594/  8460 | global iter:    594/  8460 | loss: 0.9499 | ds_loss: 0.0000 | lr: 4.9394e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    595/  8460 | global iter:    595/  8460 | loss: 1.3990 | ds_loss: 0.0000 | lr: 4.9392e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    596/  8460 | global iter:    596/  8460 | loss: 0.5903 | ds_loss: 0.0000 | lr: 4.9390e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    596/  8460 | global iter:    596/  8460 | loss: 0.8834 | ds_loss: 0.0000 | lr: 4.9390e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    597/  8460 | global iter:    597/  8460 | loss: 0.9561 | ds_loss: 0.0000 | lr: 4.9388e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    598/  8460 | global iter:    598/  8460 | loss: 0.7446 | ds_loss: 0.0000 | lr: 4.9386e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    599/  8460 | global iter:    599/  8460 | loss: 0.9121 | ds_loss: 0.0000 | lr: 4.9384e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    600/  8460 | global iter:    600/  8460 | loss: 0.4225 | ds_loss: 0.0000 | lr: 4.9382e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    600/  8460 | global iter:    600/  8460 | loss: 0.7588 | ds_loss: 0.0000 | lr: 4.9382e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    601/  8460 | global iter:    601/  8460 | loss: 1.1943 | ds_loss: 0.0000 | lr: 4.9380e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    602/  8460 | global iter:    602/  8460 | loss: 0.4048 | ds_loss: 0.0000 | lr: 4.9378e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    603/  8460 | global iter:    603/  8460 | loss: 0.4558 | ds_loss: 0.0000 | lr: 4.9376e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    604/  8460 | global iter:    604/  8460 | loss: 0.4461 | ds_loss: 0.0000 | lr: 4.9374e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    604/  8460 | global iter:    604/  8460 | loss: 0.6253 | ds_loss: 0.0000 | lr: 4.9374e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    605/  8460 | global iter:    605/  8460 | loss: 1.4072 | ds_loss: 0.0000 | lr: 4.9372e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    606/  8460 | global iter:    606/  8460 | loss: 1.1521 | ds_loss: 0.0000 | lr: 4.9370e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    607/  8460 | global iter:    607/  8460 | loss: 0.3537 | ds_loss: 0.0000 | lr: 4.9368e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    608/  8460 | global iter:    608/  8460 | loss: 1.5697 | ds_loss: 0.0000 | lr: 4.9366e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    608/  8460 | global iter:    608/  8460 | loss: 1.1207 | ds_loss: 0.0000 | lr: 4.9366e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    609/  8460 | global iter:    609/  8460 | loss: 1.2908 | ds_loss: 0.0000 | lr: 4.9364e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    610/  8460 | global iter:    610/  8460 | loss: 0.7081 | ds_loss: 0.0000 | lr: 4.9361e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    611/  8460 | global iter:    611/  8460 | loss: 0.9986 | ds_loss: 0.0000 | lr: 4.9359e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    612/  8460 | global iter:    612/  8460 | loss: 0.6374 | ds_loss: 0.0000 | lr: 4.9357e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    612/  8460 | global iter:    612/  8460 | loss: 0.9087 | ds_loss: 0.0000 | lr: 4.9357e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    613/  8460 | global iter:    613/  8460 | loss: 1.8680 | ds_loss: 0.0000 | lr: 4.9355e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    614/  8460 | global iter:    614/  8460 | loss: 0.5517 | ds_loss: 0.0000 | lr: 4.9353e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    615/  8460 | global iter:    615/  8460 | loss: 1.9954 | ds_loss: 0.0000 | lr: 4.9351e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    616/  8460 | global iter:    616/  8460 | loss: 1.8692 | ds_loss: 0.0000 | lr: 4.9349e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    616/  8460 | global iter:    616/  8460 | loss: 1.5711 | ds_loss: 0.0000 | lr: 4.9349e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    617/  8460 | global iter:    617/  8460 | loss: 0.6545 | ds_loss: 0.0000 | lr: 4.9347e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    618/  8460 | global iter:    618/  8460 | loss: 0.7233 | ds_loss: 0.0000 | lr: 4.9345e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    619/  8460 | global iter:    619/  8460 | loss: 0.6767 | ds_loss: 0.0000 | lr: 4.9343e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    620/  8460 | global iter:    620/  8460 | loss: 0.4267 | ds_loss: 0.0000 | lr: 4.9340e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    620/  8460 | global iter:    620/  8460 | loss: 0.6203 | ds_loss: 0.0000 | lr: 4.9340e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    621/  8460 | global iter:    621/  8460 | loss: 0.9259 | ds_loss: 0.0000 | lr: 4.9338e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    622/  8460 | global iter:    622/  8460 | loss: 0.3521 | ds_loss: 0.0000 | lr: 4.9336e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    623/  8460 | global iter:    623/  8460 | loss: 0.6993 | ds_loss: 0.0000 | lr: 4.9334e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    624/  8460 | global iter:    624/  8460 | loss: 0.8376 | ds_loss: 0.0000 | lr: 4.9332e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    624/  8460 | global iter:    624/  8460 | loss: 0.7037 | ds_loss: 0.0000 | lr: 4.9332e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    625/  8460 | global iter:    625/  8460 | loss: 0.5291 | ds_loss: 0.0000 | lr: 4.9330e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    626/  8460 | global iter:    626/  8460 | loss: 0.6098 | ds_loss: 0.0000 | lr: 4.9328e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    627/  8460 | global iter:    627/  8460 | loss: 0.5509 | ds_loss: 0.0000 | lr: 4.9326e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    628/  8460 | global iter:    628/  8460 | loss: 0.7320 | ds_loss: 0.0000 | lr: 4.9323e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    628/  8460 | global iter:    628/  8460 | loss: 0.6055 | ds_loss: 0.0000 | lr: 4.9323e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    629/  8460 | global iter:    629/  8460 | loss: 1.5154 | ds_loss: 0.0000 | lr: 4.9321e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    630/  8460 | global iter:    630/  8460 | loss: 1.4092 | ds_loss: 0.0000 | lr: 4.9319e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    631/  8460 | global iter:    631/  8460 | loss: 0.4877 | ds_loss: 0.0000 | lr: 4.9317e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    632/  8460 | global iter:    632/  8460 | loss: 0.7109 | ds_loss: 0.0000 | lr: 4.9315e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    632/  8460 | global iter:    632/  8460 | loss: 1.0308 | ds_loss: 0.0000 | lr: 4.9315e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    633/  8460 | global iter:    633/  8460 | loss: 0.7224 | ds_loss: 0.0000 | lr: 4.9313e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    634/  8460 | global iter:    634/  8460 | loss: 0.6995 | ds_loss: 0.0000 | lr: 4.9310e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    635/  8460 | global iter:    635/  8460 | loss: 0.6703 | ds_loss: 0.0000 | lr: 4.9308e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    636/  8460 | global iter:    636/  8460 | loss: 0.3648 | ds_loss: 0.0000 | lr: 4.9306e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    636/  8460 | global iter:    636/  8460 | loss: 0.6143 | ds_loss: 0.0000 | lr: 4.9306e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    637/  8460 | global iter:    637/  8460 | loss: 0.6571 | ds_loss: 0.0000 | lr: 4.9304e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    638/  8460 | global iter:    638/  8460 | loss: 0.7239 | ds_loss: 0.0000 | lr: 4.9302e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    639/  8460 | global iter:    639/  8460 | loss: 0.7403 | ds_loss: 0.0000 | lr: 4.9300e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    640/  8460 | global iter:    640/  8460 | loss: 1.3021 | ds_loss: 0.0000 | lr: 4.9297e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    640/  8460 | global iter:    640/  8460 | loss: 0.8558 | ds_loss: 0.0000 | lr: 4.9297e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    641/  8460 | global iter:    641/  8460 | loss: 0.9324 | ds_loss: 0.0000 | lr: 4.9295e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    642/  8460 | global iter:    642/  8460 | loss: 0.9621 | ds_loss: 0.0000 | lr: 4.9293e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    643/  8460 | global iter:    643/  8460 | loss: 0.6584 | ds_loss: 0.0000 | lr: 4.9291e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    644/  8460 | global iter:    644/  8460 | loss: 1.6379 | ds_loss: 0.0000 | lr: 4.9289e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    644/  8460 | global iter:    644/  8460 | loss: 1.0477 | ds_loss: 0.0000 | lr: 4.9289e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    645/  8460 | global iter:    645/  8460 | loss: 0.5673 | ds_loss: 0.0000 | lr: 4.9286e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    646/  8460 | global iter:    646/  8460 | loss: 0.5531 | ds_loss: 0.0000 | lr: 4.9284e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    647/  8460 | global iter:    647/  8460 | loss: 1.6796 | ds_loss: 0.0000 | lr: 4.9282e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    648/  8460 | global iter:    648/  8460 | loss: 2.0205 | ds_loss: 0.0000 | lr: 4.9280e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    648/  8460 | global iter:    648/  8460 | loss: 1.2051 | ds_loss: 0.0000 | lr: 4.9280e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    649/  8460 | global iter:    649/  8460 | loss: 0.9650 | ds_loss: 0.0000 | lr: 4.9278e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    650/  8460 | global iter:    650/  8460 | loss: 1.0395 | ds_loss: 0.0000 | lr: 4.9275e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    651/  8460 | global iter:    651/  8460 | loss: 0.5972 | ds_loss: 0.0000 | lr: 4.9273e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    652/  8460 | global iter:    652/  8460 | loss: 0.4843 | ds_loss: 0.0000 | lr: 4.9271e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    652/  8460 | global iter:    652/  8460 | loss: 0.7715 | ds_loss: 0.0000 | lr: 4.9271e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    653/  8460 | global iter:    653/  8460 | loss: 0.6264 | ds_loss: 0.0000 | lr: 4.9269e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    654/  8460 | global iter:    654/  8460 | loss: 1.2639 | ds_loss: 0.0000 | lr: 4.9266e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    655/  8460 | global iter:    655/  8460 | loss: 0.9452 | ds_loss: 0.0000 | lr: 4.9264e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    656/  8460 | global iter:    656/  8460 | loss: 0.2229 | ds_loss: 0.0000 | lr: 4.9262e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    656/  8460 | global iter:    656/  8460 | loss: 0.7646 | ds_loss: 0.0000 | lr: 4.9262e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    657/  8460 | global iter:    657/  8460 | loss: 1.0841 | ds_loss: 0.0000 | lr: 4.9260e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    658/  8460 | global iter:    658/  8460 | loss: 0.5628 | ds_loss: 0.0000 | lr: 4.9258e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    659/  8460 | global iter:    659/  8460 | loss: 1.5946 | ds_loss: 0.0000 | lr: 4.9255e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    660/  8460 | global iter:    660/  8460 | loss: 0.7350 | ds_loss: 0.0000 | lr: 4.9253e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    660/  8460 | global iter:    660/  8460 | loss: 0.9941 | ds_loss: 0.0000 | lr: 4.9253e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    661/  8460 | global iter:    661/  8460 | loss: 1.5705 | ds_loss: 0.0000 | lr: 4.9251e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    662/  8460 | global iter:    662/  8460 | loss: 1.2081 | ds_loss: 0.0000 | lr: 4.9249e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    663/  8460 | global iter:    663/  8460 | loss: 0.6942 | ds_loss: 0.0000 | lr: 4.9246e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    664/  8460 | global iter:    664/  8460 | loss: 1.9392 | ds_loss: 0.0000 | lr: 4.9244e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    664/  8460 | global iter:    664/  8460 | loss: 1.3530 | ds_loss: 0.0000 | lr: 4.9244e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    665/  8460 | global iter:    665/  8460 | loss: 1.0658 | ds_loss: 0.0000 | lr: 4.9242e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    666/  8460 | global iter:    666/  8460 | loss: 0.8015 | ds_loss: 0.0000 | lr: 4.9239e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    667/  8460 | global iter:    667/  8460 | loss: 0.9231 | ds_loss: 0.0000 | lr: 4.9237e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    668/  8460 | global iter:    668/  8460 | loss: 0.6974 | ds_loss: 0.0000 | lr: 4.9235e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    668/  8460 | global iter:    668/  8460 | loss: 0.8720 | ds_loss: 0.0000 | lr: 4.9235e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    669/  8460 | global iter:    669/  8460 | loss: 0.6939 | ds_loss: 0.0000 | lr: 4.9233e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    670/  8460 | global iter:    670/  8460 | loss: 1.3482 | ds_loss: 0.0000 | lr: 4.9230e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    671/  8460 | global iter:    671/  8460 | loss: 0.6832 | ds_loss: 0.0000 | lr: 4.9228e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    672/  8460 | global iter:    672/  8460 | loss: 0.6406 | ds_loss: 0.0000 | lr: 4.9226e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    672/  8460 | global iter:    672/  8460 | loss: 0.8415 | ds_loss: 0.0000 | lr: 4.9226e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    673/  8460 | global iter:    673/  8460 | loss: 0.9127 | ds_loss: 0.0000 | lr: 4.9223e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    674/  8460 | global iter:    674/  8460 | loss: 0.3341 | ds_loss: 0.0000 | lr: 4.9221e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    675/  8460 | global iter:    675/  8460 | loss: 1.0191 | ds_loss: 0.0000 | lr: 4.9219e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    676/  8460 | global iter:    676/  8460 | loss: 0.8977 | ds_loss: 0.0000 | lr: 4.9217e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    676/  8460 | global iter:    676/  8460 | loss: 0.7909 | ds_loss: 0.0000 | lr: 4.9217e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    677/  8460 | global iter:    677/  8460 | loss: 0.9599 | ds_loss: 0.0000 | lr: 4.9214e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    678/  8460 | global iter:    678/  8460 | loss: 1.5202 | ds_loss: 0.0000 | lr: 4.9212e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    679/  8460 | global iter:    679/  8460 | loss: 1.4924 | ds_loss: 0.0000 | lr: 4.9210e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    680/  8460 | global iter:    680/  8460 | loss: 0.4184 | ds_loss: 0.0000 | lr: 4.9207e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    680/  8460 | global iter:    680/  8460 | loss: 1.0977 | ds_loss: 0.0000 | lr: 4.9207e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    681/  8460 | global iter:    681/  8460 | loss: 1.0826 | ds_loss: 0.0000 | lr: 4.9205e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    682/  8460 | global iter:    682/  8460 | loss: 0.6625 | ds_loss: 0.0000 | lr: 4.9203e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    683/  8460 | global iter:    683/  8460 | loss: 0.8932 | ds_loss: 0.0000 | lr: 4.9200e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    684/  8460 | global iter:    684/  8460 | loss: 0.3661 | ds_loss: 0.0000 | lr: 4.9198e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    684/  8460 | global iter:    684/  8460 | loss: 0.7511 | ds_loss: 0.0000 | lr: 4.9198e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    685/  8460 | global iter:    685/  8460 | loss: 0.2954 | ds_loss: 0.0000 | lr: 4.9196e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    686/  8460 | global iter:    686/  8460 | loss: 0.3466 | ds_loss: 0.0000 | lr: 4.9193e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    687/  8460 | global iter:    687/  8460 | loss: 0.7715 | ds_loss: 0.0000 | lr: 4.9191e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    688/  8460 | global iter:    688/  8460 | loss: 1.2112 | ds_loss: 0.0000 | lr: 4.9189e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    688/  8460 | global iter:    688/  8460 | loss: 0.6562 | ds_loss: 0.0000 | lr: 4.9189e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    689/  8460 | global iter:    689/  8460 | loss: 0.5863 | ds_loss: 0.0000 | lr: 4.9186e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    690/  8460 | global iter:    690/  8460 | loss: 1.2056 | ds_loss: 0.0000 | lr: 4.9184e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    691/  8460 | global iter:    691/  8460 | loss: 1.1889 | ds_loss: 0.0000 | lr: 4.9182e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    692/  8460 | global iter:    692/  8460 | loss: 0.5133 | ds_loss: 0.0000 | lr: 4.9179e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    692/  8460 | global iter:    692/  8460 | loss: 0.8735 | ds_loss: 0.0000 | lr: 4.9179e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    693/  8460 | global iter:    693/  8460 | loss: 0.4411 | ds_loss: 0.0000 | lr: 4.9177e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    694/  8460 | global iter:    694/  8460 | loss: 1.5898 | ds_loss: 0.0000 | lr: 4.9175e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    695/  8460 | global iter:    695/  8460 | loss: 1.5580 | ds_loss: 0.0000 | lr: 4.9172e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    696/  8460 | global iter:    696/  8460 | loss: 0.7175 | ds_loss: 0.0000 | lr: 4.9170e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    696/  8460 | global iter:    696/  8460 | loss: 1.0766 | ds_loss: 0.0000 | lr: 4.9170e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    697/  8460 | global iter:    697/  8460 | loss: 1.6998 | ds_loss: 0.0000 | lr: 4.9167e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    698/  8460 | global iter:    698/  8460 | loss: 0.4161 | ds_loss: 0.0000 | lr: 4.9165e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    699/  8460 | global iter:    699/  8460 | loss: 0.7582 | ds_loss: 0.0000 | lr: 4.9163e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    700/  8460 | global iter:    700/  8460 | loss: 1.0520 | ds_loss: 0.0000 | lr: 4.9160e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    700/  8460 | global iter:    700/  8460 | loss: 0.9815 | ds_loss: 0.0000 | lr: 4.9160e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    701/  8460 | global iter:    701/  8460 | loss: 1.3263 | ds_loss: 0.0000 | lr: 4.9158e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    702/  8460 | global iter:    702/  8460 | loss: 0.7926 | ds_loss: 0.0000 | lr: 4.9156e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    703/  8460 | global iter:    703/  8460 | loss: 0.8918 | ds_loss: 0.0000 | lr: 4.9153e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    704/  8460 | global iter:    704/  8460 | loss: 1.0803 | ds_loss: 0.0000 | lr: 4.9151e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    704/  8460 | global iter:    704/  8460 | loss: 1.0227 | ds_loss: 0.0000 | lr: 4.9151e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    705/  8460 | global iter:    705/  8460 | loss: 0.4002 | ds_loss: 0.0000 | lr: 4.9148e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    706/  8460 | global iter:    706/  8460 | loss: 0.3802 | ds_loss: 0.0000 | lr: 4.9146e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    707/  8460 | global iter:    707/  8460 | loss: 0.9233 | ds_loss: 0.0000 | lr: 4.9144e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    708/  8460 | global iter:    708/  8460 | loss: 1.3372 | ds_loss: 0.0000 | lr: 4.9141e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    708/  8460 | global iter:    708/  8460 | loss: 0.7603 | ds_loss: 0.0000 | lr: 4.9141e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    709/  8460 | global iter:    709/  8460 | loss: 0.9827 | ds_loss: 0.0000 | lr: 4.9139e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    710/  8460 | global iter:    710/  8460 | loss: 1.1651 | ds_loss: 0.0000 | lr: 4.9136e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    711/  8460 | global iter:    711/  8460 | loss: 0.4536 | ds_loss: 0.0000 | lr: 4.9134e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    712/  8460 | global iter:    712/  8460 | loss: 0.4259 | ds_loss: 0.0000 | lr: 4.9131e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    712/  8460 | global iter:    712/  8460 | loss: 0.7568 | ds_loss: 0.0000 | lr: 4.9131e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    713/  8460 | global iter:    713/  8460 | loss: 0.6654 | ds_loss: 0.0000 | lr: 4.9129e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    714/  8460 | global iter:    714/  8460 | loss: 1.2962 | ds_loss: 0.0000 | lr: 4.9127e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    715/  8460 | global iter:    715/  8460 | loss: 0.8430 | ds_loss: 0.0000 | lr: 4.9124e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    716/  8460 | global iter:    716/  8460 | loss: 1.1072 | ds_loss: 0.0000 | lr: 4.9122e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    716/  8460 | global iter:    716/  8460 | loss: 0.9779 | ds_loss: 0.0000 | lr: 4.9122e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    717/  8460 | global iter:    717/  8460 | loss: 0.4353 | ds_loss: 0.0000 | lr: 4.9119e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    718/  8460 | global iter:    718/  8460 | loss: 0.9278 | ds_loss: 0.0000 | lr: 4.9117e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    719/  8460 | global iter:    719/  8460 | loss: 0.5070 | ds_loss: 0.0000 | lr: 4.9114e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    720/  8460 | global iter:    720/  8460 | loss: 0.6971 | ds_loss: 0.0000 | lr: 4.9112e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    720/  8460 | global iter:    720/  8460 | loss: 0.6418 | ds_loss: 0.0000 | lr: 4.9112e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    721/  8460 | global iter:    721/  8460 | loss: 0.5724 | ds_loss: 0.0000 | lr: 4.9109e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    722/  8460 | global iter:    722/  8460 | loss: 0.8382 | ds_loss: 0.0000 | lr: 4.9107e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    723/  8460 | global iter:    723/  8460 | loss: 0.7436 | ds_loss: 0.0000 | lr: 4.9105e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    724/  8460 | global iter:    724/  8460 | loss: 1.1995 | ds_loss: 0.0000 | lr: 4.9102e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    724/  8460 | global iter:    724/  8460 | loss: 0.8384 | ds_loss: 0.0000 | lr: 4.9102e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    725/  8460 | global iter:    725/  8460 | loss: 0.4473 | ds_loss: 0.0000 | lr: 4.9100e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    726/  8460 | global iter:    726/  8460 | loss: 0.3772 | ds_loss: 0.0000 | lr: 4.9097e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    727/  8460 | global iter:    727/  8460 | loss: 0.6171 | ds_loss: 0.0000 | lr: 4.9095e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    728/  8460 | global iter:    728/  8460 | loss: 1.1522 | ds_loss: 0.0000 | lr: 4.9092e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    728/  8460 | global iter:    728/  8460 | loss: 0.6484 | ds_loss: 0.0000 | lr: 4.9092e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    729/  8460 | global iter:    729/  8460 | loss: 0.8219 | ds_loss: 0.0000 | lr: 4.9090e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    730/  8460 | global iter:    730/  8460 | loss: 0.4708 | ds_loss: 0.0000 | lr: 4.9087e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    731/  8460 | global iter:    731/  8460 | loss: 0.9598 | ds_loss: 0.0000 | lr: 4.9085e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    732/  8460 | global iter:    732/  8460 | loss: 0.8194 | ds_loss: 0.0000 | lr: 4.9082e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    732/  8460 | global iter:    732/  8460 | loss: 0.7680 | ds_loss: 0.0000 | lr: 4.9082e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    733/  8460 | global iter:    733/  8460 | loss: 0.8828 | ds_loss: 0.0000 | lr: 4.9080e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    734/  8460 | global iter:    734/  8460 | loss: 0.5056 | ds_loss: 0.0000 | lr: 4.9077e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    735/  8460 | global iter:    735/  8460 | loss: 0.9261 | ds_loss: 0.0000 | lr: 4.9075e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    736/  8460 | global iter:    736/  8460 | loss: 1.2678 | ds_loss: 0.0000 | lr: 4.9072e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    736/  8460 | global iter:    736/  8460 | loss: 0.8956 | ds_loss: 0.0000 | lr: 4.9072e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    737/  8460 | global iter:    737/  8460 | loss: 0.7769 | ds_loss: 0.0000 | lr: 4.9070e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    738/  8460 | global iter:    738/  8460 | loss: 0.9450 | ds_loss: 0.0000 | lr: 4.9067e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    739/  8460 | global iter:    739/  8460 | loss: 1.3960 | ds_loss: 0.0000 | lr: 4.9065e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    740/  8460 | global iter:    740/  8460 | loss: 1.2485 | ds_loss: 0.0000 | lr: 4.9062e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    740/  8460 | global iter:    740/  8460 | loss: 1.0916 | ds_loss: 0.0000 | lr: 4.9062e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    741/  8460 | global iter:    741/  8460 | loss: 1.1521 | ds_loss: 0.0000 | lr: 4.9060e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    742/  8460 | global iter:    742/  8460 | loss: 2.1765 | ds_loss: 0.0000 | lr: 4.9057e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    743/  8460 | global iter:    743/  8460 | loss: 0.6445 | ds_loss: 0.0000 | lr: 4.9055e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    744/  8460 | global iter:    744/  8460 | loss: 0.5313 | ds_loss: 0.0000 | lr: 4.9052e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    744/  8460 | global iter:    744/  8460 | loss: 1.1261 | ds_loss: 0.0000 | lr: 4.9052e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    745/  8460 | global iter:    745/  8460 | loss: 0.8342 | ds_loss: 0.0000 | lr: 4.9050e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    746/  8460 | global iter:    746/  8460 | loss: 0.7383 | ds_loss: 0.0000 | lr: 4.9047e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    747/  8460 | global iter:    747/  8460 | loss: 1.7628 | ds_loss: 0.0000 | lr: 4.9044e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    748/  8460 | global iter:    748/  8460 | loss: 0.9185 | ds_loss: 0.0000 | lr: 4.9042e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    748/  8460 | global iter:    748/  8460 | loss: 1.0634 | ds_loss: 0.0000 | lr: 4.9042e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    749/  8460 | global iter:    749/  8460 | loss: 0.5792 | ds_loss: 0.0000 | lr: 4.9039e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    750/  8460 | global iter:    750/  8460 | loss: 0.2744 | ds_loss: 0.0000 | lr: 4.9037e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    751/  8460 | global iter:    751/  8460 | loss: 0.5706 | ds_loss: 0.0000 | lr: 4.9034e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    752/  8460 | global iter:    752/  8460 | loss: 0.3231 | ds_loss: 0.0000 | lr: 4.9032e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    752/  8460 | global iter:    752/  8460 | loss: 0.4368 | ds_loss: 0.0000 | lr: 4.9032e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    753/  8460 | global iter:    753/  8460 | loss: 0.8228 | ds_loss: 0.0000 | lr: 4.9029e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.000
train | epoch   0 | Iter:    754/  8460 | global iter:    754/  8460 | loss: 1.4315 | ds_loss: 0.0000 | lr: 4.9027e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    755/  8460 | global iter:    755/  8460 | loss: 0.8968 | ds_loss: 0.0000 | lr: 4.9024e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    756/  8460 | global iter:    756/  8460 | loss: 0.6494 | ds_loss: 0.0000 | lr: 4.9021e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    756/  8460 | global iter:    756/  8460 | loss: 0.9501 | ds_loss: 0.0000 | lr: 4.9021e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    757/  8460 | global iter:    757/  8460 | loss: 0.8343 | ds_loss: 0.0000 | lr: 4.9019e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    758/  8460 | global iter:    758/  8460 | loss: 1.4253 | ds_loss: 0.0000 | lr: 4.9016e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    759/  8460 | global iter:    759/  8460 | loss: 0.7267 | ds_loss: 0.0000 | lr: 4.9014e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    760/  8460 | global iter:    760/  8460 | loss: 1.4048 | ds_loss: 0.0000 | lr: 4.9011e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    760/  8460 | global iter:    760/  8460 | loss: 1.0978 | ds_loss: 0.0000 | lr: 4.9011e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    761/  8460 | global iter:    761/  8460 | loss: 0.6352 | ds_loss: 0.0000 | lr: 4.9009e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    762/  8460 | global iter:    762/  8460 | loss: 1.0890 | ds_loss: 0.0000 | lr: 4.9006e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    763/  8460 | global iter:    763/  8460 | loss: 0.6264 | ds_loss: 0.0000 | lr: 4.9003e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    764/  8460 | global iter:    764/  8460 | loss: 0.9915 | ds_loss: 0.0000 | lr: 4.9001e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    764/  8460 | global iter:    764/  8460 | loss: 0.8355 | ds_loss: 0.0000 | lr: 4.9001e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    765/  8460 | global iter:    765/  8460 | loss: 0.8548 | ds_loss: 0.0000 | lr: 4.8998e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    766/  8460 | global iter:    766/  8460 | loss: 1.4959 | ds_loss: 0.0000 | lr: 4.8996e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    767/  8460 | global iter:    767/  8460 | loss: 0.8238 | ds_loss: 0.0000 | lr: 4.8993e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    768/  8460 | global iter:    768/  8460 | loss: 0.6126 | ds_loss: 0.0000 | lr: 4.8990e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    768/  8460 | global iter:    768/  8460 | loss: 0.9468 | ds_loss: 0.0000 | lr: 4.8990e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    769/  8460 | global iter:    769/  8460 | loss: 1.2686 | ds_loss: 0.0000 | lr: 4.8988e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    770/  8460 | global iter:    770/  8460 | loss: 0.6934 | ds_loss: 0.0000 | lr: 4.8985e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    771/  8460 | global iter:    771/  8460 | loss: 0.3385 | ds_loss: 0.0000 | lr: 4.8983e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    772/  8460 | global iter:    772/  8460 | loss: 0.7081 | ds_loss: 0.0000 | lr: 4.8980e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    772/  8460 | global iter:    772/  8460 | loss: 0.7521 | ds_loss: 0.0000 | lr: 4.8980e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    773/  8460 | global iter:    773/  8460 | loss: 0.7317 | ds_loss: 0.0000 | lr: 4.8977e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    774/  8460 | global iter:    774/  8460 | loss: 0.7375 | ds_loss: 0.0000 | lr: 4.8975e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    775/  8460 | global iter:    775/  8460 | loss: 0.1925 | ds_loss: 0.0000 | lr: 4.8972e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    776/  8460 | global iter:    776/  8460 | loss: 0.8346 | ds_loss: 0.0000 | lr: 4.8969e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    776/  8460 | global iter:    776/  8460 | loss: 0.6241 | ds_loss: 0.0000 | lr: 4.8969e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    777/  8460 | global iter:    777/  8460 | loss: 1.0246 | ds_loss: 0.0000 | lr: 4.8967e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    778/  8460 | global iter:    778/  8460 | loss: 0.6349 | ds_loss: 0.0000 | lr: 4.8964e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    779/  8460 | global iter:    779/  8460 | loss: 0.9463 | ds_loss: 0.0000 | lr: 4.8961e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    780/  8460 | global iter:    780/  8460 | loss: 1.3220 | ds_loss: 0.0000 | lr: 4.8959e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    780/  8460 | global iter:    780/  8460 | loss: 0.9819 | ds_loss: 0.0000 | lr: 4.8959e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    781/  8460 | global iter:    781/  8460 | loss: 0.2270 | ds_loss: 0.0000 | lr: 4.8956e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    782/  8460 | global iter:    782/  8460 | loss: 0.7245 | ds_loss: 0.0000 | lr: 4.8953e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    783/  8460 | global iter:    783/  8460 | loss: 0.8912 | ds_loss: 0.0000 | lr: 4.8951e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    784/  8460 | global iter:    784/  8460 | loss: 0.2764 | ds_loss: 0.0000 | lr: 4.8948e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    784/  8460 | global iter:    784/  8460 | loss: 0.5298 | ds_loss: 0.0000 | lr: 4.8948e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    785/  8460 | global iter:    785/  8460 | loss: 0.8437 | ds_loss: 0.0000 | lr: 4.8946e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    786/  8460 | global iter:    786/  8460 | loss: 0.7484 | ds_loss: 0.0000 | lr: 4.8943e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    787/  8460 | global iter:    787/  8460 | loss: 0.8853 | ds_loss: 0.0000 | lr: 4.8940e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    788/  8460 | global iter:    788/  8460 | loss: 0.8729 | ds_loss: 0.0000 | lr: 4.8937e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    788/  8460 | global iter:    788/  8460 | loss: 0.8376 | ds_loss: 0.0000 | lr: 4.8937e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    789/  8460 | global iter:    789/  8460 | loss: 0.5979 | ds_loss: 0.0000 | lr: 4.8935e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    790/  8460 | global iter:    790/  8460 | loss: 0.9528 | ds_loss: 0.0000 | lr: 4.8932e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    791/  8460 | global iter:    791/  8460 | loss: 1.5185 | ds_loss: 0.0000 | lr: 4.8929e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    792/  8460 | global iter:    792/  8460 | loss: 0.7532 | ds_loss: 0.0000 | lr: 4.8927e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    792/  8460 | global iter:    792/  8460 | loss: 0.9556 | ds_loss: 0.0000 | lr: 4.8927e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    793/  8460 | global iter:    793/  8460 | loss: 1.0809 | ds_loss: 0.0000 | lr: 4.8924e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    794/  8460 | global iter:    794/  8460 | loss: 0.3204 | ds_loss: 0.0000 | lr: 4.8921e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    795/  8460 | global iter:    795/  8460 | loss: 1.2320 | ds_loss: 0.0000 | lr: 4.8919e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    796/  8460 | global iter:    796/  8460 | loss: 1.1294 | ds_loss: 0.0000 | lr: 4.8916e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    796/  8460 | global iter:    796/  8460 | loss: 0.9407 | ds_loss: 0.0000 | lr: 4.8916e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    797/  8460 | global iter:    797/  8460 | loss: 1.0371 | ds_loss: 0.0000 | lr: 4.8913e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    798/  8460 | global iter:    798/  8460 | loss: 0.7716 | ds_loss: 0.0000 | lr: 4.8911e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    799/  8460 | global iter:    799/  8460 | loss: 0.7890 | ds_loss: 0.0000 | lr: 4.8908e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    800/  8460 | global iter:    800/  8460 | loss: 0.8088 | ds_loss: 0.0000 | lr: 4.8905e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    800/  8460 | global iter:    800/  8460 | loss: 0.8516 | ds_loss: 0.0000 | lr: 4.8905e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    801/  8460 | global iter:    801/  8460 | loss: 1.2430 | ds_loss: 0.0000 | lr: 4.8902e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    802/  8460 | global iter:    802/  8460 | loss: 0.5199 | ds_loss: 0.0000 | lr: 4.8900e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    803/  8460 | global iter:    803/  8460 | loss: 1.3101 | ds_loss: 0.0000 | lr: 4.8897e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    804/  8460 | global iter:    804/  8460 | loss: 0.6488 | ds_loss: 0.0000 | lr: 4.8894e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    804/  8460 | global iter:    804/  8460 | loss: 0.9304 | ds_loss: 0.0000 | lr: 4.8894e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    805/  8460 | global iter:    805/  8460 | loss: 0.5301 | ds_loss: 0.0000 | lr: 4.8891e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    806/  8460 | global iter:    806/  8460 | loss: 0.5259 | ds_loss: 0.0000 | lr: 4.8889e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    807/  8460 | global iter:    807/  8460 | loss: 0.5429 | ds_loss: 0.0000 | lr: 4.8886e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    808/  8460 | global iter:    808/  8460 | loss: 0.7601 | ds_loss: 0.0000 | lr: 4.8883e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    808/  8460 | global iter:    808/  8460 | loss: 0.5898 | ds_loss: 0.0000 | lr: 4.8883e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    809/  8460 | global iter:    809/  8460 | loss: 0.6311 | ds_loss: 0.0000 | lr: 4.8881e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    810/  8460 | global iter:    810/  8460 | loss: 0.4517 | ds_loss: 0.0000 | lr: 4.8878e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    811/  8460 | global iter:    811/  8460 | loss: 0.4381 | ds_loss: 0.0000 | lr: 4.8875e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    812/  8460 | global iter:    812/  8460 | loss: 0.9872 | ds_loss: 0.0000 | lr: 4.8872e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    812/  8460 | global iter:    812/  8460 | loss: 0.6270 | ds_loss: 0.0000 | lr: 4.8872e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    813/  8460 | global iter:    813/  8460 | loss: 1.2135 | ds_loss: 0.0000 | lr: 4.8870e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    814/  8460 | global iter:    814/  8460 | loss: 0.7834 | ds_loss: 0.0000 | lr: 4.8867e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    815/  8460 | global iter:    815/  8460 | loss: 0.6993 | ds_loss: 0.0000 | lr: 4.8864e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    816/  8460 | global iter:    816/  8460 | loss: 1.7126 | ds_loss: 0.0000 | lr: 4.8861e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    816/  8460 | global iter:    816/  8460 | loss: 1.1022 | ds_loss: 0.0000 | lr: 4.8861e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    817/  8460 | global iter:    817/  8460 | loss: 0.3226 | ds_loss: 0.0000 | lr: 4.8858e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    818/  8460 | global iter:    818/  8460 | loss: 1.2192 | ds_loss: 0.0000 | lr: 4.8856e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    819/  8460 | global iter:    819/  8460 | loss: 0.7861 | ds_loss: 0.0000 | lr: 4.8853e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    820/  8460 | global iter:    820/  8460 | loss: 0.3857 | ds_loss: 0.0000 | lr: 4.8850e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    820/  8460 | global iter:    820/  8460 | loss: 0.6784 | ds_loss: 0.0000 | lr: 4.8850e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    821/  8460 | global iter:    821/  8460 | loss: 0.4568 | ds_loss: 0.0000 | lr: 4.8847e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    822/  8460 | global iter:    822/  8460 | loss: 0.3545 | ds_loss: 0.0000 | lr: 4.8845e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    823/  8460 | global iter:    823/  8460 | loss: 0.2606 | ds_loss: 0.0000 | lr: 4.8842e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    824/  8460 | global iter:    824/  8460 | loss: 0.8014 | ds_loss: 0.0000 | lr: 4.8839e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    824/  8460 | global iter:    824/  8460 | loss: 0.4683 | ds_loss: 0.0000 | lr: 4.8839e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    825/  8460 | global iter:    825/  8460 | loss: 0.9388 | ds_loss: 0.0000 | lr: 4.8836e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    826/  8460 | global iter:    826/  8460 | loss: 0.5246 | ds_loss: 0.0000 | lr: 4.8833e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    827/  8460 | global iter:    827/  8460 | loss: 0.2247 | ds_loss: 0.0000 | lr: 4.8831e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    828/  8460 | global iter:    828/  8460 | loss: 0.6037 | ds_loss: 0.0000 | lr: 4.8828e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    828/  8460 | global iter:    828/  8460 | loss: 0.5729 | ds_loss: 0.0000 | lr: 4.8828e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    829/  8460 | global iter:    829/  8460 | loss: 0.8842 | ds_loss: 0.0000 | lr: 4.8825e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    830/  8460 | global iter:    830/  8460 | loss: 0.5004 | ds_loss: 0.0000 | lr: 4.8822e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    831/  8460 | global iter:    831/  8460 | loss: 0.6607 | ds_loss: 0.0000 | lr: 4.8819e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    832/  8460 | global iter:    832/  8460 | loss: 0.9684 | ds_loss: 0.0000 | lr: 4.8816e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    832/  8460 | global iter:    832/  8460 | loss: 0.7534 | ds_loss: 0.0000 | lr: 4.8816e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    833/  8460 | global iter:    833/  8460 | loss: 1.0521 | ds_loss: 0.0000 | lr: 4.8814e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    834/  8460 | global iter:    834/  8460 | loss: 0.9367 | ds_loss: 0.0000 | lr: 4.8811e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    835/  8460 | global iter:    835/  8460 | loss: 1.0834 | ds_loss: 0.0000 | lr: 4.8808e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   0 | Iter:    836/  8460 | global iter:    836/  8460 | loss: 1.2593 | ds_loss: 0.0000 | lr: 4.8805e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    836/  8460 | global iter:    836/  8460 | loss: 1.0829 | ds_loss: 0.0000 | lr: 4.8805e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    837/  8460 | global iter:    837/  8460 | loss: 0.1821 | ds_loss: 0.0000 | lr: 4.8802e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    838/  8460 | global iter:    838/  8460 | loss: 1.1126 | ds_loss: 0.0000 | lr: 4.8799e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    839/  8460 | global iter:    839/  8460 | loss: 0.4656 | ds_loss: 0.0000 | lr: 4.8797e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    840/  8460 | global iter:    840/  8460 | loss: 0.5391 | ds_loss: 0.0000 | lr: 4.8794e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    840/  8460 | global iter:    840/  8460 | loss: 0.5748 | ds_loss: 0.0000 | lr: 4.8794e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    841/  8460 | global iter:    841/  8460 | loss: 1.9905 | ds_loss: 0.0000 | lr: 4.8791e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    842/  8460 | global iter:    842/  8460 | loss: 0.4977 | ds_loss: 0.0000 | lr: 4.8788e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   0 | Iter:    843/  8460 | global iter:    843/  8460 | loss: 1.2724 | ds_loss: 0.0000 | lr: 4.8785e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    844/  8460 | global iter:    844/  8460 | loss: 0.7822 | ds_loss: 0.0000 | lr: 4.8782e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    844/  8460 | global iter:    844/  8460 | loss: 1.1357 | ds_loss: 0.0000 | lr: 4.8782e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   0 | Iter:    845/  8460 | global iter:    845/  8460 | loss: 0.3455 | ds_loss: 0.0000 | lr: 4.8780e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    846/  8460 | global iter:    846/  8460 | loss: 0.4435 | ds_loss: 0.0000 | lr: 4.8777e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   0 | Iter:    847/  8460 | global iter:    847/  8460 | loss: 0.3882 | ds_loss: 0.0000 | lr: 4.8774e-04 | scale:     1.0000 | micro time: 0.367 | step time: 0.000
Sun Apr  6 20:55:38 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla P100-PCIE-12GB           Off |   00000000:81:00.0 Off |                    0 |
| N/A   52C    P0             39W /  250W |    8807MiB /  12288MiB |     78%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A    244677      C   ...project_distillLLM/venv/bin/python3       8804MiB |
+-----------------------------------------------------------------------------------------+

train | epoch   1 | Iter:    848/  8460 | global iter:    848/  8460 | loss: 0.7922 | ds_loss: 0.0000 | lr: 4.8771e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    848/  8460 | global iter:    848/  8460 | loss: 0.4924 | ds_loss: 0.0000 | lr: 4.8771e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.413
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    849/  8460 | global iter:    849/  8460 | loss: 1.3107 | ds_loss: 0.0000 | lr: 4.8768e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    850/  8460 | global iter:    850/  8460 | loss: 0.6165 | ds_loss: 0.0000 | lr: 4.8765e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    851/  8460 | global iter:    851/  8460 | loss: 0.7702 | ds_loss: 0.0000 | lr: 4.8762e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    852/  8460 | global iter:    852/  8460 | loss: 0.9631 | ds_loss: 0.0000 | lr: 4.8759e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    852/  8460 | global iter:    852/  8460 | loss: 0.9151 | ds_loss: 0.0000 | lr: 4.8759e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    853/  8460 | global iter:    853/  8460 | loss: 1.1670 | ds_loss: 0.0000 | lr: 4.8756e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    854/  8460 | global iter:    854/  8460 | loss: 1.3387 | ds_loss: 0.0000 | lr: 4.8754e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    855/  8460 | global iter:    855/  8460 | loss: 0.9244 | ds_loss: 0.0000 | lr: 4.8751e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    856/  8460 | global iter:    856/  8460 | loss: 1.2724 | ds_loss: 0.0000 | lr: 4.8748e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    856/  8460 | global iter:    856/  8460 | loss: 1.1756 | ds_loss: 0.0000 | lr: 4.8748e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    857/  8460 | global iter:    857/  8460 | loss: 0.9284 | ds_loss: 0.0000 | lr: 4.8745e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    858/  8460 | global iter:    858/  8460 | loss: 0.9630 | ds_loss: 0.0000 | lr: 4.8742e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    859/  8460 | global iter:    859/  8460 | loss: 0.7599 | ds_loss: 0.0000 | lr: 4.8739e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    860/  8460 | global iter:    860/  8460 | loss: 0.6960 | ds_loss: 0.0000 | lr: 4.8736e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    860/  8460 | global iter:    860/  8460 | loss: 0.8368 | ds_loss: 0.0000 | lr: 4.8736e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    861/  8460 | global iter:    861/  8460 | loss: 0.4009 | ds_loss: 0.0000 | lr: 4.8733e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:    862/  8460 | global iter:    862/  8460 | loss: 0.5529 | ds_loss: 0.0000 | lr: 4.8730e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:    863/  8460 | global iter:    863/  8460 | loss: 0.3188 | ds_loss: 0.0000 | lr: 4.8727e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    864/  8460 | global iter:    864/  8460 | loss: 0.6116 | ds_loss: 0.0000 | lr: 4.8724e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    864/  8460 | global iter:    864/  8460 | loss: 0.4710 | ds_loss: 0.0000 | lr: 4.8724e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    865/  8460 | global iter:    865/  8460 | loss: 0.3485 | ds_loss: 0.0000 | lr: 4.8722e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    866/  8460 | global iter:    866/  8460 | loss: 0.4535 | ds_loss: 0.0000 | lr: 4.8719e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    867/  8460 | global iter:    867/  8460 | loss: 0.7368 | ds_loss: 0.0000 | lr: 4.8716e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    868/  8460 | global iter:    868/  8460 | loss: 0.9924 | ds_loss: 0.0000 | lr: 4.8713e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    868/  8460 | global iter:    868/  8460 | loss: 0.6328 | ds_loss: 0.0000 | lr: 4.8713e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    869/  8460 | global iter:    869/  8460 | loss: 0.5464 | ds_loss: 0.0000 | lr: 4.8710e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    870/  8460 | global iter:    870/  8460 | loss: 1.0929 | ds_loss: 0.0000 | lr: 4.8707e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:    871/  8460 | global iter:    871/  8460 | loss: 0.9127 | ds_loss: 0.0000 | lr: 4.8704e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    872/  8460 | global iter:    872/  8460 | loss: 0.1556 | ds_loss: 0.0000 | lr: 4.8701e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    872/  8460 | global iter:    872/  8460 | loss: 0.6769 | ds_loss: 0.0000 | lr: 4.8701e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    873/  8460 | global iter:    873/  8460 | loss: 1.3870 | ds_loss: 0.0000 | lr: 4.8698e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    874/  8460 | global iter:    874/  8460 | loss: 0.6425 | ds_loss: 0.0000 | lr: 4.8695e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    875/  8460 | global iter:    875/  8460 | loss: 0.5586 | ds_loss: 0.0000 | lr: 4.8692e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    876/  8460 | global iter:    876/  8460 | loss: 0.6161 | ds_loss: 0.0000 | lr: 4.8689e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    876/  8460 | global iter:    876/  8460 | loss: 0.8010 | ds_loss: 0.0000 | lr: 4.8689e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    877/  8460 | global iter:    877/  8460 | loss: 0.4849 | ds_loss: 0.0000 | lr: 4.8686e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    878/  8460 | global iter:    878/  8460 | loss: 1.2048 | ds_loss: 0.0000 | lr: 4.8683e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    879/  8460 | global iter:    879/  8460 | loss: 0.5126 | ds_loss: 0.0000 | lr: 4.8680e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    880/  8460 | global iter:    880/  8460 | loss: 0.4500 | ds_loss: 0.0000 | lr: 4.8677e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    880/  8460 | global iter:    880/  8460 | loss: 0.6631 | ds_loss: 0.0000 | lr: 4.8677e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    881/  8460 | global iter:    881/  8460 | loss: 1.6132 | ds_loss: 0.0000 | lr: 4.8674e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    882/  8460 | global iter:    882/  8460 | loss: 1.0917 | ds_loss: 0.0000 | lr: 4.8671e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    883/  8460 | global iter:    883/  8460 | loss: 1.0583 | ds_loss: 0.0000 | lr: 4.8668e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    884/  8460 | global iter:    884/  8460 | loss: 0.7568 | ds_loss: 0.0000 | lr: 4.8665e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    884/  8460 | global iter:    884/  8460 | loss: 1.1300 | ds_loss: 0.0000 | lr: 4.8665e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    885/  8460 | global iter:    885/  8460 | loss: 1.5159 | ds_loss: 0.0000 | lr: 4.8662e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    886/  8460 | global iter:    886/  8460 | loss: 0.5425 | ds_loss: 0.0000 | lr: 4.8659e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    887/  8460 | global iter:    887/  8460 | loss: 0.4213 | ds_loss: 0.0000 | lr: 4.8656e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    888/  8460 | global iter:    888/  8460 | loss: 1.6637 | ds_loss: 0.0000 | lr: 4.8653e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    888/  8460 | global iter:    888/  8460 | loss: 1.0358 | ds_loss: 0.0000 | lr: 4.8653e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    889/  8460 | global iter:    889/  8460 | loss: 0.4402 | ds_loss: 0.0000 | lr: 4.8650e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    890/  8460 | global iter:    890/  8460 | loss: 0.6207 | ds_loss: 0.0000 | lr: 4.8647e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    891/  8460 | global iter:    891/  8460 | loss: 0.7090 | ds_loss: 0.0000 | lr: 4.8644e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    892/  8460 | global iter:    892/  8460 | loss: 0.2064 | ds_loss: 0.0000 | lr: 4.8641e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    892/  8460 | global iter:    892/  8460 | loss: 0.4941 | ds_loss: 0.0000 | lr: 4.8641e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    893/  8460 | global iter:    893/  8460 | loss: 0.4454 | ds_loss: 0.0000 | lr: 4.8638e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    894/  8460 | global iter:    894/  8460 | loss: 0.4824 | ds_loss: 0.0000 | lr: 4.8635e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    895/  8460 | global iter:    895/  8460 | loss: 0.8221 | ds_loss: 0.0000 | lr: 4.8632e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    896/  8460 | global iter:    896/  8460 | loss: 0.5525 | ds_loss: 0.0000 | lr: 4.8629e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    896/  8460 | global iter:    896/  8460 | loss: 0.5756 | ds_loss: 0.0000 | lr: 4.8629e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    897/  8460 | global iter:    897/  8460 | loss: 0.7886 | ds_loss: 0.0000 | lr: 4.8626e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    898/  8460 | global iter:    898/  8460 | loss: 0.3024 | ds_loss: 0.0000 | lr: 4.8623e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    899/  8460 | global iter:    899/  8460 | loss: 0.8472 | ds_loss: 0.0000 | lr: 4.8620e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    900/  8460 | global iter:    900/  8460 | loss: 0.5093 | ds_loss: 0.0000 | lr: 4.8617e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    900/  8460 | global iter:    900/  8460 | loss: 0.6119 | ds_loss: 0.0000 | lr: 4.8617e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    901/  8460 | global iter:    901/  8460 | loss: 0.5591 | ds_loss: 0.0000 | lr: 4.8614e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    902/  8460 | global iter:    902/  8460 | loss: 0.5027 | ds_loss: 0.0000 | lr: 4.8611e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:    903/  8460 | global iter:    903/  8460 | loss: 0.6576 | ds_loss: 0.0000 | lr: 4.8608e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    904/  8460 | global iter:    904/  8460 | loss: 0.5147 | ds_loss: 0.0000 | lr: 4.8605e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    904/  8460 | global iter:    904/  8460 | loss: 0.5586 | ds_loss: 0.0000 | lr: 4.8605e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    905/  8460 | global iter:    905/  8460 | loss: 0.2402 | ds_loss: 0.0000 | lr: 4.8602e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    906/  8460 | global iter:    906/  8460 | loss: 0.2403 | ds_loss: 0.0000 | lr: 4.8599e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:    907/  8460 | global iter:    907/  8460 | loss: 0.6749 | ds_loss: 0.0000 | lr: 4.8596e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    908/  8460 | global iter:    908/  8460 | loss: 0.5340 | ds_loss: 0.0000 | lr: 4.8593e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    908/  8460 | global iter:    908/  8460 | loss: 0.4224 | ds_loss: 0.0000 | lr: 4.8593e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    909/  8460 | global iter:    909/  8460 | loss: 0.3049 | ds_loss: 0.0000 | lr: 4.8589e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:    910/  8460 | global iter:    910/  8460 | loss: 0.8239 | ds_loss: 0.0000 | lr: 4.8586e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:    911/  8460 | global iter:    911/  8460 | loss: 0.8696 | ds_loss: 0.0000 | lr: 4.8583e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    912/  8460 | global iter:    912/  8460 | loss: 0.7185 | ds_loss: 0.0000 | lr: 4.8580e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    912/  8460 | global iter:    912/  8460 | loss: 0.6792 | ds_loss: 0.0000 | lr: 4.8580e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    913/  8460 | global iter:    913/  8460 | loss: 0.5146 | ds_loss: 0.0000 | lr: 4.8577e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    914/  8460 | global iter:    914/  8460 | loss: 0.4481 | ds_loss: 0.0000 | lr: 4.8574e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    915/  8460 | global iter:    915/  8460 | loss: 0.3876 | ds_loss: 0.0000 | lr: 4.8571e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    916/  8460 | global iter:    916/  8460 | loss: 1.0517 | ds_loss: 0.0000 | lr: 4.8568e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    916/  8460 | global iter:    916/  8460 | loss: 0.6005 | ds_loss: 0.0000 | lr: 4.8568e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    917/  8460 | global iter:    917/  8460 | loss: 0.2228 | ds_loss: 0.0000 | lr: 4.8565e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    918/  8460 | global iter:    918/  8460 | loss: 0.7224 | ds_loss: 0.0000 | lr: 4.8562e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    919/  8460 | global iter:    919/  8460 | loss: 0.6015 | ds_loss: 0.0000 | lr: 4.8559e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    920/  8460 | global iter:    920/  8460 | loss: 1.1403 | ds_loss: 0.0000 | lr: 4.8555e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    920/  8460 | global iter:    920/  8460 | loss: 0.6718 | ds_loss: 0.0000 | lr: 4.8555e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    921/  8460 | global iter:    921/  8460 | loss: 0.2561 | ds_loss: 0.0000 | lr: 4.8552e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:    922/  8460 | global iter:    922/  8460 | loss: 0.4501 | ds_loss: 0.0000 | lr: 4.8549e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    923/  8460 | global iter:    923/  8460 | loss: 0.3973 | ds_loss: 0.0000 | lr: 4.8546e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    924/  8460 | global iter:    924/  8460 | loss: 0.6024 | ds_loss: 0.0000 | lr: 4.8543e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    924/  8460 | global iter:    924/  8460 | loss: 0.4265 | ds_loss: 0.0000 | lr: 4.8543e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    925/  8460 | global iter:    925/  8460 | loss: 0.5192 | ds_loss: 0.0000 | lr: 4.8540e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    926/  8460 | global iter:    926/  8460 | loss: 0.4153 | ds_loss: 0.0000 | lr: 4.8537e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    927/  8460 | global iter:    927/  8460 | loss: 0.6985 | ds_loss: 0.0000 | lr: 4.8534e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    928/  8460 | global iter:    928/  8460 | loss: 0.6415 | ds_loss: 0.0000 | lr: 4.8530e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    928/  8460 | global iter:    928/  8460 | loss: 0.5686 | ds_loss: 0.0000 | lr: 4.8530e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    929/  8460 | global iter:    929/  8460 | loss: 0.6114 | ds_loss: 0.0000 | lr: 4.8527e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    930/  8460 | global iter:    930/  8460 | loss: 0.7705 | ds_loss: 0.0000 | lr: 4.8524e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    931/  8460 | global iter:    931/  8460 | loss: 0.3813 | ds_loss: 0.0000 | lr: 4.8521e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    932/  8460 | global iter:    932/  8460 | loss: 0.2389 | ds_loss: 0.0000 | lr: 4.8518e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    932/  8460 | global iter:    932/  8460 | loss: 0.5005 | ds_loss: 0.0000 | lr: 4.8518e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    933/  8460 | global iter:    933/  8460 | loss: 0.4148 | ds_loss: 0.0000 | lr: 4.8515e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    934/  8460 | global iter:    934/  8460 | loss: 0.4157 | ds_loss: 0.0000 | lr: 4.8512e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    935/  8460 | global iter:    935/  8460 | loss: 0.8231 | ds_loss: 0.0000 | lr: 4.8508e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    936/  8460 | global iter:    936/  8460 | loss: 0.6538 | ds_loss: 0.0000 | lr: 4.8505e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    936/  8460 | global iter:    936/  8460 | loss: 0.5768 | ds_loss: 0.0000 | lr: 4.8505e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    937/  8460 | global iter:    937/  8460 | loss: 1.2811 | ds_loss: 0.0000 | lr: 4.8502e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    938/  8460 | global iter:    938/  8460 | loss: 1.0277 | ds_loss: 0.0000 | lr: 4.8499e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    939/  8460 | global iter:    939/  8460 | loss: 0.4715 | ds_loss: 0.0000 | lr: 4.8496e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    940/  8460 | global iter:    940/  8460 | loss: 0.4286 | ds_loss: 0.0000 | lr: 4.8493e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    940/  8460 | global iter:    940/  8460 | loss: 0.8022 | ds_loss: 0.0000 | lr: 4.8493e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    941/  8460 | global iter:    941/  8460 | loss: 0.1983 | ds_loss: 0.0000 | lr: 4.8489e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    942/  8460 | global iter:    942/  8460 | loss: 0.5398 | ds_loss: 0.0000 | lr: 4.8486e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    943/  8460 | global iter:    943/  8460 | loss: 0.3653 | ds_loss: 0.0000 | lr: 4.8483e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    944/  8460 | global iter:    944/  8460 | loss: 0.9423 | ds_loss: 0.0000 | lr: 4.8480e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    944/  8460 | global iter:    944/  8460 | loss: 0.5114 | ds_loss: 0.0000 | lr: 4.8480e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    945/  8460 | global iter:    945/  8460 | loss: 1.4229 | ds_loss: 0.0000 | lr: 4.8477e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    946/  8460 | global iter:    946/  8460 | loss: 0.9151 | ds_loss: 0.0000 | lr: 4.8474e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    947/  8460 | global iter:    947/  8460 | loss: 0.5125 | ds_loss: 0.0000 | lr: 4.8470e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    948/  8460 | global iter:    948/  8460 | loss: 0.1404 | ds_loss: 0.0000 | lr: 4.8467e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    948/  8460 | global iter:    948/  8460 | loss: 0.7477 | ds_loss: 0.0000 | lr: 4.8467e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    949/  8460 | global iter:    949/  8460 | loss: 0.5452 | ds_loss: 0.0000 | lr: 4.8464e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    950/  8460 | global iter:    950/  8460 | loss: 0.0931 | ds_loss: 0.0000 | lr: 4.8461e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    951/  8460 | global iter:    951/  8460 | loss: 0.9975 | ds_loss: 0.0000 | lr: 4.8458e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:    952/  8460 | global iter:    952/  8460 | loss: 0.2176 | ds_loss: 0.0000 | lr: 4.8454e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    952/  8460 | global iter:    952/  8460 | loss: 0.4634 | ds_loss: 0.0000 | lr: 4.8454e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    953/  8460 | global iter:    953/  8460 | loss: 0.9385 | ds_loss: 0.0000 | lr: 4.8451e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    954/  8460 | global iter:    954/  8460 | loss: 0.5565 | ds_loss: 0.0000 | lr: 4.8448e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    955/  8460 | global iter:    955/  8460 | loss: 0.4216 | ds_loss: 0.0000 | lr: 4.8445e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:    956/  8460 | global iter:    956/  8460 | loss: 1.8673 | ds_loss: 0.0000 | lr: 4.8441e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    956/  8460 | global iter:    956/  8460 | loss: 0.9460 | ds_loss: 0.0000 | lr: 4.8441e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    957/  8460 | global iter:    957/  8460 | loss: 0.3328 | ds_loss: 0.0000 | lr: 4.8438e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:    958/  8460 | global iter:    958/  8460 | loss: 0.3542 | ds_loss: 0.0000 | lr: 4.8435e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    959/  8460 | global iter:    959/  8460 | loss: 0.2913 | ds_loss: 0.0000 | lr: 4.8432e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    960/  8460 | global iter:    960/  8460 | loss: 0.4970 | ds_loss: 0.0000 | lr: 4.8428e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    960/  8460 | global iter:    960/  8460 | loss: 0.3688 | ds_loss: 0.0000 | lr: 4.8428e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    961/  8460 | global iter:    961/  8460 | loss: 1.2259 | ds_loss: 0.0000 | lr: 4.8425e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    962/  8460 | global iter:    962/  8460 | loss: 0.3697 | ds_loss: 0.0000 | lr: 4.8422e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    963/  8460 | global iter:    963/  8460 | loss: 0.7479 | ds_loss: 0.0000 | lr: 4.8419e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    964/  8460 | global iter:    964/  8460 | loss: 0.9770 | ds_loss: 0.0000 | lr: 4.8415e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    964/  8460 | global iter:    964/  8460 | loss: 0.8301 | ds_loss: 0.0000 | lr: 4.8415e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    965/  8460 | global iter:    965/  8460 | loss: 0.7586 | ds_loss: 0.0000 | lr: 4.8412e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    966/  8460 | global iter:    966/  8460 | loss: 0.6992 | ds_loss: 0.0000 | lr: 4.8409e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    967/  8460 | global iter:    967/  8460 | loss: 1.2446 | ds_loss: 0.0000 | lr: 4.8406e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    968/  8460 | global iter:    968/  8460 | loss: 1.1071 | ds_loss: 0.0000 | lr: 4.8402e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    968/  8460 | global iter:    968/  8460 | loss: 0.9524 | ds_loss: 0.0000 | lr: 4.8402e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    969/  8460 | global iter:    969/  8460 | loss: 0.5233 | ds_loss: 0.0000 | lr: 4.8399e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    970/  8460 | global iter:    970/  8460 | loss: 0.7233 | ds_loss: 0.0000 | lr: 4.8396e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    971/  8460 | global iter:    971/  8460 | loss: 1.3995 | ds_loss: 0.0000 | lr: 4.8393e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    972/  8460 | global iter:    972/  8460 | loss: 0.6678 | ds_loss: 0.0000 | lr: 4.8389e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    972/  8460 | global iter:    972/  8460 | loss: 0.8285 | ds_loss: 0.0000 | lr: 4.8389e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    973/  8460 | global iter:    973/  8460 | loss: 0.7215 | ds_loss: 0.0000 | lr: 4.8386e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    974/  8460 | global iter:    974/  8460 | loss: 1.1057 | ds_loss: 0.0000 | lr: 4.8383e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    975/  8460 | global iter:    975/  8460 | loss: 0.6780 | ds_loss: 0.0000 | lr: 4.8380e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    976/  8460 | global iter:    976/  8460 | loss: 0.8542 | ds_loss: 0.0000 | lr: 4.8376e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    976/  8460 | global iter:    976/  8460 | loss: 0.8398 | ds_loss: 0.0000 | lr: 4.8376e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    977/  8460 | global iter:    977/  8460 | loss: 0.7339 | ds_loss: 0.0000 | lr: 4.8373e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    978/  8460 | global iter:    978/  8460 | loss: 1.3790 | ds_loss: 0.0000 | lr: 4.8370e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    979/  8460 | global iter:    979/  8460 | loss: 1.3227 | ds_loss: 0.0000 | lr: 4.8366e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    980/  8460 | global iter:    980/  8460 | loss: 0.8024 | ds_loss: 0.0000 | lr: 4.8363e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    980/  8460 | global iter:    980/  8460 | loss: 1.0595 | ds_loss: 0.0000 | lr: 4.8363e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    981/  8460 | global iter:    981/  8460 | loss: 0.4132 | ds_loss: 0.0000 | lr: 4.8360e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    982/  8460 | global iter:    982/  8460 | loss: 0.7348 | ds_loss: 0.0000 | lr: 4.8356e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    983/  8460 | global iter:    983/  8460 | loss: 0.4776 | ds_loss: 0.0000 | lr: 4.8353e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    984/  8460 | global iter:    984/  8460 | loss: 1.2753 | ds_loss: 0.0000 | lr: 4.8350e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    984/  8460 | global iter:    984/  8460 | loss: 0.7252 | ds_loss: 0.0000 | lr: 4.8350e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    985/  8460 | global iter:    985/  8460 | loss: 1.1580 | ds_loss: 0.0000 | lr: 4.8346e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    986/  8460 | global iter:    986/  8460 | loss: 0.6017 | ds_loss: 0.0000 | lr: 4.8343e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    987/  8460 | global iter:    987/  8460 | loss: 0.4361 | ds_loss: 0.0000 | lr: 4.8340e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    988/  8460 | global iter:    988/  8460 | loss: 0.8730 | ds_loss: 0.0000 | lr: 4.8337e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    988/  8460 | global iter:    988/  8460 | loss: 0.7672 | ds_loss: 0.0000 | lr: 4.8337e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    989/  8460 | global iter:    989/  8460 | loss: 0.6402 | ds_loss: 0.0000 | lr: 4.8333e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    990/  8460 | global iter:    990/  8460 | loss: 0.8486 | ds_loss: 0.0000 | lr: 4.8330e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    991/  8460 | global iter:    991/  8460 | loss: 0.2208 | ds_loss: 0.0000 | lr: 4.8327e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    992/  8460 | global iter:    992/  8460 | loss: 0.3437 | ds_loss: 0.0000 | lr: 4.8323e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    992/  8460 | global iter:    992/  8460 | loss: 0.5133 | ds_loss: 0.0000 | lr: 4.8323e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    993/  8460 | global iter:    993/  8460 | loss: 0.9027 | ds_loss: 0.0000 | lr: 4.8320e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    994/  8460 | global iter:    994/  8460 | loss: 0.5625 | ds_loss: 0.0000 | lr: 4.8316e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    995/  8460 | global iter:    995/  8460 | loss: 0.6621 | ds_loss: 0.0000 | lr: 4.8313e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:    996/  8460 | global iter:    996/  8460 | loss: 0.2338 | ds_loss: 0.0000 | lr: 4.8310e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:    996/  8460 | global iter:    996/  8460 | loss: 0.5903 | ds_loss: 0.0000 | lr: 4.8310e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:    997/  8460 | global iter:    997/  8460 | loss: 0.8321 | ds_loss: 0.0000 | lr: 4.8306e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    998/  8460 | global iter:    998/  8460 | loss: 0.3728 | ds_loss: 0.0000 | lr: 4.8303e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:    999/  8460 | global iter:    999/  8460 | loss: 0.6065 | ds_loss: 0.0000 | lr: 4.8300e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1000/  8460 | global iter:   1000/  8460 | loss: 0.7088 | ds_loss: 0.0000 | lr: 4.8296e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1000/  8460 | global iter:   1000/  8460 | loss: 0.6300 | ds_loss: 0.0000 | lr: 4.8296e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1001/  8460 | global iter:   1001/  8460 | loss: 0.5382 | ds_loss: 0.0000 | lr: 4.8293e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1002/  8460 | global iter:   1002/  8460 | loss: 0.5200 | ds_loss: 0.0000 | lr: 4.8290e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1003/  8460 | global iter:   1003/  8460 | loss: 0.4446 | ds_loss: 0.0000 | lr: 4.8286e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1004/  8460 | global iter:   1004/  8460 | loss: 0.7070 | ds_loss: 0.0000 | lr: 4.8283e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1004/  8460 | global iter:   1004/  8460 | loss: 0.5524 | ds_loss: 0.0000 | lr: 4.8283e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1005/  8460 | global iter:   1005/  8460 | loss: 0.3308 | ds_loss: 0.0000 | lr: 4.8279e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.000
train | epoch   1 | Iter:   1006/  8460 | global iter:   1006/  8460 | loss: 0.4872 | ds_loss: 0.0000 | lr: 4.8276e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1007/  8460 | global iter:   1007/  8460 | loss: 0.6256 | ds_loss: 0.0000 | lr: 4.8273e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1008/  8460 | global iter:   1008/  8460 | loss: 0.5278 | ds_loss: 0.0000 | lr: 4.8269e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1008/  8460 | global iter:   1008/  8460 | loss: 0.4928 | ds_loss: 0.0000 | lr: 4.8269e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1009/  8460 | global iter:   1009/  8460 | loss: 0.3998 | ds_loss: 0.0000 | lr: 4.8266e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1010/  8460 | global iter:   1010/  8460 | loss: 0.5097 | ds_loss: 0.0000 | lr: 4.8262e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1011/  8460 | global iter:   1011/  8460 | loss: 0.4257 | ds_loss: 0.0000 | lr: 4.8259e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1012/  8460 | global iter:   1012/  8460 | loss: 0.2251 | ds_loss: 0.0000 | lr: 4.8256e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1012/  8460 | global iter:   1012/  8460 | loss: 0.3901 | ds_loss: 0.0000 | lr: 4.8256e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1013/  8460 | global iter:   1013/  8460 | loss: 0.6948 | ds_loss: 0.0000 | lr: 4.8252e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1014/  8460 | global iter:   1014/  8460 | loss: 0.4345 | ds_loss: 0.0000 | lr: 4.8249e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1015/  8460 | global iter:   1015/  8460 | loss: 1.3951 | ds_loss: 0.0000 | lr: 4.8245e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1016/  8460 | global iter:   1016/  8460 | loss: 0.5360 | ds_loss: 0.0000 | lr: 4.8242e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1016/  8460 | global iter:   1016/  8460 | loss: 0.7651 | ds_loss: 0.0000 | lr: 4.8242e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1017/  8460 | global iter:   1017/  8460 | loss: 0.9420 | ds_loss: 0.0000 | lr: 4.8239e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1018/  8460 | global iter:   1018/  8460 | loss: 0.5524 | ds_loss: 0.0000 | lr: 4.8235e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1019/  8460 | global iter:   1019/  8460 | loss: 1.2644 | ds_loss: 0.0000 | lr: 4.8232e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1020/  8460 | global iter:   1020/  8460 | loss: 0.7940 | ds_loss: 0.0000 | lr: 4.8228e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1020/  8460 | global iter:   1020/  8460 | loss: 0.8882 | ds_loss: 0.0000 | lr: 4.8228e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1021/  8460 | global iter:   1021/  8460 | loss: 0.7602 | ds_loss: 0.0000 | lr: 4.8225e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1022/  8460 | global iter:   1022/  8460 | loss: 1.1376 | ds_loss: 0.0000 | lr: 4.8221e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1023/  8460 | global iter:   1023/  8460 | loss: 0.6091 | ds_loss: 0.0000 | lr: 4.8218e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1024/  8460 | global iter:   1024/  8460 | loss: 0.9830 | ds_loss: 0.0000 | lr: 4.8215e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1024/  8460 | global iter:   1024/  8460 | loss: 0.8725 | ds_loss: 0.0000 | lr: 4.8215e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1025/  8460 | global iter:   1025/  8460 | loss: 0.4557 | ds_loss: 0.0000 | lr: 4.8211e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1026/  8460 | global iter:   1026/  8460 | loss: 0.3258 | ds_loss: 0.0000 | lr: 4.8208e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1027/  8460 | global iter:   1027/  8460 | loss: 0.5632 | ds_loss: 0.0000 | lr: 4.8204e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1028/  8460 | global iter:   1028/  8460 | loss: 0.5114 | ds_loss: 0.0000 | lr: 4.8201e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1028/  8460 | global iter:   1028/  8460 | loss: 0.4640 | ds_loss: 0.0000 | lr: 4.8201e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1029/  8460 | global iter:   1029/  8460 | loss: 0.7184 | ds_loss: 0.0000 | lr: 4.8197e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1030/  8460 | global iter:   1030/  8460 | loss: 1.0384 | ds_loss: 0.0000 | lr: 4.8194e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1031/  8460 | global iter:   1031/  8460 | loss: 1.0936 | ds_loss: 0.0000 | lr: 4.8190e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1032/  8460 | global iter:   1032/  8460 | loss: 0.6430 | ds_loss: 0.0000 | lr: 4.8187e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1032/  8460 | global iter:   1032/  8460 | loss: 0.8733 | ds_loss: 0.0000 | lr: 4.8187e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1033/  8460 | global iter:   1033/  8460 | loss: 0.1806 | ds_loss: 0.0000 | lr: 4.8183e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1034/  8460 | global iter:   1034/  8460 | loss: 0.5825 | ds_loss: 0.0000 | lr: 4.8180e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1035/  8460 | global iter:   1035/  8460 | loss: 0.8320 | ds_loss: 0.0000 | lr: 4.8176e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1036/  8460 | global iter:   1036/  8460 | loss: 0.6120 | ds_loss: 0.0000 | lr: 4.8173e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1036/  8460 | global iter:   1036/  8460 | loss: 0.5518 | ds_loss: 0.0000 | lr: 4.8173e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1037/  8460 | global iter:   1037/  8460 | loss: 0.8742 | ds_loss: 0.0000 | lr: 4.8170e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1038/  8460 | global iter:   1038/  8460 | loss: 0.5109 | ds_loss: 0.0000 | lr: 4.8166e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1039/  8460 | global iter:   1039/  8460 | loss: 0.3698 | ds_loss: 0.0000 | lr: 4.8163e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1040/  8460 | global iter:   1040/  8460 | loss: 0.2177 | ds_loss: 0.0000 | lr: 4.8159e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1040/  8460 | global iter:   1040/  8460 | loss: 0.4931 | ds_loss: 0.0000 | lr: 4.8159e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1041/  8460 | global iter:   1041/  8460 | loss: 0.7816 | ds_loss: 0.0000 | lr: 4.8156e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1042/  8460 | global iter:   1042/  8460 | loss: 0.2889 | ds_loss: 0.0000 | lr: 4.8152e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1043/  8460 | global iter:   1043/  8460 | loss: 0.4976 | ds_loss: 0.0000 | lr: 4.8149e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1044/  8460 | global iter:   1044/  8460 | loss: 0.5841 | ds_loss: 0.0000 | lr: 4.8145e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1044/  8460 | global iter:   1044/  8460 | loss: 0.5381 | ds_loss: 0.0000 | lr: 4.8145e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1045/  8460 | global iter:   1045/  8460 | loss: 0.3212 | ds_loss: 0.0000 | lr: 4.8142e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1046/  8460 | global iter:   1046/  8460 | loss: 0.6433 | ds_loss: 0.0000 | lr: 4.8138e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1047/  8460 | global iter:   1047/  8460 | loss: 1.0217 | ds_loss: 0.0000 | lr: 4.8134e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1048/  8460 | global iter:   1048/  8460 | loss: 0.3432 | ds_loss: 0.0000 | lr: 4.8131e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1048/  8460 | global iter:   1048/  8460 | loss: 0.5824 | ds_loss: 0.0000 | lr: 4.8131e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1049/  8460 | global iter:   1049/  8460 | loss: 0.6039 | ds_loss: 0.0000 | lr: 4.8127e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1050/  8460 | global iter:   1050/  8460 | loss: 0.6534 | ds_loss: 0.0000 | lr: 4.8124e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1051/  8460 | global iter:   1051/  8460 | loss: 1.1239 | ds_loss: 0.0000 | lr: 4.8120e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1052/  8460 | global iter:   1052/  8460 | loss: 0.6652 | ds_loss: 0.0000 | lr: 4.8117e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1052/  8460 | global iter:   1052/  8460 | loss: 0.7616 | ds_loss: 0.0000 | lr: 4.8117e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1053/  8460 | global iter:   1053/  8460 | loss: 0.4154 | ds_loss: 0.0000 | lr: 4.8113e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1054/  8460 | global iter:   1054/  8460 | loss: 1.0141 | ds_loss: 0.0000 | lr: 4.8110e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1055/  8460 | global iter:   1055/  8460 | loss: 0.3381 | ds_loss: 0.0000 | lr: 4.8106e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1056/  8460 | global iter:   1056/  8460 | loss: 0.4997 | ds_loss: 0.0000 | lr: 4.8103e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1056/  8460 | global iter:   1056/  8460 | loss: 0.5668 | ds_loss: 0.0000 | lr: 4.8103e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1057/  8460 | global iter:   1057/  8460 | loss: 0.9974 | ds_loss: 0.0000 | lr: 4.8099e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1058/  8460 | global iter:   1058/  8460 | loss: 0.7408 | ds_loss: 0.0000 | lr: 4.8096e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1059/  8460 | global iter:   1059/  8460 | loss: 0.4017 | ds_loss: 0.0000 | lr: 4.8092e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1060/  8460 | global iter:   1060/  8460 | loss: 0.3556 | ds_loss: 0.0000 | lr: 4.8088e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1060/  8460 | global iter:   1060/  8460 | loss: 0.6239 | ds_loss: 0.0000 | lr: 4.8088e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1061/  8460 | global iter:   1061/  8460 | loss: 0.8446 | ds_loss: 0.0000 | lr: 4.8085e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1062/  8460 | global iter:   1062/  8460 | loss: 0.7587 | ds_loss: 0.0000 | lr: 4.8081e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1063/  8460 | global iter:   1063/  8460 | loss: 1.0429 | ds_loss: 0.0000 | lr: 4.8078e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1064/  8460 | global iter:   1064/  8460 | loss: 0.5419 | ds_loss: 0.0000 | lr: 4.8074e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1064/  8460 | global iter:   1064/  8460 | loss: 0.7970 | ds_loss: 0.0000 | lr: 4.8074e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1065/  8460 | global iter:   1065/  8460 | loss: 0.7108 | ds_loss: 0.0000 | lr: 4.8071e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1066/  8460 | global iter:   1066/  8460 | loss: 0.9713 | ds_loss: 0.0000 | lr: 4.8067e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1067/  8460 | global iter:   1067/  8460 | loss: 0.7121 | ds_loss: 0.0000 | lr: 4.8063e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1068/  8460 | global iter:   1068/  8460 | loss: 0.4328 | ds_loss: 0.0000 | lr: 4.8060e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1068/  8460 | global iter:   1068/  8460 | loss: 0.7068 | ds_loss: 0.0000 | lr: 4.8060e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1069/  8460 | global iter:   1069/  8460 | loss: 0.4484 | ds_loss: 0.0000 | lr: 4.8056e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1070/  8460 | global iter:   1070/  8460 | loss: 1.5651 | ds_loss: 0.0000 | lr: 4.8053e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1071/  8460 | global iter:   1071/  8460 | loss: 0.3061 | ds_loss: 0.0000 | lr: 4.8049e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1072/  8460 | global iter:   1072/  8460 | loss: 1.1190 | ds_loss: 0.0000 | lr: 4.8046e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1072/  8460 | global iter:   1072/  8460 | loss: 0.8597 | ds_loss: 0.0000 | lr: 4.8046e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1073/  8460 | global iter:   1073/  8460 | loss: 0.9384 | ds_loss: 0.0000 | lr: 4.8042e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1074/  8460 | global iter:   1074/  8460 | loss: 0.5018 | ds_loss: 0.0000 | lr: 4.8038e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1075/  8460 | global iter:   1075/  8460 | loss: 1.3656 | ds_loss: 0.0000 | lr: 4.8035e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1076/  8460 | global iter:   1076/  8460 | loss: 0.3808 | ds_loss: 0.0000 | lr: 4.8031e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1076/  8460 | global iter:   1076/  8460 | loss: 0.7966 | ds_loss: 0.0000 | lr: 4.8031e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1077/  8460 | global iter:   1077/  8460 | loss: 0.6734 | ds_loss: 0.0000 | lr: 4.8028e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1078/  8460 | global iter:   1078/  8460 | loss: 0.7381 | ds_loss: 0.0000 | lr: 4.8024e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1079/  8460 | global iter:   1079/  8460 | loss: 0.7041 | ds_loss: 0.0000 | lr: 4.8020e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1080/  8460 | global iter:   1080/  8460 | loss: 0.3116 | ds_loss: 0.0000 | lr: 4.8017e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1080/  8460 | global iter:   1080/  8460 | loss: 0.6068 | ds_loss: 0.0000 | lr: 4.8017e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1081/  8460 | global iter:   1081/  8460 | loss: 0.3889 | ds_loss: 0.0000 | lr: 4.8013e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1082/  8460 | global iter:   1082/  8460 | loss: 0.9570 | ds_loss: 0.0000 | lr: 4.8009e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1083/  8460 | global iter:   1083/  8460 | loss: 1.0102 | ds_loss: 0.0000 | lr: 4.8006e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1084/  8460 | global iter:   1084/  8460 | loss: 0.4514 | ds_loss: 0.0000 | lr: 4.8002e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1084/  8460 | global iter:   1084/  8460 | loss: 0.7019 | ds_loss: 0.0000 | lr: 4.8002e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1085/  8460 | global iter:   1085/  8460 | loss: 0.5025 | ds_loss: 0.0000 | lr: 4.7998e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1086/  8460 | global iter:   1086/  8460 | loss: 0.5637 | ds_loss: 0.0000 | lr: 4.7995e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1087/  8460 | global iter:   1087/  8460 | loss: 0.3977 | ds_loss: 0.0000 | lr: 4.7991e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1088/  8460 | global iter:   1088/  8460 | loss: 0.2759 | ds_loss: 0.0000 | lr: 4.7988e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1088/  8460 | global iter:   1088/  8460 | loss: 0.4349 | ds_loss: 0.0000 | lr: 4.7988e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1089/  8460 | global iter:   1089/  8460 | loss: 0.2882 | ds_loss: 0.0000 | lr: 4.7984e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1090/  8460 | global iter:   1090/  8460 | loss: 0.4449 | ds_loss: 0.0000 | lr: 4.7980e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1091/  8460 | global iter:   1091/  8460 | loss: 0.9351 | ds_loss: 0.0000 | lr: 4.7977e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1092/  8460 | global iter:   1092/  8460 | loss: 0.6033 | ds_loss: 0.0000 | lr: 4.7973e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1092/  8460 | global iter:   1092/  8460 | loss: 0.5679 | ds_loss: 0.0000 | lr: 4.7973e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1093/  8460 | global iter:   1093/  8460 | loss: 0.4846 | ds_loss: 0.0000 | lr: 4.7969e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1094/  8460 | global iter:   1094/  8460 | loss: 0.6066 | ds_loss: 0.0000 | lr: 4.7966e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1095/  8460 | global iter:   1095/  8460 | loss: 0.9146 | ds_loss: 0.0000 | lr: 4.7962e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1096/  8460 | global iter:   1096/  8460 | loss: 0.4164 | ds_loss: 0.0000 | lr: 4.7958e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1096/  8460 | global iter:   1096/  8460 | loss: 0.6055 | ds_loss: 0.0000 | lr: 4.7958e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1097/  8460 | global iter:   1097/  8460 | loss: 0.8006 | ds_loss: 0.0000 | lr: 4.7955e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1098/  8460 | global iter:   1098/  8460 | loss: 0.6725 | ds_loss: 0.0000 | lr: 4.7951e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1099/  8460 | global iter:   1099/  8460 | loss: 0.5585 | ds_loss: 0.0000 | lr: 4.7947e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1100/  8460 | global iter:   1100/  8460 | loss: 0.6798 | ds_loss: 0.0000 | lr: 4.7944e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1100/  8460 | global iter:   1100/  8460 | loss: 0.6779 | ds_loss: 0.0000 | lr: 4.7944e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1101/  8460 | global iter:   1101/  8460 | loss: 0.8282 | ds_loss: 0.0000 | lr: 4.7940e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1102/  8460 | global iter:   1102/  8460 | loss: 0.4272 | ds_loss: 0.0000 | lr: 4.7936e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1103/  8460 | global iter:   1103/  8460 | loss: 0.5226 | ds_loss: 0.0000 | lr: 4.7932e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1104/  8460 | global iter:   1104/  8460 | loss: 0.6219 | ds_loss: 0.0000 | lr: 4.7929e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1104/  8460 | global iter:   1104/  8460 | loss: 0.6000 | ds_loss: 0.0000 | lr: 4.7929e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1105/  8460 | global iter:   1105/  8460 | loss: 1.1533 | ds_loss: 0.0000 | lr: 4.7925e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1106/  8460 | global iter:   1106/  8460 | loss: 0.4882 | ds_loss: 0.0000 | lr: 4.7921e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1107/  8460 | global iter:   1107/  8460 | loss: 0.7130 | ds_loss: 0.0000 | lr: 4.7918e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1108/  8460 | global iter:   1108/  8460 | loss: 0.7869 | ds_loss: 0.0000 | lr: 4.7914e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1108/  8460 | global iter:   1108/  8460 | loss: 0.7854 | ds_loss: 0.0000 | lr: 4.7914e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1109/  8460 | global iter:   1109/  8460 | loss: 1.0340 | ds_loss: 0.0000 | lr: 4.7910e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1110/  8460 | global iter:   1110/  8460 | loss: 0.6685 | ds_loss: 0.0000 | lr: 4.7907e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1111/  8460 | global iter:   1111/  8460 | loss: 0.7851 | ds_loss: 0.0000 | lr: 4.7903e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1112/  8460 | global iter:   1112/  8460 | loss: 0.5093 | ds_loss: 0.0000 | lr: 4.7899e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1112/  8460 | global iter:   1112/  8460 | loss: 0.7492 | ds_loss: 0.0000 | lr: 4.7899e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1113/  8460 | global iter:   1113/  8460 | loss: 0.2266 | ds_loss: 0.0000 | lr: 4.7895e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1114/  8460 | global iter:   1114/  8460 | loss: 0.1598 | ds_loss: 0.0000 | lr: 4.7892e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1115/  8460 | global iter:   1115/  8460 | loss: 0.3663 | ds_loss: 0.0000 | lr: 4.7888e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1116/  8460 | global iter:   1116/  8460 | loss: 0.5168 | ds_loss: 0.0000 | lr: 4.7884e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1116/  8460 | global iter:   1116/  8460 | loss: 0.3174 | ds_loss: 0.0000 | lr: 4.7884e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1117/  8460 | global iter:   1117/  8460 | loss: 0.5053 | ds_loss: 0.0000 | lr: 4.7880e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1118/  8460 | global iter:   1118/  8460 | loss: 0.9852 | ds_loss: 0.0000 | lr: 4.7877e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1119/  8460 | global iter:   1119/  8460 | loss: 0.5062 | ds_loss: 0.0000 | lr: 4.7873e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1120/  8460 | global iter:   1120/  8460 | loss: 0.3810 | ds_loss: 0.0000 | lr: 4.7869e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1120/  8460 | global iter:   1120/  8460 | loss: 0.5944 | ds_loss: 0.0000 | lr: 4.7869e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1121/  8460 | global iter:   1121/  8460 | loss: 0.1655 | ds_loss: 0.0000 | lr: 4.7865e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1122/  8460 | global iter:   1122/  8460 | loss: 0.4580 | ds_loss: 0.0000 | lr: 4.7862e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1123/  8460 | global iter:   1123/  8460 | loss: 0.6944 | ds_loss: 0.0000 | lr: 4.7858e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1124/  8460 | global iter:   1124/  8460 | loss: 1.2272 | ds_loss: 0.0000 | lr: 4.7854e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1124/  8460 | global iter:   1124/  8460 | loss: 0.6363 | ds_loss: 0.0000 | lr: 4.7854e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1125/  8460 | global iter:   1125/  8460 | loss: 0.5928 | ds_loss: 0.0000 | lr: 4.7850e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1126/  8460 | global iter:   1126/  8460 | loss: 0.2801 | ds_loss: 0.0000 | lr: 4.7847e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1127/  8460 | global iter:   1127/  8460 | loss: 0.5395 | ds_loss: 0.0000 | lr: 4.7843e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1128/  8460 | global iter:   1128/  8460 | loss: 0.5869 | ds_loss: 0.0000 | lr: 4.7839e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1128/  8460 | global iter:   1128/  8460 | loss: 0.4998 | ds_loss: 0.0000 | lr: 4.7839e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1129/  8460 | global iter:   1129/  8460 | loss: 0.2689 | ds_loss: 0.0000 | lr: 4.7835e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1130/  8460 | global iter:   1130/  8460 | loss: 0.8787 | ds_loss: 0.0000 | lr: 4.7832e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1131/  8460 | global iter:   1131/  8460 | loss: 1.4346 | ds_loss: 0.0000 | lr: 4.7828e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1132/  8460 | global iter:   1132/  8460 | loss: 0.5936 | ds_loss: 0.0000 | lr: 4.7824e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1132/  8460 | global iter:   1132/  8460 | loss: 0.7940 | ds_loss: 0.0000 | lr: 4.7824e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1133/  8460 | global iter:   1133/  8460 | loss: 0.7052 | ds_loss: 0.0000 | lr: 4.7820e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1134/  8460 | global iter:   1134/  8460 | loss: 0.9947 | ds_loss: 0.0000 | lr: 4.7816e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1135/  8460 | global iter:   1135/  8460 | loss: 0.7359 | ds_loss: 0.0000 | lr: 4.7813e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1136/  8460 | global iter:   1136/  8460 | loss: 0.4836 | ds_loss: 0.0000 | lr: 4.7809e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1136/  8460 | global iter:   1136/  8460 | loss: 0.7299 | ds_loss: 0.0000 | lr: 4.7809e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1137/  8460 | global iter:   1137/  8460 | loss: 0.4040 | ds_loss: 0.0000 | lr: 4.7805e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1138/  8460 | global iter:   1138/  8460 | loss: 0.5944 | ds_loss: 0.0000 | lr: 4.7801e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1139/  8460 | global iter:   1139/  8460 | loss: 0.8042 | ds_loss: 0.0000 | lr: 4.7797e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1140/  8460 | global iter:   1140/  8460 | loss: 0.2793 | ds_loss: 0.0000 | lr: 4.7794e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1140/  8460 | global iter:   1140/  8460 | loss: 0.5205 | ds_loss: 0.0000 | lr: 4.7794e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1141/  8460 | global iter:   1141/  8460 | loss: 0.6933 | ds_loss: 0.0000 | lr: 4.7790e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1142/  8460 | global iter:   1142/  8460 | loss: 0.3277 | ds_loss: 0.0000 | lr: 4.7786e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1143/  8460 | global iter:   1143/  8460 | loss: 0.3916 | ds_loss: 0.0000 | lr: 4.7782e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1144/  8460 | global iter:   1144/  8460 | loss: 0.2999 | ds_loss: 0.0000 | lr: 4.7778e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1144/  8460 | global iter:   1144/  8460 | loss: 0.4281 | ds_loss: 0.0000 | lr: 4.7778e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1145/  8460 | global iter:   1145/  8460 | loss: 0.6071 | ds_loss: 0.0000 | lr: 4.7774e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1146/  8460 | global iter:   1146/  8460 | loss: 0.7197 | ds_loss: 0.0000 | lr: 4.7771e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1147/  8460 | global iter:   1147/  8460 | loss: 0.3417 | ds_loss: 0.0000 | lr: 4.7767e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1148/  8460 | global iter:   1148/  8460 | loss: 0.7650 | ds_loss: 0.0000 | lr: 4.7763e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1148/  8460 | global iter:   1148/  8460 | loss: 0.6084 | ds_loss: 0.0000 | lr: 4.7763e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1149/  8460 | global iter:   1149/  8460 | loss: 1.3639 | ds_loss: 0.0000 | lr: 4.7759e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1150/  8460 | global iter:   1150/  8460 | loss: 0.4955 | ds_loss: 0.0000 | lr: 4.7755e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1151/  8460 | global iter:   1151/  8460 | loss: 0.7893 | ds_loss: 0.0000 | lr: 4.7751e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1152/  8460 | global iter:   1152/  8460 | loss: 0.9151 | ds_loss: 0.0000 | lr: 4.7748e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1152/  8460 | global iter:   1152/  8460 | loss: 0.8910 | ds_loss: 0.0000 | lr: 4.7748e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1153/  8460 | global iter:   1153/  8460 | loss: 0.1357 | ds_loss: 0.0000 | lr: 4.7744e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1154/  8460 | global iter:   1154/  8460 | loss: 1.1362 | ds_loss: 0.0000 | lr: 4.7740e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1155/  8460 | global iter:   1155/  8460 | loss: 0.7243 | ds_loss: 0.0000 | lr: 4.7736e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1156/  8460 | global iter:   1156/  8460 | loss: 0.5683 | ds_loss: 0.0000 | lr: 4.7732e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1156/  8460 | global iter:   1156/  8460 | loss: 0.6411 | ds_loss: 0.0000 | lr: 4.7732e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1157/  8460 | global iter:   1157/  8460 | loss: 0.4491 | ds_loss: 0.0000 | lr: 4.7728e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1158/  8460 | global iter:   1158/  8460 | loss: 0.2249 | ds_loss: 0.0000 | lr: 4.7724e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1159/  8460 | global iter:   1159/  8460 | loss: 0.4321 | ds_loss: 0.0000 | lr: 4.7721e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1160/  8460 | global iter:   1160/  8460 | loss: 0.8576 | ds_loss: 0.0000 | lr: 4.7717e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1160/  8460 | global iter:   1160/  8460 | loss: 0.4909 | ds_loss: 0.0000 | lr: 4.7717e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1161/  8460 | global iter:   1161/  8460 | loss: 1.2055 | ds_loss: 0.0000 | lr: 4.7713e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1162/  8460 | global iter:   1162/  8460 | loss: 0.4822 | ds_loss: 0.0000 | lr: 4.7709e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1163/  8460 | global iter:   1163/  8460 | loss: 0.3975 | ds_loss: 0.0000 | lr: 4.7705e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1164/  8460 | global iter:   1164/  8460 | loss: 0.5347 | ds_loss: 0.0000 | lr: 4.7701e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1164/  8460 | global iter:   1164/  8460 | loss: 0.6550 | ds_loss: 0.0000 | lr: 4.7701e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1165/  8460 | global iter:   1165/  8460 | loss: 0.6462 | ds_loss: 0.0000 | lr: 4.7697e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1166/  8460 | global iter:   1166/  8460 | loss: 0.4806 | ds_loss: 0.0000 | lr: 4.7693e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1167/  8460 | global iter:   1167/  8460 | loss: 1.1186 | ds_loss: 0.0000 | lr: 4.7689e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1168/  8460 | global iter:   1168/  8460 | loss: 0.7806 | ds_loss: 0.0000 | lr: 4.7686e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1168/  8460 | global iter:   1168/  8460 | loss: 0.7565 | ds_loss: 0.0000 | lr: 4.7686e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1169/  8460 | global iter:   1169/  8460 | loss: 0.4867 | ds_loss: 0.0000 | lr: 4.7682e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1170/  8460 | global iter:   1170/  8460 | loss: 0.3582 | ds_loss: 0.0000 | lr: 4.7678e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1171/  8460 | global iter:   1171/  8460 | loss: 0.8876 | ds_loss: 0.0000 | lr: 4.7674e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1172/  8460 | global iter:   1172/  8460 | loss: 0.7921 | ds_loss: 0.0000 | lr: 4.7670e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1172/  8460 | global iter:   1172/  8460 | loss: 0.6312 | ds_loss: 0.0000 | lr: 4.7670e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1173/  8460 | global iter:   1173/  8460 | loss: 0.4361 | ds_loss: 0.0000 | lr: 4.7666e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1174/  8460 | global iter:   1174/  8460 | loss: 0.6682 | ds_loss: 0.0000 | lr: 4.7662e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1175/  8460 | global iter:   1175/  8460 | loss: 1.1982 | ds_loss: 0.0000 | lr: 4.7658e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1176/  8460 | global iter:   1176/  8460 | loss: 0.3184 | ds_loss: 0.0000 | lr: 4.7654e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1176/  8460 | global iter:   1176/  8460 | loss: 0.6552 | ds_loss: 0.0000 | lr: 4.7654e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1177/  8460 | global iter:   1177/  8460 | loss: 0.4563 | ds_loss: 0.0000 | lr: 4.7650e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1178/  8460 | global iter:   1178/  8460 | loss: 0.5072 | ds_loss: 0.0000 | lr: 4.7646e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1179/  8460 | global iter:   1179/  8460 | loss: 1.1177 | ds_loss: 0.0000 | lr: 4.7642e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1180/  8460 | global iter:   1180/  8460 | loss: 0.9038 | ds_loss: 0.0000 | lr: 4.7639e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1180/  8460 | global iter:   1180/  8460 | loss: 0.7463 | ds_loss: 0.0000 | lr: 4.7639e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1181/  8460 | global iter:   1181/  8460 | loss: 0.2209 | ds_loss: 0.0000 | lr: 4.7635e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1182/  8460 | global iter:   1182/  8460 | loss: 0.3898 | ds_loss: 0.0000 | lr: 4.7631e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1183/  8460 | global iter:   1183/  8460 | loss: 0.8505 | ds_loss: 0.0000 | lr: 4.7627e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1184/  8460 | global iter:   1184/  8460 | loss: 0.5258 | ds_loss: 0.0000 | lr: 4.7623e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1184/  8460 | global iter:   1184/  8460 | loss: 0.4968 | ds_loss: 0.0000 | lr: 4.7623e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1185/  8460 | global iter:   1185/  8460 | loss: 0.5068 | ds_loss: 0.0000 | lr: 4.7619e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1186/  8460 | global iter:   1186/  8460 | loss: 1.3084 | ds_loss: 0.0000 | lr: 4.7615e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1187/  8460 | global iter:   1187/  8460 | loss: 1.0269 | ds_loss: 0.0000 | lr: 4.7611e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1188/  8460 | global iter:   1188/  8460 | loss: 1.0888 | ds_loss: 0.0000 | lr: 4.7607e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1188/  8460 | global iter:   1188/  8460 | loss: 0.9827 | ds_loss: 0.0000 | lr: 4.7607e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1189/  8460 | global iter:   1189/  8460 | loss: 0.2351 | ds_loss: 0.0000 | lr: 4.7603e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1190/  8460 | global iter:   1190/  8460 | loss: 0.6542 | ds_loss: 0.0000 | lr: 4.7599e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1191/  8460 | global iter:   1191/  8460 | loss: 0.5680 | ds_loss: 0.0000 | lr: 4.7595e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1192/  8460 | global iter:   1192/  8460 | loss: 1.0639 | ds_loss: 0.0000 | lr: 4.7591e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1192/  8460 | global iter:   1192/  8460 | loss: 0.6303 | ds_loss: 0.0000 | lr: 4.7591e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1193/  8460 | global iter:   1193/  8460 | loss: 0.7238 | ds_loss: 0.0000 | lr: 4.7587e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1194/  8460 | global iter:   1194/  8460 | loss: 0.3686 | ds_loss: 0.0000 | lr: 4.7583e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1195/  8460 | global iter:   1195/  8460 | loss: 0.8161 | ds_loss: 0.0000 | lr: 4.7579e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1196/  8460 | global iter:   1196/  8460 | loss: 0.4274 | ds_loss: 0.0000 | lr: 4.7575e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1196/  8460 | global iter:   1196/  8460 | loss: 0.5840 | ds_loss: 0.0000 | lr: 4.7575e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1197/  8460 | global iter:   1197/  8460 | loss: 0.2661 | ds_loss: 0.0000 | lr: 4.7571e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1198/  8460 | global iter:   1198/  8460 | loss: 0.4898 | ds_loss: 0.0000 | lr: 4.7567e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1199/  8460 | global iter:   1199/  8460 | loss: 0.2944 | ds_loss: 0.0000 | lr: 4.7563e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1200/  8460 | global iter:   1200/  8460 | loss: 1.5446 | ds_loss: 0.0000 | lr: 4.7559e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1200/  8460 | global iter:   1200/  8460 | loss: 0.6487 | ds_loss: 0.0000 | lr: 4.7559e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1201/  8460 | global iter:   1201/  8460 | loss: 0.6403 | ds_loss: 0.0000 | lr: 4.7555e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1202/  8460 | global iter:   1202/  8460 | loss: 0.9127 | ds_loss: 0.0000 | lr: 4.7551e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1203/  8460 | global iter:   1203/  8460 | loss: 0.1775 | ds_loss: 0.0000 | lr: 4.7547e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1204/  8460 | global iter:   1204/  8460 | loss: 0.8223 | ds_loss: 0.0000 | lr: 4.7543e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1204/  8460 | global iter:   1204/  8460 | loss: 0.6382 | ds_loss: 0.0000 | lr: 4.7543e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1205/  8460 | global iter:   1205/  8460 | loss: 0.4868 | ds_loss: 0.0000 | lr: 4.7539e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1206/  8460 | global iter:   1206/  8460 | loss: 0.3445 | ds_loss: 0.0000 | lr: 4.7535e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1207/  8460 | global iter:   1207/  8460 | loss: 0.9689 | ds_loss: 0.0000 | lr: 4.7531e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1208/  8460 | global iter:   1208/  8460 | loss: 0.6642 | ds_loss: 0.0000 | lr: 4.7527e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1208/  8460 | global iter:   1208/  8460 | loss: 0.6161 | ds_loss: 0.0000 | lr: 4.7527e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1209/  8460 | global iter:   1209/  8460 | loss: 0.2073 | ds_loss: 0.0000 | lr: 4.7523e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1210/  8460 | global iter:   1210/  8460 | loss: 0.6854 | ds_loss: 0.0000 | lr: 4.7519e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1211/  8460 | global iter:   1211/  8460 | loss: 0.5004 | ds_loss: 0.0000 | lr: 4.7515e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1212/  8460 | global iter:   1212/  8460 | loss: 0.7246 | ds_loss: 0.0000 | lr: 4.7511e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1212/  8460 | global iter:   1212/  8460 | loss: 0.5294 | ds_loss: 0.0000 | lr: 4.7511e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1213/  8460 | global iter:   1213/  8460 | loss: 1.1013 | ds_loss: 0.0000 | lr: 4.7507e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1214/  8460 | global iter:   1214/  8460 | loss: 0.7858 | ds_loss: 0.0000 | lr: 4.7503e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1215/  8460 | global iter:   1215/  8460 | loss: 1.0616 | ds_loss: 0.0000 | lr: 4.7499e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1216/  8460 | global iter:   1216/  8460 | loss: 1.1788 | ds_loss: 0.0000 | lr: 4.7495e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1216/  8460 | global iter:   1216/  8460 | loss: 1.0319 | ds_loss: 0.0000 | lr: 4.7495e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1217/  8460 | global iter:   1217/  8460 | loss: 0.5610 | ds_loss: 0.0000 | lr: 4.7491e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1218/  8460 | global iter:   1218/  8460 | loss: 1.2035 | ds_loss: 0.0000 | lr: 4.7487e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1219/  8460 | global iter:   1219/  8460 | loss: 0.8648 | ds_loss: 0.0000 | lr: 4.7483e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1220/  8460 | global iter:   1220/  8460 | loss: 1.0364 | ds_loss: 0.0000 | lr: 4.7478e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1220/  8460 | global iter:   1220/  8460 | loss: 0.9164 | ds_loss: 0.0000 | lr: 4.7478e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1221/  8460 | global iter:   1221/  8460 | loss: 0.5796 | ds_loss: 0.0000 | lr: 4.7474e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1222/  8460 | global iter:   1222/  8460 | loss: 0.8865 | ds_loss: 0.0000 | lr: 4.7470e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1223/  8460 | global iter:   1223/  8460 | loss: 1.0600 | ds_loss: 0.0000 | lr: 4.7466e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1224/  8460 | global iter:   1224/  8460 | loss: 1.3874 | ds_loss: 0.0000 | lr: 4.7462e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1224/  8460 | global iter:   1224/  8460 | loss: 0.9784 | ds_loss: 0.0000 | lr: 4.7462e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1225/  8460 | global iter:   1225/  8460 | loss: 0.8838 | ds_loss: 0.0000 | lr: 4.7458e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1226/  8460 | global iter:   1226/  8460 | loss: 0.3080 | ds_loss: 0.0000 | lr: 4.7454e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1227/  8460 | global iter:   1227/  8460 | loss: 0.8631 | ds_loss: 0.0000 | lr: 4.7450e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1228/  8460 | global iter:   1228/  8460 | loss: 0.6187 | ds_loss: 0.0000 | lr: 4.7446e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1228/  8460 | global iter:   1228/  8460 | loss: 0.6684 | ds_loss: 0.0000 | lr: 4.7446e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1229/  8460 | global iter:   1229/  8460 | loss: 0.8872 | ds_loss: 0.0000 | lr: 4.7442e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1230/  8460 | global iter:   1230/  8460 | loss: 0.8736 | ds_loss: 0.0000 | lr: 4.7438e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1231/  8460 | global iter:   1231/  8460 | loss: 0.5856 | ds_loss: 0.0000 | lr: 4.7434e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1232/  8460 | global iter:   1232/  8460 | loss: 0.6159 | ds_loss: 0.0000 | lr: 4.7430e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1232/  8460 | global iter:   1232/  8460 | loss: 0.7406 | ds_loss: 0.0000 | lr: 4.7430e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1233/  8460 | global iter:   1233/  8460 | loss: 0.6371 | ds_loss: 0.0000 | lr: 4.7425e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1234/  8460 | global iter:   1234/  8460 | loss: 0.2719 | ds_loss: 0.0000 | lr: 4.7421e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1235/  8460 | global iter:   1235/  8460 | loss: 0.1829 | ds_loss: 0.0000 | lr: 4.7417e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1236/  8460 | global iter:   1236/  8460 | loss: 0.3403 | ds_loss: 0.0000 | lr: 4.7413e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1236/  8460 | global iter:   1236/  8460 | loss: 0.3580 | ds_loss: 0.0000 | lr: 4.7413e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1237/  8460 | global iter:   1237/  8460 | loss: 0.7271 | ds_loss: 0.0000 | lr: 4.7409e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1238/  8460 | global iter:   1238/  8460 | loss: 0.3468 | ds_loss: 0.0000 | lr: 4.7405e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1239/  8460 | global iter:   1239/  8460 | loss: 0.8963 | ds_loss: 0.0000 | lr: 4.7401e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1240/  8460 | global iter:   1240/  8460 | loss: 0.5560 | ds_loss: 0.0000 | lr: 4.7397e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1240/  8460 | global iter:   1240/  8460 | loss: 0.6316 | ds_loss: 0.0000 | lr: 4.7397e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1241/  8460 | global iter:   1241/  8460 | loss: 0.3388 | ds_loss: 0.0000 | lr: 4.7392e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1242/  8460 | global iter:   1242/  8460 | loss: 0.1666 | ds_loss: 0.0000 | lr: 4.7388e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1243/  8460 | global iter:   1243/  8460 | loss: 0.3219 | ds_loss: 0.0000 | lr: 4.7384e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1244/  8460 | global iter:   1244/  8460 | loss: 0.1229 | ds_loss: 0.0000 | lr: 4.7380e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1244/  8460 | global iter:   1244/  8460 | loss: 0.2375 | ds_loss: 0.0000 | lr: 4.7380e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1245/  8460 | global iter:   1245/  8460 | loss: 0.2540 | ds_loss: 0.0000 | lr: 4.7376e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1246/  8460 | global iter:   1246/  8460 | loss: 0.5744 | ds_loss: 0.0000 | lr: 4.7372e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1247/  8460 | global iter:   1247/  8460 | loss: 0.2641 | ds_loss: 0.0000 | lr: 4.7368e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1248/  8460 | global iter:   1248/  8460 | loss: 0.4274 | ds_loss: 0.0000 | lr: 4.7364e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1248/  8460 | global iter:   1248/  8460 | loss: 0.3800 | ds_loss: 0.0000 | lr: 4.7364e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1249/  8460 | global iter:   1249/  8460 | loss: 0.4122 | ds_loss: 0.0000 | lr: 4.7359e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1250/  8460 | global iter:   1250/  8460 | loss: 0.6113 | ds_loss: 0.0000 | lr: 4.7355e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1251/  8460 | global iter:   1251/  8460 | loss: 0.5833 | ds_loss: 0.0000 | lr: 4.7351e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1252/  8460 | global iter:   1252/  8460 | loss: 0.5330 | ds_loss: 0.0000 | lr: 4.7347e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1252/  8460 | global iter:   1252/  8460 | loss: 0.5349 | ds_loss: 0.0000 | lr: 4.7347e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1253/  8460 | global iter:   1253/  8460 | loss: 0.4662 | ds_loss: 0.0000 | lr: 4.7343e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1254/  8460 | global iter:   1254/  8460 | loss: 0.6543 | ds_loss: 0.0000 | lr: 4.7339e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1255/  8460 | global iter:   1255/  8460 | loss: 0.4443 | ds_loss: 0.0000 | lr: 4.7334e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1256/  8460 | global iter:   1256/  8460 | loss: 1.4933 | ds_loss: 0.0000 | lr: 4.7330e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1256/  8460 | global iter:   1256/  8460 | loss: 0.7645 | ds_loss: 0.0000 | lr: 4.7330e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1257/  8460 | global iter:   1257/  8460 | loss: 1.2687 | ds_loss: 0.0000 | lr: 4.7326e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1258/  8460 | global iter:   1258/  8460 | loss: 0.3374 | ds_loss: 0.0000 | lr: 4.7322e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1259/  8460 | global iter:   1259/  8460 | loss: 0.9206 | ds_loss: 0.0000 | lr: 4.7318e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1260/  8460 | global iter:   1260/  8460 | loss: 1.0739 | ds_loss: 0.0000 | lr: 4.7314e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1260/  8460 | global iter:   1260/  8460 | loss: 0.9002 | ds_loss: 0.0000 | lr: 4.7314e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1261/  8460 | global iter:   1261/  8460 | loss: 0.4685 | ds_loss: 0.0000 | lr: 4.7309e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1262/  8460 | global iter:   1262/  8460 | loss: 0.2095 | ds_loss: 0.0000 | lr: 4.7305e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1263/  8460 | global iter:   1263/  8460 | loss: 0.6018 | ds_loss: 0.0000 | lr: 4.7301e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1264/  8460 | global iter:   1264/  8460 | loss: 0.3310 | ds_loss: 0.0000 | lr: 4.7297e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1264/  8460 | global iter:   1264/  8460 | loss: 0.4027 | ds_loss: 0.0000 | lr: 4.7297e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1265/  8460 | global iter:   1265/  8460 | loss: 0.9171 | ds_loss: 0.0000 | lr: 4.7293e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1266/  8460 | global iter:   1266/  8460 | loss: 0.4398 | ds_loss: 0.0000 | lr: 4.7288e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1267/  8460 | global iter:   1267/  8460 | loss: 1.1504 | ds_loss: 0.0000 | lr: 4.7284e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1268/  8460 | global iter:   1268/  8460 | loss: 0.3142 | ds_loss: 0.0000 | lr: 4.7280e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1268/  8460 | global iter:   1268/  8460 | loss: 0.7054 | ds_loss: 0.0000 | lr: 4.7280e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1269/  8460 | global iter:   1269/  8460 | loss: 0.3127 | ds_loss: 0.0000 | lr: 4.7276e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1270/  8460 | global iter:   1270/  8460 | loss: 0.4705 | ds_loss: 0.0000 | lr: 4.7271e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1271/  8460 | global iter:   1271/  8460 | loss: 0.3579 | ds_loss: 0.0000 | lr: 4.7267e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1272/  8460 | global iter:   1272/  8460 | loss: 0.3310 | ds_loss: 0.0000 | lr: 4.7263e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1272/  8460 | global iter:   1272/  8460 | loss: 0.3680 | ds_loss: 0.0000 | lr: 4.7263e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1273/  8460 | global iter:   1273/  8460 | loss: 0.6430 | ds_loss: 0.0000 | lr: 4.7259e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1274/  8460 | global iter:   1274/  8460 | loss: 0.3166 | ds_loss: 0.0000 | lr: 4.7255e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1275/  8460 | global iter:   1275/  8460 | loss: 0.3874 | ds_loss: 0.0000 | lr: 4.7250e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1276/  8460 | global iter:   1276/  8460 | loss: 0.9917 | ds_loss: 0.0000 | lr: 4.7246e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1276/  8460 | global iter:   1276/  8460 | loss: 0.5847 | ds_loss: 0.0000 | lr: 4.7246e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1277/  8460 | global iter:   1277/  8460 | loss: 0.2740 | ds_loss: 0.0000 | lr: 4.7242e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1278/  8460 | global iter:   1278/  8460 | loss: 0.5432 | ds_loss: 0.0000 | lr: 4.7238e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1279/  8460 | global iter:   1279/  8460 | loss: 0.9281 | ds_loss: 0.0000 | lr: 4.7233e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1280/  8460 | global iter:   1280/  8460 | loss: 0.3021 | ds_loss: 0.0000 | lr: 4.7229e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1280/  8460 | global iter:   1280/  8460 | loss: 0.5118 | ds_loss: 0.0000 | lr: 4.7229e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1281/  8460 | global iter:   1281/  8460 | loss: 0.4186 | ds_loss: 0.0000 | lr: 4.7225e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1282/  8460 | global iter:   1282/  8460 | loss: 1.1798 | ds_loss: 0.0000 | lr: 4.7221e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1283/  8460 | global iter:   1283/  8460 | loss: 0.5179 | ds_loss: 0.0000 | lr: 4.7216e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1284/  8460 | global iter:   1284/  8460 | loss: 1.0592 | ds_loss: 0.0000 | lr: 4.7212e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1284/  8460 | global iter:   1284/  8460 | loss: 0.7939 | ds_loss: 0.0000 | lr: 4.7212e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1285/  8460 | global iter:   1285/  8460 | loss: 0.2374 | ds_loss: 0.0000 | lr: 4.7208e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1286/  8460 | global iter:   1286/  8460 | loss: 1.2027 | ds_loss: 0.0000 | lr: 4.7204e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1287/  8460 | global iter:   1287/  8460 | loss: 0.4015 | ds_loss: 0.0000 | lr: 4.7199e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1288/  8460 | global iter:   1288/  8460 | loss: 0.8181 | ds_loss: 0.0000 | lr: 4.7195e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1288/  8460 | global iter:   1288/  8460 | loss: 0.6649 | ds_loss: 0.0000 | lr: 4.7195e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1289/  8460 | global iter:   1289/  8460 | loss: 0.6936 | ds_loss: 0.0000 | lr: 4.7191e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1290/  8460 | global iter:   1290/  8460 | loss: 1.0938 | ds_loss: 0.0000 | lr: 4.7187e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1291/  8460 | global iter:   1291/  8460 | loss: 0.8880 | ds_loss: 0.0000 | lr: 4.7182e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1292/  8460 | global iter:   1292/  8460 | loss: 0.6334 | ds_loss: 0.0000 | lr: 4.7178e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1292/  8460 | global iter:   1292/  8460 | loss: 0.8272 | ds_loss: 0.0000 | lr: 4.7178e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1293/  8460 | global iter:   1293/  8460 | loss: 0.7907 | ds_loss: 0.0000 | lr: 4.7174e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1294/  8460 | global iter:   1294/  8460 | loss: 0.8627 | ds_loss: 0.0000 | lr: 4.7169e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1295/  8460 | global iter:   1295/  8460 | loss: 0.3902 | ds_loss: 0.0000 | lr: 4.7165e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1296/  8460 | global iter:   1296/  8460 | loss: 0.8360 | ds_loss: 0.0000 | lr: 4.7161e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1296/  8460 | global iter:   1296/  8460 | loss: 0.7199 | ds_loss: 0.0000 | lr: 4.7161e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1297/  8460 | global iter:   1297/  8460 | loss: 0.7634 | ds_loss: 0.0000 | lr: 4.7157e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1298/  8460 | global iter:   1298/  8460 | loss: 0.2770 | ds_loss: 0.0000 | lr: 4.7152e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1299/  8460 | global iter:   1299/  8460 | loss: 1.4519 | ds_loss: 0.0000 | lr: 4.7148e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1300/  8460 | global iter:   1300/  8460 | loss: 1.3296 | ds_loss: 0.0000 | lr: 4.7144e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1300/  8460 | global iter:   1300/  8460 | loss: 0.9555 | ds_loss: 0.0000 | lr: 4.7144e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1301/  8460 | global iter:   1301/  8460 | loss: 1.3475 | ds_loss: 0.0000 | lr: 4.7139e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1302/  8460 | global iter:   1302/  8460 | loss: 0.4103 | ds_loss: 0.0000 | lr: 4.7135e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1303/  8460 | global iter:   1303/  8460 | loss: 0.3870 | ds_loss: 0.0000 | lr: 4.7131e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1304/  8460 | global iter:   1304/  8460 | loss: 0.4854 | ds_loss: 0.0000 | lr: 4.7126e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1304/  8460 | global iter:   1304/  8460 | loss: 0.6575 | ds_loss: 0.0000 | lr: 4.7126e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1305/  8460 | global iter:   1305/  8460 | loss: 0.2781 | ds_loss: 0.0000 | lr: 4.7122e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1306/  8460 | global iter:   1306/  8460 | loss: 0.4689 | ds_loss: 0.0000 | lr: 4.7118e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1307/  8460 | global iter:   1307/  8460 | loss: 0.7691 | ds_loss: 0.0000 | lr: 4.7113e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1308/  8460 | global iter:   1308/  8460 | loss: 0.3006 | ds_loss: 0.0000 | lr: 4.7109e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1308/  8460 | global iter:   1308/  8460 | loss: 0.4542 | ds_loss: 0.0000 | lr: 4.7109e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1309/  8460 | global iter:   1309/  8460 | loss: 0.3294 | ds_loss: 0.0000 | lr: 4.7105e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1310/  8460 | global iter:   1310/  8460 | loss: 0.5205 | ds_loss: 0.0000 | lr: 4.7100e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1311/  8460 | global iter:   1311/  8460 | loss: 0.6038 | ds_loss: 0.0000 | lr: 4.7096e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1312/  8460 | global iter:   1312/  8460 | loss: 0.3276 | ds_loss: 0.0000 | lr: 4.7092e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1312/  8460 | global iter:   1312/  8460 | loss: 0.4453 | ds_loss: 0.0000 | lr: 4.7092e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1313/  8460 | global iter:   1313/  8460 | loss: 0.1272 | ds_loss: 0.0000 | lr: 4.7087e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1314/  8460 | global iter:   1314/  8460 | loss: 0.2936 | ds_loss: 0.0000 | lr: 4.7083e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1315/  8460 | global iter:   1315/  8460 | loss: 0.8018 | ds_loss: 0.0000 | lr: 4.7079e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1316/  8460 | global iter:   1316/  8460 | loss: 0.2439 | ds_loss: 0.0000 | lr: 4.7074e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1316/  8460 | global iter:   1316/  8460 | loss: 0.3666 | ds_loss: 0.0000 | lr: 4.7074e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1317/  8460 | global iter:   1317/  8460 | loss: 0.6831 | ds_loss: 0.0000 | lr: 4.7070e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1318/  8460 | global iter:   1318/  8460 | loss: 0.3795 | ds_loss: 0.0000 | lr: 4.7066e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1319/  8460 | global iter:   1319/  8460 | loss: 0.2407 | ds_loss: 0.0000 | lr: 4.7061e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1320/  8460 | global iter:   1320/  8460 | loss: 0.4720 | ds_loss: 0.0000 | lr: 4.7057e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1320/  8460 | global iter:   1320/  8460 | loss: 0.4438 | ds_loss: 0.0000 | lr: 4.7057e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1321/  8460 | global iter:   1321/  8460 | loss: 0.6612 | ds_loss: 0.0000 | lr: 4.7052e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1322/  8460 | global iter:   1322/  8460 | loss: 0.6423 | ds_loss: 0.0000 | lr: 4.7048e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1323/  8460 | global iter:   1323/  8460 | loss: 0.8914 | ds_loss: 0.0000 | lr: 4.7044e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1324/  8460 | global iter:   1324/  8460 | loss: 0.4720 | ds_loss: 0.0000 | lr: 4.7039e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1324/  8460 | global iter:   1324/  8460 | loss: 0.6667 | ds_loss: 0.0000 | lr: 4.7039e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1325/  8460 | global iter:   1325/  8460 | loss: 1.3411 | ds_loss: 0.0000 | lr: 4.7035e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1326/  8460 | global iter:   1326/  8460 | loss: 0.5747 | ds_loss: 0.0000 | lr: 4.7031e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1327/  8460 | global iter:   1327/  8460 | loss: 0.3108 | ds_loss: 0.0000 | lr: 4.7026e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1328/  8460 | global iter:   1328/  8460 | loss: 0.6838 | ds_loss: 0.0000 | lr: 4.7022e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1328/  8460 | global iter:   1328/  8460 | loss: 0.7276 | ds_loss: 0.0000 | lr: 4.7022e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1329/  8460 | global iter:   1329/  8460 | loss: 0.8895 | ds_loss: 0.0000 | lr: 4.7017e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1330/  8460 | global iter:   1330/  8460 | loss: 0.3767 | ds_loss: 0.0000 | lr: 4.7013e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1331/  8460 | global iter:   1331/  8460 | loss: 0.4538 | ds_loss: 0.0000 | lr: 4.7009e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1332/  8460 | global iter:   1332/  8460 | loss: 0.6626 | ds_loss: 0.0000 | lr: 4.7004e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1332/  8460 | global iter:   1332/  8460 | loss: 0.5956 | ds_loss: 0.0000 | lr: 4.7004e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1333/  8460 | global iter:   1333/  8460 | loss: 0.5421 | ds_loss: 0.0000 | lr: 4.7000e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1334/  8460 | global iter:   1334/  8460 | loss: 0.6555 | ds_loss: 0.0000 | lr: 4.6995e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1335/  8460 | global iter:   1335/  8460 | loss: 0.6591 | ds_loss: 0.0000 | lr: 4.6991e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1336/  8460 | global iter:   1336/  8460 | loss: 0.6032 | ds_loss: 0.0000 | lr: 4.6987e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1336/  8460 | global iter:   1336/  8460 | loss: 0.6150 | ds_loss: 0.0000 | lr: 4.6987e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1337/  8460 | global iter:   1337/  8460 | loss: 1.3190 | ds_loss: 0.0000 | lr: 4.6982e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1338/  8460 | global iter:   1338/  8460 | loss: 0.4199 | ds_loss: 0.0000 | lr: 4.6978e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1339/  8460 | global iter:   1339/  8460 | loss: 0.6110 | ds_loss: 0.0000 | lr: 4.6973e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1340/  8460 | global iter:   1340/  8460 | loss: 0.2900 | ds_loss: 0.0000 | lr: 4.6969e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1340/  8460 | global iter:   1340/  8460 | loss: 0.6600 | ds_loss: 0.0000 | lr: 4.6969e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1341/  8460 | global iter:   1341/  8460 | loss: 0.5797 | ds_loss: 0.0000 | lr: 4.6964e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1342/  8460 | global iter:   1342/  8460 | loss: 1.0684 | ds_loss: 0.0000 | lr: 4.6960e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1343/  8460 | global iter:   1343/  8460 | loss: 0.5880 | ds_loss: 0.0000 | lr: 4.6956e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1344/  8460 | global iter:   1344/  8460 | loss: 0.5361 | ds_loss: 0.0000 | lr: 4.6951e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1344/  8460 | global iter:   1344/  8460 | loss: 0.6930 | ds_loss: 0.0000 | lr: 4.6951e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1345/  8460 | global iter:   1345/  8460 | loss: 0.2612 | ds_loss: 0.0000 | lr: 4.6947e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1346/  8460 | global iter:   1346/  8460 | loss: 0.4894 | ds_loss: 0.0000 | lr: 4.6942e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1347/  8460 | global iter:   1347/  8460 | loss: 0.3816 | ds_loss: 0.0000 | lr: 4.6938e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1348/  8460 | global iter:   1348/  8460 | loss: 0.2106 | ds_loss: 0.0000 | lr: 4.6933e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1348/  8460 | global iter:   1348/  8460 | loss: 0.3357 | ds_loss: 0.0000 | lr: 4.6933e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1349/  8460 | global iter:   1349/  8460 | loss: 0.3489 | ds_loss: 0.0000 | lr: 4.6929e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1350/  8460 | global iter:   1350/  8460 | loss: 0.4390 | ds_loss: 0.0000 | lr: 4.6924e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1351/  8460 | global iter:   1351/  8460 | loss: 0.6696 | ds_loss: 0.0000 | lr: 4.6920e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1352/  8460 | global iter:   1352/  8460 | loss: 0.4932 | ds_loss: 0.0000 | lr: 4.6915e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1352/  8460 | global iter:   1352/  8460 | loss: 0.4877 | ds_loss: 0.0000 | lr: 4.6915e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1353/  8460 | global iter:   1353/  8460 | loss: 0.8030 | ds_loss: 0.0000 | lr: 4.6911e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1354/  8460 | global iter:   1354/  8460 | loss: 1.4554 | ds_loss: 0.0000 | lr: 4.6906e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1355/  8460 | global iter:   1355/  8460 | loss: 0.5625 | ds_loss: 0.0000 | lr: 4.6902e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1356/  8460 | global iter:   1356/  8460 | loss: 0.7395 | ds_loss: 0.0000 | lr: 4.6898e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1356/  8460 | global iter:   1356/  8460 | loss: 0.8901 | ds_loss: 0.0000 | lr: 4.6898e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1357/  8460 | global iter:   1357/  8460 | loss: 0.4760 | ds_loss: 0.0000 | lr: 4.6893e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1358/  8460 | global iter:   1358/  8460 | loss: 0.5939 | ds_loss: 0.0000 | lr: 4.6889e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1359/  8460 | global iter:   1359/  8460 | loss: 0.6057 | ds_loss: 0.0000 | lr: 4.6884e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1360/  8460 | global iter:   1360/  8460 | loss: 0.2874 | ds_loss: 0.0000 | lr: 4.6880e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1360/  8460 | global iter:   1360/  8460 | loss: 0.4907 | ds_loss: 0.0000 | lr: 4.6880e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1361/  8460 | global iter:   1361/  8460 | loss: 0.5879 | ds_loss: 0.0000 | lr: 4.6875e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1362/  8460 | global iter:   1362/  8460 | loss: 0.4957 | ds_loss: 0.0000 | lr: 4.6871e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1363/  8460 | global iter:   1363/  8460 | loss: 0.4758 | ds_loss: 0.0000 | lr: 4.6866e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1364/  8460 | global iter:   1364/  8460 | loss: 0.8691 | ds_loss: 0.0000 | lr: 4.6862e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1364/  8460 | global iter:   1364/  8460 | loss: 0.6071 | ds_loss: 0.0000 | lr: 4.6862e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1365/  8460 | global iter:   1365/  8460 | loss: 0.2727 | ds_loss: 0.0000 | lr: 4.6857e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1366/  8460 | global iter:   1366/  8460 | loss: 0.5519 | ds_loss: 0.0000 | lr: 4.6853e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1367/  8460 | global iter:   1367/  8460 | loss: 0.4484 | ds_loss: 0.0000 | lr: 4.6848e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1368/  8460 | global iter:   1368/  8460 | loss: 0.6995 | ds_loss: 0.0000 | lr: 4.6844e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1368/  8460 | global iter:   1368/  8460 | loss: 0.4931 | ds_loss: 0.0000 | lr: 4.6844e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1369/  8460 | global iter:   1369/  8460 | loss: 0.6961 | ds_loss: 0.0000 | lr: 4.6839e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1370/  8460 | global iter:   1370/  8460 | loss: 0.3643 | ds_loss: 0.0000 | lr: 4.6835e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1371/  8460 | global iter:   1371/  8460 | loss: 0.1765 | ds_loss: 0.0000 | lr: 4.6830e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1372/  8460 | global iter:   1372/  8460 | loss: 0.6286 | ds_loss: 0.0000 | lr: 4.6825e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1372/  8460 | global iter:   1372/  8460 | loss: 0.4664 | ds_loss: 0.0000 | lr: 4.6825e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1373/  8460 | global iter:   1373/  8460 | loss: 0.7587 | ds_loss: 0.0000 | lr: 4.6821e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1374/  8460 | global iter:   1374/  8460 | loss: 0.2561 | ds_loss: 0.0000 | lr: 4.6816e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1375/  8460 | global iter:   1375/  8460 | loss: 0.9558 | ds_loss: 0.0000 | lr: 4.6812e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1376/  8460 | global iter:   1376/  8460 | loss: 0.5378 | ds_loss: 0.0000 | lr: 4.6807e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1376/  8460 | global iter:   1376/  8460 | loss: 0.6271 | ds_loss: 0.0000 | lr: 4.6807e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1377/  8460 | global iter:   1377/  8460 | loss: 0.7337 | ds_loss: 0.0000 | lr: 4.6803e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1378/  8460 | global iter:   1378/  8460 | loss: 0.6534 | ds_loss: 0.0000 | lr: 4.6798e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1379/  8460 | global iter:   1379/  8460 | loss: 0.8396 | ds_loss: 0.0000 | lr: 4.6794e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1380/  8460 | global iter:   1380/  8460 | loss: 0.5245 | ds_loss: 0.0000 | lr: 4.6789e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1380/  8460 | global iter:   1380/  8460 | loss: 0.6878 | ds_loss: 0.0000 | lr: 4.6789e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1381/  8460 | global iter:   1381/  8460 | loss: 0.8927 | ds_loss: 0.0000 | lr: 4.6785e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1382/  8460 | global iter:   1382/  8460 | loss: 1.2513 | ds_loss: 0.0000 | lr: 4.6780e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1383/  8460 | global iter:   1383/  8460 | loss: 0.7644 | ds_loss: 0.0000 | lr: 4.6776e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1384/  8460 | global iter:   1384/  8460 | loss: 0.8551 | ds_loss: 0.0000 | lr: 4.6771e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1384/  8460 | global iter:   1384/  8460 | loss: 0.9409 | ds_loss: 0.0000 | lr: 4.6771e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1385/  8460 | global iter:   1385/  8460 | loss: 0.3778 | ds_loss: 0.0000 | lr: 4.6766e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1386/  8460 | global iter:   1386/  8460 | loss: 0.5270 | ds_loss: 0.0000 | lr: 4.6762e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1387/  8460 | global iter:   1387/  8460 | loss: 1.3053 | ds_loss: 0.0000 | lr: 4.6757e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1388/  8460 | global iter:   1388/  8460 | loss: 0.8444 | ds_loss: 0.0000 | lr: 4.6753e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1388/  8460 | global iter:   1388/  8460 | loss: 0.7636 | ds_loss: 0.0000 | lr: 4.6753e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1389/  8460 | global iter:   1389/  8460 | loss: 0.9002 | ds_loss: 0.0000 | lr: 4.6748e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1390/  8460 | global iter:   1390/  8460 | loss: 1.6670 | ds_loss: 0.0000 | lr: 4.6744e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1391/  8460 | global iter:   1391/  8460 | loss: 0.2351 | ds_loss: 0.0000 | lr: 4.6739e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1392/  8460 | global iter:   1392/  8460 | loss: 0.8126 | ds_loss: 0.0000 | lr: 4.6734e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1392/  8460 | global iter:   1392/  8460 | loss: 0.9037 | ds_loss: 0.0000 | lr: 4.6734e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1393/  8460 | global iter:   1393/  8460 | loss: 0.5643 | ds_loss: 0.0000 | lr: 4.6730e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1394/  8460 | global iter:   1394/  8460 | loss: 0.4581 | ds_loss: 0.0000 | lr: 4.6725e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1395/  8460 | global iter:   1395/  8460 | loss: 0.7566 | ds_loss: 0.0000 | lr: 4.6721e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1396/  8460 | global iter:   1396/  8460 | loss: 0.3551 | ds_loss: 0.0000 | lr: 4.6716e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1396/  8460 | global iter:   1396/  8460 | loss: 0.5335 | ds_loss: 0.0000 | lr: 4.6716e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1397/  8460 | global iter:   1397/  8460 | loss: 0.4367 | ds_loss: 0.0000 | lr: 4.6711e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1398/  8460 | global iter:   1398/  8460 | loss: 1.0415 | ds_loss: 0.0000 | lr: 4.6707e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1399/  8460 | global iter:   1399/  8460 | loss: 0.6249 | ds_loss: 0.0000 | lr: 4.6702e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1400/  8460 | global iter:   1400/  8460 | loss: 0.5571 | ds_loss: 0.0000 | lr: 4.6698e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1400/  8460 | global iter:   1400/  8460 | loss: 0.6651 | ds_loss: 0.0000 | lr: 4.6698e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1401/  8460 | global iter:   1401/  8460 | loss: 0.2593 | ds_loss: 0.0000 | lr: 4.6693e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1402/  8460 | global iter:   1402/  8460 | loss: 0.7077 | ds_loss: 0.0000 | lr: 4.6688e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1403/  8460 | global iter:   1403/  8460 | loss: 0.7167 | ds_loss: 0.0000 | lr: 4.6684e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1404/  8460 | global iter:   1404/  8460 | loss: 1.0375 | ds_loss: 0.0000 | lr: 4.6679e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1404/  8460 | global iter:   1404/  8460 | loss: 0.6803 | ds_loss: 0.0000 | lr: 4.6679e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1405/  8460 | global iter:   1405/  8460 | loss: 0.5358 | ds_loss: 0.0000 | lr: 4.6674e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1406/  8460 | global iter:   1406/  8460 | loss: 0.3675 | ds_loss: 0.0000 | lr: 4.6670e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1407/  8460 | global iter:   1407/  8460 | loss: 1.0004 | ds_loss: 0.0000 | lr: 4.6665e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1408/  8460 | global iter:   1408/  8460 | loss: 0.3056 | ds_loss: 0.0000 | lr: 4.6661e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1408/  8460 | global iter:   1408/  8460 | loss: 0.5523 | ds_loss: 0.0000 | lr: 4.6661e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1409/  8460 | global iter:   1409/  8460 | loss: 0.5396 | ds_loss: 0.0000 | lr: 4.6656e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1410/  8460 | global iter:   1410/  8460 | loss: 0.2366 | ds_loss: 0.0000 | lr: 4.6651e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1411/  8460 | global iter:   1411/  8460 | loss: 0.5873 | ds_loss: 0.0000 | lr: 4.6647e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1412/  8460 | global iter:   1412/  8460 | loss: 0.6874 | ds_loss: 0.0000 | lr: 4.6642e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1412/  8460 | global iter:   1412/  8460 | loss: 0.5127 | ds_loss: 0.0000 | lr: 4.6642e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1413/  8460 | global iter:   1413/  8460 | loss: 0.6482 | ds_loss: 0.0000 | lr: 4.6637e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1414/  8460 | global iter:   1414/  8460 | loss: 1.2040 | ds_loss: 0.0000 | lr: 4.6633e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1415/  8460 | global iter:   1415/  8460 | loss: 0.3568 | ds_loss: 0.0000 | lr: 4.6628e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1416/  8460 | global iter:   1416/  8460 | loss: 0.8951 | ds_loss: 0.0000 | lr: 4.6623e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1416/  8460 | global iter:   1416/  8460 | loss: 0.7760 | ds_loss: 0.0000 | lr: 4.6623e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1417/  8460 | global iter:   1417/  8460 | loss: 1.7576 | ds_loss: 0.0000 | lr: 4.6619e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1418/  8460 | global iter:   1418/  8460 | loss: 1.1627 | ds_loss: 0.0000 | lr: 4.6614e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1419/  8460 | global iter:   1419/  8460 | loss: 0.7354 | ds_loss: 0.0000 | lr: 4.6609e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1420/  8460 | global iter:   1420/  8460 | loss: 1.3471 | ds_loss: 0.0000 | lr: 4.6605e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1420/  8460 | global iter:   1420/  8460 | loss: 1.2507 | ds_loss: 0.0000 | lr: 4.6605e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1421/  8460 | global iter:   1421/  8460 | loss: 0.6850 | ds_loss: 0.0000 | lr: 4.6600e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1422/  8460 | global iter:   1422/  8460 | loss: 1.2608 | ds_loss: 0.0000 | lr: 4.6595e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1423/  8460 | global iter:   1423/  8460 | loss: 0.3916 | ds_loss: 0.0000 | lr: 4.6591e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1424/  8460 | global iter:   1424/  8460 | loss: 1.1960 | ds_loss: 0.0000 | lr: 4.6586e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1424/  8460 | global iter:   1424/  8460 | loss: 0.8834 | ds_loss: 0.0000 | lr: 4.6586e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1425/  8460 | global iter:   1425/  8460 | loss: 1.0214 | ds_loss: 0.0000 | lr: 4.6581e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1426/  8460 | global iter:   1426/  8460 | loss: 0.8066 | ds_loss: 0.0000 | lr: 4.6577e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1427/  8460 | global iter:   1427/  8460 | loss: 0.4040 | ds_loss: 0.0000 | lr: 4.6572e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1428/  8460 | global iter:   1428/  8460 | loss: 0.8973 | ds_loss: 0.0000 | lr: 4.6567e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1428/  8460 | global iter:   1428/  8460 | loss: 0.7823 | ds_loss: 0.0000 | lr: 4.6567e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1429/  8460 | global iter:   1429/  8460 | loss: 0.8137 | ds_loss: 0.0000 | lr: 4.6563e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1430/  8460 | global iter:   1430/  8460 | loss: 0.6007 | ds_loss: 0.0000 | lr: 4.6558e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1431/  8460 | global iter:   1431/  8460 | loss: 1.0446 | ds_loss: 0.0000 | lr: 4.6553e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1432/  8460 | global iter:   1432/  8460 | loss: 0.4188 | ds_loss: 0.0000 | lr: 4.6548e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1432/  8460 | global iter:   1432/  8460 | loss: 0.7194 | ds_loss: 0.0000 | lr: 4.6548e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1433/  8460 | global iter:   1433/  8460 | loss: 1.0925 | ds_loss: 0.0000 | lr: 4.6544e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1434/  8460 | global iter:   1434/  8460 | loss: 0.5452 | ds_loss: 0.0000 | lr: 4.6539e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1435/  8460 | global iter:   1435/  8460 | loss: 0.4551 | ds_loss: 0.0000 | lr: 4.6534e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1436/  8460 | global iter:   1436/  8460 | loss: 0.7090 | ds_loss: 0.0000 | lr: 4.6530e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1436/  8460 | global iter:   1436/  8460 | loss: 0.7004 | ds_loss: 0.0000 | lr: 4.6530e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1437/  8460 | global iter:   1437/  8460 | loss: 0.4363 | ds_loss: 0.0000 | lr: 4.6525e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1438/  8460 | global iter:   1438/  8460 | loss: 1.0045 | ds_loss: 0.0000 | lr: 4.6520e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1439/  8460 | global iter:   1439/  8460 | loss: 0.2004 | ds_loss: 0.0000 | lr: 4.6515e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1440/  8460 | global iter:   1440/  8460 | loss: 0.8250 | ds_loss: 0.0000 | lr: 4.6511e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1440/  8460 | global iter:   1440/  8460 | loss: 0.6165 | ds_loss: 0.0000 | lr: 4.6511e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1441/  8460 | global iter:   1441/  8460 | loss: 0.7372 | ds_loss: 0.0000 | lr: 4.6506e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1442/  8460 | global iter:   1442/  8460 | loss: 0.8111 | ds_loss: 0.0000 | lr: 4.6501e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1443/  8460 | global iter:   1443/  8460 | loss: 0.5453 | ds_loss: 0.0000 | lr: 4.6497e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1444/  8460 | global iter:   1444/  8460 | loss: 0.5292 | ds_loss: 0.0000 | lr: 4.6492e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1444/  8460 | global iter:   1444/  8460 | loss: 0.6557 | ds_loss: 0.0000 | lr: 4.6492e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1445/  8460 | global iter:   1445/  8460 | loss: 0.3930 | ds_loss: 0.0000 | lr: 4.6487e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1446/  8460 | global iter:   1446/  8460 | loss: 0.4347 | ds_loss: 0.0000 | lr: 4.6482e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1447/  8460 | global iter:   1447/  8460 | loss: 1.2529 | ds_loss: 0.0000 | lr: 4.6478e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1448/  8460 | global iter:   1448/  8460 | loss: 0.7707 | ds_loss: 0.0000 | lr: 4.6473e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1448/  8460 | global iter:   1448/  8460 | loss: 0.7128 | ds_loss: 0.0000 | lr: 4.6473e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1449/  8460 | global iter:   1449/  8460 | loss: 0.2810 | ds_loss: 0.0000 | lr: 4.6468e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1450/  8460 | global iter:   1450/  8460 | loss: 0.5737 | ds_loss: 0.0000 | lr: 4.6463e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1451/  8460 | global iter:   1451/  8460 | loss: 0.3761 | ds_loss: 0.0000 | lr: 4.6459e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1452/  8460 | global iter:   1452/  8460 | loss: 0.5278 | ds_loss: 0.0000 | lr: 4.6454e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1452/  8460 | global iter:   1452/  8460 | loss: 0.4396 | ds_loss: 0.0000 | lr: 4.6454e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1453/  8460 | global iter:   1453/  8460 | loss: 0.3200 | ds_loss: 0.0000 | lr: 4.6449e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1454/  8460 | global iter:   1454/  8460 | loss: 1.1612 | ds_loss: 0.0000 | lr: 4.6444e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1455/  8460 | global iter:   1455/  8460 | loss: 1.0310 | ds_loss: 0.0000 | lr: 4.6439e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1456/  8460 | global iter:   1456/  8460 | loss: 0.6000 | ds_loss: 0.0000 | lr: 4.6435e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1456/  8460 | global iter:   1456/  8460 | loss: 0.7780 | ds_loss: 0.0000 | lr: 4.6435e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1457/  8460 | global iter:   1457/  8460 | loss: 0.2212 | ds_loss: 0.0000 | lr: 4.6430e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1458/  8460 | global iter:   1458/  8460 | loss: 0.4818 | ds_loss: 0.0000 | lr: 4.6425e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1459/  8460 | global iter:   1459/  8460 | loss: 0.2788 | ds_loss: 0.0000 | lr: 4.6420e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1460/  8460 | global iter:   1460/  8460 | loss: 0.1986 | ds_loss: 0.0000 | lr: 4.6416e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1460/  8460 | global iter:   1460/  8460 | loss: 0.2951 | ds_loss: 0.0000 | lr: 4.6416e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1461/  8460 | global iter:   1461/  8460 | loss: 0.9526 | ds_loss: 0.0000 | lr: 4.6411e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1462/  8460 | global iter:   1462/  8460 | loss: 1.0292 | ds_loss: 0.0000 | lr: 4.6406e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1463/  8460 | global iter:   1463/  8460 | loss: 0.4078 | ds_loss: 0.0000 | lr: 4.6401e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1464/  8460 | global iter:   1464/  8460 | loss: 0.4626 | ds_loss: 0.0000 | lr: 4.6396e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1464/  8460 | global iter:   1464/  8460 | loss: 0.7130 | ds_loss: 0.0000 | lr: 4.6396e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1465/  8460 | global iter:   1465/  8460 | loss: 0.5429 | ds_loss: 0.0000 | lr: 4.6392e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1466/  8460 | global iter:   1466/  8460 | loss: 0.4332 | ds_loss: 0.0000 | lr: 4.6387e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1467/  8460 | global iter:   1467/  8460 | loss: 0.5623 | ds_loss: 0.0000 | lr: 4.6382e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1468/  8460 | global iter:   1468/  8460 | loss: 0.5150 | ds_loss: 0.0000 | lr: 4.6377e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1468/  8460 | global iter:   1468/  8460 | loss: 0.5134 | ds_loss: 0.0000 | lr: 4.6377e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1469/  8460 | global iter:   1469/  8460 | loss: 0.5228 | ds_loss: 0.0000 | lr: 4.6372e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1470/  8460 | global iter:   1470/  8460 | loss: 0.9019 | ds_loss: 0.0000 | lr: 4.6368e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1471/  8460 | global iter:   1471/  8460 | loss: 0.5694 | ds_loss: 0.0000 | lr: 4.6363e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1472/  8460 | global iter:   1472/  8460 | loss: 0.8390 | ds_loss: 0.0000 | lr: 4.6358e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1472/  8460 | global iter:   1472/  8460 | loss: 0.7083 | ds_loss: 0.0000 | lr: 4.6358e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1473/  8460 | global iter:   1473/  8460 | loss: 0.9539 | ds_loss: 0.0000 | lr: 4.6353e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1474/  8460 | global iter:   1474/  8460 | loss: 0.6475 | ds_loss: 0.0000 | lr: 4.6348e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1475/  8460 | global iter:   1475/  8460 | loss: 0.6378 | ds_loss: 0.0000 | lr: 4.6343e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1476/  8460 | global iter:   1476/  8460 | loss: 0.4541 | ds_loss: 0.0000 | lr: 4.6339e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1476/  8460 | global iter:   1476/  8460 | loss: 0.6733 | ds_loss: 0.0000 | lr: 4.6339e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1477/  8460 | global iter:   1477/  8460 | loss: 0.3064 | ds_loss: 0.0000 | lr: 4.6334e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1478/  8460 | global iter:   1478/  8460 | loss: 0.9183 | ds_loss: 0.0000 | lr: 4.6329e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1479/  8460 | global iter:   1479/  8460 | loss: 0.2788 | ds_loss: 0.0000 | lr: 4.6324e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1480/  8460 | global iter:   1480/  8460 | loss: 0.3752 | ds_loss: 0.0000 | lr: 4.6319e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1480/  8460 | global iter:   1480/  8460 | loss: 0.4697 | ds_loss: 0.0000 | lr: 4.6319e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1481/  8460 | global iter:   1481/  8460 | loss: 1.2649 | ds_loss: 0.0000 | lr: 4.6314e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1482/  8460 | global iter:   1482/  8460 | loss: 0.1256 | ds_loss: 0.0000 | lr: 4.6309e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1483/  8460 | global iter:   1483/  8460 | loss: 0.5214 | ds_loss: 0.0000 | lr: 4.6305e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1484/  8460 | global iter:   1484/  8460 | loss: 0.4328 | ds_loss: 0.0000 | lr: 4.6300e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1484/  8460 | global iter:   1484/  8460 | loss: 0.5862 | ds_loss: 0.0000 | lr: 4.6300e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1485/  8460 | global iter:   1485/  8460 | loss: 0.6033 | ds_loss: 0.0000 | lr: 4.6295e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1486/  8460 | global iter:   1486/  8460 | loss: 0.5934 | ds_loss: 0.0000 | lr: 4.6290e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1487/  8460 | global iter:   1487/  8460 | loss: 0.2503 | ds_loss: 0.0000 | lr: 4.6285e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1488/  8460 | global iter:   1488/  8460 | loss: 0.2666 | ds_loss: 0.0000 | lr: 4.6280e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1488/  8460 | global iter:   1488/  8460 | loss: 0.4284 | ds_loss: 0.0000 | lr: 4.6280e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1489/  8460 | global iter:   1489/  8460 | loss: 1.4423 | ds_loss: 0.0000 | lr: 4.6275e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1490/  8460 | global iter:   1490/  8460 | loss: 0.2236 | ds_loss: 0.0000 | lr: 4.6271e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1491/  8460 | global iter:   1491/  8460 | loss: 0.3716 | ds_loss: 0.0000 | lr: 4.6266e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1492/  8460 | global iter:   1492/  8460 | loss: 1.4457 | ds_loss: 0.0000 | lr: 4.6261e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1492/  8460 | global iter:   1492/  8460 | loss: 0.8708 | ds_loss: 0.0000 | lr: 4.6261e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1493/  8460 | global iter:   1493/  8460 | loss: 0.5886 | ds_loss: 0.0000 | lr: 4.6256e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1494/  8460 | global iter:   1494/  8460 | loss: 1.5131 | ds_loss: 0.0000 | lr: 4.6251e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1495/  8460 | global iter:   1495/  8460 | loss: 0.2725 | ds_loss: 0.0000 | lr: 4.6246e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1496/  8460 | global iter:   1496/  8460 | loss: 1.1647 | ds_loss: 0.0000 | lr: 4.6241e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1496/  8460 | global iter:   1496/  8460 | loss: 0.8847 | ds_loss: 0.0000 | lr: 4.6241e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1497/  8460 | global iter:   1497/  8460 | loss: 0.6661 | ds_loss: 0.0000 | lr: 4.6236e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1498/  8460 | global iter:   1498/  8460 | loss: 0.8363 | ds_loss: 0.0000 | lr: 4.6231e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1499/  8460 | global iter:   1499/  8460 | loss: 0.2628 | ds_loss: 0.0000 | lr: 4.6227e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1500/  8460 | global iter:   1500/  8460 | loss: 0.5547 | ds_loss: 0.0000 | lr: 4.6222e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1500/  8460 | global iter:   1500/  8460 | loss: 0.5800 | ds_loss: 0.0000 | lr: 4.6222e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1501/  8460 | global iter:   1501/  8460 | loss: 0.5224 | ds_loss: 0.0000 | lr: 4.6217e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1502/  8460 | global iter:   1502/  8460 | loss: 0.3153 | ds_loss: 0.0000 | lr: 4.6212e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1503/  8460 | global iter:   1503/  8460 | loss: 0.4467 | ds_loss: 0.0000 | lr: 4.6207e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1504/  8460 | global iter:   1504/  8460 | loss: 0.3273 | ds_loss: 0.0000 | lr: 4.6202e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1504/  8460 | global iter:   1504/  8460 | loss: 0.4029 | ds_loss: 0.0000 | lr: 4.6202e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1505/  8460 | global iter:   1505/  8460 | loss: 1.1113 | ds_loss: 0.0000 | lr: 4.6197e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1506/  8460 | global iter:   1506/  8460 | loss: 0.5319 | ds_loss: 0.0000 | lr: 4.6192e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1507/  8460 | global iter:   1507/  8460 | loss: 0.4077 | ds_loss: 0.0000 | lr: 4.6187e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1508/  8460 | global iter:   1508/  8460 | loss: 0.5188 | ds_loss: 0.0000 | lr: 4.6182e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1508/  8460 | global iter:   1508/  8460 | loss: 0.6424 | ds_loss: 0.0000 | lr: 4.6182e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1509/  8460 | global iter:   1509/  8460 | loss: 0.5505 | ds_loss: 0.0000 | lr: 4.6177e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1510/  8460 | global iter:   1510/  8460 | loss: 0.3227 | ds_loss: 0.0000 | lr: 4.6172e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1511/  8460 | global iter:   1511/  8460 | loss: 1.2833 | ds_loss: 0.0000 | lr: 4.6167e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1512/  8460 | global iter:   1512/  8460 | loss: 0.7326 | ds_loss: 0.0000 | lr: 4.6163e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1512/  8460 | global iter:   1512/  8460 | loss: 0.7223 | ds_loss: 0.0000 | lr: 4.6163e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1513/  8460 | global iter:   1513/  8460 | loss: 0.2855 | ds_loss: 0.0000 | lr: 4.6158e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1514/  8460 | global iter:   1514/  8460 | loss: 0.6584 | ds_loss: 0.0000 | lr: 4.6153e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1515/  8460 | global iter:   1515/  8460 | loss: 0.6001 | ds_loss: 0.0000 | lr: 4.6148e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1516/  8460 | global iter:   1516/  8460 | loss: 0.2602 | ds_loss: 0.0000 | lr: 4.6143e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1516/  8460 | global iter:   1516/  8460 | loss: 0.4510 | ds_loss: 0.0000 | lr: 4.6143e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1517/  8460 | global iter:   1517/  8460 | loss: 0.6166 | ds_loss: 0.0000 | lr: 4.6138e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1518/  8460 | global iter:   1518/  8460 | loss: 0.7992 | ds_loss: 0.0000 | lr: 4.6133e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1519/  8460 | global iter:   1519/  8460 | loss: 0.3996 | ds_loss: 0.0000 | lr: 4.6128e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1520/  8460 | global iter:   1520/  8460 | loss: 0.2415 | ds_loss: 0.0000 | lr: 4.6123e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1520/  8460 | global iter:   1520/  8460 | loss: 0.5142 | ds_loss: 0.0000 | lr: 4.6123e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1521/  8460 | global iter:   1521/  8460 | loss: 0.9877 | ds_loss: 0.0000 | lr: 4.6118e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1522/  8460 | global iter:   1522/  8460 | loss: 0.5610 | ds_loss: 0.0000 | lr: 4.6113e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1523/  8460 | global iter:   1523/  8460 | loss: 0.8751 | ds_loss: 0.0000 | lr: 4.6108e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1524/  8460 | global iter:   1524/  8460 | loss: 0.6731 | ds_loss: 0.0000 | lr: 4.6103e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1524/  8460 | global iter:   1524/  8460 | loss: 0.7742 | ds_loss: 0.0000 | lr: 4.6103e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1525/  8460 | global iter:   1525/  8460 | loss: 0.5117 | ds_loss: 0.0000 | lr: 4.6098e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1526/  8460 | global iter:   1526/  8460 | loss: 0.3947 | ds_loss: 0.0000 | lr: 4.6093e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1527/  8460 | global iter:   1527/  8460 | loss: 0.8947 | ds_loss: 0.0000 | lr: 4.6088e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1528/  8460 | global iter:   1528/  8460 | loss: 0.6584 | ds_loss: 0.0000 | lr: 4.6083e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1528/  8460 | global iter:   1528/  8460 | loss: 0.6149 | ds_loss: 0.0000 | lr: 4.6083e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1529/  8460 | global iter:   1529/  8460 | loss: 1.2049 | ds_loss: 0.0000 | lr: 4.6078e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1530/  8460 | global iter:   1530/  8460 | loss: 0.8144 | ds_loss: 0.0000 | lr: 4.6073e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1531/  8460 | global iter:   1531/  8460 | loss: 0.2058 | ds_loss: 0.0000 | lr: 4.6068e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1532/  8460 | global iter:   1532/  8460 | loss: 0.7750 | ds_loss: 0.0000 | lr: 4.6063e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1532/  8460 | global iter:   1532/  8460 | loss: 0.7500 | ds_loss: 0.0000 | lr: 4.6063e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1533/  8460 | global iter:   1533/  8460 | loss: 0.5973 | ds_loss: 0.0000 | lr: 4.6058e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1534/  8460 | global iter:   1534/  8460 | loss: 0.5523 | ds_loss: 0.0000 | lr: 4.6053e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1535/  8460 | global iter:   1535/  8460 | loss: 0.5053 | ds_loss: 0.0000 | lr: 4.6048e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1536/  8460 | global iter:   1536/  8460 | loss: 1.9270 | ds_loss: 0.0000 | lr: 4.6043e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1536/  8460 | global iter:   1536/  8460 | loss: 0.8955 | ds_loss: 0.0000 | lr: 4.6043e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1537/  8460 | global iter:   1537/  8460 | loss: 0.5863 | ds_loss: 0.0000 | lr: 4.6038e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1538/  8460 | global iter:   1538/  8460 | loss: 1.3681 | ds_loss: 0.0000 | lr: 4.6033e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1539/  8460 | global iter:   1539/  8460 | loss: 1.2813 | ds_loss: 0.0000 | lr: 4.6028e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1540/  8460 | global iter:   1540/  8460 | loss: 0.7255 | ds_loss: 0.0000 | lr: 4.6023e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1540/  8460 | global iter:   1540/  8460 | loss: 0.9903 | ds_loss: 0.0000 | lr: 4.6023e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1541/  8460 | global iter:   1541/  8460 | loss: 0.4936 | ds_loss: 0.0000 | lr: 4.6018e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1542/  8460 | global iter:   1542/  8460 | loss: 0.7567 | ds_loss: 0.0000 | lr: 4.6013e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1543/  8460 | global iter:   1543/  8460 | loss: 0.7074 | ds_loss: 0.0000 | lr: 4.6008e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1544/  8460 | global iter:   1544/  8460 | loss: 0.4561 | ds_loss: 0.0000 | lr: 4.6003e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1544/  8460 | global iter:   1544/  8460 | loss: 0.6035 | ds_loss: 0.0000 | lr: 4.6003e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1545/  8460 | global iter:   1545/  8460 | loss: 0.6106 | ds_loss: 0.0000 | lr: 4.5998e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1546/  8460 | global iter:   1546/  8460 | loss: 0.7734 | ds_loss: 0.0000 | lr: 4.5993e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1547/  8460 | global iter:   1547/  8460 | loss: 1.3376 | ds_loss: 0.0000 | lr: 4.5988e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1548/  8460 | global iter:   1548/  8460 | loss: 1.1135 | ds_loss: 0.0000 | lr: 4.5983e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1548/  8460 | global iter:   1548/  8460 | loss: 0.9588 | ds_loss: 0.0000 | lr: 4.5983e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1549/  8460 | global iter:   1549/  8460 | loss: 0.4951 | ds_loss: 0.0000 | lr: 4.5978e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1550/  8460 | global iter:   1550/  8460 | loss: 0.5836 | ds_loss: 0.0000 | lr: 4.5973e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1551/  8460 | global iter:   1551/  8460 | loss: 0.7315 | ds_loss: 0.0000 | lr: 4.5968e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1552/  8460 | global iter:   1552/  8460 | loss: 0.9317 | ds_loss: 0.0000 | lr: 4.5963e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1552/  8460 | global iter:   1552/  8460 | loss: 0.6855 | ds_loss: 0.0000 | lr: 4.5963e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1553/  8460 | global iter:   1553/  8460 | loss: 0.9104 | ds_loss: 0.0000 | lr: 4.5957e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1554/  8460 | global iter:   1554/  8460 | loss: 0.2927 | ds_loss: 0.0000 | lr: 4.5952e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1555/  8460 | global iter:   1555/  8460 | loss: 0.6403 | ds_loss: 0.0000 | lr: 4.5947e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1556/  8460 | global iter:   1556/  8460 | loss: 0.2518 | ds_loss: 0.0000 | lr: 4.5942e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1556/  8460 | global iter:   1556/  8460 | loss: 0.5238 | ds_loss: 0.0000 | lr: 4.5942e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1557/  8460 | global iter:   1557/  8460 | loss: 1.1332 | ds_loss: 0.0000 | lr: 4.5937e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1558/  8460 | global iter:   1558/  8460 | loss: 0.8176 | ds_loss: 0.0000 | lr: 4.5932e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1559/  8460 | global iter:   1559/  8460 | loss: 0.9892 | ds_loss: 0.0000 | lr: 4.5927e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1560/  8460 | global iter:   1560/  8460 | loss: 0.5274 | ds_loss: 0.0000 | lr: 4.5922e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1560/  8460 | global iter:   1560/  8460 | loss: 0.8668 | ds_loss: 0.0000 | lr: 4.5922e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1561/  8460 | global iter:   1561/  8460 | loss: 0.3220 | ds_loss: 0.0000 | lr: 4.5917e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1562/  8460 | global iter:   1562/  8460 | loss: 0.9777 | ds_loss: 0.0000 | lr: 4.5912e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1563/  8460 | global iter:   1563/  8460 | loss: 0.3992 | ds_loss: 0.0000 | lr: 4.5907e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1564/  8460 | global iter:   1564/  8460 | loss: 0.9421 | ds_loss: 0.0000 | lr: 4.5902e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1564/  8460 | global iter:   1564/  8460 | loss: 0.6603 | ds_loss: 0.0000 | lr: 4.5902e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1565/  8460 | global iter:   1565/  8460 | loss: 0.4688 | ds_loss: 0.0000 | lr: 4.5897e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1566/  8460 | global iter:   1566/  8460 | loss: 0.6261 | ds_loss: 0.0000 | lr: 4.5891e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1567/  8460 | global iter:   1567/  8460 | loss: 1.4973 | ds_loss: 0.0000 | lr: 4.5886e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1568/  8460 | global iter:   1568/  8460 | loss: 0.4195 | ds_loss: 0.0000 | lr: 4.5881e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1568/  8460 | global iter:   1568/  8460 | loss: 0.7529 | ds_loss: 0.0000 | lr: 4.5881e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1569/  8460 | global iter:   1569/  8460 | loss: 0.6533 | ds_loss: 0.0000 | lr: 4.5876e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1570/  8460 | global iter:   1570/  8460 | loss: 0.7225 | ds_loss: 0.0000 | lr: 4.5871e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1571/  8460 | global iter:   1571/  8460 | loss: 0.7224 | ds_loss: 0.0000 | lr: 4.5866e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1572/  8460 | global iter:   1572/  8460 | loss: 0.5879 | ds_loss: 0.0000 | lr: 4.5861e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1572/  8460 | global iter:   1572/  8460 | loss: 0.6715 | ds_loss: 0.0000 | lr: 4.5861e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1573/  8460 | global iter:   1573/  8460 | loss: 0.3157 | ds_loss: 0.0000 | lr: 4.5856e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1574/  8460 | global iter:   1574/  8460 | loss: 0.3942 | ds_loss: 0.0000 | lr: 4.5851e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1575/  8460 | global iter:   1575/  8460 | loss: 1.0747 | ds_loss: 0.0000 | lr: 4.5845e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1576/  8460 | global iter:   1576/  8460 | loss: 0.2998 | ds_loss: 0.0000 | lr: 4.5840e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1576/  8460 | global iter:   1576/  8460 | loss: 0.5211 | ds_loss: 0.0000 | lr: 4.5840e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1577/  8460 | global iter:   1577/  8460 | loss: 0.8505 | ds_loss: 0.0000 | lr: 4.5835e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1578/  8460 | global iter:   1578/  8460 | loss: 0.6855 | ds_loss: 0.0000 | lr: 4.5830e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1579/  8460 | global iter:   1579/  8460 | loss: 0.8509 | ds_loss: 0.0000 | lr: 4.5825e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1580/  8460 | global iter:   1580/  8460 | loss: 0.5929 | ds_loss: 0.0000 | lr: 4.5820e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1580/  8460 | global iter:   1580/  8460 | loss: 0.7450 | ds_loss: 0.0000 | lr: 4.5820e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1581/  8460 | global iter:   1581/  8460 | loss: 0.3161 | ds_loss: 0.0000 | lr: 4.5815e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1582/  8460 | global iter:   1582/  8460 | loss: 1.3215 | ds_loss: 0.0000 | lr: 4.5809e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1583/  8460 | global iter:   1583/  8460 | loss: 0.8912 | ds_loss: 0.0000 | lr: 4.5804e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1584/  8460 | global iter:   1584/  8460 | loss: 0.8089 | ds_loss: 0.0000 | lr: 4.5799e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1584/  8460 | global iter:   1584/  8460 | loss: 0.8344 | ds_loss: 0.0000 | lr: 4.5799e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1585/  8460 | global iter:   1585/  8460 | loss: 0.2585 | ds_loss: 0.0000 | lr: 4.5794e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1586/  8460 | global iter:   1586/  8460 | loss: 1.0353 | ds_loss: 0.0000 | lr: 4.5789e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1587/  8460 | global iter:   1587/  8460 | loss: 0.6572 | ds_loss: 0.0000 | lr: 4.5784e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1588/  8460 | global iter:   1588/  8460 | loss: 0.3663 | ds_loss: 0.0000 | lr: 4.5779e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1588/  8460 | global iter:   1588/  8460 | loss: 0.5793 | ds_loss: 0.0000 | lr: 4.5779e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1589/  8460 | global iter:   1589/  8460 | loss: 0.3501 | ds_loss: 0.0000 | lr: 4.5773e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1590/  8460 | global iter:   1590/  8460 | loss: 0.8436 | ds_loss: 0.0000 | lr: 4.5768e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1591/  8460 | global iter:   1591/  8460 | loss: 0.5319 | ds_loss: 0.0000 | lr: 4.5763e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1592/  8460 | global iter:   1592/  8460 | loss: 0.3770 | ds_loss: 0.0000 | lr: 4.5758e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1592/  8460 | global iter:   1592/  8460 | loss: 0.5256 | ds_loss: 0.0000 | lr: 4.5758e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1593/  8460 | global iter:   1593/  8460 | loss: 0.5336 | ds_loss: 0.0000 | lr: 4.5753e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1594/  8460 | global iter:   1594/  8460 | loss: 0.5908 | ds_loss: 0.0000 | lr: 4.5748e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1595/  8460 | global iter:   1595/  8460 | loss: 0.6271 | ds_loss: 0.0000 | lr: 4.5742e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1596/  8460 | global iter:   1596/  8460 | loss: 0.2937 | ds_loss: 0.0000 | lr: 4.5737e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1596/  8460 | global iter:   1596/  8460 | loss: 0.5113 | ds_loss: 0.0000 | lr: 4.5737e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1597/  8460 | global iter:   1597/  8460 | loss: 0.5617 | ds_loss: 0.0000 | lr: 4.5732e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1598/  8460 | global iter:   1598/  8460 | loss: 0.2631 | ds_loss: 0.0000 | lr: 4.5727e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1599/  8460 | global iter:   1599/  8460 | loss: 0.4287 | ds_loss: 0.0000 | lr: 4.5722e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1600/  8460 | global iter:   1600/  8460 | loss: 0.6012 | ds_loss: 0.0000 | lr: 4.5716e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1600/  8460 | global iter:   1600/  8460 | loss: 0.4637 | ds_loss: 0.0000 | lr: 4.5716e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1601/  8460 | global iter:   1601/  8460 | loss: 0.4679 | ds_loss: 0.0000 | lr: 4.5711e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1602/  8460 | global iter:   1602/  8460 | loss: 0.6671 | ds_loss: 0.0000 | lr: 4.5706e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1603/  8460 | global iter:   1603/  8460 | loss: 0.4027 | ds_loss: 0.0000 | lr: 4.5701e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1604/  8460 | global iter:   1604/  8460 | loss: 0.3167 | ds_loss: 0.0000 | lr: 4.5696e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1604/  8460 | global iter:   1604/  8460 | loss: 0.4636 | ds_loss: 0.0000 | lr: 4.5696e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1605/  8460 | global iter:   1605/  8460 | loss: 1.5928 | ds_loss: 0.0000 | lr: 4.5690e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1606/  8460 | global iter:   1606/  8460 | loss: 0.1936 | ds_loss: 0.0000 | lr: 4.5685e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1607/  8460 | global iter:   1607/  8460 | loss: 0.4027 | ds_loss: 0.0000 | lr: 4.5680e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1608/  8460 | global iter:   1608/  8460 | loss: 0.9117 | ds_loss: 0.0000 | lr: 4.5675e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1608/  8460 | global iter:   1608/  8460 | loss: 0.7752 | ds_loss: 0.0000 | lr: 4.5675e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1609/  8460 | global iter:   1609/  8460 | loss: 0.7538 | ds_loss: 0.0000 | lr: 4.5670e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1610/  8460 | global iter:   1610/  8460 | loss: 0.3847 | ds_loss: 0.0000 | lr: 4.5664e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1611/  8460 | global iter:   1611/  8460 | loss: 0.4870 | ds_loss: 0.0000 | lr: 4.5659e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1612/  8460 | global iter:   1612/  8460 | loss: 0.7189 | ds_loss: 0.0000 | lr: 4.5654e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1612/  8460 | global iter:   1612/  8460 | loss: 0.5861 | ds_loss: 0.0000 | lr: 4.5654e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1613/  8460 | global iter:   1613/  8460 | loss: 0.8410 | ds_loss: 0.0000 | lr: 4.5649e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1614/  8460 | global iter:   1614/  8460 | loss: 0.4665 | ds_loss: 0.0000 | lr: 4.5643e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1615/  8460 | global iter:   1615/  8460 | loss: 0.5258 | ds_loss: 0.0000 | lr: 4.5638e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1616/  8460 | global iter:   1616/  8460 | loss: 0.6194 | ds_loss: 0.0000 | lr: 4.5633e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1616/  8460 | global iter:   1616/  8460 | loss: 0.6132 | ds_loss: 0.0000 | lr: 4.5633e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1617/  8460 | global iter:   1617/  8460 | loss: 0.9304 | ds_loss: 0.0000 | lr: 4.5628e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1618/  8460 | global iter:   1618/  8460 | loss: 0.4095 | ds_loss: 0.0000 | lr: 4.5622e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1619/  8460 | global iter:   1619/  8460 | loss: 0.4618 | ds_loss: 0.0000 | lr: 4.5617e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1620/  8460 | global iter:   1620/  8460 | loss: 0.6462 | ds_loss: 0.0000 | lr: 4.5612e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1620/  8460 | global iter:   1620/  8460 | loss: 0.6120 | ds_loss: 0.0000 | lr: 4.5612e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1621/  8460 | global iter:   1621/  8460 | loss: 0.8859 | ds_loss: 0.0000 | lr: 4.5607e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1622/  8460 | global iter:   1622/  8460 | loss: 0.7540 | ds_loss: 0.0000 | lr: 4.5601e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1623/  8460 | global iter:   1623/  8460 | loss: 0.7817 | ds_loss: 0.0000 | lr: 4.5596e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1624/  8460 | global iter:   1624/  8460 | loss: 0.4798 | ds_loss: 0.0000 | lr: 4.5591e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1624/  8460 | global iter:   1624/  8460 | loss: 0.7254 | ds_loss: 0.0000 | lr: 4.5591e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1625/  8460 | global iter:   1625/  8460 | loss: 0.4726 | ds_loss: 0.0000 | lr: 4.5586e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1626/  8460 | global iter:   1626/  8460 | loss: 0.3523 | ds_loss: 0.0000 | lr: 4.5580e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1627/  8460 | global iter:   1627/  8460 | loss: 0.5468 | ds_loss: 0.0000 | lr: 4.5575e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1628/  8460 | global iter:   1628/  8460 | loss: 0.8489 | ds_loss: 0.0000 | lr: 4.5570e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1628/  8460 | global iter:   1628/  8460 | loss: 0.5552 | ds_loss: 0.0000 | lr: 4.5570e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1629/  8460 | global iter:   1629/  8460 | loss: 1.3446 | ds_loss: 0.0000 | lr: 4.5565e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1630/  8460 | global iter:   1630/  8460 | loss: 0.8538 | ds_loss: 0.0000 | lr: 4.5559e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1631/  8460 | global iter:   1631/  8460 | loss: 0.2109 | ds_loss: 0.0000 | lr: 4.5554e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1632/  8460 | global iter:   1632/  8460 | loss: 1.0167 | ds_loss: 0.0000 | lr: 4.5549e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1632/  8460 | global iter:   1632/  8460 | loss: 0.8565 | ds_loss: 0.0000 | lr: 4.5549e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1633/  8460 | global iter:   1633/  8460 | loss: 0.6186 | ds_loss: 0.0000 | lr: 4.5543e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1634/  8460 | global iter:   1634/  8460 | loss: 0.7768 | ds_loss: 0.0000 | lr: 4.5538e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1635/  8460 | global iter:   1635/  8460 | loss: 0.3664 | ds_loss: 0.0000 | lr: 4.5533e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1636/  8460 | global iter:   1636/  8460 | loss: 0.8047 | ds_loss: 0.0000 | lr: 4.5528e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1636/  8460 | global iter:   1636/  8460 | loss: 0.6417 | ds_loss: 0.0000 | lr: 4.5528e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1637/  8460 | global iter:   1637/  8460 | loss: 0.5341 | ds_loss: 0.0000 | lr: 4.5522e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1638/  8460 | global iter:   1638/  8460 | loss: 0.2984 | ds_loss: 0.0000 | lr: 4.5517e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1639/  8460 | global iter:   1639/  8460 | loss: 0.3700 | ds_loss: 0.0000 | lr: 4.5512e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1640/  8460 | global iter:   1640/  8460 | loss: 0.3036 | ds_loss: 0.0000 | lr: 4.5506e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1640/  8460 | global iter:   1640/  8460 | loss: 0.3765 | ds_loss: 0.0000 | lr: 4.5506e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1641/  8460 | global iter:   1641/  8460 | loss: 0.9131 | ds_loss: 0.0000 | lr: 4.5501e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1642/  8460 | global iter:   1642/  8460 | loss: 0.8225 | ds_loss: 0.0000 | lr: 4.5496e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1643/  8460 | global iter:   1643/  8460 | loss: 0.4996 | ds_loss: 0.0000 | lr: 4.5490e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1644/  8460 | global iter:   1644/  8460 | loss: 1.2570 | ds_loss: 0.0000 | lr: 4.5485e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1644/  8460 | global iter:   1644/  8460 | loss: 0.8730 | ds_loss: 0.0000 | lr: 4.5485e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1645/  8460 | global iter:   1645/  8460 | loss: 0.6864 | ds_loss: 0.0000 | lr: 4.5480e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1646/  8460 | global iter:   1646/  8460 | loss: 0.7742 | ds_loss: 0.0000 | lr: 4.5474e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1647/  8460 | global iter:   1647/  8460 | loss: 0.4046 | ds_loss: 0.0000 | lr: 4.5469e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1648/  8460 | global iter:   1648/  8460 | loss: 0.5425 | ds_loss: 0.0000 | lr: 4.5464e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1648/  8460 | global iter:   1648/  8460 | loss: 0.6019 | ds_loss: 0.0000 | lr: 4.5464e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1649/  8460 | global iter:   1649/  8460 | loss: 0.5354 | ds_loss: 0.0000 | lr: 4.5458e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1650/  8460 | global iter:   1650/  8460 | loss: 0.5990 | ds_loss: 0.0000 | lr: 4.5453e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1651/  8460 | global iter:   1651/  8460 | loss: 1.1925 | ds_loss: 0.0000 | lr: 4.5448e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1652/  8460 | global iter:   1652/  8460 | loss: 0.6625 | ds_loss: 0.0000 | lr: 4.5442e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1652/  8460 | global iter:   1652/  8460 | loss: 0.7474 | ds_loss: 0.0000 | lr: 4.5442e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1653/  8460 | global iter:   1653/  8460 | loss: 0.5977 | ds_loss: 0.0000 | lr: 4.5437e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1654/  8460 | global iter:   1654/  8460 | loss: 0.5874 | ds_loss: 0.0000 | lr: 4.5432e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1655/  8460 | global iter:   1655/  8460 | loss: 0.9069 | ds_loss: 0.0000 | lr: 4.5426e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1656/  8460 | global iter:   1656/  8460 | loss: 1.3582 | ds_loss: 0.0000 | lr: 4.5421e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1656/  8460 | global iter:   1656/  8460 | loss: 0.8626 | ds_loss: 0.0000 | lr: 4.5421e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1657/  8460 | global iter:   1657/  8460 | loss: 0.3954 | ds_loss: 0.0000 | lr: 4.5416e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1658/  8460 | global iter:   1658/  8460 | loss: 1.0091 | ds_loss: 0.0000 | lr: 4.5410e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1659/  8460 | global iter:   1659/  8460 | loss: 1.2760 | ds_loss: 0.0000 | lr: 4.5405e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1660/  8460 | global iter:   1660/  8460 | loss: 0.8052 | ds_loss: 0.0000 | lr: 4.5400e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1660/  8460 | global iter:   1660/  8460 | loss: 0.8714 | ds_loss: 0.0000 | lr: 4.5400e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1661/  8460 | global iter:   1661/  8460 | loss: 0.3142 | ds_loss: 0.0000 | lr: 4.5394e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   1 | Iter:   1662/  8460 | global iter:   1662/  8460 | loss: 1.1164 | ds_loss: 0.0000 | lr: 4.5389e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1663/  8460 | global iter:   1663/  8460 | loss: 0.4008 | ds_loss: 0.0000 | lr: 4.5383e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1664/  8460 | global iter:   1664/  8460 | loss: 0.5862 | ds_loss: 0.0000 | lr: 4.5378e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1664/  8460 | global iter:   1664/  8460 | loss: 0.6044 | ds_loss: 0.0000 | lr: 4.5378e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1665/  8460 | global iter:   1665/  8460 | loss: 0.2492 | ds_loss: 0.0000 | lr: 4.5373e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1666/  8460 | global iter:   1666/  8460 | loss: 0.6778 | ds_loss: 0.0000 | lr: 4.5367e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1667/  8460 | global iter:   1667/  8460 | loss: 0.4434 | ds_loss: 0.0000 | lr: 4.5362e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1668/  8460 | global iter:   1668/  8460 | loss: 0.6005 | ds_loss: 0.0000 | lr: 4.5357e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1668/  8460 | global iter:   1668/  8460 | loss: 0.4927 | ds_loss: 0.0000 | lr: 4.5357e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1669/  8460 | global iter:   1669/  8460 | loss: 0.1535 | ds_loss: 0.0000 | lr: 4.5351e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1670/  8460 | global iter:   1670/  8460 | loss: 1.0514 | ds_loss: 0.0000 | lr: 4.5346e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1671/  8460 | global iter:   1671/  8460 | loss: 0.3010 | ds_loss: 0.0000 | lr: 4.5340e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1672/  8460 | global iter:   1672/  8460 | loss: 0.3193 | ds_loss: 0.0000 | lr: 4.5335e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1672/  8460 | global iter:   1672/  8460 | loss: 0.4563 | ds_loss: 0.0000 | lr: 4.5335e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1673/  8460 | global iter:   1673/  8460 | loss: 1.2479 | ds_loss: 0.0000 | lr: 4.5330e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1674/  8460 | global iter:   1674/  8460 | loss: 0.8537 | ds_loss: 0.0000 | lr: 4.5324e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1675/  8460 | global iter:   1675/  8460 | loss: 1.4759 | ds_loss: 0.0000 | lr: 4.5319e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1676/  8460 | global iter:   1676/  8460 | loss: 0.9743 | ds_loss: 0.0000 | lr: 4.5313e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1676/  8460 | global iter:   1676/  8460 | loss: 1.1380 | ds_loss: 0.0000 | lr: 4.5313e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1677/  8460 | global iter:   1677/  8460 | loss: 0.3187 | ds_loss: 0.0000 | lr: 4.5308e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1678/  8460 | global iter:   1678/  8460 | loss: 0.4320 | ds_loss: 0.0000 | lr: 4.5302e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1679/  8460 | global iter:   1679/  8460 | loss: 0.5206 | ds_loss: 0.0000 | lr: 4.5297e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1680/  8460 | global iter:   1680/  8460 | loss: 0.2393 | ds_loss: 0.0000 | lr: 4.5292e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1680/  8460 | global iter:   1680/  8460 | loss: 0.3777 | ds_loss: 0.0000 | lr: 4.5292e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1681/  8460 | global iter:   1681/  8460 | loss: 0.8645 | ds_loss: 0.0000 | lr: 4.5286e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1682/  8460 | global iter:   1682/  8460 | loss: 0.5543 | ds_loss: 0.0000 | lr: 4.5281e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1683/  8460 | global iter:   1683/  8460 | loss: 0.5455 | ds_loss: 0.0000 | lr: 4.5275e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1684/  8460 | global iter:   1684/  8460 | loss: 0.5731 | ds_loss: 0.0000 | lr: 4.5270e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1684/  8460 | global iter:   1684/  8460 | loss: 0.6344 | ds_loss: 0.0000 | lr: 4.5270e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1685/  8460 | global iter:   1685/  8460 | loss: 0.9486 | ds_loss: 0.0000 | lr: 4.5265e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1686/  8460 | global iter:   1686/  8460 | loss: 0.8856 | ds_loss: 0.0000 | lr: 4.5259e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1687/  8460 | global iter:   1687/  8460 | loss: 0.2467 | ds_loss: 0.0000 | lr: 4.5254e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1688/  8460 | global iter:   1688/  8460 | loss: 0.5589 | ds_loss: 0.0000 | lr: 4.5248e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1688/  8460 | global iter:   1688/  8460 | loss: 0.6599 | ds_loss: 0.0000 | lr: 4.5248e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1689/  8460 | global iter:   1689/  8460 | loss: 1.0355 | ds_loss: 0.0000 | lr: 4.5243e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   1 | Iter:   1690/  8460 | global iter:   1690/  8460 | loss: 0.8593 | ds_loss: 0.0000 | lr: 4.5237e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1691/  8460 | global iter:   1691/  8460 | loss: 0.5240 | ds_loss: 0.0000 | lr: 4.5232e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1692/  8460 | global iter:   1692/  8460 | loss: 1.0555 | ds_loss: 0.0000 | lr: 4.5226e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   1 | Iter:   1692/  8460 | global iter:   1692/  8460 | loss: 0.8686 | ds_loss: 0.0000 | lr: 4.5226e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   1 | Iter:   1693/  8460 | global iter:   1693/  8460 | loss: 0.7012 | ds_loss: 0.0000 | lr: 4.5221e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   1 | Iter:   1694/  8460 | global iter:   1694/  8460 | loss: 0.6913 | ds_loss: 0.0000 | lr: 4.5215e-04 | scale:     1.0000 | micro time: 0.366 | step time: 0.000
Sun Apr  6 21:01:41 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla P100-PCIE-12GB           Off |   00000000:81:00.0 Off |                    0 |
| N/A   52C    P0             40W /  250W |    8807MiB /  12288MiB |    100%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A    244677      C   ...project_distillLLM/venv/bin/python3       8804MiB |
+-----------------------------------------------------------------------------------------+

train | epoch   2 | Iter:   1695/  8460 | global iter:   1695/  8460 | loss: 0.3403 | ds_loss: 0.0000 | lr: 4.5210e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1696/  8460 | global iter:   1696/  8460 | loss: 0.2432 | ds_loss: 0.0000 | lr: 4.5205e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1696/  8460 | global iter:   1696/  8460 | loss: 0.4940 | ds_loss: 0.0000 | lr: 4.5205e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.412
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1697/  8460 | global iter:   1697/  8460 | loss: 0.5310 | ds_loss: 0.0000 | lr: 4.5199e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1698/  8460 | global iter:   1698/  8460 | loss: 0.3246 | ds_loss: 0.0000 | lr: 4.5194e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1699/  8460 | global iter:   1699/  8460 | loss: 0.7053 | ds_loss: 0.0000 | lr: 4.5188e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1700/  8460 | global iter:   1700/  8460 | loss: 0.2289 | ds_loss: 0.0000 | lr: 4.5183e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1700/  8460 | global iter:   1700/  8460 | loss: 0.4474 | ds_loss: 0.0000 | lr: 4.5183e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1701/  8460 | global iter:   1701/  8460 | loss: 0.4559 | ds_loss: 0.0000 | lr: 4.5177e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1702/  8460 | global iter:   1702/  8460 | loss: 0.3444 | ds_loss: 0.0000 | lr: 4.5172e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   1703/  8460 | global iter:   1703/  8460 | loss: 0.4559 | ds_loss: 0.0000 | lr: 4.5166e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1704/  8460 | global iter:   1704/  8460 | loss: 0.8368 | ds_loss: 0.0000 | lr: 4.5161e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1704/  8460 | global iter:   1704/  8460 | loss: 0.5232 | ds_loss: 0.0000 | lr: 4.5161e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1705/  8460 | global iter:   1705/  8460 | loss: 0.6530 | ds_loss: 0.0000 | lr: 4.5155e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   1706/  8460 | global iter:   1706/  8460 | loss: 0.2821 | ds_loss: 0.0000 | lr: 4.5150e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1707/  8460 | global iter:   1707/  8460 | loss: 0.4449 | ds_loss: 0.0000 | lr: 4.5144e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1708/  8460 | global iter:   1708/  8460 | loss: 0.3158 | ds_loss: 0.0000 | lr: 4.5139e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1708/  8460 | global iter:   1708/  8460 | loss: 0.4239 | ds_loss: 0.0000 | lr: 4.5139e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1709/  8460 | global iter:   1709/  8460 | loss: 0.3823 | ds_loss: 0.0000 | lr: 4.5133e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   1710/  8460 | global iter:   1710/  8460 | loss: 0.2998 | ds_loss: 0.0000 | lr: 4.5128e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   1711/  8460 | global iter:   1711/  8460 | loss: 0.4936 | ds_loss: 0.0000 | lr: 4.5122e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   1712/  8460 | global iter:   1712/  8460 | loss: 0.3463 | ds_loss: 0.0000 | lr: 4.5117e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1712/  8460 | global iter:   1712/  8460 | loss: 0.3805 | ds_loss: 0.0000 | lr: 4.5117e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1713/  8460 | global iter:   1713/  8460 | loss: 0.6754 | ds_loss: 0.0000 | lr: 4.5111e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1714/  8460 | global iter:   1714/  8460 | loss: 0.7779 | ds_loss: 0.0000 | lr: 4.5106e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1715/  8460 | global iter:   1715/  8460 | loss: 0.1346 | ds_loss: 0.0000 | lr: 4.5100e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1716/  8460 | global iter:   1716/  8460 | loss: 0.7696 | ds_loss: 0.0000 | lr: 4.5095e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1716/  8460 | global iter:   1716/  8460 | loss: 0.5894 | ds_loss: 0.0000 | lr: 4.5095e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1717/  8460 | global iter:   1717/  8460 | loss: 0.1921 | ds_loss: 0.0000 | lr: 4.5089e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1718/  8460 | global iter:   1718/  8460 | loss: 0.8348 | ds_loss: 0.0000 | lr: 4.5084e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1719/  8460 | global iter:   1719/  8460 | loss: 0.3430 | ds_loss: 0.0000 | lr: 4.5078e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1720/  8460 | global iter:   1720/  8460 | loss: 0.5800 | ds_loss: 0.0000 | lr: 4.5073e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1720/  8460 | global iter:   1720/  8460 | loss: 0.4875 | ds_loss: 0.0000 | lr: 4.5073e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1721/  8460 | global iter:   1721/  8460 | loss: 0.8497 | ds_loss: 0.0000 | lr: 4.5067e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1722/  8460 | global iter:   1722/  8460 | loss: 0.7718 | ds_loss: 0.0000 | lr: 4.5061e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1723/  8460 | global iter:   1723/  8460 | loss: 0.7297 | ds_loss: 0.0000 | lr: 4.5056e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1724/  8460 | global iter:   1724/  8460 | loss: 0.3621 | ds_loss: 0.0000 | lr: 4.5050e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1724/  8460 | global iter:   1724/  8460 | loss: 0.6783 | ds_loss: 0.0000 | lr: 4.5050e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1725/  8460 | global iter:   1725/  8460 | loss: 0.3443 | ds_loss: 0.0000 | lr: 4.5045e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1726/  8460 | global iter:   1726/  8460 | loss: 1.0008 | ds_loss: 0.0000 | lr: 4.5039e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1727/  8460 | global iter:   1727/  8460 | loss: 0.4903 | ds_loss: 0.0000 | lr: 4.5034e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1728/  8460 | global iter:   1728/  8460 | loss: 0.9284 | ds_loss: 0.0000 | lr: 4.5028e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1728/  8460 | global iter:   1728/  8460 | loss: 0.6910 | ds_loss: 0.0000 | lr: 4.5028e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1729/  8460 | global iter:   1729/  8460 | loss: 0.2961 | ds_loss: 0.0000 | lr: 4.5023e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1730/  8460 | global iter:   1730/  8460 | loss: 0.1197 | ds_loss: 0.0000 | lr: 4.5017e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1731/  8460 | global iter:   1731/  8460 | loss: 0.7714 | ds_loss: 0.0000 | lr: 4.5011e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1732/  8460 | global iter:   1732/  8460 | loss: 0.1596 | ds_loss: 0.0000 | lr: 4.5006e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1732/  8460 | global iter:   1732/  8460 | loss: 0.3367 | ds_loss: 0.0000 | lr: 4.5006e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1733/  8460 | global iter:   1733/  8460 | loss: 0.4112 | ds_loss: 0.0000 | lr: 4.5000e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   1734/  8460 | global iter:   1734/  8460 | loss: 0.4978 | ds_loss: 0.0000 | lr: 4.4995e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1735/  8460 | global iter:   1735/  8460 | loss: 0.1764 | ds_loss: 0.0000 | lr: 4.4989e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1736/  8460 | global iter:   1736/  8460 | loss: 0.4828 | ds_loss: 0.0000 | lr: 4.4984e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1736/  8460 | global iter:   1736/  8460 | loss: 0.3921 | ds_loss: 0.0000 | lr: 4.4984e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1737/  8460 | global iter:   1737/  8460 | loss: 0.6945 | ds_loss: 0.0000 | lr: 4.4978e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1738/  8460 | global iter:   1738/  8460 | loss: 0.3945 | ds_loss: 0.0000 | lr: 4.4972e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1739/  8460 | global iter:   1739/  8460 | loss: 0.7157 | ds_loss: 0.0000 | lr: 4.4967e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1740/  8460 | global iter:   1740/  8460 | loss: 0.7912 | ds_loss: 0.0000 | lr: 4.4961e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1740/  8460 | global iter:   1740/  8460 | loss: 0.6490 | ds_loss: 0.0000 | lr: 4.4961e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1741/  8460 | global iter:   1741/  8460 | loss: 0.2496 | ds_loss: 0.0000 | lr: 4.4956e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1742/  8460 | global iter:   1742/  8460 | loss: 0.4042 | ds_loss: 0.0000 | lr: 4.4950e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1743/  8460 | global iter:   1743/  8460 | loss: 0.4474 | ds_loss: 0.0000 | lr: 4.4945e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1744/  8460 | global iter:   1744/  8460 | loss: 0.7264 | ds_loss: 0.0000 | lr: 4.4939e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1744/  8460 | global iter:   1744/  8460 | loss: 0.4569 | ds_loss: 0.0000 | lr: 4.4939e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1745/  8460 | global iter:   1745/  8460 | loss: 0.2264 | ds_loss: 0.0000 | lr: 4.4933e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1746/  8460 | global iter:   1746/  8460 | loss: 0.3059 | ds_loss: 0.0000 | lr: 4.4928e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1747/  8460 | global iter:   1747/  8460 | loss: 0.7711 | ds_loss: 0.0000 | lr: 4.4922e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1748/  8460 | global iter:   1748/  8460 | loss: 0.2515 | ds_loss: 0.0000 | lr: 4.4917e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1748/  8460 | global iter:   1748/  8460 | loss: 0.3887 | ds_loss: 0.0000 | lr: 4.4917e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1749/  8460 | global iter:   1749/  8460 | loss: 0.3417 | ds_loss: 0.0000 | lr: 4.4911e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1750/  8460 | global iter:   1750/  8460 | loss: 0.3897 | ds_loss: 0.0000 | lr: 4.4905e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1751/  8460 | global iter:   1751/  8460 | loss: 1.0713 | ds_loss: 0.0000 | lr: 4.4900e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1752/  8460 | global iter:   1752/  8460 | loss: 0.1672 | ds_loss: 0.0000 | lr: 4.4894e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1752/  8460 | global iter:   1752/  8460 | loss: 0.4925 | ds_loss: 0.0000 | lr: 4.4894e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1753/  8460 | global iter:   1753/  8460 | loss: 0.6545 | ds_loss: 0.0000 | lr: 4.4888e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1754/  8460 | global iter:   1754/  8460 | loss: 0.1236 | ds_loss: 0.0000 | lr: 4.4883e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1755/  8460 | global iter:   1755/  8460 | loss: 0.4895 | ds_loss: 0.0000 | lr: 4.4877e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1756/  8460 | global iter:   1756/  8460 | loss: 0.2476 | ds_loss: 0.0000 | lr: 4.4872e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1756/  8460 | global iter:   1756/  8460 | loss: 0.3788 | ds_loss: 0.0000 | lr: 4.4872e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1757/  8460 | global iter:   1757/  8460 | loss: 0.2421 | ds_loss: 0.0000 | lr: 4.4866e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   1758/  8460 | global iter:   1758/  8460 | loss: 0.4852 | ds_loss: 0.0000 | lr: 4.4860e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   1759/  8460 | global iter:   1759/  8460 | loss: 0.4354 | ds_loss: 0.0000 | lr: 4.4855e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1760/  8460 | global iter:   1760/  8460 | loss: 0.7614 | ds_loss: 0.0000 | lr: 4.4849e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1760/  8460 | global iter:   1760/  8460 | loss: 0.4810 | ds_loss: 0.0000 | lr: 4.4849e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1761/  8460 | global iter:   1761/  8460 | loss: 0.5364 | ds_loss: 0.0000 | lr: 4.4843e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1762/  8460 | global iter:   1762/  8460 | loss: 0.3302 | ds_loss: 0.0000 | lr: 4.4838e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1763/  8460 | global iter:   1763/  8460 | loss: 0.2085 | ds_loss: 0.0000 | lr: 4.4832e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1764/  8460 | global iter:   1764/  8460 | loss: 0.5061 | ds_loss: 0.0000 | lr: 4.4826e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1764/  8460 | global iter:   1764/  8460 | loss: 0.3953 | ds_loss: 0.0000 | lr: 4.4826e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1765/  8460 | global iter:   1765/  8460 | loss: 0.4056 | ds_loss: 0.0000 | lr: 4.4821e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1766/  8460 | global iter:   1766/  8460 | loss: 0.5918 | ds_loss: 0.0000 | lr: 4.4815e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1767/  8460 | global iter:   1767/  8460 | loss: 0.1865 | ds_loss: 0.0000 | lr: 4.4809e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   1768/  8460 | global iter:   1768/  8460 | loss: 0.4243 | ds_loss: 0.0000 | lr: 4.4804e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1768/  8460 | global iter:   1768/  8460 | loss: 0.4021 | ds_loss: 0.0000 | lr: 4.4804e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1769/  8460 | global iter:   1769/  8460 | loss: 1.0887 | ds_loss: 0.0000 | lr: 4.4798e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1770/  8460 | global iter:   1770/  8460 | loss: 0.1962 | ds_loss: 0.0000 | lr: 4.4792e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1771/  8460 | global iter:   1771/  8460 | loss: 0.8794 | ds_loss: 0.0000 | lr: 4.4787e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1772/  8460 | global iter:   1772/  8460 | loss: 0.8272 | ds_loss: 0.0000 | lr: 4.4781e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1772/  8460 | global iter:   1772/  8460 | loss: 0.7479 | ds_loss: 0.0000 | lr: 4.4781e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1773/  8460 | global iter:   1773/  8460 | loss: 0.2725 | ds_loss: 0.0000 | lr: 4.4775e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1774/  8460 | global iter:   1774/  8460 | loss: 0.3804 | ds_loss: 0.0000 | lr: 4.4770e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1775/  8460 | global iter:   1775/  8460 | loss: 0.5576 | ds_loss: 0.0000 | lr: 4.4764e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1776/  8460 | global iter:   1776/  8460 | loss: 1.3094 | ds_loss: 0.0000 | lr: 4.4758e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1776/  8460 | global iter:   1776/  8460 | loss: 0.6300 | ds_loss: 0.0000 | lr: 4.4758e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1777/  8460 | global iter:   1777/  8460 | loss: 0.3990 | ds_loss: 0.0000 | lr: 4.4753e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1778/  8460 | global iter:   1778/  8460 | loss: 0.6589 | ds_loss: 0.0000 | lr: 4.4747e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1779/  8460 | global iter:   1779/  8460 | loss: 0.8715 | ds_loss: 0.0000 | lr: 4.4741e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1780/  8460 | global iter:   1780/  8460 | loss: 0.3800 | ds_loss: 0.0000 | lr: 4.4736e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1780/  8460 | global iter:   1780/  8460 | loss: 0.5774 | ds_loss: 0.0000 | lr: 4.4736e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1781/  8460 | global iter:   1781/  8460 | loss: 0.8587 | ds_loss: 0.0000 | lr: 4.4730e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1782/  8460 | global iter:   1782/  8460 | loss: 0.1825 | ds_loss: 0.0000 | lr: 4.4724e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1783/  8460 | global iter:   1783/  8460 | loss: 0.2623 | ds_loss: 0.0000 | lr: 4.4718e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1784/  8460 | global iter:   1784/  8460 | loss: 0.3444 | ds_loss: 0.0000 | lr: 4.4713e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1784/  8460 | global iter:   1784/  8460 | loss: 0.4120 | ds_loss: 0.0000 | lr: 4.4713e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1785/  8460 | global iter:   1785/  8460 | loss: 0.4116 | ds_loss: 0.0000 | lr: 4.4707e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1786/  8460 | global iter:   1786/  8460 | loss: 0.3311 | ds_loss: 0.0000 | lr: 4.4701e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1787/  8460 | global iter:   1787/  8460 | loss: 1.0378 | ds_loss: 0.0000 | lr: 4.4696e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1788/  8460 | global iter:   1788/  8460 | loss: 0.8160 | ds_loss: 0.0000 | lr: 4.4690e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1788/  8460 | global iter:   1788/  8460 | loss: 0.6491 | ds_loss: 0.0000 | lr: 4.4690e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1789/  8460 | global iter:   1789/  8460 | loss: 0.3392 | ds_loss: 0.0000 | lr: 4.4684e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1790/  8460 | global iter:   1790/  8460 | loss: 0.2991 | ds_loss: 0.0000 | lr: 4.4678e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1791/  8460 | global iter:   1791/  8460 | loss: 0.3775 | ds_loss: 0.0000 | lr: 4.4673e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1792/  8460 | global iter:   1792/  8460 | loss: 0.4947 | ds_loss: 0.0000 | lr: 4.4667e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1792/  8460 | global iter:   1792/  8460 | loss: 0.3777 | ds_loss: 0.0000 | lr: 4.4667e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1793/  8460 | global iter:   1793/  8460 | loss: 0.8847 | ds_loss: 0.0000 | lr: 4.4661e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1794/  8460 | global iter:   1794/  8460 | loss: 0.2327 | ds_loss: 0.0000 | lr: 4.4656e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1795/  8460 | global iter:   1795/  8460 | loss: 0.2504 | ds_loss: 0.0000 | lr: 4.4650e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1796/  8460 | global iter:   1796/  8460 | loss: 0.6187 | ds_loss: 0.0000 | lr: 4.4644e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1796/  8460 | global iter:   1796/  8460 | loss: 0.4966 | ds_loss: 0.0000 | lr: 4.4644e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1797/  8460 | global iter:   1797/  8460 | loss: 0.2151 | ds_loss: 0.0000 | lr: 4.4638e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1798/  8460 | global iter:   1798/  8460 | loss: 0.1391 | ds_loss: 0.0000 | lr: 4.4633e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1799/  8460 | global iter:   1799/  8460 | loss: 0.5319 | ds_loss: 0.0000 | lr: 4.4627e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1800/  8460 | global iter:   1800/  8460 | loss: 0.2415 | ds_loss: 0.0000 | lr: 4.4621e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1800/  8460 | global iter:   1800/  8460 | loss: 0.2819 | ds_loss: 0.0000 | lr: 4.4621e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1801/  8460 | global iter:   1801/  8460 | loss: 0.3518 | ds_loss: 0.0000 | lr: 4.4615e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1802/  8460 | global iter:   1802/  8460 | loss: 0.3073 | ds_loss: 0.0000 | lr: 4.4610e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1803/  8460 | global iter:   1803/  8460 | loss: 0.3775 | ds_loss: 0.0000 | lr: 4.4604e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1804/  8460 | global iter:   1804/  8460 | loss: 0.7144 | ds_loss: 0.0000 | lr: 4.4598e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1804/  8460 | global iter:   1804/  8460 | loss: 0.4377 | ds_loss: 0.0000 | lr: 4.4598e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1805/  8460 | global iter:   1805/  8460 | loss: 0.1562 | ds_loss: 0.0000 | lr: 4.4592e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1806/  8460 | global iter:   1806/  8460 | loss: 0.5514 | ds_loss: 0.0000 | lr: 4.4586e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1807/  8460 | global iter:   1807/  8460 | loss: 0.3448 | ds_loss: 0.0000 | lr: 4.4581e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1808/  8460 | global iter:   1808/  8460 | loss: 0.7494 | ds_loss: 0.0000 | lr: 4.4575e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1808/  8460 | global iter:   1808/  8460 | loss: 0.4505 | ds_loss: 0.0000 | lr: 4.4575e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1809/  8460 | global iter:   1809/  8460 | loss: 0.6290 | ds_loss: 0.0000 | lr: 4.4569e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1810/  8460 | global iter:   1810/  8460 | loss: 0.4514 | ds_loss: 0.0000 | lr: 4.4563e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1811/  8460 | global iter:   1811/  8460 | loss: 0.3328 | ds_loss: 0.0000 | lr: 4.4558e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1812/  8460 | global iter:   1812/  8460 | loss: 1.2334 | ds_loss: 0.0000 | lr: 4.4552e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1812/  8460 | global iter:   1812/  8460 | loss: 0.6617 | ds_loss: 0.0000 | lr: 4.4552e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1813/  8460 | global iter:   1813/  8460 | loss: 0.1893 | ds_loss: 0.0000 | lr: 4.4546e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1814/  8460 | global iter:   1814/  8460 | loss: 0.8504 | ds_loss: 0.0000 | lr: 4.4540e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1815/  8460 | global iter:   1815/  8460 | loss: 0.9699 | ds_loss: 0.0000 | lr: 4.4534e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1816/  8460 | global iter:   1816/  8460 | loss: 0.8039 | ds_loss: 0.0000 | lr: 4.4529e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1816/  8460 | global iter:   1816/  8460 | loss: 0.7034 | ds_loss: 0.0000 | lr: 4.4529e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1817/  8460 | global iter:   1817/  8460 | loss: 0.7226 | ds_loss: 0.0000 | lr: 4.4523e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1818/  8460 | global iter:   1818/  8460 | loss: 0.3621 | ds_loss: 0.0000 | lr: 4.4517e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1819/  8460 | global iter:   1819/  8460 | loss: 0.5204 | ds_loss: 0.0000 | lr: 4.4511e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1820/  8460 | global iter:   1820/  8460 | loss: 1.0362 | ds_loss: 0.0000 | lr: 4.4505e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1820/  8460 | global iter:   1820/  8460 | loss: 0.6603 | ds_loss: 0.0000 | lr: 4.4505e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1821/  8460 | global iter:   1821/  8460 | loss: 0.2024 | ds_loss: 0.0000 | lr: 4.4500e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1822/  8460 | global iter:   1822/  8460 | loss: 0.3926 | ds_loss: 0.0000 | lr: 4.4494e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1823/  8460 | global iter:   1823/  8460 | loss: 0.8064 | ds_loss: 0.0000 | lr: 4.4488e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   1824/  8460 | global iter:   1824/  8460 | loss: 0.5844 | ds_loss: 0.0000 | lr: 4.4482e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1824/  8460 | global iter:   1824/  8460 | loss: 0.4965 | ds_loss: 0.0000 | lr: 4.4482e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1825/  8460 | global iter:   1825/  8460 | loss: 0.2723 | ds_loss: 0.0000 | lr: 4.4476e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1826/  8460 | global iter:   1826/  8460 | loss: 0.4845 | ds_loss: 0.0000 | lr: 4.4471e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1827/  8460 | global iter:   1827/  8460 | loss: 0.8934 | ds_loss: 0.0000 | lr: 4.4465e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1828/  8460 | global iter:   1828/  8460 | loss: 0.4031 | ds_loss: 0.0000 | lr: 4.4459e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1828/  8460 | global iter:   1828/  8460 | loss: 0.5133 | ds_loss: 0.0000 | lr: 4.4459e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1829/  8460 | global iter:   1829/  8460 | loss: 0.4468 | ds_loss: 0.0000 | lr: 4.4453e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1830/  8460 | global iter:   1830/  8460 | loss: 0.8274 | ds_loss: 0.0000 | lr: 4.4447e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1831/  8460 | global iter:   1831/  8460 | loss: 0.4280 | ds_loss: 0.0000 | lr: 4.4441e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1832/  8460 | global iter:   1832/  8460 | loss: 0.8613 | ds_loss: 0.0000 | lr: 4.4436e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1832/  8460 | global iter:   1832/  8460 | loss: 0.6409 | ds_loss: 0.0000 | lr: 4.4436e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1833/  8460 | global iter:   1833/  8460 | loss: 0.4677 | ds_loss: 0.0000 | lr: 4.4430e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1834/  8460 | global iter:   1834/  8460 | loss: 0.4414 | ds_loss: 0.0000 | lr: 4.4424e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1835/  8460 | global iter:   1835/  8460 | loss: 0.4030 | ds_loss: 0.0000 | lr: 4.4418e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1836/  8460 | global iter:   1836/  8460 | loss: 0.7363 | ds_loss: 0.0000 | lr: 4.4412e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1836/  8460 | global iter:   1836/  8460 | loss: 0.5121 | ds_loss: 0.0000 | lr: 4.4412e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1837/  8460 | global iter:   1837/  8460 | loss: 0.5890 | ds_loss: 0.0000 | lr: 4.4406e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1838/  8460 | global iter:   1838/  8460 | loss: 0.4015 | ds_loss: 0.0000 | lr: 4.4401e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1839/  8460 | global iter:   1839/  8460 | loss: 0.9468 | ds_loss: 0.0000 | lr: 4.4395e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1840/  8460 | global iter:   1840/  8460 | loss: 0.1280 | ds_loss: 0.0000 | lr: 4.4389e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1840/  8460 | global iter:   1840/  8460 | loss: 0.5163 | ds_loss: 0.0000 | lr: 4.4389e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1841/  8460 | global iter:   1841/  8460 | loss: 1.0017 | ds_loss: 0.0000 | lr: 4.4383e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1842/  8460 | global iter:   1842/  8460 | loss: 0.5181 | ds_loss: 0.0000 | lr: 4.4377e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1843/  8460 | global iter:   1843/  8460 | loss: 0.8846 | ds_loss: 0.0000 | lr: 4.4371e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1844/  8460 | global iter:   1844/  8460 | loss: 0.2533 | ds_loss: 0.0000 | lr: 4.4365e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1844/  8460 | global iter:   1844/  8460 | loss: 0.6644 | ds_loss: 0.0000 | lr: 4.4365e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1845/  8460 | global iter:   1845/  8460 | loss: 0.4923 | ds_loss: 0.0000 | lr: 4.4359e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1846/  8460 | global iter:   1846/  8460 | loss: 0.4565 | ds_loss: 0.0000 | lr: 4.4354e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1847/  8460 | global iter:   1847/  8460 | loss: 0.8176 | ds_loss: 0.0000 | lr: 4.4348e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1848/  8460 | global iter:   1848/  8460 | loss: 0.4070 | ds_loss: 0.0000 | lr: 4.4342e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1848/  8460 | global iter:   1848/  8460 | loss: 0.5433 | ds_loss: 0.0000 | lr: 4.4342e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1849/  8460 | global iter:   1849/  8460 | loss: 0.3760 | ds_loss: 0.0000 | lr: 4.4336e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1850/  8460 | global iter:   1850/  8460 | loss: 1.1439 | ds_loss: 0.0000 | lr: 4.4330e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1851/  8460 | global iter:   1851/  8460 | loss: 0.2246 | ds_loss: 0.0000 | lr: 4.4324e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   1852/  8460 | global iter:   1852/  8460 | loss: 0.4035 | ds_loss: 0.0000 | lr: 4.4318e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1852/  8460 | global iter:   1852/  8460 | loss: 0.5370 | ds_loss: 0.0000 | lr: 4.4318e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1853/  8460 | global iter:   1853/  8460 | loss: 0.3576 | ds_loss: 0.0000 | lr: 4.4312e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1854/  8460 | global iter:   1854/  8460 | loss: 0.4799 | ds_loss: 0.0000 | lr: 4.4307e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1855/  8460 | global iter:   1855/  8460 | loss: 1.1260 | ds_loss: 0.0000 | lr: 4.4301e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1856/  8460 | global iter:   1856/  8460 | loss: 0.6837 | ds_loss: 0.0000 | lr: 4.4295e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1856/  8460 | global iter:   1856/  8460 | loss: 0.6618 | ds_loss: 0.0000 | lr: 4.4295e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1857/  8460 | global iter:   1857/  8460 | loss: 0.2664 | ds_loss: 0.0000 | lr: 4.4289e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1858/  8460 | global iter:   1858/  8460 | loss: 0.4097 | ds_loss: 0.0000 | lr: 4.4283e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1859/  8460 | global iter:   1859/  8460 | loss: 0.2110 | ds_loss: 0.0000 | lr: 4.4277e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1860/  8460 | global iter:   1860/  8460 | loss: 0.1579 | ds_loss: 0.0000 | lr: 4.4271e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1860/  8460 | global iter:   1860/  8460 | loss: 0.2613 | ds_loss: 0.0000 | lr: 4.4271e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1861/  8460 | global iter:   1861/  8460 | loss: 0.7751 | ds_loss: 0.0000 | lr: 4.4265e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1862/  8460 | global iter:   1862/  8460 | loss: 0.2317 | ds_loss: 0.0000 | lr: 4.4259e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1863/  8460 | global iter:   1863/  8460 | loss: 0.2666 | ds_loss: 0.0000 | lr: 4.4253e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1864/  8460 | global iter:   1864/  8460 | loss: 0.3726 | ds_loss: 0.0000 | lr: 4.4247e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1864/  8460 | global iter:   1864/  8460 | loss: 0.4115 | ds_loss: 0.0000 | lr: 4.4247e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1865/  8460 | global iter:   1865/  8460 | loss: 0.4307 | ds_loss: 0.0000 | lr: 4.4241e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1866/  8460 | global iter:   1866/  8460 | loss: 0.2238 | ds_loss: 0.0000 | lr: 4.4236e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1867/  8460 | global iter:   1867/  8460 | loss: 0.8325 | ds_loss: 0.0000 | lr: 4.4230e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1868/  8460 | global iter:   1868/  8460 | loss: 0.8174 | ds_loss: 0.0000 | lr: 4.4224e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1868/  8460 | global iter:   1868/  8460 | loss: 0.5761 | ds_loss: 0.0000 | lr: 4.4224e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1869/  8460 | global iter:   1869/  8460 | loss: 0.4897 | ds_loss: 0.0000 | lr: 4.4218e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1870/  8460 | global iter:   1870/  8460 | loss: 0.7010 | ds_loss: 0.0000 | lr: 4.4212e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1871/  8460 | global iter:   1871/  8460 | loss: 0.3900 | ds_loss: 0.0000 | lr: 4.4206e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1872/  8460 | global iter:   1872/  8460 | loss: 0.8711 | ds_loss: 0.0000 | lr: 4.4200e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1872/  8460 | global iter:   1872/  8460 | loss: 0.6129 | ds_loss: 0.0000 | lr: 4.4200e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1873/  8460 | global iter:   1873/  8460 | loss: 0.6891 | ds_loss: 0.0000 | lr: 4.4194e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1874/  8460 | global iter:   1874/  8460 | loss: 0.5882 | ds_loss: 0.0000 | lr: 4.4188e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1875/  8460 | global iter:   1875/  8460 | loss: 1.1122 | ds_loss: 0.0000 | lr: 4.4182e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1876/  8460 | global iter:   1876/  8460 | loss: 0.5689 | ds_loss: 0.0000 | lr: 4.4176e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1876/  8460 | global iter:   1876/  8460 | loss: 0.7396 | ds_loss: 0.0000 | lr: 4.4176e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1877/  8460 | global iter:   1877/  8460 | loss: 0.4205 | ds_loss: 0.0000 | lr: 4.4170e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1878/  8460 | global iter:   1878/  8460 | loss: 0.3537 | ds_loss: 0.0000 | lr: 4.4164e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1879/  8460 | global iter:   1879/  8460 | loss: 0.4902 | ds_loss: 0.0000 | lr: 4.4158e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1880/  8460 | global iter:   1880/  8460 | loss: 0.8999 | ds_loss: 0.0000 | lr: 4.4152e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1880/  8460 | global iter:   1880/  8460 | loss: 0.5411 | ds_loss: 0.0000 | lr: 4.4152e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1881/  8460 | global iter:   1881/  8460 | loss: 0.7492 | ds_loss: 0.0000 | lr: 4.4146e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1882/  8460 | global iter:   1882/  8460 | loss: 0.4673 | ds_loss: 0.0000 | lr: 4.4140e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1883/  8460 | global iter:   1883/  8460 | loss: 0.5728 | ds_loss: 0.0000 | lr: 4.4134e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1884/  8460 | global iter:   1884/  8460 | loss: 0.4067 | ds_loss: 0.0000 | lr: 4.4128e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1884/  8460 | global iter:   1884/  8460 | loss: 0.5490 | ds_loss: 0.0000 | lr: 4.4128e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1885/  8460 | global iter:   1885/  8460 | loss: 1.0120 | ds_loss: 0.0000 | lr: 4.4122e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1886/  8460 | global iter:   1886/  8460 | loss: 0.6554 | ds_loss: 0.0000 | lr: 4.4116e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1887/  8460 | global iter:   1887/  8460 | loss: 0.3086 | ds_loss: 0.0000 | lr: 4.4110e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1888/  8460 | global iter:   1888/  8460 | loss: 0.3954 | ds_loss: 0.0000 | lr: 4.4104e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1888/  8460 | global iter:   1888/  8460 | loss: 0.5928 | ds_loss: 0.0000 | lr: 4.4104e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1889/  8460 | global iter:   1889/  8460 | loss: 0.5510 | ds_loss: 0.0000 | lr: 4.4098e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1890/  8460 | global iter:   1890/  8460 | loss: 0.4346 | ds_loss: 0.0000 | lr: 4.4092e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1891/  8460 | global iter:   1891/  8460 | loss: 0.3923 | ds_loss: 0.0000 | lr: 4.4086e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1892/  8460 | global iter:   1892/  8460 | loss: 0.2551 | ds_loss: 0.0000 | lr: 4.4080e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1892/  8460 | global iter:   1892/  8460 | loss: 0.4082 | ds_loss: 0.0000 | lr: 4.4080e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1893/  8460 | global iter:   1893/  8460 | loss: 1.1411 | ds_loss: 0.0000 | lr: 4.4074e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1894/  8460 | global iter:   1894/  8460 | loss: 0.4393 | ds_loss: 0.0000 | lr: 4.4068e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1895/  8460 | global iter:   1895/  8460 | loss: 0.4243 | ds_loss: 0.0000 | lr: 4.4062e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1896/  8460 | global iter:   1896/  8460 | loss: 0.5268 | ds_loss: 0.0000 | lr: 4.4056e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1896/  8460 | global iter:   1896/  8460 | loss: 0.6329 | ds_loss: 0.0000 | lr: 4.4056e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1897/  8460 | global iter:   1897/  8460 | loss: 0.7536 | ds_loss: 0.0000 | lr: 4.4050e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1898/  8460 | global iter:   1898/  8460 | loss: 0.9829 | ds_loss: 0.0000 | lr: 4.4044e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   1899/  8460 | global iter:   1899/  8460 | loss: 0.4767 | ds_loss: 0.0000 | lr: 4.4038e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   1900/  8460 | global iter:   1900/  8460 | loss: 0.7015 | ds_loss: 0.0000 | lr: 4.4032e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1900/  8460 | global iter:   1900/  8460 | loss: 0.7287 | ds_loss: 0.0000 | lr: 4.4032e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1901/  8460 | global iter:   1901/  8460 | loss: 0.3964 | ds_loss: 0.0000 | lr: 4.4026e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1902/  8460 | global iter:   1902/  8460 | loss: 1.0792 | ds_loss: 0.0000 | lr: 4.4020e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1903/  8460 | global iter:   1903/  8460 | loss: 0.1720 | ds_loss: 0.0000 | lr: 4.4014e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1904/  8460 | global iter:   1904/  8460 | loss: 0.5451 | ds_loss: 0.0000 | lr: 4.4008e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1904/  8460 | global iter:   1904/  8460 | loss: 0.5482 | ds_loss: 0.0000 | lr: 4.4008e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1905/  8460 | global iter:   1905/  8460 | loss: 0.2244 | ds_loss: 0.0000 | lr: 4.4002e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1906/  8460 | global iter:   1906/  8460 | loss: 0.6578 | ds_loss: 0.0000 | lr: 4.3996e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1907/  8460 | global iter:   1907/  8460 | loss: 0.7657 | ds_loss: 0.0000 | lr: 4.3990e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1908/  8460 | global iter:   1908/  8460 | loss: 1.5252 | ds_loss: 0.0000 | lr: 4.3984e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1908/  8460 | global iter:   1908/  8460 | loss: 0.7932 | ds_loss: 0.0000 | lr: 4.3984e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1909/  8460 | global iter:   1909/  8460 | loss: 0.2653 | ds_loss: 0.0000 | lr: 4.3978e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1910/  8460 | global iter:   1910/  8460 | loss: 0.7057 | ds_loss: 0.0000 | lr: 4.3972e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   1911/  8460 | global iter:   1911/  8460 | loss: 0.6241 | ds_loss: 0.0000 | lr: 4.3966e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1912/  8460 | global iter:   1912/  8460 | loss: 0.1595 | ds_loss: 0.0000 | lr: 4.3960e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1912/  8460 | global iter:   1912/  8460 | loss: 0.4386 | ds_loss: 0.0000 | lr: 4.3960e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1913/  8460 | global iter:   1913/  8460 | loss: 0.5260 | ds_loss: 0.0000 | lr: 4.3954e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1914/  8460 | global iter:   1914/  8460 | loss: 1.1588 | ds_loss: 0.0000 | lr: 4.3948e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1915/  8460 | global iter:   1915/  8460 | loss: 0.6911 | ds_loss: 0.0000 | lr: 4.3942e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1916/  8460 | global iter:   1916/  8460 | loss: 0.6632 | ds_loss: 0.0000 | lr: 4.3936e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1916/  8460 | global iter:   1916/  8460 | loss: 0.7598 | ds_loss: 0.0000 | lr: 4.3936e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1917/  8460 | global iter:   1917/  8460 | loss: 0.8133 | ds_loss: 0.0000 | lr: 4.3930e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   1918/  8460 | global iter:   1918/  8460 | loss: 0.5360 | ds_loss: 0.0000 | lr: 4.3924e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1919/  8460 | global iter:   1919/  8460 | loss: 0.3547 | ds_loss: 0.0000 | lr: 4.3918e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1920/  8460 | global iter:   1920/  8460 | loss: 0.7069 | ds_loss: 0.0000 | lr: 4.3912e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1920/  8460 | global iter:   1920/  8460 | loss: 0.6028 | ds_loss: 0.0000 | lr: 4.3912e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1921/  8460 | global iter:   1921/  8460 | loss: 0.2232 | ds_loss: 0.0000 | lr: 4.3905e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1922/  8460 | global iter:   1922/  8460 | loss: 0.9099 | ds_loss: 0.0000 | lr: 4.3899e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1923/  8460 | global iter:   1923/  8460 | loss: 0.7247 | ds_loss: 0.0000 | lr: 4.3893e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1924/  8460 | global iter:   1924/  8460 | loss: 0.4961 | ds_loss: 0.0000 | lr: 4.3887e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1924/  8460 | global iter:   1924/  8460 | loss: 0.5885 | ds_loss: 0.0000 | lr: 4.3887e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1925/  8460 | global iter:   1925/  8460 | loss: 0.2843 | ds_loss: 0.0000 | lr: 4.3881e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1926/  8460 | global iter:   1926/  8460 | loss: 0.4731 | ds_loss: 0.0000 | lr: 4.3875e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1927/  8460 | global iter:   1927/  8460 | loss: 0.4105 | ds_loss: 0.0000 | lr: 4.3869e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1928/  8460 | global iter:   1928/  8460 | loss: 0.2594 | ds_loss: 0.0000 | lr: 4.3863e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1928/  8460 | global iter:   1928/  8460 | loss: 0.3568 | ds_loss: 0.0000 | lr: 4.3863e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1929/  8460 | global iter:   1929/  8460 | loss: 0.4015 | ds_loss: 0.0000 | lr: 4.3857e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1930/  8460 | global iter:   1930/  8460 | loss: 0.7590 | ds_loss: 0.0000 | lr: 4.3851e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1931/  8460 | global iter:   1931/  8460 | loss: 0.5197 | ds_loss: 0.0000 | lr: 4.3845e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   1932/  8460 | global iter:   1932/  8460 | loss: 0.6135 | ds_loss: 0.0000 | lr: 4.3838e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1932/  8460 | global iter:   1932/  8460 | loss: 0.5734 | ds_loss: 0.0000 | lr: 4.3838e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1933/  8460 | global iter:   1933/  8460 | loss: 0.6276 | ds_loss: 0.0000 | lr: 4.3832e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1934/  8460 | global iter:   1934/  8460 | loss: 0.5920 | ds_loss: 0.0000 | lr: 4.3826e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1935/  8460 | global iter:   1935/  8460 | loss: 0.3452 | ds_loss: 0.0000 | lr: 4.3820e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1936/  8460 | global iter:   1936/  8460 | loss: 0.2388 | ds_loss: 0.0000 | lr: 4.3814e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1936/  8460 | global iter:   1936/  8460 | loss: 0.4509 | ds_loss: 0.0000 | lr: 4.3814e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1937/  8460 | global iter:   1937/  8460 | loss: 0.4112 | ds_loss: 0.0000 | lr: 4.3808e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1938/  8460 | global iter:   1938/  8460 | loss: 0.4794 | ds_loss: 0.0000 | lr: 4.3802e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1939/  8460 | global iter:   1939/  8460 | loss: 0.6188 | ds_loss: 0.0000 | lr: 4.3796e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1940/  8460 | global iter:   1940/  8460 | loss: 0.4743 | ds_loss: 0.0000 | lr: 4.3790e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1940/  8460 | global iter:   1940/  8460 | loss: 0.4959 | ds_loss: 0.0000 | lr: 4.3790e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1941/  8460 | global iter:   1941/  8460 | loss: 0.7281 | ds_loss: 0.0000 | lr: 4.3783e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1942/  8460 | global iter:   1942/  8460 | loss: 0.3988 | ds_loss: 0.0000 | lr: 4.3777e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1943/  8460 | global iter:   1943/  8460 | loss: 0.7644 | ds_loss: 0.0000 | lr: 4.3771e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1944/  8460 | global iter:   1944/  8460 | loss: 0.4257 | ds_loss: 0.0000 | lr: 4.3765e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1944/  8460 | global iter:   1944/  8460 | loss: 0.5792 | ds_loss: 0.0000 | lr: 4.3765e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1945/  8460 | global iter:   1945/  8460 | loss: 0.7711 | ds_loss: 0.0000 | lr: 4.3759e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1946/  8460 | global iter:   1946/  8460 | loss: 0.6684 | ds_loss: 0.0000 | lr: 4.3753e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1947/  8460 | global iter:   1947/  8460 | loss: 0.2512 | ds_loss: 0.0000 | lr: 4.3747e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1948/  8460 | global iter:   1948/  8460 | loss: 0.6978 | ds_loss: 0.0000 | lr: 4.3741e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1948/  8460 | global iter:   1948/  8460 | loss: 0.5971 | ds_loss: 0.0000 | lr: 4.3741e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1949/  8460 | global iter:   1949/  8460 | loss: 0.5733 | ds_loss: 0.0000 | lr: 4.3734e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1950/  8460 | global iter:   1950/  8460 | loss: 0.3963 | ds_loss: 0.0000 | lr: 4.3728e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1951/  8460 | global iter:   1951/  8460 | loss: 0.3443 | ds_loss: 0.0000 | lr: 4.3722e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1952/  8460 | global iter:   1952/  8460 | loss: 0.3764 | ds_loss: 0.0000 | lr: 4.3716e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1952/  8460 | global iter:   1952/  8460 | loss: 0.4226 | ds_loss: 0.0000 | lr: 4.3716e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1953/  8460 | global iter:   1953/  8460 | loss: 0.3738 | ds_loss: 0.0000 | lr: 4.3710e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1954/  8460 | global iter:   1954/  8460 | loss: 0.6661 | ds_loss: 0.0000 | lr: 4.3704e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1955/  8460 | global iter:   1955/  8460 | loss: 0.7156 | ds_loss: 0.0000 | lr: 4.3697e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   1956/  8460 | global iter:   1956/  8460 | loss: 0.3126 | ds_loss: 0.0000 | lr: 4.3691e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1956/  8460 | global iter:   1956/  8460 | loss: 0.5170 | ds_loss: 0.0000 | lr: 4.3691e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1957/  8460 | global iter:   1957/  8460 | loss: 0.3100 | ds_loss: 0.0000 | lr: 4.3685e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1958/  8460 | global iter:   1958/  8460 | loss: 0.3626 | ds_loss: 0.0000 | lr: 4.3679e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1959/  8460 | global iter:   1959/  8460 | loss: 0.3849 | ds_loss: 0.0000 | lr: 4.3673e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1960/  8460 | global iter:   1960/  8460 | loss: 0.3246 | ds_loss: 0.0000 | lr: 4.3667e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1960/  8460 | global iter:   1960/  8460 | loss: 0.3455 | ds_loss: 0.0000 | lr: 4.3667e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1961/  8460 | global iter:   1961/  8460 | loss: 0.5419 | ds_loss: 0.0000 | lr: 4.3660e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1962/  8460 | global iter:   1962/  8460 | loss: 0.4278 | ds_loss: 0.0000 | lr: 4.3654e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1963/  8460 | global iter:   1963/  8460 | loss: 1.0710 | ds_loss: 0.0000 | lr: 4.3648e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1964/  8460 | global iter:   1964/  8460 | loss: 0.5383 | ds_loss: 0.0000 | lr: 4.3642e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1964/  8460 | global iter:   1964/  8460 | loss: 0.6447 | ds_loss: 0.0000 | lr: 4.3642e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1965/  8460 | global iter:   1965/  8460 | loss: 0.9768 | ds_loss: 0.0000 | lr: 4.3636e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1966/  8460 | global iter:   1966/  8460 | loss: 0.8086 | ds_loss: 0.0000 | lr: 4.3630e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1967/  8460 | global iter:   1967/  8460 | loss: 1.0284 | ds_loss: 0.0000 | lr: 4.3623e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1968/  8460 | global iter:   1968/  8460 | loss: 1.1493 | ds_loss: 0.0000 | lr: 4.3617e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1968/  8460 | global iter:   1968/  8460 | loss: 0.9908 | ds_loss: 0.0000 | lr: 4.3617e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1969/  8460 | global iter:   1969/  8460 | loss: 0.8977 | ds_loss: 0.0000 | lr: 4.3611e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1970/  8460 | global iter:   1970/  8460 | loss: 0.3055 | ds_loss: 0.0000 | lr: 4.3605e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1971/  8460 | global iter:   1971/  8460 | loss: 1.0629 | ds_loss: 0.0000 | lr: 4.3599e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1972/  8460 | global iter:   1972/  8460 | loss: 0.4319 | ds_loss: 0.0000 | lr: 4.3592e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1972/  8460 | global iter:   1972/  8460 | loss: 0.6745 | ds_loss: 0.0000 | lr: 4.3592e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1973/  8460 | global iter:   1973/  8460 | loss: 0.9156 | ds_loss: 0.0000 | lr: 4.3586e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1974/  8460 | global iter:   1974/  8460 | loss: 0.7837 | ds_loss: 0.0000 | lr: 4.3580e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1975/  8460 | global iter:   1975/  8460 | loss: 0.3300 | ds_loss: 0.0000 | lr: 4.3574e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1976/  8460 | global iter:   1976/  8460 | loss: 1.0117 | ds_loss: 0.0000 | lr: 4.3567e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1976/  8460 | global iter:   1976/  8460 | loss: 0.7603 | ds_loss: 0.0000 | lr: 4.3567e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1977/  8460 | global iter:   1977/  8460 | loss: 0.3306 | ds_loss: 0.0000 | lr: 4.3561e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1978/  8460 | global iter:   1978/  8460 | loss: 0.7105 | ds_loss: 0.0000 | lr: 4.3555e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1979/  8460 | global iter:   1979/  8460 | loss: 0.7569 | ds_loss: 0.0000 | lr: 4.3549e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1980/  8460 | global iter:   1980/  8460 | loss: 0.8068 | ds_loss: 0.0000 | lr: 4.3543e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1980/  8460 | global iter:   1980/  8460 | loss: 0.6512 | ds_loss: 0.0000 | lr: 4.3543e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1981/  8460 | global iter:   1981/  8460 | loss: 0.7186 | ds_loss: 0.0000 | lr: 4.3536e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1982/  8460 | global iter:   1982/  8460 | loss: 0.1814 | ds_loss: 0.0000 | lr: 4.3530e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1983/  8460 | global iter:   1983/  8460 | loss: 0.3877 | ds_loss: 0.0000 | lr: 4.3524e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   1984/  8460 | global iter:   1984/  8460 | loss: 0.3523 | ds_loss: 0.0000 | lr: 4.3518e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1984/  8460 | global iter:   1984/  8460 | loss: 0.4100 | ds_loss: 0.0000 | lr: 4.3518e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1985/  8460 | global iter:   1985/  8460 | loss: 0.4507 | ds_loss: 0.0000 | lr: 4.3511e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1986/  8460 | global iter:   1986/  8460 | loss: 0.9075 | ds_loss: 0.0000 | lr: 4.3505e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1987/  8460 | global iter:   1987/  8460 | loss: 0.7240 | ds_loss: 0.0000 | lr: 4.3499e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1988/  8460 | global iter:   1988/  8460 | loss: 0.2229 | ds_loss: 0.0000 | lr: 4.3493e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1988/  8460 | global iter:   1988/  8460 | loss: 0.5763 | ds_loss: 0.0000 | lr: 4.3493e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1989/  8460 | global iter:   1989/  8460 | loss: 0.5275 | ds_loss: 0.0000 | lr: 4.3486e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1990/  8460 | global iter:   1990/  8460 | loss: 0.3360 | ds_loss: 0.0000 | lr: 4.3480e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   1991/  8460 | global iter:   1991/  8460 | loss: 0.4056 | ds_loss: 0.0000 | lr: 4.3474e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1992/  8460 | global iter:   1992/  8460 | loss: 0.2980 | ds_loss: 0.0000 | lr: 4.3468e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1992/  8460 | global iter:   1992/  8460 | loss: 0.3918 | ds_loss: 0.0000 | lr: 4.3468e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1993/  8460 | global iter:   1993/  8460 | loss: 0.3115 | ds_loss: 0.0000 | lr: 4.3461e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1994/  8460 | global iter:   1994/  8460 | loss: 0.9868 | ds_loss: 0.0000 | lr: 4.3455e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   1995/  8460 | global iter:   1995/  8460 | loss: 0.3009 | ds_loss: 0.0000 | lr: 4.3449e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   1996/  8460 | global iter:   1996/  8460 | loss: 0.2646 | ds_loss: 0.0000 | lr: 4.3443e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   1996/  8460 | global iter:   1996/  8460 | loss: 0.4660 | ds_loss: 0.0000 | lr: 4.3443e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   1997/  8460 | global iter:   1997/  8460 | loss: 0.3589 | ds_loss: 0.0000 | lr: 4.3436e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   1998/  8460 | global iter:   1998/  8460 | loss: 0.3354 | ds_loss: 0.0000 | lr: 4.3430e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   1999/  8460 | global iter:   1999/  8460 | loss: 0.2458 | ds_loss: 0.0000 | lr: 4.3424e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2000/  8460 | global iter:   2000/  8460 | loss: 0.3318 | ds_loss: 0.0000 | lr: 4.3418e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2000/  8460 | global iter:   2000/  8460 | loss: 0.3180 | ds_loss: 0.0000 | lr: 4.3418e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2001/  8460 | global iter:   2001/  8460 | loss: 0.9870 | ds_loss: 0.0000 | lr: 4.3411e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2002/  8460 | global iter:   2002/  8460 | loss: 0.8296 | ds_loss: 0.0000 | lr: 4.3405e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2003/  8460 | global iter:   2003/  8460 | loss: 0.3930 | ds_loss: 0.0000 | lr: 4.3399e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2004/  8460 | global iter:   2004/  8460 | loss: 0.1935 | ds_loss: 0.0000 | lr: 4.3392e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2004/  8460 | global iter:   2004/  8460 | loss: 0.6008 | ds_loss: 0.0000 | lr: 4.3392e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2005/  8460 | global iter:   2005/  8460 | loss: 0.2917 | ds_loss: 0.0000 | lr: 4.3386e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2006/  8460 | global iter:   2006/  8460 | loss: 0.2432 | ds_loss: 0.0000 | lr: 4.3380e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2007/  8460 | global iter:   2007/  8460 | loss: 0.3946 | ds_loss: 0.0000 | lr: 4.3374e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2008/  8460 | global iter:   2008/  8460 | loss: 0.1882 | ds_loss: 0.0000 | lr: 4.3367e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2008/  8460 | global iter:   2008/  8460 | loss: 0.2794 | ds_loss: 0.0000 | lr: 4.3367e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2009/  8460 | global iter:   2009/  8460 | loss: 0.4823 | ds_loss: 0.0000 | lr: 4.3361e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2010/  8460 | global iter:   2010/  8460 | loss: 0.3723 | ds_loss: 0.0000 | lr: 4.3355e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2011/  8460 | global iter:   2011/  8460 | loss: 0.7580 | ds_loss: 0.0000 | lr: 4.3348e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2012/  8460 | global iter:   2012/  8460 | loss: 0.3178 | ds_loss: 0.0000 | lr: 4.3342e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2012/  8460 | global iter:   2012/  8460 | loss: 0.4826 | ds_loss: 0.0000 | lr: 4.3342e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2013/  8460 | global iter:   2013/  8460 | loss: 0.6805 | ds_loss: 0.0000 | lr: 4.3336e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2014/  8460 | global iter:   2014/  8460 | loss: 0.5213 | ds_loss: 0.0000 | lr: 4.3329e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2015/  8460 | global iter:   2015/  8460 | loss: 0.3495 | ds_loss: 0.0000 | lr: 4.3323e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2016/  8460 | global iter:   2016/  8460 | loss: 0.2546 | ds_loss: 0.0000 | lr: 4.3317e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2016/  8460 | global iter:   2016/  8460 | loss: 0.4515 | ds_loss: 0.0000 | lr: 4.3317e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2017/  8460 | global iter:   2017/  8460 | loss: 0.9560 | ds_loss: 0.0000 | lr: 4.3310e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2018/  8460 | global iter:   2018/  8460 | loss: 0.2923 | ds_loss: 0.0000 | lr: 4.3304e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2019/  8460 | global iter:   2019/  8460 | loss: 0.4017 | ds_loss: 0.0000 | lr: 4.3298e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2020/  8460 | global iter:   2020/  8460 | loss: 0.2611 | ds_loss: 0.0000 | lr: 4.3292e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2020/  8460 | global iter:   2020/  8460 | loss: 0.4778 | ds_loss: 0.0000 | lr: 4.3292e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2021/  8460 | global iter:   2021/  8460 | loss: 0.3470 | ds_loss: 0.0000 | lr: 4.3285e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2022/  8460 | global iter:   2022/  8460 | loss: 0.2490 | ds_loss: 0.0000 | lr: 4.3279e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2023/  8460 | global iter:   2023/  8460 | loss: 0.2740 | ds_loss: 0.0000 | lr: 4.3273e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2024/  8460 | global iter:   2024/  8460 | loss: 0.7973 | ds_loss: 0.0000 | lr: 4.3266e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2024/  8460 | global iter:   2024/  8460 | loss: 0.4168 | ds_loss: 0.0000 | lr: 4.3266e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2025/  8460 | global iter:   2025/  8460 | loss: 0.7100 | ds_loss: 0.0000 | lr: 4.3260e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2026/  8460 | global iter:   2026/  8460 | loss: 0.4479 | ds_loss: 0.0000 | lr: 4.3254e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2027/  8460 | global iter:   2027/  8460 | loss: 0.2440 | ds_loss: 0.0000 | lr: 4.3247e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2028/  8460 | global iter:   2028/  8460 | loss: 0.8660 | ds_loss: 0.0000 | lr: 4.3241e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2028/  8460 | global iter:   2028/  8460 | loss: 0.5670 | ds_loss: 0.0000 | lr: 4.3241e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2029/  8460 | global iter:   2029/  8460 | loss: 0.2502 | ds_loss: 0.0000 | lr: 4.3234e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2030/  8460 | global iter:   2030/  8460 | loss: 0.2531 | ds_loss: 0.0000 | lr: 4.3228e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2031/  8460 | global iter:   2031/  8460 | loss: 0.3964 | ds_loss: 0.0000 | lr: 4.3222e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2032/  8460 | global iter:   2032/  8460 | loss: 0.6198 | ds_loss: 0.0000 | lr: 4.3215e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2032/  8460 | global iter:   2032/  8460 | loss: 0.3799 | ds_loss: 0.0000 | lr: 4.3215e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2033/  8460 | global iter:   2033/  8460 | loss: 0.4022 | ds_loss: 0.0000 | lr: 4.3209e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2034/  8460 | global iter:   2034/  8460 | loss: 0.7571 | ds_loss: 0.0000 | lr: 4.3203e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2035/  8460 | global iter:   2035/  8460 | loss: 0.5256 | ds_loss: 0.0000 | lr: 4.3196e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2036/  8460 | global iter:   2036/  8460 | loss: 0.1018 | ds_loss: 0.0000 | lr: 4.3190e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2036/  8460 | global iter:   2036/  8460 | loss: 0.4467 | ds_loss: 0.0000 | lr: 4.3190e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2037/  8460 | global iter:   2037/  8460 | loss: 0.5327 | ds_loss: 0.0000 | lr: 4.3184e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2038/  8460 | global iter:   2038/  8460 | loss: 0.4433 | ds_loss: 0.0000 | lr: 4.3177e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2039/  8460 | global iter:   2039/  8460 | loss: 0.6954 | ds_loss: 0.0000 | lr: 4.3171e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2040/  8460 | global iter:   2040/  8460 | loss: 0.3879 | ds_loss: 0.0000 | lr: 4.3164e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2040/  8460 | global iter:   2040/  8460 | loss: 0.5148 | ds_loss: 0.0000 | lr: 4.3164e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2041/  8460 | global iter:   2041/  8460 | loss: 0.9813 | ds_loss: 0.0000 | lr: 4.3158e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2042/  8460 | global iter:   2042/  8460 | loss: 0.8191 | ds_loss: 0.0000 | lr: 4.3152e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2043/  8460 | global iter:   2043/  8460 | loss: 1.2134 | ds_loss: 0.0000 | lr: 4.3145e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2044/  8460 | global iter:   2044/  8460 | loss: 0.6087 | ds_loss: 0.0000 | lr: 4.3139e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2044/  8460 | global iter:   2044/  8460 | loss: 0.9056 | ds_loss: 0.0000 | lr: 4.3139e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2045/  8460 | global iter:   2045/  8460 | loss: 0.3518 | ds_loss: 0.0000 | lr: 4.3133e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2046/  8460 | global iter:   2046/  8460 | loss: 0.5084 | ds_loss: 0.0000 | lr: 4.3126e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2047/  8460 | global iter:   2047/  8460 | loss: 0.3447 | ds_loss: 0.0000 | lr: 4.3120e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2048/  8460 | global iter:   2048/  8460 | loss: 0.4641 | ds_loss: 0.0000 | lr: 4.3113e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2048/  8460 | global iter:   2048/  8460 | loss: 0.4172 | ds_loss: 0.0000 | lr: 4.3113e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2049/  8460 | global iter:   2049/  8460 | loss: 0.3759 | ds_loss: 0.0000 | lr: 4.3107e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2050/  8460 | global iter:   2050/  8460 | loss: 0.2337 | ds_loss: 0.0000 | lr: 4.3101e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2051/  8460 | global iter:   2051/  8460 | loss: 0.5700 | ds_loss: 0.0000 | lr: 4.3094e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2052/  8460 | global iter:   2052/  8460 | loss: 0.4653 | ds_loss: 0.0000 | lr: 4.3088e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2052/  8460 | global iter:   2052/  8460 | loss: 0.4112 | ds_loss: 0.0000 | lr: 4.3088e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2053/  8460 | global iter:   2053/  8460 | loss: 0.6446 | ds_loss: 0.0000 | lr: 4.3081e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2054/  8460 | global iter:   2054/  8460 | loss: 0.7898 | ds_loss: 0.0000 | lr: 4.3075e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2055/  8460 | global iter:   2055/  8460 | loss: 0.1788 | ds_loss: 0.0000 | lr: 4.3069e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2056/  8460 | global iter:   2056/  8460 | loss: 0.4168 | ds_loss: 0.0000 | lr: 4.3062e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2056/  8460 | global iter:   2056/  8460 | loss: 0.5075 | ds_loss: 0.0000 | lr: 4.3062e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2057/  8460 | global iter:   2057/  8460 | loss: 0.1496 | ds_loss: 0.0000 | lr: 4.3056e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2058/  8460 | global iter:   2058/  8460 | loss: 0.4353 | ds_loss: 0.0000 | lr: 4.3049e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2059/  8460 | global iter:   2059/  8460 | loss: 0.6503 | ds_loss: 0.0000 | lr: 4.3043e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2060/  8460 | global iter:   2060/  8460 | loss: 0.4644 | ds_loss: 0.0000 | lr: 4.3036e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2060/  8460 | global iter:   2060/  8460 | loss: 0.4249 | ds_loss: 0.0000 | lr: 4.3036e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2061/  8460 | global iter:   2061/  8460 | loss: 0.2483 | ds_loss: 0.0000 | lr: 4.3030e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2062/  8460 | global iter:   2062/  8460 | loss: 0.3433 | ds_loss: 0.0000 | lr: 4.3024e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2063/  8460 | global iter:   2063/  8460 | loss: 0.2788 | ds_loss: 0.0000 | lr: 4.3017e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2064/  8460 | global iter:   2064/  8460 | loss: 0.4270 | ds_loss: 0.0000 | lr: 4.3011e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2064/  8460 | global iter:   2064/  8460 | loss: 0.3243 | ds_loss: 0.0000 | lr: 4.3011e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2065/  8460 | global iter:   2065/  8460 | loss: 0.9374 | ds_loss: 0.0000 | lr: 4.3004e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2066/  8460 | global iter:   2066/  8460 | loss: 0.5957 | ds_loss: 0.0000 | lr: 4.2998e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2067/  8460 | global iter:   2067/  8460 | loss: 0.2100 | ds_loss: 0.0000 | lr: 4.2991e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2068/  8460 | global iter:   2068/  8460 | loss: 1.0237 | ds_loss: 0.0000 | lr: 4.2985e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2068/  8460 | global iter:   2068/  8460 | loss: 0.6917 | ds_loss: 0.0000 | lr: 4.2985e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2069/  8460 | global iter:   2069/  8460 | loss: 0.2237 | ds_loss: 0.0000 | lr: 4.2978e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2070/  8460 | global iter:   2070/  8460 | loss: 0.0952 | ds_loss: 0.0000 | lr: 4.2972e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2071/  8460 | global iter:   2071/  8460 | loss: 0.4546 | ds_loss: 0.0000 | lr: 4.2966e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2072/  8460 | global iter:   2072/  8460 | loss: 0.6438 | ds_loss: 0.0000 | lr: 4.2959e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2072/  8460 | global iter:   2072/  8460 | loss: 0.3543 | ds_loss: 0.0000 | lr: 4.2959e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2073/  8460 | global iter:   2073/  8460 | loss: 0.2585 | ds_loss: 0.0000 | lr: 4.2953e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2074/  8460 | global iter:   2074/  8460 | loss: 0.9903 | ds_loss: 0.0000 | lr: 4.2946e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2075/  8460 | global iter:   2075/  8460 | loss: 0.4341 | ds_loss: 0.0000 | lr: 4.2940e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2076/  8460 | global iter:   2076/  8460 | loss: 0.2385 | ds_loss: 0.0000 | lr: 4.2933e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2076/  8460 | global iter:   2076/  8460 | loss: 0.4804 | ds_loss: 0.0000 | lr: 4.2933e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2077/  8460 | global iter:   2077/  8460 | loss: 0.6143 | ds_loss: 0.0000 | lr: 4.2927e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2078/  8460 | global iter:   2078/  8460 | loss: 0.3474 | ds_loss: 0.0000 | lr: 4.2920e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2079/  8460 | global iter:   2079/  8460 | loss: 0.6620 | ds_loss: 0.0000 | lr: 4.2914e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2080/  8460 | global iter:   2080/  8460 | loss: 0.8498 | ds_loss: 0.0000 | lr: 4.2907e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2080/  8460 | global iter:   2080/  8460 | loss: 0.6184 | ds_loss: 0.0000 | lr: 4.2907e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2081/  8460 | global iter:   2081/  8460 | loss: 0.2940 | ds_loss: 0.0000 | lr: 4.2901e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2082/  8460 | global iter:   2082/  8460 | loss: 0.4434 | ds_loss: 0.0000 | lr: 4.2894e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2083/  8460 | global iter:   2083/  8460 | loss: 0.5196 | ds_loss: 0.0000 | lr: 4.2888e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2084/  8460 | global iter:   2084/  8460 | loss: 0.4540 | ds_loss: 0.0000 | lr: 4.2881e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2084/  8460 | global iter:   2084/  8460 | loss: 0.4277 | ds_loss: 0.0000 | lr: 4.2881e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2085/  8460 | global iter:   2085/  8460 | loss: 0.5366 | ds_loss: 0.0000 | lr: 4.2875e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2086/  8460 | global iter:   2086/  8460 | loss: 0.6192 | ds_loss: 0.0000 | lr: 4.2868e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2087/  8460 | global iter:   2087/  8460 | loss: 1.5378 | ds_loss: 0.0000 | lr: 4.2862e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2088/  8460 | global iter:   2088/  8460 | loss: 0.2928 | ds_loss: 0.0000 | lr: 4.2855e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2088/  8460 | global iter:   2088/  8460 | loss: 0.7466 | ds_loss: 0.0000 | lr: 4.2855e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2089/  8460 | global iter:   2089/  8460 | loss: 0.1941 | ds_loss: 0.0000 | lr: 4.2849e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2090/  8460 | global iter:   2090/  8460 | loss: 0.8452 | ds_loss: 0.0000 | lr: 4.2842e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2091/  8460 | global iter:   2091/  8460 | loss: 0.4168 | ds_loss: 0.0000 | lr: 4.2836e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2092/  8460 | global iter:   2092/  8460 | loss: 0.3151 | ds_loss: 0.0000 | lr: 4.2829e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2092/  8460 | global iter:   2092/  8460 | loss: 0.4428 | ds_loss: 0.0000 | lr: 4.2829e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2093/  8460 | global iter:   2093/  8460 | loss: 0.6082 | ds_loss: 0.0000 | lr: 4.2823e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2094/  8460 | global iter:   2094/  8460 | loss: 0.4543 | ds_loss: 0.0000 | lr: 4.2816e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2095/  8460 | global iter:   2095/  8460 | loss: 0.3222 | ds_loss: 0.0000 | lr: 4.2810e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2096/  8460 | global iter:   2096/  8460 | loss: 0.3248 | ds_loss: 0.0000 | lr: 4.2803e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2096/  8460 | global iter:   2096/  8460 | loss: 0.4274 | ds_loss: 0.0000 | lr: 4.2803e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2097/  8460 | global iter:   2097/  8460 | loss: 1.3330 | ds_loss: 0.0000 | lr: 4.2797e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2098/  8460 | global iter:   2098/  8460 | loss: 0.3680 | ds_loss: 0.0000 | lr: 4.2790e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2099/  8460 | global iter:   2099/  8460 | loss: 0.2453 | ds_loss: 0.0000 | lr: 4.2784e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2100/  8460 | global iter:   2100/  8460 | loss: 0.3968 | ds_loss: 0.0000 | lr: 4.2777e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2100/  8460 | global iter:   2100/  8460 | loss: 0.5858 | ds_loss: 0.0000 | lr: 4.2777e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2101/  8460 | global iter:   2101/  8460 | loss: 0.3970 | ds_loss: 0.0000 | lr: 4.2771e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2102/  8460 | global iter:   2102/  8460 | loss: 0.1734 | ds_loss: 0.0000 | lr: 4.2764e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2103/  8460 | global iter:   2103/  8460 | loss: 0.1982 | ds_loss: 0.0000 | lr: 4.2758e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2104/  8460 | global iter:   2104/  8460 | loss: 1.1569 | ds_loss: 0.0000 | lr: 4.2751e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2104/  8460 | global iter:   2104/  8460 | loss: 0.4814 | ds_loss: 0.0000 | lr: 4.2751e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2105/  8460 | global iter:   2105/  8460 | loss: 0.3212 | ds_loss: 0.0000 | lr: 4.2745e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2106/  8460 | global iter:   2106/  8460 | loss: 0.6236 | ds_loss: 0.0000 | lr: 4.2738e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2107/  8460 | global iter:   2107/  8460 | loss: 0.2628 | ds_loss: 0.0000 | lr: 4.2732e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2108/  8460 | global iter:   2108/  8460 | loss: 0.3725 | ds_loss: 0.0000 | lr: 4.2725e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2108/  8460 | global iter:   2108/  8460 | loss: 0.3950 | ds_loss: 0.0000 | lr: 4.2725e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2109/  8460 | global iter:   2109/  8460 | loss: 0.9971 | ds_loss: 0.0000 | lr: 4.2718e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2110/  8460 | global iter:   2110/  8460 | loss: 0.3916 | ds_loss: 0.0000 | lr: 4.2712e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2111/  8460 | global iter:   2111/  8460 | loss: 0.2328 | ds_loss: 0.0000 | lr: 4.2705e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2112/  8460 | global iter:   2112/  8460 | loss: 1.1015 | ds_loss: 0.0000 | lr: 4.2699e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2112/  8460 | global iter:   2112/  8460 | loss: 0.6808 | ds_loss: 0.0000 | lr: 4.2699e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2113/  8460 | global iter:   2113/  8460 | loss: 1.0026 | ds_loss: 0.0000 | lr: 4.2692e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2114/  8460 | global iter:   2114/  8460 | loss: 0.1391 | ds_loss: 0.0000 | lr: 4.2686e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2115/  8460 | global iter:   2115/  8460 | loss: 0.5054 | ds_loss: 0.0000 | lr: 4.2679e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2116/  8460 | global iter:   2116/  8460 | loss: 0.7525 | ds_loss: 0.0000 | lr: 4.2673e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2116/  8460 | global iter:   2116/  8460 | loss: 0.5999 | ds_loss: 0.0000 | lr: 4.2673e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2117/  8460 | global iter:   2117/  8460 | loss: 0.1585 | ds_loss: 0.0000 | lr: 4.2666e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2118/  8460 | global iter:   2118/  8460 | loss: 0.4150 | ds_loss: 0.0000 | lr: 4.2659e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2119/  8460 | global iter:   2119/  8460 | loss: 0.3494 | ds_loss: 0.0000 | lr: 4.2653e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2120/  8460 | global iter:   2120/  8460 | loss: 0.9689 | ds_loss: 0.0000 | lr: 4.2646e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2120/  8460 | global iter:   2120/  8460 | loss: 0.4729 | ds_loss: 0.0000 | lr: 4.2646e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2121/  8460 | global iter:   2121/  8460 | loss: 0.1331 | ds_loss: 0.0000 | lr: 4.2640e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2122/  8460 | global iter:   2122/  8460 | loss: 0.2237 | ds_loss: 0.0000 | lr: 4.2633e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2123/  8460 | global iter:   2123/  8460 | loss: 1.3447 | ds_loss: 0.0000 | lr: 4.2627e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2124/  8460 | global iter:   2124/  8460 | loss: 0.3320 | ds_loss: 0.0000 | lr: 4.2620e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2124/  8460 | global iter:   2124/  8460 | loss: 0.5084 | ds_loss: 0.0000 | lr: 4.2620e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2125/  8460 | global iter:   2125/  8460 | loss: 0.6538 | ds_loss: 0.0000 | lr: 4.2613e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2126/  8460 | global iter:   2126/  8460 | loss: 0.7615 | ds_loss: 0.0000 | lr: 4.2607e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2127/  8460 | global iter:   2127/  8460 | loss: 0.8564 | ds_loss: 0.0000 | lr: 4.2600e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2128/  8460 | global iter:   2128/  8460 | loss: 0.6444 | ds_loss: 0.0000 | lr: 4.2594e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2128/  8460 | global iter:   2128/  8460 | loss: 0.7290 | ds_loss: 0.0000 | lr: 4.2594e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2129/  8460 | global iter:   2129/  8460 | loss: 0.3210 | ds_loss: 0.0000 | lr: 4.2587e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2130/  8460 | global iter:   2130/  8460 | loss: 0.3823 | ds_loss: 0.0000 | lr: 4.2580e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2131/  8460 | global iter:   2131/  8460 | loss: 0.3914 | ds_loss: 0.0000 | lr: 4.2574e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2132/  8460 | global iter:   2132/  8460 | loss: 0.2876 | ds_loss: 0.0000 | lr: 4.2567e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2132/  8460 | global iter:   2132/  8460 | loss: 0.3456 | ds_loss: 0.0000 | lr: 4.2567e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2133/  8460 | global iter:   2133/  8460 | loss: 0.2571 | ds_loss: 0.0000 | lr: 4.2561e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2134/  8460 | global iter:   2134/  8460 | loss: 0.6971 | ds_loss: 0.0000 | lr: 4.2554e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2135/  8460 | global iter:   2135/  8460 | loss: 0.2622 | ds_loss: 0.0000 | lr: 4.2547e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2136/  8460 | global iter:   2136/  8460 | loss: 0.4845 | ds_loss: 0.0000 | lr: 4.2541e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2136/  8460 | global iter:   2136/  8460 | loss: 0.4252 | ds_loss: 0.0000 | lr: 4.2541e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2137/  8460 | global iter:   2137/  8460 | loss: 0.4381 | ds_loss: 0.0000 | lr: 4.2534e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2138/  8460 | global iter:   2138/  8460 | loss: 0.4508 | ds_loss: 0.0000 | lr: 4.2528e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2139/  8460 | global iter:   2139/  8460 | loss: 0.3437 | ds_loss: 0.0000 | lr: 4.2521e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2140/  8460 | global iter:   2140/  8460 | loss: 0.6603 | ds_loss: 0.0000 | lr: 4.2514e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2140/  8460 | global iter:   2140/  8460 | loss: 0.4732 | ds_loss: 0.0000 | lr: 4.2514e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2141/  8460 | global iter:   2141/  8460 | loss: 0.5570 | ds_loss: 0.0000 | lr: 4.2508e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2142/  8460 | global iter:   2142/  8460 | loss: 0.2512 | ds_loss: 0.0000 | lr: 4.2501e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2143/  8460 | global iter:   2143/  8460 | loss: 1.0200 | ds_loss: 0.0000 | lr: 4.2494e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2144/  8460 | global iter:   2144/  8460 | loss: 0.4199 | ds_loss: 0.0000 | lr: 4.2488e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2144/  8460 | global iter:   2144/  8460 | loss: 0.5620 | ds_loss: 0.0000 | lr: 4.2488e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2145/  8460 | global iter:   2145/  8460 | loss: 0.2946 | ds_loss: 0.0000 | lr: 4.2481e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2146/  8460 | global iter:   2146/  8460 | loss: 0.2595 | ds_loss: 0.0000 | lr: 4.2475e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2147/  8460 | global iter:   2147/  8460 | loss: 0.3987 | ds_loss: 0.0000 | lr: 4.2468e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2148/  8460 | global iter:   2148/  8460 | loss: 0.4592 | ds_loss: 0.0000 | lr: 4.2461e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2148/  8460 | global iter:   2148/  8460 | loss: 0.3530 | ds_loss: 0.0000 | lr: 4.2461e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2149/  8460 | global iter:   2149/  8460 | loss: 0.7546 | ds_loss: 0.0000 | lr: 4.2455e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2150/  8460 | global iter:   2150/  8460 | loss: 0.5103 | ds_loss: 0.0000 | lr: 4.2448e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2151/  8460 | global iter:   2151/  8460 | loss: 0.2908 | ds_loss: 0.0000 | lr: 4.2441e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2152/  8460 | global iter:   2152/  8460 | loss: 0.5402 | ds_loss: 0.0000 | lr: 4.2435e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2152/  8460 | global iter:   2152/  8460 | loss: 0.5240 | ds_loss: 0.0000 | lr: 4.2435e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2153/  8460 | global iter:   2153/  8460 | loss: 0.4868 | ds_loss: 0.0000 | lr: 4.2428e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2154/  8460 | global iter:   2154/  8460 | loss: 0.4187 | ds_loss: 0.0000 | lr: 4.2421e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2155/  8460 | global iter:   2155/  8460 | loss: 0.3683 | ds_loss: 0.0000 | lr: 4.2415e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2156/  8460 | global iter:   2156/  8460 | loss: 0.7011 | ds_loss: 0.0000 | lr: 4.2408e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2156/  8460 | global iter:   2156/  8460 | loss: 0.4937 | ds_loss: 0.0000 | lr: 4.2408e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2157/  8460 | global iter:   2157/  8460 | loss: 0.4495 | ds_loss: 0.0000 | lr: 4.2401e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2158/  8460 | global iter:   2158/  8460 | loss: 0.2481 | ds_loss: 0.0000 | lr: 4.2395e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2159/  8460 | global iter:   2159/  8460 | loss: 0.3547 | ds_loss: 0.0000 | lr: 4.2388e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2160/  8460 | global iter:   2160/  8460 | loss: 0.7938 | ds_loss: 0.0000 | lr: 4.2381e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2160/  8460 | global iter:   2160/  8460 | loss: 0.4615 | ds_loss: 0.0000 | lr: 4.2381e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2161/  8460 | global iter:   2161/  8460 | loss: 0.7673 | ds_loss: 0.0000 | lr: 4.2375e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2162/  8460 | global iter:   2162/  8460 | loss: 0.8151 | ds_loss: 0.0000 | lr: 4.2368e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2163/  8460 | global iter:   2163/  8460 | loss: 1.1783 | ds_loss: 0.0000 | lr: 4.2361e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2164/  8460 | global iter:   2164/  8460 | loss: 0.8423 | ds_loss: 0.0000 | lr: 4.2355e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2164/  8460 | global iter:   2164/  8460 | loss: 0.9007 | ds_loss: 0.0000 | lr: 4.2355e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2165/  8460 | global iter:   2165/  8460 | loss: 0.5600 | ds_loss: 0.0000 | lr: 4.2348e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2166/  8460 | global iter:   2166/  8460 | loss: 0.7024 | ds_loss: 0.0000 | lr: 4.2341e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2167/  8460 | global iter:   2167/  8460 | loss: 0.5553 | ds_loss: 0.0000 | lr: 4.2335e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2168/  8460 | global iter:   2168/  8460 | loss: 0.3049 | ds_loss: 0.0000 | lr: 4.2328e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2168/  8460 | global iter:   2168/  8460 | loss: 0.5306 | ds_loss: 0.0000 | lr: 4.2328e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2169/  8460 | global iter:   2169/  8460 | loss: 0.8344 | ds_loss: 0.0000 | lr: 4.2321e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2170/  8460 | global iter:   2170/  8460 | loss: 0.2141 | ds_loss: 0.0000 | lr: 4.2314e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2171/  8460 | global iter:   2171/  8460 | loss: 0.8202 | ds_loss: 0.0000 | lr: 4.2308e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2172/  8460 | global iter:   2172/  8460 | loss: 0.6794 | ds_loss: 0.0000 | lr: 4.2301e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2172/  8460 | global iter:   2172/  8460 | loss: 0.6370 | ds_loss: 0.0000 | lr: 4.2301e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2173/  8460 | global iter:   2173/  8460 | loss: 0.5329 | ds_loss: 0.0000 | lr: 4.2294e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2174/  8460 | global iter:   2174/  8460 | loss: 0.4898 | ds_loss: 0.0000 | lr: 4.2288e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2175/  8460 | global iter:   2175/  8460 | loss: 0.7051 | ds_loss: 0.0000 | lr: 4.2281e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2176/  8460 | global iter:   2176/  8460 | loss: 0.6826 | ds_loss: 0.0000 | lr: 4.2274e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2176/  8460 | global iter:   2176/  8460 | loss: 0.6026 | ds_loss: 0.0000 | lr: 4.2274e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2177/  8460 | global iter:   2177/  8460 | loss: 0.2177 | ds_loss: 0.0000 | lr: 4.2268e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2178/  8460 | global iter:   2178/  8460 | loss: 0.2930 | ds_loss: 0.0000 | lr: 4.2261e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2179/  8460 | global iter:   2179/  8460 | loss: 0.6166 | ds_loss: 0.0000 | lr: 4.2254e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2180/  8460 | global iter:   2180/  8460 | loss: 0.2478 | ds_loss: 0.0000 | lr: 4.2247e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2180/  8460 | global iter:   2180/  8460 | loss: 0.3438 | ds_loss: 0.0000 | lr: 4.2247e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2181/  8460 | global iter:   2181/  8460 | loss: 0.7795 | ds_loss: 0.0000 | lr: 4.2241e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2182/  8460 | global iter:   2182/  8460 | loss: 0.2207 | ds_loss: 0.0000 | lr: 4.2234e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2183/  8460 | global iter:   2183/  8460 | loss: 0.2549 | ds_loss: 0.0000 | lr: 4.2227e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2184/  8460 | global iter:   2184/  8460 | loss: 0.4129 | ds_loss: 0.0000 | lr: 4.2221e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2184/  8460 | global iter:   2184/  8460 | loss: 0.4170 | ds_loss: 0.0000 | lr: 4.2221e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2185/  8460 | global iter:   2185/  8460 | loss: 0.4644 | ds_loss: 0.0000 | lr: 4.2214e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2186/  8460 | global iter:   2186/  8460 | loss: 1.0127 | ds_loss: 0.0000 | lr: 4.2207e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2187/  8460 | global iter:   2187/  8460 | loss: 0.1691 | ds_loss: 0.0000 | lr: 4.2200e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2188/  8460 | global iter:   2188/  8460 | loss: 0.4240 | ds_loss: 0.0000 | lr: 4.2194e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2188/  8460 | global iter:   2188/  8460 | loss: 0.5175 | ds_loss: 0.0000 | lr: 4.2194e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2189/  8460 | global iter:   2189/  8460 | loss: 0.6181 | ds_loss: 0.0000 | lr: 4.2187e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2190/  8460 | global iter:   2190/  8460 | loss: 0.3497 | ds_loss: 0.0000 | lr: 4.2180e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2191/  8460 | global iter:   2191/  8460 | loss: 1.0012 | ds_loss: 0.0000 | lr: 4.2173e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2192/  8460 | global iter:   2192/  8460 | loss: 0.4470 | ds_loss: 0.0000 | lr: 4.2167e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2192/  8460 | global iter:   2192/  8460 | loss: 0.6040 | ds_loss: 0.0000 | lr: 4.2167e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2193/  8460 | global iter:   2193/  8460 | loss: 0.5674 | ds_loss: 0.0000 | lr: 4.2160e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2194/  8460 | global iter:   2194/  8460 | loss: 0.9803 | ds_loss: 0.0000 | lr: 4.2153e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2195/  8460 | global iter:   2195/  8460 | loss: 0.3913 | ds_loss: 0.0000 | lr: 4.2146e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2196/  8460 | global iter:   2196/  8460 | loss: 1.0436 | ds_loss: 0.0000 | lr: 4.2140e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2196/  8460 | global iter:   2196/  8460 | loss: 0.7456 | ds_loss: 0.0000 | lr: 4.2140e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2197/  8460 | global iter:   2197/  8460 | loss: 0.4695 | ds_loss: 0.0000 | lr: 4.2133e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2198/  8460 | global iter:   2198/  8460 | loss: 0.1832 | ds_loss: 0.0000 | lr: 4.2126e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2199/  8460 | global iter:   2199/  8460 | loss: 0.1316 | ds_loss: 0.0000 | lr: 4.2119e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2200/  8460 | global iter:   2200/  8460 | loss: 0.4259 | ds_loss: 0.0000 | lr: 4.2113e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2200/  8460 | global iter:   2200/  8460 | loss: 0.3026 | ds_loss: 0.0000 | lr: 4.2113e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2201/  8460 | global iter:   2201/  8460 | loss: 0.6748 | ds_loss: 0.0000 | lr: 4.2106e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2202/  8460 | global iter:   2202/  8460 | loss: 1.1135 | ds_loss: 0.0000 | lr: 4.2099e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2203/  8460 | global iter:   2203/  8460 | loss: 0.3901 | ds_loss: 0.0000 | lr: 4.2092e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2204/  8460 | global iter:   2204/  8460 | loss: 0.3581 | ds_loss: 0.0000 | lr: 4.2085e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2204/  8460 | global iter:   2204/  8460 | loss: 0.6341 | ds_loss: 0.0000 | lr: 4.2085e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2205/  8460 | global iter:   2205/  8460 | loss: 0.9395 | ds_loss: 0.0000 | lr: 4.2079e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2206/  8460 | global iter:   2206/  8460 | loss: 0.3541 | ds_loss: 0.0000 | lr: 4.2072e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2207/  8460 | global iter:   2207/  8460 | loss: 0.7336 | ds_loss: 0.0000 | lr: 4.2065e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2208/  8460 | global iter:   2208/  8460 | loss: 0.4452 | ds_loss: 0.0000 | lr: 4.2058e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2208/  8460 | global iter:   2208/  8460 | loss: 0.6181 | ds_loss: 0.0000 | lr: 4.2058e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2209/  8460 | global iter:   2209/  8460 | loss: 0.2041 | ds_loss: 0.0000 | lr: 4.2052e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2210/  8460 | global iter:   2210/  8460 | loss: 0.3660 | ds_loss: 0.0000 | lr: 4.2045e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2211/  8460 | global iter:   2211/  8460 | loss: 0.8390 | ds_loss: 0.0000 | lr: 4.2038e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2212/  8460 | global iter:   2212/  8460 | loss: 0.6182 | ds_loss: 0.0000 | lr: 4.2031e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2212/  8460 | global iter:   2212/  8460 | loss: 0.5068 | ds_loss: 0.0000 | lr: 4.2031e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2213/  8460 | global iter:   2213/  8460 | loss: 0.3513 | ds_loss: 0.0000 | lr: 4.2024e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2214/  8460 | global iter:   2214/  8460 | loss: 0.5170 | ds_loss: 0.0000 | lr: 4.2018e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2215/  8460 | global iter:   2215/  8460 | loss: 0.4646 | ds_loss: 0.0000 | lr: 4.2011e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2216/  8460 | global iter:   2216/  8460 | loss: 0.3942 | ds_loss: 0.0000 | lr: 4.2004e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2216/  8460 | global iter:   2216/  8460 | loss: 0.4318 | ds_loss: 0.0000 | lr: 4.2004e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2217/  8460 | global iter:   2217/  8460 | loss: 0.1643 | ds_loss: 0.0000 | lr: 4.1997e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2218/  8460 | global iter:   2218/  8460 | loss: 0.5913 | ds_loss: 0.0000 | lr: 4.1990e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2219/  8460 | global iter:   2219/  8460 | loss: 1.3198 | ds_loss: 0.0000 | lr: 4.1984e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2220/  8460 | global iter:   2220/  8460 | loss: 0.4464 | ds_loss: 0.0000 | lr: 4.1977e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2220/  8460 | global iter:   2220/  8460 | loss: 0.6305 | ds_loss: 0.0000 | lr: 4.1977e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2221/  8460 | global iter:   2221/  8460 | loss: 0.1208 | ds_loss: 0.0000 | lr: 4.1970e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2222/  8460 | global iter:   2222/  8460 | loss: 0.2640 | ds_loss: 0.0000 | lr: 4.1963e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2223/  8460 | global iter:   2223/  8460 | loss: 0.1821 | ds_loss: 0.0000 | lr: 4.1956e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2224/  8460 | global iter:   2224/  8460 | loss: 0.1456 | ds_loss: 0.0000 | lr: 4.1949e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2224/  8460 | global iter:   2224/  8460 | loss: 0.1781 | ds_loss: 0.0000 | lr: 4.1949e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2225/  8460 | global iter:   2225/  8460 | loss: 0.2495 | ds_loss: 0.0000 | lr: 4.1943e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2226/  8460 | global iter:   2226/  8460 | loss: 0.8249 | ds_loss: 0.0000 | lr: 4.1936e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2227/  8460 | global iter:   2227/  8460 | loss: 0.5878 | ds_loss: 0.0000 | lr: 4.1929e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2228/  8460 | global iter:   2228/  8460 | loss: 0.2807 | ds_loss: 0.0000 | lr: 4.1922e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2228/  8460 | global iter:   2228/  8460 | loss: 0.4857 | ds_loss: 0.0000 | lr: 4.1922e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2229/  8460 | global iter:   2229/  8460 | loss: 0.2854 | ds_loss: 0.0000 | lr: 4.1915e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2230/  8460 | global iter:   2230/  8460 | loss: 0.2121 | ds_loss: 0.0000 | lr: 4.1908e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2231/  8460 | global iter:   2231/  8460 | loss: 0.6834 | ds_loss: 0.0000 | lr: 4.1902e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2232/  8460 | global iter:   2232/  8460 | loss: 0.1392 | ds_loss: 0.0000 | lr: 4.1895e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2232/  8460 | global iter:   2232/  8460 | loss: 0.3300 | ds_loss: 0.0000 | lr: 4.1895e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2233/  8460 | global iter:   2233/  8460 | loss: 0.9888 | ds_loss: 0.0000 | lr: 4.1888e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2234/  8460 | global iter:   2234/  8460 | loss: 0.5832 | ds_loss: 0.0000 | lr: 4.1881e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2235/  8460 | global iter:   2235/  8460 | loss: 0.3377 | ds_loss: 0.0000 | lr: 4.1874e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2236/  8460 | global iter:   2236/  8460 | loss: 0.6035 | ds_loss: 0.0000 | lr: 4.1867e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2236/  8460 | global iter:   2236/  8460 | loss: 0.6283 | ds_loss: 0.0000 | lr: 4.1867e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2237/  8460 | global iter:   2237/  8460 | loss: 0.2940 | ds_loss: 0.0000 | lr: 4.1861e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2238/  8460 | global iter:   2238/  8460 | loss: 0.4468 | ds_loss: 0.0000 | lr: 4.1854e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2239/  8460 | global iter:   2239/  8460 | loss: 0.3625 | ds_loss: 0.0000 | lr: 4.1847e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2240/  8460 | global iter:   2240/  8460 | loss: 0.5118 | ds_loss: 0.0000 | lr: 4.1840e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2240/  8460 | global iter:   2240/  8460 | loss: 0.4038 | ds_loss: 0.0000 | lr: 4.1840e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2241/  8460 | global iter:   2241/  8460 | loss: 0.2281 | ds_loss: 0.0000 | lr: 4.1833e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2242/  8460 | global iter:   2242/  8460 | loss: 0.3163 | ds_loss: 0.0000 | lr: 4.1826e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2243/  8460 | global iter:   2243/  8460 | loss: 0.2173 | ds_loss: 0.0000 | lr: 4.1819e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2244/  8460 | global iter:   2244/  8460 | loss: 0.3076 | ds_loss: 0.0000 | lr: 4.1813e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2244/  8460 | global iter:   2244/  8460 | loss: 0.2673 | ds_loss: 0.0000 | lr: 4.1813e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2245/  8460 | global iter:   2245/  8460 | loss: 0.3174 | ds_loss: 0.0000 | lr: 4.1806e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2246/  8460 | global iter:   2246/  8460 | loss: 0.9364 | ds_loss: 0.0000 | lr: 4.1799e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2247/  8460 | global iter:   2247/  8460 | loss: 1.0576 | ds_loss: 0.0000 | lr: 4.1792e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2248/  8460 | global iter:   2248/  8460 | loss: 1.0560 | ds_loss: 0.0000 | lr: 4.1785e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2248/  8460 | global iter:   2248/  8460 | loss: 0.8418 | ds_loss: 0.0000 | lr: 4.1785e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2249/  8460 | global iter:   2249/  8460 | loss: 0.3396 | ds_loss: 0.0000 | lr: 4.1778e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2250/  8460 | global iter:   2250/  8460 | loss: 0.1758 | ds_loss: 0.0000 | lr: 4.1771e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2251/  8460 | global iter:   2251/  8460 | loss: 0.2824 | ds_loss: 0.0000 | lr: 4.1764e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2252/  8460 | global iter:   2252/  8460 | loss: 0.9951 | ds_loss: 0.0000 | lr: 4.1757e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2252/  8460 | global iter:   2252/  8460 | loss: 0.4482 | ds_loss: 0.0000 | lr: 4.1757e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2253/  8460 | global iter:   2253/  8460 | loss: 0.3003 | ds_loss: 0.0000 | lr: 4.1751e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2254/  8460 | global iter:   2254/  8460 | loss: 0.4678 | ds_loss: 0.0000 | lr: 4.1744e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2255/  8460 | global iter:   2255/  8460 | loss: 0.2290 | ds_loss: 0.0000 | lr: 4.1737e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2256/  8460 | global iter:   2256/  8460 | loss: 0.7844 | ds_loss: 0.0000 | lr: 4.1730e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2256/  8460 | global iter:   2256/  8460 | loss: 0.4454 | ds_loss: 0.0000 | lr: 4.1730e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2257/  8460 | global iter:   2257/  8460 | loss: 0.2676 | ds_loss: 0.0000 | lr: 4.1723e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2258/  8460 | global iter:   2258/  8460 | loss: 0.6208 | ds_loss: 0.0000 | lr: 4.1716e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2259/  8460 | global iter:   2259/  8460 | loss: 0.9881 | ds_loss: 0.0000 | lr: 4.1709e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2260/  8460 | global iter:   2260/  8460 | loss: 0.8845 | ds_loss: 0.0000 | lr: 4.1702e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2260/  8460 | global iter:   2260/  8460 | loss: 0.6902 | ds_loss: 0.0000 | lr: 4.1702e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2261/  8460 | global iter:   2261/  8460 | loss: 0.3769 | ds_loss: 0.0000 | lr: 4.1695e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2262/  8460 | global iter:   2262/  8460 | loss: 0.1458 | ds_loss: 0.0000 | lr: 4.1688e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2263/  8460 | global iter:   2263/  8460 | loss: 0.2836 | ds_loss: 0.0000 | lr: 4.1682e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2264/  8460 | global iter:   2264/  8460 | loss: 1.3003 | ds_loss: 0.0000 | lr: 4.1675e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2264/  8460 | global iter:   2264/  8460 | loss: 0.5267 | ds_loss: 0.0000 | lr: 4.1675e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2265/  8460 | global iter:   2265/  8460 | loss: 0.3325 | ds_loss: 0.0000 | lr: 4.1668e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2266/  8460 | global iter:   2266/  8460 | loss: 0.2869 | ds_loss: 0.0000 | lr: 4.1661e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2267/  8460 | global iter:   2267/  8460 | loss: 2.0553 | ds_loss: 0.0000 | lr: 4.1654e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2268/  8460 | global iter:   2268/  8460 | loss: 0.8863 | ds_loss: 0.0000 | lr: 4.1647e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2268/  8460 | global iter:   2268/  8460 | loss: 0.8902 | ds_loss: 0.0000 | lr: 4.1647e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2269/  8460 | global iter:   2269/  8460 | loss: 0.4974 | ds_loss: 0.0000 | lr: 4.1640e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2270/  8460 | global iter:   2270/  8460 | loss: 0.3337 | ds_loss: 0.0000 | lr: 4.1633e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2271/  8460 | global iter:   2271/  8460 | loss: 0.1483 | ds_loss: 0.0000 | lr: 4.1626e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2272/  8460 | global iter:   2272/  8460 | loss: 0.4691 | ds_loss: 0.0000 | lr: 4.1619e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2272/  8460 | global iter:   2272/  8460 | loss: 0.3621 | ds_loss: 0.0000 | lr: 4.1619e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2273/  8460 | global iter:   2273/  8460 | loss: 0.3120 | ds_loss: 0.0000 | lr: 4.1612e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2274/  8460 | global iter:   2274/  8460 | loss: 1.1149 | ds_loss: 0.0000 | lr: 4.1605e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2275/  8460 | global iter:   2275/  8460 | loss: 1.4726 | ds_loss: 0.0000 | lr: 4.1598e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2276/  8460 | global iter:   2276/  8460 | loss: 0.6047 | ds_loss: 0.0000 | lr: 4.1592e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2276/  8460 | global iter:   2276/  8460 | loss: 0.8761 | ds_loss: 0.0000 | lr: 4.1592e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2277/  8460 | global iter:   2277/  8460 | loss: 0.5582 | ds_loss: 0.0000 | lr: 4.1585e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2278/  8460 | global iter:   2278/  8460 | loss: 0.4059 | ds_loss: 0.0000 | lr: 4.1578e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2279/  8460 | global iter:   2279/  8460 | loss: 0.7315 | ds_loss: 0.0000 | lr: 4.1571e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2280/  8460 | global iter:   2280/  8460 | loss: 0.3620 | ds_loss: 0.0000 | lr: 4.1564e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2280/  8460 | global iter:   2280/  8460 | loss: 0.5144 | ds_loss: 0.0000 | lr: 4.1564e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2281/  8460 | global iter:   2281/  8460 | loss: 0.4694 | ds_loss: 0.0000 | lr: 4.1557e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2282/  8460 | global iter:   2282/  8460 | loss: 0.7187 | ds_loss: 0.0000 | lr: 4.1550e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2283/  8460 | global iter:   2283/  8460 | loss: 0.2965 | ds_loss: 0.0000 | lr: 4.1543e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2284/  8460 | global iter:   2284/  8460 | loss: 0.8285 | ds_loss: 0.0000 | lr: 4.1536e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2284/  8460 | global iter:   2284/  8460 | loss: 0.5783 | ds_loss: 0.0000 | lr: 4.1536e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2285/  8460 | global iter:   2285/  8460 | loss: 1.1209 | ds_loss: 0.0000 | lr: 4.1529e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2286/  8460 | global iter:   2286/  8460 | loss: 0.3231 | ds_loss: 0.0000 | lr: 4.1522e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2287/  8460 | global iter:   2287/  8460 | loss: 0.2783 | ds_loss: 0.0000 | lr: 4.1515e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2288/  8460 | global iter:   2288/  8460 | loss: 0.4451 | ds_loss: 0.0000 | lr: 4.1508e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2288/  8460 | global iter:   2288/  8460 | loss: 0.5419 | ds_loss: 0.0000 | lr: 4.1508e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2289/  8460 | global iter:   2289/  8460 | loss: 0.2193 | ds_loss: 0.0000 | lr: 4.1501e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2290/  8460 | global iter:   2290/  8460 | loss: 0.4758 | ds_loss: 0.0000 | lr: 4.1494e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2291/  8460 | global iter:   2291/  8460 | loss: 0.2588 | ds_loss: 0.0000 | lr: 4.1487e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2292/  8460 | global iter:   2292/  8460 | loss: 0.4176 | ds_loss: 0.0000 | lr: 4.1480e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2292/  8460 | global iter:   2292/  8460 | loss: 0.3429 | ds_loss: 0.0000 | lr: 4.1480e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2293/  8460 | global iter:   2293/  8460 | loss: 0.7902 | ds_loss: 0.0000 | lr: 4.1473e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2294/  8460 | global iter:   2294/  8460 | loss: 0.4542 | ds_loss: 0.0000 | lr: 4.1466e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2295/  8460 | global iter:   2295/  8460 | loss: 0.1521 | ds_loss: 0.0000 | lr: 4.1459e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2296/  8460 | global iter:   2296/  8460 | loss: 0.9096 | ds_loss: 0.0000 | lr: 4.1452e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2296/  8460 | global iter:   2296/  8460 | loss: 0.5765 | ds_loss: 0.0000 | lr: 4.1452e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2297/  8460 | global iter:   2297/  8460 | loss: 0.3920 | ds_loss: 0.0000 | lr: 4.1445e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2298/  8460 | global iter:   2298/  8460 | loss: 0.4114 | ds_loss: 0.0000 | lr: 4.1438e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2299/  8460 | global iter:   2299/  8460 | loss: 0.7623 | ds_loss: 0.0000 | lr: 4.1431e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2300/  8460 | global iter:   2300/  8460 | loss: 0.3455 | ds_loss: 0.0000 | lr: 4.1424e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2300/  8460 | global iter:   2300/  8460 | loss: 0.4778 | ds_loss: 0.0000 | lr: 4.1424e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2301/  8460 | global iter:   2301/  8460 | loss: 0.5804 | ds_loss: 0.0000 | lr: 4.1417e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2302/  8460 | global iter:   2302/  8460 | loss: 0.0779 | ds_loss: 0.0000 | lr: 4.1410e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2303/  8460 | global iter:   2303/  8460 | loss: 0.3537 | ds_loss: 0.0000 | lr: 4.1403e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2304/  8460 | global iter:   2304/  8460 | loss: 0.3487 | ds_loss: 0.0000 | lr: 4.1396e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2304/  8460 | global iter:   2304/  8460 | loss: 0.3402 | ds_loss: 0.0000 | lr: 4.1396e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2305/  8460 | global iter:   2305/  8460 | loss: 0.6687 | ds_loss: 0.0000 | lr: 4.1389e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2306/  8460 | global iter:   2306/  8460 | loss: 0.3056 | ds_loss: 0.0000 | lr: 4.1382e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2307/  8460 | global iter:   2307/  8460 | loss: 0.8662 | ds_loss: 0.0000 | lr: 4.1375e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2308/  8460 | global iter:   2308/  8460 | loss: 0.4501 | ds_loss: 0.0000 | lr: 4.1368e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2308/  8460 | global iter:   2308/  8460 | loss: 0.5727 | ds_loss: 0.0000 | lr: 4.1368e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2309/  8460 | global iter:   2309/  8460 | loss: 0.4519 | ds_loss: 0.0000 | lr: 4.1361e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2310/  8460 | global iter:   2310/  8460 | loss: 0.2496 | ds_loss: 0.0000 | lr: 4.1354e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2311/  8460 | global iter:   2311/  8460 | loss: 0.4023 | ds_loss: 0.0000 | lr: 4.1347e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2312/  8460 | global iter:   2312/  8460 | loss: 0.8172 | ds_loss: 0.0000 | lr: 4.1340e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2312/  8460 | global iter:   2312/  8460 | loss: 0.4802 | ds_loss: 0.0000 | lr: 4.1340e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2313/  8460 | global iter:   2313/  8460 | loss: 0.5356 | ds_loss: 0.0000 | lr: 4.1333e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2314/  8460 | global iter:   2314/  8460 | loss: 0.2463 | ds_loss: 0.0000 | lr: 4.1326e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2315/  8460 | global iter:   2315/  8460 | loss: 0.3091 | ds_loss: 0.0000 | lr: 4.1319e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2316/  8460 | global iter:   2316/  8460 | loss: 0.4296 | ds_loss: 0.0000 | lr: 4.1312e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2316/  8460 | global iter:   2316/  8460 | loss: 0.3802 | ds_loss: 0.0000 | lr: 4.1312e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2317/  8460 | global iter:   2317/  8460 | loss: 0.2770 | ds_loss: 0.0000 | lr: 4.1305e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2318/  8460 | global iter:   2318/  8460 | loss: 0.4422 | ds_loss: 0.0000 | lr: 4.1298e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2319/  8460 | global iter:   2319/  8460 | loss: 0.1817 | ds_loss: 0.0000 | lr: 4.1291e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2320/  8460 | global iter:   2320/  8460 | loss: 0.3083 | ds_loss: 0.0000 | lr: 4.1284e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2320/  8460 | global iter:   2320/  8460 | loss: 0.3023 | ds_loss: 0.0000 | lr: 4.1284e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2321/  8460 | global iter:   2321/  8460 | loss: 0.7589 | ds_loss: 0.0000 | lr: 4.1277e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2322/  8460 | global iter:   2322/  8460 | loss: 0.2619 | ds_loss: 0.0000 | lr: 4.1270e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2323/  8460 | global iter:   2323/  8460 | loss: 0.3739 | ds_loss: 0.0000 | lr: 4.1263e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2324/  8460 | global iter:   2324/  8460 | loss: 0.8969 | ds_loss: 0.0000 | lr: 4.1256e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2324/  8460 | global iter:   2324/  8460 | loss: 0.5729 | ds_loss: 0.0000 | lr: 4.1256e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2325/  8460 | global iter:   2325/  8460 | loss: 0.3741 | ds_loss: 0.0000 | lr: 4.1249e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2326/  8460 | global iter:   2326/  8460 | loss: 0.2031 | ds_loss: 0.0000 | lr: 4.1241e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2327/  8460 | global iter:   2327/  8460 | loss: 0.4375 | ds_loss: 0.0000 | lr: 4.1234e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2328/  8460 | global iter:   2328/  8460 | loss: 0.8846 | ds_loss: 0.0000 | lr: 4.1227e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2328/  8460 | global iter:   2328/  8460 | loss: 0.4748 | ds_loss: 0.0000 | lr: 4.1227e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2329/  8460 | global iter:   2329/  8460 | loss: 0.9600 | ds_loss: 0.0000 | lr: 4.1220e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2330/  8460 | global iter:   2330/  8460 | loss: 0.5875 | ds_loss: 0.0000 | lr: 4.1213e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2331/  8460 | global iter:   2331/  8460 | loss: 0.3828 | ds_loss: 0.0000 | lr: 4.1206e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2332/  8460 | global iter:   2332/  8460 | loss: 0.3601 | ds_loss: 0.0000 | lr: 4.1199e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2332/  8460 | global iter:   2332/  8460 | loss: 0.5726 | ds_loss: 0.0000 | lr: 4.1199e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2333/  8460 | global iter:   2333/  8460 | loss: 0.2635 | ds_loss: 0.0000 | lr: 4.1192e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2334/  8460 | global iter:   2334/  8460 | loss: 0.3872 | ds_loss: 0.0000 | lr: 4.1185e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2335/  8460 | global iter:   2335/  8460 | loss: 0.2553 | ds_loss: 0.0000 | lr: 4.1178e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2336/  8460 | global iter:   2336/  8460 | loss: 0.7136 | ds_loss: 0.0000 | lr: 4.1171e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2336/  8460 | global iter:   2336/  8460 | loss: 0.4049 | ds_loss: 0.0000 | lr: 4.1171e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2337/  8460 | global iter:   2337/  8460 | loss: 0.1847 | ds_loss: 0.0000 | lr: 4.1164e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2338/  8460 | global iter:   2338/  8460 | loss: 0.1275 | ds_loss: 0.0000 | lr: 4.1157e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2339/  8460 | global iter:   2339/  8460 | loss: 1.2334 | ds_loss: 0.0000 | lr: 4.1150e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2340/  8460 | global iter:   2340/  8460 | loss: 0.5373 | ds_loss: 0.0000 | lr: 4.1142e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2340/  8460 | global iter:   2340/  8460 | loss: 0.5207 | ds_loss: 0.0000 | lr: 4.1142e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2341/  8460 | global iter:   2341/  8460 | loss: 1.0097 | ds_loss: 0.0000 | lr: 4.1135e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2342/  8460 | global iter:   2342/  8460 | loss: 0.4212 | ds_loss: 0.0000 | lr: 4.1128e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2343/  8460 | global iter:   2343/  8460 | loss: 0.8491 | ds_loss: 0.0000 | lr: 4.1121e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2344/  8460 | global iter:   2344/  8460 | loss: 0.5277 | ds_loss: 0.0000 | lr: 4.1114e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2344/  8460 | global iter:   2344/  8460 | loss: 0.7019 | ds_loss: 0.0000 | lr: 4.1114e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2345/  8460 | global iter:   2345/  8460 | loss: 0.5900 | ds_loss: 0.0000 | lr: 4.1107e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2346/  8460 | global iter:   2346/  8460 | loss: 0.2550 | ds_loss: 0.0000 | lr: 4.1100e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2347/  8460 | global iter:   2347/  8460 | loss: 0.2860 | ds_loss: 0.0000 | lr: 4.1093e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2348/  8460 | global iter:   2348/  8460 | loss: 0.2927 | ds_loss: 0.0000 | lr: 4.1086e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2348/  8460 | global iter:   2348/  8460 | loss: 0.3559 | ds_loss: 0.0000 | lr: 4.1086e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2349/  8460 | global iter:   2349/  8460 | loss: 0.5152 | ds_loss: 0.0000 | lr: 4.1079e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2350/  8460 | global iter:   2350/  8460 | loss: 0.3911 | ds_loss: 0.0000 | lr: 4.1071e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2351/  8460 | global iter:   2351/  8460 | loss: 0.5135 | ds_loss: 0.0000 | lr: 4.1064e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2352/  8460 | global iter:   2352/  8460 | loss: 0.4167 | ds_loss: 0.0000 | lr: 4.1057e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2352/  8460 | global iter:   2352/  8460 | loss: 0.4591 | ds_loss: 0.0000 | lr: 4.1057e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2353/  8460 | global iter:   2353/  8460 | loss: 0.7215 | ds_loss: 0.0000 | lr: 4.1050e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2354/  8460 | global iter:   2354/  8460 | loss: 0.9607 | ds_loss: 0.0000 | lr: 4.1043e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2355/  8460 | global iter:   2355/  8460 | loss: 0.4322 | ds_loss: 0.0000 | lr: 4.1036e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2356/  8460 | global iter:   2356/  8460 | loss: 0.7415 | ds_loss: 0.0000 | lr: 4.1029e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2356/  8460 | global iter:   2356/  8460 | loss: 0.7140 | ds_loss: 0.0000 | lr: 4.1029e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2357/  8460 | global iter:   2357/  8460 | loss: 0.3975 | ds_loss: 0.0000 | lr: 4.1022e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.000
train | epoch   2 | Iter:   2358/  8460 | global iter:   2358/  8460 | loss: 0.5688 | ds_loss: 0.0000 | lr: 4.1015e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2359/  8460 | global iter:   2359/  8460 | loss: 0.9859 | ds_loss: 0.0000 | lr: 4.1007e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2360/  8460 | global iter:   2360/  8460 | loss: 0.2703 | ds_loss: 0.0000 | lr: 4.1000e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2360/  8460 | global iter:   2360/  8460 | loss: 0.5556 | ds_loss: 0.0000 | lr: 4.1000e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2361/  8460 | global iter:   2361/  8460 | loss: 0.0783 | ds_loss: 0.0000 | lr: 4.0993e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2362/  8460 | global iter:   2362/  8460 | loss: 0.4774 | ds_loss: 0.0000 | lr: 4.0986e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2363/  8460 | global iter:   2363/  8460 | loss: 0.5000 | ds_loss: 0.0000 | lr: 4.0979e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2364/  8460 | global iter:   2364/  8460 | loss: 0.3310 | ds_loss: 0.0000 | lr: 4.0972e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2364/  8460 | global iter:   2364/  8460 | loss: 0.3467 | ds_loss: 0.0000 | lr: 4.0972e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2365/  8460 | global iter:   2365/  8460 | loss: 0.6052 | ds_loss: 0.0000 | lr: 4.0965e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2366/  8460 | global iter:   2366/  8460 | loss: 0.3344 | ds_loss: 0.0000 | lr: 4.0957e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2367/  8460 | global iter:   2367/  8460 | loss: 0.6418 | ds_loss: 0.0000 | lr: 4.0950e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2368/  8460 | global iter:   2368/  8460 | loss: 0.8467 | ds_loss: 0.0000 | lr: 4.0943e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2368/  8460 | global iter:   2368/  8460 | loss: 0.6070 | ds_loss: 0.0000 | lr: 4.0943e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2369/  8460 | global iter:   2369/  8460 | loss: 0.5935 | ds_loss: 0.0000 | lr: 4.0936e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2370/  8460 | global iter:   2370/  8460 | loss: 0.6795 | ds_loss: 0.0000 | lr: 4.0929e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2371/  8460 | global iter:   2371/  8460 | loss: 0.3356 | ds_loss: 0.0000 | lr: 4.0922e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2372/  8460 | global iter:   2372/  8460 | loss: 0.6106 | ds_loss: 0.0000 | lr: 4.0915e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2372/  8460 | global iter:   2372/  8460 | loss: 0.5548 | ds_loss: 0.0000 | lr: 4.0915e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2373/  8460 | global iter:   2373/  8460 | loss: 0.3687 | ds_loss: 0.0000 | lr: 4.0907e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2374/  8460 | global iter:   2374/  8460 | loss: 0.2981 | ds_loss: 0.0000 | lr: 4.0900e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2375/  8460 | global iter:   2375/  8460 | loss: 0.3158 | ds_loss: 0.0000 | lr: 4.0893e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2376/  8460 | global iter:   2376/  8460 | loss: 1.3018 | ds_loss: 0.0000 | lr: 4.0886e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2376/  8460 | global iter:   2376/  8460 | loss: 0.5711 | ds_loss: 0.0000 | lr: 4.0886e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2377/  8460 | global iter:   2377/  8460 | loss: 0.4893 | ds_loss: 0.0000 | lr: 4.0879e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2378/  8460 | global iter:   2378/  8460 | loss: 0.9607 | ds_loss: 0.0000 | lr: 4.0872e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2379/  8460 | global iter:   2379/  8460 | loss: 0.3621 | ds_loss: 0.0000 | lr: 4.0864e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2380/  8460 | global iter:   2380/  8460 | loss: 0.1489 | ds_loss: 0.0000 | lr: 4.0857e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2380/  8460 | global iter:   2380/  8460 | loss: 0.4903 | ds_loss: 0.0000 | lr: 4.0857e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2381/  8460 | global iter:   2381/  8460 | loss: 0.7280 | ds_loss: 0.0000 | lr: 4.0850e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2382/  8460 | global iter:   2382/  8460 | loss: 0.6875 | ds_loss: 0.0000 | lr: 4.0843e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2383/  8460 | global iter:   2383/  8460 | loss: 0.3668 | ds_loss: 0.0000 | lr: 4.0836e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2384/  8460 | global iter:   2384/  8460 | loss: 0.8108 | ds_loss: 0.0000 | lr: 4.0828e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2384/  8460 | global iter:   2384/  8460 | loss: 0.6483 | ds_loss: 0.0000 | lr: 4.0828e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2385/  8460 | global iter:   2385/  8460 | loss: 0.7185 | ds_loss: 0.0000 | lr: 4.0821e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2386/  8460 | global iter:   2386/  8460 | loss: 0.2444 | ds_loss: 0.0000 | lr: 4.0814e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2387/  8460 | global iter:   2387/  8460 | loss: 0.5761 | ds_loss: 0.0000 | lr: 4.0807e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2388/  8460 | global iter:   2388/  8460 | loss: 0.4077 | ds_loss: 0.0000 | lr: 4.0800e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2388/  8460 | global iter:   2388/  8460 | loss: 0.4867 | ds_loss: 0.0000 | lr: 4.0800e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2389/  8460 | global iter:   2389/  8460 | loss: 0.0410 | ds_loss: 0.0000 | lr: 4.0793e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2390/  8460 | global iter:   2390/  8460 | loss: 0.4192 | ds_loss: 0.0000 | lr: 4.0785e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2391/  8460 | global iter:   2391/  8460 | loss: 0.2582 | ds_loss: 0.0000 | lr: 4.0778e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2392/  8460 | global iter:   2392/  8460 | loss: 1.1103 | ds_loss: 0.0000 | lr: 4.0771e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2392/  8460 | global iter:   2392/  8460 | loss: 0.4572 | ds_loss: 0.0000 | lr: 4.0771e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2393/  8460 | global iter:   2393/  8460 | loss: 0.3118 | ds_loss: 0.0000 | lr: 4.0764e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2394/  8460 | global iter:   2394/  8460 | loss: 0.2934 | ds_loss: 0.0000 | lr: 4.0756e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2395/  8460 | global iter:   2395/  8460 | loss: 0.9590 | ds_loss: 0.0000 | lr: 4.0749e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2396/  8460 | global iter:   2396/  8460 | loss: 0.6757 | ds_loss: 0.0000 | lr: 4.0742e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2396/  8460 | global iter:   2396/  8460 | loss: 0.5600 | ds_loss: 0.0000 | lr: 4.0742e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2397/  8460 | global iter:   2397/  8460 | loss: 0.6138 | ds_loss: 0.0000 | lr: 4.0735e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2398/  8460 | global iter:   2398/  8460 | loss: 0.5002 | ds_loss: 0.0000 | lr: 4.0728e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2399/  8460 | global iter:   2399/  8460 | loss: 0.4614 | ds_loss: 0.0000 | lr: 4.0720e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2400/  8460 | global iter:   2400/  8460 | loss: 0.5900 | ds_loss: 0.0000 | lr: 4.0713e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2400/  8460 | global iter:   2400/  8460 | loss: 0.5414 | ds_loss: 0.0000 | lr: 4.0713e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2401/  8460 | global iter:   2401/  8460 | loss: 0.3880 | ds_loss: 0.0000 | lr: 4.0706e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2402/  8460 | global iter:   2402/  8460 | loss: 0.3323 | ds_loss: 0.0000 | lr: 4.0699e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2403/  8460 | global iter:   2403/  8460 | loss: 0.2738 | ds_loss: 0.0000 | lr: 4.0692e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2404/  8460 | global iter:   2404/  8460 | loss: 0.3146 | ds_loss: 0.0000 | lr: 4.0684e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2404/  8460 | global iter:   2404/  8460 | loss: 0.3272 | ds_loss: 0.0000 | lr: 4.0684e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2405/  8460 | global iter:   2405/  8460 | loss: 0.2656 | ds_loss: 0.0000 | lr: 4.0677e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2406/  8460 | global iter:   2406/  8460 | loss: 0.2465 | ds_loss: 0.0000 | lr: 4.0670e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2407/  8460 | global iter:   2407/  8460 | loss: 0.6184 | ds_loss: 0.0000 | lr: 4.0663e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2408/  8460 | global iter:   2408/  8460 | loss: 0.6094 | ds_loss: 0.0000 | lr: 4.0655e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2408/  8460 | global iter:   2408/  8460 | loss: 0.4350 | ds_loss: 0.0000 | lr: 4.0655e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2409/  8460 | global iter:   2409/  8460 | loss: 0.3132 | ds_loss: 0.0000 | lr: 4.0648e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2410/  8460 | global iter:   2410/  8460 | loss: 0.2095 | ds_loss: 0.0000 | lr: 4.0641e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2411/  8460 | global iter:   2411/  8460 | loss: 0.9876 | ds_loss: 0.0000 | lr: 4.0634e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2412/  8460 | global iter:   2412/  8460 | loss: 0.5721 | ds_loss: 0.0000 | lr: 4.0626e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2412/  8460 | global iter:   2412/  8460 | loss: 0.5206 | ds_loss: 0.0000 | lr: 4.0626e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2413/  8460 | global iter:   2413/  8460 | loss: 0.6297 | ds_loss: 0.0000 | lr: 4.0619e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2414/  8460 | global iter:   2414/  8460 | loss: 0.3421 | ds_loss: 0.0000 | lr: 4.0612e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2415/  8460 | global iter:   2415/  8460 | loss: 0.6323 | ds_loss: 0.0000 | lr: 4.0605e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2416/  8460 | global iter:   2416/  8460 | loss: 0.3851 | ds_loss: 0.0000 | lr: 4.0597e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2416/  8460 | global iter:   2416/  8460 | loss: 0.4973 | ds_loss: 0.0000 | lr: 4.0597e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2417/  8460 | global iter:   2417/  8460 | loss: 0.3109 | ds_loss: 0.0000 | lr: 4.0590e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2418/  8460 | global iter:   2418/  8460 | loss: 0.5327 | ds_loss: 0.0000 | lr: 4.0583e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2419/  8460 | global iter:   2419/  8460 | loss: 0.4889 | ds_loss: 0.0000 | lr: 4.0576e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2420/  8460 | global iter:   2420/  8460 | loss: 0.4309 | ds_loss: 0.0000 | lr: 4.0568e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2420/  8460 | global iter:   2420/  8460 | loss: 0.4408 | ds_loss: 0.0000 | lr: 4.0568e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2421/  8460 | global iter:   2421/  8460 | loss: 0.3126 | ds_loss: 0.0000 | lr: 4.0561e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2422/  8460 | global iter:   2422/  8460 | loss: 1.0886 | ds_loss: 0.0000 | lr: 4.0554e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2423/  8460 | global iter:   2423/  8460 | loss: 0.5447 | ds_loss: 0.0000 | lr: 4.0547e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2424/  8460 | global iter:   2424/  8460 | loss: 0.3612 | ds_loss: 0.0000 | lr: 4.0539e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2424/  8460 | global iter:   2424/  8460 | loss: 0.5768 | ds_loss: 0.0000 | lr: 4.0539e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2425/  8460 | global iter:   2425/  8460 | loss: 0.2703 | ds_loss: 0.0000 | lr: 4.0532e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2426/  8460 | global iter:   2426/  8460 | loss: 0.8888 | ds_loss: 0.0000 | lr: 4.0525e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2427/  8460 | global iter:   2427/  8460 | loss: 0.4851 | ds_loss: 0.0000 | lr: 4.0517e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2428/  8460 | global iter:   2428/  8460 | loss: 0.3067 | ds_loss: 0.0000 | lr: 4.0510e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2428/  8460 | global iter:   2428/  8460 | loss: 0.4877 | ds_loss: 0.0000 | lr: 4.0510e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2429/  8460 | global iter:   2429/  8460 | loss: 0.7905 | ds_loss: 0.0000 | lr: 4.0503e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2430/  8460 | global iter:   2430/  8460 | loss: 0.5328 | ds_loss: 0.0000 | lr: 4.0496e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2431/  8460 | global iter:   2431/  8460 | loss: 0.3057 | ds_loss: 0.0000 | lr: 4.0488e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2432/  8460 | global iter:   2432/  8460 | loss: 0.4550 | ds_loss: 0.0000 | lr: 4.0481e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2432/  8460 | global iter:   2432/  8460 | loss: 0.5210 | ds_loss: 0.0000 | lr: 4.0481e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2433/  8460 | global iter:   2433/  8460 | loss: 0.5217 | ds_loss: 0.0000 | lr: 4.0474e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2434/  8460 | global iter:   2434/  8460 | loss: 0.1913 | ds_loss: 0.0000 | lr: 4.0466e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2435/  8460 | global iter:   2435/  8460 | loss: 0.6447 | ds_loss: 0.0000 | lr: 4.0459e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2436/  8460 | global iter:   2436/  8460 | loss: 0.9924 | ds_loss: 0.0000 | lr: 4.0452e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2436/  8460 | global iter:   2436/  8460 | loss: 0.5875 | ds_loss: 0.0000 | lr: 4.0452e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2437/  8460 | global iter:   2437/  8460 | loss: 0.4111 | ds_loss: 0.0000 | lr: 4.0445e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2438/  8460 | global iter:   2438/  8460 | loss: 0.5461 | ds_loss: 0.0000 | lr: 4.0437e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2439/  8460 | global iter:   2439/  8460 | loss: 0.3594 | ds_loss: 0.0000 | lr: 4.0430e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2440/  8460 | global iter:   2440/  8460 | loss: 0.6950 | ds_loss: 0.0000 | lr: 4.0423e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2440/  8460 | global iter:   2440/  8460 | loss: 0.5029 | ds_loss: 0.0000 | lr: 4.0423e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2441/  8460 | global iter:   2441/  8460 | loss: 0.2810 | ds_loss: 0.0000 | lr: 4.0415e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2442/  8460 | global iter:   2442/  8460 | loss: 0.5760 | ds_loss: 0.0000 | lr: 4.0408e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2443/  8460 | global iter:   2443/  8460 | loss: 0.7029 | ds_loss: 0.0000 | lr: 4.0401e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2444/  8460 | global iter:   2444/  8460 | loss: 0.6392 | ds_loss: 0.0000 | lr: 4.0393e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2444/  8460 | global iter:   2444/  8460 | loss: 0.5498 | ds_loss: 0.0000 | lr: 4.0393e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2445/  8460 | global iter:   2445/  8460 | loss: 0.5047 | ds_loss: 0.0000 | lr: 4.0386e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2446/  8460 | global iter:   2446/  8460 | loss: 0.2358 | ds_loss: 0.0000 | lr: 4.0379e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2447/  8460 | global iter:   2447/  8460 | loss: 0.3110 | ds_loss: 0.0000 | lr: 4.0372e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2448/  8460 | global iter:   2448/  8460 | loss: 0.6743 | ds_loss: 0.0000 | lr: 4.0364e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2448/  8460 | global iter:   2448/  8460 | loss: 0.4315 | ds_loss: 0.0000 | lr: 4.0364e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2449/  8460 | global iter:   2449/  8460 | loss: 0.3290 | ds_loss: 0.0000 | lr: 4.0357e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2450/  8460 | global iter:   2450/  8460 | loss: 0.3941 | ds_loss: 0.0000 | lr: 4.0350e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2451/  8460 | global iter:   2451/  8460 | loss: 0.3249 | ds_loss: 0.0000 | lr: 4.0342e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2452/  8460 | global iter:   2452/  8460 | loss: 0.5117 | ds_loss: 0.0000 | lr: 4.0335e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2452/  8460 | global iter:   2452/  8460 | loss: 0.3899 | ds_loss: 0.0000 | lr: 4.0335e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2453/  8460 | global iter:   2453/  8460 | loss: 0.1217 | ds_loss: 0.0000 | lr: 4.0328e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2454/  8460 | global iter:   2454/  8460 | loss: 0.1894 | ds_loss: 0.0000 | lr: 4.0320e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2455/  8460 | global iter:   2455/  8460 | loss: 0.1204 | ds_loss: 0.0000 | lr: 4.0313e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2456/  8460 | global iter:   2456/  8460 | loss: 0.5841 | ds_loss: 0.0000 | lr: 4.0306e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2456/  8460 | global iter:   2456/  8460 | loss: 0.2539 | ds_loss: 0.0000 | lr: 4.0306e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2457/  8460 | global iter:   2457/  8460 | loss: 0.2852 | ds_loss: 0.0000 | lr: 4.0298e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2458/  8460 | global iter:   2458/  8460 | loss: 0.9079 | ds_loss: 0.0000 | lr: 4.0291e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2459/  8460 | global iter:   2459/  8460 | loss: 0.3026 | ds_loss: 0.0000 | lr: 4.0284e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2460/  8460 | global iter:   2460/  8460 | loss: 0.1788 | ds_loss: 0.0000 | lr: 4.0276e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2460/  8460 | global iter:   2460/  8460 | loss: 0.4186 | ds_loss: 0.0000 | lr: 4.0276e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2461/  8460 | global iter:   2461/  8460 | loss: 0.3726 | ds_loss: 0.0000 | lr: 4.0269e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2462/  8460 | global iter:   2462/  8460 | loss: 0.7944 | ds_loss: 0.0000 | lr: 4.0261e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2463/  8460 | global iter:   2463/  8460 | loss: 0.4398 | ds_loss: 0.0000 | lr: 4.0254e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2464/  8460 | global iter:   2464/  8460 | loss: 0.9452 | ds_loss: 0.0000 | lr: 4.0247e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2464/  8460 | global iter:   2464/  8460 | loss: 0.6380 | ds_loss: 0.0000 | lr: 4.0247e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2465/  8460 | global iter:   2465/  8460 | loss: 0.1965 | ds_loss: 0.0000 | lr: 4.0239e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   2 | Iter:   2466/  8460 | global iter:   2466/  8460 | loss: 0.2993 | ds_loss: 0.0000 | lr: 4.0232e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2467/  8460 | global iter:   2467/  8460 | loss: 0.4162 | ds_loss: 0.0000 | lr: 4.0225e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2468/  8460 | global iter:   2468/  8460 | loss: 0.2945 | ds_loss: 0.0000 | lr: 4.0217e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2468/  8460 | global iter:   2468/  8460 | loss: 0.3016 | ds_loss: 0.0000 | lr: 4.0217e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2469/  8460 | global iter:   2469/  8460 | loss: 0.2001 | ds_loss: 0.0000 | lr: 4.0210e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2470/  8460 | global iter:   2470/  8460 | loss: 0.5526 | ds_loss: 0.0000 | lr: 4.0203e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2471/  8460 | global iter:   2471/  8460 | loss: 0.3924 | ds_loss: 0.0000 | lr: 4.0195e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2472/  8460 | global iter:   2472/  8460 | loss: 0.5536 | ds_loss: 0.0000 | lr: 4.0188e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2472/  8460 | global iter:   2472/  8460 | loss: 0.4247 | ds_loss: 0.0000 | lr: 4.0188e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2473/  8460 | global iter:   2473/  8460 | loss: 0.1404 | ds_loss: 0.0000 | lr: 4.0180e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2474/  8460 | global iter:   2474/  8460 | loss: 0.7643 | ds_loss: 0.0000 | lr: 4.0173e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2475/  8460 | global iter:   2475/  8460 | loss: 0.2882 | ds_loss: 0.0000 | lr: 4.0166e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2476/  8460 | global iter:   2476/  8460 | loss: 0.7552 | ds_loss: 0.0000 | lr: 4.0158e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2476/  8460 | global iter:   2476/  8460 | loss: 0.4870 | ds_loss: 0.0000 | lr: 4.0158e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2477/  8460 | global iter:   2477/  8460 | loss: 0.8605 | ds_loss: 0.0000 | lr: 4.0151e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2478/  8460 | global iter:   2478/  8460 | loss: 0.3572 | ds_loss: 0.0000 | lr: 4.0144e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2479/  8460 | global iter:   2479/  8460 | loss: 0.2550 | ds_loss: 0.0000 | lr: 4.0136e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2480/  8460 | global iter:   2480/  8460 | loss: 0.6463 | ds_loss: 0.0000 | lr: 4.0129e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2480/  8460 | global iter:   2480/  8460 | loss: 0.5297 | ds_loss: 0.0000 | lr: 4.0129e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2481/  8460 | global iter:   2481/  8460 | loss: 1.0616 | ds_loss: 0.0000 | lr: 4.0121e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2482/  8460 | global iter:   2482/  8460 | loss: 0.3338 | ds_loss: 0.0000 | lr: 4.0114e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2483/  8460 | global iter:   2483/  8460 | loss: 0.3076 | ds_loss: 0.0000 | lr: 4.0107e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2484/  8460 | global iter:   2484/  8460 | loss: 0.8101 | ds_loss: 0.0000 | lr: 4.0099e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2484/  8460 | global iter:   2484/  8460 | loss: 0.6283 | ds_loss: 0.0000 | lr: 4.0099e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2485/  8460 | global iter:   2485/  8460 | loss: 0.3212 | ds_loss: 0.0000 | lr: 4.0092e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2486/  8460 | global iter:   2486/  8460 | loss: 0.6271 | ds_loss: 0.0000 | lr: 4.0084e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2487/  8460 | global iter:   2487/  8460 | loss: 0.2978 | ds_loss: 0.0000 | lr: 4.0077e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2488/  8460 | global iter:   2488/  8460 | loss: 0.1286 | ds_loss: 0.0000 | lr: 4.0070e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2488/  8460 | global iter:   2488/  8460 | loss: 0.3437 | ds_loss: 0.0000 | lr: 4.0070e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2489/  8460 | global iter:   2489/  8460 | loss: 0.3811 | ds_loss: 0.0000 | lr: 4.0062e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2490/  8460 | global iter:   2490/  8460 | loss: 0.4653 | ds_loss: 0.0000 | lr: 4.0055e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2491/  8460 | global iter:   2491/  8460 | loss: 0.1812 | ds_loss: 0.0000 | lr: 4.0047e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2492/  8460 | global iter:   2492/  8460 | loss: 0.8643 | ds_loss: 0.0000 | lr: 4.0040e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2492/  8460 | global iter:   2492/  8460 | loss: 0.4730 | ds_loss: 0.0000 | lr: 4.0040e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2493/  8460 | global iter:   2493/  8460 | loss: 0.1541 | ds_loss: 0.0000 | lr: 4.0033e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2494/  8460 | global iter:   2494/  8460 | loss: 0.4644 | ds_loss: 0.0000 | lr: 4.0025e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2495/  8460 | global iter:   2495/  8460 | loss: 0.6730 | ds_loss: 0.0000 | lr: 4.0018e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2496/  8460 | global iter:   2496/  8460 | loss: 0.1982 | ds_loss: 0.0000 | lr: 4.0010e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2496/  8460 | global iter:   2496/  8460 | loss: 0.3724 | ds_loss: 0.0000 | lr: 4.0010e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2497/  8460 | global iter:   2497/  8460 | loss: 0.3333 | ds_loss: 0.0000 | lr: 4.0003e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2498/  8460 | global iter:   2498/  8460 | loss: 0.4865 | ds_loss: 0.0000 | lr: 3.9995e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2499/  8460 | global iter:   2499/  8460 | loss: 0.2256 | ds_loss: 0.0000 | lr: 3.9988e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2500/  8460 | global iter:   2500/  8460 | loss: 0.3390 | ds_loss: 0.0000 | lr: 3.9981e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2500/  8460 | global iter:   2500/  8460 | loss: 0.3461 | ds_loss: 0.0000 | lr: 3.9981e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2501/  8460 | global iter:   2501/  8460 | loss: 0.4270 | ds_loss: 0.0000 | lr: 3.9973e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2502/  8460 | global iter:   2502/  8460 | loss: 0.4797 | ds_loss: 0.0000 | lr: 3.9966e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2503/  8460 | global iter:   2503/  8460 | loss: 0.5285 | ds_loss: 0.0000 | lr: 3.9958e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2504/  8460 | global iter:   2504/  8460 | loss: 0.4410 | ds_loss: 0.0000 | lr: 3.9951e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2504/  8460 | global iter:   2504/  8460 | loss: 0.4690 | ds_loss: 0.0000 | lr: 3.9951e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2505/  8460 | global iter:   2505/  8460 | loss: 0.4536 | ds_loss: 0.0000 | lr: 3.9943e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2506/  8460 | global iter:   2506/  8460 | loss: 0.6041 | ds_loss: 0.0000 | lr: 3.9936e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2507/  8460 | global iter:   2507/  8460 | loss: 0.1975 | ds_loss: 0.0000 | lr: 3.9928e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2508/  8460 | global iter:   2508/  8460 | loss: 0.9036 | ds_loss: 0.0000 | lr: 3.9921e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2508/  8460 | global iter:   2508/  8460 | loss: 0.5397 | ds_loss: 0.0000 | lr: 3.9921e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2509/  8460 | global iter:   2509/  8460 | loss: 0.4076 | ds_loss: 0.0000 | lr: 3.9914e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2510/  8460 | global iter:   2510/  8460 | loss: 0.6365 | ds_loss: 0.0000 | lr: 3.9906e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2511/  8460 | global iter:   2511/  8460 | loss: 0.5532 | ds_loss: 0.0000 | lr: 3.9899e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2512/  8460 | global iter:   2512/  8460 | loss: 0.9859 | ds_loss: 0.0000 | lr: 3.9891e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2512/  8460 | global iter:   2512/  8460 | loss: 0.6458 | ds_loss: 0.0000 | lr: 3.9891e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2513/  8460 | global iter:   2513/  8460 | loss: 0.4735 | ds_loss: 0.0000 | lr: 3.9884e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2514/  8460 | global iter:   2514/  8460 | loss: 0.1167 | ds_loss: 0.0000 | lr: 3.9876e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2515/  8460 | global iter:   2515/  8460 | loss: 0.8052 | ds_loss: 0.0000 | lr: 3.9869e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2516/  8460 | global iter:   2516/  8460 | loss: 0.8310 | ds_loss: 0.0000 | lr: 3.9861e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2516/  8460 | global iter:   2516/  8460 | loss: 0.5566 | ds_loss: 0.0000 | lr: 3.9861e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2517/  8460 | global iter:   2517/  8460 | loss: 0.4554 | ds_loss: 0.0000 | lr: 3.9854e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2518/  8460 | global iter:   2518/  8460 | loss: 0.6075 | ds_loss: 0.0000 | lr: 3.9846e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2519/  8460 | global iter:   2519/  8460 | loss: 0.1172 | ds_loss: 0.0000 | lr: 3.9839e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2520/  8460 | global iter:   2520/  8460 | loss: 0.5552 | ds_loss: 0.0000 | lr: 3.9832e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2520/  8460 | global iter:   2520/  8460 | loss: 0.4338 | ds_loss: 0.0000 | lr: 3.9832e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2521/  8460 | global iter:   2521/  8460 | loss: 1.1587 | ds_loss: 0.0000 | lr: 3.9824e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2522/  8460 | global iter:   2522/  8460 | loss: 0.1295 | ds_loss: 0.0000 | lr: 3.9817e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2523/  8460 | global iter:   2523/  8460 | loss: 0.1668 | ds_loss: 0.0000 | lr: 3.9809e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2524/  8460 | global iter:   2524/  8460 | loss: 0.4571 | ds_loss: 0.0000 | lr: 3.9802e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2524/  8460 | global iter:   2524/  8460 | loss: 0.4780 | ds_loss: 0.0000 | lr: 3.9802e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2525/  8460 | global iter:   2525/  8460 | loss: 0.9794 | ds_loss: 0.0000 | lr: 3.9794e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2526/  8460 | global iter:   2526/  8460 | loss: 0.2818 | ds_loss: 0.0000 | lr: 3.9787e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2527/  8460 | global iter:   2527/  8460 | loss: 0.6727 | ds_loss: 0.0000 | lr: 3.9779e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2528/  8460 | global iter:   2528/  8460 | loss: 0.2213 | ds_loss: 0.0000 | lr: 3.9772e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2528/  8460 | global iter:   2528/  8460 | loss: 0.5388 | ds_loss: 0.0000 | lr: 3.9772e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2529/  8460 | global iter:   2529/  8460 | loss: 0.2733 | ds_loss: 0.0000 | lr: 3.9764e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2530/  8460 | global iter:   2530/  8460 | loss: 0.7625 | ds_loss: 0.0000 | lr: 3.9757e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2531/  8460 | global iter:   2531/  8460 | loss: 0.5077 | ds_loss: 0.0000 | lr: 3.9749e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2532/  8460 | global iter:   2532/  8460 | loss: 0.6180 | ds_loss: 0.0000 | lr: 3.9742e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2532/  8460 | global iter:   2532/  8460 | loss: 0.5404 | ds_loss: 0.0000 | lr: 3.9742e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2533/  8460 | global iter:   2533/  8460 | loss: 0.7800 | ds_loss: 0.0000 | lr: 3.9734e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2534/  8460 | global iter:   2534/  8460 | loss: 0.3838 | ds_loss: 0.0000 | lr: 3.9727e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2535/  8460 | global iter:   2535/  8460 | loss: 0.9010 | ds_loss: 0.0000 | lr: 3.9719e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2536/  8460 | global iter:   2536/  8460 | loss: 0.5464 | ds_loss: 0.0000 | lr: 3.9712e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2536/  8460 | global iter:   2536/  8460 | loss: 0.6528 | ds_loss: 0.0000 | lr: 3.9712e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2537/  8460 | global iter:   2537/  8460 | loss: 0.8084 | ds_loss: 0.0000 | lr: 3.9704e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   2 | Iter:   2538/  8460 | global iter:   2538/  8460 | loss: 0.6186 | ds_loss: 0.0000 | lr: 3.9697e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2539/  8460 | global iter:   2539/  8460 | loss: 0.2494 | ds_loss: 0.0000 | lr: 3.9689e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   2 | Iter:   2540/  8460 | global iter:   2540/  8460 | loss: 0.3938 | ds_loss: 0.0000 | lr: 3.9682e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   2 | Iter:   2540/  8460 | global iter:   2540/  8460 | loss: 0.5176 | ds_loss: 0.0000 | lr: 3.9682e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   2 | Iter:   2541/  8460 | global iter:   2541/  8460 | loss: 0.1228 | ds_loss: 0.0000 | lr: 3.9674e-04 | scale:     1.0000 | micro time: 0.366 | step time: 0.000
Sun Apr  6 21:07:44 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla P100-PCIE-12GB           Off |   00000000:81:00.0 Off |                    0 |
| N/A   51C    P0             40W /  250W |    8807MiB /  12288MiB |     97%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A    244677      C   ...project_distillLLM/venv/bin/python3       8804MiB |
+-----------------------------------------------------------------------------------------+

train | epoch   3 | Iter:   2542/  8460 | global iter:   2542/  8460 | loss: 0.2998 | ds_loss: 0.0000 | lr: 3.9667e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2543/  8460 | global iter:   2543/  8460 | loss: 0.3489 | ds_loss: 0.0000 | lr: 3.9659e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2544/  8460 | global iter:   2544/  8460 | loss: 0.2841 | ds_loss: 0.0000 | lr: 3.9652e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2544/  8460 | global iter:   2544/  8460 | loss: 0.2639 | ds_loss: 0.0000 | lr: 3.9652e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.413
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2545/  8460 | global iter:   2545/  8460 | loss: 0.2599 | ds_loss: 0.0000 | lr: 3.9644e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   2546/  8460 | global iter:   2546/  8460 | loss: 0.6618 | ds_loss: 0.0000 | lr: 3.9637e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   2547/  8460 | global iter:   2547/  8460 | loss: 0.1431 | ds_loss: 0.0000 | lr: 3.9629e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2548/  8460 | global iter:   2548/  8460 | loss: 0.2184 | ds_loss: 0.0000 | lr: 3.9621e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2548/  8460 | global iter:   2548/  8460 | loss: 0.3208 | ds_loss: 0.0000 | lr: 3.9621e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2549/  8460 | global iter:   2549/  8460 | loss: 0.2376 | ds_loss: 0.0000 | lr: 3.9614e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2550/  8460 | global iter:   2550/  8460 | loss: 0.2902 | ds_loss: 0.0000 | lr: 3.9606e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2551/  8460 | global iter:   2551/  8460 | loss: 0.1400 | ds_loss: 0.0000 | lr: 3.9599e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2552/  8460 | global iter:   2552/  8460 | loss: 0.4823 | ds_loss: 0.0000 | lr: 3.9591e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2552/  8460 | global iter:   2552/  8460 | loss: 0.2875 | ds_loss: 0.0000 | lr: 3.9591e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2553/  8460 | global iter:   2553/  8460 | loss: 0.3538 | ds_loss: 0.0000 | lr: 3.9584e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2554/  8460 | global iter:   2554/  8460 | loss: 0.2748 | ds_loss: 0.0000 | lr: 3.9576e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2555/  8460 | global iter:   2555/  8460 | loss: 0.0849 | ds_loss: 0.0000 | lr: 3.9569e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2556/  8460 | global iter:   2556/  8460 | loss: 0.5393 | ds_loss: 0.0000 | lr: 3.9561e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2556/  8460 | global iter:   2556/  8460 | loss: 0.3132 | ds_loss: 0.0000 | lr: 3.9561e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2557/  8460 | global iter:   2557/  8460 | loss: 0.6146 | ds_loss: 0.0000 | lr: 3.9554e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2558/  8460 | global iter:   2558/  8460 | loss: 0.5263 | ds_loss: 0.0000 | lr: 3.9546e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2559/  8460 | global iter:   2559/  8460 | loss: 0.1771 | ds_loss: 0.0000 | lr: 3.9539e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2560/  8460 | global iter:   2560/  8460 | loss: 0.7268 | ds_loss: 0.0000 | lr: 3.9531e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2560/  8460 | global iter:   2560/  8460 | loss: 0.5112 | ds_loss: 0.0000 | lr: 3.9531e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2561/  8460 | global iter:   2561/  8460 | loss: 1.0466 | ds_loss: 0.0000 | lr: 3.9523e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2562/  8460 | global iter:   2562/  8460 | loss: 0.3020 | ds_loss: 0.0000 | lr: 3.9516e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2563/  8460 | global iter:   2563/  8460 | loss: 0.1120 | ds_loss: 0.0000 | lr: 3.9508e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2564/  8460 | global iter:   2564/  8460 | loss: 0.4155 | ds_loss: 0.0000 | lr: 3.9501e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2564/  8460 | global iter:   2564/  8460 | loss: 0.4690 | ds_loss: 0.0000 | lr: 3.9501e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2565/  8460 | global iter:   2565/  8460 | loss: 0.4736 | ds_loss: 0.0000 | lr: 3.9493e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2566/  8460 | global iter:   2566/  8460 | loss: 0.3777 | ds_loss: 0.0000 | lr: 3.9486e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2567/  8460 | global iter:   2567/  8460 | loss: 0.1941 | ds_loss: 0.0000 | lr: 3.9478e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2568/  8460 | global iter:   2568/  8460 | loss: 0.7482 | ds_loss: 0.0000 | lr: 3.9471e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2568/  8460 | global iter:   2568/  8460 | loss: 0.4484 | ds_loss: 0.0000 | lr: 3.9471e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2569/  8460 | global iter:   2569/  8460 | loss: 0.4828 | ds_loss: 0.0000 | lr: 3.9463e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2570/  8460 | global iter:   2570/  8460 | loss: 0.2708 | ds_loss: 0.0000 | lr: 3.9455e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2571/  8460 | global iter:   2571/  8460 | loss: 0.2984 | ds_loss: 0.0000 | lr: 3.9448e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2572/  8460 | global iter:   2572/  8460 | loss: 0.6618 | ds_loss: 0.0000 | lr: 3.9440e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2572/  8460 | global iter:   2572/  8460 | loss: 0.4285 | ds_loss: 0.0000 | lr: 3.9440e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2573/  8460 | global iter:   2573/  8460 | loss: 0.1921 | ds_loss: 0.0000 | lr: 3.9433e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2574/  8460 | global iter:   2574/  8460 | loss: 0.3872 | ds_loss: 0.0000 | lr: 3.9425e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2575/  8460 | global iter:   2575/  8460 | loss: 0.1697 | ds_loss: 0.0000 | lr: 3.9417e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2576/  8460 | global iter:   2576/  8460 | loss: 0.6370 | ds_loss: 0.0000 | lr: 3.9410e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2576/  8460 | global iter:   2576/  8460 | loss: 0.3465 | ds_loss: 0.0000 | lr: 3.9410e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2577/  8460 | global iter:   2577/  8460 | loss: 0.4467 | ds_loss: 0.0000 | lr: 3.9402e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2578/  8460 | global iter:   2578/  8460 | loss: 0.4751 | ds_loss: 0.0000 | lr: 3.9395e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2579/  8460 | global iter:   2579/  8460 | loss: 0.8344 | ds_loss: 0.0000 | lr: 3.9387e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2580/  8460 | global iter:   2580/  8460 | loss: 0.3991 | ds_loss: 0.0000 | lr: 3.9380e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2580/  8460 | global iter:   2580/  8460 | loss: 0.5388 | ds_loss: 0.0000 | lr: 3.9380e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2581/  8460 | global iter:   2581/  8460 | loss: 0.2556 | ds_loss: 0.0000 | lr: 3.9372e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2582/  8460 | global iter:   2582/  8460 | loss: 0.3409 | ds_loss: 0.0000 | lr: 3.9364e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2583/  8460 | global iter:   2583/  8460 | loss: 0.4261 | ds_loss: 0.0000 | lr: 3.9357e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2584/  8460 | global iter:   2584/  8460 | loss: 0.2245 | ds_loss: 0.0000 | lr: 3.9349e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2584/  8460 | global iter:   2584/  8460 | loss: 0.3118 | ds_loss: 0.0000 | lr: 3.9349e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2585/  8460 | global iter:   2585/  8460 | loss: 0.5011 | ds_loss: 0.0000 | lr: 3.9342e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2586/  8460 | global iter:   2586/  8460 | loss: 0.1830 | ds_loss: 0.0000 | lr: 3.9334e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   2587/  8460 | global iter:   2587/  8460 | loss: 0.2794 | ds_loss: 0.0000 | lr: 3.9326e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2588/  8460 | global iter:   2588/  8460 | loss: 0.2087 | ds_loss: 0.0000 | lr: 3.9319e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2588/  8460 | global iter:   2588/  8460 | loss: 0.2930 | ds_loss: 0.0000 | lr: 3.9319e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2589/  8460 | global iter:   2589/  8460 | loss: 0.1727 | ds_loss: 0.0000 | lr: 3.9311e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2590/  8460 | global iter:   2590/  8460 | loss: 0.4132 | ds_loss: 0.0000 | lr: 3.9304e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   2591/  8460 | global iter:   2591/  8460 | loss: 0.3610 | ds_loss: 0.0000 | lr: 3.9296e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   2592/  8460 | global iter:   2592/  8460 | loss: 0.4499 | ds_loss: 0.0000 | lr: 3.9288e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2592/  8460 | global iter:   2592/  8460 | loss: 0.3492 | ds_loss: 0.0000 | lr: 3.9288e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2593/  8460 | global iter:   2593/  8460 | loss: 0.2120 | ds_loss: 0.0000 | lr: 3.9281e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   2594/  8460 | global iter:   2594/  8460 | loss: 0.8364 | ds_loss: 0.0000 | lr: 3.9273e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   2595/  8460 | global iter:   2595/  8460 | loss: 0.1506 | ds_loss: 0.0000 | lr: 3.9265e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2596/  8460 | global iter:   2596/  8460 | loss: 0.4686 | ds_loss: 0.0000 | lr: 3.9258e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2596/  8460 | global iter:   2596/  8460 | loss: 0.4169 | ds_loss: 0.0000 | lr: 3.9258e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2597/  8460 | global iter:   2597/  8460 | loss: 0.8459 | ds_loss: 0.0000 | lr: 3.9250e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2598/  8460 | global iter:   2598/  8460 | loss: 0.1875 | ds_loss: 0.0000 | lr: 3.9243e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   2599/  8460 | global iter:   2599/  8460 | loss: 0.0453 | ds_loss: 0.0000 | lr: 3.9235e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2600/  8460 | global iter:   2600/  8460 | loss: 0.6328 | ds_loss: 0.0000 | lr: 3.9227e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2600/  8460 | global iter:   2600/  8460 | loss: 0.4279 | ds_loss: 0.0000 | lr: 3.9227e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2601/  8460 | global iter:   2601/  8460 | loss: 0.6516 | ds_loss: 0.0000 | lr: 3.9220e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2602/  8460 | global iter:   2602/  8460 | loss: 0.3019 | ds_loss: 0.0000 | lr: 3.9212e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2603/  8460 | global iter:   2603/  8460 | loss: 0.2513 | ds_loss: 0.0000 | lr: 3.9204e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2604/  8460 | global iter:   2604/  8460 | loss: 0.3457 | ds_loss: 0.0000 | lr: 3.9197e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2604/  8460 | global iter:   2604/  8460 | loss: 0.3876 | ds_loss: 0.0000 | lr: 3.9197e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2605/  8460 | global iter:   2605/  8460 | loss: 0.4803 | ds_loss: 0.0000 | lr: 3.9189e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2606/  8460 | global iter:   2606/  8460 | loss: 0.5569 | ds_loss: 0.0000 | lr: 3.9181e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2607/  8460 | global iter:   2607/  8460 | loss: 0.6483 | ds_loss: 0.0000 | lr: 3.9174e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2608/  8460 | global iter:   2608/  8460 | loss: 1.1033 | ds_loss: 0.0000 | lr: 3.9166e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2608/  8460 | global iter:   2608/  8460 | loss: 0.6972 | ds_loss: 0.0000 | lr: 3.9166e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2609/  8460 | global iter:   2609/  8460 | loss: 0.2507 | ds_loss: 0.0000 | lr: 3.9158e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2610/  8460 | global iter:   2610/  8460 | loss: 0.3319 | ds_loss: 0.0000 | lr: 3.9151e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2611/  8460 | global iter:   2611/  8460 | loss: 0.2730 | ds_loss: 0.0000 | lr: 3.9143e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2612/  8460 | global iter:   2612/  8460 | loss: 0.6246 | ds_loss: 0.0000 | lr: 3.9136e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2612/  8460 | global iter:   2612/  8460 | loss: 0.3700 | ds_loss: 0.0000 | lr: 3.9136e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2613/  8460 | global iter:   2613/  8460 | loss: 0.2062 | ds_loss: 0.0000 | lr: 3.9128e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2614/  8460 | global iter:   2614/  8460 | loss: 0.7472 | ds_loss: 0.0000 | lr: 3.9120e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2615/  8460 | global iter:   2615/  8460 | loss: 0.5505 | ds_loss: 0.0000 | lr: 3.9113e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2616/  8460 | global iter:   2616/  8460 | loss: 0.3618 | ds_loss: 0.0000 | lr: 3.9105e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2616/  8460 | global iter:   2616/  8460 | loss: 0.4664 | ds_loss: 0.0000 | lr: 3.9105e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2617/  8460 | global iter:   2617/  8460 | loss: 0.7101 | ds_loss: 0.0000 | lr: 3.9097e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2618/  8460 | global iter:   2618/  8460 | loss: 0.5355 | ds_loss: 0.0000 | lr: 3.9090e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2619/  8460 | global iter:   2619/  8460 | loss: 0.2390 | ds_loss: 0.0000 | lr: 3.9082e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2620/  8460 | global iter:   2620/  8460 | loss: 0.1892 | ds_loss: 0.0000 | lr: 3.9074e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2620/  8460 | global iter:   2620/  8460 | loss: 0.4184 | ds_loss: 0.0000 | lr: 3.9074e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2621/  8460 | global iter:   2621/  8460 | loss: 0.5866 | ds_loss: 0.0000 | lr: 3.9067e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2622/  8460 | global iter:   2622/  8460 | loss: 0.5525 | ds_loss: 0.0000 | lr: 3.9059e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2623/  8460 | global iter:   2623/  8460 | loss: 0.5202 | ds_loss: 0.0000 | lr: 3.9051e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2624/  8460 | global iter:   2624/  8460 | loss: 0.1302 | ds_loss: 0.0000 | lr: 3.9044e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2624/  8460 | global iter:   2624/  8460 | loss: 0.4474 | ds_loss: 0.0000 | lr: 3.9044e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2625/  8460 | global iter:   2625/  8460 | loss: 0.1783 | ds_loss: 0.0000 | lr: 3.9036e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2626/  8460 | global iter:   2626/  8460 | loss: 0.1692 | ds_loss: 0.0000 | lr: 3.9028e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2627/  8460 | global iter:   2627/  8460 | loss: 0.3920 | ds_loss: 0.0000 | lr: 3.9020e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2628/  8460 | global iter:   2628/  8460 | loss: 0.6723 | ds_loss: 0.0000 | lr: 3.9013e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2628/  8460 | global iter:   2628/  8460 | loss: 0.3529 | ds_loss: 0.0000 | lr: 3.9013e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2629/  8460 | global iter:   2629/  8460 | loss: 0.2371 | ds_loss: 0.0000 | lr: 3.9005e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2630/  8460 | global iter:   2630/  8460 | loss: 0.5621 | ds_loss: 0.0000 | lr: 3.8997e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2631/  8460 | global iter:   2631/  8460 | loss: 0.7174 | ds_loss: 0.0000 | lr: 3.8990e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2632/  8460 | global iter:   2632/  8460 | loss: 0.7151 | ds_loss: 0.0000 | lr: 3.8982e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2632/  8460 | global iter:   2632/  8460 | loss: 0.5579 | ds_loss: 0.0000 | lr: 3.8982e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2633/  8460 | global iter:   2633/  8460 | loss: 0.3810 | ds_loss: 0.0000 | lr: 3.8974e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2634/  8460 | global iter:   2634/  8460 | loss: 0.4243 | ds_loss: 0.0000 | lr: 3.8967e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2635/  8460 | global iter:   2635/  8460 | loss: 0.3242 | ds_loss: 0.0000 | lr: 3.8959e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2636/  8460 | global iter:   2636/  8460 | loss: 0.1180 | ds_loss: 0.0000 | lr: 3.8951e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2636/  8460 | global iter:   2636/  8460 | loss: 0.3119 | ds_loss: 0.0000 | lr: 3.8951e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2637/  8460 | global iter:   2637/  8460 | loss: 0.5420 | ds_loss: 0.0000 | lr: 3.8944e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2638/  8460 | global iter:   2638/  8460 | loss: 0.3218 | ds_loss: 0.0000 | lr: 3.8936e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2639/  8460 | global iter:   2639/  8460 | loss: 0.5986 | ds_loss: 0.0000 | lr: 3.8928e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2640/  8460 | global iter:   2640/  8460 | loss: 0.2009 | ds_loss: 0.0000 | lr: 3.8920e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2640/  8460 | global iter:   2640/  8460 | loss: 0.4158 | ds_loss: 0.0000 | lr: 3.8920e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2641/  8460 | global iter:   2641/  8460 | loss: 0.2116 | ds_loss: 0.0000 | lr: 3.8913e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2642/  8460 | global iter:   2642/  8460 | loss: 0.3947 | ds_loss: 0.0000 | lr: 3.8905e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2643/  8460 | global iter:   2643/  8460 | loss: 0.9576 | ds_loss: 0.0000 | lr: 3.8897e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2644/  8460 | global iter:   2644/  8460 | loss: 0.5100 | ds_loss: 0.0000 | lr: 3.8890e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2644/  8460 | global iter:   2644/  8460 | loss: 0.5185 | ds_loss: 0.0000 | lr: 3.8890e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2645/  8460 | global iter:   2645/  8460 | loss: 0.4147 | ds_loss: 0.0000 | lr: 3.8882e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   2646/  8460 | global iter:   2646/  8460 | loss: 0.9298 | ds_loss: 0.0000 | lr: 3.8874e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   2647/  8460 | global iter:   2647/  8460 | loss: 0.1170 | ds_loss: 0.0000 | lr: 3.8866e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2648/  8460 | global iter:   2648/  8460 | loss: 0.7404 | ds_loss: 0.0000 | lr: 3.8859e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2648/  8460 | global iter:   2648/  8460 | loss: 0.5505 | ds_loss: 0.0000 | lr: 3.8859e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2649/  8460 | global iter:   2649/  8460 | loss: 0.8940 | ds_loss: 0.0000 | lr: 3.8851e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2650/  8460 | global iter:   2650/  8460 | loss: 0.6877 | ds_loss: 0.0000 | lr: 3.8843e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2651/  8460 | global iter:   2651/  8460 | loss: 0.8206 | ds_loss: 0.0000 | lr: 3.8835e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2652/  8460 | global iter:   2652/  8460 | loss: 0.0887 | ds_loss: 0.0000 | lr: 3.8828e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2652/  8460 | global iter:   2652/  8460 | loss: 0.6227 | ds_loss: 0.0000 | lr: 3.8828e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2653/  8460 | global iter:   2653/  8460 | loss: 0.4430 | ds_loss: 0.0000 | lr: 3.8820e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2654/  8460 | global iter:   2654/  8460 | loss: 0.1421 | ds_loss: 0.0000 | lr: 3.8812e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2655/  8460 | global iter:   2655/  8460 | loss: 0.1541 | ds_loss: 0.0000 | lr: 3.8805e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2656/  8460 | global iter:   2656/  8460 | loss: 0.6190 | ds_loss: 0.0000 | lr: 3.8797e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2656/  8460 | global iter:   2656/  8460 | loss: 0.3395 | ds_loss: 0.0000 | lr: 3.8797e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2657/  8460 | global iter:   2657/  8460 | loss: 0.3027 | ds_loss: 0.0000 | lr: 3.8789e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2658/  8460 | global iter:   2658/  8460 | loss: 0.3476 | ds_loss: 0.0000 | lr: 3.8781e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2659/  8460 | global iter:   2659/  8460 | loss: 0.6439 | ds_loss: 0.0000 | lr: 3.8774e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2660/  8460 | global iter:   2660/  8460 | loss: 0.3077 | ds_loss: 0.0000 | lr: 3.8766e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2660/  8460 | global iter:   2660/  8460 | loss: 0.4005 | ds_loss: 0.0000 | lr: 3.8766e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2661/  8460 | global iter:   2661/  8460 | loss: 0.2570 | ds_loss: 0.0000 | lr: 3.8758e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2662/  8460 | global iter:   2662/  8460 | loss: 0.1684 | ds_loss: 0.0000 | lr: 3.8750e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2663/  8460 | global iter:   2663/  8460 | loss: 0.7214 | ds_loss: 0.0000 | lr: 3.8743e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2664/  8460 | global iter:   2664/  8460 | loss: 0.1199 | ds_loss: 0.0000 | lr: 3.8735e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2664/  8460 | global iter:   2664/  8460 | loss: 0.3167 | ds_loss: 0.0000 | lr: 3.8735e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2665/  8460 | global iter:   2665/  8460 | loss: 0.4097 | ds_loss: 0.0000 | lr: 3.8727e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2666/  8460 | global iter:   2666/  8460 | loss: 0.1960 | ds_loss: 0.0000 | lr: 3.8719e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2667/  8460 | global iter:   2667/  8460 | loss: 0.2194 | ds_loss: 0.0000 | lr: 3.8712e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2668/  8460 | global iter:   2668/  8460 | loss: 0.4016 | ds_loss: 0.0000 | lr: 3.8704e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2668/  8460 | global iter:   2668/  8460 | loss: 0.3067 | ds_loss: 0.0000 | lr: 3.8704e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2669/  8460 | global iter:   2669/  8460 | loss: 0.2055 | ds_loss: 0.0000 | lr: 3.8696e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2670/  8460 | global iter:   2670/  8460 | loss: 0.3756 | ds_loss: 0.0000 | lr: 3.8688e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2671/  8460 | global iter:   2671/  8460 | loss: 0.2359 | ds_loss: 0.0000 | lr: 3.8680e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2672/  8460 | global iter:   2672/  8460 | loss: 0.4881 | ds_loss: 0.0000 | lr: 3.8673e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2672/  8460 | global iter:   2672/  8460 | loss: 0.3263 | ds_loss: 0.0000 | lr: 3.8673e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2673/  8460 | global iter:   2673/  8460 | loss: 0.0737 | ds_loss: 0.0000 | lr: 3.8665e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2674/  8460 | global iter:   2674/  8460 | loss: 0.8630 | ds_loss: 0.0000 | lr: 3.8657e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2675/  8460 | global iter:   2675/  8460 | loss: 0.3803 | ds_loss: 0.0000 | lr: 3.8649e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2676/  8460 | global iter:   2676/  8460 | loss: 0.2492 | ds_loss: 0.0000 | lr: 3.8642e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2676/  8460 | global iter:   2676/  8460 | loss: 0.3915 | ds_loss: 0.0000 | lr: 3.8642e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2677/  8460 | global iter:   2677/  8460 | loss: 0.4486 | ds_loss: 0.0000 | lr: 3.8634e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2678/  8460 | global iter:   2678/  8460 | loss: 0.1415 | ds_loss: 0.0000 | lr: 3.8626e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2679/  8460 | global iter:   2679/  8460 | loss: 0.7467 | ds_loss: 0.0000 | lr: 3.8618e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2680/  8460 | global iter:   2680/  8460 | loss: 0.1478 | ds_loss: 0.0000 | lr: 3.8610e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2680/  8460 | global iter:   2680/  8460 | loss: 0.3712 | ds_loss: 0.0000 | lr: 3.8610e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2681/  8460 | global iter:   2681/  8460 | loss: 0.2215 | ds_loss: 0.0000 | lr: 3.8603e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2682/  8460 | global iter:   2682/  8460 | loss: 0.2704 | ds_loss: 0.0000 | lr: 3.8595e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2683/  8460 | global iter:   2683/  8460 | loss: 0.1718 | ds_loss: 0.0000 | lr: 3.8587e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2684/  8460 | global iter:   2684/  8460 | loss: 0.8254 | ds_loss: 0.0000 | lr: 3.8579e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2684/  8460 | global iter:   2684/  8460 | loss: 0.3723 | ds_loss: 0.0000 | lr: 3.8579e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2685/  8460 | global iter:   2685/  8460 | loss: 0.3996 | ds_loss: 0.0000 | lr: 3.8572e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2686/  8460 | global iter:   2686/  8460 | loss: 0.1829 | ds_loss: 0.0000 | lr: 3.8564e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2687/  8460 | global iter:   2687/  8460 | loss: 0.4463 | ds_loss: 0.0000 | lr: 3.8556e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2688/  8460 | global iter:   2688/  8460 | loss: 0.3640 | ds_loss: 0.0000 | lr: 3.8548e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2688/  8460 | global iter:   2688/  8460 | loss: 0.3482 | ds_loss: 0.0000 | lr: 3.8548e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2689/  8460 | global iter:   2689/  8460 | loss: 0.3031 | ds_loss: 0.0000 | lr: 3.8540e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2690/  8460 | global iter:   2690/  8460 | loss: 0.4569 | ds_loss: 0.0000 | lr: 3.8533e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2691/  8460 | global iter:   2691/  8460 | loss: 0.4650 | ds_loss: 0.0000 | lr: 3.8525e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   2692/  8460 | global iter:   2692/  8460 | loss: 0.3499 | ds_loss: 0.0000 | lr: 3.8517e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2692/  8460 | global iter:   2692/  8460 | loss: 0.3937 | ds_loss: 0.0000 | lr: 3.8517e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2693/  8460 | global iter:   2693/  8460 | loss: 0.5892 | ds_loss: 0.0000 | lr: 3.8509e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2694/  8460 | global iter:   2694/  8460 | loss: 0.2442 | ds_loss: 0.0000 | lr: 3.8501e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2695/  8460 | global iter:   2695/  8460 | loss: 0.3491 | ds_loss: 0.0000 | lr: 3.8493e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2696/  8460 | global iter:   2696/  8460 | loss: 0.7408 | ds_loss: 0.0000 | lr: 3.8486e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2696/  8460 | global iter:   2696/  8460 | loss: 0.4808 | ds_loss: 0.0000 | lr: 3.8486e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2697/  8460 | global iter:   2697/  8460 | loss: 0.3960 | ds_loss: 0.0000 | lr: 3.8478e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2698/  8460 | global iter:   2698/  8460 | loss: 0.4761 | ds_loss: 0.0000 | lr: 3.8470e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2699/  8460 | global iter:   2699/  8460 | loss: 0.3726 | ds_loss: 0.0000 | lr: 3.8462e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2700/  8460 | global iter:   2700/  8460 | loss: 0.0735 | ds_loss: 0.0000 | lr: 3.8454e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2700/  8460 | global iter:   2700/  8460 | loss: 0.3295 | ds_loss: 0.0000 | lr: 3.8454e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2701/  8460 | global iter:   2701/  8460 | loss: 0.4130 | ds_loss: 0.0000 | lr: 3.8447e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2702/  8460 | global iter:   2702/  8460 | loss: 0.2786 | ds_loss: 0.0000 | lr: 3.8439e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2703/  8460 | global iter:   2703/  8460 | loss: 0.1031 | ds_loss: 0.0000 | lr: 3.8431e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2704/  8460 | global iter:   2704/  8460 | loss: 0.4347 | ds_loss: 0.0000 | lr: 3.8423e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2704/  8460 | global iter:   2704/  8460 | loss: 0.3074 | ds_loss: 0.0000 | lr: 3.8423e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2705/  8460 | global iter:   2705/  8460 | loss: 0.4911 | ds_loss: 0.0000 | lr: 3.8415e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2706/  8460 | global iter:   2706/  8460 | loss: 0.4194 | ds_loss: 0.0000 | lr: 3.8407e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2707/  8460 | global iter:   2707/  8460 | loss: 0.7797 | ds_loss: 0.0000 | lr: 3.8400e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2708/  8460 | global iter:   2708/  8460 | loss: 0.3786 | ds_loss: 0.0000 | lr: 3.8392e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2708/  8460 | global iter:   2708/  8460 | loss: 0.5172 | ds_loss: 0.0000 | lr: 3.8392e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2709/  8460 | global iter:   2709/  8460 | loss: 0.5292 | ds_loss: 0.0000 | lr: 3.8384e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2710/  8460 | global iter:   2710/  8460 | loss: 0.0948 | ds_loss: 0.0000 | lr: 3.8376e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2711/  8460 | global iter:   2711/  8460 | loss: 0.5703 | ds_loss: 0.0000 | lr: 3.8368e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2712/  8460 | global iter:   2712/  8460 | loss: 0.3175 | ds_loss: 0.0000 | lr: 3.8360e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2712/  8460 | global iter:   2712/  8460 | loss: 0.3779 | ds_loss: 0.0000 | lr: 3.8360e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2713/  8460 | global iter:   2713/  8460 | loss: 0.2913 | ds_loss: 0.0000 | lr: 3.8353e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2714/  8460 | global iter:   2714/  8460 | loss: 0.3705 | ds_loss: 0.0000 | lr: 3.8345e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2715/  8460 | global iter:   2715/  8460 | loss: 0.2136 | ds_loss: 0.0000 | lr: 3.8337e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   2716/  8460 | global iter:   2716/  8460 | loss: 0.1541 | ds_loss: 0.0000 | lr: 3.8329e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2716/  8460 | global iter:   2716/  8460 | loss: 0.2574 | ds_loss: 0.0000 | lr: 3.8329e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2717/  8460 | global iter:   2717/  8460 | loss: 0.2796 | ds_loss: 0.0000 | lr: 3.8321e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2718/  8460 | global iter:   2718/  8460 | loss: 0.2448 | ds_loss: 0.0000 | lr: 3.8313e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2719/  8460 | global iter:   2719/  8460 | loss: 0.2168 | ds_loss: 0.0000 | lr: 3.8305e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2720/  8460 | global iter:   2720/  8460 | loss: 0.4468 | ds_loss: 0.0000 | lr: 3.8298e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2720/  8460 | global iter:   2720/  8460 | loss: 0.2970 | ds_loss: 0.0000 | lr: 3.8298e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2721/  8460 | global iter:   2721/  8460 | loss: 0.3578 | ds_loss: 0.0000 | lr: 3.8290e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2722/  8460 | global iter:   2722/  8460 | loss: 0.4670 | ds_loss: 0.0000 | lr: 3.8282e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2723/  8460 | global iter:   2723/  8460 | loss: 0.2119 | ds_loss: 0.0000 | lr: 3.8274e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2724/  8460 | global iter:   2724/  8460 | loss: 0.6391 | ds_loss: 0.0000 | lr: 3.8266e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2724/  8460 | global iter:   2724/  8460 | loss: 0.4190 | ds_loss: 0.0000 | lr: 3.8266e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2725/  8460 | global iter:   2725/  8460 | loss: 0.3240 | ds_loss: 0.0000 | lr: 3.8258e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2726/  8460 | global iter:   2726/  8460 | loss: 0.1952 | ds_loss: 0.0000 | lr: 3.8250e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2727/  8460 | global iter:   2727/  8460 | loss: 0.3818 | ds_loss: 0.0000 | lr: 3.8242e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2728/  8460 | global iter:   2728/  8460 | loss: 0.9985 | ds_loss: 0.0000 | lr: 3.8235e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2728/  8460 | global iter:   2728/  8460 | loss: 0.4749 | ds_loss: 0.0000 | lr: 3.8235e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2729/  8460 | global iter:   2729/  8460 | loss: 0.3202 | ds_loss: 0.0000 | lr: 3.8227e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2730/  8460 | global iter:   2730/  8460 | loss: 0.2932 | ds_loss: 0.0000 | lr: 3.8219e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2731/  8460 | global iter:   2731/  8460 | loss: 0.1875 | ds_loss: 0.0000 | lr: 3.8211e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2732/  8460 | global iter:   2732/  8460 | loss: 0.1966 | ds_loss: 0.0000 | lr: 3.8203e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2732/  8460 | global iter:   2732/  8460 | loss: 0.2494 | ds_loss: 0.0000 | lr: 3.8203e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2733/  8460 | global iter:   2733/  8460 | loss: 0.2556 | ds_loss: 0.0000 | lr: 3.8195e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2734/  8460 | global iter:   2734/  8460 | loss: 0.4298 | ds_loss: 0.0000 | lr: 3.8187e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2735/  8460 | global iter:   2735/  8460 | loss: 0.4026 | ds_loss: 0.0000 | lr: 3.8179e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2736/  8460 | global iter:   2736/  8460 | loss: 0.2518 | ds_loss: 0.0000 | lr: 3.8172e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2736/  8460 | global iter:   2736/  8460 | loss: 0.3349 | ds_loss: 0.0000 | lr: 3.8172e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2737/  8460 | global iter:   2737/  8460 | loss: 0.6587 | ds_loss: 0.0000 | lr: 3.8164e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2738/  8460 | global iter:   2738/  8460 | loss: 0.2445 | ds_loss: 0.0000 | lr: 3.8156e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   2739/  8460 | global iter:   2739/  8460 | loss: 0.3046 | ds_loss: 0.0000 | lr: 3.8148e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2740/  8460 | global iter:   2740/  8460 | loss: 0.2965 | ds_loss: 0.0000 | lr: 3.8140e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2740/  8460 | global iter:   2740/  8460 | loss: 0.3761 | ds_loss: 0.0000 | lr: 3.8140e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2741/  8460 | global iter:   2741/  8460 | loss: 0.5558 | ds_loss: 0.0000 | lr: 3.8132e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   2742/  8460 | global iter:   2742/  8460 | loss: 0.5166 | ds_loss: 0.0000 | lr: 3.8124e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   2743/  8460 | global iter:   2743/  8460 | loss: 0.3391 | ds_loss: 0.0000 | lr: 3.8116e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2744/  8460 | global iter:   2744/  8460 | loss: 1.0258 | ds_loss: 0.0000 | lr: 3.8108e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2744/  8460 | global iter:   2744/  8460 | loss: 0.6093 | ds_loss: 0.0000 | lr: 3.8108e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2745/  8460 | global iter:   2745/  8460 | loss: 0.2044 | ds_loss: 0.0000 | lr: 3.8100e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2746/  8460 | global iter:   2746/  8460 | loss: 0.8965 | ds_loss: 0.0000 | lr: 3.8093e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2747/  8460 | global iter:   2747/  8460 | loss: 0.5540 | ds_loss: 0.0000 | lr: 3.8085e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2748/  8460 | global iter:   2748/  8460 | loss: 0.3753 | ds_loss: 0.0000 | lr: 3.8077e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2748/  8460 | global iter:   2748/  8460 | loss: 0.5076 | ds_loss: 0.0000 | lr: 3.8077e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2749/  8460 | global iter:   2749/  8460 | loss: 0.3390 | ds_loss: 0.0000 | lr: 3.8069e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   2750/  8460 | global iter:   2750/  8460 | loss: 0.3026 | ds_loss: 0.0000 | lr: 3.8061e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2751/  8460 | global iter:   2751/  8460 | loss: 0.1734 | ds_loss: 0.0000 | lr: 3.8053e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2752/  8460 | global iter:   2752/  8460 | loss: 0.2694 | ds_loss: 0.0000 | lr: 3.8045e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2752/  8460 | global iter:   2752/  8460 | loss: 0.2711 | ds_loss: 0.0000 | lr: 3.8045e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2753/  8460 | global iter:   2753/  8460 | loss: 0.0517 | ds_loss: 0.0000 | lr: 3.8037e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2754/  8460 | global iter:   2754/  8460 | loss: 0.2076 | ds_loss: 0.0000 | lr: 3.8029e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2755/  8460 | global iter:   2755/  8460 | loss: 0.4786 | ds_loss: 0.0000 | lr: 3.8021e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2756/  8460 | global iter:   2756/  8460 | loss: 0.2493 | ds_loss: 0.0000 | lr: 3.8013e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2756/  8460 | global iter:   2756/  8460 | loss: 0.2468 | ds_loss: 0.0000 | lr: 3.8013e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2757/  8460 | global iter:   2757/  8460 | loss: 0.1402 | ds_loss: 0.0000 | lr: 3.8005e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2758/  8460 | global iter:   2758/  8460 | loss: 0.5964 | ds_loss: 0.0000 | lr: 3.7998e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2759/  8460 | global iter:   2759/  8460 | loss: 0.5195 | ds_loss: 0.0000 | lr: 3.7990e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2760/  8460 | global iter:   2760/  8460 | loss: 0.2980 | ds_loss: 0.0000 | lr: 3.7982e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2760/  8460 | global iter:   2760/  8460 | loss: 0.3885 | ds_loss: 0.0000 | lr: 3.7982e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2761/  8460 | global iter:   2761/  8460 | loss: 0.2989 | ds_loss: 0.0000 | lr: 3.7974e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2762/  8460 | global iter:   2762/  8460 | loss: 0.4929 | ds_loss: 0.0000 | lr: 3.7966e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   2763/  8460 | global iter:   2763/  8460 | loss: 0.3826 | ds_loss: 0.0000 | lr: 3.7958e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2764/  8460 | global iter:   2764/  8460 | loss: 0.3777 | ds_loss: 0.0000 | lr: 3.7950e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2764/  8460 | global iter:   2764/  8460 | loss: 0.3880 | ds_loss: 0.0000 | lr: 3.7950e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2765/  8460 | global iter:   2765/  8460 | loss: 0.1276 | ds_loss: 0.0000 | lr: 3.7942e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2766/  8460 | global iter:   2766/  8460 | loss: 0.3232 | ds_loss: 0.0000 | lr: 3.7934e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2767/  8460 | global iter:   2767/  8460 | loss: 0.5425 | ds_loss: 0.0000 | lr: 3.7926e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2768/  8460 | global iter:   2768/  8460 | loss: 0.9475 | ds_loss: 0.0000 | lr: 3.7918e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2768/  8460 | global iter:   2768/  8460 | loss: 0.4852 | ds_loss: 0.0000 | lr: 3.7918e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2769/  8460 | global iter:   2769/  8460 | loss: 0.7144 | ds_loss: 0.0000 | lr: 3.7910e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2770/  8460 | global iter:   2770/  8460 | loss: 0.2822 | ds_loss: 0.0000 | lr: 3.7902e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2771/  8460 | global iter:   2771/  8460 | loss: 0.5350 | ds_loss: 0.0000 | lr: 3.7894e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2772/  8460 | global iter:   2772/  8460 | loss: 0.3986 | ds_loss: 0.0000 | lr: 3.7886e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2772/  8460 | global iter:   2772/  8460 | loss: 0.4826 | ds_loss: 0.0000 | lr: 3.7886e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2773/  8460 | global iter:   2773/  8460 | loss: 0.5268 | ds_loss: 0.0000 | lr: 3.7878e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2774/  8460 | global iter:   2774/  8460 | loss: 0.4064 | ds_loss: 0.0000 | lr: 3.7870e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2775/  8460 | global iter:   2775/  8460 | loss: 0.1035 | ds_loss: 0.0000 | lr: 3.7862e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2776/  8460 | global iter:   2776/  8460 | loss: 0.9059 | ds_loss: 0.0000 | lr: 3.7855e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2776/  8460 | global iter:   2776/  8460 | loss: 0.4856 | ds_loss: 0.0000 | lr: 3.7855e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2777/  8460 | global iter:   2777/  8460 | loss: 0.3116 | ds_loss: 0.0000 | lr: 3.7847e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2778/  8460 | global iter:   2778/  8460 | loss: 0.7072 | ds_loss: 0.0000 | lr: 3.7839e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2779/  8460 | global iter:   2779/  8460 | loss: 0.4598 | ds_loss: 0.0000 | lr: 3.7831e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2780/  8460 | global iter:   2780/  8460 | loss: 0.5241 | ds_loss: 0.0000 | lr: 3.7823e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2780/  8460 | global iter:   2780/  8460 | loss: 0.5007 | ds_loss: 0.0000 | lr: 3.7823e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2781/  8460 | global iter:   2781/  8460 | loss: 0.3269 | ds_loss: 0.0000 | lr: 3.7815e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2782/  8460 | global iter:   2782/  8460 | loss: 0.1630 | ds_loss: 0.0000 | lr: 3.7807e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2783/  8460 | global iter:   2783/  8460 | loss: 0.5078 | ds_loss: 0.0000 | lr: 3.7799e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2784/  8460 | global iter:   2784/  8460 | loss: 0.4520 | ds_loss: 0.0000 | lr: 3.7791e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2784/  8460 | global iter:   2784/  8460 | loss: 0.3624 | ds_loss: 0.0000 | lr: 3.7791e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2785/  8460 | global iter:   2785/  8460 | loss: 0.4069 | ds_loss: 0.0000 | lr: 3.7783e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2786/  8460 | global iter:   2786/  8460 | loss: 0.4988 | ds_loss: 0.0000 | lr: 3.7775e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2787/  8460 | global iter:   2787/  8460 | loss: 0.6508 | ds_loss: 0.0000 | lr: 3.7767e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2788/  8460 | global iter:   2788/  8460 | loss: 0.5943 | ds_loss: 0.0000 | lr: 3.7759e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2788/  8460 | global iter:   2788/  8460 | loss: 0.5377 | ds_loss: 0.0000 | lr: 3.7759e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2789/  8460 | global iter:   2789/  8460 | loss: 0.3529 | ds_loss: 0.0000 | lr: 3.7751e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2790/  8460 | global iter:   2790/  8460 | loss: 0.5511 | ds_loss: 0.0000 | lr: 3.7743e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2791/  8460 | global iter:   2791/  8460 | loss: 0.2905 | ds_loss: 0.0000 | lr: 3.7735e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2792/  8460 | global iter:   2792/  8460 | loss: 0.7286 | ds_loss: 0.0000 | lr: 3.7727e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2792/  8460 | global iter:   2792/  8460 | loss: 0.4808 | ds_loss: 0.0000 | lr: 3.7727e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2793/  8460 | global iter:   2793/  8460 | loss: 0.3019 | ds_loss: 0.0000 | lr: 3.7719e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2794/  8460 | global iter:   2794/  8460 | loss: 0.5030 | ds_loss: 0.0000 | lr: 3.7711e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2795/  8460 | global iter:   2795/  8460 | loss: 0.4090 | ds_loss: 0.0000 | lr: 3.7703e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2796/  8460 | global iter:   2796/  8460 | loss: 0.2898 | ds_loss: 0.0000 | lr: 3.7695e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2796/  8460 | global iter:   2796/  8460 | loss: 0.3759 | ds_loss: 0.0000 | lr: 3.7695e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2797/  8460 | global iter:   2797/  8460 | loss: 1.0793 | ds_loss: 0.0000 | lr: 3.7687e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2798/  8460 | global iter:   2798/  8460 | loss: 0.3847 | ds_loss: 0.0000 | lr: 3.7679e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2799/  8460 | global iter:   2799/  8460 | loss: 0.7192 | ds_loss: 0.0000 | lr: 3.7671e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2800/  8460 | global iter:   2800/  8460 | loss: 0.6522 | ds_loss: 0.0000 | lr: 3.7663e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2800/  8460 | global iter:   2800/  8460 | loss: 0.7088 | ds_loss: 0.0000 | lr: 3.7663e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2801/  8460 | global iter:   2801/  8460 | loss: 0.4056 | ds_loss: 0.0000 | lr: 3.7655e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2802/  8460 | global iter:   2802/  8460 | loss: 0.4591 | ds_loss: 0.0000 | lr: 3.7647e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2803/  8460 | global iter:   2803/  8460 | loss: 0.2784 | ds_loss: 0.0000 | lr: 3.7639e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2804/  8460 | global iter:   2804/  8460 | loss: 0.7684 | ds_loss: 0.0000 | lr: 3.7631e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2804/  8460 | global iter:   2804/  8460 | loss: 0.4779 | ds_loss: 0.0000 | lr: 3.7631e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2805/  8460 | global iter:   2805/  8460 | loss: 0.1972 | ds_loss: 0.0000 | lr: 3.7623e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2806/  8460 | global iter:   2806/  8460 | loss: 0.7609 | ds_loss: 0.0000 | lr: 3.7615e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2807/  8460 | global iter:   2807/  8460 | loss: 0.7027 | ds_loss: 0.0000 | lr: 3.7607e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2808/  8460 | global iter:   2808/  8460 | loss: 0.1793 | ds_loss: 0.0000 | lr: 3.7599e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2808/  8460 | global iter:   2808/  8460 | loss: 0.4600 | ds_loss: 0.0000 | lr: 3.7599e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2809/  8460 | global iter:   2809/  8460 | loss: 0.3415 | ds_loss: 0.0000 | lr: 3.7591e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2810/  8460 | global iter:   2810/  8460 | loss: 0.1677 | ds_loss: 0.0000 | lr: 3.7583e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2811/  8460 | global iter:   2811/  8460 | loss: 0.2504 | ds_loss: 0.0000 | lr: 3.7575e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2812/  8460 | global iter:   2812/  8460 | loss: 0.1584 | ds_loss: 0.0000 | lr: 3.7567e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2812/  8460 | global iter:   2812/  8460 | loss: 0.2295 | ds_loss: 0.0000 | lr: 3.7567e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2813/  8460 | global iter:   2813/  8460 | loss: 0.4074 | ds_loss: 0.0000 | lr: 3.7559e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2814/  8460 | global iter:   2814/  8460 | loss: 0.3268 | ds_loss: 0.0000 | lr: 3.7551e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2815/  8460 | global iter:   2815/  8460 | loss: 0.3456 | ds_loss: 0.0000 | lr: 3.7543e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2816/  8460 | global iter:   2816/  8460 | loss: 0.2695 | ds_loss: 0.0000 | lr: 3.7535e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2816/  8460 | global iter:   2816/  8460 | loss: 0.3373 | ds_loss: 0.0000 | lr: 3.7535e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2817/  8460 | global iter:   2817/  8460 | loss: 0.2383 | ds_loss: 0.0000 | lr: 3.7527e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2818/  8460 | global iter:   2818/  8460 | loss: 0.4257 | ds_loss: 0.0000 | lr: 3.7519e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2819/  8460 | global iter:   2819/  8460 | loss: 0.1028 | ds_loss: 0.0000 | lr: 3.7511e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2820/  8460 | global iter:   2820/  8460 | loss: 0.6698 | ds_loss: 0.0000 | lr: 3.7502e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2820/  8460 | global iter:   2820/  8460 | loss: 0.3591 | ds_loss: 0.0000 | lr: 3.7502e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2821/  8460 | global iter:   2821/  8460 | loss: 0.4558 | ds_loss: 0.0000 | lr: 3.7494e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2822/  8460 | global iter:   2822/  8460 | loss: 0.2587 | ds_loss: 0.0000 | lr: 3.7486e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2823/  8460 | global iter:   2823/  8460 | loss: 0.3772 | ds_loss: 0.0000 | lr: 3.7478e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2824/  8460 | global iter:   2824/  8460 | loss: 0.2566 | ds_loss: 0.0000 | lr: 3.7470e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2824/  8460 | global iter:   2824/  8460 | loss: 0.3371 | ds_loss: 0.0000 | lr: 3.7470e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2825/  8460 | global iter:   2825/  8460 | loss: 0.9783 | ds_loss: 0.0000 | lr: 3.7462e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2826/  8460 | global iter:   2826/  8460 | loss: 0.3177 | ds_loss: 0.0000 | lr: 3.7454e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2827/  8460 | global iter:   2827/  8460 | loss: 0.4126 | ds_loss: 0.0000 | lr: 3.7446e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2828/  8460 | global iter:   2828/  8460 | loss: 0.2036 | ds_loss: 0.0000 | lr: 3.7438e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2828/  8460 | global iter:   2828/  8460 | loss: 0.4781 | ds_loss: 0.0000 | lr: 3.7438e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2829/  8460 | global iter:   2829/  8460 | loss: 0.4160 | ds_loss: 0.0000 | lr: 3.7430e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2830/  8460 | global iter:   2830/  8460 | loss: 0.2322 | ds_loss: 0.0000 | lr: 3.7422e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2831/  8460 | global iter:   2831/  8460 | loss: 0.7489 | ds_loss: 0.0000 | lr: 3.7414e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2832/  8460 | global iter:   2832/  8460 | loss: 0.1068 | ds_loss: 0.0000 | lr: 3.7406e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2832/  8460 | global iter:   2832/  8460 | loss: 0.3760 | ds_loss: 0.0000 | lr: 3.7406e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2833/  8460 | global iter:   2833/  8460 | loss: 0.7319 | ds_loss: 0.0000 | lr: 3.7398e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2834/  8460 | global iter:   2834/  8460 | loss: 0.5884 | ds_loss: 0.0000 | lr: 3.7390e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2835/  8460 | global iter:   2835/  8460 | loss: 0.1864 | ds_loss: 0.0000 | lr: 3.7382e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   2836/  8460 | global iter:   2836/  8460 | loss: 0.3394 | ds_loss: 0.0000 | lr: 3.7374e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2836/  8460 | global iter:   2836/  8460 | loss: 0.4615 | ds_loss: 0.0000 | lr: 3.7374e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2837/  8460 | global iter:   2837/  8460 | loss: 0.3394 | ds_loss: 0.0000 | lr: 3.7366e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2838/  8460 | global iter:   2838/  8460 | loss: 0.9387 | ds_loss: 0.0000 | lr: 3.7358e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2839/  8460 | global iter:   2839/  8460 | loss: 0.9157 | ds_loss: 0.0000 | lr: 3.7349e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2840/  8460 | global iter:   2840/  8460 | loss: 0.1504 | ds_loss: 0.0000 | lr: 3.7341e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2840/  8460 | global iter:   2840/  8460 | loss: 0.5861 | ds_loss: 0.0000 | lr: 3.7341e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2841/  8460 | global iter:   2841/  8460 | loss: 0.6151 | ds_loss: 0.0000 | lr: 3.7333e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2842/  8460 | global iter:   2842/  8460 | loss: 0.6437 | ds_loss: 0.0000 | lr: 3.7325e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2843/  8460 | global iter:   2843/  8460 | loss: 0.4683 | ds_loss: 0.0000 | lr: 3.7317e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2844/  8460 | global iter:   2844/  8460 | loss: 0.7596 | ds_loss: 0.0000 | lr: 3.7309e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2844/  8460 | global iter:   2844/  8460 | loss: 0.6217 | ds_loss: 0.0000 | lr: 3.7309e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2845/  8460 | global iter:   2845/  8460 | loss: 0.4095 | ds_loss: 0.0000 | lr: 3.7301e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2846/  8460 | global iter:   2846/  8460 | loss: 0.4766 | ds_loss: 0.0000 | lr: 3.7293e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2847/  8460 | global iter:   2847/  8460 | loss: 0.2727 | ds_loss: 0.0000 | lr: 3.7285e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2848/  8460 | global iter:   2848/  8460 | loss: 0.2368 | ds_loss: 0.0000 | lr: 3.7277e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2848/  8460 | global iter:   2848/  8460 | loss: 0.3489 | ds_loss: 0.0000 | lr: 3.7277e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2849/  8460 | global iter:   2849/  8460 | loss: 0.3327 | ds_loss: 0.0000 | lr: 3.7269e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2850/  8460 | global iter:   2850/  8460 | loss: 0.4618 | ds_loss: 0.0000 | lr: 3.7261e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2851/  8460 | global iter:   2851/  8460 | loss: 0.7664 | ds_loss: 0.0000 | lr: 3.7252e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2852/  8460 | global iter:   2852/  8460 | loss: 0.2780 | ds_loss: 0.0000 | lr: 3.7244e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2852/  8460 | global iter:   2852/  8460 | loss: 0.4597 | ds_loss: 0.0000 | lr: 3.7244e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2853/  8460 | global iter:   2853/  8460 | loss: 0.3845 | ds_loss: 0.0000 | lr: 3.7236e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2854/  8460 | global iter:   2854/  8460 | loss: 0.2638 | ds_loss: 0.0000 | lr: 3.7228e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2855/  8460 | global iter:   2855/  8460 | loss: 0.0961 | ds_loss: 0.0000 | lr: 3.7220e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2856/  8460 | global iter:   2856/  8460 | loss: 0.8486 | ds_loss: 0.0000 | lr: 3.7212e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2856/  8460 | global iter:   2856/  8460 | loss: 0.3982 | ds_loss: 0.0000 | lr: 3.7212e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2857/  8460 | global iter:   2857/  8460 | loss: 0.1567 | ds_loss: 0.0000 | lr: 3.7204e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2858/  8460 | global iter:   2858/  8460 | loss: 0.3248 | ds_loss: 0.0000 | lr: 3.7196e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2859/  8460 | global iter:   2859/  8460 | loss: 0.4249 | ds_loss: 0.0000 | lr: 3.7188e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2860/  8460 | global iter:   2860/  8460 | loss: 0.3831 | ds_loss: 0.0000 | lr: 3.7180e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2860/  8460 | global iter:   2860/  8460 | loss: 0.3224 | ds_loss: 0.0000 | lr: 3.7180e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2861/  8460 | global iter:   2861/  8460 | loss: 0.6359 | ds_loss: 0.0000 | lr: 3.7171e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2862/  8460 | global iter:   2862/  8460 | loss: 0.3491 | ds_loss: 0.0000 | lr: 3.7163e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2863/  8460 | global iter:   2863/  8460 | loss: 0.3729 | ds_loss: 0.0000 | lr: 3.7155e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2864/  8460 | global iter:   2864/  8460 | loss: 0.4711 | ds_loss: 0.0000 | lr: 3.7147e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2864/  8460 | global iter:   2864/  8460 | loss: 0.4572 | ds_loss: 0.0000 | lr: 3.7147e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2865/  8460 | global iter:   2865/  8460 | loss: 0.1615 | ds_loss: 0.0000 | lr: 3.7139e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2866/  8460 | global iter:   2866/  8460 | loss: 0.1229 | ds_loss: 0.0000 | lr: 3.7131e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2867/  8460 | global iter:   2867/  8460 | loss: 0.5391 | ds_loss: 0.0000 | lr: 3.7123e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2868/  8460 | global iter:   2868/  8460 | loss: 0.1530 | ds_loss: 0.0000 | lr: 3.7115e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2868/  8460 | global iter:   2868/  8460 | loss: 0.2441 | ds_loss: 0.0000 | lr: 3.7115e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2869/  8460 | global iter:   2869/  8460 | loss: 0.1696 | ds_loss: 0.0000 | lr: 3.7107e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2870/  8460 | global iter:   2870/  8460 | loss: 0.1457 | ds_loss: 0.0000 | lr: 3.7098e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2871/  8460 | global iter:   2871/  8460 | loss: 0.5636 | ds_loss: 0.0000 | lr: 3.7090e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2872/  8460 | global iter:   2872/  8460 | loss: 0.5200 | ds_loss: 0.0000 | lr: 3.7082e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2872/  8460 | global iter:   2872/  8460 | loss: 0.3497 | ds_loss: 0.0000 | lr: 3.7082e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2873/  8460 | global iter:   2873/  8460 | loss: 0.2770 | ds_loss: 0.0000 | lr: 3.7074e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2874/  8460 | global iter:   2874/  8460 | loss: 0.8824 | ds_loss: 0.0000 | lr: 3.7066e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2875/  8460 | global iter:   2875/  8460 | loss: 0.4428 | ds_loss: 0.0000 | lr: 3.7058e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2876/  8460 | global iter:   2876/  8460 | loss: 0.2250 | ds_loss: 0.0000 | lr: 3.7050e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2876/  8460 | global iter:   2876/  8460 | loss: 0.4568 | ds_loss: 0.0000 | lr: 3.7050e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2877/  8460 | global iter:   2877/  8460 | loss: 0.2746 | ds_loss: 0.0000 | lr: 3.7042e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   2878/  8460 | global iter:   2878/  8460 | loss: 0.3107 | ds_loss: 0.0000 | lr: 3.7033e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2879/  8460 | global iter:   2879/  8460 | loss: 0.2327 | ds_loss: 0.0000 | lr: 3.7025e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2880/  8460 | global iter:   2880/  8460 | loss: 0.3824 | ds_loss: 0.0000 | lr: 3.7017e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2880/  8460 | global iter:   2880/  8460 | loss: 0.3001 | ds_loss: 0.0000 | lr: 3.7017e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2881/  8460 | global iter:   2881/  8460 | loss: 0.4797 | ds_loss: 0.0000 | lr: 3.7009e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2882/  8460 | global iter:   2882/  8460 | loss: 0.1117 | ds_loss: 0.0000 | lr: 3.7001e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2883/  8460 | global iter:   2883/  8460 | loss: 0.1798 | ds_loss: 0.0000 | lr: 3.6993e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2884/  8460 | global iter:   2884/  8460 | loss: 0.3592 | ds_loss: 0.0000 | lr: 3.6985e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2884/  8460 | global iter:   2884/  8460 | loss: 0.2826 | ds_loss: 0.0000 | lr: 3.6985e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2885/  8460 | global iter:   2885/  8460 | loss: 0.4573 | ds_loss: 0.0000 | lr: 3.6976e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2886/  8460 | global iter:   2886/  8460 | loss: 0.5115 | ds_loss: 0.0000 | lr: 3.6968e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   2887/  8460 | global iter:   2887/  8460 | loss: 0.3490 | ds_loss: 0.0000 | lr: 3.6960e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2888/  8460 | global iter:   2888/  8460 | loss: 0.4466 | ds_loss: 0.0000 | lr: 3.6952e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2888/  8460 | global iter:   2888/  8460 | loss: 0.4411 | ds_loss: 0.0000 | lr: 3.6952e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2889/  8460 | global iter:   2889/  8460 | loss: 0.2157 | ds_loss: 0.0000 | lr: 3.6944e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2890/  8460 | global iter:   2890/  8460 | loss: 0.2136 | ds_loss: 0.0000 | lr: 3.6936e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2891/  8460 | global iter:   2891/  8460 | loss: 0.2067 | ds_loss: 0.0000 | lr: 3.6928e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2892/  8460 | global iter:   2892/  8460 | loss: 0.3213 | ds_loss: 0.0000 | lr: 3.6919e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2892/  8460 | global iter:   2892/  8460 | loss: 0.2393 | ds_loss: 0.0000 | lr: 3.6919e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2893/  8460 | global iter:   2893/  8460 | loss: 0.3525 | ds_loss: 0.0000 | lr: 3.6911e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2894/  8460 | global iter:   2894/  8460 | loss: 0.6886 | ds_loss: 0.0000 | lr: 3.6903e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2895/  8460 | global iter:   2895/  8460 | loss: 0.5307 | ds_loss: 0.0000 | lr: 3.6895e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2896/  8460 | global iter:   2896/  8460 | loss: 0.3917 | ds_loss: 0.0000 | lr: 3.6887e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2896/  8460 | global iter:   2896/  8460 | loss: 0.4909 | ds_loss: 0.0000 | lr: 3.6887e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2897/  8460 | global iter:   2897/  8460 | loss: 0.3985 | ds_loss: 0.0000 | lr: 3.6879e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2898/  8460 | global iter:   2898/  8460 | loss: 0.3464 | ds_loss: 0.0000 | lr: 3.6870e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2899/  8460 | global iter:   2899/  8460 | loss: 0.1335 | ds_loss: 0.0000 | lr: 3.6862e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2900/  8460 | global iter:   2900/  8460 | loss: 0.4363 | ds_loss: 0.0000 | lr: 3.6854e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2900/  8460 | global iter:   2900/  8460 | loss: 0.3287 | ds_loss: 0.0000 | lr: 3.6854e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2901/  8460 | global iter:   2901/  8460 | loss: 0.3500 | ds_loss: 0.0000 | lr: 3.6846e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2902/  8460 | global iter:   2902/  8460 | loss: 0.6586 | ds_loss: 0.0000 | lr: 3.6838e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2903/  8460 | global iter:   2903/  8460 | loss: 0.1472 | ds_loss: 0.0000 | lr: 3.6829e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2904/  8460 | global iter:   2904/  8460 | loss: 0.2292 | ds_loss: 0.0000 | lr: 3.6821e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2904/  8460 | global iter:   2904/  8460 | loss: 0.3462 | ds_loss: 0.0000 | lr: 3.6821e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2905/  8460 | global iter:   2905/  8460 | loss: 0.4664 | ds_loss: 0.0000 | lr: 3.6813e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2906/  8460 | global iter:   2906/  8460 | loss: 0.7393 | ds_loss: 0.0000 | lr: 3.6805e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2907/  8460 | global iter:   2907/  8460 | loss: 0.2688 | ds_loss: 0.0000 | lr: 3.6797e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2908/  8460 | global iter:   2908/  8460 | loss: 0.1857 | ds_loss: 0.0000 | lr: 3.6789e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2908/  8460 | global iter:   2908/  8460 | loss: 0.4150 | ds_loss: 0.0000 | lr: 3.6789e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2909/  8460 | global iter:   2909/  8460 | loss: 0.6346 | ds_loss: 0.0000 | lr: 3.6780e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2910/  8460 | global iter:   2910/  8460 | loss: 0.2918 | ds_loss: 0.0000 | lr: 3.6772e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2911/  8460 | global iter:   2911/  8460 | loss: 0.1098 | ds_loss: 0.0000 | lr: 3.6764e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2912/  8460 | global iter:   2912/  8460 | loss: 0.1737 | ds_loss: 0.0000 | lr: 3.6756e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2912/  8460 | global iter:   2912/  8460 | loss: 0.3025 | ds_loss: 0.0000 | lr: 3.6756e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2913/  8460 | global iter:   2913/  8460 | loss: 0.6249 | ds_loss: 0.0000 | lr: 3.6748e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2914/  8460 | global iter:   2914/  8460 | loss: 0.3180 | ds_loss: 0.0000 | lr: 3.6739e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2915/  8460 | global iter:   2915/  8460 | loss: 0.3324 | ds_loss: 0.0000 | lr: 3.6731e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2916/  8460 | global iter:   2916/  8460 | loss: 0.0523 | ds_loss: 0.0000 | lr: 3.6723e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2916/  8460 | global iter:   2916/  8460 | loss: 0.3319 | ds_loss: 0.0000 | lr: 3.6723e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2917/  8460 | global iter:   2917/  8460 | loss: 0.5450 | ds_loss: 0.0000 | lr: 3.6715e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2918/  8460 | global iter:   2918/  8460 | loss: 0.2366 | ds_loss: 0.0000 | lr: 3.6707e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2919/  8460 | global iter:   2919/  8460 | loss: 0.6281 | ds_loss: 0.0000 | lr: 3.6698e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2920/  8460 | global iter:   2920/  8460 | loss: 0.1779 | ds_loss: 0.0000 | lr: 3.6690e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2920/  8460 | global iter:   2920/  8460 | loss: 0.3969 | ds_loss: 0.0000 | lr: 3.6690e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2921/  8460 | global iter:   2921/  8460 | loss: 0.1812 | ds_loss: 0.0000 | lr: 3.6682e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2922/  8460 | global iter:   2922/  8460 | loss: 0.4210 | ds_loss: 0.0000 | lr: 3.6674e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2923/  8460 | global iter:   2923/  8460 | loss: 0.3024 | ds_loss: 0.0000 | lr: 3.6666e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2924/  8460 | global iter:   2924/  8460 | loss: 0.6806 | ds_loss: 0.0000 | lr: 3.6657e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2924/  8460 | global iter:   2924/  8460 | loss: 0.3963 | ds_loss: 0.0000 | lr: 3.6657e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2925/  8460 | global iter:   2925/  8460 | loss: 0.6625 | ds_loss: 0.0000 | lr: 3.6649e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2926/  8460 | global iter:   2926/  8460 | loss: 0.8409 | ds_loss: 0.0000 | lr: 3.6641e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2927/  8460 | global iter:   2927/  8460 | loss: 0.5782 | ds_loss: 0.0000 | lr: 3.6633e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2928/  8460 | global iter:   2928/  8460 | loss: 0.3861 | ds_loss: 0.0000 | lr: 3.6625e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2928/  8460 | global iter:   2928/  8460 | loss: 0.6169 | ds_loss: 0.0000 | lr: 3.6625e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2929/  8460 | global iter:   2929/  8460 | loss: 0.8128 | ds_loss: 0.0000 | lr: 3.6616e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2930/  8460 | global iter:   2930/  8460 | loss: 0.3727 | ds_loss: 0.0000 | lr: 3.6608e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2931/  8460 | global iter:   2931/  8460 | loss: 0.2081 | ds_loss: 0.0000 | lr: 3.6600e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2932/  8460 | global iter:   2932/  8460 | loss: 0.1650 | ds_loss: 0.0000 | lr: 3.6592e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2932/  8460 | global iter:   2932/  8460 | loss: 0.3896 | ds_loss: 0.0000 | lr: 3.6592e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2933/  8460 | global iter:   2933/  8460 | loss: 0.3010 | ds_loss: 0.0000 | lr: 3.6583e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   2934/  8460 | global iter:   2934/  8460 | loss: 0.3647 | ds_loss: 0.0000 | lr: 3.6575e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2935/  8460 | global iter:   2935/  8460 | loss: 0.2822 | ds_loss: 0.0000 | lr: 3.6567e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2936/  8460 | global iter:   2936/  8460 | loss: 0.4711 | ds_loss: 0.0000 | lr: 3.6559e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2936/  8460 | global iter:   2936/  8460 | loss: 0.3547 | ds_loss: 0.0000 | lr: 3.6559e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2937/  8460 | global iter:   2937/  8460 | loss: 0.2238 | ds_loss: 0.0000 | lr: 3.6551e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2938/  8460 | global iter:   2938/  8460 | loss: 0.1809 | ds_loss: 0.0000 | lr: 3.6542e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2939/  8460 | global iter:   2939/  8460 | loss: 0.6445 | ds_loss: 0.0000 | lr: 3.6534e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2940/  8460 | global iter:   2940/  8460 | loss: 0.7061 | ds_loss: 0.0000 | lr: 3.6526e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2940/  8460 | global iter:   2940/  8460 | loss: 0.4388 | ds_loss: 0.0000 | lr: 3.6526e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2941/  8460 | global iter:   2941/  8460 | loss: 0.6274 | ds_loss: 0.0000 | lr: 3.6518e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2942/  8460 | global iter:   2942/  8460 | loss: 0.1903 | ds_loss: 0.0000 | lr: 3.6509e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2943/  8460 | global iter:   2943/  8460 | loss: 0.2608 | ds_loss: 0.0000 | lr: 3.6501e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2944/  8460 | global iter:   2944/  8460 | loss: 0.6572 | ds_loss: 0.0000 | lr: 3.6493e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2944/  8460 | global iter:   2944/  8460 | loss: 0.4339 | ds_loss: 0.0000 | lr: 3.6493e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2945/  8460 | global iter:   2945/  8460 | loss: 0.2926 | ds_loss: 0.0000 | lr: 3.6485e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2946/  8460 | global iter:   2946/  8460 | loss: 0.6721 | ds_loss: 0.0000 | lr: 3.6476e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2947/  8460 | global iter:   2947/  8460 | loss: 0.4985 | ds_loss: 0.0000 | lr: 3.6468e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2948/  8460 | global iter:   2948/  8460 | loss: 0.5700 | ds_loss: 0.0000 | lr: 3.6460e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2948/  8460 | global iter:   2948/  8460 | loss: 0.5083 | ds_loss: 0.0000 | lr: 3.6460e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2949/  8460 | global iter:   2949/  8460 | loss: 0.3077 | ds_loss: 0.0000 | lr: 3.6452e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2950/  8460 | global iter:   2950/  8460 | loss: 0.5783 | ds_loss: 0.0000 | lr: 3.6443e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2951/  8460 | global iter:   2951/  8460 | loss: 0.2208 | ds_loss: 0.0000 | lr: 3.6435e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2952/  8460 | global iter:   2952/  8460 | loss: 0.5871 | ds_loss: 0.0000 | lr: 3.6427e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2952/  8460 | global iter:   2952/  8460 | loss: 0.4235 | ds_loss: 0.0000 | lr: 3.6427e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2953/  8460 | global iter:   2953/  8460 | loss: 0.3229 | ds_loss: 0.0000 | lr: 3.6419e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2954/  8460 | global iter:   2954/  8460 | loss: 0.2693 | ds_loss: 0.0000 | lr: 3.6410e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2955/  8460 | global iter:   2955/  8460 | loss: 0.4417 | ds_loss: 0.0000 | lr: 3.6402e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2956/  8460 | global iter:   2956/  8460 | loss: 0.3586 | ds_loss: 0.0000 | lr: 3.6394e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2956/  8460 | global iter:   2956/  8460 | loss: 0.3481 | ds_loss: 0.0000 | lr: 3.6394e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2957/  8460 | global iter:   2957/  8460 | loss: 0.5501 | ds_loss: 0.0000 | lr: 3.6386e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2958/  8460 | global iter:   2958/  8460 | loss: 0.8147 | ds_loss: 0.0000 | lr: 3.6377e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2959/  8460 | global iter:   2959/  8460 | loss: 0.1648 | ds_loss: 0.0000 | lr: 3.6369e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2960/  8460 | global iter:   2960/  8460 | loss: 0.3137 | ds_loss: 0.0000 | lr: 3.6361e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2960/  8460 | global iter:   2960/  8460 | loss: 0.4608 | ds_loss: 0.0000 | lr: 3.6361e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2961/  8460 | global iter:   2961/  8460 | loss: 0.1537 | ds_loss: 0.0000 | lr: 3.6352e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2962/  8460 | global iter:   2962/  8460 | loss: 0.3883 | ds_loss: 0.0000 | lr: 3.6344e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2963/  8460 | global iter:   2963/  8460 | loss: 0.4485 | ds_loss: 0.0000 | lr: 3.6336e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2964/  8460 | global iter:   2964/  8460 | loss: 0.1397 | ds_loss: 0.0000 | lr: 3.6328e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2964/  8460 | global iter:   2964/  8460 | loss: 0.2825 | ds_loss: 0.0000 | lr: 3.6328e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2965/  8460 | global iter:   2965/  8460 | loss: 0.4175 | ds_loss: 0.0000 | lr: 3.6319e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2966/  8460 | global iter:   2966/  8460 | loss: 0.2839 | ds_loss: 0.0000 | lr: 3.6311e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2967/  8460 | global iter:   2967/  8460 | loss: 0.1304 | ds_loss: 0.0000 | lr: 3.6303e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2968/  8460 | global iter:   2968/  8460 | loss: 0.6112 | ds_loss: 0.0000 | lr: 3.6295e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2968/  8460 | global iter:   2968/  8460 | loss: 0.3607 | ds_loss: 0.0000 | lr: 3.6295e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2969/  8460 | global iter:   2969/  8460 | loss: 0.3588 | ds_loss: 0.0000 | lr: 3.6286e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   2970/  8460 | global iter:   2970/  8460 | loss: 0.2612 | ds_loss: 0.0000 | lr: 3.6278e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2971/  8460 | global iter:   2971/  8460 | loss: 0.1838 | ds_loss: 0.0000 | lr: 3.6270e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2972/  8460 | global iter:   2972/  8460 | loss: 0.6036 | ds_loss: 0.0000 | lr: 3.6261e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2972/  8460 | global iter:   2972/  8460 | loss: 0.3518 | ds_loss: 0.0000 | lr: 3.6261e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2973/  8460 | global iter:   2973/  8460 | loss: 0.1982 | ds_loss: 0.0000 | lr: 3.6253e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2974/  8460 | global iter:   2974/  8460 | loss: 0.2631 | ds_loss: 0.0000 | lr: 3.6245e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2975/  8460 | global iter:   2975/  8460 | loss: 0.2576 | ds_loss: 0.0000 | lr: 3.6237e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2976/  8460 | global iter:   2976/  8460 | loss: 0.3661 | ds_loss: 0.0000 | lr: 3.6228e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2976/  8460 | global iter:   2976/  8460 | loss: 0.2712 | ds_loss: 0.0000 | lr: 3.6228e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2977/  8460 | global iter:   2977/  8460 | loss: 0.1320 | ds_loss: 0.0000 | lr: 3.6220e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2978/  8460 | global iter:   2978/  8460 | loss: 0.6925 | ds_loss: 0.0000 | lr: 3.6212e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2979/  8460 | global iter:   2979/  8460 | loss: 0.9286 | ds_loss: 0.0000 | lr: 3.6203e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2980/  8460 | global iter:   2980/  8460 | loss: 0.3206 | ds_loss: 0.0000 | lr: 3.6195e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2980/  8460 | global iter:   2980/  8460 | loss: 0.5184 | ds_loss: 0.0000 | lr: 3.6195e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2981/  8460 | global iter:   2981/  8460 | loss: 0.4911 | ds_loss: 0.0000 | lr: 3.6187e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   2982/  8460 | global iter:   2982/  8460 | loss: 0.6210 | ds_loss: 0.0000 | lr: 3.6178e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   2983/  8460 | global iter:   2983/  8460 | loss: 0.5324 | ds_loss: 0.0000 | lr: 3.6170e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   2984/  8460 | global iter:   2984/  8460 | loss: 0.1210 | ds_loss: 0.0000 | lr: 3.6162e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2984/  8460 | global iter:   2984/  8460 | loss: 0.4414 | ds_loss: 0.0000 | lr: 3.6162e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2985/  8460 | global iter:   2985/  8460 | loss: 0.3026 | ds_loss: 0.0000 | lr: 3.6154e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2986/  8460 | global iter:   2986/  8460 | loss: 0.8360 | ds_loss: 0.0000 | lr: 3.6145e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2987/  8460 | global iter:   2987/  8460 | loss: 0.4580 | ds_loss: 0.0000 | lr: 3.6137e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2988/  8460 | global iter:   2988/  8460 | loss: 0.3654 | ds_loss: 0.0000 | lr: 3.6129e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2988/  8460 | global iter:   2988/  8460 | loss: 0.4905 | ds_loss: 0.0000 | lr: 3.6129e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2989/  8460 | global iter:   2989/  8460 | loss: 0.2086 | ds_loss: 0.0000 | lr: 3.6120e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2990/  8460 | global iter:   2990/  8460 | loss: 0.3442 | ds_loss: 0.0000 | lr: 3.6112e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2991/  8460 | global iter:   2991/  8460 | loss: 0.2927 | ds_loss: 0.0000 | lr: 3.6104e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2992/  8460 | global iter:   2992/  8460 | loss: 0.6786 | ds_loss: 0.0000 | lr: 3.6095e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2992/  8460 | global iter:   2992/  8460 | loss: 0.3810 | ds_loss: 0.0000 | lr: 3.6095e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2993/  8460 | global iter:   2993/  8460 | loss: 0.6462 | ds_loss: 0.0000 | lr: 3.6087e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   2994/  8460 | global iter:   2994/  8460 | loss: 0.2778 | ds_loss: 0.0000 | lr: 3.6079e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   2995/  8460 | global iter:   2995/  8460 | loss: 0.4353 | ds_loss: 0.0000 | lr: 3.6070e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   2996/  8460 | global iter:   2996/  8460 | loss: 0.0449 | ds_loss: 0.0000 | lr: 3.6062e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   2996/  8460 | global iter:   2996/  8460 | loss: 0.3511 | ds_loss: 0.0000 | lr: 3.6062e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   2997/  8460 | global iter:   2997/  8460 | loss: 0.2482 | ds_loss: 0.0000 | lr: 3.6054e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2998/  8460 | global iter:   2998/  8460 | loss: 0.2720 | ds_loss: 0.0000 | lr: 3.6045e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   2999/  8460 | global iter:   2999/  8460 | loss: 0.2566 | ds_loss: 0.0000 | lr: 3.6037e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3000/  8460 | global iter:   3000/  8460 | loss: 0.1904 | ds_loss: 0.0000 | lr: 3.6029e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3000/  8460 | global iter:   3000/  8460 | loss: 0.2418 | ds_loss: 0.0000 | lr: 3.6029e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3001/  8460 | global iter:   3001/  8460 | loss: 0.2058 | ds_loss: 0.0000 | lr: 3.6020e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3002/  8460 | global iter:   3002/  8460 | loss: 0.0577 | ds_loss: 0.0000 | lr: 3.6012e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3003/  8460 | global iter:   3003/  8460 | loss: 0.3588 | ds_loss: 0.0000 | lr: 3.6004e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3004/  8460 | global iter:   3004/  8460 | loss: 0.3742 | ds_loss: 0.0000 | lr: 3.5995e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3004/  8460 | global iter:   3004/  8460 | loss: 0.2491 | ds_loss: 0.0000 | lr: 3.5995e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3005/  8460 | global iter:   3005/  8460 | loss: 0.1443 | ds_loss: 0.0000 | lr: 3.5987e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3006/  8460 | global iter:   3006/  8460 | loss: 0.1897 | ds_loss: 0.0000 | lr: 3.5979e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3007/  8460 | global iter:   3007/  8460 | loss: 0.3078 | ds_loss: 0.0000 | lr: 3.5970e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3008/  8460 | global iter:   3008/  8460 | loss: 0.3413 | ds_loss: 0.0000 | lr: 3.5962e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3008/  8460 | global iter:   3008/  8460 | loss: 0.2458 | ds_loss: 0.0000 | lr: 3.5962e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3009/  8460 | global iter:   3009/  8460 | loss: 0.3120 | ds_loss: 0.0000 | lr: 3.5954e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3010/  8460 | global iter:   3010/  8460 | loss: 0.2462 | ds_loss: 0.0000 | lr: 3.5945e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3011/  8460 | global iter:   3011/  8460 | loss: 0.6189 | ds_loss: 0.0000 | lr: 3.5937e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3012/  8460 | global iter:   3012/  8460 | loss: 0.3663 | ds_loss: 0.0000 | lr: 3.5929e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3012/  8460 | global iter:   3012/  8460 | loss: 0.3858 | ds_loss: 0.0000 | lr: 3.5929e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3013/  8460 | global iter:   3013/  8460 | loss: 0.1719 | ds_loss: 0.0000 | lr: 3.5920e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3014/  8460 | global iter:   3014/  8460 | loss: 0.7979 | ds_loss: 0.0000 | lr: 3.5912e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3015/  8460 | global iter:   3015/  8460 | loss: 0.2538 | ds_loss: 0.0000 | lr: 3.5904e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3016/  8460 | global iter:   3016/  8460 | loss: 0.2334 | ds_loss: 0.0000 | lr: 3.5895e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3016/  8460 | global iter:   3016/  8460 | loss: 0.3642 | ds_loss: 0.0000 | lr: 3.5895e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3017/  8460 | global iter:   3017/  8460 | loss: 0.5638 | ds_loss: 0.0000 | lr: 3.5887e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3018/  8460 | global iter:   3018/  8460 | loss: 0.7509 | ds_loss: 0.0000 | lr: 3.5879e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3019/  8460 | global iter:   3019/  8460 | loss: 0.5853 | ds_loss: 0.0000 | lr: 3.5870e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3020/  8460 | global iter:   3020/  8460 | loss: 0.2328 | ds_loss: 0.0000 | lr: 3.5862e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3020/  8460 | global iter:   3020/  8460 | loss: 0.5332 | ds_loss: 0.0000 | lr: 3.5862e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3021/  8460 | global iter:   3021/  8460 | loss: 0.1747 | ds_loss: 0.0000 | lr: 3.5854e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3022/  8460 | global iter:   3022/  8460 | loss: 0.8917 | ds_loss: 0.0000 | lr: 3.5845e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3023/  8460 | global iter:   3023/  8460 | loss: 0.1195 | ds_loss: 0.0000 | lr: 3.5837e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3024/  8460 | global iter:   3024/  8460 | loss: 0.1956 | ds_loss: 0.0000 | lr: 3.5828e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3024/  8460 | global iter:   3024/  8460 | loss: 0.3454 | ds_loss: 0.0000 | lr: 3.5828e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3025/  8460 | global iter:   3025/  8460 | loss: 0.2361 | ds_loss: 0.0000 | lr: 3.5820e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3026/  8460 | global iter:   3026/  8460 | loss: 0.7241 | ds_loss: 0.0000 | lr: 3.5812e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3027/  8460 | global iter:   3027/  8460 | loss: 0.1509 | ds_loss: 0.0000 | lr: 3.5803e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3028/  8460 | global iter:   3028/  8460 | loss: 0.4800 | ds_loss: 0.0000 | lr: 3.5795e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3028/  8460 | global iter:   3028/  8460 | loss: 0.3978 | ds_loss: 0.0000 | lr: 3.5795e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3029/  8460 | global iter:   3029/  8460 | loss: 0.4480 | ds_loss: 0.0000 | lr: 3.5787e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3030/  8460 | global iter:   3030/  8460 | loss: 0.3226 | ds_loss: 0.0000 | lr: 3.5778e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3031/  8460 | global iter:   3031/  8460 | loss: 0.5101 | ds_loss: 0.0000 | lr: 3.5770e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3032/  8460 | global iter:   3032/  8460 | loss: 0.1727 | ds_loss: 0.0000 | lr: 3.5761e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3032/  8460 | global iter:   3032/  8460 | loss: 0.3634 | ds_loss: 0.0000 | lr: 3.5761e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3033/  8460 | global iter:   3033/  8460 | loss: 0.1300 | ds_loss: 0.0000 | lr: 3.5753e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3034/  8460 | global iter:   3034/  8460 | loss: 0.7577 | ds_loss: 0.0000 | lr: 3.5745e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3035/  8460 | global iter:   3035/  8460 | loss: 0.2627 | ds_loss: 0.0000 | lr: 3.5736e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3036/  8460 | global iter:   3036/  8460 | loss: 0.5954 | ds_loss: 0.0000 | lr: 3.5728e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3036/  8460 | global iter:   3036/  8460 | loss: 0.4364 | ds_loss: 0.0000 | lr: 3.5728e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3037/  8460 | global iter:   3037/  8460 | loss: 0.1734 | ds_loss: 0.0000 | lr: 3.5720e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3038/  8460 | global iter:   3038/  8460 | loss: 0.5480 | ds_loss: 0.0000 | lr: 3.5711e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3039/  8460 | global iter:   3039/  8460 | loss: 0.2632 | ds_loss: 0.0000 | lr: 3.5703e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3040/  8460 | global iter:   3040/  8460 | loss: 0.3064 | ds_loss: 0.0000 | lr: 3.5694e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3040/  8460 | global iter:   3040/  8460 | loss: 0.3228 | ds_loss: 0.0000 | lr: 3.5694e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3041/  8460 | global iter:   3041/  8460 | loss: 0.1521 | ds_loss: 0.0000 | lr: 3.5686e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3042/  8460 | global iter:   3042/  8460 | loss: 0.4031 | ds_loss: 0.0000 | lr: 3.5678e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3043/  8460 | global iter:   3043/  8460 | loss: 0.2284 | ds_loss: 0.0000 | lr: 3.5669e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3044/  8460 | global iter:   3044/  8460 | loss: 0.2621 | ds_loss: 0.0000 | lr: 3.5661e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3044/  8460 | global iter:   3044/  8460 | loss: 0.2614 | ds_loss: 0.0000 | lr: 3.5661e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3045/  8460 | global iter:   3045/  8460 | loss: 0.6916 | ds_loss: 0.0000 | lr: 3.5652e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3046/  8460 | global iter:   3046/  8460 | loss: 0.4913 | ds_loss: 0.0000 | lr: 3.5644e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3047/  8460 | global iter:   3047/  8460 | loss: 0.1387 | ds_loss: 0.0000 | lr: 3.5636e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3048/  8460 | global iter:   3048/  8460 | loss: 0.2656 | ds_loss: 0.0000 | lr: 3.5627e-04 | scale:     1.0000 | micro time: 0.439 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3048/  8460 | global iter:   3048/  8460 | loss: 0.3968 | ds_loss: 0.0000 | lr: 3.5627e-04 | scale:     1.0000 | micro time: 0.439 | step time: 0.431
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3049/  8460 | global iter:   3049/  8460 | loss: 0.6737 | ds_loss: 0.0000 | lr: 3.5619e-04 | scale:     1.0000 | micro time: 0.440 | step time: 0.000
train | epoch   3 | Iter:   3050/  8460 | global iter:   3050/  8460 | loss: 0.1343 | ds_loss: 0.0000 | lr: 3.5610e-04 | scale:     1.0000 | micro time: 0.439 | step time: 0.000
train | epoch   3 | Iter:   3051/  8460 | global iter:   3051/  8460 | loss: 0.2049 | ds_loss: 0.0000 | lr: 3.5602e-04 | scale:     1.0000 | micro time: 0.439 | step time: 0.000
train | epoch   3 | Iter:   3052/  8460 | global iter:   3052/  8460 | loss: 0.4374 | ds_loss: 0.0000 | lr: 3.5594e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3052/  8460 | global iter:   3052/  8460 | loss: 0.3626 | ds_loss: 0.0000 | lr: 3.5594e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.437
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3053/  8460 | global iter:   3053/  8460 | loss: 0.8896 | ds_loss: 0.0000 | lr: 3.5585e-04 | scale:     1.0000 | micro time: 0.438 | step time: 0.000
train | epoch   3 | Iter:   3054/  8460 | global iter:   3054/  8460 | loss: 0.1733 | ds_loss: 0.0000 | lr: 3.5577e-04 | scale:     1.0000 | micro time: 0.442 | step time: 0.000
train | epoch   3 | Iter:   3055/  8460 | global iter:   3055/  8460 | loss: 0.3391 | ds_loss: 0.0000 | lr: 3.5568e-04 | scale:     1.0000 | micro time: 0.439 | step time: 0.000
train | epoch   3 | Iter:   3056/  8460 | global iter:   3056/  8460 | loss: 0.1509 | ds_loss: 0.0000 | lr: 3.5560e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3056/  8460 | global iter:   3056/  8460 | loss: 0.3882 | ds_loss: 0.0000 | lr: 3.5560e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.437
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3057/  8460 | global iter:   3057/  8460 | loss: 0.2706 | ds_loss: 0.0000 | lr: 3.5552e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3058/  8460 | global iter:   3058/  8460 | loss: 0.2732 | ds_loss: 0.0000 | lr: 3.5543e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3059/  8460 | global iter:   3059/  8460 | loss: 0.4249 | ds_loss: 0.0000 | lr: 3.5535e-04 | scale:     1.0000 | micro time: 0.439 | step time: 0.000
train | epoch   3 | Iter:   3060/  8460 | global iter:   3060/  8460 | loss: 0.4198 | ds_loss: 0.0000 | lr: 3.5526e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3060/  8460 | global iter:   3060/  8460 | loss: 0.3471 | ds_loss: 0.0000 | lr: 3.5526e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.431
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3061/  8460 | global iter:   3061/  8460 | loss: 0.1633 | ds_loss: 0.0000 | lr: 3.5518e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3062/  8460 | global iter:   3062/  8460 | loss: 0.2537 | ds_loss: 0.0000 | lr: 3.5509e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3063/  8460 | global iter:   3063/  8460 | loss: 0.4430 | ds_loss: 0.0000 | lr: 3.5501e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3064/  8460 | global iter:   3064/  8460 | loss: 0.4644 | ds_loss: 0.0000 | lr: 3.5493e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3064/  8460 | global iter:   3064/  8460 | loss: 0.3311 | ds_loss: 0.0000 | lr: 3.5493e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3065/  8460 | global iter:   3065/  8460 | loss: 0.1797 | ds_loss: 0.0000 | lr: 3.5484e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3066/  8460 | global iter:   3066/  8460 | loss: 0.5339 | ds_loss: 0.0000 | lr: 3.5476e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3067/  8460 | global iter:   3067/  8460 | loss: 0.1488 | ds_loss: 0.0000 | lr: 3.5467e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3068/  8460 | global iter:   3068/  8460 | loss: 0.5206 | ds_loss: 0.0000 | lr: 3.5459e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3068/  8460 | global iter:   3068/  8460 | loss: 0.3458 | ds_loss: 0.0000 | lr: 3.5459e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3069/  8460 | global iter:   3069/  8460 | loss: 0.6500 | ds_loss: 0.0000 | lr: 3.5450e-04 | scale:     1.0000 | micro time: 0.438 | step time: 0.000
train | epoch   3 | Iter:   3070/  8460 | global iter:   3070/  8460 | loss: 0.2631 | ds_loss: 0.0000 | lr: 3.5442e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3071/  8460 | global iter:   3071/  8460 | loss: 0.7271 | ds_loss: 0.0000 | lr: 3.5434e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3072/  8460 | global iter:   3072/  8460 | loss: 0.1721 | ds_loss: 0.0000 | lr: 3.5425e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3072/  8460 | global iter:   3072/  8460 | loss: 0.4531 | ds_loss: 0.0000 | lr: 3.5425e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.431
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3073/  8460 | global iter:   3073/  8460 | loss: 0.1131 | ds_loss: 0.0000 | lr: 3.5417e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3074/  8460 | global iter:   3074/  8460 | loss: 0.1388 | ds_loss: 0.0000 | lr: 3.5408e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3075/  8460 | global iter:   3075/  8460 | loss: 0.4412 | ds_loss: 0.0000 | lr: 3.5400e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3076/  8460 | global iter:   3076/  8460 | loss: 0.0886 | ds_loss: 0.0000 | lr: 3.5391e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3076/  8460 | global iter:   3076/  8460 | loss: 0.1954 | ds_loss: 0.0000 | lr: 3.5391e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3077/  8460 | global iter:   3077/  8460 | loss: 0.2813 | ds_loss: 0.0000 | lr: 3.5383e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3078/  8460 | global iter:   3078/  8460 | loss: 0.3475 | ds_loss: 0.0000 | lr: 3.5374e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3079/  8460 | global iter:   3079/  8460 | loss: 0.7364 | ds_loss: 0.0000 | lr: 3.5366e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3080/  8460 | global iter:   3080/  8460 | loss: 0.2933 | ds_loss: 0.0000 | lr: 3.5358e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3080/  8460 | global iter:   3080/  8460 | loss: 0.4146 | ds_loss: 0.0000 | lr: 3.5358e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3081/  8460 | global iter:   3081/  8460 | loss: 0.6036 | ds_loss: 0.0000 | lr: 3.5349e-04 | scale:     1.0000 | micro time: 0.437 | step time: 0.000
train | epoch   3 | Iter:   3082/  8460 | global iter:   3082/  8460 | loss: 0.1205 | ds_loss: 0.0000 | lr: 3.5341e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3083/  8460 | global iter:   3083/  8460 | loss: 0.1691 | ds_loss: 0.0000 | lr: 3.5332e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3084/  8460 | global iter:   3084/  8460 | loss: 0.1128 | ds_loss: 0.0000 | lr: 3.5324e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3084/  8460 | global iter:   3084/  8460 | loss: 0.2515 | ds_loss: 0.0000 | lr: 3.5324e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.430
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3085/  8460 | global iter:   3085/  8460 | loss: 0.4323 | ds_loss: 0.0000 | lr: 3.5315e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3086/  8460 | global iter:   3086/  8460 | loss: 0.1318 | ds_loss: 0.0000 | lr: 3.5307e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3087/  8460 | global iter:   3087/  8460 | loss: 0.2979 | ds_loss: 0.0000 | lr: 3.5298e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3088/  8460 | global iter:   3088/  8460 | loss: 0.3820 | ds_loss: 0.0000 | lr: 3.5290e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3088/  8460 | global iter:   3088/  8460 | loss: 0.3110 | ds_loss: 0.0000 | lr: 3.5290e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3089/  8460 | global iter:   3089/  8460 | loss: 0.1237 | ds_loss: 0.0000 | lr: 3.5281e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3090/  8460 | global iter:   3090/  8460 | loss: 0.5218 | ds_loss: 0.0000 | lr: 3.5273e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3091/  8460 | global iter:   3091/  8460 | loss: 0.4950 | ds_loss: 0.0000 | lr: 3.5265e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3092/  8460 | global iter:   3092/  8460 | loss: 0.3222 | ds_loss: 0.0000 | lr: 3.5256e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3092/  8460 | global iter:   3092/  8460 | loss: 0.3657 | ds_loss: 0.0000 | lr: 3.5256e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3093/  8460 | global iter:   3093/  8460 | loss: 0.3825 | ds_loss: 0.0000 | lr: 3.5248e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3094/  8460 | global iter:   3094/  8460 | loss: 0.4661 | ds_loss: 0.0000 | lr: 3.5239e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3095/  8460 | global iter:   3095/  8460 | loss: 0.3868 | ds_loss: 0.0000 | lr: 3.5231e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3096/  8460 | global iter:   3096/  8460 | loss: 0.3284 | ds_loss: 0.0000 | lr: 3.5222e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3096/  8460 | global iter:   3096/  8460 | loss: 0.3909 | ds_loss: 0.0000 | lr: 3.5222e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3097/  8460 | global iter:   3097/  8460 | loss: 0.1208 | ds_loss: 0.0000 | lr: 3.5214e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3098/  8460 | global iter:   3098/  8460 | loss: 0.4279 | ds_loss: 0.0000 | lr: 3.5205e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3099/  8460 | global iter:   3099/  8460 | loss: 0.4126 | ds_loss: 0.0000 | lr: 3.5197e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3100/  8460 | global iter:   3100/  8460 | loss: 1.1029 | ds_loss: 0.0000 | lr: 3.5188e-04 | scale:     1.0000 | micro time: 0.438 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3100/  8460 | global iter:   3100/  8460 | loss: 0.5161 | ds_loss: 0.0000 | lr: 3.5188e-04 | scale:     1.0000 | micro time: 0.438 | step time: 0.431
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3101/  8460 | global iter:   3101/  8460 | loss: 0.1758 | ds_loss: 0.0000 | lr: 3.5180e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.000
train | epoch   3 | Iter:   3102/  8460 | global iter:   3102/  8460 | loss: 0.3060 | ds_loss: 0.0000 | lr: 3.5171e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3103/  8460 | global iter:   3103/  8460 | loss: 0.1572 | ds_loss: 0.0000 | lr: 3.5163e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3104/  8460 | global iter:   3104/  8460 | loss: 0.3136 | ds_loss: 0.0000 | lr: 3.5154e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3104/  8460 | global iter:   3104/  8460 | loss: 0.2382 | ds_loss: 0.0000 | lr: 3.5154e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3105/  8460 | global iter:   3105/  8460 | loss: 0.3513 | ds_loss: 0.0000 | lr: 3.5146e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3106/  8460 | global iter:   3106/  8460 | loss: 0.1549 | ds_loss: 0.0000 | lr: 3.5137e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3107/  8460 | global iter:   3107/  8460 | loss: 0.1766 | ds_loss: 0.0000 | lr: 3.5129e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3108/  8460 | global iter:   3108/  8460 | loss: 0.3706 | ds_loss: 0.0000 | lr: 3.5120e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3108/  8460 | global iter:   3108/  8460 | loss: 0.2633 | ds_loss: 0.0000 | lr: 3.5120e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3109/  8460 | global iter:   3109/  8460 | loss: 0.4478 | ds_loss: 0.0000 | lr: 3.5112e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3110/  8460 | global iter:   3110/  8460 | loss: 0.8302 | ds_loss: 0.0000 | lr: 3.5104e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3111/  8460 | global iter:   3111/  8460 | loss: 0.3534 | ds_loss: 0.0000 | lr: 3.5095e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3112/  8460 | global iter:   3112/  8460 | loss: 0.2775 | ds_loss: 0.0000 | lr: 3.5087e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3112/  8460 | global iter:   3112/  8460 | loss: 0.4772 | ds_loss: 0.0000 | lr: 3.5087e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3113/  8460 | global iter:   3113/  8460 | loss: 0.3757 | ds_loss: 0.0000 | lr: 3.5078e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3114/  8460 | global iter:   3114/  8460 | loss: 0.1873 | ds_loss: 0.0000 | lr: 3.5070e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3115/  8460 | global iter:   3115/  8460 | loss: 0.3468 | ds_loss: 0.0000 | lr: 3.5061e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3116/  8460 | global iter:   3116/  8460 | loss: 0.7246 | ds_loss: 0.0000 | lr: 3.5053e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3116/  8460 | global iter:   3116/  8460 | loss: 0.4086 | ds_loss: 0.0000 | lr: 3.5053e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3117/  8460 | global iter:   3117/  8460 | loss: 0.3334 | ds_loss: 0.0000 | lr: 3.5044e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3118/  8460 | global iter:   3118/  8460 | loss: 0.1891 | ds_loss: 0.0000 | lr: 3.5036e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3119/  8460 | global iter:   3119/  8460 | loss: 0.4969 | ds_loss: 0.0000 | lr: 3.5027e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3120/  8460 | global iter:   3120/  8460 | loss: 0.4617 | ds_loss: 0.0000 | lr: 3.5019e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3120/  8460 | global iter:   3120/  8460 | loss: 0.3703 | ds_loss: 0.0000 | lr: 3.5019e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3121/  8460 | global iter:   3121/  8460 | loss: 0.5381 | ds_loss: 0.0000 | lr: 3.5010e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3122/  8460 | global iter:   3122/  8460 | loss: 0.4513 | ds_loss: 0.0000 | lr: 3.5002e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3123/  8460 | global iter:   3123/  8460 | loss: 0.5913 | ds_loss: 0.0000 | lr: 3.4993e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3124/  8460 | global iter:   3124/  8460 | loss: 0.5628 | ds_loss: 0.0000 | lr: 3.4984e-04 | scale:     1.0000 | micro time: 0.440 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3124/  8460 | global iter:   3124/  8460 | loss: 0.5359 | ds_loss: 0.0000 | lr: 3.4984e-04 | scale:     1.0000 | micro time: 0.440 | step time: 0.431
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3125/  8460 | global iter:   3125/  8460 | loss: 0.5032 | ds_loss: 0.0000 | lr: 3.4976e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3126/  8460 | global iter:   3126/  8460 | loss: 0.4508 | ds_loss: 0.0000 | lr: 3.4967e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3127/  8460 | global iter:   3127/  8460 | loss: 0.2977 | ds_loss: 0.0000 | lr: 3.4959e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3128/  8460 | global iter:   3128/  8460 | loss: 0.2837 | ds_loss: 0.0000 | lr: 3.4950e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3128/  8460 | global iter:   3128/  8460 | loss: 0.3838 | ds_loss: 0.0000 | lr: 3.4950e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3129/  8460 | global iter:   3129/  8460 | loss: 0.4447 | ds_loss: 0.0000 | lr: 3.4942e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3130/  8460 | global iter:   3130/  8460 | loss: 0.3383 | ds_loss: 0.0000 | lr: 3.4933e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3131/  8460 | global iter:   3131/  8460 | loss: 0.5643 | ds_loss: 0.0000 | lr: 3.4925e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3132/  8460 | global iter:   3132/  8460 | loss: 0.6861 | ds_loss: 0.0000 | lr: 3.4916e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3132/  8460 | global iter:   3132/  8460 | loss: 0.5084 | ds_loss: 0.0000 | lr: 3.4916e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3133/  8460 | global iter:   3133/  8460 | loss: 0.4524 | ds_loss: 0.0000 | lr: 3.4908e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3134/  8460 | global iter:   3134/  8460 | loss: 0.7454 | ds_loss: 0.0000 | lr: 3.4899e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3135/  8460 | global iter:   3135/  8460 | loss: 0.7352 | ds_loss: 0.0000 | lr: 3.4891e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3136/  8460 | global iter:   3136/  8460 | loss: 0.7537 | ds_loss: 0.0000 | lr: 3.4882e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3136/  8460 | global iter:   3136/  8460 | loss: 0.6717 | ds_loss: 0.0000 | lr: 3.4882e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3137/  8460 | global iter:   3137/  8460 | loss: 0.1647 | ds_loss: 0.0000 | lr: 3.4874e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3138/  8460 | global iter:   3138/  8460 | loss: 0.5804 | ds_loss: 0.0000 | lr: 3.4865e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3139/  8460 | global iter:   3139/  8460 | loss: 0.7944 | ds_loss: 0.0000 | lr: 3.4857e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3140/  8460 | global iter:   3140/  8460 | loss: 0.7998 | ds_loss: 0.0000 | lr: 3.4848e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3140/  8460 | global iter:   3140/  8460 | loss: 0.5848 | ds_loss: 0.0000 | lr: 3.4848e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3141/  8460 | global iter:   3141/  8460 | loss: 0.4361 | ds_loss: 0.0000 | lr: 3.4840e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3142/  8460 | global iter:   3142/  8460 | loss: 0.4575 | ds_loss: 0.0000 | lr: 3.4831e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3143/  8460 | global iter:   3143/  8460 | loss: 0.4105 | ds_loss: 0.0000 | lr: 3.4823e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3144/  8460 | global iter:   3144/  8460 | loss: 0.4597 | ds_loss: 0.0000 | lr: 3.4814e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3144/  8460 | global iter:   3144/  8460 | loss: 0.4409 | ds_loss: 0.0000 | lr: 3.4814e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3145/  8460 | global iter:   3145/  8460 | loss: 0.4937 | ds_loss: 0.0000 | lr: 3.4805e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3146/  8460 | global iter:   3146/  8460 | loss: 0.3671 | ds_loss: 0.0000 | lr: 3.4797e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3147/  8460 | global iter:   3147/  8460 | loss: 0.3147 | ds_loss: 0.0000 | lr: 3.4788e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3148/  8460 | global iter:   3148/  8460 | loss: 0.2948 | ds_loss: 0.0000 | lr: 3.4780e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3148/  8460 | global iter:   3148/  8460 | loss: 0.3676 | ds_loss: 0.0000 | lr: 3.4780e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3149/  8460 | global iter:   3149/  8460 | loss: 0.6113 | ds_loss: 0.0000 | lr: 3.4771e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3150/  8460 | global iter:   3150/  8460 | loss: 1.1458 | ds_loss: 0.0000 | lr: 3.4763e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3151/  8460 | global iter:   3151/  8460 | loss: 0.4307 | ds_loss: 0.0000 | lr: 3.4754e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3152/  8460 | global iter:   3152/  8460 | loss: 0.6363 | ds_loss: 0.0000 | lr: 3.4746e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3152/  8460 | global iter:   3152/  8460 | loss: 0.7060 | ds_loss: 0.0000 | lr: 3.4746e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3153/  8460 | global iter:   3153/  8460 | loss: 0.5898 | ds_loss: 0.0000 | lr: 3.4737e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3154/  8460 | global iter:   3154/  8460 | loss: 0.6139 | ds_loss: 0.0000 | lr: 3.4729e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3155/  8460 | global iter:   3155/  8460 | loss: 0.2716 | ds_loss: 0.0000 | lr: 3.4720e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3156/  8460 | global iter:   3156/  8460 | loss: 0.4296 | ds_loss: 0.0000 | lr: 3.4711e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3156/  8460 | global iter:   3156/  8460 | loss: 0.4762 | ds_loss: 0.0000 | lr: 3.4711e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3157/  8460 | global iter:   3157/  8460 | loss: 0.1982 | ds_loss: 0.0000 | lr: 3.4703e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3158/  8460 | global iter:   3158/  8460 | loss: 0.2109 | ds_loss: 0.0000 | lr: 3.4694e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3159/  8460 | global iter:   3159/  8460 | loss: 0.1806 | ds_loss: 0.0000 | lr: 3.4686e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3160/  8460 | global iter:   3160/  8460 | loss: 0.6441 | ds_loss: 0.0000 | lr: 3.4677e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3160/  8460 | global iter:   3160/  8460 | loss: 0.3085 | ds_loss: 0.0000 | lr: 3.4677e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3161/  8460 | global iter:   3161/  8460 | loss: 0.5813 | ds_loss: 0.0000 | lr: 3.4669e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3162/  8460 | global iter:   3162/  8460 | loss: 0.6403 | ds_loss: 0.0000 | lr: 3.4660e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3163/  8460 | global iter:   3163/  8460 | loss: 0.1981 | ds_loss: 0.0000 | lr: 3.4652e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3164/  8460 | global iter:   3164/  8460 | loss: 0.6489 | ds_loss: 0.0000 | lr: 3.4643e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3164/  8460 | global iter:   3164/  8460 | loss: 0.5171 | ds_loss: 0.0000 | lr: 3.4643e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3165/  8460 | global iter:   3165/  8460 | loss: 0.4709 | ds_loss: 0.0000 | lr: 3.4634e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3166/  8460 | global iter:   3166/  8460 | loss: 0.3532 | ds_loss: 0.0000 | lr: 3.4626e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3167/  8460 | global iter:   3167/  8460 | loss: 0.4912 | ds_loss: 0.0000 | lr: 3.4617e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3168/  8460 | global iter:   3168/  8460 | loss: 0.5664 | ds_loss: 0.0000 | lr: 3.4609e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3168/  8460 | global iter:   3168/  8460 | loss: 0.4704 | ds_loss: 0.0000 | lr: 3.4609e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3169/  8460 | global iter:   3169/  8460 | loss: 0.0856 | ds_loss: 0.0000 | lr: 3.4600e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3170/  8460 | global iter:   3170/  8460 | loss: 0.3981 | ds_loss: 0.0000 | lr: 3.4592e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3171/  8460 | global iter:   3171/  8460 | loss: 1.0509 | ds_loss: 0.0000 | lr: 3.4583e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3172/  8460 | global iter:   3172/  8460 | loss: 0.7365 | ds_loss: 0.0000 | lr: 3.4574e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3172/  8460 | global iter:   3172/  8460 | loss: 0.5678 | ds_loss: 0.0000 | lr: 3.4574e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3173/  8460 | global iter:   3173/  8460 | loss: 0.5985 | ds_loss: 0.0000 | lr: 3.4566e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3174/  8460 | global iter:   3174/  8460 | loss: 0.3137 | ds_loss: 0.0000 | lr: 3.4557e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3175/  8460 | global iter:   3175/  8460 | loss: 0.2681 | ds_loss: 0.0000 | lr: 3.4549e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3176/  8460 | global iter:   3176/  8460 | loss: 0.1822 | ds_loss: 0.0000 | lr: 3.4540e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3176/  8460 | global iter:   3176/  8460 | loss: 0.3406 | ds_loss: 0.0000 | lr: 3.4540e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3177/  8460 | global iter:   3177/  8460 | loss: 0.1644 | ds_loss: 0.0000 | lr: 3.4532e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3178/  8460 | global iter:   3178/  8460 | loss: 0.5528 | ds_loss: 0.0000 | lr: 3.4523e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3179/  8460 | global iter:   3179/  8460 | loss: 0.3508 | ds_loss: 0.0000 | lr: 3.4514e-04 | scale:     1.0000 | micro time: 0.437 | step time: 0.000
train | epoch   3 | Iter:   3180/  8460 | global iter:   3180/  8460 | loss: 0.1299 | ds_loss: 0.0000 | lr: 3.4506e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3180/  8460 | global iter:   3180/  8460 | loss: 0.2995 | ds_loss: 0.0000 | lr: 3.4506e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.430
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3181/  8460 | global iter:   3181/  8460 | loss: 0.1819 | ds_loss: 0.0000 | lr: 3.4497e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3182/  8460 | global iter:   3182/  8460 | loss: 0.1303 | ds_loss: 0.0000 | lr: 3.4489e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3183/  8460 | global iter:   3183/  8460 | loss: 0.8406 | ds_loss: 0.0000 | lr: 3.4480e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3184/  8460 | global iter:   3184/  8460 | loss: 0.2722 | ds_loss: 0.0000 | lr: 3.4471e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3184/  8460 | global iter:   3184/  8460 | loss: 0.3562 | ds_loss: 0.0000 | lr: 3.4471e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3185/  8460 | global iter:   3185/  8460 | loss: 0.3054 | ds_loss: 0.0000 | lr: 3.4463e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3186/  8460 | global iter:   3186/  8460 | loss: 0.8455 | ds_loss: 0.0000 | lr: 3.4454e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3187/  8460 | global iter:   3187/  8460 | loss: 0.1467 | ds_loss: 0.0000 | lr: 3.4446e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3188/  8460 | global iter:   3188/  8460 | loss: 0.3884 | ds_loss: 0.0000 | lr: 3.4437e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3188/  8460 | global iter:   3188/  8460 | loss: 0.4215 | ds_loss: 0.0000 | lr: 3.4437e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3189/  8460 | global iter:   3189/  8460 | loss: 0.1863 | ds_loss: 0.0000 | lr: 3.4429e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3190/  8460 | global iter:   3190/  8460 | loss: 0.4177 | ds_loss: 0.0000 | lr: 3.4420e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3191/  8460 | global iter:   3191/  8460 | loss: 0.3933 | ds_loss: 0.0000 | lr: 3.4411e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3192/  8460 | global iter:   3192/  8460 | loss: 0.4417 | ds_loss: 0.0000 | lr: 3.4403e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3192/  8460 | global iter:   3192/  8460 | loss: 0.3597 | ds_loss: 0.0000 | lr: 3.4403e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3193/  8460 | global iter:   3193/  8460 | loss: 0.3770 | ds_loss: 0.0000 | lr: 3.4394e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3194/  8460 | global iter:   3194/  8460 | loss: 0.2111 | ds_loss: 0.0000 | lr: 3.4386e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3195/  8460 | global iter:   3195/  8460 | loss: 0.3922 | ds_loss: 0.0000 | lr: 3.4377e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3196/  8460 | global iter:   3196/  8460 | loss: 0.2494 | ds_loss: 0.0000 | lr: 3.4368e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3196/  8460 | global iter:   3196/  8460 | loss: 0.3074 | ds_loss: 0.0000 | lr: 3.4368e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3197/  8460 | global iter:   3197/  8460 | loss: 0.1907 | ds_loss: 0.0000 | lr: 3.4360e-04 | scale:     1.0000 | micro time: 0.438 | step time: 0.000
train | epoch   3 | Iter:   3198/  8460 | global iter:   3198/  8460 | loss: 0.4437 | ds_loss: 0.0000 | lr: 3.4351e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3199/  8460 | global iter:   3199/  8460 | loss: 0.2704 | ds_loss: 0.0000 | lr: 3.4342e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3200/  8460 | global iter:   3200/  8460 | loss: 0.3068 | ds_loss: 0.0000 | lr: 3.4334e-04 | scale:     1.0000 | micro time: 0.437 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3200/  8460 | global iter:   3200/  8460 | loss: 0.3029 | ds_loss: 0.0000 | lr: 3.4334e-04 | scale:     1.0000 | micro time: 0.437 | step time: 0.433
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3201/  8460 | global iter:   3201/  8460 | loss: 0.8266 | ds_loss: 0.0000 | lr: 3.4325e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3202/  8460 | global iter:   3202/  8460 | loss: 0.1676 | ds_loss: 0.0000 | lr: 3.4317e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3203/  8460 | global iter:   3203/  8460 | loss: 0.6230 | ds_loss: 0.0000 | lr: 3.4308e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3204/  8460 | global iter:   3204/  8460 | loss: 0.1408 | ds_loss: 0.0000 | lr: 3.4299e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3204/  8460 | global iter:   3204/  8460 | loss: 0.4395 | ds_loss: 0.0000 | lr: 3.4299e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3205/  8460 | global iter:   3205/  8460 | loss: 0.2270 | ds_loss: 0.0000 | lr: 3.4291e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3206/  8460 | global iter:   3206/  8460 | loss: 0.4132 | ds_loss: 0.0000 | lr: 3.4282e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3207/  8460 | global iter:   3207/  8460 | loss: 0.5468 | ds_loss: 0.0000 | lr: 3.4274e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3208/  8460 | global iter:   3208/  8460 | loss: 0.2322 | ds_loss: 0.0000 | lr: 3.4265e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3208/  8460 | global iter:   3208/  8460 | loss: 0.3548 | ds_loss: 0.0000 | lr: 3.4265e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3209/  8460 | global iter:   3209/  8460 | loss: 0.2267 | ds_loss: 0.0000 | lr: 3.4256e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3210/  8460 | global iter:   3210/  8460 | loss: 0.3427 | ds_loss: 0.0000 | lr: 3.4248e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3211/  8460 | global iter:   3211/  8460 | loss: 0.4841 | ds_loss: 0.0000 | lr: 3.4239e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3212/  8460 | global iter:   3212/  8460 | loss: 0.2404 | ds_loss: 0.0000 | lr: 3.4230e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3212/  8460 | global iter:   3212/  8460 | loss: 0.3235 | ds_loss: 0.0000 | lr: 3.4230e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3213/  8460 | global iter:   3213/  8460 | loss: 0.3671 | ds_loss: 0.0000 | lr: 3.4222e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3214/  8460 | global iter:   3214/  8460 | loss: 0.3193 | ds_loss: 0.0000 | lr: 3.4213e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3215/  8460 | global iter:   3215/  8460 | loss: 0.6291 | ds_loss: 0.0000 | lr: 3.4205e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3216/  8460 | global iter:   3216/  8460 | loss: 0.1309 | ds_loss: 0.0000 | lr: 3.4196e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3216/  8460 | global iter:   3216/  8460 | loss: 0.3616 | ds_loss: 0.0000 | lr: 3.4196e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3217/  8460 | global iter:   3217/  8460 | loss: 0.3891 | ds_loss: 0.0000 | lr: 3.4187e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3218/  8460 | global iter:   3218/  8460 | loss: 0.2201 | ds_loss: 0.0000 | lr: 3.4179e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3219/  8460 | global iter:   3219/  8460 | loss: 0.2015 | ds_loss: 0.0000 | lr: 3.4170e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3220/  8460 | global iter:   3220/  8460 | loss: 0.3921 | ds_loss: 0.0000 | lr: 3.4161e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3220/  8460 | global iter:   3220/  8460 | loss: 0.3007 | ds_loss: 0.0000 | lr: 3.4161e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3221/  8460 | global iter:   3221/  8460 | loss: 0.1932 | ds_loss: 0.0000 | lr: 3.4153e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3222/  8460 | global iter:   3222/  8460 | loss: 0.2301 | ds_loss: 0.0000 | lr: 3.4144e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3223/  8460 | global iter:   3223/  8460 | loss: 0.1212 | ds_loss: 0.0000 | lr: 3.4135e-04 | scale:     1.0000 | micro time: 0.438 | step time: 0.000
train | epoch   3 | Iter:   3224/  8460 | global iter:   3224/  8460 | loss: 0.5382 | ds_loss: 0.0000 | lr: 3.4127e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3224/  8460 | global iter:   3224/  8460 | loss: 0.2707 | ds_loss: 0.0000 | lr: 3.4127e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.431
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3225/  8460 | global iter:   3225/  8460 | loss: 0.3631 | ds_loss: 0.0000 | lr: 3.4118e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3226/  8460 | global iter:   3226/  8460 | loss: 0.4075 | ds_loss: 0.0000 | lr: 3.4110e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3227/  8460 | global iter:   3227/  8460 | loss: 0.5369 | ds_loss: 0.0000 | lr: 3.4101e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3228/  8460 | global iter:   3228/  8460 | loss: 0.7239 | ds_loss: 0.0000 | lr: 3.4092e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3228/  8460 | global iter:   3228/  8460 | loss: 0.5079 | ds_loss: 0.0000 | lr: 3.4092e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3229/  8460 | global iter:   3229/  8460 | loss: 0.2940 | ds_loss: 0.0000 | lr: 3.4084e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3230/  8460 | global iter:   3230/  8460 | loss: 0.2749 | ds_loss: 0.0000 | lr: 3.4075e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3231/  8460 | global iter:   3231/  8460 | loss: 0.3505 | ds_loss: 0.0000 | lr: 3.4066e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3232/  8460 | global iter:   3232/  8460 | loss: 0.1141 | ds_loss: 0.0000 | lr: 3.4058e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3232/  8460 | global iter:   3232/  8460 | loss: 0.2584 | ds_loss: 0.0000 | lr: 3.4058e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3233/  8460 | global iter:   3233/  8460 | loss: 0.4450 | ds_loss: 0.0000 | lr: 3.4049e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3234/  8460 | global iter:   3234/  8460 | loss: 0.4194 | ds_loss: 0.0000 | lr: 3.4040e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3235/  8460 | global iter:   3235/  8460 | loss: 0.8035 | ds_loss: 0.0000 | lr: 3.4032e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3236/  8460 | global iter:   3236/  8460 | loss: 0.3541 | ds_loss: 0.0000 | lr: 3.4023e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3236/  8460 | global iter:   3236/  8460 | loss: 0.5055 | ds_loss: 0.0000 | lr: 3.4023e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3237/  8460 | global iter:   3237/  8460 | loss: 0.3372 | ds_loss: 0.0000 | lr: 3.4014e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3238/  8460 | global iter:   3238/  8460 | loss: 0.4223 | ds_loss: 0.0000 | lr: 3.4006e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3239/  8460 | global iter:   3239/  8460 | loss: 0.1240 | ds_loss: 0.0000 | lr: 3.3997e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3240/  8460 | global iter:   3240/  8460 | loss: 0.4710 | ds_loss: 0.0000 | lr: 3.3988e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3240/  8460 | global iter:   3240/  8460 | loss: 0.3386 | ds_loss: 0.0000 | lr: 3.3988e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3241/  8460 | global iter:   3241/  8460 | loss: 0.6783 | ds_loss: 0.0000 | lr: 3.3980e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3242/  8460 | global iter:   3242/  8460 | loss: 0.3053 | ds_loss: 0.0000 | lr: 3.3971e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3243/  8460 | global iter:   3243/  8460 | loss: 0.2713 | ds_loss: 0.0000 | lr: 3.3962e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3244/  8460 | global iter:   3244/  8460 | loss: 0.1366 | ds_loss: 0.0000 | lr: 3.3954e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3244/  8460 | global iter:   3244/  8460 | loss: 0.3479 | ds_loss: 0.0000 | lr: 3.3954e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3245/  8460 | global iter:   3245/  8460 | loss: 0.2024 | ds_loss: 0.0000 | lr: 3.3945e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3246/  8460 | global iter:   3246/  8460 | loss: 0.5156 | ds_loss: 0.0000 | lr: 3.3936e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3247/  8460 | global iter:   3247/  8460 | loss: 0.8266 | ds_loss: 0.0000 | lr: 3.3928e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3248/  8460 | global iter:   3248/  8460 | loss: 0.6243 | ds_loss: 0.0000 | lr: 3.3919e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3248/  8460 | global iter:   3248/  8460 | loss: 0.5422 | ds_loss: 0.0000 | lr: 3.3919e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3249/  8460 | global iter:   3249/  8460 | loss: 0.8939 | ds_loss: 0.0000 | lr: 3.3910e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3250/  8460 | global iter:   3250/  8460 | loss: 0.7322 | ds_loss: 0.0000 | lr: 3.3902e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3251/  8460 | global iter:   3251/  8460 | loss: 1.6058 | ds_loss: 0.0000 | lr: 3.3893e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3252/  8460 | global iter:   3252/  8460 | loss: 0.4465 | ds_loss: 0.0000 | lr: 3.3884e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3252/  8460 | global iter:   3252/  8460 | loss: 0.9196 | ds_loss: 0.0000 | lr: 3.3884e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3253/  8460 | global iter:   3253/  8460 | loss: 0.2333 | ds_loss: 0.0000 | lr: 3.3876e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3254/  8460 | global iter:   3254/  8460 | loss: 0.1469 | ds_loss: 0.0000 | lr: 3.3867e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3255/  8460 | global iter:   3255/  8460 | loss: 0.6963 | ds_loss: 0.0000 | lr: 3.3858e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3256/  8460 | global iter:   3256/  8460 | loss: 0.4946 | ds_loss: 0.0000 | lr: 3.3850e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3256/  8460 | global iter:   3256/  8460 | loss: 0.3928 | ds_loss: 0.0000 | lr: 3.3850e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3257/  8460 | global iter:   3257/  8460 | loss: 0.7277 | ds_loss: 0.0000 | lr: 3.3841e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3258/  8460 | global iter:   3258/  8460 | loss: 0.2895 | ds_loss: 0.0000 | lr: 3.3832e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3259/  8460 | global iter:   3259/  8460 | loss: 0.2009 | ds_loss: 0.0000 | lr: 3.3824e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3260/  8460 | global iter:   3260/  8460 | loss: 0.2524 | ds_loss: 0.0000 | lr: 3.3815e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3260/  8460 | global iter:   3260/  8460 | loss: 0.3676 | ds_loss: 0.0000 | lr: 3.3815e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3261/  8460 | global iter:   3261/  8460 | loss: 0.2251 | ds_loss: 0.0000 | lr: 3.3806e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3262/  8460 | global iter:   3262/  8460 | loss: 0.0723 | ds_loss: 0.0000 | lr: 3.3798e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3263/  8460 | global iter:   3263/  8460 | loss: 0.1941 | ds_loss: 0.0000 | lr: 3.3789e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3264/  8460 | global iter:   3264/  8460 | loss: 0.6074 | ds_loss: 0.0000 | lr: 3.3780e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3264/  8460 | global iter:   3264/  8460 | loss: 0.2747 | ds_loss: 0.0000 | lr: 3.3780e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3265/  8460 | global iter:   3265/  8460 | loss: 0.1317 | ds_loss: 0.0000 | lr: 3.3771e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3266/  8460 | global iter:   3266/  8460 | loss: 0.2549 | ds_loss: 0.0000 | lr: 3.3763e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3267/  8460 | global iter:   3267/  8460 | loss: 0.7972 | ds_loss: 0.0000 | lr: 3.3754e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3268/  8460 | global iter:   3268/  8460 | loss: 0.3045 | ds_loss: 0.0000 | lr: 3.3745e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3268/  8460 | global iter:   3268/  8460 | loss: 0.3721 | ds_loss: 0.0000 | lr: 3.3745e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3269/  8460 | global iter:   3269/  8460 | loss: 0.1384 | ds_loss: 0.0000 | lr: 3.3737e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3270/  8460 | global iter:   3270/  8460 | loss: 0.8947 | ds_loss: 0.0000 | lr: 3.3728e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3271/  8460 | global iter:   3271/  8460 | loss: 0.1183 | ds_loss: 0.0000 | lr: 3.3719e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3272/  8460 | global iter:   3272/  8460 | loss: 0.1930 | ds_loss: 0.0000 | lr: 3.3711e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3272/  8460 | global iter:   3272/  8460 | loss: 0.3361 | ds_loss: 0.0000 | lr: 3.3711e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3273/  8460 | global iter:   3273/  8460 | loss: 0.2514 | ds_loss: 0.0000 | lr: 3.3702e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3274/  8460 | global iter:   3274/  8460 | loss: 0.2031 | ds_loss: 0.0000 | lr: 3.3693e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3275/  8460 | global iter:   3275/  8460 | loss: 0.4113 | ds_loss: 0.0000 | lr: 3.3684e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3276/  8460 | global iter:   3276/  8460 | loss: 0.1653 | ds_loss: 0.0000 | lr: 3.3676e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3276/  8460 | global iter:   3276/  8460 | loss: 0.2577 | ds_loss: 0.0000 | lr: 3.3676e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3277/  8460 | global iter:   3277/  8460 | loss: 0.2356 | ds_loss: 0.0000 | lr: 3.3667e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3278/  8460 | global iter:   3278/  8460 | loss: 0.8367 | ds_loss: 0.0000 | lr: 3.3658e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3279/  8460 | global iter:   3279/  8460 | loss: 0.2520 | ds_loss: 0.0000 | lr: 3.3650e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3280/  8460 | global iter:   3280/  8460 | loss: 0.1239 | ds_loss: 0.0000 | lr: 3.3641e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3280/  8460 | global iter:   3280/  8460 | loss: 0.3621 | ds_loss: 0.0000 | lr: 3.3641e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3281/  8460 | global iter:   3281/  8460 | loss: 0.4601 | ds_loss: 0.0000 | lr: 3.3632e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3282/  8460 | global iter:   3282/  8460 | loss: 0.4639 | ds_loss: 0.0000 | lr: 3.3624e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3283/  8460 | global iter:   3283/  8460 | loss: 0.3414 | ds_loss: 0.0000 | lr: 3.3615e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3284/  8460 | global iter:   3284/  8460 | loss: 0.5085 | ds_loss: 0.0000 | lr: 3.3606e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3284/  8460 | global iter:   3284/  8460 | loss: 0.4435 | ds_loss: 0.0000 | lr: 3.3606e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3285/  8460 | global iter:   3285/  8460 | loss: 0.3646 | ds_loss: 0.0000 | lr: 3.3597e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3286/  8460 | global iter:   3286/  8460 | loss: 0.1484 | ds_loss: 0.0000 | lr: 3.3589e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3287/  8460 | global iter:   3287/  8460 | loss: 0.6128 | ds_loss: 0.0000 | lr: 3.3580e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3288/  8460 | global iter:   3288/  8460 | loss: 0.1748 | ds_loss: 0.0000 | lr: 3.3571e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3288/  8460 | global iter:   3288/  8460 | loss: 0.3252 | ds_loss: 0.0000 | lr: 3.3571e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3289/  8460 | global iter:   3289/  8460 | loss: 0.7975 | ds_loss: 0.0000 | lr: 3.3563e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3290/  8460 | global iter:   3290/  8460 | loss: 0.5487 | ds_loss: 0.0000 | lr: 3.3554e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3291/  8460 | global iter:   3291/  8460 | loss: 0.5094 | ds_loss: 0.0000 | lr: 3.3545e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3292/  8460 | global iter:   3292/  8460 | loss: 0.4012 | ds_loss: 0.0000 | lr: 3.3536e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3292/  8460 | global iter:   3292/  8460 | loss: 0.5642 | ds_loss: 0.0000 | lr: 3.3536e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3293/  8460 | global iter:   3293/  8460 | loss: 0.6088 | ds_loss: 0.0000 | lr: 3.3528e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3294/  8460 | global iter:   3294/  8460 | loss: 0.4585 | ds_loss: 0.0000 | lr: 3.3519e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3295/  8460 | global iter:   3295/  8460 | loss: 1.0641 | ds_loss: 0.0000 | lr: 3.3510e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3296/  8460 | global iter:   3296/  8460 | loss: 0.3195 | ds_loss: 0.0000 | lr: 3.3501e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3296/  8460 | global iter:   3296/  8460 | loss: 0.6127 | ds_loss: 0.0000 | lr: 3.3501e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3297/  8460 | global iter:   3297/  8460 | loss: 0.0611 | ds_loss: 0.0000 | lr: 3.3493e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3298/  8460 | global iter:   3298/  8460 | loss: 0.8322 | ds_loss: 0.0000 | lr: 3.3484e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3299/  8460 | global iter:   3299/  8460 | loss: 0.6897 | ds_loss: 0.0000 | lr: 3.3475e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3300/  8460 | global iter:   3300/  8460 | loss: 0.2344 | ds_loss: 0.0000 | lr: 3.3467e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3300/  8460 | global iter:   3300/  8460 | loss: 0.4543 | ds_loss: 0.0000 | lr: 3.3467e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3301/  8460 | global iter:   3301/  8460 | loss: 0.3923 | ds_loss: 0.0000 | lr: 3.3458e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3302/  8460 | global iter:   3302/  8460 | loss: 0.5135 | ds_loss: 0.0000 | lr: 3.3449e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3303/  8460 | global iter:   3303/  8460 | loss: 0.3467 | ds_loss: 0.0000 | lr: 3.3440e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3304/  8460 | global iter:   3304/  8460 | loss: 0.3165 | ds_loss: 0.0000 | lr: 3.3432e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3304/  8460 | global iter:   3304/  8460 | loss: 0.3922 | ds_loss: 0.0000 | lr: 3.3432e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3305/  8460 | global iter:   3305/  8460 | loss: 0.8315 | ds_loss: 0.0000 | lr: 3.3423e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3306/  8460 | global iter:   3306/  8460 | loss: 0.4631 | ds_loss: 0.0000 | lr: 3.3414e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3307/  8460 | global iter:   3307/  8460 | loss: 0.3340 | ds_loss: 0.0000 | lr: 3.3405e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3308/  8460 | global iter:   3308/  8460 | loss: 0.0716 | ds_loss: 0.0000 | lr: 3.3397e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3308/  8460 | global iter:   3308/  8460 | loss: 0.4251 | ds_loss: 0.0000 | lr: 3.3397e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3309/  8460 | global iter:   3309/  8460 | loss: 0.5611 | ds_loss: 0.0000 | lr: 3.3388e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3310/  8460 | global iter:   3310/  8460 | loss: 0.7094 | ds_loss: 0.0000 | lr: 3.3379e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3311/  8460 | global iter:   3311/  8460 | loss: 0.1903 | ds_loss: 0.0000 | lr: 3.3370e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3312/  8460 | global iter:   3312/  8460 | loss: 1.4816 | ds_loss: 0.0000 | lr: 3.3362e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3312/  8460 | global iter:   3312/  8460 | loss: 0.7356 | ds_loss: 0.0000 | lr: 3.3362e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3313/  8460 | global iter:   3313/  8460 | loss: 0.3451 | ds_loss: 0.0000 | lr: 3.3353e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3314/  8460 | global iter:   3314/  8460 | loss: 0.3327 | ds_loss: 0.0000 | lr: 3.3344e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3315/  8460 | global iter:   3315/  8460 | loss: 0.4096 | ds_loss: 0.0000 | lr: 3.3335e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3316/  8460 | global iter:   3316/  8460 | loss: 0.5042 | ds_loss: 0.0000 | lr: 3.3327e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3316/  8460 | global iter:   3316/  8460 | loss: 0.3979 | ds_loss: 0.0000 | lr: 3.3327e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3317/  8460 | global iter:   3317/  8460 | loss: 0.4005 | ds_loss: 0.0000 | lr: 3.3318e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3318/  8460 | global iter:   3318/  8460 | loss: 0.3076 | ds_loss: 0.0000 | lr: 3.3309e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3319/  8460 | global iter:   3319/  8460 | loss: 0.6384 | ds_loss: 0.0000 | lr: 3.3300e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3320/  8460 | global iter:   3320/  8460 | loss: 0.4349 | ds_loss: 0.0000 | lr: 3.3292e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3320/  8460 | global iter:   3320/  8460 | loss: 0.4453 | ds_loss: 0.0000 | lr: 3.3292e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3321/  8460 | global iter:   3321/  8460 | loss: 0.1250 | ds_loss: 0.0000 | lr: 3.3283e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3322/  8460 | global iter:   3322/  8460 | loss: 0.5908 | ds_loss: 0.0000 | lr: 3.3274e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3323/  8460 | global iter:   3323/  8460 | loss: 0.4615 | ds_loss: 0.0000 | lr: 3.3265e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3324/  8460 | global iter:   3324/  8460 | loss: 0.3499 | ds_loss: 0.0000 | lr: 3.3257e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3324/  8460 | global iter:   3324/  8460 | loss: 0.3818 | ds_loss: 0.0000 | lr: 3.3257e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3325/  8460 | global iter:   3325/  8460 | loss: 0.7230 | ds_loss: 0.0000 | lr: 3.3248e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3326/  8460 | global iter:   3326/  8460 | loss: 0.3759 | ds_loss: 0.0000 | lr: 3.3239e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3327/  8460 | global iter:   3327/  8460 | loss: 0.1154 | ds_loss: 0.0000 | lr: 3.3230e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3328/  8460 | global iter:   3328/  8460 | loss: 0.3631 | ds_loss: 0.0000 | lr: 3.3222e-04 | scale:     1.0000 | micro time: 0.437 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3328/  8460 | global iter:   3328/  8460 | loss: 0.3944 | ds_loss: 0.0000 | lr: 3.3222e-04 | scale:     1.0000 | micro time: 0.437 | step time: 0.430
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3329/  8460 | global iter:   3329/  8460 | loss: 0.4151 | ds_loss: 0.0000 | lr: 3.3213e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3330/  8460 | global iter:   3330/  8460 | loss: 0.1793 | ds_loss: 0.0000 | lr: 3.3204e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3331/  8460 | global iter:   3331/  8460 | loss: 0.3323 | ds_loss: 0.0000 | lr: 3.3195e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3332/  8460 | global iter:   3332/  8460 | loss: 0.3008 | ds_loss: 0.0000 | lr: 3.3186e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3332/  8460 | global iter:   3332/  8460 | loss: 0.3069 | ds_loss: 0.0000 | lr: 3.3186e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3333/  8460 | global iter:   3333/  8460 | loss: 0.2511 | ds_loss: 0.0000 | lr: 3.3178e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.000
train | epoch   3 | Iter:   3334/  8460 | global iter:   3334/  8460 | loss: 0.4522 | ds_loss: 0.0000 | lr: 3.3169e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.000
train | epoch   3 | Iter:   3335/  8460 | global iter:   3335/  8460 | loss: 0.0998 | ds_loss: 0.0000 | lr: 3.3160e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3336/  8460 | global iter:   3336/  8460 | loss: 0.2523 | ds_loss: 0.0000 | lr: 3.3151e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3336/  8460 | global iter:   3336/  8460 | loss: 0.2638 | ds_loss: 0.0000 | lr: 3.3151e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3337/  8460 | global iter:   3337/  8460 | loss: 0.2977 | ds_loss: 0.0000 | lr: 3.3143e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3338/  8460 | global iter:   3338/  8460 | loss: 0.3152 | ds_loss: 0.0000 | lr: 3.3134e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3339/  8460 | global iter:   3339/  8460 | loss: 0.3183 | ds_loss: 0.0000 | lr: 3.3125e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3340/  8460 | global iter:   3340/  8460 | loss: 0.2024 | ds_loss: 0.0000 | lr: 3.3116e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3340/  8460 | global iter:   3340/  8460 | loss: 0.2834 | ds_loss: 0.0000 | lr: 3.3116e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3341/  8460 | global iter:   3341/  8460 | loss: 0.1682 | ds_loss: 0.0000 | lr: 3.3107e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3342/  8460 | global iter:   3342/  8460 | loss: 1.0770 | ds_loss: 0.0000 | lr: 3.3099e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3343/  8460 | global iter:   3343/  8460 | loss: 0.4797 | ds_loss: 0.0000 | lr: 3.3090e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3344/  8460 | global iter:   3344/  8460 | loss: 0.2912 | ds_loss: 0.0000 | lr: 3.3081e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3344/  8460 | global iter:   3344/  8460 | loss: 0.5040 | ds_loss: 0.0000 | lr: 3.3081e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3345/  8460 | global iter:   3345/  8460 | loss: 0.8471 | ds_loss: 0.0000 | lr: 3.3072e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3346/  8460 | global iter:   3346/  8460 | loss: 0.8339 | ds_loss: 0.0000 | lr: 3.3064e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3347/  8460 | global iter:   3347/  8460 | loss: 0.5373 | ds_loss: 0.0000 | lr: 3.3055e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3348/  8460 | global iter:   3348/  8460 | loss: 0.5145 | ds_loss: 0.0000 | lr: 3.3046e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3348/  8460 | global iter:   3348/  8460 | loss: 0.6832 | ds_loss: 0.0000 | lr: 3.3046e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3349/  8460 | global iter:   3349/  8460 | loss: 0.4519 | ds_loss: 0.0000 | lr: 3.3037e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3350/  8460 | global iter:   3350/  8460 | loss: 0.8860 | ds_loss: 0.0000 | lr: 3.3028e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3351/  8460 | global iter:   3351/  8460 | loss: 0.3148 | ds_loss: 0.0000 | lr: 3.3020e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3352/  8460 | global iter:   3352/  8460 | loss: 0.3235 | ds_loss: 0.0000 | lr: 3.3011e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3352/  8460 | global iter:   3352/  8460 | loss: 0.4941 | ds_loss: 0.0000 | lr: 3.3011e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3353/  8460 | global iter:   3353/  8460 | loss: 0.2499 | ds_loss: 0.0000 | lr: 3.3002e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3354/  8460 | global iter:   3354/  8460 | loss: 0.5268 | ds_loss: 0.0000 | lr: 3.2993e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3355/  8460 | global iter:   3355/  8460 | loss: 0.6887 | ds_loss: 0.0000 | lr: 3.2984e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3356/  8460 | global iter:   3356/  8460 | loss: 0.1004 | ds_loss: 0.0000 | lr: 3.2976e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3356/  8460 | global iter:   3356/  8460 | loss: 0.3914 | ds_loss: 0.0000 | lr: 3.2976e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3357/  8460 | global iter:   3357/  8460 | loss: 0.3210 | ds_loss: 0.0000 | lr: 3.2967e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3358/  8460 | global iter:   3358/  8460 | loss: 0.1714 | ds_loss: 0.0000 | lr: 3.2958e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3359/  8460 | global iter:   3359/  8460 | loss: 0.2249 | ds_loss: 0.0000 | lr: 3.2949e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3360/  8460 | global iter:   3360/  8460 | loss: 0.2480 | ds_loss: 0.0000 | lr: 3.2940e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3360/  8460 | global iter:   3360/  8460 | loss: 0.2413 | ds_loss: 0.0000 | lr: 3.2940e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3361/  8460 | global iter:   3361/  8460 | loss: 0.3175 | ds_loss: 0.0000 | lr: 3.2932e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3362/  8460 | global iter:   3362/  8460 | loss: 0.3968 | ds_loss: 0.0000 | lr: 3.2923e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3363/  8460 | global iter:   3363/  8460 | loss: 0.8066 | ds_loss: 0.0000 | lr: 3.2914e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3364/  8460 | global iter:   3364/  8460 | loss: 0.2123 | ds_loss: 0.0000 | lr: 3.2905e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3364/  8460 | global iter:   3364/  8460 | loss: 0.4333 | ds_loss: 0.0000 | lr: 3.2905e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3365/  8460 | global iter:   3365/  8460 | loss: 0.5984 | ds_loss: 0.0000 | lr: 3.2896e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3366/  8460 | global iter:   3366/  8460 | loss: 0.3907 | ds_loss: 0.0000 | lr: 3.2888e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3367/  8460 | global iter:   3367/  8460 | loss: 0.4570 | ds_loss: 0.0000 | lr: 3.2879e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3368/  8460 | global iter:   3368/  8460 | loss: 0.1013 | ds_loss: 0.0000 | lr: 3.2870e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3368/  8460 | global iter:   3368/  8460 | loss: 0.3868 | ds_loss: 0.0000 | lr: 3.2870e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3369/  8460 | global iter:   3369/  8460 | loss: 0.6804 | ds_loss: 0.0000 | lr: 3.2861e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3370/  8460 | global iter:   3370/  8460 | loss: 0.4802 | ds_loss: 0.0000 | lr: 3.2852e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3371/  8460 | global iter:   3371/  8460 | loss: 0.2012 | ds_loss: 0.0000 | lr: 3.2844e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3372/  8460 | global iter:   3372/  8460 | loss: 0.2968 | ds_loss: 0.0000 | lr: 3.2835e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3372/  8460 | global iter:   3372/  8460 | loss: 0.4146 | ds_loss: 0.0000 | lr: 3.2835e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3373/  8460 | global iter:   3373/  8460 | loss: 0.6262 | ds_loss: 0.0000 | lr: 3.2826e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3374/  8460 | global iter:   3374/  8460 | loss: 0.3502 | ds_loss: 0.0000 | lr: 3.2817e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3375/  8460 | global iter:   3375/  8460 | loss: 0.5023 | ds_loss: 0.0000 | lr: 3.2808e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   3 | Iter:   3376/  8460 | global iter:   3376/  8460 | loss: 0.4408 | ds_loss: 0.0000 | lr: 3.2799e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3376/  8460 | global iter:   3376/  8460 | loss: 0.4799 | ds_loss: 0.0000 | lr: 3.2799e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3377/  8460 | global iter:   3377/  8460 | loss: 0.6738 | ds_loss: 0.0000 | lr: 3.2791e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3378/  8460 | global iter:   3378/  8460 | loss: 0.6253 | ds_loss: 0.0000 | lr: 3.2782e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3379/  8460 | global iter:   3379/  8460 | loss: 0.7480 | ds_loss: 0.0000 | lr: 3.2773e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3380/  8460 | global iter:   3380/  8460 | loss: 0.1962 | ds_loss: 0.0000 | lr: 3.2764e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3380/  8460 | global iter:   3380/  8460 | loss: 0.5608 | ds_loss: 0.0000 | lr: 3.2764e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3381/  8460 | global iter:   3381/  8460 | loss: 0.2178 | ds_loss: 0.0000 | lr: 3.2755e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3382/  8460 | global iter:   3382/  8460 | loss: 0.1760 | ds_loss: 0.0000 | lr: 3.2747e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3383/  8460 | global iter:   3383/  8460 | loss: 0.4407 | ds_loss: 0.0000 | lr: 3.2738e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3384/  8460 | global iter:   3384/  8460 | loss: 0.2587 | ds_loss: 0.0000 | lr: 3.2729e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3384/  8460 | global iter:   3384/  8460 | loss: 0.2733 | ds_loss: 0.0000 | lr: 3.2729e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   3 | Iter:   3385/  8460 | global iter:   3385/  8460 | loss: 0.4930 | ds_loss: 0.0000 | lr: 3.2720e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3386/  8460 | global iter:   3386/  8460 | loss: 0.3863 | ds_loss: 0.0000 | lr: 3.2711e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   3 | Iter:   3387/  8460 | global iter:   3387/  8460 | loss: 0.3282 | ds_loss: 0.0000 | lr: 3.2702e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   3 | Iter:   3388/  8460 | global iter:   3388/  8460 | loss: 0.0771 | ds_loss: 0.0000 | lr: 3.2694e-04 | scale:     1.0000 | micro time: 0.366 | step time: 0.000
****************************************************************************************************
train | epoch   3 | Iter:   3388/  8460 | global iter:   3388/  8460 | loss: 0.3211 | ds_loss: 0.0000 | lr: 3.2694e-04 | scale:     1.0000 | micro time: 0.366 | step time: 0.412
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
Sun Apr  6 21:13:48 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla P100-PCIE-12GB           Off |   00000000:81:00.0 Off |                    0 |
| N/A   51C    P0             39W /  250W |    8807MiB /  12288MiB |     97%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A    244677      C   ...project_distillLLM/venv/bin/python3       8804MiB |
+-----------------------------------------------------------------------------------------+

train | epoch   4 | Iter:   3389/  8460 | global iter:   3389/  8460 | loss: 0.6497 | ds_loss: 0.0000 | lr: 3.2685e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3390/  8460 | global iter:   3390/  8460 | loss: 0.1168 | ds_loss: 0.0000 | lr: 3.2676e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3391/  8460 | global iter:   3391/  8460 | loss: 0.1497 | ds_loss: 0.0000 | lr: 3.2667e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3392/  8460 | global iter:   3392/  8460 | loss: 0.0878 | ds_loss: 0.0000 | lr: 3.2658e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3392/  8460 | global iter:   3392/  8460 | loss: 0.2510 | ds_loss: 0.0000 | lr: 3.2658e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3393/  8460 | global iter:   3393/  8460 | loss: 0.6056 | ds_loss: 0.0000 | lr: 3.2649e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3394/  8460 | global iter:   3394/  8460 | loss: 0.1508 | ds_loss: 0.0000 | lr: 3.2641e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3395/  8460 | global iter:   3395/  8460 | loss: 0.3934 | ds_loss: 0.0000 | lr: 3.2632e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3396/  8460 | global iter:   3396/  8460 | loss: 0.1930 | ds_loss: 0.0000 | lr: 3.2623e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3396/  8460 | global iter:   3396/  8460 | loss: 0.3357 | ds_loss: 0.0000 | lr: 3.2623e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3397/  8460 | global iter:   3397/  8460 | loss: 0.4573 | ds_loss: 0.0000 | lr: 3.2614e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3398/  8460 | global iter:   3398/  8460 | loss: 0.2760 | ds_loss: 0.0000 | lr: 3.2605e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3399/  8460 | global iter:   3399/  8460 | loss: 0.6960 | ds_loss: 0.0000 | lr: 3.2596e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3400/  8460 | global iter:   3400/  8460 | loss: 0.7127 | ds_loss: 0.0000 | lr: 3.2588e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3400/  8460 | global iter:   3400/  8460 | loss: 0.5355 | ds_loss: 0.0000 | lr: 3.2588e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3401/  8460 | global iter:   3401/  8460 | loss: 0.1682 | ds_loss: 0.0000 | lr: 3.2579e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3402/  8460 | global iter:   3402/  8460 | loss: 0.4160 | ds_loss: 0.0000 | lr: 3.2570e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3403/  8460 | global iter:   3403/  8460 | loss: 0.1407 | ds_loss: 0.0000 | lr: 3.2561e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3404/  8460 | global iter:   3404/  8460 | loss: 0.1263 | ds_loss: 0.0000 | lr: 3.2552e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3404/  8460 | global iter:   3404/  8460 | loss: 0.2128 | ds_loss: 0.0000 | lr: 3.2552e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3405/  8460 | global iter:   3405/  8460 | loss: 0.0416 | ds_loss: 0.0000 | lr: 3.2543e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3406/  8460 | global iter:   3406/  8460 | loss: 0.2562 | ds_loss: 0.0000 | lr: 3.2534e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3407/  8460 | global iter:   3407/  8460 | loss: 0.3221 | ds_loss: 0.0000 | lr: 3.2526e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3408/  8460 | global iter:   3408/  8460 | loss: 0.2455 | ds_loss: 0.0000 | lr: 3.2517e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3408/  8460 | global iter:   3408/  8460 | loss: 0.2163 | ds_loss: 0.0000 | lr: 3.2517e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3409/  8460 | global iter:   3409/  8460 | loss: 0.2925 | ds_loss: 0.0000 | lr: 3.2508e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3410/  8460 | global iter:   3410/  8460 | loss: 0.3467 | ds_loss: 0.0000 | lr: 3.2499e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3411/  8460 | global iter:   3411/  8460 | loss: 0.2313 | ds_loss: 0.0000 | lr: 3.2490e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3412/  8460 | global iter:   3412/  8460 | loss: 0.1305 | ds_loss: 0.0000 | lr: 3.2481e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3412/  8460 | global iter:   3412/  8460 | loss: 0.2502 | ds_loss: 0.0000 | lr: 3.2481e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3413/  8460 | global iter:   3413/  8460 | loss: 0.2369 | ds_loss: 0.0000 | lr: 3.2472e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3414/  8460 | global iter:   3414/  8460 | loss: 0.1758 | ds_loss: 0.0000 | lr: 3.2464e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3415/  8460 | global iter:   3415/  8460 | loss: 0.4837 | ds_loss: 0.0000 | lr: 3.2455e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3416/  8460 | global iter:   3416/  8460 | loss: 0.1467 | ds_loss: 0.0000 | lr: 3.2446e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3416/  8460 | global iter:   3416/  8460 | loss: 0.2608 | ds_loss: 0.0000 | lr: 3.2446e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3417/  8460 | global iter:   3417/  8460 | loss: 0.3237 | ds_loss: 0.0000 | lr: 3.2437e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3418/  8460 | global iter:   3418/  8460 | loss: 0.3343 | ds_loss: 0.0000 | lr: 3.2428e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3419/  8460 | global iter:   3419/  8460 | loss: 0.1767 | ds_loss: 0.0000 | lr: 3.2419e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3420/  8460 | global iter:   3420/  8460 | loss: 0.3615 | ds_loss: 0.0000 | lr: 3.2410e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3420/  8460 | global iter:   3420/  8460 | loss: 0.2990 | ds_loss: 0.0000 | lr: 3.2410e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3421/  8460 | global iter:   3421/  8460 | loss: 0.2477 | ds_loss: 0.0000 | lr: 3.2402e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3422/  8460 | global iter:   3422/  8460 | loss: 0.3370 | ds_loss: 0.0000 | lr: 3.2393e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3423/  8460 | global iter:   3423/  8460 | loss: 0.2472 | ds_loss: 0.0000 | lr: 3.2384e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3424/  8460 | global iter:   3424/  8460 | loss: 0.1671 | ds_loss: 0.0000 | lr: 3.2375e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3424/  8460 | global iter:   3424/  8460 | loss: 0.2498 | ds_loss: 0.0000 | lr: 3.2375e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3425/  8460 | global iter:   3425/  8460 | loss: 0.1625 | ds_loss: 0.0000 | lr: 3.2366e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3426/  8460 | global iter:   3426/  8460 | loss: 0.2352 | ds_loss: 0.0000 | lr: 3.2357e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3427/  8460 | global iter:   3427/  8460 | loss: 0.2924 | ds_loss: 0.0000 | lr: 3.2348e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3428/  8460 | global iter:   3428/  8460 | loss: 0.7908 | ds_loss: 0.0000 | lr: 3.2339e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3428/  8460 | global iter:   3428/  8460 | loss: 0.3702 | ds_loss: 0.0000 | lr: 3.2339e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3429/  8460 | global iter:   3429/  8460 | loss: 0.4418 | ds_loss: 0.0000 | lr: 3.2331e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3430/  8460 | global iter:   3430/  8460 | loss: 0.4888 | ds_loss: 0.0000 | lr: 3.2322e-04 | scale:     1.0000 | micro time: 0.439 | step time: 0.000
train | epoch   4 | Iter:   3431/  8460 | global iter:   3431/  8460 | loss: 0.2412 | ds_loss: 0.0000 | lr: 3.2313e-04 | scale:     1.0000 | micro time: 0.437 | step time: 0.000
train | epoch   4 | Iter:   3432/  8460 | global iter:   3432/  8460 | loss: 0.1556 | ds_loss: 0.0000 | lr: 3.2304e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3432/  8460 | global iter:   3432/  8460 | loss: 0.3318 | ds_loss: 0.0000 | lr: 3.2304e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.434
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3433/  8460 | global iter:   3433/  8460 | loss: 0.3103 | ds_loss: 0.0000 | lr: 3.2295e-04 | scale:     1.0000 | micro time: 0.434 | step time: 0.000
train | epoch   4 | Iter:   3434/  8460 | global iter:   3434/  8460 | loss: 0.1198 | ds_loss: 0.0000 | lr: 3.2286e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3435/  8460 | global iter:   3435/  8460 | loss: 0.0918 | ds_loss: 0.0000 | lr: 3.2277e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3436/  8460 | global iter:   3436/  8460 | loss: 0.4155 | ds_loss: 0.0000 | lr: 3.2268e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3436/  8460 | global iter:   3436/  8460 | loss: 0.2344 | ds_loss: 0.0000 | lr: 3.2268e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3437/  8460 | global iter:   3437/  8460 | loss: 0.1454 | ds_loss: 0.0000 | lr: 3.2260e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3438/  8460 | global iter:   3438/  8460 | loss: 0.1876 | ds_loss: 0.0000 | lr: 3.2251e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3439/  8460 | global iter:   3439/  8460 | loss: 0.1225 | ds_loss: 0.0000 | lr: 3.2242e-04 | scale:     1.0000 | micro time: 0.437 | step time: 0.000
train | epoch   4 | Iter:   3440/  8460 | global iter:   3440/  8460 | loss: 0.0890 | ds_loss: 0.0000 | lr: 3.2233e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3440/  8460 | global iter:   3440/  8460 | loss: 0.1361 | ds_loss: 0.0000 | lr: 3.2233e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.430
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3441/  8460 | global iter:   3441/  8460 | loss: 0.3937 | ds_loss: 0.0000 | lr: 3.2224e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3442/  8460 | global iter:   3442/  8460 | loss: 0.1887 | ds_loss: 0.0000 | lr: 3.2215e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3443/  8460 | global iter:   3443/  8460 | loss: 0.4568 | ds_loss: 0.0000 | lr: 3.2206e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3444/  8460 | global iter:   3444/  8460 | loss: 0.3638 | ds_loss: 0.0000 | lr: 3.2197e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3444/  8460 | global iter:   3444/  8460 | loss: 0.3507 | ds_loss: 0.0000 | lr: 3.2197e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3445/  8460 | global iter:   3445/  8460 | loss: 0.7079 | ds_loss: 0.0000 | lr: 3.2188e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3446/  8460 | global iter:   3446/  8460 | loss: 0.8812 | ds_loss: 0.0000 | lr: 3.2180e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3447/  8460 | global iter:   3447/  8460 | loss: 0.1146 | ds_loss: 0.0000 | lr: 3.2171e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3448/  8460 | global iter:   3448/  8460 | loss: 0.1924 | ds_loss: 0.0000 | lr: 3.2162e-04 | scale:     1.0000 | micro time: 0.438 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3448/  8460 | global iter:   3448/  8460 | loss: 0.4740 | ds_loss: 0.0000 | lr: 3.2162e-04 | scale:     1.0000 | micro time: 0.438 | step time: 0.430
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3449/  8460 | global iter:   3449/  8460 | loss: 0.3578 | ds_loss: 0.0000 | lr: 3.2153e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3450/  8460 | global iter:   3450/  8460 | loss: 0.1395 | ds_loss: 0.0000 | lr: 3.2144e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3451/  8460 | global iter:   3451/  8460 | loss: 0.3023 | ds_loss: 0.0000 | lr: 3.2135e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3452/  8460 | global iter:   3452/  8460 | loss: 0.2516 | ds_loss: 0.0000 | lr: 3.2126e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3452/  8460 | global iter:   3452/  8460 | loss: 0.2628 | ds_loss: 0.0000 | lr: 3.2126e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3453/  8460 | global iter:   3453/  8460 | loss: 0.3185 | ds_loss: 0.0000 | lr: 3.2117e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3454/  8460 | global iter:   3454/  8460 | loss: 0.0835 | ds_loss: 0.0000 | lr: 3.2108e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3455/  8460 | global iter:   3455/  8460 | loss: 0.1345 | ds_loss: 0.0000 | lr: 3.2100e-04 | scale:     1.0000 | micro time: 0.439 | step time: 0.000
train | epoch   4 | Iter:   3456/  8460 | global iter:   3456/  8460 | loss: 0.7891 | ds_loss: 0.0000 | lr: 3.2091e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3456/  8460 | global iter:   3456/  8460 | loss: 0.3314 | ds_loss: 0.0000 | lr: 3.2091e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.431
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3457/  8460 | global iter:   3457/  8460 | loss: 0.0598 | ds_loss: 0.0000 | lr: 3.2082e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3458/  8460 | global iter:   3458/  8460 | loss: 0.2714 | ds_loss: 0.0000 | lr: 3.2073e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3459/  8460 | global iter:   3459/  8460 | loss: 0.1736 | ds_loss: 0.0000 | lr: 3.2064e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3460/  8460 | global iter:   3460/  8460 | loss: 0.3737 | ds_loss: 0.0000 | lr: 3.2055e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3460/  8460 | global iter:   3460/  8460 | loss: 0.2197 | ds_loss: 0.0000 | lr: 3.2055e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3461/  8460 | global iter:   3461/  8460 | loss: 0.1747 | ds_loss: 0.0000 | lr: 3.2046e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3462/  8460 | global iter:   3462/  8460 | loss: 0.1915 | ds_loss: 0.0000 | lr: 3.2037e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3463/  8460 | global iter:   3463/  8460 | loss: 0.3975 | ds_loss: 0.0000 | lr: 3.2028e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3464/  8460 | global iter:   3464/  8460 | loss: 0.1247 | ds_loss: 0.0000 | lr: 3.2019e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3464/  8460 | global iter:   3464/  8460 | loss: 0.2221 | ds_loss: 0.0000 | lr: 3.2019e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3465/  8460 | global iter:   3465/  8460 | loss: 0.3345 | ds_loss: 0.0000 | lr: 3.2010e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3466/  8460 | global iter:   3466/  8460 | loss: 0.4659 | ds_loss: 0.0000 | lr: 3.2002e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3467/  8460 | global iter:   3467/  8460 | loss: 0.5908 | ds_loss: 0.0000 | lr: 3.1993e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3468/  8460 | global iter:   3468/  8460 | loss: 0.3314 | ds_loss: 0.0000 | lr: 3.1984e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3468/  8460 | global iter:   3468/  8460 | loss: 0.4306 | ds_loss: 0.0000 | lr: 3.1984e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3469/  8460 | global iter:   3469/  8460 | loss: 0.2013 | ds_loss: 0.0000 | lr: 3.1975e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3470/  8460 | global iter:   3470/  8460 | loss: 0.0706 | ds_loss: 0.0000 | lr: 3.1966e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3471/  8460 | global iter:   3471/  8460 | loss: 0.1734 | ds_loss: 0.0000 | lr: 3.1957e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3472/  8460 | global iter:   3472/  8460 | loss: 0.5055 | ds_loss: 0.0000 | lr: 3.1948e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3472/  8460 | global iter:   3472/  8460 | loss: 0.2377 | ds_loss: 0.0000 | lr: 3.1948e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3473/  8460 | global iter:   3473/  8460 | loss: 0.6503 | ds_loss: 0.0000 | lr: 3.1939e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3474/  8460 | global iter:   3474/  8460 | loss: 0.2657 | ds_loss: 0.0000 | lr: 3.1930e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3475/  8460 | global iter:   3475/  8460 | loss: 0.6901 | ds_loss: 0.0000 | lr: 3.1921e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3476/  8460 | global iter:   3476/  8460 | loss: 0.2227 | ds_loss: 0.0000 | lr: 3.1912e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3476/  8460 | global iter:   3476/  8460 | loss: 0.4572 | ds_loss: 0.0000 | lr: 3.1912e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3477/  8460 | global iter:   3477/  8460 | loss: 0.3375 | ds_loss: 0.0000 | lr: 3.1903e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3478/  8460 | global iter:   3478/  8460 | loss: 0.1325 | ds_loss: 0.0000 | lr: 3.1895e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3479/  8460 | global iter:   3479/  8460 | loss: 0.6081 | ds_loss: 0.0000 | lr: 3.1886e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3480/  8460 | global iter:   3480/  8460 | loss: 0.6193 | ds_loss: 0.0000 | lr: 3.1877e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3480/  8460 | global iter:   3480/  8460 | loss: 0.4244 | ds_loss: 0.0000 | lr: 3.1877e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3481/  8460 | global iter:   3481/  8460 | loss: 0.0335 | ds_loss: 0.0000 | lr: 3.1868e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3482/  8460 | global iter:   3482/  8460 | loss: 0.1447 | ds_loss: 0.0000 | lr: 3.1859e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3483/  8460 | global iter:   3483/  8460 | loss: 0.4309 | ds_loss: 0.0000 | lr: 3.1850e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3484/  8460 | global iter:   3484/  8460 | loss: 0.0919 | ds_loss: 0.0000 | lr: 3.1841e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3484/  8460 | global iter:   3484/  8460 | loss: 0.1752 | ds_loss: 0.0000 | lr: 3.1841e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3485/  8460 | global iter:   3485/  8460 | loss: 0.0862 | ds_loss: 0.0000 | lr: 3.1832e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3486/  8460 | global iter:   3486/  8460 | loss: 0.3092 | ds_loss: 0.0000 | lr: 3.1823e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3487/  8460 | global iter:   3487/  8460 | loss: 0.4338 | ds_loss: 0.0000 | lr: 3.1814e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3488/  8460 | global iter:   3488/  8460 | loss: 0.1442 | ds_loss: 0.0000 | lr: 3.1805e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3488/  8460 | global iter:   3488/  8460 | loss: 0.2434 | ds_loss: 0.0000 | lr: 3.1805e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3489/  8460 | global iter:   3489/  8460 | loss: 0.2937 | ds_loss: 0.0000 | lr: 3.1796e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3490/  8460 | global iter:   3490/  8460 | loss: 0.2670 | ds_loss: 0.0000 | lr: 3.1787e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3491/  8460 | global iter:   3491/  8460 | loss: 0.3376 | ds_loss: 0.0000 | lr: 3.1778e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3492/  8460 | global iter:   3492/  8460 | loss: 0.4383 | ds_loss: 0.0000 | lr: 3.1770e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3492/  8460 | global iter:   3492/  8460 | loss: 0.3341 | ds_loss: 0.0000 | lr: 3.1770e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3493/  8460 | global iter:   3493/  8460 | loss: 0.3897 | ds_loss: 0.0000 | lr: 3.1761e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3494/  8460 | global iter:   3494/  8460 | loss: 0.1568 | ds_loss: 0.0000 | lr: 3.1752e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3495/  8460 | global iter:   3495/  8460 | loss: 0.2395 | ds_loss: 0.0000 | lr: 3.1743e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3496/  8460 | global iter:   3496/  8460 | loss: 0.3518 | ds_loss: 0.0000 | lr: 3.1734e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3496/  8460 | global iter:   3496/  8460 | loss: 0.2844 | ds_loss: 0.0000 | lr: 3.1734e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3497/  8460 | global iter:   3497/  8460 | loss: 0.3500 | ds_loss: 0.0000 | lr: 3.1725e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3498/  8460 | global iter:   3498/  8460 | loss: 0.3187 | ds_loss: 0.0000 | lr: 3.1716e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3499/  8460 | global iter:   3499/  8460 | loss: 0.3868 | ds_loss: 0.0000 | lr: 3.1707e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3500/  8460 | global iter:   3500/  8460 | loss: 0.2045 | ds_loss: 0.0000 | lr: 3.1698e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3500/  8460 | global iter:   3500/  8460 | loss: 0.3150 | ds_loss: 0.0000 | lr: 3.1698e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3501/  8460 | global iter:   3501/  8460 | loss: 0.2621 | ds_loss: 0.0000 | lr: 3.1689e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3502/  8460 | global iter:   3502/  8460 | loss: 0.1343 | ds_loss: 0.0000 | lr: 3.1680e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3503/  8460 | global iter:   3503/  8460 | loss: 0.1963 | ds_loss: 0.0000 | lr: 3.1671e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3504/  8460 | global iter:   3504/  8460 | loss: 0.2345 | ds_loss: 0.0000 | lr: 3.1662e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3504/  8460 | global iter:   3504/  8460 | loss: 0.2068 | ds_loss: 0.0000 | lr: 3.1662e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3505/  8460 | global iter:   3505/  8460 | loss: 0.4789 | ds_loss: 0.0000 | lr: 3.1653e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3506/  8460 | global iter:   3506/  8460 | loss: 0.2588 | ds_loss: 0.0000 | lr: 3.1644e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3507/  8460 | global iter:   3507/  8460 | loss: 0.8237 | ds_loss: 0.0000 | lr: 3.1635e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3508/  8460 | global iter:   3508/  8460 | loss: 0.4253 | ds_loss: 0.0000 | lr: 3.1626e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3508/  8460 | global iter:   3508/  8460 | loss: 0.4967 | ds_loss: 0.0000 | lr: 3.1626e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3509/  8460 | global iter:   3509/  8460 | loss: 0.7415 | ds_loss: 0.0000 | lr: 3.1618e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3510/  8460 | global iter:   3510/  8460 | loss: 0.4742 | ds_loss: 0.0000 | lr: 3.1609e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3511/  8460 | global iter:   3511/  8460 | loss: 0.2584 | ds_loss: 0.0000 | lr: 3.1600e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3512/  8460 | global iter:   3512/  8460 | loss: 0.1587 | ds_loss: 0.0000 | lr: 3.1591e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3512/  8460 | global iter:   3512/  8460 | loss: 0.4082 | ds_loss: 0.0000 | lr: 3.1591e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3513/  8460 | global iter:   3513/  8460 | loss: 0.7087 | ds_loss: 0.0000 | lr: 3.1582e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3514/  8460 | global iter:   3514/  8460 | loss: 0.3983 | ds_loss: 0.0000 | lr: 3.1573e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3515/  8460 | global iter:   3515/  8460 | loss: 0.0848 | ds_loss: 0.0000 | lr: 3.1564e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3516/  8460 | global iter:   3516/  8460 | loss: 0.4201 | ds_loss: 0.0000 | lr: 3.1555e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3516/  8460 | global iter:   3516/  8460 | loss: 0.4030 | ds_loss: 0.0000 | lr: 3.1555e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3517/  8460 | global iter:   3517/  8460 | loss: 0.1770 | ds_loss: 0.0000 | lr: 3.1546e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3518/  8460 | global iter:   3518/  8460 | loss: 0.4233 | ds_loss: 0.0000 | lr: 3.1537e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3519/  8460 | global iter:   3519/  8460 | loss: 0.1341 | ds_loss: 0.0000 | lr: 3.1528e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3520/  8460 | global iter:   3520/  8460 | loss: 0.1475 | ds_loss: 0.0000 | lr: 3.1519e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3520/  8460 | global iter:   3520/  8460 | loss: 0.2205 | ds_loss: 0.0000 | lr: 3.1519e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3521/  8460 | global iter:   3521/  8460 | loss: 0.1809 | ds_loss: 0.0000 | lr: 3.1510e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3522/  8460 | global iter:   3522/  8460 | loss: 0.2971 | ds_loss: 0.0000 | lr: 3.1501e-04 | scale:     1.0000 | micro time: 0.437 | step time: 0.000
train | epoch   4 | Iter:   3523/  8460 | global iter:   3523/  8460 | loss: 0.3748 | ds_loss: 0.0000 | lr: 3.1492e-04 | scale:     1.0000 | micro time: 0.434 | step time: 0.000
train | epoch   4 | Iter:   3524/  8460 | global iter:   3524/  8460 | loss: 0.2594 | ds_loss: 0.0000 | lr: 3.1483e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3524/  8460 | global iter:   3524/  8460 | loss: 0.2780 | ds_loss: 0.0000 | lr: 3.1483e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.431
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3525/  8460 | global iter:   3525/  8460 | loss: 0.1324 | ds_loss: 0.0000 | lr: 3.1474e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3526/  8460 | global iter:   3526/  8460 | loss: 0.3520 | ds_loss: 0.0000 | lr: 3.1465e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3527/  8460 | global iter:   3527/  8460 | loss: 0.1613 | ds_loss: 0.0000 | lr: 3.1456e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3528/  8460 | global iter:   3528/  8460 | loss: 0.1298 | ds_loss: 0.0000 | lr: 3.1447e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3528/  8460 | global iter:   3528/  8460 | loss: 0.1939 | ds_loss: 0.0000 | lr: 3.1447e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3529/  8460 | global iter:   3529/  8460 | loss: 0.0854 | ds_loss: 0.0000 | lr: 3.1438e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3530/  8460 | global iter:   3530/  8460 | loss: 0.3574 | ds_loss: 0.0000 | lr: 3.1429e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3531/  8460 | global iter:   3531/  8460 | loss: 0.1850 | ds_loss: 0.0000 | lr: 3.1420e-04 | scale:     1.0000 | micro time: 0.439 | step time: 0.000
train | epoch   4 | Iter:   3532/  8460 | global iter:   3532/  8460 | loss: 0.0406 | ds_loss: 0.0000 | lr: 3.1411e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3532/  8460 | global iter:   3532/  8460 | loss: 0.1671 | ds_loss: 0.0000 | lr: 3.1411e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.431
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3533/  8460 | global iter:   3533/  8460 | loss: 0.1692 | ds_loss: 0.0000 | lr: 3.1402e-04 | scale:     1.0000 | micro time: 0.439 | step time: 0.000
train | epoch   4 | Iter:   3534/  8460 | global iter:   3534/  8460 | loss: 0.3973 | ds_loss: 0.0000 | lr: 3.1393e-04 | scale:     1.0000 | micro time: 0.438 | step time: 0.000
train | epoch   4 | Iter:   3535/  8460 | global iter:   3535/  8460 | loss: 0.4211 | ds_loss: 0.0000 | lr: 3.1384e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.000
train | epoch   4 | Iter:   3536/  8460 | global iter:   3536/  8460 | loss: 0.1280 | ds_loss: 0.0000 | lr: 3.1376e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3536/  8460 | global iter:   3536/  8460 | loss: 0.2789 | ds_loss: 0.0000 | lr: 3.1376e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.434
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3537/  8460 | global iter:   3537/  8460 | loss: 0.1163 | ds_loss: 0.0000 | lr: 3.1367e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3538/  8460 | global iter:   3538/  8460 | loss: 0.0267 | ds_loss: 0.0000 | lr: 3.1358e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3539/  8460 | global iter:   3539/  8460 | loss: 0.2504 | ds_loss: 0.0000 | lr: 3.1349e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3540/  8460 | global iter:   3540/  8460 | loss: 0.2471 | ds_loss: 0.0000 | lr: 3.1340e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3540/  8460 | global iter:   3540/  8460 | loss: 0.1601 | ds_loss: 0.0000 | lr: 3.1340e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3541/  8460 | global iter:   3541/  8460 | loss: 0.3654 | ds_loss: 0.0000 | lr: 3.1331e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3542/  8460 | global iter:   3542/  8460 | loss: 0.0860 | ds_loss: 0.0000 | lr: 3.1322e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3543/  8460 | global iter:   3543/  8460 | loss: 0.2723 | ds_loss: 0.0000 | lr: 3.1313e-04 | scale:     1.0000 | micro time: 0.438 | step time: 0.000
train | epoch   4 | Iter:   3544/  8460 | global iter:   3544/  8460 | loss: 0.1472 | ds_loss: 0.0000 | lr: 3.1304e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3544/  8460 | global iter:   3544/  8460 | loss: 0.2177 | ds_loss: 0.0000 | lr: 3.1304e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.431
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3545/  8460 | global iter:   3545/  8460 | loss: 0.1475 | ds_loss: 0.0000 | lr: 3.1295e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3546/  8460 | global iter:   3546/  8460 | loss: 0.2539 | ds_loss: 0.0000 | lr: 3.1286e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3547/  8460 | global iter:   3547/  8460 | loss: 0.6292 | ds_loss: 0.0000 | lr: 3.1277e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3548/  8460 | global iter:   3548/  8460 | loss: 0.1796 | ds_loss: 0.0000 | lr: 3.1268e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3548/  8460 | global iter:   3548/  8460 | loss: 0.3025 | ds_loss: 0.0000 | lr: 3.1268e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3549/  8460 | global iter:   3549/  8460 | loss: 0.1957 | ds_loss: 0.0000 | lr: 3.1259e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3550/  8460 | global iter:   3550/  8460 | loss: 0.1899 | ds_loss: 0.0000 | lr: 3.1250e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3551/  8460 | global iter:   3551/  8460 | loss: 0.1608 | ds_loss: 0.0000 | lr: 3.1241e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3552/  8460 | global iter:   3552/  8460 | loss: 0.7186 | ds_loss: 0.0000 | lr: 3.1232e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3552/  8460 | global iter:   3552/  8460 | loss: 0.3162 | ds_loss: 0.0000 | lr: 3.1232e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3553/  8460 | global iter:   3553/  8460 | loss: 0.3095 | ds_loss: 0.0000 | lr: 3.1223e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3554/  8460 | global iter:   3554/  8460 | loss: 0.1626 | ds_loss: 0.0000 | lr: 3.1214e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3555/  8460 | global iter:   3555/  8460 | loss: 0.3922 | ds_loss: 0.0000 | lr: 3.1205e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3556/  8460 | global iter:   3556/  8460 | loss: 0.1831 | ds_loss: 0.0000 | lr: 3.1196e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3556/  8460 | global iter:   3556/  8460 | loss: 0.2618 | ds_loss: 0.0000 | lr: 3.1196e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3557/  8460 | global iter:   3557/  8460 | loss: 0.2814 | ds_loss: 0.0000 | lr: 3.1187e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3558/  8460 | global iter:   3558/  8460 | loss: 0.5996 | ds_loss: 0.0000 | lr: 3.1178e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3559/  8460 | global iter:   3559/  8460 | loss: 0.2304 | ds_loss: 0.0000 | lr: 3.1169e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3560/  8460 | global iter:   3560/  8460 | loss: 0.2098 | ds_loss: 0.0000 | lr: 3.1160e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3560/  8460 | global iter:   3560/  8460 | loss: 0.3303 | ds_loss: 0.0000 | lr: 3.1160e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3561/  8460 | global iter:   3561/  8460 | loss: 0.5339 | ds_loss: 0.0000 | lr: 3.1151e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3562/  8460 | global iter:   3562/  8460 | loss: 0.3556 | ds_loss: 0.0000 | lr: 3.1142e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3563/  8460 | global iter:   3563/  8460 | loss: 0.2685 | ds_loss: 0.0000 | lr: 3.1133e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3564/  8460 | global iter:   3564/  8460 | loss: 0.2236 | ds_loss: 0.0000 | lr: 3.1124e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3564/  8460 | global iter:   3564/  8460 | loss: 0.3454 | ds_loss: 0.0000 | lr: 3.1124e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3565/  8460 | global iter:   3565/  8460 | loss: 0.2906 | ds_loss: 0.0000 | lr: 3.1115e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3566/  8460 | global iter:   3566/  8460 | loss: 0.0894 | ds_loss: 0.0000 | lr: 3.1106e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3567/  8460 | global iter:   3567/  8460 | loss: 0.3645 | ds_loss: 0.0000 | lr: 3.1097e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3568/  8460 | global iter:   3568/  8460 | loss: 0.1976 | ds_loss: 0.0000 | lr: 3.1088e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3568/  8460 | global iter:   3568/  8460 | loss: 0.2355 | ds_loss: 0.0000 | lr: 3.1088e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3569/  8460 | global iter:   3569/  8460 | loss: 0.1048 | ds_loss: 0.0000 | lr: 3.1079e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3570/  8460 | global iter:   3570/  8460 | loss: 0.1062 | ds_loss: 0.0000 | lr: 3.1070e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3571/  8460 | global iter:   3571/  8460 | loss: 0.6569 | ds_loss: 0.0000 | lr: 3.1061e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3572/  8460 | global iter:   3572/  8460 | loss: 0.1470 | ds_loss: 0.0000 | lr: 3.1052e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3572/  8460 | global iter:   3572/  8460 | loss: 0.2537 | ds_loss: 0.0000 | lr: 3.1052e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3573/  8460 | global iter:   3573/  8460 | loss: 0.4316 | ds_loss: 0.0000 | lr: 3.1043e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3574/  8460 | global iter:   3574/  8460 | loss: 0.1141 | ds_loss: 0.0000 | lr: 3.1034e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3575/  8460 | global iter:   3575/  8460 | loss: 0.4733 | ds_loss: 0.0000 | lr: 3.1025e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3576/  8460 | global iter:   3576/  8460 | loss: 0.1707 | ds_loss: 0.0000 | lr: 3.1016e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3576/  8460 | global iter:   3576/  8460 | loss: 0.2974 | ds_loss: 0.0000 | lr: 3.1016e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3577/  8460 | global iter:   3577/  8460 | loss: 0.1698 | ds_loss: 0.0000 | lr: 3.1007e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3578/  8460 | global iter:   3578/  8460 | loss: 0.1894 | ds_loss: 0.0000 | lr: 3.0998e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3579/  8460 | global iter:   3579/  8460 | loss: 0.4374 | ds_loss: 0.0000 | lr: 3.0989e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3580/  8460 | global iter:   3580/  8460 | loss: 0.1395 | ds_loss: 0.0000 | lr: 3.0980e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3580/  8460 | global iter:   3580/  8460 | loss: 0.2340 | ds_loss: 0.0000 | lr: 3.0980e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3581/  8460 | global iter:   3581/  8460 | loss: 0.2013 | ds_loss: 0.0000 | lr: 3.0971e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3582/  8460 | global iter:   3582/  8460 | loss: 0.2355 | ds_loss: 0.0000 | lr: 3.0962e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3583/  8460 | global iter:   3583/  8460 | loss: 0.2133 | ds_loss: 0.0000 | lr: 3.0953e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3584/  8460 | global iter:   3584/  8460 | loss: 0.1860 | ds_loss: 0.0000 | lr: 3.0944e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3584/  8460 | global iter:   3584/  8460 | loss: 0.2090 | ds_loss: 0.0000 | lr: 3.0944e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3585/  8460 | global iter:   3585/  8460 | loss: 0.2959 | ds_loss: 0.0000 | lr: 3.0935e-04 | scale:     1.0000 | micro time: 0.432 | step time: 0.000
train | epoch   4 | Iter:   3586/  8460 | global iter:   3586/  8460 | loss: 0.2417 | ds_loss: 0.0000 | lr: 3.0926e-04 | scale:     1.0000 | micro time: 0.438 | step time: 0.000
train | epoch   4 | Iter:   3587/  8460 | global iter:   3587/  8460 | loss: 0.1195 | ds_loss: 0.0000 | lr: 3.0917e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.000
train | epoch   4 | Iter:   3588/  8460 | global iter:   3588/  8460 | loss: 0.2904 | ds_loss: 0.0000 | lr: 3.0908e-04 | scale:     1.0000 | micro time: 0.439 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3588/  8460 | global iter:   3588/  8460 | loss: 0.2369 | ds_loss: 0.0000 | lr: 3.0908e-04 | scale:     1.0000 | micro time: 0.439 | step time: 0.435
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3589/  8460 | global iter:   3589/  8460 | loss: 0.5286 | ds_loss: 0.0000 | lr: 3.0899e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.000
train | epoch   4 | Iter:   3590/  8460 | global iter:   3590/  8460 | loss: 0.2273 | ds_loss: 0.0000 | lr: 3.0890e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3591/  8460 | global iter:   3591/  8460 | loss: 0.3050 | ds_loss: 0.0000 | lr: 3.0881e-04 | scale:     1.0000 | micro time: 0.437 | step time: 0.000
train | epoch   4 | Iter:   3592/  8460 | global iter:   3592/  8460 | loss: 0.0436 | ds_loss: 0.0000 | lr: 3.0872e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3592/  8460 | global iter:   3592/  8460 | loss: 0.2761 | ds_loss: 0.0000 | lr: 3.0872e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.431
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3593/  8460 | global iter:   3593/  8460 | loss: 0.1375 | ds_loss: 0.0000 | lr: 3.0863e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3594/  8460 | global iter:   3594/  8460 | loss: 0.2182 | ds_loss: 0.0000 | lr: 3.0854e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3595/  8460 | global iter:   3595/  8460 | loss: 0.2770 | ds_loss: 0.0000 | lr: 3.0844e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3596/  8460 | global iter:   3596/  8460 | loss: 0.0913 | ds_loss: 0.0000 | lr: 3.0835e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3596/  8460 | global iter:   3596/  8460 | loss: 0.1810 | ds_loss: 0.0000 | lr: 3.0835e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3597/  8460 | global iter:   3597/  8460 | loss: 0.3020 | ds_loss: 0.0000 | lr: 3.0826e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3598/  8460 | global iter:   3598/  8460 | loss: 0.3869 | ds_loss: 0.0000 | lr: 3.0817e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3599/  8460 | global iter:   3599/  8460 | loss: 0.1924 | ds_loss: 0.0000 | lr: 3.0808e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3600/  8460 | global iter:   3600/  8460 | loss: 0.4290 | ds_loss: 0.0000 | lr: 3.0799e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3600/  8460 | global iter:   3600/  8460 | loss: 0.3276 | ds_loss: 0.0000 | lr: 3.0799e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3601/  8460 | global iter:   3601/  8460 | loss: 0.1508 | ds_loss: 0.0000 | lr: 3.0790e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3602/  8460 | global iter:   3602/  8460 | loss: 0.1706 | ds_loss: 0.0000 | lr: 3.0781e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3603/  8460 | global iter:   3603/  8460 | loss: 0.1959 | ds_loss: 0.0000 | lr: 3.0772e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3604/  8460 | global iter:   3604/  8460 | loss: 0.3474 | ds_loss: 0.0000 | lr: 3.0763e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3604/  8460 | global iter:   3604/  8460 | loss: 0.2162 | ds_loss: 0.0000 | lr: 3.0763e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3605/  8460 | global iter:   3605/  8460 | loss: 0.0632 | ds_loss: 0.0000 | lr: 3.0754e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3606/  8460 | global iter:   3606/  8460 | loss: 0.8278 | ds_loss: 0.0000 | lr: 3.0745e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3607/  8460 | global iter:   3607/  8460 | loss: 0.5668 | ds_loss: 0.0000 | lr: 3.0736e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3608/  8460 | global iter:   3608/  8460 | loss: 0.2179 | ds_loss: 0.0000 | lr: 3.0727e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3608/  8460 | global iter:   3608/  8460 | loss: 0.4189 | ds_loss: 0.0000 | lr: 3.0727e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3609/  8460 | global iter:   3609/  8460 | loss: 0.2952 | ds_loss: 0.0000 | lr: 3.0718e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3610/  8460 | global iter:   3610/  8460 | loss: 0.1818 | ds_loss: 0.0000 | lr: 3.0709e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3611/  8460 | global iter:   3611/  8460 | loss: 0.2249 | ds_loss: 0.0000 | lr: 3.0700e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3612/  8460 | global iter:   3612/  8460 | loss: 0.5078 | ds_loss: 0.0000 | lr: 3.0691e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3612/  8460 | global iter:   3612/  8460 | loss: 0.3024 | ds_loss: 0.0000 | lr: 3.0691e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3613/  8460 | global iter:   3613/  8460 | loss: 0.3636 | ds_loss: 0.0000 | lr: 3.0682e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3614/  8460 | global iter:   3614/  8460 | loss: 0.3405 | ds_loss: 0.0000 | lr: 3.0673e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3615/  8460 | global iter:   3615/  8460 | loss: 0.2352 | ds_loss: 0.0000 | lr: 3.0664e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3616/  8460 | global iter:   3616/  8460 | loss: 0.5183 | ds_loss: 0.0000 | lr: 3.0655e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3616/  8460 | global iter:   3616/  8460 | loss: 0.3644 | ds_loss: 0.0000 | lr: 3.0655e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3617/  8460 | global iter:   3617/  8460 | loss: 0.2449 | ds_loss: 0.0000 | lr: 3.0646e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3618/  8460 | global iter:   3618/  8460 | loss: 0.2046 | ds_loss: 0.0000 | lr: 3.0637e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3619/  8460 | global iter:   3619/  8460 | loss: 0.2790 | ds_loss: 0.0000 | lr: 3.0628e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3620/  8460 | global iter:   3620/  8460 | loss: 0.3791 | ds_loss: 0.0000 | lr: 3.0619e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3620/  8460 | global iter:   3620/  8460 | loss: 0.2769 | ds_loss: 0.0000 | lr: 3.0619e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3621/  8460 | global iter:   3621/  8460 | loss: 0.1875 | ds_loss: 0.0000 | lr: 3.0610e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3622/  8460 | global iter:   3622/  8460 | loss: 0.5081 | ds_loss: 0.0000 | lr: 3.0601e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3623/  8460 | global iter:   3623/  8460 | loss: 0.5265 | ds_loss: 0.0000 | lr: 3.0591e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3624/  8460 | global iter:   3624/  8460 | loss: 0.3949 | ds_loss: 0.0000 | lr: 3.0582e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3624/  8460 | global iter:   3624/  8460 | loss: 0.4043 | ds_loss: 0.0000 | lr: 3.0582e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3625/  8460 | global iter:   3625/  8460 | loss: 0.2889 | ds_loss: 0.0000 | lr: 3.0573e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3626/  8460 | global iter:   3626/  8460 | loss: 0.3201 | ds_loss: 0.0000 | lr: 3.0564e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3627/  8460 | global iter:   3627/  8460 | loss: 0.1937 | ds_loss: 0.0000 | lr: 3.0555e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3628/  8460 | global iter:   3628/  8460 | loss: 0.3295 | ds_loss: 0.0000 | lr: 3.0546e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3628/  8460 | global iter:   3628/  8460 | loss: 0.2830 | ds_loss: 0.0000 | lr: 3.0546e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3629/  8460 | global iter:   3629/  8460 | loss: 0.6050 | ds_loss: 0.0000 | lr: 3.0537e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3630/  8460 | global iter:   3630/  8460 | loss: 0.3689 | ds_loss: 0.0000 | lr: 3.0528e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3631/  8460 | global iter:   3631/  8460 | loss: 0.3367 | ds_loss: 0.0000 | lr: 3.0519e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3632/  8460 | global iter:   3632/  8460 | loss: 0.1794 | ds_loss: 0.0000 | lr: 3.0510e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3632/  8460 | global iter:   3632/  8460 | loss: 0.3725 | ds_loss: 0.0000 | lr: 3.0510e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3633/  8460 | global iter:   3633/  8460 | loss: 0.4940 | ds_loss: 0.0000 | lr: 3.0501e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3634/  8460 | global iter:   3634/  8460 | loss: 0.2342 | ds_loss: 0.0000 | lr: 3.0492e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3635/  8460 | global iter:   3635/  8460 | loss: 0.4801 | ds_loss: 0.0000 | lr: 3.0483e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3636/  8460 | global iter:   3636/  8460 | loss: 0.1539 | ds_loss: 0.0000 | lr: 3.0474e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3636/  8460 | global iter:   3636/  8460 | loss: 0.3405 | ds_loss: 0.0000 | lr: 3.0474e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3637/  8460 | global iter:   3637/  8460 | loss: 0.5295 | ds_loss: 0.0000 | lr: 3.0465e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3638/  8460 | global iter:   3638/  8460 | loss: 0.3106 | ds_loss: 0.0000 | lr: 3.0456e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3639/  8460 | global iter:   3639/  8460 | loss: 0.5106 | ds_loss: 0.0000 | lr: 3.0447e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3640/  8460 | global iter:   3640/  8460 | loss: 0.5030 | ds_loss: 0.0000 | lr: 3.0438e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3640/  8460 | global iter:   3640/  8460 | loss: 0.4634 | ds_loss: 0.0000 | lr: 3.0438e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3641/  8460 | global iter:   3641/  8460 | loss: 0.2814 | ds_loss: 0.0000 | lr: 3.0429e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3642/  8460 | global iter:   3642/  8460 | loss: 0.6206 | ds_loss: 0.0000 | lr: 3.0419e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3643/  8460 | global iter:   3643/  8460 | loss: 0.1909 | ds_loss: 0.0000 | lr: 3.0410e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3644/  8460 | global iter:   3644/  8460 | loss: 0.2171 | ds_loss: 0.0000 | lr: 3.0401e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3644/  8460 | global iter:   3644/  8460 | loss: 0.3275 | ds_loss: 0.0000 | lr: 3.0401e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3645/  8460 | global iter:   3645/  8460 | loss: 0.1298 | ds_loss: 0.0000 | lr: 3.0392e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3646/  8460 | global iter:   3646/  8460 | loss: 0.2340 | ds_loss: 0.0000 | lr: 3.0383e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3647/  8460 | global iter:   3647/  8460 | loss: 0.1616 | ds_loss: 0.0000 | lr: 3.0374e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3648/  8460 | global iter:   3648/  8460 | loss: 0.6813 | ds_loss: 0.0000 | lr: 3.0365e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3648/  8460 | global iter:   3648/  8460 | loss: 0.3017 | ds_loss: 0.0000 | lr: 3.0365e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3649/  8460 | global iter:   3649/  8460 | loss: 0.4321 | ds_loss: 0.0000 | lr: 3.0356e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3650/  8460 | global iter:   3650/  8460 | loss: 0.0784 | ds_loss: 0.0000 | lr: 3.0347e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3651/  8460 | global iter:   3651/  8460 | loss: 0.3134 | ds_loss: 0.0000 | lr: 3.0338e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3652/  8460 | global iter:   3652/  8460 | loss: 0.4122 | ds_loss: 0.0000 | lr: 3.0329e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3652/  8460 | global iter:   3652/  8460 | loss: 0.3090 | ds_loss: 0.0000 | lr: 3.0329e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3653/  8460 | global iter:   3653/  8460 | loss: 0.3343 | ds_loss: 0.0000 | lr: 3.0320e-04 | scale:     1.0000 | micro time: 0.436 | step time: 0.000
train | epoch   4 | Iter:   3654/  8460 | global iter:   3654/  8460 | loss: 0.4404 | ds_loss: 0.0000 | lr: 3.0311e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3655/  8460 | global iter:   3655/  8460 | loss: 0.0709 | ds_loss: 0.0000 | lr: 3.0302e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3656/  8460 | global iter:   3656/  8460 | loss: 0.7928 | ds_loss: 0.0000 | lr: 3.0293e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3656/  8460 | global iter:   3656/  8460 | loss: 0.4096 | ds_loss: 0.0000 | lr: 3.0293e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.430
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3657/  8460 | global iter:   3657/  8460 | loss: 0.1536 | ds_loss: 0.0000 | lr: 3.0283e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3658/  8460 | global iter:   3658/  8460 | loss: 0.7863 | ds_loss: 0.0000 | lr: 3.0274e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3659/  8460 | global iter:   3659/  8460 | loss: 0.1577 | ds_loss: 0.0000 | lr: 3.0265e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3660/  8460 | global iter:   3660/  8460 | loss: 0.4857 | ds_loss: 0.0000 | lr: 3.0256e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3660/  8460 | global iter:   3660/  8460 | loss: 0.3958 | ds_loss: 0.0000 | lr: 3.0256e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3661/  8460 | global iter:   3661/  8460 | loss: 0.3258 | ds_loss: 0.0000 | lr: 3.0247e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3662/  8460 | global iter:   3662/  8460 | loss: 0.5219 | ds_loss: 0.0000 | lr: 3.0238e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3663/  8460 | global iter:   3663/  8460 | loss: 0.2004 | ds_loss: 0.0000 | lr: 3.0229e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3664/  8460 | global iter:   3664/  8460 | loss: 0.4877 | ds_loss: 0.0000 | lr: 3.0220e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3664/  8460 | global iter:   3664/  8460 | loss: 0.3839 | ds_loss: 0.0000 | lr: 3.0220e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3665/  8460 | global iter:   3665/  8460 | loss: 0.3362 | ds_loss: 0.0000 | lr: 3.0211e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3666/  8460 | global iter:   3666/  8460 | loss: 0.2619 | ds_loss: 0.0000 | lr: 3.0202e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3667/  8460 | global iter:   3667/  8460 | loss: 0.2943 | ds_loss: 0.0000 | lr: 3.0193e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3668/  8460 | global iter:   3668/  8460 | loss: 0.1788 | ds_loss: 0.0000 | lr: 3.0184e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3668/  8460 | global iter:   3668/  8460 | loss: 0.2678 | ds_loss: 0.0000 | lr: 3.0184e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3669/  8460 | global iter:   3669/  8460 | loss: 0.3613 | ds_loss: 0.0000 | lr: 3.0175e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3670/  8460 | global iter:   3670/  8460 | loss: 0.3709 | ds_loss: 0.0000 | lr: 3.0165e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3671/  8460 | global iter:   3671/  8460 | loss: 0.5243 | ds_loss: 0.0000 | lr: 3.0156e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3672/  8460 | global iter:   3672/  8460 | loss: 0.1806 | ds_loss: 0.0000 | lr: 3.0147e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3672/  8460 | global iter:   3672/  8460 | loss: 0.3593 | ds_loss: 0.0000 | lr: 3.0147e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3673/  8460 | global iter:   3673/  8460 | loss: 0.4281 | ds_loss: 0.0000 | lr: 3.0138e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3674/  8460 | global iter:   3674/  8460 | loss: 0.2031 | ds_loss: 0.0000 | lr: 3.0129e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3675/  8460 | global iter:   3675/  8460 | loss: 0.2724 | ds_loss: 0.0000 | lr: 3.0120e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3676/  8460 | global iter:   3676/  8460 | loss: 0.4417 | ds_loss: 0.0000 | lr: 3.0111e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3676/  8460 | global iter:   3676/  8460 | loss: 0.3363 | ds_loss: 0.0000 | lr: 3.0111e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3677/  8460 | global iter:   3677/  8460 | loss: 0.2892 | ds_loss: 0.0000 | lr: 3.0102e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3678/  8460 | global iter:   3678/  8460 | loss: 0.0643 | ds_loss: 0.0000 | lr: 3.0093e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3679/  8460 | global iter:   3679/  8460 | loss: 0.2084 | ds_loss: 0.0000 | lr: 3.0084e-04 | scale:     1.0000 | micro time: 0.437 | step time: 0.000
train | epoch   4 | Iter:   3680/  8460 | global iter:   3680/  8460 | loss: 0.1636 | ds_loss: 0.0000 | lr: 3.0075e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3680/  8460 | global iter:   3680/  8460 | loss: 0.1814 | ds_loss: 0.0000 | lr: 3.0075e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.430
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3681/  8460 | global iter:   3681/  8460 | loss: 0.3763 | ds_loss: 0.0000 | lr: 3.0065e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3682/  8460 | global iter:   3682/  8460 | loss: 0.1809 | ds_loss: 0.0000 | lr: 3.0056e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3683/  8460 | global iter:   3683/  8460 | loss: 0.4351 | ds_loss: 0.0000 | lr: 3.0047e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.000
train | epoch   4 | Iter:   3684/  8460 | global iter:   3684/  8460 | loss: 0.2242 | ds_loss: 0.0000 | lr: 3.0038e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3684/  8460 | global iter:   3684/  8460 | loss: 0.3041 | ds_loss: 0.0000 | lr: 3.0038e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3685/  8460 | global iter:   3685/  8460 | loss: 0.0902 | ds_loss: 0.0000 | lr: 3.0029e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3686/  8460 | global iter:   3686/  8460 | loss: 0.4136 | ds_loss: 0.0000 | lr: 3.0020e-04 | scale:     1.0000 | micro time: 0.431 | step time: 0.000
train | epoch   4 | Iter:   3687/  8460 | global iter:   3687/  8460 | loss: 0.5211 | ds_loss: 0.0000 | lr: 3.0011e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3688/  8460 | global iter:   3688/  8460 | loss: 0.1121 | ds_loss: 0.0000 | lr: 3.0002e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3688/  8460 | global iter:   3688/  8460 | loss: 0.2843 | ds_loss: 0.0000 | lr: 3.0002e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3689/  8460 | global iter:   3689/  8460 | loss: 0.1408 | ds_loss: 0.0000 | lr: 2.9993e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3690/  8460 | global iter:   3690/  8460 | loss: 0.1915 | ds_loss: 0.0000 | lr: 2.9984e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3691/  8460 | global iter:   3691/  8460 | loss: 0.5944 | ds_loss: 0.0000 | lr: 2.9975e-04 | scale:     1.0000 | micro time: 0.438 | step time: 0.000
train | epoch   4 | Iter:   3692/  8460 | global iter:   3692/  8460 | loss: 0.5579 | ds_loss: 0.0000 | lr: 2.9965e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3692/  8460 | global iter:   3692/  8460 | loss: 0.3712 | ds_loss: 0.0000 | lr: 2.9965e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.430
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3693/  8460 | global iter:   3693/  8460 | loss: 0.2278 | ds_loss: 0.0000 | lr: 2.9956e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3694/  8460 | global iter:   3694/  8460 | loss: 0.3717 | ds_loss: 0.0000 | lr: 2.9947e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3695/  8460 | global iter:   3695/  8460 | loss: 0.4274 | ds_loss: 0.0000 | lr: 2.9938e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3696/  8460 | global iter:   3696/  8460 | loss: 0.1863 | ds_loss: 0.0000 | lr: 2.9929e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3696/  8460 | global iter:   3696/  8460 | loss: 0.3033 | ds_loss: 0.0000 | lr: 2.9929e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3697/  8460 | global iter:   3697/  8460 | loss: 0.1808 | ds_loss: 0.0000 | lr: 2.9920e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3698/  8460 | global iter:   3698/  8460 | loss: 0.5157 | ds_loss: 0.0000 | lr: 2.9911e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3699/  8460 | global iter:   3699/  8460 | loss: 0.3396 | ds_loss: 0.0000 | lr: 2.9902e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3700/  8460 | global iter:   3700/  8460 | loss: 0.1336 | ds_loss: 0.0000 | lr: 2.9893e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3700/  8460 | global iter:   3700/  8460 | loss: 0.2924 | ds_loss: 0.0000 | lr: 2.9893e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3701/  8460 | global iter:   3701/  8460 | loss: 0.8936 | ds_loss: 0.0000 | lr: 2.9884e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3702/  8460 | global iter:   3702/  8460 | loss: 0.3988 | ds_loss: 0.0000 | lr: 2.9874e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3703/  8460 | global iter:   3703/  8460 | loss: 0.2980 | ds_loss: 0.0000 | lr: 2.9865e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3704/  8460 | global iter:   3704/  8460 | loss: 0.2062 | ds_loss: 0.0000 | lr: 2.9856e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3704/  8460 | global iter:   3704/  8460 | loss: 0.4492 | ds_loss: 0.0000 | lr: 2.9856e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3705/  8460 | global iter:   3705/  8460 | loss: 0.2951 | ds_loss: 0.0000 | lr: 2.9847e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3706/  8460 | global iter:   3706/  8460 | loss: 0.1733 | ds_loss: 0.0000 | lr: 2.9838e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3707/  8460 | global iter:   3707/  8460 | loss: 0.1174 | ds_loss: 0.0000 | lr: 2.9829e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3708/  8460 | global iter:   3708/  8460 | loss: 0.3514 | ds_loss: 0.0000 | lr: 2.9820e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3708/  8460 | global iter:   3708/  8460 | loss: 0.2343 | ds_loss: 0.0000 | lr: 2.9820e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3709/  8460 | global iter:   3709/  8460 | loss: 0.2618 | ds_loss: 0.0000 | lr: 2.9811e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3710/  8460 | global iter:   3710/  8460 | loss: 0.8955 | ds_loss: 0.0000 | lr: 2.9802e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3711/  8460 | global iter:   3711/  8460 | loss: 0.1017 | ds_loss: 0.0000 | lr: 2.9792e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3712/  8460 | global iter:   3712/  8460 | loss: 0.4399 | ds_loss: 0.0000 | lr: 2.9783e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3712/  8460 | global iter:   3712/  8460 | loss: 0.4247 | ds_loss: 0.0000 | lr: 2.9783e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3713/  8460 | global iter:   3713/  8460 | loss: 0.1425 | ds_loss: 0.0000 | lr: 2.9774e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3714/  8460 | global iter:   3714/  8460 | loss: 0.1713 | ds_loss: 0.0000 | lr: 2.9765e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3715/  8460 | global iter:   3715/  8460 | loss: 0.1704 | ds_loss: 0.0000 | lr: 2.9756e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3716/  8460 | global iter:   3716/  8460 | loss: 0.1706 | ds_loss: 0.0000 | lr: 2.9747e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3716/  8460 | global iter:   3716/  8460 | loss: 0.1637 | ds_loss: 0.0000 | lr: 2.9747e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3717/  8460 | global iter:   3717/  8460 | loss: 0.3789 | ds_loss: 0.0000 | lr: 2.9738e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3718/  8460 | global iter:   3718/  8460 | loss: 0.3450 | ds_loss: 0.0000 | lr: 2.9729e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3719/  8460 | global iter:   3719/  8460 | loss: 0.3207 | ds_loss: 0.0000 | lr: 2.9720e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3720/  8460 | global iter:   3720/  8460 | loss: 0.2451 | ds_loss: 0.0000 | lr: 2.9710e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3720/  8460 | global iter:   3720/  8460 | loss: 0.3224 | ds_loss: 0.0000 | lr: 2.9710e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3721/  8460 | global iter:   3721/  8460 | loss: 0.3946 | ds_loss: 0.0000 | lr: 2.9701e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3722/  8460 | global iter:   3722/  8460 | loss: 0.1105 | ds_loss: 0.0000 | lr: 2.9692e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3723/  8460 | global iter:   3723/  8460 | loss: 0.4299 | ds_loss: 0.0000 | lr: 2.9683e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3724/  8460 | global iter:   3724/  8460 | loss: 0.1666 | ds_loss: 0.0000 | lr: 2.9674e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3724/  8460 | global iter:   3724/  8460 | loss: 0.2754 | ds_loss: 0.0000 | lr: 2.9674e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3725/  8460 | global iter:   3725/  8460 | loss: 0.2811 | ds_loss: 0.0000 | lr: 2.9665e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3726/  8460 | global iter:   3726/  8460 | loss: 0.3085 | ds_loss: 0.0000 | lr: 2.9656e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3727/  8460 | global iter:   3727/  8460 | loss: 0.1810 | ds_loss: 0.0000 | lr: 2.9647e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3728/  8460 | global iter:   3728/  8460 | loss: 0.3892 | ds_loss: 0.0000 | lr: 2.9638e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3728/  8460 | global iter:   3728/  8460 | loss: 0.2899 | ds_loss: 0.0000 | lr: 2.9638e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3729/  8460 | global iter:   3729/  8460 | loss: 0.1027 | ds_loss: 0.0000 | lr: 2.9628e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3730/  8460 | global iter:   3730/  8460 | loss: 0.3164 | ds_loss: 0.0000 | lr: 2.9619e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3731/  8460 | global iter:   3731/  8460 | loss: 0.1076 | ds_loss: 0.0000 | lr: 2.9610e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3732/  8460 | global iter:   3732/  8460 | loss: 0.2422 | ds_loss: 0.0000 | lr: 2.9601e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3732/  8460 | global iter:   3732/  8460 | loss: 0.1922 | ds_loss: 0.0000 | lr: 2.9601e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3733/  8460 | global iter:   3733/  8460 | loss: 0.4068 | ds_loss: 0.0000 | lr: 2.9592e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3734/  8460 | global iter:   3734/  8460 | loss: 0.0335 | ds_loss: 0.0000 | lr: 2.9583e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3735/  8460 | global iter:   3735/  8460 | loss: 0.3250 | ds_loss: 0.0000 | lr: 2.9574e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3736/  8460 | global iter:   3736/  8460 | loss: 0.1654 | ds_loss: 0.0000 | lr: 2.9565e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3736/  8460 | global iter:   3736/  8460 | loss: 0.2327 | ds_loss: 0.0000 | lr: 2.9565e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3737/  8460 | global iter:   3737/  8460 | loss: 0.1816 | ds_loss: 0.0000 | lr: 2.9555e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3738/  8460 | global iter:   3738/  8460 | loss: 0.2020 | ds_loss: 0.0000 | lr: 2.9546e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3739/  8460 | global iter:   3739/  8460 | loss: 0.3062 | ds_loss: 0.0000 | lr: 2.9537e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3740/  8460 | global iter:   3740/  8460 | loss: 0.3099 | ds_loss: 0.0000 | lr: 2.9528e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3740/  8460 | global iter:   3740/  8460 | loss: 0.2499 | ds_loss: 0.0000 | lr: 2.9528e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3741/  8460 | global iter:   3741/  8460 | loss: 0.1685 | ds_loss: 0.0000 | lr: 2.9519e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3742/  8460 | global iter:   3742/  8460 | loss: 0.2602 | ds_loss: 0.0000 | lr: 2.9510e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3743/  8460 | global iter:   3743/  8460 | loss: 0.2644 | ds_loss: 0.0000 | lr: 2.9501e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3744/  8460 | global iter:   3744/  8460 | loss: 0.1693 | ds_loss: 0.0000 | lr: 2.9492e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3744/  8460 | global iter:   3744/  8460 | loss: 0.2156 | ds_loss: 0.0000 | lr: 2.9492e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3745/  8460 | global iter:   3745/  8460 | loss: 0.1672 | ds_loss: 0.0000 | lr: 2.9482e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3746/  8460 | global iter:   3746/  8460 | loss: 0.6307 | ds_loss: 0.0000 | lr: 2.9473e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3747/  8460 | global iter:   3747/  8460 | loss: 0.0674 | ds_loss: 0.0000 | lr: 2.9464e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3748/  8460 | global iter:   3748/  8460 | loss: 0.7077 | ds_loss: 0.0000 | lr: 2.9455e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3748/  8460 | global iter:   3748/  8460 | loss: 0.3933 | ds_loss: 0.0000 | lr: 2.9455e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3749/  8460 | global iter:   3749/  8460 | loss: 0.5405 | ds_loss: 0.0000 | lr: 2.9446e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3750/  8460 | global iter:   3750/  8460 | loss: 0.0326 | ds_loss: 0.0000 | lr: 2.9437e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3751/  8460 | global iter:   3751/  8460 | loss: 0.3362 | ds_loss: 0.0000 | lr: 2.9428e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3752/  8460 | global iter:   3752/  8460 | loss: 0.3388 | ds_loss: 0.0000 | lr: 2.9418e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3752/  8460 | global iter:   3752/  8460 | loss: 0.3120 | ds_loss: 0.0000 | lr: 2.9418e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3753/  8460 | global iter:   3753/  8460 | loss: 0.4295 | ds_loss: 0.0000 | lr: 2.9409e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3754/  8460 | global iter:   3754/  8460 | loss: 0.5436 | ds_loss: 0.0000 | lr: 2.9400e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3755/  8460 | global iter:   3755/  8460 | loss: 0.3354 | ds_loss: 0.0000 | lr: 2.9391e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3756/  8460 | global iter:   3756/  8460 | loss: 0.2447 | ds_loss: 0.0000 | lr: 2.9382e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3756/  8460 | global iter:   3756/  8460 | loss: 0.3883 | ds_loss: 0.0000 | lr: 2.9382e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3757/  8460 | global iter:   3757/  8460 | loss: 0.1294 | ds_loss: 0.0000 | lr: 2.9373e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3758/  8460 | global iter:   3758/  8460 | loss: 0.3640 | ds_loss: 0.0000 | lr: 2.9364e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3759/  8460 | global iter:   3759/  8460 | loss: 0.2781 | ds_loss: 0.0000 | lr: 2.9354e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3760/  8460 | global iter:   3760/  8460 | loss: 0.2014 | ds_loss: 0.0000 | lr: 2.9345e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3760/  8460 | global iter:   3760/  8460 | loss: 0.2432 | ds_loss: 0.0000 | lr: 2.9345e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3761/  8460 | global iter:   3761/  8460 | loss: 0.4223 | ds_loss: 0.0000 | lr: 2.9336e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3762/  8460 | global iter:   3762/  8460 | loss: 0.4641 | ds_loss: 0.0000 | lr: 2.9327e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3763/  8460 | global iter:   3763/  8460 | loss: 0.6520 | ds_loss: 0.0000 | lr: 2.9318e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3764/  8460 | global iter:   3764/  8460 | loss: 0.2550 | ds_loss: 0.0000 | lr: 2.9309e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3764/  8460 | global iter:   3764/  8460 | loss: 0.4484 | ds_loss: 0.0000 | lr: 2.9309e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3765/  8460 | global iter:   3765/  8460 | loss: 0.6674 | ds_loss: 0.0000 | lr: 2.9300e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3766/  8460 | global iter:   3766/  8460 | loss: 0.1313 | ds_loss: 0.0000 | lr: 2.9290e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3767/  8460 | global iter:   3767/  8460 | loss: 0.2083 | ds_loss: 0.0000 | lr: 2.9281e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3768/  8460 | global iter:   3768/  8460 | loss: 0.5263 | ds_loss: 0.0000 | lr: 2.9272e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3768/  8460 | global iter:   3768/  8460 | loss: 0.3833 | ds_loss: 0.0000 | lr: 2.9272e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3769/  8460 | global iter:   3769/  8460 | loss: 0.2952 | ds_loss: 0.0000 | lr: 2.9263e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3770/  8460 | global iter:   3770/  8460 | loss: 0.0506 | ds_loss: 0.0000 | lr: 2.9254e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3771/  8460 | global iter:   3771/  8460 | loss: 0.5527 | ds_loss: 0.0000 | lr: 2.9245e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3772/  8460 | global iter:   3772/  8460 | loss: 0.6549 | ds_loss: 0.0000 | lr: 2.9236e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3772/  8460 | global iter:   3772/  8460 | loss: 0.3883 | ds_loss: 0.0000 | lr: 2.9236e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3773/  8460 | global iter:   3773/  8460 | loss: 0.1810 | ds_loss: 0.0000 | lr: 2.9226e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3774/  8460 | global iter:   3774/  8460 | loss: 0.1192 | ds_loss: 0.0000 | lr: 2.9217e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3775/  8460 | global iter:   3775/  8460 | loss: 0.4148 | ds_loss: 0.0000 | lr: 2.9208e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3776/  8460 | global iter:   3776/  8460 | loss: 0.0170 | ds_loss: 0.0000 | lr: 2.9199e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3776/  8460 | global iter:   3776/  8460 | loss: 0.1830 | ds_loss: 0.0000 | lr: 2.9199e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3777/  8460 | global iter:   3777/  8460 | loss: 0.6864 | ds_loss: 0.0000 | lr: 2.9190e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3778/  8460 | global iter:   3778/  8460 | loss: 0.3261 | ds_loss: 0.0000 | lr: 2.9181e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3779/  8460 | global iter:   3779/  8460 | loss: 0.5966 | ds_loss: 0.0000 | lr: 2.9172e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3780/  8460 | global iter:   3780/  8460 | loss: 0.1455 | ds_loss: 0.0000 | lr: 2.9162e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3780/  8460 | global iter:   3780/  8460 | loss: 0.4387 | ds_loss: 0.0000 | lr: 2.9162e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3781/  8460 | global iter:   3781/  8460 | loss: 0.2584 | ds_loss: 0.0000 | lr: 2.9153e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3782/  8460 | global iter:   3782/  8460 | loss: 0.3970 | ds_loss: 0.0000 | lr: 2.9144e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3783/  8460 | global iter:   3783/  8460 | loss: 0.6407 | ds_loss: 0.0000 | lr: 2.9135e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3784/  8460 | global iter:   3784/  8460 | loss: 0.4108 | ds_loss: 0.0000 | lr: 2.9126e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3784/  8460 | global iter:   3784/  8460 | loss: 0.4267 | ds_loss: 0.0000 | lr: 2.9126e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3785/  8460 | global iter:   3785/  8460 | loss: 0.3243 | ds_loss: 0.0000 | lr: 2.9117e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3786/  8460 | global iter:   3786/  8460 | loss: 0.1655 | ds_loss: 0.0000 | lr: 2.9107e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3787/  8460 | global iter:   3787/  8460 | loss: 0.4007 | ds_loss: 0.0000 | lr: 2.9098e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3788/  8460 | global iter:   3788/  8460 | loss: 0.2523 | ds_loss: 0.0000 | lr: 2.9089e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3788/  8460 | global iter:   3788/  8460 | loss: 0.2857 | ds_loss: 0.0000 | lr: 2.9089e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3789/  8460 | global iter:   3789/  8460 | loss: 0.1050 | ds_loss: 0.0000 | lr: 2.9080e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3790/  8460 | global iter:   3790/  8460 | loss: 0.4401 | ds_loss: 0.0000 | lr: 2.9071e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3791/  8460 | global iter:   3791/  8460 | loss: 0.2082 | ds_loss: 0.0000 | lr: 2.9062e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3792/  8460 | global iter:   3792/  8460 | loss: 0.4828 | ds_loss: 0.0000 | lr: 2.9053e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3792/  8460 | global iter:   3792/  8460 | loss: 0.3090 | ds_loss: 0.0000 | lr: 2.9053e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3793/  8460 | global iter:   3793/  8460 | loss: 0.2513 | ds_loss: 0.0000 | lr: 2.9043e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3794/  8460 | global iter:   3794/  8460 | loss: 0.2655 | ds_loss: 0.0000 | lr: 2.9034e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3795/  8460 | global iter:   3795/  8460 | loss: 0.1094 | ds_loss: 0.0000 | lr: 2.9025e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3796/  8460 | global iter:   3796/  8460 | loss: 0.0923 | ds_loss: 0.0000 | lr: 2.9016e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3796/  8460 | global iter:   3796/  8460 | loss: 0.1796 | ds_loss: 0.0000 | lr: 2.9016e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3797/  8460 | global iter:   3797/  8460 | loss: 0.1575 | ds_loss: 0.0000 | lr: 2.9007e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3798/  8460 | global iter:   3798/  8460 | loss: 0.3312 | ds_loss: 0.0000 | lr: 2.8998e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3799/  8460 | global iter:   3799/  8460 | loss: 0.5150 | ds_loss: 0.0000 | lr: 2.8988e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3800/  8460 | global iter:   3800/  8460 | loss: 0.2600 | ds_loss: 0.0000 | lr: 2.8979e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3800/  8460 | global iter:   3800/  8460 | loss: 0.3159 | ds_loss: 0.0000 | lr: 2.8979e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3801/  8460 | global iter:   3801/  8460 | loss: 0.1921 | ds_loss: 0.0000 | lr: 2.8970e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3802/  8460 | global iter:   3802/  8460 | loss: 0.2344 | ds_loss: 0.0000 | lr: 2.8961e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3803/  8460 | global iter:   3803/  8460 | loss: 0.0617 | ds_loss: 0.0000 | lr: 2.8952e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3804/  8460 | global iter:   3804/  8460 | loss: 0.1451 | ds_loss: 0.0000 | lr: 2.8943e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3804/  8460 | global iter:   3804/  8460 | loss: 0.1583 | ds_loss: 0.0000 | lr: 2.8943e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3805/  8460 | global iter:   3805/  8460 | loss: 0.1251 | ds_loss: 0.0000 | lr: 2.8933e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3806/  8460 | global iter:   3806/  8460 | loss: 0.2232 | ds_loss: 0.0000 | lr: 2.8924e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3807/  8460 | global iter:   3807/  8460 | loss: 0.7109 | ds_loss: 0.0000 | lr: 2.8915e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3808/  8460 | global iter:   3808/  8460 | loss: 0.5080 | ds_loss: 0.0000 | lr: 2.8906e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3808/  8460 | global iter:   3808/  8460 | loss: 0.3918 | ds_loss: 0.0000 | lr: 2.8906e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3809/  8460 | global iter:   3809/  8460 | loss: 0.4883 | ds_loss: 0.0000 | lr: 2.8897e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3810/  8460 | global iter:   3810/  8460 | loss: 0.3001 | ds_loss: 0.0000 | lr: 2.8888e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3811/  8460 | global iter:   3811/  8460 | loss: 0.6381 | ds_loss: 0.0000 | lr: 2.8878e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3812/  8460 | global iter:   3812/  8460 | loss: 0.2748 | ds_loss: 0.0000 | lr: 2.8869e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3812/  8460 | global iter:   3812/  8460 | loss: 0.4253 | ds_loss: 0.0000 | lr: 2.8869e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3813/  8460 | global iter:   3813/  8460 | loss: 0.0838 | ds_loss: 0.0000 | lr: 2.8860e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3814/  8460 | global iter:   3814/  8460 | loss: 0.2200 | ds_loss: 0.0000 | lr: 2.8851e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3815/  8460 | global iter:   3815/  8460 | loss: 0.1327 | ds_loss: 0.0000 | lr: 2.8842e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3816/  8460 | global iter:   3816/  8460 | loss: 0.1534 | ds_loss: 0.0000 | lr: 2.8833e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3816/  8460 | global iter:   3816/  8460 | loss: 0.1475 | ds_loss: 0.0000 | lr: 2.8833e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3817/  8460 | global iter:   3817/  8460 | loss: 0.4269 | ds_loss: 0.0000 | lr: 2.8823e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3818/  8460 | global iter:   3818/  8460 | loss: 0.1576 | ds_loss: 0.0000 | lr: 2.8814e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3819/  8460 | global iter:   3819/  8460 | loss: 0.4689 | ds_loss: 0.0000 | lr: 2.8805e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3820/  8460 | global iter:   3820/  8460 | loss: 0.4213 | ds_loss: 0.0000 | lr: 2.8796e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3820/  8460 | global iter:   3820/  8460 | loss: 0.3687 | ds_loss: 0.0000 | lr: 2.8796e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3821/  8460 | global iter:   3821/  8460 | loss: 0.1780 | ds_loss: 0.0000 | lr: 2.8787e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3822/  8460 | global iter:   3822/  8460 | loss: 0.0997 | ds_loss: 0.0000 | lr: 2.8778e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3823/  8460 | global iter:   3823/  8460 | loss: 0.7532 | ds_loss: 0.0000 | lr: 2.8768e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3824/  8460 | global iter:   3824/  8460 | loss: 0.2253 | ds_loss: 0.0000 | lr: 2.8759e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3824/  8460 | global iter:   3824/  8460 | loss: 0.3140 | ds_loss: 0.0000 | lr: 2.8759e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3825/  8460 | global iter:   3825/  8460 | loss: 0.1137 | ds_loss: 0.0000 | lr: 2.8750e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3826/  8460 | global iter:   3826/  8460 | loss: 0.1671 | ds_loss: 0.0000 | lr: 2.8741e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3827/  8460 | global iter:   3827/  8460 | loss: 0.1237 | ds_loss: 0.0000 | lr: 2.8732e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3828/  8460 | global iter:   3828/  8460 | loss: 0.3536 | ds_loss: 0.0000 | lr: 2.8722e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3828/  8460 | global iter:   3828/  8460 | loss: 0.1895 | ds_loss: 0.0000 | lr: 2.8722e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3829/  8460 | global iter:   3829/  8460 | loss: 0.1455 | ds_loss: 0.0000 | lr: 2.8713e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3830/  8460 | global iter:   3830/  8460 | loss: 0.1296 | ds_loss: 0.0000 | lr: 2.8704e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3831/  8460 | global iter:   3831/  8460 | loss: 0.3008 | ds_loss: 0.0000 | lr: 2.8695e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3832/  8460 | global iter:   3832/  8460 | loss: 0.5573 | ds_loss: 0.0000 | lr: 2.8686e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3832/  8460 | global iter:   3832/  8460 | loss: 0.2833 | ds_loss: 0.0000 | lr: 2.8686e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3833/  8460 | global iter:   3833/  8460 | loss: 0.7627 | ds_loss: 0.0000 | lr: 2.8677e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3834/  8460 | global iter:   3834/  8460 | loss: 0.1556 | ds_loss: 0.0000 | lr: 2.8667e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3835/  8460 | global iter:   3835/  8460 | loss: 0.0602 | ds_loss: 0.0000 | lr: 2.8658e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3836/  8460 | global iter:   3836/  8460 | loss: 0.0901 | ds_loss: 0.0000 | lr: 2.8649e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3836/  8460 | global iter:   3836/  8460 | loss: 0.2672 | ds_loss: 0.0000 | lr: 2.8649e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3837/  8460 | global iter:   3837/  8460 | loss: 0.8202 | ds_loss: 0.0000 | lr: 2.8640e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3838/  8460 | global iter:   3838/  8460 | loss: 0.2016 | ds_loss: 0.0000 | lr: 2.8631e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3839/  8460 | global iter:   3839/  8460 | loss: 0.2701 | ds_loss: 0.0000 | lr: 2.8621e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3840/  8460 | global iter:   3840/  8460 | loss: 0.5089 | ds_loss: 0.0000 | lr: 2.8612e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3840/  8460 | global iter:   3840/  8460 | loss: 0.4502 | ds_loss: 0.0000 | lr: 2.8612e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3841/  8460 | global iter:   3841/  8460 | loss: 0.3953 | ds_loss: 0.0000 | lr: 2.8603e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3842/  8460 | global iter:   3842/  8460 | loss: 0.3126 | ds_loss: 0.0000 | lr: 2.8594e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3843/  8460 | global iter:   3843/  8460 | loss: 0.3164 | ds_loss: 0.0000 | lr: 2.8585e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3844/  8460 | global iter:   3844/  8460 | loss: 0.3801 | ds_loss: 0.0000 | lr: 2.8576e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3844/  8460 | global iter:   3844/  8460 | loss: 0.3511 | ds_loss: 0.0000 | lr: 2.8576e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3845/  8460 | global iter:   3845/  8460 | loss: 0.2552 | ds_loss: 0.0000 | lr: 2.8566e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3846/  8460 | global iter:   3846/  8460 | loss: 0.9125 | ds_loss: 0.0000 | lr: 2.8557e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3847/  8460 | global iter:   3847/  8460 | loss: 0.1505 | ds_loss: 0.0000 | lr: 2.8548e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3848/  8460 | global iter:   3848/  8460 | loss: 0.1994 | ds_loss: 0.0000 | lr: 2.8539e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3848/  8460 | global iter:   3848/  8460 | loss: 0.3794 | ds_loss: 0.0000 | lr: 2.8539e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3849/  8460 | global iter:   3849/  8460 | loss: 0.5478 | ds_loss: 0.0000 | lr: 2.8530e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3850/  8460 | global iter:   3850/  8460 | loss: 0.2040 | ds_loss: 0.0000 | lr: 2.8520e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3851/  8460 | global iter:   3851/  8460 | loss: 0.3530 | ds_loss: 0.0000 | lr: 2.8511e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3852/  8460 | global iter:   3852/  8460 | loss: 0.3067 | ds_loss: 0.0000 | lr: 2.8502e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3852/  8460 | global iter:   3852/  8460 | loss: 0.3529 | ds_loss: 0.0000 | lr: 2.8502e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3853/  8460 | global iter:   3853/  8460 | loss: 0.1631 | ds_loss: 0.0000 | lr: 2.8493e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3854/  8460 | global iter:   3854/  8460 | loss: 0.2137 | ds_loss: 0.0000 | lr: 2.8484e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3855/  8460 | global iter:   3855/  8460 | loss: 0.1540 | ds_loss: 0.0000 | lr: 2.8474e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3856/  8460 | global iter:   3856/  8460 | loss: 0.1862 | ds_loss: 0.0000 | lr: 2.8465e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3856/  8460 | global iter:   3856/  8460 | loss: 0.1792 | ds_loss: 0.0000 | lr: 2.8465e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3857/  8460 | global iter:   3857/  8460 | loss: 0.4159 | ds_loss: 0.0000 | lr: 2.8456e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3858/  8460 | global iter:   3858/  8460 | loss: 0.2499 | ds_loss: 0.0000 | lr: 2.8447e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3859/  8460 | global iter:   3859/  8460 | loss: 0.1267 | ds_loss: 0.0000 | lr: 2.8438e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3860/  8460 | global iter:   3860/  8460 | loss: 0.1968 | ds_loss: 0.0000 | lr: 2.8428e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3860/  8460 | global iter:   3860/  8460 | loss: 0.2474 | ds_loss: 0.0000 | lr: 2.8428e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3861/  8460 | global iter:   3861/  8460 | loss: 0.3129 | ds_loss: 0.0000 | lr: 2.8419e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3862/  8460 | global iter:   3862/  8460 | loss: 0.3411 | ds_loss: 0.0000 | lr: 2.8410e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3863/  8460 | global iter:   3863/  8460 | loss: 0.5631 | ds_loss: 0.0000 | lr: 2.8401e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3864/  8460 | global iter:   3864/  8460 | loss: 0.2500 | ds_loss: 0.0000 | lr: 2.8392e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3864/  8460 | global iter:   3864/  8460 | loss: 0.3668 | ds_loss: 0.0000 | lr: 2.8392e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3865/  8460 | global iter:   3865/  8460 | loss: 0.1475 | ds_loss: 0.0000 | lr: 2.8382e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3866/  8460 | global iter:   3866/  8460 | loss: 0.4338 | ds_loss: 0.0000 | lr: 2.8373e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3867/  8460 | global iter:   3867/  8460 | loss: 0.2786 | ds_loss: 0.0000 | lr: 2.8364e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3868/  8460 | global iter:   3868/  8460 | loss: 0.4895 | ds_loss: 0.0000 | lr: 2.8355e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3868/  8460 | global iter:   3868/  8460 | loss: 0.3373 | ds_loss: 0.0000 | lr: 2.8355e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3869/  8460 | global iter:   3869/  8460 | loss: 0.3714 | ds_loss: 0.0000 | lr: 2.8346e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3870/  8460 | global iter:   3870/  8460 | loss: 0.2544 | ds_loss: 0.0000 | lr: 2.8337e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3871/  8460 | global iter:   3871/  8460 | loss: 0.4058 | ds_loss: 0.0000 | lr: 2.8327e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3872/  8460 | global iter:   3872/  8460 | loss: 0.2928 | ds_loss: 0.0000 | lr: 2.8318e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3872/  8460 | global iter:   3872/  8460 | loss: 0.3311 | ds_loss: 0.0000 | lr: 2.8318e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3873/  8460 | global iter:   3873/  8460 | loss: 0.1128 | ds_loss: 0.0000 | lr: 2.8309e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.000
train | epoch   4 | Iter:   3874/  8460 | global iter:   3874/  8460 | loss: 0.0721 | ds_loss: 0.0000 | lr: 2.8300e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.000
train | epoch   4 | Iter:   3875/  8460 | global iter:   3875/  8460 | loss: 0.3978 | ds_loss: 0.0000 | lr: 2.8291e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3876/  8460 | global iter:   3876/  8460 | loss: 0.6242 | ds_loss: 0.0000 | lr: 2.8281e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3876/  8460 | global iter:   3876/  8460 | loss: 0.3017 | ds_loss: 0.0000 | lr: 2.8281e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3877/  8460 | global iter:   3877/  8460 | loss: 0.0529 | ds_loss: 0.0000 | lr: 2.8272e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3878/  8460 | global iter:   3878/  8460 | loss: 0.0562 | ds_loss: 0.0000 | lr: 2.8263e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3879/  8460 | global iter:   3879/  8460 | loss: 0.1984 | ds_loss: 0.0000 | lr: 2.8254e-04 | scale:     1.0000 | micro time: 0.431 | step time: 0.000
train | epoch   4 | Iter:   3880/  8460 | global iter:   3880/  8460 | loss: 0.2923 | ds_loss: 0.0000 | lr: 2.8244e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3880/  8460 | global iter:   3880/  8460 | loss: 0.1500 | ds_loss: 0.0000 | lr: 2.8244e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3881/  8460 | global iter:   3881/  8460 | loss: 0.3990 | ds_loss: 0.0000 | lr: 2.8235e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3882/  8460 | global iter:   3882/  8460 | loss: 0.2720 | ds_loss: 0.0000 | lr: 2.8226e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3883/  8460 | global iter:   3883/  8460 | loss: 0.3378 | ds_loss: 0.0000 | lr: 2.8217e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3884/  8460 | global iter:   3884/  8460 | loss: 0.2370 | ds_loss: 0.0000 | lr: 2.8208e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3884/  8460 | global iter:   3884/  8460 | loss: 0.3114 | ds_loss: 0.0000 | lr: 2.8208e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3885/  8460 | global iter:   3885/  8460 | loss: 0.0578 | ds_loss: 0.0000 | lr: 2.8198e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3886/  8460 | global iter:   3886/  8460 | loss: 0.5448 | ds_loss: 0.0000 | lr: 2.8189e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3887/  8460 | global iter:   3887/  8460 | loss: 0.4533 | ds_loss: 0.0000 | lr: 2.8180e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3888/  8460 | global iter:   3888/  8460 | loss: 0.1734 | ds_loss: 0.0000 | lr: 2.8171e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3888/  8460 | global iter:   3888/  8460 | loss: 0.3073 | ds_loss: 0.0000 | lr: 2.8171e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3889/  8460 | global iter:   3889/  8460 | loss: 0.2167 | ds_loss: 0.0000 | lr: 2.8162e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3890/  8460 | global iter:   3890/  8460 | loss: 0.3266 | ds_loss: 0.0000 | lr: 2.8152e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3891/  8460 | global iter:   3891/  8460 | loss: 0.2294 | ds_loss: 0.0000 | lr: 2.8143e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3892/  8460 | global iter:   3892/  8460 | loss: 0.5046 | ds_loss: 0.0000 | lr: 2.8134e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3892/  8460 | global iter:   3892/  8460 | loss: 0.3193 | ds_loss: 0.0000 | lr: 2.8134e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3893/  8460 | global iter:   3893/  8460 | loss: 0.2651 | ds_loss: 0.0000 | lr: 2.8125e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3894/  8460 | global iter:   3894/  8460 | loss: 0.3645 | ds_loss: 0.0000 | lr: 2.8116e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3895/  8460 | global iter:   3895/  8460 | loss: 0.3048 | ds_loss: 0.0000 | lr: 2.8106e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3896/  8460 | global iter:   3896/  8460 | loss: 0.1724 | ds_loss: 0.0000 | lr: 2.8097e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3896/  8460 | global iter:   3896/  8460 | loss: 0.2767 | ds_loss: 0.0000 | lr: 2.8097e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3897/  8460 | global iter:   3897/  8460 | loss: 0.1238 | ds_loss: 0.0000 | lr: 2.8088e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3898/  8460 | global iter:   3898/  8460 | loss: 0.3973 | ds_loss: 0.0000 | lr: 2.8079e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3899/  8460 | global iter:   3899/  8460 | loss: 0.0889 | ds_loss: 0.0000 | lr: 2.8070e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3900/  8460 | global iter:   3900/  8460 | loss: 0.2848 | ds_loss: 0.0000 | lr: 2.8060e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3900/  8460 | global iter:   3900/  8460 | loss: 0.2237 | ds_loss: 0.0000 | lr: 2.8060e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3901/  8460 | global iter:   3901/  8460 | loss: 0.1020 | ds_loss: 0.0000 | lr: 2.8051e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3902/  8460 | global iter:   3902/  8460 | loss: 0.3881 | ds_loss: 0.0000 | lr: 2.8042e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3903/  8460 | global iter:   3903/  8460 | loss: 0.1242 | ds_loss: 0.0000 | lr: 2.8033e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3904/  8460 | global iter:   3904/  8460 | loss: 0.4966 | ds_loss: 0.0000 | lr: 2.8023e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3904/  8460 | global iter:   3904/  8460 | loss: 0.2777 | ds_loss: 0.0000 | lr: 2.8023e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3905/  8460 | global iter:   3905/  8460 | loss: 0.3030 | ds_loss: 0.0000 | lr: 2.8014e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3906/  8460 | global iter:   3906/  8460 | loss: 0.2046 | ds_loss: 0.0000 | lr: 2.8005e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3907/  8460 | global iter:   3907/  8460 | loss: 0.2883 | ds_loss: 0.0000 | lr: 2.7996e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3908/  8460 | global iter:   3908/  8460 | loss: 0.2853 | ds_loss: 0.0000 | lr: 2.7987e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3908/  8460 | global iter:   3908/  8460 | loss: 0.2703 | ds_loss: 0.0000 | lr: 2.7987e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3909/  8460 | global iter:   3909/  8460 | loss: 0.1528 | ds_loss: 0.0000 | lr: 2.7977e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3910/  8460 | global iter:   3910/  8460 | loss: 0.2965 | ds_loss: 0.0000 | lr: 2.7968e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3911/  8460 | global iter:   3911/  8460 | loss: 0.4422 | ds_loss: 0.0000 | lr: 2.7959e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3912/  8460 | global iter:   3912/  8460 | loss: 0.1292 | ds_loss: 0.0000 | lr: 2.7950e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3912/  8460 | global iter:   3912/  8460 | loss: 0.2552 | ds_loss: 0.0000 | lr: 2.7950e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3913/  8460 | global iter:   3913/  8460 | loss: 0.1273 | ds_loss: 0.0000 | lr: 2.7941e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3914/  8460 | global iter:   3914/  8460 | loss: 0.1283 | ds_loss: 0.0000 | lr: 2.7931e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3915/  8460 | global iter:   3915/  8460 | loss: 0.2937 | ds_loss: 0.0000 | lr: 2.7922e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3916/  8460 | global iter:   3916/  8460 | loss: 0.2084 | ds_loss: 0.0000 | lr: 2.7913e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3916/  8460 | global iter:   3916/  8460 | loss: 0.1895 | ds_loss: 0.0000 | lr: 2.7913e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3917/  8460 | global iter:   3917/  8460 | loss: 0.3564 | ds_loss: 0.0000 | lr: 2.7904e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3918/  8460 | global iter:   3918/  8460 | loss: 0.5497 | ds_loss: 0.0000 | lr: 2.7894e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3919/  8460 | global iter:   3919/  8460 | loss: 0.0769 | ds_loss: 0.0000 | lr: 2.7885e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3920/  8460 | global iter:   3920/  8460 | loss: 0.2180 | ds_loss: 0.0000 | lr: 2.7876e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3920/  8460 | global iter:   3920/  8460 | loss: 0.3002 | ds_loss: 0.0000 | lr: 2.7876e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3921/  8460 | global iter:   3921/  8460 | loss: 0.4431 | ds_loss: 0.0000 | lr: 2.7867e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3922/  8460 | global iter:   3922/  8460 | loss: 0.1442 | ds_loss: 0.0000 | lr: 2.7858e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3923/  8460 | global iter:   3923/  8460 | loss: 0.1111 | ds_loss: 0.0000 | lr: 2.7848e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3924/  8460 | global iter:   3924/  8460 | loss: 0.3590 | ds_loss: 0.0000 | lr: 2.7839e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3924/  8460 | global iter:   3924/  8460 | loss: 0.2644 | ds_loss: 0.0000 | lr: 2.7839e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3925/  8460 | global iter:   3925/  8460 | loss: 0.2514 | ds_loss: 0.0000 | lr: 2.7830e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3926/  8460 | global iter:   3926/  8460 | loss: 0.4545 | ds_loss: 0.0000 | lr: 2.7821e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3927/  8460 | global iter:   3927/  8460 | loss: 0.4809 | ds_loss: 0.0000 | lr: 2.7811e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3928/  8460 | global iter:   3928/  8460 | loss: 0.0705 | ds_loss: 0.0000 | lr: 2.7802e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3928/  8460 | global iter:   3928/  8460 | loss: 0.3143 | ds_loss: 0.0000 | lr: 2.7802e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3929/  8460 | global iter:   3929/  8460 | loss: 0.1585 | ds_loss: 0.0000 | lr: 2.7793e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3930/  8460 | global iter:   3930/  8460 | loss: 0.1207 | ds_loss: 0.0000 | lr: 2.7784e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3931/  8460 | global iter:   3931/  8460 | loss: 0.2200 | ds_loss: 0.0000 | lr: 2.7775e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3932/  8460 | global iter:   3932/  8460 | loss: 0.2282 | ds_loss: 0.0000 | lr: 2.7765e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3932/  8460 | global iter:   3932/  8460 | loss: 0.1819 | ds_loss: 0.0000 | lr: 2.7765e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3933/  8460 | global iter:   3933/  8460 | loss: 0.6200 | ds_loss: 0.0000 | lr: 2.7756e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3934/  8460 | global iter:   3934/  8460 | loss: 0.3037 | ds_loss: 0.0000 | lr: 2.7747e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3935/  8460 | global iter:   3935/  8460 | loss: 0.1729 | ds_loss: 0.0000 | lr: 2.7738e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3936/  8460 | global iter:   3936/  8460 | loss: 0.3451 | ds_loss: 0.0000 | lr: 2.7728e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3936/  8460 | global iter:   3936/  8460 | loss: 0.3604 | ds_loss: 0.0000 | lr: 2.7728e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3937/  8460 | global iter:   3937/  8460 | loss: 0.1060 | ds_loss: 0.0000 | lr: 2.7719e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3938/  8460 | global iter:   3938/  8460 | loss: 0.4729 | ds_loss: 0.0000 | lr: 2.7710e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3939/  8460 | global iter:   3939/  8460 | loss: 0.1378 | ds_loss: 0.0000 | lr: 2.7701e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3940/  8460 | global iter:   3940/  8460 | loss: 0.1885 | ds_loss: 0.0000 | lr: 2.7692e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3940/  8460 | global iter:   3940/  8460 | loss: 0.2263 | ds_loss: 0.0000 | lr: 2.7692e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3941/  8460 | global iter:   3941/  8460 | loss: 0.5838 | ds_loss: 0.0000 | lr: 2.7682e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3942/  8460 | global iter:   3942/  8460 | loss: 0.0853 | ds_loss: 0.0000 | lr: 2.7673e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3943/  8460 | global iter:   3943/  8460 | loss: 0.3666 | ds_loss: 0.0000 | lr: 2.7664e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3944/  8460 | global iter:   3944/  8460 | loss: 0.1464 | ds_loss: 0.0000 | lr: 2.7655e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3944/  8460 | global iter:   3944/  8460 | loss: 0.2955 | ds_loss: 0.0000 | lr: 2.7655e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3945/  8460 | global iter:   3945/  8460 | loss: 0.2347 | ds_loss: 0.0000 | lr: 2.7645e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3946/  8460 | global iter:   3946/  8460 | loss: 0.6109 | ds_loss: 0.0000 | lr: 2.7636e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3947/  8460 | global iter:   3947/  8460 | loss: 0.3082 | ds_loss: 0.0000 | lr: 2.7627e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3948/  8460 | global iter:   3948/  8460 | loss: 0.5747 | ds_loss: 0.0000 | lr: 2.7618e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3948/  8460 | global iter:   3948/  8460 | loss: 0.4321 | ds_loss: 0.0000 | lr: 2.7618e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3949/  8460 | global iter:   3949/  8460 | loss: 0.0892 | ds_loss: 0.0000 | lr: 2.7608e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3950/  8460 | global iter:   3950/  8460 | loss: 0.3363 | ds_loss: 0.0000 | lr: 2.7599e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3951/  8460 | global iter:   3951/  8460 | loss: 0.2007 | ds_loss: 0.0000 | lr: 2.7590e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3952/  8460 | global iter:   3952/  8460 | loss: 0.3016 | ds_loss: 0.0000 | lr: 2.7581e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3952/  8460 | global iter:   3952/  8460 | loss: 0.2320 | ds_loss: 0.0000 | lr: 2.7581e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3953/  8460 | global iter:   3953/  8460 | loss: 0.4376 | ds_loss: 0.0000 | lr: 2.7572e-04 | scale:     1.0000 | micro time: 0.437 | step time: 0.000
train | epoch   4 | Iter:   3954/  8460 | global iter:   3954/  8460 | loss: 0.1495 | ds_loss: 0.0000 | lr: 2.7562e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3955/  8460 | global iter:   3955/  8460 | loss: 0.2989 | ds_loss: 0.0000 | lr: 2.7553e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3956/  8460 | global iter:   3956/  8460 | loss: 0.1569 | ds_loss: 0.0000 | lr: 2.7544e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3956/  8460 | global iter:   3956/  8460 | loss: 0.2607 | ds_loss: 0.0000 | lr: 2.7544e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.430
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3957/  8460 | global iter:   3957/  8460 | loss: 0.3385 | ds_loss: 0.0000 | lr: 2.7535e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3958/  8460 | global iter:   3958/  8460 | loss: 0.1641 | ds_loss: 0.0000 | lr: 2.7525e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3959/  8460 | global iter:   3959/  8460 | loss: 0.2071 | ds_loss: 0.0000 | lr: 2.7516e-04 | scale:     1.0000 | micro time: 0.435 | step time: 0.000
train | epoch   4 | Iter:   3960/  8460 | global iter:   3960/  8460 | loss: 0.6080 | ds_loss: 0.0000 | lr: 2.7507e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3960/  8460 | global iter:   3960/  8460 | loss: 0.3294 | ds_loss: 0.0000 | lr: 2.7507e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.430
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3961/  8460 | global iter:   3961/  8460 | loss: 0.1183 | ds_loss: 0.0000 | lr: 2.7498e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3962/  8460 | global iter:   3962/  8460 | loss: 0.1963 | ds_loss: 0.0000 | lr: 2.7488e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3963/  8460 | global iter:   3963/  8460 | loss: 0.1264 | ds_loss: 0.0000 | lr: 2.7479e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3964/  8460 | global iter:   3964/  8460 | loss: 0.3357 | ds_loss: 0.0000 | lr: 2.7470e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3964/  8460 | global iter:   3964/  8460 | loss: 0.1942 | ds_loss: 0.0000 | lr: 2.7470e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3965/  8460 | global iter:   3965/  8460 | loss: 0.1629 | ds_loss: 0.0000 | lr: 2.7461e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3966/  8460 | global iter:   3966/  8460 | loss: 0.1683 | ds_loss: 0.0000 | lr: 2.7451e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3967/  8460 | global iter:   3967/  8460 | loss: 0.5542 | ds_loss: 0.0000 | lr: 2.7442e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3968/  8460 | global iter:   3968/  8460 | loss: 0.1538 | ds_loss: 0.0000 | lr: 2.7433e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3968/  8460 | global iter:   3968/  8460 | loss: 0.2598 | ds_loss: 0.0000 | lr: 2.7433e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3969/  8460 | global iter:   3969/  8460 | loss: 0.1035 | ds_loss: 0.0000 | lr: 2.7424e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3970/  8460 | global iter:   3970/  8460 | loss: 0.2449 | ds_loss: 0.0000 | lr: 2.7415e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3971/  8460 | global iter:   3971/  8460 | loss: 0.3259 | ds_loss: 0.0000 | lr: 2.7405e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3972/  8460 | global iter:   3972/  8460 | loss: 0.2220 | ds_loss: 0.0000 | lr: 2.7396e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3972/  8460 | global iter:   3972/  8460 | loss: 0.2241 | ds_loss: 0.0000 | lr: 2.7396e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3973/  8460 | global iter:   3973/  8460 | loss: 0.2654 | ds_loss: 0.0000 | lr: 2.7387e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3974/  8460 | global iter:   3974/  8460 | loss: 0.1983 | ds_loss: 0.0000 | lr: 2.7378e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3975/  8460 | global iter:   3975/  8460 | loss: 0.3808 | ds_loss: 0.0000 | lr: 2.7368e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3976/  8460 | global iter:   3976/  8460 | loss: 0.3406 | ds_loss: 0.0000 | lr: 2.7359e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3976/  8460 | global iter:   3976/  8460 | loss: 0.2963 | ds_loss: 0.0000 | lr: 2.7359e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3977/  8460 | global iter:   3977/  8460 | loss: 0.1720 | ds_loss: 0.0000 | lr: 2.7350e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3978/  8460 | global iter:   3978/  8460 | loss: 0.2980 | ds_loss: 0.0000 | lr: 2.7341e-04 | scale:     1.0000 | micro time: 0.436 | step time: 0.000
train | epoch   4 | Iter:   3979/  8460 | global iter:   3979/  8460 | loss: 0.3174 | ds_loss: 0.0000 | lr: 2.7331e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   3980/  8460 | global iter:   3980/  8460 | loss: 0.2425 | ds_loss: 0.0000 | lr: 2.7322e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3980/  8460 | global iter:   3980/  8460 | loss: 0.2575 | ds_loss: 0.0000 | lr: 2.7322e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.431
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3981/  8460 | global iter:   3981/  8460 | loss: 0.4614 | ds_loss: 0.0000 | lr: 2.7313e-04 | scale:     1.0000 | micro time: 0.436 | step time: 0.000
train | epoch   4 | Iter:   3982/  8460 | global iter:   3982/  8460 | loss: 0.2992 | ds_loss: 0.0000 | lr: 2.7304e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3983/  8460 | global iter:   3983/  8460 | loss: 0.4539 | ds_loss: 0.0000 | lr: 2.7294e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3984/  8460 | global iter:   3984/  8460 | loss: 0.2570 | ds_loss: 0.0000 | lr: 2.7285e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3984/  8460 | global iter:   3984/  8460 | loss: 0.3679 | ds_loss: 0.0000 | lr: 2.7285e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.430
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3985/  8460 | global iter:   3985/  8460 | loss: 0.2509 | ds_loss: 0.0000 | lr: 2.7276e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3986/  8460 | global iter:   3986/  8460 | loss: 0.2806 | ds_loss: 0.0000 | lr: 2.7267e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3987/  8460 | global iter:   3987/  8460 | loss: 0.4571 | ds_loss: 0.0000 | lr: 2.7257e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3988/  8460 | global iter:   3988/  8460 | loss: 0.2109 | ds_loss: 0.0000 | lr: 2.7248e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3988/  8460 | global iter:   3988/  8460 | loss: 0.2999 | ds_loss: 0.0000 | lr: 2.7248e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3989/  8460 | global iter:   3989/  8460 | loss: 0.1173 | ds_loss: 0.0000 | lr: 2.7239e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3990/  8460 | global iter:   3990/  8460 | loss: 0.0887 | ds_loss: 0.0000 | lr: 2.7230e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3991/  8460 | global iter:   3991/  8460 | loss: 0.2848 | ds_loss: 0.0000 | lr: 2.7220e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3992/  8460 | global iter:   3992/  8460 | loss: 0.3018 | ds_loss: 0.0000 | lr: 2.7211e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3992/  8460 | global iter:   3992/  8460 | loss: 0.1982 | ds_loss: 0.0000 | lr: 2.7211e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3993/  8460 | global iter:   3993/  8460 | loss: 0.4014 | ds_loss: 0.0000 | lr: 2.7202e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3994/  8460 | global iter:   3994/  8460 | loss: 0.2861 | ds_loss: 0.0000 | lr: 2.7193e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   3995/  8460 | global iter:   3995/  8460 | loss: 0.2852 | ds_loss: 0.0000 | lr: 2.7183e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3996/  8460 | global iter:   3996/  8460 | loss: 0.8916 | ds_loss: 0.0000 | lr: 2.7174e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   3996/  8460 | global iter:   3996/  8460 | loss: 0.4661 | ds_loss: 0.0000 | lr: 2.7174e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   3997/  8460 | global iter:   3997/  8460 | loss: 0.1158 | ds_loss: 0.0000 | lr: 2.7165e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   3998/  8460 | global iter:   3998/  8460 | loss: 0.1375 | ds_loss: 0.0000 | lr: 2.7156e-04 | scale:     1.0000 | micro time: 0.437 | step time: 0.000
train | epoch   4 | Iter:   3999/  8460 | global iter:   3999/  8460 | loss: 0.5587 | ds_loss: 0.0000 | lr: 2.7146e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   4000/  8460 | global iter:   4000/  8460 | loss: 0.5854 | ds_loss: 0.0000 | lr: 2.7137e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4000/  8460 | global iter:   4000/  8460 | loss: 0.3493 | ds_loss: 0.0000 | lr: 2.7137e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.430
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
Model save to ./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1/4000
dp size 1
0/125
1/125
2/125
3/125
4/125
5/125
6/125
7/125
8/125
9/125
10/125
11/125
12/125
13/125
14/125
15/125
Evaluating:   0%|          | 0/125 [00:00<?, ?it/s]Evaluating:   1%|          | 1/125 [00:02<05:36,  2.71s/it]Evaluating:   2%|▏         | 2/125 [00:05<05:39,  2.76s/it]Evaluating:   2%|▏         | 3/125 [00:07<04:57,  2.44s/it]Evaluating:   3%|▎         | 4/125 [00:10<05:04,  2.52s/it]Evaluating:   4%|▍         | 5/125 [00:11<04:30,  2.25s/it]Evaluating:   5%|▍         | 6/125 [00:13<04:13,  2.13s/it]Evaluating:   6%|▌         | 7/125 [00:14<03:18,  1.68s/it]Evaluating:   6%|▋         | 8/125 [00:17<03:46,  1.93s/it]Evaluating:   7%|▋         | 9/125 [00:19<04:14,  2.20s/it]Evaluating:   8%|▊         | 10/125 [00:22<04:33,  2.38s/it]Evaluating:   9%|▉         | 11/125 [00:25<04:33,  2.40s/it]Evaluating:  10%|▉         | 12/125 [00:27<04:44,  2.51s/it]Evaluating:  10%|█         | 13/125 [00:29<04:15,  2.28s/it]Evaluating:  11%|█         | 14/125 [00:31<04:08,  2.24s/it]Evaluating:  12%|█▏        | 15/125 [00:34<04:24,  2.40s/it]Evaluating:  13%|█▎        | 1616/125
17/125
18/125
19/125
20/125
21/125
22/125
23/125
24/125
25/125
26/125
27/125
28/125
29/125
30/125
31/125
/125 [00:37<04:34,  2.52s/it]Evaluating:  14%|█▎        | 17/125 [00:38<03:51,  2.15s/it]Evaluating:  14%|█▍        | 18/125 [00:39<03:22,  1.89s/it]Evaluating:  15%|█▌        | 19/125 [00:42<03:49,  2.16s/it]Evaluating:  16%|█▌        | 20/125 [00:45<04:08,  2.37s/it]Evaluating:  17%|█▋        | 21/125 [00:47<04:00,  2.31s/it]Evaluating:  18%|█▊        | 22/125 [00:50<04:10,  2.43s/it]Evaluating:  18%|█▊        | 23/125 [00:53<04:19,  2.54s/it]Evaluating:  19%|█▉        | 24/125 [00:56<04:24,  2.62s/it]Evaluating:  20%|██        | 25/125 [00:58<04:01,  2.41s/it]Evaluating:  21%|██        | 26/125 [01:00<04:10,  2.53s/it]Evaluating:  22%|██▏       | 27/125 [01:03<04:16,  2.62s/it]Evaluating:  22%|██▏       | 28/125 [01:06<04:20,  2.69s/it]Evaluating:  23%|██▎       | 29/125 [01:09<04:21,  2.73s/it]Evaluating:  24%|██▍       | 30/125 [01:11<04:03,  2.57s/it]Evaluating:  25%|██▍       | 31/125 [01:14<04:08,  2.64s/it]Evaluatin32/125
33/125
34/125
35/125
36/125
37/125
38/125
39/125
40/125
41/125
42/125
43/125
44/125
45/125
46/125
g:  26%|██▌       | 32/125 [01:15<03:31,  2.27s/it]Evaluating:  26%|██▋       | 33/125 [01:18<03:43,  2.43s/it]Evaluating:  27%|██▋       | 34/125 [01:21<03:51,  2.55s/it]Evaluating:  28%|██▊       | 35/125 [01:24<04:07,  2.75s/it]Evaluating:  29%|██▉       | 36/125 [01:27<04:06,  2.77s/it]Evaluating:  30%|██▉       | 37/125 [01:30<04:05,  2.80s/it]Evaluating:  30%|███       | 38/125 [01:31<03:29,  2.40s/it]Evaluating:  31%|███       | 39/125 [01:34<03:37,  2.52s/it]Evaluating:  32%|███▏      | 40/125 [01:37<03:45,  2.65s/it]Evaluating:  33%|███▎      | 41/125 [01:40<03:46,  2.70s/it]Evaluating:  34%|███▎      | 42/125 [01:43<03:46,  2.73s/it]Evaluating:  34%|███▍      | 43/125 [01:44<03:19,  2.43s/it]Evaluating:  35%|███▌      | 44/125 [01:47<03:13,  2.39s/it]Evaluating:  36%|███▌      | 45/125 [01:49<03:21,  2.52s/it]Evaluating:  37%|███▋      | 46/125 [01:52<03:23,  2.58s/it]Evaluating:  347/125
48/125
49/125
50/125
51/125
52/125
53/125
54/125
55/125
56/125
57/125
58/125
59/125
60/125
8%|███▊      | 47/125 [01:54<03:14,  2.50s/it]Evaluating:  38%|███▊      | 48/125 [01:57<03:16,  2.55s/it]Evaluating:  39%|███▉      | 49/125 [02:00<03:25,  2.70s/it]Evaluating:  40%|████      | 50/125 [02:02<02:53,  2.31s/it]Evaluating:  41%|████      | 51/125 [02:05<03:07,  2.54s/it]Evaluating:  42%|████▏     | 52/125 [02:07<03:00,  2.47s/it]Evaluating:  42%|████▏     | 53/125 [02:10<03:14,  2.70s/it]Evaluating:  43%|████▎     | 54/125 [02:12<03:01,  2.56s/it]Evaluating:  44%|████▍     | 55/125 [02:15<03:04,  2.63s/it]Evaluating:  45%|████▍     | 56/125 [02:18<02:56,  2.56s/it]Evaluating:  46%|████▌     | 57/125 [02:20<03:00,  2.65s/it]Evaluating:  46%|████▋     | 58/125 [02:23<02:49,  2.53s/it]Evaluating:  47%|████▋     | 59/125 [02:26<02:53,  2.63s/it]Evaluating:  48%|████▊     | 60/125 [02:28<02:54,  2.68s/it]Evaluating:  49%|████▉     | 61/125 [02:31<061/125
62/125
63/125
64/125
65/125
66/125
67/125
68/125
69/125
70/125
71/125
72/125
73/125
Distributed index stop interation. Idx: 596 Total_length: 596
2:54,  2.72s/it]Evaluating:  50%|████▉     | 62/125 [02:34<02:54,  2.76s/it]Evaluating:  50%|█████     | 63/125 [02:37<02:52,  2.78s/it]Evaluating:  51%|█████     | 64/125 [02:40<02:50,  2.79s/it]Evaluating:  52%|█████▏    | 65/125 [02:42<02:47,  2.79s/it]Evaluating:  53%|█████▎    | 66/125 [02:45<02:44,  2.80s/it]Evaluating:  54%|█████▎    | 67/125 [02:47<02:28,  2.57s/it]Evaluating:  54%|█████▍    | 68/125 [02:50<02:30,  2.64s/it]Evaluating:  55%|█████▌    | 69/125 [02:53<02:30,  2.69s/it]Evaluating:  56%|█████▌    | 70/125 [02:55<02:21,  2.58s/it]Evaluating:  57%|█████▋    | 71/125 [02:58<02:26,  2.72s/it]Evaluating:  58%|█████▊    | 72/125 [03:01<02:25,  2.74s/it]Evaluating:  58%|█████▊    | 73/125 [03:03<02:03,  2.38s/it]Evaluating:  59%|█████▉    | 74/125 [03:05<02:08,  2.51s/it]Evaluating:  59%|█████▉    | 74/125 [03:05<02:08,  2.51s/it]
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1/eval/4
dev | avg_loss: 0.7985823343734484 | {'exact_match': 0.0, 'rougeL': 51.2065}
train | epoch   4 | Iter:   4001/  8460 | global iter:   4001/  8460 | loss: 0.1070 | ds_loss: 0.0000 | lr: 2.7128e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4002/  8460 | global iter:   4002/  8460 | loss: 0.3677 | ds_loss: 0.0000 | lr: 2.7119e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4003/  8460 | global iter:   4003/  8460 | loss: 0.3197 | ds_loss: 0.0000 | lr: 2.7109e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4004/  8460 | global iter:   4004/  8460 | loss: 0.2263 | ds_loss: 0.0000 | lr: 2.7100e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4004/  8460 | global iter:   4004/  8460 | loss: 0.2552 | ds_loss: 0.0000 | lr: 2.7100e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4005/  8460 | global iter:   4005/  8460 | loss: 0.5604 | ds_loss: 0.0000 | lr: 2.7091e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4006/  8460 | global iter:   4006/  8460 | loss: 0.4449 | ds_loss: 0.0000 | lr: 2.7082e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4007/  8460 | global iter:   4007/  8460 | loss: 0.1771 | ds_loss: 0.0000 | lr: 2.7072e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4008/  8460 | global iter:   4008/  8460 | loss: 0.4800 | ds_loss: 0.0000 | lr: 2.7063e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4008/  8460 | global iter:   4008/  8460 | loss: 0.4156 | ds_loss: 0.0000 | lr: 2.7063e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4009/  8460 | global iter:   4009/  8460 | loss: 0.2016 | ds_loss: 0.0000 | lr: 2.7054e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4010/  8460 | global iter:   4010/  8460 | loss: 0.1899 | ds_loss: 0.0000 | lr: 2.7045e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4011/  8460 | global iter:   4011/  8460 | loss: 0.0737 | ds_loss: 0.0000 | lr: 2.7035e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   4012/  8460 | global iter:   4012/  8460 | loss: 0.2488 | ds_loss: 0.0000 | lr: 2.7026e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4012/  8460 | global iter:   4012/  8460 | loss: 0.1785 | ds_loss: 0.0000 | lr: 2.7026e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4013/  8460 | global iter:   4013/  8460 | loss: 0.3476 | ds_loss: 0.0000 | lr: 2.7017e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4014/  8460 | global iter:   4014/  8460 | loss: 0.5389 | ds_loss: 0.0000 | lr: 2.7008e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4015/  8460 | global iter:   4015/  8460 | loss: 0.3092 | ds_loss: 0.0000 | lr: 2.6998e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   4016/  8460 | global iter:   4016/  8460 | loss: 0.0948 | ds_loss: 0.0000 | lr: 2.6989e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4016/  8460 | global iter:   4016/  8460 | loss: 0.3226 | ds_loss: 0.0000 | lr: 2.6989e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4017/  8460 | global iter:   4017/  8460 | loss: 0.2007 | ds_loss: 0.0000 | lr: 2.6980e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4018/  8460 | global iter:   4018/  8460 | loss: 0.3069 | ds_loss: 0.0000 | lr: 2.6971e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4019/  8460 | global iter:   4019/  8460 | loss: 0.1277 | ds_loss: 0.0000 | lr: 2.6961e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4020/  8460 | global iter:   4020/  8460 | loss: 0.4710 | ds_loss: 0.0000 | lr: 2.6952e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4020/  8460 | global iter:   4020/  8460 | loss: 0.2766 | ds_loss: 0.0000 | lr: 2.6952e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4021/  8460 | global iter:   4021/  8460 | loss: 0.1427 | ds_loss: 0.0000 | lr: 2.6943e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4022/  8460 | global iter:   4022/  8460 | loss: 0.2569 | ds_loss: 0.0000 | lr: 2.6934e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4023/  8460 | global iter:   4023/  8460 | loss: 0.4597 | ds_loss: 0.0000 | lr: 2.6924e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4024/  8460 | global iter:   4024/  8460 | loss: 0.2825 | ds_loss: 0.0000 | lr: 2.6915e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4024/  8460 | global iter:   4024/  8460 | loss: 0.2855 | ds_loss: 0.0000 | lr: 2.6915e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4025/  8460 | global iter:   4025/  8460 | loss: 0.5243 | ds_loss: 0.0000 | lr: 2.6906e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4026/  8460 | global iter:   4026/  8460 | loss: 0.4227 | ds_loss: 0.0000 | lr: 2.6897e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4027/  8460 | global iter:   4027/  8460 | loss: 0.2103 | ds_loss: 0.0000 | lr: 2.6887e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4028/  8460 | global iter:   4028/  8460 | loss: 0.3153 | ds_loss: 0.0000 | lr: 2.6878e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4028/  8460 | global iter:   4028/  8460 | loss: 0.3682 | ds_loss: 0.0000 | lr: 2.6878e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4029/  8460 | global iter:   4029/  8460 | loss: 0.2810 | ds_loss: 0.0000 | lr: 2.6869e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4030/  8460 | global iter:   4030/  8460 | loss: 0.2739 | ds_loss: 0.0000 | lr: 2.6860e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4031/  8460 | global iter:   4031/  8460 | loss: 0.5647 | ds_loss: 0.0000 | lr: 2.6850e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4032/  8460 | global iter:   4032/  8460 | loss: 0.1545 | ds_loss: 0.0000 | lr: 2.6841e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4032/  8460 | global iter:   4032/  8460 | loss: 0.3186 | ds_loss: 0.0000 | lr: 2.6841e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4033/  8460 | global iter:   4033/  8460 | loss: 0.7158 | ds_loss: 0.0000 | lr: 2.6832e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4034/  8460 | global iter:   4034/  8460 | loss: 0.1071 | ds_loss: 0.0000 | lr: 2.6823e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4035/  8460 | global iter:   4035/  8460 | loss: 0.3355 | ds_loss: 0.0000 | lr: 2.6813e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4036/  8460 | global iter:   4036/  8460 | loss: 0.2925 | ds_loss: 0.0000 | lr: 2.6804e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4036/  8460 | global iter:   4036/  8460 | loss: 0.3627 | ds_loss: 0.0000 | lr: 2.6804e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4037/  8460 | global iter:   4037/  8460 | loss: 0.1732 | ds_loss: 0.0000 | lr: 2.6795e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4038/  8460 | global iter:   4038/  8460 | loss: 0.2301 | ds_loss: 0.0000 | lr: 2.6786e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4039/  8460 | global iter:   4039/  8460 | loss: 0.3026 | ds_loss: 0.0000 | lr: 2.6776e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4040/  8460 | global iter:   4040/  8460 | loss: 0.3685 | ds_loss: 0.0000 | lr: 2.6767e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4040/  8460 | global iter:   4040/  8460 | loss: 0.2686 | ds_loss: 0.0000 | lr: 2.6767e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4041/  8460 | global iter:   4041/  8460 | loss: 0.2131 | ds_loss: 0.0000 | lr: 2.6758e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4042/  8460 | global iter:   4042/  8460 | loss: 0.4192 | ds_loss: 0.0000 | lr: 2.6749e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4043/  8460 | global iter:   4043/  8460 | loss: 0.5598 | ds_loss: 0.0000 | lr: 2.6739e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4044/  8460 | global iter:   4044/  8460 | loss: 0.3184 | ds_loss: 0.0000 | lr: 2.6730e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4044/  8460 | global iter:   4044/  8460 | loss: 0.3776 | ds_loss: 0.0000 | lr: 2.6730e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4045/  8460 | global iter:   4045/  8460 | loss: 0.1929 | ds_loss: 0.0000 | lr: 2.6721e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4046/  8460 | global iter:   4046/  8460 | loss: 0.5074 | ds_loss: 0.0000 | lr: 2.6712e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4047/  8460 | global iter:   4047/  8460 | loss: 0.2693 | ds_loss: 0.0000 | lr: 2.6702e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4048/  8460 | global iter:   4048/  8460 | loss: 0.1754 | ds_loss: 0.0000 | lr: 2.6693e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4048/  8460 | global iter:   4048/  8460 | loss: 0.2863 | ds_loss: 0.0000 | lr: 2.6693e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4049/  8460 | global iter:   4049/  8460 | loss: 0.1060 | ds_loss: 0.0000 | lr: 2.6684e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4050/  8460 | global iter:   4050/  8460 | loss: 0.0970 | ds_loss: 0.0000 | lr: 2.6674e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4051/  8460 | global iter:   4051/  8460 | loss: 0.3225 | ds_loss: 0.0000 | lr: 2.6665e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4052/  8460 | global iter:   4052/  8460 | loss: 0.2663 | ds_loss: 0.0000 | lr: 2.6656e-04 | scale:     1.0000 | micro time: 0.438 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4052/  8460 | global iter:   4052/  8460 | loss: 0.1980 | ds_loss: 0.0000 | lr: 2.6656e-04 | scale:     1.0000 | micro time: 0.438 | step time: 0.430
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4053/  8460 | global iter:   4053/  8460 | loss: 0.6196 | ds_loss: 0.0000 | lr: 2.6647e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.000
train | epoch   4 | Iter:   4054/  8460 | global iter:   4054/  8460 | loss: 0.4514 | ds_loss: 0.0000 | lr: 2.6637e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   4055/  8460 | global iter:   4055/  8460 | loss: 0.2939 | ds_loss: 0.0000 | lr: 2.6628e-04 | scale:     1.0000 | micro time: 0.438 | step time: 0.000
train | epoch   4 | Iter:   4056/  8460 | global iter:   4056/  8460 | loss: 0.0592 | ds_loss: 0.0000 | lr: 2.6619e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4056/  8460 | global iter:   4056/  8460 | loss: 0.3560 | ds_loss: 0.0000 | lr: 2.6619e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.431
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4057/  8460 | global iter:   4057/  8460 | loss: 0.2641 | ds_loss: 0.0000 | lr: 2.6610e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   4058/  8460 | global iter:   4058/  8460 | loss: 0.1111 | ds_loss: 0.0000 | lr: 2.6600e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4059/  8460 | global iter:   4059/  8460 | loss: 0.6439 | ds_loss: 0.0000 | lr: 2.6591e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4060/  8460 | global iter:   4060/  8460 | loss: 0.1449 | ds_loss: 0.0000 | lr: 2.6582e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4060/  8460 | global iter:   4060/  8460 | loss: 0.2910 | ds_loss: 0.0000 | lr: 2.6582e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4061/  8460 | global iter:   4061/  8460 | loss: 0.8965 | ds_loss: 0.0000 | lr: 2.6573e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4062/  8460 | global iter:   4062/  8460 | loss: 0.0707 | ds_loss: 0.0000 | lr: 2.6563e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4063/  8460 | global iter:   4063/  8460 | loss: 0.1526 | ds_loss: 0.0000 | lr: 2.6554e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   4064/  8460 | global iter:   4064/  8460 | loss: 0.5405 | ds_loss: 0.0000 | lr: 2.6545e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4064/  8460 | global iter:   4064/  8460 | loss: 0.4151 | ds_loss: 0.0000 | lr: 2.6545e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4065/  8460 | global iter:   4065/  8460 | loss: 0.4501 | ds_loss: 0.0000 | lr: 2.6536e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4066/  8460 | global iter:   4066/  8460 | loss: 0.2816 | ds_loss: 0.0000 | lr: 2.6526e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4067/  8460 | global iter:   4067/  8460 | loss: 0.7320 | ds_loss: 0.0000 | lr: 2.6517e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4068/  8460 | global iter:   4068/  8460 | loss: 0.0704 | ds_loss: 0.0000 | lr: 2.6508e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4068/  8460 | global iter:   4068/  8460 | loss: 0.3835 | ds_loss: 0.0000 | lr: 2.6508e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4069/  8460 | global iter:   4069/  8460 | loss: 0.2082 | ds_loss: 0.0000 | lr: 2.6498e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4070/  8460 | global iter:   4070/  8460 | loss: 0.4996 | ds_loss: 0.0000 | lr: 2.6489e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4071/  8460 | global iter:   4071/  8460 | loss: 0.1601 | ds_loss: 0.0000 | lr: 2.6480e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4072/  8460 | global iter:   4072/  8460 | loss: 0.1809 | ds_loss: 0.0000 | lr: 2.6471e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4072/  8460 | global iter:   4072/  8460 | loss: 0.2622 | ds_loss: 0.0000 | lr: 2.6471e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4073/  8460 | global iter:   4073/  8460 | loss: 0.2901 | ds_loss: 0.0000 | lr: 2.6461e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4074/  8460 | global iter:   4074/  8460 | loss: 0.0460 | ds_loss: 0.0000 | lr: 2.6452e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4075/  8460 | global iter:   4075/  8460 | loss: 0.4699 | ds_loss: 0.0000 | lr: 2.6443e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4076/  8460 | global iter:   4076/  8460 | loss: 0.3791 | ds_loss: 0.0000 | lr: 2.6434e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4076/  8460 | global iter:   4076/  8460 | loss: 0.2963 | ds_loss: 0.0000 | lr: 2.6434e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4077/  8460 | global iter:   4077/  8460 | loss: 0.1281 | ds_loss: 0.0000 | lr: 2.6424e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4078/  8460 | global iter:   4078/  8460 | loss: 0.0228 | ds_loss: 0.0000 | lr: 2.6415e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4079/  8460 | global iter:   4079/  8460 | loss: 0.1776 | ds_loss: 0.0000 | lr: 2.6406e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4080/  8460 | global iter:   4080/  8460 | loss: 0.6711 | ds_loss: 0.0000 | lr: 2.6397e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4080/  8460 | global iter:   4080/  8460 | loss: 0.2499 | ds_loss: 0.0000 | lr: 2.6397e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4081/  8460 | global iter:   4081/  8460 | loss: 0.2270 | ds_loss: 0.0000 | lr: 2.6387e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4082/  8460 | global iter:   4082/  8460 | loss: 0.6524 | ds_loss: 0.0000 | lr: 2.6378e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4083/  8460 | global iter:   4083/  8460 | loss: 0.1324 | ds_loss: 0.0000 | lr: 2.6369e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4084/  8460 | global iter:   4084/  8460 | loss: 0.2151 | ds_loss: 0.0000 | lr: 2.6359e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4084/  8460 | global iter:   4084/  8460 | loss: 0.3067 | ds_loss: 0.0000 | lr: 2.6359e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4085/  8460 | global iter:   4085/  8460 | loss: 0.1234 | ds_loss: 0.0000 | lr: 2.6350e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4086/  8460 | global iter:   4086/  8460 | loss: 0.2292 | ds_loss: 0.0000 | lr: 2.6341e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4087/  8460 | global iter:   4087/  8460 | loss: 0.2433 | ds_loss: 0.0000 | lr: 2.6332e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4088/  8460 | global iter:   4088/  8460 | loss: 0.4685 | ds_loss: 0.0000 | lr: 2.6322e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4088/  8460 | global iter:   4088/  8460 | loss: 0.2661 | ds_loss: 0.0000 | lr: 2.6322e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4089/  8460 | global iter:   4089/  8460 | loss: 0.5198 | ds_loss: 0.0000 | lr: 2.6313e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4090/  8460 | global iter:   4090/  8460 | loss: 0.3712 | ds_loss: 0.0000 | lr: 2.6304e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4091/  8460 | global iter:   4091/  8460 | loss: 0.3088 | ds_loss: 0.0000 | lr: 2.6295e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4092/  8460 | global iter:   4092/  8460 | loss: 0.6586 | ds_loss: 0.0000 | lr: 2.6285e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4092/  8460 | global iter:   4092/  8460 | loss: 0.4646 | ds_loss: 0.0000 | lr: 2.6285e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4093/  8460 | global iter:   4093/  8460 | loss: 0.3690 | ds_loss: 0.0000 | lr: 2.6276e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4094/  8460 | global iter:   4094/  8460 | loss: 0.1650 | ds_loss: 0.0000 | lr: 2.6267e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4095/  8460 | global iter:   4095/  8460 | loss: 0.2437 | ds_loss: 0.0000 | lr: 2.6258e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4096/  8460 | global iter:   4096/  8460 | loss: 0.4396 | ds_loss: 0.0000 | lr: 2.6248e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4096/  8460 | global iter:   4096/  8460 | loss: 0.3043 | ds_loss: 0.0000 | lr: 2.6248e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4097/  8460 | global iter:   4097/  8460 | loss: 0.1124 | ds_loss: 0.0000 | lr: 2.6239e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4098/  8460 | global iter:   4098/  8460 | loss: 0.1861 | ds_loss: 0.0000 | lr: 2.6230e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4099/  8460 | global iter:   4099/  8460 | loss: 0.1438 | ds_loss: 0.0000 | lr: 2.6220e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   4100/  8460 | global iter:   4100/  8460 | loss: 0.2004 | ds_loss: 0.0000 | lr: 2.6211e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4100/  8460 | global iter:   4100/  8460 | loss: 0.1607 | ds_loss: 0.0000 | lr: 2.6211e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4101/  8460 | global iter:   4101/  8460 | loss: 0.1575 | ds_loss: 0.0000 | lr: 2.6202e-04 | scale:     1.0000 | micro time: 0.438 | step time: 0.000
train | epoch   4 | Iter:   4102/  8460 | global iter:   4102/  8460 | loss: 0.2996 | ds_loss: 0.0000 | lr: 2.6193e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   4103/  8460 | global iter:   4103/  8460 | loss: 0.2045 | ds_loss: 0.0000 | lr: 2.6183e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4104/  8460 | global iter:   4104/  8460 | loss: 0.5937 | ds_loss: 0.0000 | lr: 2.6174e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4104/  8460 | global iter:   4104/  8460 | loss: 0.3138 | ds_loss: 0.0000 | lr: 2.6174e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.430
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4105/  8460 | global iter:   4105/  8460 | loss: 0.1205 | ds_loss: 0.0000 | lr: 2.6165e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4106/  8460 | global iter:   4106/  8460 | loss: 0.1647 | ds_loss: 0.0000 | lr: 2.6156e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4107/  8460 | global iter:   4107/  8460 | loss: 0.6262 | ds_loss: 0.0000 | lr: 2.6146e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4108/  8460 | global iter:   4108/  8460 | loss: 0.0417 | ds_loss: 0.0000 | lr: 2.6137e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4108/  8460 | global iter:   4108/  8460 | loss: 0.2382 | ds_loss: 0.0000 | lr: 2.6137e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4109/  8460 | global iter:   4109/  8460 | loss: 0.4901 | ds_loss: 0.0000 | lr: 2.6128e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   4110/  8460 | global iter:   4110/  8460 | loss: 0.3048 | ds_loss: 0.0000 | lr: 2.6118e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4111/  8460 | global iter:   4111/  8460 | loss: 0.1467 | ds_loss: 0.0000 | lr: 2.6109e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4112/  8460 | global iter:   4112/  8460 | loss: 0.1032 | ds_loss: 0.0000 | lr: 2.6100e-04 | scale:     1.0000 | micro time: 0.437 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4112/  8460 | global iter:   4112/  8460 | loss: 0.2612 | ds_loss: 0.0000 | lr: 2.6100e-04 | scale:     1.0000 | micro time: 0.437 | step time: 0.430
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4113/  8460 | global iter:   4113/  8460 | loss: 0.2764 | ds_loss: 0.0000 | lr: 2.6091e-04 | scale:     1.0000 | micro time: 0.431 | step time: 0.000
train | epoch   4 | Iter:   4114/  8460 | global iter:   4114/  8460 | loss: 0.8312 | ds_loss: 0.0000 | lr: 2.6081e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   4115/  8460 | global iter:   4115/  8460 | loss: 0.3207 | ds_loss: 0.0000 | lr: 2.6072e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4116/  8460 | global iter:   4116/  8460 | loss: 0.3759 | ds_loss: 0.0000 | lr: 2.6063e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4116/  8460 | global iter:   4116/  8460 | loss: 0.4510 | ds_loss: 0.0000 | lr: 2.6063e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4117/  8460 | global iter:   4117/  8460 | loss: 0.3681 | ds_loss: 0.0000 | lr: 2.6054e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4118/  8460 | global iter:   4118/  8460 | loss: 0.2027 | ds_loss: 0.0000 | lr: 2.6044e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4119/  8460 | global iter:   4119/  8460 | loss: 0.2804 | ds_loss: 0.0000 | lr: 2.6035e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4120/  8460 | global iter:   4120/  8460 | loss: 0.1625 | ds_loss: 0.0000 | lr: 2.6026e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4120/  8460 | global iter:   4120/  8460 | loss: 0.2534 | ds_loss: 0.0000 | lr: 2.6026e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4121/  8460 | global iter:   4121/  8460 | loss: 0.0779 | ds_loss: 0.0000 | lr: 2.6016e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4122/  8460 | global iter:   4122/  8460 | loss: 0.1868 | ds_loss: 0.0000 | lr: 2.6007e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4123/  8460 | global iter:   4123/  8460 | loss: 0.2294 | ds_loss: 0.0000 | lr: 2.5998e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   4124/  8460 | global iter:   4124/  8460 | loss: 0.3893 | ds_loss: 0.0000 | lr: 2.5989e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4124/  8460 | global iter:   4124/  8460 | loss: 0.2208 | ds_loss: 0.0000 | lr: 2.5989e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4125/  8460 | global iter:   4125/  8460 | loss: 0.1540 | ds_loss: 0.0000 | lr: 2.5979e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4126/  8460 | global iter:   4126/  8460 | loss: 0.2602 | ds_loss: 0.0000 | lr: 2.5970e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4127/  8460 | global iter:   4127/  8460 | loss: 0.2689 | ds_loss: 0.0000 | lr: 2.5961e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4128/  8460 | global iter:   4128/  8460 | loss: 0.0804 | ds_loss: 0.0000 | lr: 2.5952e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4128/  8460 | global iter:   4128/  8460 | loss: 0.1909 | ds_loss: 0.0000 | lr: 2.5952e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4129/  8460 | global iter:   4129/  8460 | loss: 0.4511 | ds_loss: 0.0000 | lr: 2.5942e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4130/  8460 | global iter:   4130/  8460 | loss: 0.6551 | ds_loss: 0.0000 | lr: 2.5933e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4131/  8460 | global iter:   4131/  8460 | loss: 0.6608 | ds_loss: 0.0000 | lr: 2.5924e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4132/  8460 | global iter:   4132/  8460 | loss: 0.1333 | ds_loss: 0.0000 | lr: 2.5914e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4132/  8460 | global iter:   4132/  8460 | loss: 0.4751 | ds_loss: 0.0000 | lr: 2.5914e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4133/  8460 | global iter:   4133/  8460 | loss: 0.1542 | ds_loss: 0.0000 | lr: 2.5905e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4134/  8460 | global iter:   4134/  8460 | loss: 0.2441 | ds_loss: 0.0000 | lr: 2.5896e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4135/  8460 | global iter:   4135/  8460 | loss: 0.0405 | ds_loss: 0.0000 | lr: 2.5887e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4136/  8460 | global iter:   4136/  8460 | loss: 0.4384 | ds_loss: 0.0000 | lr: 2.5877e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4136/  8460 | global iter:   4136/  8460 | loss: 0.2193 | ds_loss: 0.0000 | lr: 2.5877e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4137/  8460 | global iter:   4137/  8460 | loss: 0.3529 | ds_loss: 0.0000 | lr: 2.5868e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4138/  8460 | global iter:   4138/  8460 | loss: 0.3766 | ds_loss: 0.0000 | lr: 2.5859e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4139/  8460 | global iter:   4139/  8460 | loss: 0.2034 | ds_loss: 0.0000 | lr: 2.5849e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4140/  8460 | global iter:   4140/  8460 | loss: 0.4839 | ds_loss: 0.0000 | lr: 2.5840e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4140/  8460 | global iter:   4140/  8460 | loss: 0.3542 | ds_loss: 0.0000 | lr: 2.5840e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4141/  8460 | global iter:   4141/  8460 | loss: 0.9439 | ds_loss: 0.0000 | lr: 2.5831e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4142/  8460 | global iter:   4142/  8460 | loss: 0.0719 | ds_loss: 0.0000 | lr: 2.5822e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4143/  8460 | global iter:   4143/  8460 | loss: 0.3633 | ds_loss: 0.0000 | lr: 2.5812e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4144/  8460 | global iter:   4144/  8460 | loss: 0.1904 | ds_loss: 0.0000 | lr: 2.5803e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4144/  8460 | global iter:   4144/  8460 | loss: 0.3924 | ds_loss: 0.0000 | lr: 2.5803e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4145/  8460 | global iter:   4145/  8460 | loss: 0.1531 | ds_loss: 0.0000 | lr: 2.5794e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   4146/  8460 | global iter:   4146/  8460 | loss: 0.3346 | ds_loss: 0.0000 | lr: 2.5785e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   4147/  8460 | global iter:   4147/  8460 | loss: 0.1384 | ds_loss: 0.0000 | lr: 2.5775e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4148/  8460 | global iter:   4148/  8460 | loss: 0.1780 | ds_loss: 0.0000 | lr: 2.5766e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4148/  8460 | global iter:   4148/  8460 | loss: 0.2010 | ds_loss: 0.0000 | lr: 2.5766e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4149/  8460 | global iter:   4149/  8460 | loss: 0.3925 | ds_loss: 0.0000 | lr: 2.5757e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4150/  8460 | global iter:   4150/  8460 | loss: 0.6304 | ds_loss: 0.0000 | lr: 2.5747e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4151/  8460 | global iter:   4151/  8460 | loss: 0.1659 | ds_loss: 0.0000 | lr: 2.5738e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4152/  8460 | global iter:   4152/  8460 | loss: 0.2095 | ds_loss: 0.0000 | lr: 2.5729e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4152/  8460 | global iter:   4152/  8460 | loss: 0.3496 | ds_loss: 0.0000 | lr: 2.5729e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4153/  8460 | global iter:   4153/  8460 | loss: 0.1581 | ds_loss: 0.0000 | lr: 2.5720e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4154/  8460 | global iter:   4154/  8460 | loss: 1.2025 | ds_loss: 0.0000 | lr: 2.5710e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4155/  8460 | global iter:   4155/  8460 | loss: 0.5676 | ds_loss: 0.0000 | lr: 2.5701e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4156/  8460 | global iter:   4156/  8460 | loss: 0.3570 | ds_loss: 0.0000 | lr: 2.5692e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4156/  8460 | global iter:   4156/  8460 | loss: 0.5713 | ds_loss: 0.0000 | lr: 2.5692e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4157/  8460 | global iter:   4157/  8460 | loss: 0.3444 | ds_loss: 0.0000 | lr: 2.5682e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4158/  8460 | global iter:   4158/  8460 | loss: 0.3535 | ds_loss: 0.0000 | lr: 2.5673e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4159/  8460 | global iter:   4159/  8460 | loss: 0.3243 | ds_loss: 0.0000 | lr: 2.5664e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4160/  8460 | global iter:   4160/  8460 | loss: 0.1420 | ds_loss: 0.0000 | lr: 2.5655e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4160/  8460 | global iter:   4160/  8460 | loss: 0.2910 | ds_loss: 0.0000 | lr: 2.5655e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4161/  8460 | global iter:   4161/  8460 | loss: 0.1751 | ds_loss: 0.0000 | lr: 2.5645e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4162/  8460 | global iter:   4162/  8460 | loss: 0.1800 | ds_loss: 0.0000 | lr: 2.5636e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   4163/  8460 | global iter:   4163/  8460 | loss: 0.1567 | ds_loss: 0.0000 | lr: 2.5627e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   4164/  8460 | global iter:   4164/  8460 | loss: 0.1971 | ds_loss: 0.0000 | lr: 2.5618e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4164/  8460 | global iter:   4164/  8460 | loss: 0.1772 | ds_loss: 0.0000 | lr: 2.5618e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4165/  8460 | global iter:   4165/  8460 | loss: 0.8028 | ds_loss: 0.0000 | lr: 2.5608e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4166/  8460 | global iter:   4166/  8460 | loss: 0.0508 | ds_loss: 0.0000 | lr: 2.5599e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4167/  8460 | global iter:   4167/  8460 | loss: 0.2474 | ds_loss: 0.0000 | lr: 2.5590e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4168/  8460 | global iter:   4168/  8460 | loss: 0.5333 | ds_loss: 0.0000 | lr: 2.5580e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4168/  8460 | global iter:   4168/  8460 | loss: 0.4086 | ds_loss: 0.0000 | lr: 2.5580e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4169/  8460 | global iter:   4169/  8460 | loss: 0.4743 | ds_loss: 0.0000 | lr: 2.5571e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4170/  8460 | global iter:   4170/  8460 | loss: 0.2207 | ds_loss: 0.0000 | lr: 2.5562e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4171/  8460 | global iter:   4171/  8460 | loss: 0.5267 | ds_loss: 0.0000 | lr: 2.5553e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4172/  8460 | global iter:   4172/  8460 | loss: 0.2068 | ds_loss: 0.0000 | lr: 2.5543e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4172/  8460 | global iter:   4172/  8460 | loss: 0.3571 | ds_loss: 0.0000 | lr: 2.5543e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4173/  8460 | global iter:   4173/  8460 | loss: 0.1811 | ds_loss: 0.0000 | lr: 2.5534e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4174/  8460 | global iter:   4174/  8460 | loss: 0.1873 | ds_loss: 0.0000 | lr: 2.5525e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4175/  8460 | global iter:   4175/  8460 | loss: 0.4762 | ds_loss: 0.0000 | lr: 2.5515e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4176/  8460 | global iter:   4176/  8460 | loss: 0.0250 | ds_loss: 0.0000 | lr: 2.5506e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4176/  8460 | global iter:   4176/  8460 | loss: 0.2174 | ds_loss: 0.0000 | lr: 2.5506e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4177/  8460 | global iter:   4177/  8460 | loss: 0.3680 | ds_loss: 0.0000 | lr: 2.5497e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4178/  8460 | global iter:   4178/  8460 | loss: 0.3642 | ds_loss: 0.0000 | lr: 2.5488e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4179/  8460 | global iter:   4179/  8460 | loss: 0.1129 | ds_loss: 0.0000 | lr: 2.5478e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4180/  8460 | global iter:   4180/  8460 | loss: 0.7559 | ds_loss: 0.0000 | lr: 2.5469e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4180/  8460 | global iter:   4180/  8460 | loss: 0.4002 | ds_loss: 0.0000 | lr: 2.5469e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4181/  8460 | global iter:   4181/  8460 | loss: 0.1813 | ds_loss: 0.0000 | lr: 2.5460e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4182/  8460 | global iter:   4182/  8460 | loss: 0.1630 | ds_loss: 0.0000 | lr: 2.5451e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4183/  8460 | global iter:   4183/  8460 | loss: 0.2529 | ds_loss: 0.0000 | lr: 2.5441e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4184/  8460 | global iter:   4184/  8460 | loss: 0.4626 | ds_loss: 0.0000 | lr: 2.5432e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4184/  8460 | global iter:   4184/  8460 | loss: 0.2649 | ds_loss: 0.0000 | lr: 2.5432e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4185/  8460 | global iter:   4185/  8460 | loss: 0.3361 | ds_loss: 0.0000 | lr: 2.5423e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4186/  8460 | global iter:   4186/  8460 | loss: 0.0641 | ds_loss: 0.0000 | lr: 2.5413e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4187/  8460 | global iter:   4187/  8460 | loss: 0.1756 | ds_loss: 0.0000 | lr: 2.5404e-04 | scale:     1.0000 | micro time: 0.438 | step time: 0.000
train | epoch   4 | Iter:   4188/  8460 | global iter:   4188/  8460 | loss: 0.1618 | ds_loss: 0.0000 | lr: 2.5395e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4188/  8460 | global iter:   4188/  8460 | loss: 0.1844 | ds_loss: 0.0000 | lr: 2.5395e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.430
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4189/  8460 | global iter:   4189/  8460 | loss: 0.4995 | ds_loss: 0.0000 | lr: 2.5386e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4190/  8460 | global iter:   4190/  8460 | loss: 0.6048 | ds_loss: 0.0000 | lr: 2.5376e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4191/  8460 | global iter:   4191/  8460 | loss: 0.3620 | ds_loss: 0.0000 | lr: 2.5367e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4192/  8460 | global iter:   4192/  8460 | loss: 0.1239 | ds_loss: 0.0000 | lr: 2.5358e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4192/  8460 | global iter:   4192/  8460 | loss: 0.3976 | ds_loss: 0.0000 | lr: 2.5358e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4193/  8460 | global iter:   4193/  8460 | loss: 0.2525 | ds_loss: 0.0000 | lr: 2.5348e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4194/  8460 | global iter:   4194/  8460 | loss: 0.2208 | ds_loss: 0.0000 | lr: 2.5339e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4195/  8460 | global iter:   4195/  8460 | loss: 0.5194 | ds_loss: 0.0000 | lr: 2.5330e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4196/  8460 | global iter:   4196/  8460 | loss: 0.4421 | ds_loss: 0.0000 | lr: 2.5321e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4196/  8460 | global iter:   4196/  8460 | loss: 0.3587 | ds_loss: 0.0000 | lr: 2.5321e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4197/  8460 | global iter:   4197/  8460 | loss: 0.0393 | ds_loss: 0.0000 | lr: 2.5311e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4198/  8460 | global iter:   4198/  8460 | loss: 0.2312 | ds_loss: 0.0000 | lr: 2.5302e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4199/  8460 | global iter:   4199/  8460 | loss: 0.6398 | ds_loss: 0.0000 | lr: 2.5293e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4200/  8460 | global iter:   4200/  8460 | loss: 0.3580 | ds_loss: 0.0000 | lr: 2.5283e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4200/  8460 | global iter:   4200/  8460 | loss: 0.3171 | ds_loss: 0.0000 | lr: 2.5283e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4201/  8460 | global iter:   4201/  8460 | loss: 0.2686 | ds_loss: 0.0000 | lr: 2.5274e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4202/  8460 | global iter:   4202/  8460 | loss: 0.4841 | ds_loss: 0.0000 | lr: 2.5265e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4203/  8460 | global iter:   4203/  8460 | loss: 0.1246 | ds_loss: 0.0000 | lr: 2.5256e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4204/  8460 | global iter:   4204/  8460 | loss: 0.1024 | ds_loss: 0.0000 | lr: 2.5246e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4204/  8460 | global iter:   4204/  8460 | loss: 0.2449 | ds_loss: 0.0000 | lr: 2.5246e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4205/  8460 | global iter:   4205/  8460 | loss: 0.6184 | ds_loss: 0.0000 | lr: 2.5237e-04 | scale:     1.0000 | micro time: 0.436 | step time: 0.000
train | epoch   4 | Iter:   4206/  8460 | global iter:   4206/  8460 | loss: 0.0978 | ds_loss: 0.0000 | lr: 2.5228e-04 | scale:     1.0000 | micro time: 0.439 | step time: 0.000
train | epoch   4 | Iter:   4207/  8460 | global iter:   4207/  8460 | loss: 0.1847 | ds_loss: 0.0000 | lr: 2.5218e-04 | scale:     1.0000 | micro time: 0.431 | step time: 0.000
train | epoch   4 | Iter:   4208/  8460 | global iter:   4208/  8460 | loss: 0.3746 | ds_loss: 0.0000 | lr: 2.5209e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4208/  8460 | global iter:   4208/  8460 | loss: 0.3189 | ds_loss: 0.0000 | lr: 2.5209e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.434
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4209/  8460 | global iter:   4209/  8460 | loss: 0.1160 | ds_loss: 0.0000 | lr: 2.5200e-04 | scale:     1.0000 | micro time: 0.431 | step time: 0.000
train | epoch   4 | Iter:   4210/  8460 | global iter:   4210/  8460 | loss: 0.3819 | ds_loss: 0.0000 | lr: 2.5191e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   4211/  8460 | global iter:   4211/  8460 | loss: 0.4688 | ds_loss: 0.0000 | lr: 2.5181e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   4212/  8460 | global iter:   4212/  8460 | loss: 0.0900 | ds_loss: 0.0000 | lr: 2.5172e-04 | scale:     1.0000 | micro time: 0.431 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4212/  8460 | global iter:   4212/  8460 | loss: 0.2642 | ds_loss: 0.0000 | lr: 2.5172e-04 | scale:     1.0000 | micro time: 0.431 | step time: 0.430
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4213/  8460 | global iter:   4213/  8460 | loss: 0.2836 | ds_loss: 0.0000 | lr: 2.5163e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4214/  8460 | global iter:   4214/  8460 | loss: 0.4354 | ds_loss: 0.0000 | lr: 2.5154e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4215/  8460 | global iter:   4215/  8460 | loss: 0.1486 | ds_loss: 0.0000 | lr: 2.5144e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   4 | Iter:   4216/  8460 | global iter:   4216/  8460 | loss: 0.0963 | ds_loss: 0.0000 | lr: 2.5135e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4216/  8460 | global iter:   4216/  8460 | loss: 0.2409 | ds_loss: 0.0000 | lr: 2.5135e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4217/  8460 | global iter:   4217/  8460 | loss: 0.0885 | ds_loss: 0.0000 | lr: 2.5126e-04 | scale:     1.0000 | micro time: 0.440 | step time: 0.000
train | epoch   4 | Iter:   4218/  8460 | global iter:   4218/  8460 | loss: 0.2823 | ds_loss: 0.0000 | lr: 2.5116e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4219/  8460 | global iter:   4219/  8460 | loss: 0.1526 | ds_loss: 0.0000 | lr: 2.5107e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4220/  8460 | global iter:   4220/  8460 | loss: 0.0181 | ds_loss: 0.0000 | lr: 2.5098e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4220/  8460 | global iter:   4220/  8460 | loss: 0.1354 | ds_loss: 0.0000 | lr: 2.5098e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.431
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4221/  8460 | global iter:   4221/  8460 | loss: 0.2112 | ds_loss: 0.0000 | lr: 2.5089e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4222/  8460 | global iter:   4222/  8460 | loss: 0.5694 | ds_loss: 0.0000 | lr: 2.5079e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4223/  8460 | global iter:   4223/  8460 | loss: 0.1699 | ds_loss: 0.0000 | lr: 2.5070e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4224/  8460 | global iter:   4224/  8460 | loss: 0.5508 | ds_loss: 0.0000 | lr: 2.5061e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4224/  8460 | global iter:   4224/  8460 | loss: 0.3753 | ds_loss: 0.0000 | lr: 2.5061e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4225/  8460 | global iter:   4225/  8460 | loss: 0.2204 | ds_loss: 0.0000 | lr: 2.5051e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4226/  8460 | global iter:   4226/  8460 | loss: 0.1690 | ds_loss: 0.0000 | lr: 2.5042e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4227/  8460 | global iter:   4227/  8460 | loss: 0.2053 | ds_loss: 0.0000 | lr: 2.5033e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4228/  8460 | global iter:   4228/  8460 | loss: 0.2005 | ds_loss: 0.0000 | lr: 2.5024e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4228/  8460 | global iter:   4228/  8460 | loss: 0.1988 | ds_loss: 0.0000 | lr: 2.5024e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4229/  8460 | global iter:   4229/  8460 | loss: 0.2226 | ds_loss: 0.0000 | lr: 2.5014e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4230/  8460 | global iter:   4230/  8460 | loss: 0.2035 | ds_loss: 0.0000 | lr: 2.5005e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4231/  8460 | global iter:   4231/  8460 | loss: 0.1083 | ds_loss: 0.0000 | lr: 2.4996e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   4 | Iter:   4232/  8460 | global iter:   4232/  8460 | loss: 0.0766 | ds_loss: 0.0000 | lr: 2.4986e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   4 | Iter:   4232/  8460 | global iter:   4232/  8460 | loss: 0.1527 | ds_loss: 0.0000 | lr: 2.4986e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   4 | Iter:   4233/  8460 | global iter:   4233/  8460 | loss: 0.3016 | ds_loss: 0.0000 | lr: 2.4977e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4234/  8460 | global iter:   4234/  8460 | loss: 0.1883 | ds_loss: 0.0000 | lr: 2.4968e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   4 | Iter:   4235/  8460 | global iter:   4235/  8460 | loss: 0.1173 | ds_loss: 0.0000 | lr: 2.4959e-04 | scale:     1.0000 | micro time: 0.366 | step time: 0.000
Sun Apr  6 21:23:00 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla P100-PCIE-12GB           Off |   00000000:81:00.0 Off |                    0 |
| N/A   52C    P0             41W /  250W |    8807MiB /  12288MiB |    100%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A    244677      C   ...project_distillLLM/venv/bin/python3       8804MiB |
+-----------------------------------------------------------------------------------------+

train | epoch   5 | Iter:   4236/  8460 | global iter:   4236/  8460 | loss: 0.1859 | ds_loss: 0.0000 | lr: 2.4949e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4236/  8460 | global iter:   4236/  8460 | loss: 0.1983 | ds_loss: 0.0000 | lr: 2.4949e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.413
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4237/  8460 | global iter:   4237/  8460 | loss: 0.3973 | ds_loss: 0.0000 | lr: 2.4940e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4238/  8460 | global iter:   4238/  8460 | loss: 0.2455 | ds_loss: 0.0000 | lr: 2.4931e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4239/  8460 | global iter:   4239/  8460 | loss: 0.1221 | ds_loss: 0.0000 | lr: 2.4921e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4240/  8460 | global iter:   4240/  8460 | loss: 0.1246 | ds_loss: 0.0000 | lr: 2.4912e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4240/  8460 | global iter:   4240/  8460 | loss: 0.2224 | ds_loss: 0.0000 | lr: 2.4912e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4241/  8460 | global iter:   4241/  8460 | loss: 0.2982 | ds_loss: 0.0000 | lr: 2.4903e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4242/  8460 | global iter:   4242/  8460 | loss: 0.0926 | ds_loss: 0.0000 | lr: 2.4894e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4243/  8460 | global iter:   4243/  8460 | loss: 0.3615 | ds_loss: 0.0000 | lr: 2.4884e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4244/  8460 | global iter:   4244/  8460 | loss: 0.1734 | ds_loss: 0.0000 | lr: 2.4875e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4244/  8460 | global iter:   4244/  8460 | loss: 0.2314 | ds_loss: 0.0000 | lr: 2.4875e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4245/  8460 | global iter:   4245/  8460 | loss: 0.0681 | ds_loss: 0.0000 | lr: 2.4866e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4246/  8460 | global iter:   4246/  8460 | loss: 0.2443 | ds_loss: 0.0000 | lr: 2.4856e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4247/  8460 | global iter:   4247/  8460 | loss: 0.1189 | ds_loss: 0.0000 | lr: 2.4847e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4248/  8460 | global iter:   4248/  8460 | loss: 0.5184 | ds_loss: 0.0000 | lr: 2.4838e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4248/  8460 | global iter:   4248/  8460 | loss: 0.2374 | ds_loss: 0.0000 | lr: 2.4838e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4249/  8460 | global iter:   4249/  8460 | loss: 0.1537 | ds_loss: 0.0000 | lr: 2.4829e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4250/  8460 | global iter:   4250/  8460 | loss: 0.0982 | ds_loss: 0.0000 | lr: 2.4819e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4251/  8460 | global iter:   4251/  8460 | loss: 0.2752 | ds_loss: 0.0000 | lr: 2.4810e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4252/  8460 | global iter:   4252/  8460 | loss: 0.1231 | ds_loss: 0.0000 | lr: 2.4801e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4252/  8460 | global iter:   4252/  8460 | loss: 0.1625 | ds_loss: 0.0000 | lr: 2.4801e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4253/  8460 | global iter:   4253/  8460 | loss: 0.3330 | ds_loss: 0.0000 | lr: 2.4792e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4254/  8460 | global iter:   4254/  8460 | loss: 0.0408 | ds_loss: 0.0000 | lr: 2.4782e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4255/  8460 | global iter:   4255/  8460 | loss: 0.1391 | ds_loss: 0.0000 | lr: 2.4773e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4256/  8460 | global iter:   4256/  8460 | loss: 0.0807 | ds_loss: 0.0000 | lr: 2.4764e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4256/  8460 | global iter:   4256/  8460 | loss: 0.1484 | ds_loss: 0.0000 | lr: 2.4764e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4257/  8460 | global iter:   4257/  8460 | loss: 0.0889 | ds_loss: 0.0000 | lr: 2.4754e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4258/  8460 | global iter:   4258/  8460 | loss: 0.1035 | ds_loss: 0.0000 | lr: 2.4745e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4259/  8460 | global iter:   4259/  8460 | loss: 0.1610 | ds_loss: 0.0000 | lr: 2.4736e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4260/  8460 | global iter:   4260/  8460 | loss: 0.0352 | ds_loss: 0.0000 | lr: 2.4727e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4260/  8460 | global iter:   4260/  8460 | loss: 0.0972 | ds_loss: 0.0000 | lr: 2.4727e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4261/  8460 | global iter:   4261/  8460 | loss: 0.0932 | ds_loss: 0.0000 | lr: 2.4717e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4262/  8460 | global iter:   4262/  8460 | loss: 0.1406 | ds_loss: 0.0000 | lr: 2.4708e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4263/  8460 | global iter:   4263/  8460 | loss: 0.0482 | ds_loss: 0.0000 | lr: 2.4699e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4264/  8460 | global iter:   4264/  8460 | loss: 0.1398 | ds_loss: 0.0000 | lr: 2.4689e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4264/  8460 | global iter:   4264/  8460 | loss: 0.1055 | ds_loss: 0.0000 | lr: 2.4689e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4265/  8460 | global iter:   4265/  8460 | loss: 0.0501 | ds_loss: 0.0000 | lr: 2.4680e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4266/  8460 | global iter:   4266/  8460 | loss: 0.0274 | ds_loss: 0.0000 | lr: 2.4671e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4267/  8460 | global iter:   4267/  8460 | loss: 0.2969 | ds_loss: 0.0000 | lr: 2.4662e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4268/  8460 | global iter:   4268/  8460 | loss: 0.1750 | ds_loss: 0.0000 | lr: 2.4652e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4268/  8460 | global iter:   4268/  8460 | loss: 0.1374 | ds_loss: 0.0000 | lr: 2.4652e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4269/  8460 | global iter:   4269/  8460 | loss: 0.3406 | ds_loss: 0.0000 | lr: 2.4643e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4270/  8460 | global iter:   4270/  8460 | loss: 0.3368 | ds_loss: 0.0000 | lr: 2.4634e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4271/  8460 | global iter:   4271/  8460 | loss: 0.2219 | ds_loss: 0.0000 | lr: 2.4624e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4272/  8460 | global iter:   4272/  8460 | loss: 0.4093 | ds_loss: 0.0000 | lr: 2.4615e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4272/  8460 | global iter:   4272/  8460 | loss: 0.3271 | ds_loss: 0.0000 | lr: 2.4615e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4273/  8460 | global iter:   4273/  8460 | loss: 0.1541 | ds_loss: 0.0000 | lr: 2.4606e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4274/  8460 | global iter:   4274/  8460 | loss: 0.3823 | ds_loss: 0.0000 | lr: 2.4597e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4275/  8460 | global iter:   4275/  8460 | loss: 0.1981 | ds_loss: 0.0000 | lr: 2.4587e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4276/  8460 | global iter:   4276/  8460 | loss: 0.0780 | ds_loss: 0.0000 | lr: 2.4578e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4276/  8460 | global iter:   4276/  8460 | loss: 0.2031 | ds_loss: 0.0000 | lr: 2.4578e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4277/  8460 | global iter:   4277/  8460 | loss: 0.0944 | ds_loss: 0.0000 | lr: 2.4569e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4278/  8460 | global iter:   4278/  8460 | loss: 0.1729 | ds_loss: 0.0000 | lr: 2.4559e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4279/  8460 | global iter:   4279/  8460 | loss: 0.5044 | ds_loss: 0.0000 | lr: 2.4550e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4280/  8460 | global iter:   4280/  8460 | loss: 0.0743 | ds_loss: 0.0000 | lr: 2.4541e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4280/  8460 | global iter:   4280/  8460 | loss: 0.2115 | ds_loss: 0.0000 | lr: 2.4541e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4281/  8460 | global iter:   4281/  8460 | loss: 0.2168 | ds_loss: 0.0000 | lr: 2.4532e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4282/  8460 | global iter:   4282/  8460 | loss: 0.2982 | ds_loss: 0.0000 | lr: 2.4522e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4283/  8460 | global iter:   4283/  8460 | loss: 0.6178 | ds_loss: 0.0000 | lr: 2.4513e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4284/  8460 | global iter:   4284/  8460 | loss: 0.1245 | ds_loss: 0.0000 | lr: 2.4504e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4284/  8460 | global iter:   4284/  8460 | loss: 0.3143 | ds_loss: 0.0000 | lr: 2.4504e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4285/  8460 | global iter:   4285/  8460 | loss: 0.1534 | ds_loss: 0.0000 | lr: 2.4495e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4286/  8460 | global iter:   4286/  8460 | loss: 0.1979 | ds_loss: 0.0000 | lr: 2.4485e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4287/  8460 | global iter:   4287/  8460 | loss: 0.1712 | ds_loss: 0.0000 | lr: 2.4476e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4288/  8460 | global iter:   4288/  8460 | loss: 0.1206 | ds_loss: 0.0000 | lr: 2.4467e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4288/  8460 | global iter:   4288/  8460 | loss: 0.1608 | ds_loss: 0.0000 | lr: 2.4467e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4289/  8460 | global iter:   4289/  8460 | loss: 0.2575 | ds_loss: 0.0000 | lr: 2.4457e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4290/  8460 | global iter:   4290/  8460 | loss: 0.3473 | ds_loss: 0.0000 | lr: 2.4448e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4291/  8460 | global iter:   4291/  8460 | loss: 0.1684 | ds_loss: 0.0000 | lr: 2.4439e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4292/  8460 | global iter:   4292/  8460 | loss: 0.1525 | ds_loss: 0.0000 | lr: 2.4430e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4292/  8460 | global iter:   4292/  8460 | loss: 0.2314 | ds_loss: 0.0000 | lr: 2.4430e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4293/  8460 | global iter:   4293/  8460 | loss: 0.1919 | ds_loss: 0.0000 | lr: 2.4420e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4294/  8460 | global iter:   4294/  8460 | loss: 0.1368 | ds_loss: 0.0000 | lr: 2.4411e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4295/  8460 | global iter:   4295/  8460 | loss: 0.0697 | ds_loss: 0.0000 | lr: 2.4402e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4296/  8460 | global iter:   4296/  8460 | loss: 0.4242 | ds_loss: 0.0000 | lr: 2.4392e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4296/  8460 | global iter:   4296/  8460 | loss: 0.2057 | ds_loss: 0.0000 | lr: 2.4392e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4297/  8460 | global iter:   4297/  8460 | loss: 0.1601 | ds_loss: 0.0000 | lr: 2.4383e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4298/  8460 | global iter:   4298/  8460 | loss: 0.2278 | ds_loss: 0.0000 | lr: 2.4374e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4299/  8460 | global iter:   4299/  8460 | loss: 0.1309 | ds_loss: 0.0000 | lr: 2.4365e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4300/  8460 | global iter:   4300/  8460 | loss: 0.0918 | ds_loss: 0.0000 | lr: 2.4355e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4300/  8460 | global iter:   4300/  8460 | loss: 0.1527 | ds_loss: 0.0000 | lr: 2.4355e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4301/  8460 | global iter:   4301/  8460 | loss: 0.3036 | ds_loss: 0.0000 | lr: 2.4346e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4302/  8460 | global iter:   4302/  8460 | loss: 0.1232 | ds_loss: 0.0000 | lr: 2.4337e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4303/  8460 | global iter:   4303/  8460 | loss: 0.0282 | ds_loss: 0.0000 | lr: 2.4328e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4304/  8460 | global iter:   4304/  8460 | loss: 0.0792 | ds_loss: 0.0000 | lr: 2.4318e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4304/  8460 | global iter:   4304/  8460 | loss: 0.1336 | ds_loss: 0.0000 | lr: 2.4318e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4305/  8460 | global iter:   4305/  8460 | loss: 0.1384 | ds_loss: 0.0000 | lr: 2.4309e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4306/  8460 | global iter:   4306/  8460 | loss: 0.2514 | ds_loss: 0.0000 | lr: 2.4300e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4307/  8460 | global iter:   4307/  8460 | loss: 0.1140 | ds_loss: 0.0000 | lr: 2.4290e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4308/  8460 | global iter:   4308/  8460 | loss: 0.2448 | ds_loss: 0.0000 | lr: 2.4281e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4308/  8460 | global iter:   4308/  8460 | loss: 0.1872 | ds_loss: 0.0000 | lr: 2.4281e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4309/  8460 | global iter:   4309/  8460 | loss: 0.2433 | ds_loss: 0.0000 | lr: 2.4272e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4310/  8460 | global iter:   4310/  8460 | loss: 0.1454 | ds_loss: 0.0000 | lr: 2.4263e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4311/  8460 | global iter:   4311/  8460 | loss: 0.3995 | ds_loss: 0.0000 | lr: 2.4253e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4312/  8460 | global iter:   4312/  8460 | loss: 0.2908 | ds_loss: 0.0000 | lr: 2.4244e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4312/  8460 | global iter:   4312/  8460 | loss: 0.2698 | ds_loss: 0.0000 | lr: 2.4244e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4313/  8460 | global iter:   4313/  8460 | loss: 0.5142 | ds_loss: 0.0000 | lr: 2.4235e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4314/  8460 | global iter:   4314/  8460 | loss: 0.1499 | ds_loss: 0.0000 | lr: 2.4225e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4315/  8460 | global iter:   4315/  8460 | loss: 0.1092 | ds_loss: 0.0000 | lr: 2.4216e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4316/  8460 | global iter:   4316/  8460 | loss: 0.1816 | ds_loss: 0.0000 | lr: 2.4207e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4316/  8460 | global iter:   4316/  8460 | loss: 0.2387 | ds_loss: 0.0000 | lr: 2.4207e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4317/  8460 | global iter:   4317/  8460 | loss: 0.3279 | ds_loss: 0.0000 | lr: 2.4198e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4318/  8460 | global iter:   4318/  8460 | loss: 0.4182 | ds_loss: 0.0000 | lr: 2.4188e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4319/  8460 | global iter:   4319/  8460 | loss: 0.0860 | ds_loss: 0.0000 | lr: 2.4179e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4320/  8460 | global iter:   4320/  8460 | loss: 0.1168 | ds_loss: 0.0000 | lr: 2.4170e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4320/  8460 | global iter:   4320/  8460 | loss: 0.2372 | ds_loss: 0.0000 | lr: 2.4170e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4321/  8460 | global iter:   4321/  8460 | loss: 0.2369 | ds_loss: 0.0000 | lr: 2.4161e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4322/  8460 | global iter:   4322/  8460 | loss: 0.2708 | ds_loss: 0.0000 | lr: 2.4151e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4323/  8460 | global iter:   4323/  8460 | loss: 0.0701 | ds_loss: 0.0000 | lr: 2.4142e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4324/  8460 | global iter:   4324/  8460 | loss: 0.1637 | ds_loss: 0.0000 | lr: 2.4133e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4324/  8460 | global iter:   4324/  8460 | loss: 0.1854 | ds_loss: 0.0000 | lr: 2.4133e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4325/  8460 | global iter:   4325/  8460 | loss: 0.1374 | ds_loss: 0.0000 | lr: 2.4123e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4326/  8460 | global iter:   4326/  8460 | loss: 0.1567 | ds_loss: 0.0000 | lr: 2.4114e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4327/  8460 | global iter:   4327/  8460 | loss: 0.7338 | ds_loss: 0.0000 | lr: 2.4105e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4328/  8460 | global iter:   4328/  8460 | loss: 0.1814 | ds_loss: 0.0000 | lr: 2.4096e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4328/  8460 | global iter:   4328/  8460 | loss: 0.3023 | ds_loss: 0.0000 | lr: 2.4096e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4329/  8460 | global iter:   4329/  8460 | loss: 0.1340 | ds_loss: 0.0000 | lr: 2.4086e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4330/  8460 | global iter:   4330/  8460 | loss: 0.3121 | ds_loss: 0.0000 | lr: 2.4077e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4331/  8460 | global iter:   4331/  8460 | loss: 0.1992 | ds_loss: 0.0000 | lr: 2.4068e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4332/  8460 | global iter:   4332/  8460 | loss: 0.2799 | ds_loss: 0.0000 | lr: 2.4058e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4332/  8460 | global iter:   4332/  8460 | loss: 0.2313 | ds_loss: 0.0000 | lr: 2.4058e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4333/  8460 | global iter:   4333/  8460 | loss: 0.1801 | ds_loss: 0.0000 | lr: 2.4049e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4334/  8460 | global iter:   4334/  8460 | loss: 0.2572 | ds_loss: 0.0000 | lr: 2.4040e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4335/  8460 | global iter:   4335/  8460 | loss: 0.1805 | ds_loss: 0.0000 | lr: 2.4031e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4336/  8460 | global iter:   4336/  8460 | loss: 0.1342 | ds_loss: 0.0000 | lr: 2.4021e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4336/  8460 | global iter:   4336/  8460 | loss: 0.1880 | ds_loss: 0.0000 | lr: 2.4021e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4337/  8460 | global iter:   4337/  8460 | loss: 0.2399 | ds_loss: 0.0000 | lr: 2.4012e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4338/  8460 | global iter:   4338/  8460 | loss: 0.0660 | ds_loss: 0.0000 | lr: 2.4003e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4339/  8460 | global iter:   4339/  8460 | loss: 0.3570 | ds_loss: 0.0000 | lr: 2.3994e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4340/  8460 | global iter:   4340/  8460 | loss: 0.1410 | ds_loss: 0.0000 | lr: 2.3984e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4340/  8460 | global iter:   4340/  8460 | loss: 0.2010 | ds_loss: 0.0000 | lr: 2.3984e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4341/  8460 | global iter:   4341/  8460 | loss: 0.3723 | ds_loss: 0.0000 | lr: 2.3975e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4342/  8460 | global iter:   4342/  8460 | loss: 0.1836 | ds_loss: 0.0000 | lr: 2.3966e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4343/  8460 | global iter:   4343/  8460 | loss: 0.3247 | ds_loss: 0.0000 | lr: 2.3956e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4344/  8460 | global iter:   4344/  8460 | loss: 0.1074 | ds_loss: 0.0000 | lr: 2.3947e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4344/  8460 | global iter:   4344/  8460 | loss: 0.2470 | ds_loss: 0.0000 | lr: 2.3947e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4345/  8460 | global iter:   4345/  8460 | loss: 0.1645 | ds_loss: 0.0000 | lr: 2.3938e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4346/  8460 | global iter:   4346/  8460 | loss: 0.1171 | ds_loss: 0.0000 | lr: 2.3929e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4347/  8460 | global iter:   4347/  8460 | loss: 0.1767 | ds_loss: 0.0000 | lr: 2.3919e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4348/  8460 | global iter:   4348/  8460 | loss: 0.1804 | ds_loss: 0.0000 | lr: 2.3910e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4348/  8460 | global iter:   4348/  8460 | loss: 0.1597 | ds_loss: 0.0000 | lr: 2.3910e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4349/  8460 | global iter:   4349/  8460 | loss: 0.1794 | ds_loss: 0.0000 | lr: 2.3901e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4350/  8460 | global iter:   4350/  8460 | loss: 0.0432 | ds_loss: 0.0000 | lr: 2.3892e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4351/  8460 | global iter:   4351/  8460 | loss: 0.2331 | ds_loss: 0.0000 | lr: 2.3882e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4352/  8460 | global iter:   4352/  8460 | loss: 0.2174 | ds_loss: 0.0000 | lr: 2.3873e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4352/  8460 | global iter:   4352/  8460 | loss: 0.1683 | ds_loss: 0.0000 | lr: 2.3873e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4353/  8460 | global iter:   4353/  8460 | loss: 0.0720 | ds_loss: 0.0000 | lr: 2.3864e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4354/  8460 | global iter:   4354/  8460 | loss: 0.3262 | ds_loss: 0.0000 | lr: 2.3854e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4355/  8460 | global iter:   4355/  8460 | loss: 0.0703 | ds_loss: 0.0000 | lr: 2.3845e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4356/  8460 | global iter:   4356/  8460 | loss: 0.1803 | ds_loss: 0.0000 | lr: 2.3836e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4356/  8460 | global iter:   4356/  8460 | loss: 0.1622 | ds_loss: 0.0000 | lr: 2.3836e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4357/  8460 | global iter:   4357/  8460 | loss: 0.2098 | ds_loss: 0.0000 | lr: 2.3827e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4358/  8460 | global iter:   4358/  8460 | loss: 0.1075 | ds_loss: 0.0000 | lr: 2.3817e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4359/  8460 | global iter:   4359/  8460 | loss: 0.1735 | ds_loss: 0.0000 | lr: 2.3808e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4360/  8460 | global iter:   4360/  8460 | loss: 0.3837 | ds_loss: 0.0000 | lr: 2.3799e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4360/  8460 | global iter:   4360/  8460 | loss: 0.2186 | ds_loss: 0.0000 | lr: 2.3799e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4361/  8460 | global iter:   4361/  8460 | loss: 0.1435 | ds_loss: 0.0000 | lr: 2.3790e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4362/  8460 | global iter:   4362/  8460 | loss: 0.1338 | ds_loss: 0.0000 | lr: 2.3780e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4363/  8460 | global iter:   4363/  8460 | loss: 0.0765 | ds_loss: 0.0000 | lr: 2.3771e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4364/  8460 | global iter:   4364/  8460 | loss: 0.4459 | ds_loss: 0.0000 | lr: 2.3762e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4364/  8460 | global iter:   4364/  8460 | loss: 0.1999 | ds_loss: 0.0000 | lr: 2.3762e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4365/  8460 | global iter:   4365/  8460 | loss: 0.4291 | ds_loss: 0.0000 | lr: 2.3752e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4366/  8460 | global iter:   4366/  8460 | loss: 0.0956 | ds_loss: 0.0000 | lr: 2.3743e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4367/  8460 | global iter:   4367/  8460 | loss: 0.3473 | ds_loss: 0.0000 | lr: 2.3734e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4368/  8460 | global iter:   4368/  8460 | loss: 0.2385 | ds_loss: 0.0000 | lr: 2.3725e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4368/  8460 | global iter:   4368/  8460 | loss: 0.2776 | ds_loss: 0.0000 | lr: 2.3725e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4369/  8460 | global iter:   4369/  8460 | loss: 0.0421 | ds_loss: 0.0000 | lr: 2.3715e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4370/  8460 | global iter:   4370/  8460 | loss: 0.3024 | ds_loss: 0.0000 | lr: 2.3706e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4371/  8460 | global iter:   4371/  8460 | loss: 0.3198 | ds_loss: 0.0000 | lr: 2.3697e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4372/  8460 | global iter:   4372/  8460 | loss: 0.1915 | ds_loss: 0.0000 | lr: 2.3688e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4372/  8460 | global iter:   4372/  8460 | loss: 0.2139 | ds_loss: 0.0000 | lr: 2.3688e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4373/  8460 | global iter:   4373/  8460 | loss: 0.3423 | ds_loss: 0.0000 | lr: 2.3678e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4374/  8460 | global iter:   4374/  8460 | loss: 0.1527 | ds_loss: 0.0000 | lr: 2.3669e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4375/  8460 | global iter:   4375/  8460 | loss: 0.1867 | ds_loss: 0.0000 | lr: 2.3660e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4376/  8460 | global iter:   4376/  8460 | loss: 0.1195 | ds_loss: 0.0000 | lr: 2.3651e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4376/  8460 | global iter:   4376/  8460 | loss: 0.2003 | ds_loss: 0.0000 | lr: 2.3651e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4377/  8460 | global iter:   4377/  8460 | loss: 0.4736 | ds_loss: 0.0000 | lr: 2.3641e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4378/  8460 | global iter:   4378/  8460 | loss: 0.1779 | ds_loss: 0.0000 | lr: 2.3632e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4379/  8460 | global iter:   4379/  8460 | loss: 0.1232 | ds_loss: 0.0000 | lr: 2.3623e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4380/  8460 | global iter:   4380/  8460 | loss: 0.3381 | ds_loss: 0.0000 | lr: 2.3613e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4380/  8460 | global iter:   4380/  8460 | loss: 0.2782 | ds_loss: 0.0000 | lr: 2.3613e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4381/  8460 | global iter:   4381/  8460 | loss: 0.4275 | ds_loss: 0.0000 | lr: 2.3604e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4382/  8460 | global iter:   4382/  8460 | loss: 0.0982 | ds_loss: 0.0000 | lr: 2.3595e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4383/  8460 | global iter:   4383/  8460 | loss: 0.1184 | ds_loss: 0.0000 | lr: 2.3586e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4384/  8460 | global iter:   4384/  8460 | loss: 0.1933 | ds_loss: 0.0000 | lr: 2.3576e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4384/  8460 | global iter:   4384/  8460 | loss: 0.2093 | ds_loss: 0.0000 | lr: 2.3576e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4385/  8460 | global iter:   4385/  8460 | loss: 0.0744 | ds_loss: 0.0000 | lr: 2.3567e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4386/  8460 | global iter:   4386/  8460 | loss: 0.1334 | ds_loss: 0.0000 | lr: 2.3558e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4387/  8460 | global iter:   4387/  8460 | loss: 0.1406 | ds_loss: 0.0000 | lr: 2.3549e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4388/  8460 | global iter:   4388/  8460 | loss: 0.2287 | ds_loss: 0.0000 | lr: 2.3539e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4388/  8460 | global iter:   4388/  8460 | loss: 0.1443 | ds_loss: 0.0000 | lr: 2.3539e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4389/  8460 | global iter:   4389/  8460 | loss: 0.1701 | ds_loss: 0.0000 | lr: 2.3530e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4390/  8460 | global iter:   4390/  8460 | loss: 0.2517 | ds_loss: 0.0000 | lr: 2.3521e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4391/  8460 | global iter:   4391/  8460 | loss: 0.0807 | ds_loss: 0.0000 | lr: 2.3512e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4392/  8460 | global iter:   4392/  8460 | loss: 0.1712 | ds_loss: 0.0000 | lr: 2.3502e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4392/  8460 | global iter:   4392/  8460 | loss: 0.1684 | ds_loss: 0.0000 | lr: 2.3502e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4393/  8460 | global iter:   4393/  8460 | loss: 0.1699 | ds_loss: 0.0000 | lr: 2.3493e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4394/  8460 | global iter:   4394/  8460 | loss: 0.2326 | ds_loss: 0.0000 | lr: 2.3484e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4395/  8460 | global iter:   4395/  8460 | loss: 0.3823 | ds_loss: 0.0000 | lr: 2.3474e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4396/  8460 | global iter:   4396/  8460 | loss: 0.2749 | ds_loss: 0.0000 | lr: 2.3465e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4396/  8460 | global iter:   4396/  8460 | loss: 0.2649 | ds_loss: 0.0000 | lr: 2.3465e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4397/  8460 | global iter:   4397/  8460 | loss: 0.0820 | ds_loss: 0.0000 | lr: 2.3456e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4398/  8460 | global iter:   4398/  8460 | loss: 0.3221 | ds_loss: 0.0000 | lr: 2.3447e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4399/  8460 | global iter:   4399/  8460 | loss: 0.0631 | ds_loss: 0.0000 | lr: 2.3437e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4400/  8460 | global iter:   4400/  8460 | loss: 0.3729 | ds_loss: 0.0000 | lr: 2.3428e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4400/  8460 | global iter:   4400/  8460 | loss: 0.2100 | ds_loss: 0.0000 | lr: 2.3428e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4401/  8460 | global iter:   4401/  8460 | loss: 0.4569 | ds_loss: 0.0000 | lr: 2.3419e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4402/  8460 | global iter:   4402/  8460 | loss: 0.1063 | ds_loss: 0.0000 | lr: 2.3410e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4403/  8460 | global iter:   4403/  8460 | loss: 0.5660 | ds_loss: 0.0000 | lr: 2.3400e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4404/  8460 | global iter:   4404/  8460 | loss: 0.0227 | ds_loss: 0.0000 | lr: 2.3391e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4404/  8460 | global iter:   4404/  8460 | loss: 0.2880 | ds_loss: 0.0000 | lr: 2.3391e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4405/  8460 | global iter:   4405/  8460 | loss: 0.1248 | ds_loss: 0.0000 | lr: 2.3382e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4406/  8460 | global iter:   4406/  8460 | loss: 0.2563 | ds_loss: 0.0000 | lr: 2.3373e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4407/  8460 | global iter:   4407/  8460 | loss: 0.0597 | ds_loss: 0.0000 | lr: 2.3363e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4408/  8460 | global iter:   4408/  8460 | loss: 0.0869 | ds_loss: 0.0000 | lr: 2.3354e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4408/  8460 | global iter:   4408/  8460 | loss: 0.1319 | ds_loss: 0.0000 | lr: 2.3354e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4409/  8460 | global iter:   4409/  8460 | loss: 0.1347 | ds_loss: 0.0000 | lr: 2.3345e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4410/  8460 | global iter:   4410/  8460 | loss: 0.1385 | ds_loss: 0.0000 | lr: 2.3336e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4411/  8460 | global iter:   4411/  8460 | loss: 0.6903 | ds_loss: 0.0000 | lr: 2.3326e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4412/  8460 | global iter:   4412/  8460 | loss: 0.1997 | ds_loss: 0.0000 | lr: 2.3317e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4412/  8460 | global iter:   4412/  8460 | loss: 0.2908 | ds_loss: 0.0000 | lr: 2.3317e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4413/  8460 | global iter:   4413/  8460 | loss: 0.0560 | ds_loss: 0.0000 | lr: 2.3308e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4414/  8460 | global iter:   4414/  8460 | loss: 0.0861 | ds_loss: 0.0000 | lr: 2.3298e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4415/  8460 | global iter:   4415/  8460 | loss: 0.1552 | ds_loss: 0.0000 | lr: 2.3289e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4416/  8460 | global iter:   4416/  8460 | loss: 0.3657 | ds_loss: 0.0000 | lr: 2.3280e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4416/  8460 | global iter:   4416/  8460 | loss: 0.1658 | ds_loss: 0.0000 | lr: 2.3280e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4417/  8460 | global iter:   4417/  8460 | loss: 0.4547 | ds_loss: 0.0000 | lr: 2.3271e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4418/  8460 | global iter:   4418/  8460 | loss: 0.1414 | ds_loss: 0.0000 | lr: 2.3261e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4419/  8460 | global iter:   4419/  8460 | loss: 0.3912 | ds_loss: 0.0000 | lr: 2.3252e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4420/  8460 | global iter:   4420/  8460 | loss: 0.1309 | ds_loss: 0.0000 | lr: 2.3243e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4420/  8460 | global iter:   4420/  8460 | loss: 0.2795 | ds_loss: 0.0000 | lr: 2.3243e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4421/  8460 | global iter:   4421/  8460 | loss: 0.0500 | ds_loss: 0.0000 | lr: 2.3234e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4422/  8460 | global iter:   4422/  8460 | loss: 0.3526 | ds_loss: 0.0000 | lr: 2.3224e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4423/  8460 | global iter:   4423/  8460 | loss: 0.1499 | ds_loss: 0.0000 | lr: 2.3215e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4424/  8460 | global iter:   4424/  8460 | loss: 0.0759 | ds_loss: 0.0000 | lr: 2.3206e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4424/  8460 | global iter:   4424/  8460 | loss: 0.1571 | ds_loss: 0.0000 | lr: 2.3206e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4425/  8460 | global iter:   4425/  8460 | loss: 0.2064 | ds_loss: 0.0000 | lr: 2.3197e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4426/  8460 | global iter:   4426/  8460 | loss: 0.2184 | ds_loss: 0.0000 | lr: 2.3187e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4427/  8460 | global iter:   4427/  8460 | loss: 0.1483 | ds_loss: 0.0000 | lr: 2.3178e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4428/  8460 | global iter:   4428/  8460 | loss: 0.1382 | ds_loss: 0.0000 | lr: 2.3169e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4428/  8460 | global iter:   4428/  8460 | loss: 0.1778 | ds_loss: 0.0000 | lr: 2.3169e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4429/  8460 | global iter:   4429/  8460 | loss: 0.2131 | ds_loss: 0.0000 | lr: 2.3160e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4430/  8460 | global iter:   4430/  8460 | loss: 0.1919 | ds_loss: 0.0000 | lr: 2.3150e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4431/  8460 | global iter:   4431/  8460 | loss: 0.1740 | ds_loss: 0.0000 | lr: 2.3141e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4432/  8460 | global iter:   4432/  8460 | loss: 0.1149 | ds_loss: 0.0000 | lr: 2.3132e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4432/  8460 | global iter:   4432/  8460 | loss: 0.1735 | ds_loss: 0.0000 | lr: 2.3132e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4433/  8460 | global iter:   4433/  8460 | loss: 0.2019 | ds_loss: 0.0000 | lr: 2.3123e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4434/  8460 | global iter:   4434/  8460 | loss: 0.4014 | ds_loss: 0.0000 | lr: 2.3113e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4435/  8460 | global iter:   4435/  8460 | loss: 0.2131 | ds_loss: 0.0000 | lr: 2.3104e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4436/  8460 | global iter:   4436/  8460 | loss: 0.0619 | ds_loss: 0.0000 | lr: 2.3095e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4436/  8460 | global iter:   4436/  8460 | loss: 0.2196 | ds_loss: 0.0000 | lr: 2.3095e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4437/  8460 | global iter:   4437/  8460 | loss: 0.1009 | ds_loss: 0.0000 | lr: 2.3086e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4438/  8460 | global iter:   4438/  8460 | loss: 0.4258 | ds_loss: 0.0000 | lr: 2.3076e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4439/  8460 | global iter:   4439/  8460 | loss: 0.2201 | ds_loss: 0.0000 | lr: 2.3067e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4440/  8460 | global iter:   4440/  8460 | loss: 0.3918 | ds_loss: 0.0000 | lr: 2.3058e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4440/  8460 | global iter:   4440/  8460 | loss: 0.2847 | ds_loss: 0.0000 | lr: 2.3058e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4441/  8460 | global iter:   4441/  8460 | loss: 0.1639 | ds_loss: 0.0000 | lr: 2.3049e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4442/  8460 | global iter:   4442/  8460 | loss: 0.3039 | ds_loss: 0.0000 | lr: 2.3039e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4443/  8460 | global iter:   4443/  8460 | loss: 0.1895 | ds_loss: 0.0000 | lr: 2.3030e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4444/  8460 | global iter:   4444/  8460 | loss: 0.2963 | ds_loss: 0.0000 | lr: 2.3021e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4444/  8460 | global iter:   4444/  8460 | loss: 0.2384 | ds_loss: 0.0000 | lr: 2.3021e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4445/  8460 | global iter:   4445/  8460 | loss: 0.2228 | ds_loss: 0.0000 | lr: 2.3012e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4446/  8460 | global iter:   4446/  8460 | loss: 0.2360 | ds_loss: 0.0000 | lr: 2.3002e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4447/  8460 | global iter:   4447/  8460 | loss: 0.1891 | ds_loss: 0.0000 | lr: 2.2993e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4448/  8460 | global iter:   4448/  8460 | loss: 0.1416 | ds_loss: 0.0000 | lr: 2.2984e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4448/  8460 | global iter:   4448/  8460 | loss: 0.1974 | ds_loss: 0.0000 | lr: 2.2984e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4449/  8460 | global iter:   4449/  8460 | loss: 0.1925 | ds_loss: 0.0000 | lr: 2.2975e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4450/  8460 | global iter:   4450/  8460 | loss: 0.1092 | ds_loss: 0.0000 | lr: 2.2965e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4451/  8460 | global iter:   4451/  8460 | loss: 0.2396 | ds_loss: 0.0000 | lr: 2.2956e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4452/  8460 | global iter:   4452/  8460 | loss: 0.0766 | ds_loss: 0.0000 | lr: 2.2947e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4452/  8460 | global iter:   4452/  8460 | loss: 0.1545 | ds_loss: 0.0000 | lr: 2.2947e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4453/  8460 | global iter:   4453/  8460 | loss: 0.2469 | ds_loss: 0.0000 | lr: 2.2938e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4454/  8460 | global iter:   4454/  8460 | loss: 0.1146 | ds_loss: 0.0000 | lr: 2.2928e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4455/  8460 | global iter:   4455/  8460 | loss: 0.2923 | ds_loss: 0.0000 | lr: 2.2919e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4456/  8460 | global iter:   4456/  8460 | loss: 0.2355 | ds_loss: 0.0000 | lr: 2.2910e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4456/  8460 | global iter:   4456/  8460 | loss: 0.2223 | ds_loss: 0.0000 | lr: 2.2910e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4457/  8460 | global iter:   4457/  8460 | loss: 0.1756 | ds_loss: 0.0000 | lr: 2.2901e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4458/  8460 | global iter:   4458/  8460 | loss: 0.4605 | ds_loss: 0.0000 | lr: 2.2891e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4459/  8460 | global iter:   4459/  8460 | loss: 0.1305 | ds_loss: 0.0000 | lr: 2.2882e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4460/  8460 | global iter:   4460/  8460 | loss: 0.1324 | ds_loss: 0.0000 | lr: 2.2873e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4460/  8460 | global iter:   4460/  8460 | loss: 0.2248 | ds_loss: 0.0000 | lr: 2.2873e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4461/  8460 | global iter:   4461/  8460 | loss: 0.1209 | ds_loss: 0.0000 | lr: 2.2864e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4462/  8460 | global iter:   4462/  8460 | loss: 0.3328 | ds_loss: 0.0000 | lr: 2.2854e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4463/  8460 | global iter:   4463/  8460 | loss: 0.1802 | ds_loss: 0.0000 | lr: 2.2845e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4464/  8460 | global iter:   4464/  8460 | loss: 0.3905 | ds_loss: 0.0000 | lr: 2.2836e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4464/  8460 | global iter:   4464/  8460 | loss: 0.2561 | ds_loss: 0.0000 | lr: 2.2836e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4465/  8460 | global iter:   4465/  8460 | loss: 0.1177 | ds_loss: 0.0000 | lr: 2.2827e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4466/  8460 | global iter:   4466/  8460 | loss: 0.5451 | ds_loss: 0.0000 | lr: 2.2817e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4467/  8460 | global iter:   4467/  8460 | loss: 0.0225 | ds_loss: 0.0000 | lr: 2.2808e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4468/  8460 | global iter:   4468/  8460 | loss: 0.4329 | ds_loss: 0.0000 | lr: 2.2799e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4468/  8460 | global iter:   4468/  8460 | loss: 0.2796 | ds_loss: 0.0000 | lr: 2.2799e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4469/  8460 | global iter:   4469/  8460 | loss: 0.4484 | ds_loss: 0.0000 | lr: 2.2790e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4470/  8460 | global iter:   4470/  8460 | loss: 0.5561 | ds_loss: 0.0000 | lr: 2.2780e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4471/  8460 | global iter:   4471/  8460 | loss: 0.1628 | ds_loss: 0.0000 | lr: 2.2771e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4472/  8460 | global iter:   4472/  8460 | loss: 0.0894 | ds_loss: 0.0000 | lr: 2.2762e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4472/  8460 | global iter:   4472/  8460 | loss: 0.3142 | ds_loss: 0.0000 | lr: 2.2762e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4473/  8460 | global iter:   4473/  8460 | loss: 0.5033 | ds_loss: 0.0000 | lr: 2.2753e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4474/  8460 | global iter:   4474/  8460 | loss: 0.0755 | ds_loss: 0.0000 | lr: 2.2743e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4475/  8460 | global iter:   4475/  8460 | loss: 0.0870 | ds_loss: 0.0000 | lr: 2.2734e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4476/  8460 | global iter:   4476/  8460 | loss: 0.2874 | ds_loss: 0.0000 | lr: 2.2725e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4476/  8460 | global iter:   4476/  8460 | loss: 0.2383 | ds_loss: 0.0000 | lr: 2.2725e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4477/  8460 | global iter:   4477/  8460 | loss: 0.2792 | ds_loss: 0.0000 | lr: 2.2716e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4478/  8460 | global iter:   4478/  8460 | loss: 0.1217 | ds_loss: 0.0000 | lr: 2.2706e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4479/  8460 | global iter:   4479/  8460 | loss: 0.2051 | ds_loss: 0.0000 | lr: 2.2697e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4480/  8460 | global iter:   4480/  8460 | loss: 0.0983 | ds_loss: 0.0000 | lr: 2.2688e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4480/  8460 | global iter:   4480/  8460 | loss: 0.1761 | ds_loss: 0.0000 | lr: 2.2688e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4481/  8460 | global iter:   4481/  8460 | loss: 0.2907 | ds_loss: 0.0000 | lr: 2.2679e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4482/  8460 | global iter:   4482/  8460 | loss: 0.1564 | ds_loss: 0.0000 | lr: 2.2669e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4483/  8460 | global iter:   4483/  8460 | loss: 0.1141 | ds_loss: 0.0000 | lr: 2.2660e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4484/  8460 | global iter:   4484/  8460 | loss: 0.2199 | ds_loss: 0.0000 | lr: 2.2651e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4484/  8460 | global iter:   4484/  8460 | loss: 0.1953 | ds_loss: 0.0000 | lr: 2.2651e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4485/  8460 | global iter:   4485/  8460 | loss: 0.1971 | ds_loss: 0.0000 | lr: 2.2642e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4486/  8460 | global iter:   4486/  8460 | loss: 0.1539 | ds_loss: 0.0000 | lr: 2.2632e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4487/  8460 | global iter:   4487/  8460 | loss: 0.5490 | ds_loss: 0.0000 | lr: 2.2623e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4488/  8460 | global iter:   4488/  8460 | loss: 0.1877 | ds_loss: 0.0000 | lr: 2.2614e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4488/  8460 | global iter:   4488/  8460 | loss: 0.2719 | ds_loss: 0.0000 | lr: 2.2614e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4489/  8460 | global iter:   4489/  8460 | loss: 0.1815 | ds_loss: 0.0000 | lr: 2.2605e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4490/  8460 | global iter:   4490/  8460 | loss: 0.2024 | ds_loss: 0.0000 | lr: 2.2595e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4491/  8460 | global iter:   4491/  8460 | loss: 0.2394 | ds_loss: 0.0000 | lr: 2.2586e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4492/  8460 | global iter:   4492/  8460 | loss: 0.1603 | ds_loss: 0.0000 | lr: 2.2577e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4492/  8460 | global iter:   4492/  8460 | loss: 0.1959 | ds_loss: 0.0000 | lr: 2.2577e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4493/  8460 | global iter:   4493/  8460 | loss: 0.1830 | ds_loss: 0.0000 | lr: 2.2568e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4494/  8460 | global iter:   4494/  8460 | loss: 0.1060 | ds_loss: 0.0000 | lr: 2.2559e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4495/  8460 | global iter:   4495/  8460 | loss: 0.1393 | ds_loss: 0.0000 | lr: 2.2549e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4496/  8460 | global iter:   4496/  8460 | loss: 0.3392 | ds_loss: 0.0000 | lr: 2.2540e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4496/  8460 | global iter:   4496/  8460 | loss: 0.1919 | ds_loss: 0.0000 | lr: 2.2540e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4497/  8460 | global iter:   4497/  8460 | loss: 0.1983 | ds_loss: 0.0000 | lr: 2.2531e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4498/  8460 | global iter:   4498/  8460 | loss: 0.1768 | ds_loss: 0.0000 | lr: 2.2522e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4499/  8460 | global iter:   4499/  8460 | loss: 0.1830 | ds_loss: 0.0000 | lr: 2.2512e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4500/  8460 | global iter:   4500/  8460 | loss: 0.0999 | ds_loss: 0.0000 | lr: 2.2503e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4500/  8460 | global iter:   4500/  8460 | loss: 0.1645 | ds_loss: 0.0000 | lr: 2.2503e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4501/  8460 | global iter:   4501/  8460 | loss: 0.2355 | ds_loss: 0.0000 | lr: 2.2494e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4502/  8460 | global iter:   4502/  8460 | loss: 0.3056 | ds_loss: 0.0000 | lr: 2.2485e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4503/  8460 | global iter:   4503/  8460 | loss: 0.2049 | ds_loss: 0.0000 | lr: 2.2475e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4504/  8460 | global iter:   4504/  8460 | loss: 0.1634 | ds_loss: 0.0000 | lr: 2.2466e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4504/  8460 | global iter:   4504/  8460 | loss: 0.2274 | ds_loss: 0.0000 | lr: 2.2466e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4505/  8460 | global iter:   4505/  8460 | loss: 0.3136 | ds_loss: 0.0000 | lr: 2.2457e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4506/  8460 | global iter:   4506/  8460 | loss: 0.1586 | ds_loss: 0.0000 | lr: 2.2448e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4507/  8460 | global iter:   4507/  8460 | loss: 0.3196 | ds_loss: 0.0000 | lr: 2.2438e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4508/  8460 | global iter:   4508/  8460 | loss: 0.1448 | ds_loss: 0.0000 | lr: 2.2429e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4508/  8460 | global iter:   4508/  8460 | loss: 0.2341 | ds_loss: 0.0000 | lr: 2.2429e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4509/  8460 | global iter:   4509/  8460 | loss: 0.3385 | ds_loss: 0.0000 | lr: 2.2420e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4510/  8460 | global iter:   4510/  8460 | loss: 0.0232 | ds_loss: 0.0000 | lr: 2.2411e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4511/  8460 | global iter:   4511/  8460 | loss: 0.2063 | ds_loss: 0.0000 | lr: 2.2402e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4512/  8460 | global iter:   4512/  8460 | loss: 0.2868 | ds_loss: 0.0000 | lr: 2.2392e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4512/  8460 | global iter:   4512/  8460 | loss: 0.2137 | ds_loss: 0.0000 | lr: 2.2392e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4513/  8460 | global iter:   4513/  8460 | loss: 0.5209 | ds_loss: 0.0000 | lr: 2.2383e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4514/  8460 | global iter:   4514/  8460 | loss: 0.0859 | ds_loss: 0.0000 | lr: 2.2374e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4515/  8460 | global iter:   4515/  8460 | loss: 0.1431 | ds_loss: 0.0000 | lr: 2.2365e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4516/  8460 | global iter:   4516/  8460 | loss: 0.2309 | ds_loss: 0.0000 | lr: 2.2355e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4516/  8460 | global iter:   4516/  8460 | loss: 0.2452 | ds_loss: 0.0000 | lr: 2.2355e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4517/  8460 | global iter:   4517/  8460 | loss: 0.1909 | ds_loss: 0.0000 | lr: 2.2346e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4518/  8460 | global iter:   4518/  8460 | loss: 0.0635 | ds_loss: 0.0000 | lr: 2.2337e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4519/  8460 | global iter:   4519/  8460 | loss: 0.0546 | ds_loss: 0.0000 | lr: 2.2328e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4520/  8460 | global iter:   4520/  8460 | loss: 0.2880 | ds_loss: 0.0000 | lr: 2.2318e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4520/  8460 | global iter:   4520/  8460 | loss: 0.1492 | ds_loss: 0.0000 | lr: 2.2318e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4521/  8460 | global iter:   4521/  8460 | loss: 0.2614 | ds_loss: 0.0000 | lr: 2.2309e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4522/  8460 | global iter:   4522/  8460 | loss: 0.2153 | ds_loss: 0.0000 | lr: 2.2300e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4523/  8460 | global iter:   4523/  8460 | loss: 0.1935 | ds_loss: 0.0000 | lr: 2.2291e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4524/  8460 | global iter:   4524/  8460 | loss: 0.1497 | ds_loss: 0.0000 | lr: 2.2282e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4524/  8460 | global iter:   4524/  8460 | loss: 0.2050 | ds_loss: 0.0000 | lr: 2.2282e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4525/  8460 | global iter:   4525/  8460 | loss: 0.1179 | ds_loss: 0.0000 | lr: 2.2272e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4526/  8460 | global iter:   4526/  8460 | loss: 0.1038 | ds_loss: 0.0000 | lr: 2.2263e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4527/  8460 | global iter:   4527/  8460 | loss: 0.1572 | ds_loss: 0.0000 | lr: 2.2254e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4528/  8460 | global iter:   4528/  8460 | loss: 0.4987 | ds_loss: 0.0000 | lr: 2.2245e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4528/  8460 | global iter:   4528/  8460 | loss: 0.2194 | ds_loss: 0.0000 | lr: 2.2245e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4529/  8460 | global iter:   4529/  8460 | loss: 0.6952 | ds_loss: 0.0000 | lr: 2.2235e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4530/  8460 | global iter:   4530/  8460 | loss: 0.4824 | ds_loss: 0.0000 | lr: 2.2226e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4531/  8460 | global iter:   4531/  8460 | loss: 0.1999 | ds_loss: 0.0000 | lr: 2.2217e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4532/  8460 | global iter:   4532/  8460 | loss: 0.0917 | ds_loss: 0.0000 | lr: 2.2208e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4532/  8460 | global iter:   4532/  8460 | loss: 0.3673 | ds_loss: 0.0000 | lr: 2.2208e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4533/  8460 | global iter:   4533/  8460 | loss: 0.0176 | ds_loss: 0.0000 | lr: 2.2199e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4534/  8460 | global iter:   4534/  8460 | loss: 0.3334 | ds_loss: 0.0000 | lr: 2.2189e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4535/  8460 | global iter:   4535/  8460 | loss: 0.2642 | ds_loss: 0.0000 | lr: 2.2180e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4536/  8460 | global iter:   4536/  8460 | loss: 0.5831 | ds_loss: 0.0000 | lr: 2.2171e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4536/  8460 | global iter:   4536/  8460 | loss: 0.2995 | ds_loss: 0.0000 | lr: 2.2171e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4537/  8460 | global iter:   4537/  8460 | loss: 0.1553 | ds_loss: 0.0000 | lr: 2.2162e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4538/  8460 | global iter:   4538/  8460 | loss: 0.1068 | ds_loss: 0.0000 | lr: 2.2152e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4539/  8460 | global iter:   4539/  8460 | loss: 0.0728 | ds_loss: 0.0000 | lr: 2.2143e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4540/  8460 | global iter:   4540/  8460 | loss: 0.1573 | ds_loss: 0.0000 | lr: 2.2134e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4540/  8460 | global iter:   4540/  8460 | loss: 0.1230 | ds_loss: 0.0000 | lr: 2.2134e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4541/  8460 | global iter:   4541/  8460 | loss: 0.1711 | ds_loss: 0.0000 | lr: 2.2125e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4542/  8460 | global iter:   4542/  8460 | loss: 0.2024 | ds_loss: 0.0000 | lr: 2.2116e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4543/  8460 | global iter:   4543/  8460 | loss: 0.3109 | ds_loss: 0.0000 | lr: 2.2106e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4544/  8460 | global iter:   4544/  8460 | loss: 0.1006 | ds_loss: 0.0000 | lr: 2.2097e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4544/  8460 | global iter:   4544/  8460 | loss: 0.1963 | ds_loss: 0.0000 | lr: 2.2097e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4545/  8460 | global iter:   4545/  8460 | loss: 0.0927 | ds_loss: 0.0000 | lr: 2.2088e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4546/  8460 | global iter:   4546/  8460 | loss: 0.0985 | ds_loss: 0.0000 | lr: 2.2079e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4547/  8460 | global iter:   4547/  8460 | loss: 0.1210 | ds_loss: 0.0000 | lr: 2.2069e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4548/  8460 | global iter:   4548/  8460 | loss: 0.0640 | ds_loss: 0.0000 | lr: 2.2060e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4548/  8460 | global iter:   4548/  8460 | loss: 0.0940 | ds_loss: 0.0000 | lr: 2.2060e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4549/  8460 | global iter:   4549/  8460 | loss: 0.3050 | ds_loss: 0.0000 | lr: 2.2051e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4550/  8460 | global iter:   4550/  8460 | loss: 0.2824 | ds_loss: 0.0000 | lr: 2.2042e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4551/  8460 | global iter:   4551/  8460 | loss: 0.2929 | ds_loss: 0.0000 | lr: 2.2033e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4552/  8460 | global iter:   4552/  8460 | loss: 0.6033 | ds_loss: 0.0000 | lr: 2.2023e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4552/  8460 | global iter:   4552/  8460 | loss: 0.3709 | ds_loss: 0.0000 | lr: 2.2023e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4553/  8460 | global iter:   4553/  8460 | loss: 0.0877 | ds_loss: 0.0000 | lr: 2.2014e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4554/  8460 | global iter:   4554/  8460 | loss: 0.1011 | ds_loss: 0.0000 | lr: 2.2005e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4555/  8460 | global iter:   4555/  8460 | loss: 0.1500 | ds_loss: 0.0000 | lr: 2.1996e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4556/  8460 | global iter:   4556/  8460 | loss: 0.1707 | ds_loss: 0.0000 | lr: 2.1987e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4556/  8460 | global iter:   4556/  8460 | loss: 0.1274 | ds_loss: 0.0000 | lr: 2.1987e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4557/  8460 | global iter:   4557/  8460 | loss: 0.1708 | ds_loss: 0.0000 | lr: 2.1977e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4558/  8460 | global iter:   4558/  8460 | loss: 0.4291 | ds_loss: 0.0000 | lr: 2.1968e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4559/  8460 | global iter:   4559/  8460 | loss: 0.0147 | ds_loss: 0.0000 | lr: 2.1959e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4560/  8460 | global iter:   4560/  8460 | loss: 0.1287 | ds_loss: 0.0000 | lr: 2.1950e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4560/  8460 | global iter:   4560/  8460 | loss: 0.1858 | ds_loss: 0.0000 | lr: 2.1950e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4561/  8460 | global iter:   4561/  8460 | loss: 0.0882 | ds_loss: 0.0000 | lr: 2.1940e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4562/  8460 | global iter:   4562/  8460 | loss: 0.1698 | ds_loss: 0.0000 | lr: 2.1931e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4563/  8460 | global iter:   4563/  8460 | loss: 0.2143 | ds_loss: 0.0000 | lr: 2.1922e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4564/  8460 | global iter:   4564/  8460 | loss: 0.3176 | ds_loss: 0.0000 | lr: 2.1913e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4564/  8460 | global iter:   4564/  8460 | loss: 0.1975 | ds_loss: 0.0000 | lr: 2.1913e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4565/  8460 | global iter:   4565/  8460 | loss: 0.0652 | ds_loss: 0.0000 | lr: 2.1904e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4566/  8460 | global iter:   4566/  8460 | loss: 0.1471 | ds_loss: 0.0000 | lr: 2.1894e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4567/  8460 | global iter:   4567/  8460 | loss: 0.0786 | ds_loss: 0.0000 | lr: 2.1885e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4568/  8460 | global iter:   4568/  8460 | loss: 0.2215 | ds_loss: 0.0000 | lr: 2.1876e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4568/  8460 | global iter:   4568/  8460 | loss: 0.1281 | ds_loss: 0.0000 | lr: 2.1876e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4569/  8460 | global iter:   4569/  8460 | loss: 0.3533 | ds_loss: 0.0000 | lr: 2.1867e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4570/  8460 | global iter:   4570/  8460 | loss: 0.1646 | ds_loss: 0.0000 | lr: 2.1858e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4571/  8460 | global iter:   4571/  8460 | loss: 0.2025 | ds_loss: 0.0000 | lr: 2.1848e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4572/  8460 | global iter:   4572/  8460 | loss: 0.3736 | ds_loss: 0.0000 | lr: 2.1839e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4572/  8460 | global iter:   4572/  8460 | loss: 0.2735 | ds_loss: 0.0000 | lr: 2.1839e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4573/  8460 | global iter:   4573/  8460 | loss: 0.1249 | ds_loss: 0.0000 | lr: 2.1830e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4574/  8460 | global iter:   4574/  8460 | loss: 0.0853 | ds_loss: 0.0000 | lr: 2.1821e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4575/  8460 | global iter:   4575/  8460 | loss: 0.1155 | ds_loss: 0.0000 | lr: 2.1812e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4576/  8460 | global iter:   4576/  8460 | loss: 0.1507 | ds_loss: 0.0000 | lr: 2.1802e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4576/  8460 | global iter:   4576/  8460 | loss: 0.1191 | ds_loss: 0.0000 | lr: 2.1802e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4577/  8460 | global iter:   4577/  8460 | loss: 0.3904 | ds_loss: 0.0000 | lr: 2.1793e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4578/  8460 | global iter:   4578/  8460 | loss: 0.2195 | ds_loss: 0.0000 | lr: 2.1784e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4579/  8460 | global iter:   4579/  8460 | loss: 0.2207 | ds_loss: 0.0000 | lr: 2.1775e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4580/  8460 | global iter:   4580/  8460 | loss: 0.3229 | ds_loss: 0.0000 | lr: 2.1766e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4580/  8460 | global iter:   4580/  8460 | loss: 0.2884 | ds_loss: 0.0000 | lr: 2.1766e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4581/  8460 | global iter:   4581/  8460 | loss: 0.0197 | ds_loss: 0.0000 | lr: 2.1756e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4582/  8460 | global iter:   4582/  8460 | loss: 0.1615 | ds_loss: 0.0000 | lr: 2.1747e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4583/  8460 | global iter:   4583/  8460 | loss: 0.0783 | ds_loss: 0.0000 | lr: 2.1738e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4584/  8460 | global iter:   4584/  8460 | loss: 0.5083 | ds_loss: 0.0000 | lr: 2.1729e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4584/  8460 | global iter:   4584/  8460 | loss: 0.1919 | ds_loss: 0.0000 | lr: 2.1729e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4585/  8460 | global iter:   4585/  8460 | loss: 0.2324 | ds_loss: 0.0000 | lr: 2.1719e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4586/  8460 | global iter:   4586/  8460 | loss: 0.1093 | ds_loss: 0.0000 | lr: 2.1710e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4587/  8460 | global iter:   4587/  8460 | loss: 0.3386 | ds_loss: 0.0000 | lr: 2.1701e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4588/  8460 | global iter:   4588/  8460 | loss: 0.0612 | ds_loss: 0.0000 | lr: 2.1692e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4588/  8460 | global iter:   4588/  8460 | loss: 0.1854 | ds_loss: 0.0000 | lr: 2.1692e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4589/  8460 | global iter:   4589/  8460 | loss: 0.0678 | ds_loss: 0.0000 | lr: 2.1683e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4590/  8460 | global iter:   4590/  8460 | loss: 0.0811 | ds_loss: 0.0000 | lr: 2.1673e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4591/  8460 | global iter:   4591/  8460 | loss: 0.1693 | ds_loss: 0.0000 | lr: 2.1664e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4592/  8460 | global iter:   4592/  8460 | loss: 0.2649 | ds_loss: 0.0000 | lr: 2.1655e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4592/  8460 | global iter:   4592/  8460 | loss: 0.1458 | ds_loss: 0.0000 | lr: 2.1655e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4593/  8460 | global iter:   4593/  8460 | loss: 0.3040 | ds_loss: 0.0000 | lr: 2.1646e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4594/  8460 | global iter:   4594/  8460 | loss: 0.3180 | ds_loss: 0.0000 | lr: 2.1637e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4595/  8460 | global iter:   4595/  8460 | loss: 0.2923 | ds_loss: 0.0000 | lr: 2.1628e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4596/  8460 | global iter:   4596/  8460 | loss: 0.2777 | ds_loss: 0.0000 | lr: 2.1618e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4596/  8460 | global iter:   4596/  8460 | loss: 0.2980 | ds_loss: 0.0000 | lr: 2.1618e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4597/  8460 | global iter:   4597/  8460 | loss: 0.1892 | ds_loss: 0.0000 | lr: 2.1609e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4598/  8460 | global iter:   4598/  8460 | loss: 0.1782 | ds_loss: 0.0000 | lr: 2.1600e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4599/  8460 | global iter:   4599/  8460 | loss: 0.0945 | ds_loss: 0.0000 | lr: 2.1591e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4600/  8460 | global iter:   4600/  8460 | loss: 0.0665 | ds_loss: 0.0000 | lr: 2.1582e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4600/  8460 | global iter:   4600/  8460 | loss: 0.1321 | ds_loss: 0.0000 | lr: 2.1582e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4601/  8460 | global iter:   4601/  8460 | loss: 0.2319 | ds_loss: 0.0000 | lr: 2.1572e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4602/  8460 | global iter:   4602/  8460 | loss: 0.3618 | ds_loss: 0.0000 | lr: 2.1563e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4603/  8460 | global iter:   4603/  8460 | loss: 0.3591 | ds_loss: 0.0000 | lr: 2.1554e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4604/  8460 | global iter:   4604/  8460 | loss: 0.4323 | ds_loss: 0.0000 | lr: 2.1545e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4604/  8460 | global iter:   4604/  8460 | loss: 0.3463 | ds_loss: 0.0000 | lr: 2.1545e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4605/  8460 | global iter:   4605/  8460 | loss: 0.0749 | ds_loss: 0.0000 | lr: 2.1536e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4606/  8460 | global iter:   4606/  8460 | loss: 0.2346 | ds_loss: 0.0000 | lr: 2.1526e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4607/  8460 | global iter:   4607/  8460 | loss: 0.2915 | ds_loss: 0.0000 | lr: 2.1517e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4608/  8460 | global iter:   4608/  8460 | loss: 0.1555 | ds_loss: 0.0000 | lr: 2.1508e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4608/  8460 | global iter:   4608/  8460 | loss: 0.1891 | ds_loss: 0.0000 | lr: 2.1508e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4609/  8460 | global iter:   4609/  8460 | loss: 0.4406 | ds_loss: 0.0000 | lr: 2.1499e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4610/  8460 | global iter:   4610/  8460 | loss: 0.0685 | ds_loss: 0.0000 | lr: 2.1490e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4611/  8460 | global iter:   4611/  8460 | loss: 0.2418 | ds_loss: 0.0000 | lr: 2.1480e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4612/  8460 | global iter:   4612/  8460 | loss: 0.3907 | ds_loss: 0.0000 | lr: 2.1471e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4612/  8460 | global iter:   4612/  8460 | loss: 0.2854 | ds_loss: 0.0000 | lr: 2.1471e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4613/  8460 | global iter:   4613/  8460 | loss: 0.5009 | ds_loss: 0.0000 | lr: 2.1462e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4614/  8460 | global iter:   4614/  8460 | loss: 0.0685 | ds_loss: 0.0000 | lr: 2.1453e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4615/  8460 | global iter:   4615/  8460 | loss: 0.3498 | ds_loss: 0.0000 | lr: 2.1444e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4616/  8460 | global iter:   4616/  8460 | loss: 0.2556 | ds_loss: 0.0000 | lr: 2.1434e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4616/  8460 | global iter:   4616/  8460 | loss: 0.2937 | ds_loss: 0.0000 | lr: 2.1434e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4617/  8460 | global iter:   4617/  8460 | loss: 0.1075 | ds_loss: 0.0000 | lr: 2.1425e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4618/  8460 | global iter:   4618/  8460 | loss: 0.1927 | ds_loss: 0.0000 | lr: 2.1416e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4619/  8460 | global iter:   4619/  8460 | loss: 0.3437 | ds_loss: 0.0000 | lr: 2.1407e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4620/  8460 | global iter:   4620/  8460 | loss: 0.1826 | ds_loss: 0.0000 | lr: 2.1398e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4620/  8460 | global iter:   4620/  8460 | loss: 0.2066 | ds_loss: 0.0000 | lr: 2.1398e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4621/  8460 | global iter:   4621/  8460 | loss: 0.3416 | ds_loss: 0.0000 | lr: 2.1389e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4622/  8460 | global iter:   4622/  8460 | loss: 0.4438 | ds_loss: 0.0000 | lr: 2.1379e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4623/  8460 | global iter:   4623/  8460 | loss: 0.1362 | ds_loss: 0.0000 | lr: 2.1370e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4624/  8460 | global iter:   4624/  8460 | loss: 0.3890 | ds_loss: 0.0000 | lr: 2.1361e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4624/  8460 | global iter:   4624/  8460 | loss: 0.3276 | ds_loss: 0.0000 | lr: 2.1361e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4625/  8460 | global iter:   4625/  8460 | loss: 0.2466 | ds_loss: 0.0000 | lr: 2.1352e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4626/  8460 | global iter:   4626/  8460 | loss: 0.1728 | ds_loss: 0.0000 | lr: 2.1343e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4627/  8460 | global iter:   4627/  8460 | loss: 0.5607 | ds_loss: 0.0000 | lr: 2.1333e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4628/  8460 | global iter:   4628/  8460 | loss: 0.3505 | ds_loss: 0.0000 | lr: 2.1324e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4628/  8460 | global iter:   4628/  8460 | loss: 0.3327 | ds_loss: 0.0000 | lr: 2.1324e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4629/  8460 | global iter:   4629/  8460 | loss: 0.0953 | ds_loss: 0.0000 | lr: 2.1315e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4630/  8460 | global iter:   4630/  8460 | loss: 0.0807 | ds_loss: 0.0000 | lr: 2.1306e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4631/  8460 | global iter:   4631/  8460 | loss: 0.4361 | ds_loss: 0.0000 | lr: 2.1297e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4632/  8460 | global iter:   4632/  8460 | loss: 0.2343 | ds_loss: 0.0000 | lr: 2.1288e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4632/  8460 | global iter:   4632/  8460 | loss: 0.2116 | ds_loss: 0.0000 | lr: 2.1288e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4633/  8460 | global iter:   4633/  8460 | loss: 0.1475 | ds_loss: 0.0000 | lr: 2.1278e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4634/  8460 | global iter:   4634/  8460 | loss: 0.0516 | ds_loss: 0.0000 | lr: 2.1269e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4635/  8460 | global iter:   4635/  8460 | loss: 0.2577 | ds_loss: 0.0000 | lr: 2.1260e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4636/  8460 | global iter:   4636/  8460 | loss: 0.0819 | ds_loss: 0.0000 | lr: 2.1251e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4636/  8460 | global iter:   4636/  8460 | loss: 0.1347 | ds_loss: 0.0000 | lr: 2.1251e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4637/  8460 | global iter:   4637/  8460 | loss: 0.2561 | ds_loss: 0.0000 | lr: 2.1242e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4638/  8460 | global iter:   4638/  8460 | loss: 0.1823 | ds_loss: 0.0000 | lr: 2.1232e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4639/  8460 | global iter:   4639/  8460 | loss: 0.0966 | ds_loss: 0.0000 | lr: 2.1223e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4640/  8460 | global iter:   4640/  8460 | loss: 0.1229 | ds_loss: 0.0000 | lr: 2.1214e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4640/  8460 | global iter:   4640/  8460 | loss: 0.1645 | ds_loss: 0.0000 | lr: 2.1214e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4641/  8460 | global iter:   4641/  8460 | loss: 0.1404 | ds_loss: 0.0000 | lr: 2.1205e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4642/  8460 | global iter:   4642/  8460 | loss: 0.1829 | ds_loss: 0.0000 | lr: 2.1196e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4643/  8460 | global iter:   4643/  8460 | loss: 0.2813 | ds_loss: 0.0000 | lr: 2.1187e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4644/  8460 | global iter:   4644/  8460 | loss: 0.1237 | ds_loss: 0.0000 | lr: 2.1177e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4644/  8460 | global iter:   4644/  8460 | loss: 0.1820 | ds_loss: 0.0000 | lr: 2.1177e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4645/  8460 | global iter:   4645/  8460 | loss: 0.0794 | ds_loss: 0.0000 | lr: 2.1168e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4646/  8460 | global iter:   4646/  8460 | loss: 0.0442 | ds_loss: 0.0000 | lr: 2.1159e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4647/  8460 | global iter:   4647/  8460 | loss: 0.3409 | ds_loss: 0.0000 | lr: 2.1150e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4648/  8460 | global iter:   4648/  8460 | loss: 0.0740 | ds_loss: 0.0000 | lr: 2.1141e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4648/  8460 | global iter:   4648/  8460 | loss: 0.1346 | ds_loss: 0.0000 | lr: 2.1141e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4649/  8460 | global iter:   4649/  8460 | loss: 0.2783 | ds_loss: 0.0000 | lr: 2.1132e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4650/  8460 | global iter:   4650/  8460 | loss: 0.6148 | ds_loss: 0.0000 | lr: 2.1122e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4651/  8460 | global iter:   4651/  8460 | loss: 0.1544 | ds_loss: 0.0000 | lr: 2.1113e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4652/  8460 | global iter:   4652/  8460 | loss: 0.0643 | ds_loss: 0.0000 | lr: 2.1104e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4652/  8460 | global iter:   4652/  8460 | loss: 0.2779 | ds_loss: 0.0000 | lr: 2.1104e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4653/  8460 | global iter:   4653/  8460 | loss: 0.4403 | ds_loss: 0.0000 | lr: 2.1095e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4654/  8460 | global iter:   4654/  8460 | loss: 0.0762 | ds_loss: 0.0000 | lr: 2.1086e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4655/  8460 | global iter:   4655/  8460 | loss: 0.2901 | ds_loss: 0.0000 | lr: 2.1077e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4656/  8460 | global iter:   4656/  8460 | loss: 0.1559 | ds_loss: 0.0000 | lr: 2.1067e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4656/  8460 | global iter:   4656/  8460 | loss: 0.2406 | ds_loss: 0.0000 | lr: 2.1067e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4657/  8460 | global iter:   4657/  8460 | loss: 0.0809 | ds_loss: 0.0000 | lr: 2.1058e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4658/  8460 | global iter:   4658/  8460 | loss: 0.0800 | ds_loss: 0.0000 | lr: 2.1049e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4659/  8460 | global iter:   4659/  8460 | loss: 0.1452 | ds_loss: 0.0000 | lr: 2.1040e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4660/  8460 | global iter:   4660/  8460 | loss: 0.0847 | ds_loss: 0.0000 | lr: 2.1031e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4660/  8460 | global iter:   4660/  8460 | loss: 0.0977 | ds_loss: 0.0000 | lr: 2.1031e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4661/  8460 | global iter:   4661/  8460 | loss: 0.1408 | ds_loss: 0.0000 | lr: 2.1022e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4662/  8460 | global iter:   4662/  8460 | loss: 0.4392 | ds_loss: 0.0000 | lr: 2.1012e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4663/  8460 | global iter:   4663/  8460 | loss: 0.0886 | ds_loss: 0.0000 | lr: 2.1003e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4664/  8460 | global iter:   4664/  8460 | loss: 0.2853 | ds_loss: 0.0000 | lr: 2.0994e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4664/  8460 | global iter:   4664/  8460 | loss: 0.2385 | ds_loss: 0.0000 | lr: 2.0994e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4665/  8460 | global iter:   4665/  8460 | loss: 0.1668 | ds_loss: 0.0000 | lr: 2.0985e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4666/  8460 | global iter:   4666/  8460 | loss: 0.1567 | ds_loss: 0.0000 | lr: 2.0976e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4667/  8460 | global iter:   4667/  8460 | loss: 0.1831 | ds_loss: 0.0000 | lr: 2.0967e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4668/  8460 | global iter:   4668/  8460 | loss: 0.2313 | ds_loss: 0.0000 | lr: 2.0957e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4668/  8460 | global iter:   4668/  8460 | loss: 0.1845 | ds_loss: 0.0000 | lr: 2.0957e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4669/  8460 | global iter:   4669/  8460 | loss: 0.3718 | ds_loss: 0.0000 | lr: 2.0948e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4670/  8460 | global iter:   4670/  8460 | loss: 0.3782 | ds_loss: 0.0000 | lr: 2.0939e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4671/  8460 | global iter:   4671/  8460 | loss: 0.0601 | ds_loss: 0.0000 | lr: 2.0930e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4672/  8460 | global iter:   4672/  8460 | loss: 0.2824 | ds_loss: 0.0000 | lr: 2.0921e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4672/  8460 | global iter:   4672/  8460 | loss: 0.2731 | ds_loss: 0.0000 | lr: 2.0921e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4673/  8460 | global iter:   4673/  8460 | loss: 0.1819 | ds_loss: 0.0000 | lr: 2.0912e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4674/  8460 | global iter:   4674/  8460 | loss: 0.1465 | ds_loss: 0.0000 | lr: 2.0903e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4675/  8460 | global iter:   4675/  8460 | loss: 0.1859 | ds_loss: 0.0000 | lr: 2.0893e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4676/  8460 | global iter:   4676/  8460 | loss: 0.3304 | ds_loss: 0.0000 | lr: 2.0884e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4676/  8460 | global iter:   4676/  8460 | loss: 0.2112 | ds_loss: 0.0000 | lr: 2.0884e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4677/  8460 | global iter:   4677/  8460 | loss: 0.1599 | ds_loss: 0.0000 | lr: 2.0875e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4678/  8460 | global iter:   4678/  8460 | loss: 0.4331 | ds_loss: 0.0000 | lr: 2.0866e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4679/  8460 | global iter:   4679/  8460 | loss: 0.2154 | ds_loss: 0.0000 | lr: 2.0857e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4680/  8460 | global iter:   4680/  8460 | loss: 0.2938 | ds_loss: 0.0000 | lr: 2.0848e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4680/  8460 | global iter:   4680/  8460 | loss: 0.2755 | ds_loss: 0.0000 | lr: 2.0848e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4681/  8460 | global iter:   4681/  8460 | loss: 0.3040 | ds_loss: 0.0000 | lr: 2.0838e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4682/  8460 | global iter:   4682/  8460 | loss: 0.2362 | ds_loss: 0.0000 | lr: 2.0829e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4683/  8460 | global iter:   4683/  8460 | loss: 0.1350 | ds_loss: 0.0000 | lr: 2.0820e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4684/  8460 | global iter:   4684/  8460 | loss: 0.4860 | ds_loss: 0.0000 | lr: 2.0811e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4684/  8460 | global iter:   4684/  8460 | loss: 0.2903 | ds_loss: 0.0000 | lr: 2.0811e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4685/  8460 | global iter:   4685/  8460 | loss: 0.0727 | ds_loss: 0.0000 | lr: 2.0802e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4686/  8460 | global iter:   4686/  8460 | loss: 0.1689 | ds_loss: 0.0000 | lr: 2.0793e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4687/  8460 | global iter:   4687/  8460 | loss: 0.1878 | ds_loss: 0.0000 | lr: 2.0784e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4688/  8460 | global iter:   4688/  8460 | loss: 0.5116 | ds_loss: 0.0000 | lr: 2.0774e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4688/  8460 | global iter:   4688/  8460 | loss: 0.2352 | ds_loss: 0.0000 | lr: 2.0774e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4689/  8460 | global iter:   4689/  8460 | loss: 0.2342 | ds_loss: 0.0000 | lr: 2.0765e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4690/  8460 | global iter:   4690/  8460 | loss: 0.0816 | ds_loss: 0.0000 | lr: 2.0756e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4691/  8460 | global iter:   4691/  8460 | loss: 0.1294 | ds_loss: 0.0000 | lr: 2.0747e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4692/  8460 | global iter:   4692/  8460 | loss: 0.1783 | ds_loss: 0.0000 | lr: 2.0738e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4692/  8460 | global iter:   4692/  8460 | loss: 0.1559 | ds_loss: 0.0000 | lr: 2.0738e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4693/  8460 | global iter:   4693/  8460 | loss: 0.0605 | ds_loss: 0.0000 | lr: 2.0729e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4694/  8460 | global iter:   4694/  8460 | loss: 0.0784 | ds_loss: 0.0000 | lr: 2.0720e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4695/  8460 | global iter:   4695/  8460 | loss: 0.1194 | ds_loss: 0.0000 | lr: 2.0710e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4696/  8460 | global iter:   4696/  8460 | loss: 0.1376 | ds_loss: 0.0000 | lr: 2.0701e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4696/  8460 | global iter:   4696/  8460 | loss: 0.0990 | ds_loss: 0.0000 | lr: 2.0701e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4697/  8460 | global iter:   4697/  8460 | loss: 0.6356 | ds_loss: 0.0000 | lr: 2.0692e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4698/  8460 | global iter:   4698/  8460 | loss: 0.0354 | ds_loss: 0.0000 | lr: 2.0683e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4699/  8460 | global iter:   4699/  8460 | loss: 0.1868 | ds_loss: 0.0000 | lr: 2.0674e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4700/  8460 | global iter:   4700/  8460 | loss: 0.2567 | ds_loss: 0.0000 | lr: 2.0665e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4700/  8460 | global iter:   4700/  8460 | loss: 0.2786 | ds_loss: 0.0000 | lr: 2.0665e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4701/  8460 | global iter:   4701/  8460 | loss: 0.1558 | ds_loss: 0.0000 | lr: 2.0656e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4702/  8460 | global iter:   4702/  8460 | loss: 0.0546 | ds_loss: 0.0000 | lr: 2.0646e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4703/  8460 | global iter:   4703/  8460 | loss: 0.1668 | ds_loss: 0.0000 | lr: 2.0637e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4704/  8460 | global iter:   4704/  8460 | loss: 0.0842 | ds_loss: 0.0000 | lr: 2.0628e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4704/  8460 | global iter:   4704/  8460 | loss: 0.1153 | ds_loss: 0.0000 | lr: 2.0628e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4705/  8460 | global iter:   4705/  8460 | loss: 0.2324 | ds_loss: 0.0000 | lr: 2.0619e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4706/  8460 | global iter:   4706/  8460 | loss: 0.2191 | ds_loss: 0.0000 | lr: 2.0610e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4707/  8460 | global iter:   4707/  8460 | loss: 0.1455 | ds_loss: 0.0000 | lr: 2.0601e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4708/  8460 | global iter:   4708/  8460 | loss: 0.3427 | ds_loss: 0.0000 | lr: 2.0592e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4708/  8460 | global iter:   4708/  8460 | loss: 0.2349 | ds_loss: 0.0000 | lr: 2.0592e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4709/  8460 | global iter:   4709/  8460 | loss: 0.3005 | ds_loss: 0.0000 | lr: 2.0582e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4710/  8460 | global iter:   4710/  8460 | loss: 0.7584 | ds_loss: 0.0000 | lr: 2.0573e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4711/  8460 | global iter:   4711/  8460 | loss: 0.3853 | ds_loss: 0.0000 | lr: 2.0564e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4712/  8460 | global iter:   4712/  8460 | loss: 0.2031 | ds_loss: 0.0000 | lr: 2.0555e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4712/  8460 | global iter:   4712/  8460 | loss: 0.4119 | ds_loss: 0.0000 | lr: 2.0555e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4713/  8460 | global iter:   4713/  8460 | loss: 0.0521 | ds_loss: 0.0000 | lr: 2.0546e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4714/  8460 | global iter:   4714/  8460 | loss: 0.1051 | ds_loss: 0.0000 | lr: 2.0537e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4715/  8460 | global iter:   4715/  8460 | loss: 0.0735 | ds_loss: 0.0000 | lr: 2.0528e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4716/  8460 | global iter:   4716/  8460 | loss: 0.0827 | ds_loss: 0.0000 | lr: 2.0518e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4716/  8460 | global iter:   4716/  8460 | loss: 0.0783 | ds_loss: 0.0000 | lr: 2.0518e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4717/  8460 | global iter:   4717/  8460 | loss: 0.3291 | ds_loss: 0.0000 | lr: 2.0509e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4718/  8460 | global iter:   4718/  8460 | loss: 0.2095 | ds_loss: 0.0000 | lr: 2.0500e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4719/  8460 | global iter:   4719/  8460 | loss: 0.2372 | ds_loss: 0.0000 | lr: 2.0491e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4720/  8460 | global iter:   4720/  8460 | loss: 0.2264 | ds_loss: 0.0000 | lr: 2.0482e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4720/  8460 | global iter:   4720/  8460 | loss: 0.2505 | ds_loss: 0.0000 | lr: 2.0482e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4721/  8460 | global iter:   4721/  8460 | loss: 0.0757 | ds_loss: 0.0000 | lr: 2.0473e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4722/  8460 | global iter:   4722/  8460 | loss: 0.2121 | ds_loss: 0.0000 | lr: 2.0464e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4723/  8460 | global iter:   4723/  8460 | loss: 0.3259 | ds_loss: 0.0000 | lr: 2.0455e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4724/  8460 | global iter:   4724/  8460 | loss: 0.1284 | ds_loss: 0.0000 | lr: 2.0445e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4724/  8460 | global iter:   4724/  8460 | loss: 0.1855 | ds_loss: 0.0000 | lr: 2.0445e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4725/  8460 | global iter:   4725/  8460 | loss: 0.1679 | ds_loss: 0.0000 | lr: 2.0436e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4726/  8460 | global iter:   4726/  8460 | loss: 0.0773 | ds_loss: 0.0000 | lr: 2.0427e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4727/  8460 | global iter:   4727/  8460 | loss: 0.0307 | ds_loss: 0.0000 | lr: 2.0418e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4728/  8460 | global iter:   4728/  8460 | loss: 0.4678 | ds_loss: 0.0000 | lr: 2.0409e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4728/  8460 | global iter:   4728/  8460 | loss: 0.1859 | ds_loss: 0.0000 | lr: 2.0409e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4729/  8460 | global iter:   4729/  8460 | loss: 0.5765 | ds_loss: 0.0000 | lr: 2.0400e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4730/  8460 | global iter:   4730/  8460 | loss: 0.3241 | ds_loss: 0.0000 | lr: 2.0391e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4731/  8460 | global iter:   4731/  8460 | loss: 0.2129 | ds_loss: 0.0000 | lr: 2.0382e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4732/  8460 | global iter:   4732/  8460 | loss: 0.2178 | ds_loss: 0.0000 | lr: 2.0372e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4732/  8460 | global iter:   4732/  8460 | loss: 0.3328 | ds_loss: 0.0000 | lr: 2.0372e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4733/  8460 | global iter:   4733/  8460 | loss: 0.2489 | ds_loss: 0.0000 | lr: 2.0363e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4734/  8460 | global iter:   4734/  8460 | loss: 0.2422 | ds_loss: 0.0000 | lr: 2.0354e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4735/  8460 | global iter:   4735/  8460 | loss: 0.0915 | ds_loss: 0.0000 | lr: 2.0345e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4736/  8460 | global iter:   4736/  8460 | loss: 0.3029 | ds_loss: 0.0000 | lr: 2.0336e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4736/  8460 | global iter:   4736/  8460 | loss: 0.2214 | ds_loss: 0.0000 | lr: 2.0336e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4737/  8460 | global iter:   4737/  8460 | loss: 0.2693 | ds_loss: 0.0000 | lr: 2.0327e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4738/  8460 | global iter:   4738/  8460 | loss: 0.4113 | ds_loss: 0.0000 | lr: 2.0318e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4739/  8460 | global iter:   4739/  8460 | loss: 0.3902 | ds_loss: 0.0000 | lr: 2.0309e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4740/  8460 | global iter:   4740/  8460 | loss: 0.2371 | ds_loss: 0.0000 | lr: 2.0300e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4740/  8460 | global iter:   4740/  8460 | loss: 0.3269 | ds_loss: 0.0000 | lr: 2.0300e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4741/  8460 | global iter:   4741/  8460 | loss: 0.1306 | ds_loss: 0.0000 | lr: 2.0290e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4742/  8460 | global iter:   4742/  8460 | loss: 0.0832 | ds_loss: 0.0000 | lr: 2.0281e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4743/  8460 | global iter:   4743/  8460 | loss: 0.2281 | ds_loss: 0.0000 | lr: 2.0272e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4744/  8460 | global iter:   4744/  8460 | loss: 0.2787 | ds_loss: 0.0000 | lr: 2.0263e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4744/  8460 | global iter:   4744/  8460 | loss: 0.1801 | ds_loss: 0.0000 | lr: 2.0263e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4745/  8460 | global iter:   4745/  8460 | loss: 0.4944 | ds_loss: 0.0000 | lr: 2.0254e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4746/  8460 | global iter:   4746/  8460 | loss: 0.0565 | ds_loss: 0.0000 | lr: 2.0245e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4747/  8460 | global iter:   4747/  8460 | loss: 0.0711 | ds_loss: 0.0000 | lr: 2.0236e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4748/  8460 | global iter:   4748/  8460 | loss: 0.1745 | ds_loss: 0.0000 | lr: 2.0227e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4748/  8460 | global iter:   4748/  8460 | loss: 0.1992 | ds_loss: 0.0000 | lr: 2.0227e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4749/  8460 | global iter:   4749/  8460 | loss: 0.0989 | ds_loss: 0.0000 | lr: 2.0218e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4750/  8460 | global iter:   4750/  8460 | loss: 0.0399 | ds_loss: 0.0000 | lr: 2.0208e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4751/  8460 | global iter:   4751/  8460 | loss: 0.2123 | ds_loss: 0.0000 | lr: 2.0199e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4752/  8460 | global iter:   4752/  8460 | loss: 0.5896 | ds_loss: 0.0000 | lr: 2.0190e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4752/  8460 | global iter:   4752/  8460 | loss: 0.2352 | ds_loss: 0.0000 | lr: 2.0190e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4753/  8460 | global iter:   4753/  8460 | loss: 0.1779 | ds_loss: 0.0000 | lr: 2.0181e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4754/  8460 | global iter:   4754/  8460 | loss: 0.2123 | ds_loss: 0.0000 | lr: 2.0172e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4755/  8460 | global iter:   4755/  8460 | loss: 0.2988 | ds_loss: 0.0000 | lr: 2.0163e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4756/  8460 | global iter:   4756/  8460 | loss: 0.1108 | ds_loss: 0.0000 | lr: 2.0154e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4756/  8460 | global iter:   4756/  8460 | loss: 0.2000 | ds_loss: 0.0000 | lr: 2.0154e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4757/  8460 | global iter:   4757/  8460 | loss: 0.1460 | ds_loss: 0.0000 | lr: 2.0145e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4758/  8460 | global iter:   4758/  8460 | loss: 0.2377 | ds_loss: 0.0000 | lr: 2.0136e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4759/  8460 | global iter:   4759/  8460 | loss: 0.2227 | ds_loss: 0.0000 | lr: 2.0126e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4760/  8460 | global iter:   4760/  8460 | loss: 0.0678 | ds_loss: 0.0000 | lr: 2.0117e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4760/  8460 | global iter:   4760/  8460 | loss: 0.1685 | ds_loss: 0.0000 | lr: 2.0117e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4761/  8460 | global iter:   4761/  8460 | loss: 0.2543 | ds_loss: 0.0000 | lr: 2.0108e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4762/  8460 | global iter:   4762/  8460 | loss: 0.1535 | ds_loss: 0.0000 | lr: 2.0099e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4763/  8460 | global iter:   4763/  8460 | loss: 0.1858 | ds_loss: 0.0000 | lr: 2.0090e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4764/  8460 | global iter:   4764/  8460 | loss: 0.3739 | ds_loss: 0.0000 | lr: 2.0081e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4764/  8460 | global iter:   4764/  8460 | loss: 0.2419 | ds_loss: 0.0000 | lr: 2.0081e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4765/  8460 | global iter:   4765/  8460 | loss: 0.3095 | ds_loss: 0.0000 | lr: 2.0072e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4766/  8460 | global iter:   4766/  8460 | loss: 0.2639 | ds_loss: 0.0000 | lr: 2.0063e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4767/  8460 | global iter:   4767/  8460 | loss: 0.3118 | ds_loss: 0.0000 | lr: 2.0054e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4768/  8460 | global iter:   4768/  8460 | loss: 0.3507 | ds_loss: 0.0000 | lr: 2.0045e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4768/  8460 | global iter:   4768/  8460 | loss: 0.3090 | ds_loss: 0.0000 | lr: 2.0045e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4769/  8460 | global iter:   4769/  8460 | loss: 0.3138 | ds_loss: 0.0000 | lr: 2.0035e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4770/  8460 | global iter:   4770/  8460 | loss: 0.0968 | ds_loss: 0.0000 | lr: 2.0026e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4771/  8460 | global iter:   4771/  8460 | loss: 0.1560 | ds_loss: 0.0000 | lr: 2.0017e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4772/  8460 | global iter:   4772/  8460 | loss: 0.1759 | ds_loss: 0.0000 | lr: 2.0008e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4772/  8460 | global iter:   4772/  8460 | loss: 0.1856 | ds_loss: 0.0000 | lr: 2.0008e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4773/  8460 | global iter:   4773/  8460 | loss: 0.1035 | ds_loss: 0.0000 | lr: 1.9999e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4774/  8460 | global iter:   4774/  8460 | loss: 0.0684 | ds_loss: 0.0000 | lr: 1.9990e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4775/  8460 | global iter:   4775/  8460 | loss: 0.1485 | ds_loss: 0.0000 | lr: 1.9981e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4776/  8460 | global iter:   4776/  8460 | loss: 0.2155 | ds_loss: 0.0000 | lr: 1.9972e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4776/  8460 | global iter:   4776/  8460 | loss: 0.1340 | ds_loss: 0.0000 | lr: 1.9972e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4777/  8460 | global iter:   4777/  8460 | loss: 0.4548 | ds_loss: 0.0000 | lr: 1.9963e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4778/  8460 | global iter:   4778/  8460 | loss: 0.2152 | ds_loss: 0.0000 | lr: 1.9954e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4779/  8460 | global iter:   4779/  8460 | loss: 0.1887 | ds_loss: 0.0000 | lr: 1.9945e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4780/  8460 | global iter:   4780/  8460 | loss: 0.4895 | ds_loss: 0.0000 | lr: 1.9935e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4780/  8460 | global iter:   4780/  8460 | loss: 0.3371 | ds_loss: 0.0000 | lr: 1.9935e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4781/  8460 | global iter:   4781/  8460 | loss: 0.1751 | ds_loss: 0.0000 | lr: 1.9926e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4782/  8460 | global iter:   4782/  8460 | loss: 0.1551 | ds_loss: 0.0000 | lr: 1.9917e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4783/  8460 | global iter:   4783/  8460 | loss: 0.2296 | ds_loss: 0.0000 | lr: 1.9908e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4784/  8460 | global iter:   4784/  8460 | loss: 0.0465 | ds_loss: 0.0000 | lr: 1.9899e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4784/  8460 | global iter:   4784/  8460 | loss: 0.1516 | ds_loss: 0.0000 | lr: 1.9899e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4785/  8460 | global iter:   4785/  8460 | loss: 0.2751 | ds_loss: 0.0000 | lr: 1.9890e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4786/  8460 | global iter:   4786/  8460 | loss: 0.0832 | ds_loss: 0.0000 | lr: 1.9881e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4787/  8460 | global iter:   4787/  8460 | loss: 0.2566 | ds_loss: 0.0000 | lr: 1.9872e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4788/  8460 | global iter:   4788/  8460 | loss: 0.0658 | ds_loss: 0.0000 | lr: 1.9863e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4788/  8460 | global iter:   4788/  8460 | loss: 0.1702 | ds_loss: 0.0000 | lr: 1.9863e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4789/  8460 | global iter:   4789/  8460 | loss: 0.1770 | ds_loss: 0.0000 | lr: 1.9854e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4790/  8460 | global iter:   4790/  8460 | loss: 0.0796 | ds_loss: 0.0000 | lr: 1.9845e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4791/  8460 | global iter:   4791/  8460 | loss: 0.3299 | ds_loss: 0.0000 | lr: 1.9835e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4792/  8460 | global iter:   4792/  8460 | loss: 0.3457 | ds_loss: 0.0000 | lr: 1.9826e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4792/  8460 | global iter:   4792/  8460 | loss: 0.2331 | ds_loss: 0.0000 | lr: 1.9826e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4793/  8460 | global iter:   4793/  8460 | loss: 0.1515 | ds_loss: 0.0000 | lr: 1.9817e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4794/  8460 | global iter:   4794/  8460 | loss: 0.0601 | ds_loss: 0.0000 | lr: 1.9808e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4795/  8460 | global iter:   4795/  8460 | loss: 0.1154 | ds_loss: 0.0000 | lr: 1.9799e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4796/  8460 | global iter:   4796/  8460 | loss: 0.0654 | ds_loss: 0.0000 | lr: 1.9790e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4796/  8460 | global iter:   4796/  8460 | loss: 0.0981 | ds_loss: 0.0000 | lr: 1.9790e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4797/  8460 | global iter:   4797/  8460 | loss: 0.0899 | ds_loss: 0.0000 | lr: 1.9781e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4798/  8460 | global iter:   4798/  8460 | loss: 0.4214 | ds_loss: 0.0000 | lr: 1.9772e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4799/  8460 | global iter:   4799/  8460 | loss: 0.1465 | ds_loss: 0.0000 | lr: 1.9763e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4800/  8460 | global iter:   4800/  8460 | loss: 0.1523 | ds_loss: 0.0000 | lr: 1.9754e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4800/  8460 | global iter:   4800/  8460 | loss: 0.2025 | ds_loss: 0.0000 | lr: 1.9754e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4801/  8460 | global iter:   4801/  8460 | loss: 0.0665 | ds_loss: 0.0000 | lr: 1.9745e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4802/  8460 | global iter:   4802/  8460 | loss: 0.2154 | ds_loss: 0.0000 | lr: 1.9736e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4803/  8460 | global iter:   4803/  8460 | loss: 0.1047 | ds_loss: 0.0000 | lr: 1.9727e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4804/  8460 | global iter:   4804/  8460 | loss: 0.1805 | ds_loss: 0.0000 | lr: 1.9717e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4804/  8460 | global iter:   4804/  8460 | loss: 0.1418 | ds_loss: 0.0000 | lr: 1.9717e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4805/  8460 | global iter:   4805/  8460 | loss: 0.3796 | ds_loss: 0.0000 | lr: 1.9708e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4806/  8460 | global iter:   4806/  8460 | loss: 0.2335 | ds_loss: 0.0000 | lr: 1.9699e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4807/  8460 | global iter:   4807/  8460 | loss: 0.1838 | ds_loss: 0.0000 | lr: 1.9690e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4808/  8460 | global iter:   4808/  8460 | loss: 0.1093 | ds_loss: 0.0000 | lr: 1.9681e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4808/  8460 | global iter:   4808/  8460 | loss: 0.2266 | ds_loss: 0.0000 | lr: 1.9681e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4809/  8460 | global iter:   4809/  8460 | loss: 0.1066 | ds_loss: 0.0000 | lr: 1.9672e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4810/  8460 | global iter:   4810/  8460 | loss: 0.3623 | ds_loss: 0.0000 | lr: 1.9663e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4811/  8460 | global iter:   4811/  8460 | loss: 0.0392 | ds_loss: 0.0000 | lr: 1.9654e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4812/  8460 | global iter:   4812/  8460 | loss: 0.2781 | ds_loss: 0.0000 | lr: 1.9645e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4812/  8460 | global iter:   4812/  8460 | loss: 0.1966 | ds_loss: 0.0000 | lr: 1.9645e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4813/  8460 | global iter:   4813/  8460 | loss: 0.3184 | ds_loss: 0.0000 | lr: 1.9636e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4814/  8460 | global iter:   4814/  8460 | loss: 0.4506 | ds_loss: 0.0000 | lr: 1.9627e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4815/  8460 | global iter:   4815/  8460 | loss: 0.2484 | ds_loss: 0.0000 | lr: 1.9618e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4816/  8460 | global iter:   4816/  8460 | loss: 0.1375 | ds_loss: 0.0000 | lr: 1.9609e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4816/  8460 | global iter:   4816/  8460 | loss: 0.2887 | ds_loss: 0.0000 | lr: 1.9609e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4817/  8460 | global iter:   4817/  8460 | loss: 0.3529 | ds_loss: 0.0000 | lr: 1.9600e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4818/  8460 | global iter:   4818/  8460 | loss: 0.2923 | ds_loss: 0.0000 | lr: 1.9591e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4819/  8460 | global iter:   4819/  8460 | loss: 0.3917 | ds_loss: 0.0000 | lr: 1.9581e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4820/  8460 | global iter:   4820/  8460 | loss: 0.3150 | ds_loss: 0.0000 | lr: 1.9572e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4820/  8460 | global iter:   4820/  8460 | loss: 0.3380 | ds_loss: 0.0000 | lr: 1.9572e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4821/  8460 | global iter:   4821/  8460 | loss: 0.0961 | ds_loss: 0.0000 | lr: 1.9563e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4822/  8460 | global iter:   4822/  8460 | loss: 0.1060 | ds_loss: 0.0000 | lr: 1.9554e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4823/  8460 | global iter:   4823/  8460 | loss: 0.0524 | ds_loss: 0.0000 | lr: 1.9545e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4824/  8460 | global iter:   4824/  8460 | loss: 0.5903 | ds_loss: 0.0000 | lr: 1.9536e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4824/  8460 | global iter:   4824/  8460 | loss: 0.2112 | ds_loss: 0.0000 | lr: 1.9536e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4825/  8460 | global iter:   4825/  8460 | loss: 0.1909 | ds_loss: 0.0000 | lr: 1.9527e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4826/  8460 | global iter:   4826/  8460 | loss: 0.1746 | ds_loss: 0.0000 | lr: 1.9518e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4827/  8460 | global iter:   4827/  8460 | loss: 0.0143 | ds_loss: 0.0000 | lr: 1.9509e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4828/  8460 | global iter:   4828/  8460 | loss: 0.0887 | ds_loss: 0.0000 | lr: 1.9500e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4828/  8460 | global iter:   4828/  8460 | loss: 0.1171 | ds_loss: 0.0000 | lr: 1.9500e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4829/  8460 | global iter:   4829/  8460 | loss: 0.2196 | ds_loss: 0.0000 | lr: 1.9491e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4830/  8460 | global iter:   4830/  8460 | loss: 0.0710 | ds_loss: 0.0000 | lr: 1.9482e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4831/  8460 | global iter:   4831/  8460 | loss: 0.1560 | ds_loss: 0.0000 | lr: 1.9473e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4832/  8460 | global iter:   4832/  8460 | loss: 0.3206 | ds_loss: 0.0000 | lr: 1.9464e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4832/  8460 | global iter:   4832/  8460 | loss: 0.1918 | ds_loss: 0.0000 | lr: 1.9464e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4833/  8460 | global iter:   4833/  8460 | loss: 0.5833 | ds_loss: 0.0000 | lr: 1.9455e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4834/  8460 | global iter:   4834/  8460 | loss: 0.2886 | ds_loss: 0.0000 | lr: 1.9446e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4835/  8460 | global iter:   4835/  8460 | loss: 0.2259 | ds_loss: 0.0000 | lr: 1.9437e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4836/  8460 | global iter:   4836/  8460 | loss: 0.1633 | ds_loss: 0.0000 | lr: 1.9428e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4836/  8460 | global iter:   4836/  8460 | loss: 0.3152 | ds_loss: 0.0000 | lr: 1.9428e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4837/  8460 | global iter:   4837/  8460 | loss: 0.6196 | ds_loss: 0.0000 | lr: 1.9419e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4838/  8460 | global iter:   4838/  8460 | loss: 0.7541 | ds_loss: 0.0000 | lr: 1.9409e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4839/  8460 | global iter:   4839/  8460 | loss: 0.2773 | ds_loss: 0.0000 | lr: 1.9400e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4840/  8460 | global iter:   4840/  8460 | loss: 0.1267 | ds_loss: 0.0000 | lr: 1.9391e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4840/  8460 | global iter:   4840/  8460 | loss: 0.4444 | ds_loss: 0.0000 | lr: 1.9391e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4841/  8460 | global iter:   4841/  8460 | loss: 0.2524 | ds_loss: 0.0000 | lr: 1.9382e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4842/  8460 | global iter:   4842/  8460 | loss: 0.1207 | ds_loss: 0.0000 | lr: 1.9373e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4843/  8460 | global iter:   4843/  8460 | loss: 0.0468 | ds_loss: 0.0000 | lr: 1.9364e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4844/  8460 | global iter:   4844/  8460 | loss: 0.0749 | ds_loss: 0.0000 | lr: 1.9355e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4844/  8460 | global iter:   4844/  8460 | loss: 0.1237 | ds_loss: 0.0000 | lr: 1.9355e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4845/  8460 | global iter:   4845/  8460 | loss: 0.1935 | ds_loss: 0.0000 | lr: 1.9346e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4846/  8460 | global iter:   4846/  8460 | loss: 0.4214 | ds_loss: 0.0000 | lr: 1.9337e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4847/  8460 | global iter:   4847/  8460 | loss: 0.1982 | ds_loss: 0.0000 | lr: 1.9328e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4848/  8460 | global iter:   4848/  8460 | loss: 0.2031 | ds_loss: 0.0000 | lr: 1.9319e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4848/  8460 | global iter:   4848/  8460 | loss: 0.2541 | ds_loss: 0.0000 | lr: 1.9319e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4849/  8460 | global iter:   4849/  8460 | loss: 0.1121 | ds_loss: 0.0000 | lr: 1.9310e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4850/  8460 | global iter:   4850/  8460 | loss: 0.1529 | ds_loss: 0.0000 | lr: 1.9301e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4851/  8460 | global iter:   4851/  8460 | loss: 0.1980 | ds_loss: 0.0000 | lr: 1.9292e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4852/  8460 | global iter:   4852/  8460 | loss: 0.1297 | ds_loss: 0.0000 | lr: 1.9283e-04 | scale:     1.0000 | micro time: 0.435 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4852/  8460 | global iter:   4852/  8460 | loss: 0.1482 | ds_loss: 0.0000 | lr: 1.9283e-04 | scale:     1.0000 | micro time: 0.435 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4853/  8460 | global iter:   4853/  8460 | loss: 0.0595 | ds_loss: 0.0000 | lr: 1.9274e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4854/  8460 | global iter:   4854/  8460 | loss: 0.1525 | ds_loss: 0.0000 | lr: 1.9265e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4855/  8460 | global iter:   4855/  8460 | loss: 0.1644 | ds_loss: 0.0000 | lr: 1.9256e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4856/  8460 | global iter:   4856/  8460 | loss: 0.0730 | ds_loss: 0.0000 | lr: 1.9247e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4856/  8460 | global iter:   4856/  8460 | loss: 0.1124 | ds_loss: 0.0000 | lr: 1.9247e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4857/  8460 | global iter:   4857/  8460 | loss: 0.0407 | ds_loss: 0.0000 | lr: 1.9238e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4858/  8460 | global iter:   4858/  8460 | loss: 0.0823 | ds_loss: 0.0000 | lr: 1.9229e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4859/  8460 | global iter:   4859/  8460 | loss: 0.2213 | ds_loss: 0.0000 | lr: 1.9220e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4860/  8460 | global iter:   4860/  8460 | loss: 0.1919 | ds_loss: 0.0000 | lr: 1.9211e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4860/  8460 | global iter:   4860/  8460 | loss: 0.1341 | ds_loss: 0.0000 | lr: 1.9211e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4861/  8460 | global iter:   4861/  8460 | loss: 0.0708 | ds_loss: 0.0000 | lr: 1.9202e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4862/  8460 | global iter:   4862/  8460 | loss: 0.0732 | ds_loss: 0.0000 | lr: 1.9193e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4863/  8460 | global iter:   4863/  8460 | loss: 0.0659 | ds_loss: 0.0000 | lr: 1.9184e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4864/  8460 | global iter:   4864/  8460 | loss: 0.0712 | ds_loss: 0.0000 | lr: 1.9175e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4864/  8460 | global iter:   4864/  8460 | loss: 0.0703 | ds_loss: 0.0000 | lr: 1.9175e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4865/  8460 | global iter:   4865/  8460 | loss: 0.0536 | ds_loss: 0.0000 | lr: 1.9166e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4866/  8460 | global iter:   4866/  8460 | loss: 0.6197 | ds_loss: 0.0000 | lr: 1.9156e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4867/  8460 | global iter:   4867/  8460 | loss: 0.1523 | ds_loss: 0.0000 | lr: 1.9147e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4868/  8460 | global iter:   4868/  8460 | loss: 0.5157 | ds_loss: 0.0000 | lr: 1.9138e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4868/  8460 | global iter:   4868/  8460 | loss: 0.3353 | ds_loss: 0.0000 | lr: 1.9138e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4869/  8460 | global iter:   4869/  8460 | loss: 0.1424 | ds_loss: 0.0000 | lr: 1.9129e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4870/  8460 | global iter:   4870/  8460 | loss: 0.1254 | ds_loss: 0.0000 | lr: 1.9120e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4871/  8460 | global iter:   4871/  8460 | loss: 0.0486 | ds_loss: 0.0000 | lr: 1.9111e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4872/  8460 | global iter:   4872/  8460 | loss: 0.2384 | ds_loss: 0.0000 | lr: 1.9102e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4872/  8460 | global iter:   4872/  8460 | loss: 0.1387 | ds_loss: 0.0000 | lr: 1.9102e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4873/  8460 | global iter:   4873/  8460 | loss: 0.0711 | ds_loss: 0.0000 | lr: 1.9093e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4874/  8460 | global iter:   4874/  8460 | loss: 0.2672 | ds_loss: 0.0000 | lr: 1.9084e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4875/  8460 | global iter:   4875/  8460 | loss: 0.1413 | ds_loss: 0.0000 | lr: 1.9075e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4876/  8460 | global iter:   4876/  8460 | loss: 0.0942 | ds_loss: 0.0000 | lr: 1.9066e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4876/  8460 | global iter:   4876/  8460 | loss: 0.1435 | ds_loss: 0.0000 | lr: 1.9066e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4877/  8460 | global iter:   4877/  8460 | loss: 0.2414 | ds_loss: 0.0000 | lr: 1.9057e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4878/  8460 | global iter:   4878/  8460 | loss: 0.0628 | ds_loss: 0.0000 | lr: 1.9048e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4879/  8460 | global iter:   4879/  8460 | loss: 0.1583 | ds_loss: 0.0000 | lr: 1.9039e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4880/  8460 | global iter:   4880/  8460 | loss: 0.4380 | ds_loss: 0.0000 | lr: 1.9030e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4880/  8460 | global iter:   4880/  8460 | loss: 0.2251 | ds_loss: 0.0000 | lr: 1.9030e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4881/  8460 | global iter:   4881/  8460 | loss: 0.4408 | ds_loss: 0.0000 | lr: 1.9021e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4882/  8460 | global iter:   4882/  8460 | loss: 0.2961 | ds_loss: 0.0000 | lr: 1.9012e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4883/  8460 | global iter:   4883/  8460 | loss: 0.2023 | ds_loss: 0.0000 | lr: 1.9003e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4884/  8460 | global iter:   4884/  8460 | loss: 0.2295 | ds_loss: 0.0000 | lr: 1.8994e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4884/  8460 | global iter:   4884/  8460 | loss: 0.2922 | ds_loss: 0.0000 | lr: 1.8994e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4885/  8460 | global iter:   4885/  8460 | loss: 0.2765 | ds_loss: 0.0000 | lr: 1.8985e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4886/  8460 | global iter:   4886/  8460 | loss: 0.1366 | ds_loss: 0.0000 | lr: 1.8976e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4887/  8460 | global iter:   4887/  8460 | loss: 0.1890 | ds_loss: 0.0000 | lr: 1.8967e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4888/  8460 | global iter:   4888/  8460 | loss: 0.1731 | ds_loss: 0.0000 | lr: 1.8958e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4888/  8460 | global iter:   4888/  8460 | loss: 0.1938 | ds_loss: 0.0000 | lr: 1.8958e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4889/  8460 | global iter:   4889/  8460 | loss: 0.0809 | ds_loss: 0.0000 | lr: 1.8949e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4890/  8460 | global iter:   4890/  8460 | loss: 0.0402 | ds_loss: 0.0000 | lr: 1.8940e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4891/  8460 | global iter:   4891/  8460 | loss: 0.2373 | ds_loss: 0.0000 | lr: 1.8931e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4892/  8460 | global iter:   4892/  8460 | loss: 0.1090 | ds_loss: 0.0000 | lr: 1.8922e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4892/  8460 | global iter:   4892/  8460 | loss: 0.1168 | ds_loss: 0.0000 | lr: 1.8922e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4893/  8460 | global iter:   4893/  8460 | loss: 0.5145 | ds_loss: 0.0000 | lr: 1.8913e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4894/  8460 | global iter:   4894/  8460 | loss: 0.0480 | ds_loss: 0.0000 | lr: 1.8904e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4895/  8460 | global iter:   4895/  8460 | loss: 0.0444 | ds_loss: 0.0000 | lr: 1.8895e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4896/  8460 | global iter:   4896/  8460 | loss: 0.3309 | ds_loss: 0.0000 | lr: 1.8886e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4896/  8460 | global iter:   4896/  8460 | loss: 0.2345 | ds_loss: 0.0000 | lr: 1.8886e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4897/  8460 | global iter:   4897/  8460 | loss: 0.1403 | ds_loss: 0.0000 | lr: 1.8877e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4898/  8460 | global iter:   4898/  8460 | loss: 0.3560 | ds_loss: 0.0000 | lr: 1.8868e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4899/  8460 | global iter:   4899/  8460 | loss: 0.3338 | ds_loss: 0.0000 | lr: 1.8859e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4900/  8460 | global iter:   4900/  8460 | loss: 0.1222 | ds_loss: 0.0000 | lr: 1.8850e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4900/  8460 | global iter:   4900/  8460 | loss: 0.2381 | ds_loss: 0.0000 | lr: 1.8850e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4901/  8460 | global iter:   4901/  8460 | loss: 0.1640 | ds_loss: 0.0000 | lr: 1.8841e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4902/  8460 | global iter:   4902/  8460 | loss: 0.0476 | ds_loss: 0.0000 | lr: 1.8832e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4903/  8460 | global iter:   4903/  8460 | loss: 0.2975 | ds_loss: 0.0000 | lr: 1.8823e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4904/  8460 | global iter:   4904/  8460 | loss: 0.1127 | ds_loss: 0.0000 | lr: 1.8814e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4904/  8460 | global iter:   4904/  8460 | loss: 0.1555 | ds_loss: 0.0000 | lr: 1.8814e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4905/  8460 | global iter:   4905/  8460 | loss: 0.0968 | ds_loss: 0.0000 | lr: 1.8805e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4906/  8460 | global iter:   4906/  8460 | loss: 0.3124 | ds_loss: 0.0000 | lr: 1.8796e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4907/  8460 | global iter:   4907/  8460 | loss: 0.0965 | ds_loss: 0.0000 | lr: 1.8787e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4908/  8460 | global iter:   4908/  8460 | loss: 0.5587 | ds_loss: 0.0000 | lr: 1.8778e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4908/  8460 | global iter:   4908/  8460 | loss: 0.2661 | ds_loss: 0.0000 | lr: 1.8778e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4909/  8460 | global iter:   4909/  8460 | loss: 0.1413 | ds_loss: 0.0000 | lr: 1.8769e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4910/  8460 | global iter:   4910/  8460 | loss: 0.0698 | ds_loss: 0.0000 | lr: 1.8760e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4911/  8460 | global iter:   4911/  8460 | loss: 0.2667 | ds_loss: 0.0000 | lr: 1.8751e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4912/  8460 | global iter:   4912/  8460 | loss: 0.0660 | ds_loss: 0.0000 | lr: 1.8742e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4912/  8460 | global iter:   4912/  8460 | loss: 0.1359 | ds_loss: 0.0000 | lr: 1.8742e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4913/  8460 | global iter:   4913/  8460 | loss: 0.2532 | ds_loss: 0.0000 | lr: 1.8733e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4914/  8460 | global iter:   4914/  8460 | loss: 0.3554 | ds_loss: 0.0000 | lr: 1.8724e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4915/  8460 | global iter:   4915/  8460 | loss: 0.5216 | ds_loss: 0.0000 | lr: 1.8715e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4916/  8460 | global iter:   4916/  8460 | loss: 0.0157 | ds_loss: 0.0000 | lr: 1.8706e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4916/  8460 | global iter:   4916/  8460 | loss: 0.2865 | ds_loss: 0.0000 | lr: 1.8706e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4917/  8460 | global iter:   4917/  8460 | loss: 0.4061 | ds_loss: 0.0000 | lr: 1.8697e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4918/  8460 | global iter:   4918/  8460 | loss: 0.3056 | ds_loss: 0.0000 | lr: 1.8688e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4919/  8460 | global iter:   4919/  8460 | loss: 0.4493 | ds_loss: 0.0000 | lr: 1.8679e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4920/  8460 | global iter:   4920/  8460 | loss: 0.0427 | ds_loss: 0.0000 | lr: 1.8670e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4920/  8460 | global iter:   4920/  8460 | loss: 0.3009 | ds_loss: 0.0000 | lr: 1.8670e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4921/  8460 | global iter:   4921/  8460 | loss: 0.2689 | ds_loss: 0.0000 | lr: 1.8661e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4922/  8460 | global iter:   4922/  8460 | loss: 0.1095 | ds_loss: 0.0000 | lr: 1.8652e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4923/  8460 | global iter:   4923/  8460 | loss: 0.3635 | ds_loss: 0.0000 | lr: 1.8643e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4924/  8460 | global iter:   4924/  8460 | loss: 0.1159 | ds_loss: 0.0000 | lr: 1.8634e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4924/  8460 | global iter:   4924/  8460 | loss: 0.2144 | ds_loss: 0.0000 | lr: 1.8634e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4925/  8460 | global iter:   4925/  8460 | loss: 0.2040 | ds_loss: 0.0000 | lr: 1.8626e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4926/  8460 | global iter:   4926/  8460 | loss: 0.0331 | ds_loss: 0.0000 | lr: 1.8617e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4927/  8460 | global iter:   4927/  8460 | loss: 0.2108 | ds_loss: 0.0000 | lr: 1.8608e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4928/  8460 | global iter:   4928/  8460 | loss: 0.1150 | ds_loss: 0.0000 | lr: 1.8599e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4928/  8460 | global iter:   4928/  8460 | loss: 0.1407 | ds_loss: 0.0000 | lr: 1.8599e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4929/  8460 | global iter:   4929/  8460 | loss: 0.1226 | ds_loss: 0.0000 | lr: 1.8590e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4930/  8460 | global iter:   4930/  8460 | loss: 0.0675 | ds_loss: 0.0000 | lr: 1.8581e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4931/  8460 | global iter:   4931/  8460 | loss: 0.1139 | ds_loss: 0.0000 | lr: 1.8572e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4932/  8460 | global iter:   4932/  8460 | loss: 0.0603 | ds_loss: 0.0000 | lr: 1.8563e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4932/  8460 | global iter:   4932/  8460 | loss: 0.0911 | ds_loss: 0.0000 | lr: 1.8563e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4933/  8460 | global iter:   4933/  8460 | loss: 0.1387 | ds_loss: 0.0000 | lr: 1.8554e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4934/  8460 | global iter:   4934/  8460 | loss: 0.1425 | ds_loss: 0.0000 | lr: 1.8545e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4935/  8460 | global iter:   4935/  8460 | loss: 0.0978 | ds_loss: 0.0000 | lr: 1.8536e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4936/  8460 | global iter:   4936/  8460 | loss: 0.0592 | ds_loss: 0.0000 | lr: 1.8527e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4936/  8460 | global iter:   4936/  8460 | loss: 0.1095 | ds_loss: 0.0000 | lr: 1.8527e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4937/  8460 | global iter:   4937/  8460 | loss: 0.1944 | ds_loss: 0.0000 | lr: 1.8518e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4938/  8460 | global iter:   4938/  8460 | loss: 0.6032 | ds_loss: 0.0000 | lr: 1.8509e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4939/  8460 | global iter:   4939/  8460 | loss: 0.2477 | ds_loss: 0.0000 | lr: 1.8500e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4940/  8460 | global iter:   4940/  8460 | loss: 0.1313 | ds_loss: 0.0000 | lr: 1.8491e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4940/  8460 | global iter:   4940/  8460 | loss: 0.2941 | ds_loss: 0.0000 | lr: 1.8491e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4941/  8460 | global iter:   4941/  8460 | loss: 0.1936 | ds_loss: 0.0000 | lr: 1.8482e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4942/  8460 | global iter:   4942/  8460 | loss: 0.1479 | ds_loss: 0.0000 | lr: 1.8473e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4943/  8460 | global iter:   4943/  8460 | loss: 0.1914 | ds_loss: 0.0000 | lr: 1.8464e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4944/  8460 | global iter:   4944/  8460 | loss: 0.0664 | ds_loss: 0.0000 | lr: 1.8455e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4944/  8460 | global iter:   4944/  8460 | loss: 0.1498 | ds_loss: 0.0000 | lr: 1.8455e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4945/  8460 | global iter:   4945/  8460 | loss: 0.4230 | ds_loss: 0.0000 | lr: 1.8446e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4946/  8460 | global iter:   4946/  8460 | loss: 0.2829 | ds_loss: 0.0000 | lr: 1.8437e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4947/  8460 | global iter:   4947/  8460 | loss: 0.1377 | ds_loss: 0.0000 | lr: 1.8428e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4948/  8460 | global iter:   4948/  8460 | loss: 0.3322 | ds_loss: 0.0000 | lr: 1.8419e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4948/  8460 | global iter:   4948/  8460 | loss: 0.2940 | ds_loss: 0.0000 | lr: 1.8419e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4949/  8460 | global iter:   4949/  8460 | loss: 0.1855 | ds_loss: 0.0000 | lr: 1.8410e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4950/  8460 | global iter:   4950/  8460 | loss: 0.1663 | ds_loss: 0.0000 | lr: 1.8401e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4951/  8460 | global iter:   4951/  8460 | loss: 0.0991 | ds_loss: 0.0000 | lr: 1.8392e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4952/  8460 | global iter:   4952/  8460 | loss: 0.1345 | ds_loss: 0.0000 | lr: 1.8384e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4952/  8460 | global iter:   4952/  8460 | loss: 0.1464 | ds_loss: 0.0000 | lr: 1.8384e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4953/  8460 | global iter:   4953/  8460 | loss: 0.1473 | ds_loss: 0.0000 | lr: 1.8375e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4954/  8460 | global iter:   4954/  8460 | loss: 0.1956 | ds_loss: 0.0000 | lr: 1.8366e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4955/  8460 | global iter:   4955/  8460 | loss: 0.3000 | ds_loss: 0.0000 | lr: 1.8357e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4956/  8460 | global iter:   4956/  8460 | loss: 0.4455 | ds_loss: 0.0000 | lr: 1.8348e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4956/  8460 | global iter:   4956/  8460 | loss: 0.2721 | ds_loss: 0.0000 | lr: 1.8348e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4957/  8460 | global iter:   4957/  8460 | loss: 0.0086 | ds_loss: 0.0000 | lr: 1.8339e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4958/  8460 | global iter:   4958/  8460 | loss: 0.1065 | ds_loss: 0.0000 | lr: 1.8330e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4959/  8460 | global iter:   4959/  8460 | loss: 0.2232 | ds_loss: 0.0000 | lr: 1.8321e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4960/  8460 | global iter:   4960/  8460 | loss: 0.1422 | ds_loss: 0.0000 | lr: 1.8312e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4960/  8460 | global iter:   4960/  8460 | loss: 0.1201 | ds_loss: 0.0000 | lr: 1.8312e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4961/  8460 | global iter:   4961/  8460 | loss: 0.0710 | ds_loss: 0.0000 | lr: 1.8303e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4962/  8460 | global iter:   4962/  8460 | loss: 0.4002 | ds_loss: 0.0000 | lr: 1.8294e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4963/  8460 | global iter:   4963/  8460 | loss: 0.2984 | ds_loss: 0.0000 | lr: 1.8285e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4964/  8460 | global iter:   4964/  8460 | loss: 0.2565 | ds_loss: 0.0000 | lr: 1.8276e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4964/  8460 | global iter:   4964/  8460 | loss: 0.2565 | ds_loss: 0.0000 | lr: 1.8276e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4965/  8460 | global iter:   4965/  8460 | loss: 0.3653 | ds_loss: 0.0000 | lr: 1.8267e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4966/  8460 | global iter:   4966/  8460 | loss: 0.2354 | ds_loss: 0.0000 | lr: 1.8258e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4967/  8460 | global iter:   4967/  8460 | loss: 0.2180 | ds_loss: 0.0000 | lr: 1.8249e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4968/  8460 | global iter:   4968/  8460 | loss: 0.1950 | ds_loss: 0.0000 | lr: 1.8240e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4968/  8460 | global iter:   4968/  8460 | loss: 0.2534 | ds_loss: 0.0000 | lr: 1.8240e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4969/  8460 | global iter:   4969/  8460 | loss: 0.3635 | ds_loss: 0.0000 | lr: 1.8232e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4970/  8460 | global iter:   4970/  8460 | loss: 0.3363 | ds_loss: 0.0000 | lr: 1.8223e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4971/  8460 | global iter:   4971/  8460 | loss: 0.2017 | ds_loss: 0.0000 | lr: 1.8214e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4972/  8460 | global iter:   4972/  8460 | loss: 0.2820 | ds_loss: 0.0000 | lr: 1.8205e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4972/  8460 | global iter:   4972/  8460 | loss: 0.2959 | ds_loss: 0.0000 | lr: 1.8205e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4973/  8460 | global iter:   4973/  8460 | loss: 0.2690 | ds_loss: 0.0000 | lr: 1.8196e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4974/  8460 | global iter:   4974/  8460 | loss: 0.2519 | ds_loss: 0.0000 | lr: 1.8187e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4975/  8460 | global iter:   4975/  8460 | loss: 0.1278 | ds_loss: 0.0000 | lr: 1.8178e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4976/  8460 | global iter:   4976/  8460 | loss: 0.3250 | ds_loss: 0.0000 | lr: 1.8169e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4976/  8460 | global iter:   4976/  8460 | loss: 0.2434 | ds_loss: 0.0000 | lr: 1.8169e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4977/  8460 | global iter:   4977/  8460 | loss: 0.0877 | ds_loss: 0.0000 | lr: 1.8160e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4978/  8460 | global iter:   4978/  8460 | loss: 0.2076 | ds_loss: 0.0000 | lr: 1.8151e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   4979/  8460 | global iter:   4979/  8460 | loss: 0.4068 | ds_loss: 0.0000 | lr: 1.8142e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4980/  8460 | global iter:   4980/  8460 | loss: 0.1565 | ds_loss: 0.0000 | lr: 1.8133e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4980/  8460 | global iter:   4980/  8460 | loss: 0.2146 | ds_loss: 0.0000 | lr: 1.8133e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4981/  8460 | global iter:   4981/  8460 | loss: 0.1747 | ds_loss: 0.0000 | lr: 1.8124e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4982/  8460 | global iter:   4982/  8460 | loss: 0.2769 | ds_loss: 0.0000 | lr: 1.8115e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4983/  8460 | global iter:   4983/  8460 | loss: 0.1342 | ds_loss: 0.0000 | lr: 1.8107e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4984/  8460 | global iter:   4984/  8460 | loss: 0.1185 | ds_loss: 0.0000 | lr: 1.8098e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4984/  8460 | global iter:   4984/  8460 | loss: 0.1761 | ds_loss: 0.0000 | lr: 1.8098e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4985/  8460 | global iter:   4985/  8460 | loss: 0.3894 | ds_loss: 0.0000 | lr: 1.8089e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4986/  8460 | global iter:   4986/  8460 | loss: 0.3484 | ds_loss: 0.0000 | lr: 1.8080e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4987/  8460 | global iter:   4987/  8460 | loss: 0.1047 | ds_loss: 0.0000 | lr: 1.8071e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4988/  8460 | global iter:   4988/  8460 | loss: 0.1332 | ds_loss: 0.0000 | lr: 1.8062e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4988/  8460 | global iter:   4988/  8460 | loss: 0.2439 | ds_loss: 0.0000 | lr: 1.8062e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4989/  8460 | global iter:   4989/  8460 | loss: 0.4765 | ds_loss: 0.0000 | lr: 1.8053e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4990/  8460 | global iter:   4990/  8460 | loss: 0.2092 | ds_loss: 0.0000 | lr: 1.8044e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4991/  8460 | global iter:   4991/  8460 | loss: 0.5160 | ds_loss: 0.0000 | lr: 1.8035e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4992/  8460 | global iter:   4992/  8460 | loss: 0.1225 | ds_loss: 0.0000 | lr: 1.8026e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4992/  8460 | global iter:   4992/  8460 | loss: 0.3311 | ds_loss: 0.0000 | lr: 1.8026e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4993/  8460 | global iter:   4993/  8460 | loss: 0.0278 | ds_loss: 0.0000 | lr: 1.8017e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4994/  8460 | global iter:   4994/  8460 | loss: 0.0995 | ds_loss: 0.0000 | lr: 1.8008e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4995/  8460 | global iter:   4995/  8460 | loss: 0.3217 | ds_loss: 0.0000 | lr: 1.8000e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4996/  8460 | global iter:   4996/  8460 | loss: 0.2027 | ds_loss: 0.0000 | lr: 1.7991e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   4996/  8460 | global iter:   4996/  8460 | loss: 0.1629 | ds_loss: 0.0000 | lr: 1.7991e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   4997/  8460 | global iter:   4997/  8460 | loss: 0.1165 | ds_loss: 0.0000 | lr: 1.7982e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   4998/  8460 | global iter:   4998/  8460 | loss: 0.1423 | ds_loss: 0.0000 | lr: 1.7973e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   4999/  8460 | global iter:   4999/  8460 | loss: 0.5198 | ds_loss: 0.0000 | lr: 1.7964e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5000/  8460 | global iter:   5000/  8460 | loss: 0.1411 | ds_loss: 0.0000 | lr: 1.7955e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   5000/  8460 | global iter:   5000/  8460 | loss: 0.2299 | ds_loss: 0.0000 | lr: 1.7955e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   5001/  8460 | global iter:   5001/  8460 | loss: 0.0619 | ds_loss: 0.0000 | lr: 1.7946e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   5002/  8460 | global iter:   5002/  8460 | loss: 0.2316 | ds_loss: 0.0000 | lr: 1.7937e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5003/  8460 | global iter:   5003/  8460 | loss: 0.1765 | ds_loss: 0.0000 | lr: 1.7928e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5004/  8460 | global iter:   5004/  8460 | loss: 0.1039 | ds_loss: 0.0000 | lr: 1.7919e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   5004/  8460 | global iter:   5004/  8460 | loss: 0.1435 | ds_loss: 0.0000 | lr: 1.7919e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   5005/  8460 | global iter:   5005/  8460 | loss: 0.0764 | ds_loss: 0.0000 | lr: 1.7910e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5006/  8460 | global iter:   5006/  8460 | loss: 0.2373 | ds_loss: 0.0000 | lr: 1.7902e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   5007/  8460 | global iter:   5007/  8460 | loss: 0.2058 | ds_loss: 0.0000 | lr: 1.7893e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   5008/  8460 | global iter:   5008/  8460 | loss: 0.0534 | ds_loss: 0.0000 | lr: 1.7884e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   5008/  8460 | global iter:   5008/  8460 | loss: 0.1432 | ds_loss: 0.0000 | lr: 1.7884e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   5009/  8460 | global iter:   5009/  8460 | loss: 0.3111 | ds_loss: 0.0000 | lr: 1.7875e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   5010/  8460 | global iter:   5010/  8460 | loss: 0.3778 | ds_loss: 0.0000 | lr: 1.7866e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5011/  8460 | global iter:   5011/  8460 | loss: 0.0390 | ds_loss: 0.0000 | lr: 1.7857e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5012/  8460 | global iter:   5012/  8460 | loss: 0.0565 | ds_loss: 0.0000 | lr: 1.7848e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   5012/  8460 | global iter:   5012/  8460 | loss: 0.1961 | ds_loss: 0.0000 | lr: 1.7848e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   5013/  8460 | global iter:   5013/  8460 | loss: 0.1203 | ds_loss: 0.0000 | lr: 1.7839e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5014/  8460 | global iter:   5014/  8460 | loss: 0.2947 | ds_loss: 0.0000 | lr: 1.7830e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5015/  8460 | global iter:   5015/  8460 | loss: 0.2055 | ds_loss: 0.0000 | lr: 1.7822e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5016/  8460 | global iter:   5016/  8460 | loss: 0.4451 | ds_loss: 0.0000 | lr: 1.7813e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   5016/  8460 | global iter:   5016/  8460 | loss: 0.2664 | ds_loss: 0.0000 | lr: 1.7813e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   5017/  8460 | global iter:   5017/  8460 | loss: 0.0857 | ds_loss: 0.0000 | lr: 1.7804e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   5018/  8460 | global iter:   5018/  8460 | loss: 0.2551 | ds_loss: 0.0000 | lr: 1.7795e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5019/  8460 | global iter:   5019/  8460 | loss: 0.0665 | ds_loss: 0.0000 | lr: 1.7786e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5020/  8460 | global iter:   5020/  8460 | loss: 0.1033 | ds_loss: 0.0000 | lr: 1.7777e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   5020/  8460 | global iter:   5020/  8460 | loss: 0.1277 | ds_loss: 0.0000 | lr: 1.7777e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   5021/  8460 | global iter:   5021/  8460 | loss: 0.2480 | ds_loss: 0.0000 | lr: 1.7768e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5022/  8460 | global iter:   5022/  8460 | loss: 0.1131 | ds_loss: 0.0000 | lr: 1.7759e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5023/  8460 | global iter:   5023/  8460 | loss: 0.0665 | ds_loss: 0.0000 | lr: 1.7750e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5024/  8460 | global iter:   5024/  8460 | loss: 0.2148 | ds_loss: 0.0000 | lr: 1.7742e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   5024/  8460 | global iter:   5024/  8460 | loss: 0.1606 | ds_loss: 0.0000 | lr: 1.7742e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   5025/  8460 | global iter:   5025/  8460 | loss: 0.1337 | ds_loss: 0.0000 | lr: 1.7733e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5026/  8460 | global iter:   5026/  8460 | loss: 0.1660 | ds_loss: 0.0000 | lr: 1.7724e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5027/  8460 | global iter:   5027/  8460 | loss: 0.1586 | ds_loss: 0.0000 | lr: 1.7715e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5028/  8460 | global iter:   5028/  8460 | loss: 0.1669 | ds_loss: 0.0000 | lr: 1.7706e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   5028/  8460 | global iter:   5028/  8460 | loss: 0.1563 | ds_loss: 0.0000 | lr: 1.7706e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   5029/  8460 | global iter:   5029/  8460 | loss: 0.0345 | ds_loss: 0.0000 | lr: 1.7697e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   5030/  8460 | global iter:   5030/  8460 | loss: 0.3457 | ds_loss: 0.0000 | lr: 1.7688e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   5031/  8460 | global iter:   5031/  8460 | loss: 0.1140 | ds_loss: 0.0000 | lr: 1.7679e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   5032/  8460 | global iter:   5032/  8460 | loss: 0.1366 | ds_loss: 0.0000 | lr: 1.7671e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   5032/  8460 | global iter:   5032/  8460 | loss: 0.1577 | ds_loss: 0.0000 | lr: 1.7671e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   5033/  8460 | global iter:   5033/  8460 | loss: 0.5488 | ds_loss: 0.0000 | lr: 1.7662e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5034/  8460 | global iter:   5034/  8460 | loss: 0.4655 | ds_loss: 0.0000 | lr: 1.7653e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5035/  8460 | global iter:   5035/  8460 | loss: 0.3038 | ds_loss: 0.0000 | lr: 1.7644e-04 | scale:     1.0000 | micro time: 0.439 | step time: 0.000
train | epoch   5 | Iter:   5036/  8460 | global iter:   5036/  8460 | loss: 0.7102 | ds_loss: 0.0000 | lr: 1.7635e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   5036/  8460 | global iter:   5036/  8460 | loss: 0.5071 | ds_loss: 0.0000 | lr: 1.7635e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.431
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   5037/  8460 | global iter:   5037/  8460 | loss: 0.3739 | ds_loss: 0.0000 | lr: 1.7626e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5038/  8460 | global iter:   5038/  8460 | loss: 0.5124 | ds_loss: 0.0000 | lr: 1.7617e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5039/  8460 | global iter:   5039/  8460 | loss: 0.2177 | ds_loss: 0.0000 | lr: 1.7608e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5040/  8460 | global iter:   5040/  8460 | loss: 0.1292 | ds_loss: 0.0000 | lr: 1.7600e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   5040/  8460 | global iter:   5040/  8460 | loss: 0.3083 | ds_loss: 0.0000 | lr: 1.7600e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   5041/  8460 | global iter:   5041/  8460 | loss: 0.1308 | ds_loss: 0.0000 | lr: 1.7591e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5042/  8460 | global iter:   5042/  8460 | loss: 0.0829 | ds_loss: 0.0000 | lr: 1.7582e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5043/  8460 | global iter:   5043/  8460 | loss: 0.1477 | ds_loss: 0.0000 | lr: 1.7573e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   5044/  8460 | global iter:   5044/  8460 | loss: 0.0880 | ds_loss: 0.0000 | lr: 1.7564e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   5044/  8460 | global iter:   5044/  8460 | loss: 0.1124 | ds_loss: 0.0000 | lr: 1.7564e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   5045/  8460 | global iter:   5045/  8460 | loss: 0.0917 | ds_loss: 0.0000 | lr: 1.7555e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5046/  8460 | global iter:   5046/  8460 | loss: 0.0411 | ds_loss: 0.0000 | lr: 1.7546e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   5047/  8460 | global iter:   5047/  8460 | loss: 0.2904 | ds_loss: 0.0000 | lr: 1.7538e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   5048/  8460 | global iter:   5048/  8460 | loss: 0.1676 | ds_loss: 0.0000 | lr: 1.7529e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   5048/  8460 | global iter:   5048/  8460 | loss: 0.1477 | ds_loss: 0.0000 | lr: 1.7529e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   5049/  8460 | global iter:   5049/  8460 | loss: 0.4237 | ds_loss: 0.0000 | lr: 1.7520e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5050/  8460 | global iter:   5050/  8460 | loss: 0.0456 | ds_loss: 0.0000 | lr: 1.7511e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5051/  8460 | global iter:   5051/  8460 | loss: 0.1276 | ds_loss: 0.0000 | lr: 1.7502e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5052/  8460 | global iter:   5052/  8460 | loss: 0.0927 | ds_loss: 0.0000 | lr: 1.7493e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   5052/  8460 | global iter:   5052/  8460 | loss: 0.1724 | ds_loss: 0.0000 | lr: 1.7493e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   5053/  8460 | global iter:   5053/  8460 | loss: 0.1841 | ds_loss: 0.0000 | lr: 1.7484e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   5054/  8460 | global iter:   5054/  8460 | loss: 0.2147 | ds_loss: 0.0000 | lr: 1.7476e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   5055/  8460 | global iter:   5055/  8460 | loss: 0.3936 | ds_loss: 0.0000 | lr: 1.7467e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5056/  8460 | global iter:   5056/  8460 | loss: 0.1050 | ds_loss: 0.0000 | lr: 1.7458e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   5056/  8460 | global iter:   5056/  8460 | loss: 0.2244 | ds_loss: 0.0000 | lr: 1.7458e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   5057/  8460 | global iter:   5057/  8460 | loss: 0.0694 | ds_loss: 0.0000 | lr: 1.7449e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   5058/  8460 | global iter:   5058/  8460 | loss: 0.1169 | ds_loss: 0.0000 | lr: 1.7440e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5059/  8460 | global iter:   5059/  8460 | loss: 0.1943 | ds_loss: 0.0000 | lr: 1.7431e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5060/  8460 | global iter:   5060/  8460 | loss: 0.2294 | ds_loss: 0.0000 | lr: 1.7422e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   5060/  8460 | global iter:   5060/  8460 | loss: 0.1525 | ds_loss: 0.0000 | lr: 1.7422e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   5061/  8460 | global iter:   5061/  8460 | loss: 0.2059 | ds_loss: 0.0000 | lr: 1.7414e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5062/  8460 | global iter:   5062/  8460 | loss: 0.1176 | ds_loss: 0.0000 | lr: 1.7405e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5063/  8460 | global iter:   5063/  8460 | loss: 0.1956 | ds_loss: 0.0000 | lr: 1.7396e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5064/  8460 | global iter:   5064/  8460 | loss: 0.1410 | ds_loss: 0.0000 | lr: 1.7387e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   5064/  8460 | global iter:   5064/  8460 | loss: 0.1650 | ds_loss: 0.0000 | lr: 1.7387e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   5065/  8460 | global iter:   5065/  8460 | loss: 0.3852 | ds_loss: 0.0000 | lr: 1.7378e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   5066/  8460 | global iter:   5066/  8460 | loss: 0.2522 | ds_loss: 0.0000 | lr: 1.7369e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   5067/  8460 | global iter:   5067/  8460 | loss: 0.0420 | ds_loss: 0.0000 | lr: 1.7361e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   5068/  8460 | global iter:   5068/  8460 | loss: 0.1920 | ds_loss: 0.0000 | lr: 1.7352e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   5068/  8460 | global iter:   5068/  8460 | loss: 0.2178 | ds_loss: 0.0000 | lr: 1.7352e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   5069/  8460 | global iter:   5069/  8460 | loss: 0.1312 | ds_loss: 0.0000 | lr: 1.7343e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5070/  8460 | global iter:   5070/  8460 | loss: 0.1089 | ds_loss: 0.0000 | lr: 1.7334e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5071/  8460 | global iter:   5071/  8460 | loss: 0.2287 | ds_loss: 0.0000 | lr: 1.7325e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5072/  8460 | global iter:   5072/  8460 | loss: 0.3427 | ds_loss: 0.0000 | lr: 1.7316e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   5072/  8460 | global iter:   5072/  8460 | loss: 0.2029 | ds_loss: 0.0000 | lr: 1.7316e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   5073/  8460 | global iter:   5073/  8460 | loss: 0.1707 | ds_loss: 0.0000 | lr: 1.7308e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5074/  8460 | global iter:   5074/  8460 | loss: 0.2303 | ds_loss: 0.0000 | lr: 1.7299e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5075/  8460 | global iter:   5075/  8460 | loss: 0.0319 | ds_loss: 0.0000 | lr: 1.7290e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   5076/  8460 | global iter:   5076/  8460 | loss: 0.0664 | ds_loss: 0.0000 | lr: 1.7281e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   5076/  8460 | global iter:   5076/  8460 | loss: 0.1248 | ds_loss: 0.0000 | lr: 1.7281e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   5077/  8460 | global iter:   5077/  8460 | loss: 0.2781 | ds_loss: 0.0000 | lr: 1.7272e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5078/  8460 | global iter:   5078/  8460 | loss: 0.0838 | ds_loss: 0.0000 | lr: 1.7263e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   5 | Iter:   5079/  8460 | global iter:   5079/  8460 | loss: 0.2660 | ds_loss: 0.0000 | lr: 1.7255e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   5 | Iter:   5080/  8460 | global iter:   5080/  8460 | loss: 0.0604 | ds_loss: 0.0000 | lr: 1.7246e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   5 | Iter:   5080/  8460 | global iter:   5080/  8460 | loss: 0.1720 | ds_loss: 0.0000 | lr: 1.7246e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   5 | Iter:   5081/  8460 | global iter:   5081/  8460 | loss: 0.2435 | ds_loss: 0.0000 | lr: 1.7237e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   5 | Iter:   5082/  8460 | global iter:   5082/  8460 | loss: 0.1243 | ds_loss: 0.0000 | lr: 1.7228e-04 | scale:     1.0000 | micro time: 0.366 | step time: 0.000
Sun Apr  6 21:29:03 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla P100-PCIE-12GB           Off |   00000000:81:00.0 Off |                    0 |
| N/A   51C    P0             39W /  250W |    8807MiB /  12288MiB |    100%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A    244677      C   ...project_distillLLM/venv/bin/python3       8804MiB |
+-----------------------------------------------------------------------------------------+

train | epoch   6 | Iter:   5083/  8460 | global iter:   5083/  8460 | loss: 0.0467 | ds_loss: 0.0000 | lr: 1.7219e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5084/  8460 | global iter:   5084/  8460 | loss: 0.0700 | ds_loss: 0.0000 | lr: 1.7211e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5084/  8460 | global iter:   5084/  8460 | loss: 0.1211 | ds_loss: 0.0000 | lr: 1.7211e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.413
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5085/  8460 | global iter:   5085/  8460 | loss: 0.1315 | ds_loss: 0.0000 | lr: 1.7202e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5086/  8460 | global iter:   5086/  8460 | loss: 0.0685 | ds_loss: 0.0000 | lr: 1.7193e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5087/  8460 | global iter:   5087/  8460 | loss: 0.0911 | ds_loss: 0.0000 | lr: 1.7184e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5088/  8460 | global iter:   5088/  8460 | loss: 0.1439 | ds_loss: 0.0000 | lr: 1.7175e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5088/  8460 | global iter:   5088/  8460 | loss: 0.1087 | ds_loss: 0.0000 | lr: 1.7175e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5089/  8460 | global iter:   5089/  8460 | loss: 0.1711 | ds_loss: 0.0000 | lr: 1.7166e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5090/  8460 | global iter:   5090/  8460 | loss: 0.1869 | ds_loss: 0.0000 | lr: 1.7158e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5091/  8460 | global iter:   5091/  8460 | loss: 0.0093 | ds_loss: 0.0000 | lr: 1.7149e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5092/  8460 | global iter:   5092/  8460 | loss: 0.3557 | ds_loss: 0.0000 | lr: 1.7140e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5092/  8460 | global iter:   5092/  8460 | loss: 0.1808 | ds_loss: 0.0000 | lr: 1.7140e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5093/  8460 | global iter:   5093/  8460 | loss: 0.1004 | ds_loss: 0.0000 | lr: 1.7131e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5094/  8460 | global iter:   5094/  8460 | loss: 0.1051 | ds_loss: 0.0000 | lr: 1.7122e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5095/  8460 | global iter:   5095/  8460 | loss: 0.1061 | ds_loss: 0.0000 | lr: 1.7114e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5096/  8460 | global iter:   5096/  8460 | loss: 0.0630 | ds_loss: 0.0000 | lr: 1.7105e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5096/  8460 | global iter:   5096/  8460 | loss: 0.0937 | ds_loss: 0.0000 | lr: 1.7105e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5097/  8460 | global iter:   5097/  8460 | loss: 0.0827 | ds_loss: 0.0000 | lr: 1.7096e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5098/  8460 | global iter:   5098/  8460 | loss: 0.0887 | ds_loss: 0.0000 | lr: 1.7087e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5099/  8460 | global iter:   5099/  8460 | loss: 0.0467 | ds_loss: 0.0000 | lr: 1.7078e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5100/  8460 | global iter:   5100/  8460 | loss: 0.0883 | ds_loss: 0.0000 | lr: 1.7070e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5100/  8460 | global iter:   5100/  8460 | loss: 0.0766 | ds_loss: 0.0000 | lr: 1.7070e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5101/  8460 | global iter:   5101/  8460 | loss: 0.3454 | ds_loss: 0.0000 | lr: 1.7061e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5102/  8460 | global iter:   5102/  8460 | loss: 0.1511 | ds_loss: 0.0000 | lr: 1.7052e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5103/  8460 | global iter:   5103/  8460 | loss: 0.5635 | ds_loss: 0.0000 | lr: 1.7043e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5104/  8460 | global iter:   5104/  8460 | loss: 0.0268 | ds_loss: 0.0000 | lr: 1.7034e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5104/  8460 | global iter:   5104/  8460 | loss: 0.2717 | ds_loss: 0.0000 | lr: 1.7034e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5105/  8460 | global iter:   5105/  8460 | loss: 0.4682 | ds_loss: 0.0000 | lr: 1.7026e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5106/  8460 | global iter:   5106/  8460 | loss: 0.0545 | ds_loss: 0.0000 | lr: 1.7017e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5107/  8460 | global iter:   5107/  8460 | loss: 0.0617 | ds_loss: 0.0000 | lr: 1.7008e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5108/  8460 | global iter:   5108/  8460 | loss: 0.0440 | ds_loss: 0.0000 | lr: 1.6999e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5108/  8460 | global iter:   5108/  8460 | loss: 0.1571 | ds_loss: 0.0000 | lr: 1.6999e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5109/  8460 | global iter:   5109/  8460 | loss: 0.0898 | ds_loss: 0.0000 | lr: 1.6990e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5110/  8460 | global iter:   5110/  8460 | loss: 0.1998 | ds_loss: 0.0000 | lr: 1.6982e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5111/  8460 | global iter:   5111/  8460 | loss: 0.0603 | ds_loss: 0.0000 | lr: 1.6973e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5112/  8460 | global iter:   5112/  8460 | loss: 0.0870 | ds_loss: 0.0000 | lr: 1.6964e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5112/  8460 | global iter:   5112/  8460 | loss: 0.1092 | ds_loss: 0.0000 | lr: 1.6964e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5113/  8460 | global iter:   5113/  8460 | loss: 0.4587 | ds_loss: 0.0000 | lr: 1.6955e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5114/  8460 | global iter:   5114/  8460 | loss: 0.2443 | ds_loss: 0.0000 | lr: 1.6946e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5115/  8460 | global iter:   5115/  8460 | loss: 0.3183 | ds_loss: 0.0000 | lr: 1.6938e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5116/  8460 | global iter:   5116/  8460 | loss: 0.0206 | ds_loss: 0.0000 | lr: 1.6929e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5116/  8460 | global iter:   5116/  8460 | loss: 0.2605 | ds_loss: 0.0000 | lr: 1.6929e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5117/  8460 | global iter:   5117/  8460 | loss: 0.2430 | ds_loss: 0.0000 | lr: 1.6920e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5118/  8460 | global iter:   5118/  8460 | loss: 0.2842 | ds_loss: 0.0000 | lr: 1.6911e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5119/  8460 | global iter:   5119/  8460 | loss: 0.0198 | ds_loss: 0.0000 | lr: 1.6903e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5120/  8460 | global iter:   5120/  8460 | loss: 0.0373 | ds_loss: 0.0000 | lr: 1.6894e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5120/  8460 | global iter:   5120/  8460 | loss: 0.1461 | ds_loss: 0.0000 | lr: 1.6894e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5121/  8460 | global iter:   5121/  8460 | loss: 0.0948 | ds_loss: 0.0000 | lr: 1.6885e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5122/  8460 | global iter:   5122/  8460 | loss: 0.1825 | ds_loss: 0.0000 | lr: 1.6876e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5123/  8460 | global iter:   5123/  8460 | loss: 0.0699 | ds_loss: 0.0000 | lr: 1.6867e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5124/  8460 | global iter:   5124/  8460 | loss: 0.0669 | ds_loss: 0.0000 | lr: 1.6859e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5124/  8460 | global iter:   5124/  8460 | loss: 0.1035 | ds_loss: 0.0000 | lr: 1.6859e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5125/  8460 | global iter:   5125/  8460 | loss: 0.1042 | ds_loss: 0.0000 | lr: 1.6850e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5126/  8460 | global iter:   5126/  8460 | loss: 0.1536 | ds_loss: 0.0000 | lr: 1.6841e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5127/  8460 | global iter:   5127/  8460 | loss: 0.2991 | ds_loss: 0.0000 | lr: 1.6832e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5128/  8460 | global iter:   5128/  8460 | loss: 0.0526 | ds_loss: 0.0000 | lr: 1.6824e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5128/  8460 | global iter:   5128/  8460 | loss: 0.1524 | ds_loss: 0.0000 | lr: 1.6824e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5129/  8460 | global iter:   5129/  8460 | loss: 0.1928 | ds_loss: 0.0000 | lr: 1.6815e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5130/  8460 | global iter:   5130/  8460 | loss: 0.0103 | ds_loss: 0.0000 | lr: 1.6806e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5131/  8460 | global iter:   5131/  8460 | loss: 0.1252 | ds_loss: 0.0000 | lr: 1.6797e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5132/  8460 | global iter:   5132/  8460 | loss: 0.1418 | ds_loss: 0.0000 | lr: 1.6788e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5132/  8460 | global iter:   5132/  8460 | loss: 0.1175 | ds_loss: 0.0000 | lr: 1.6788e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5133/  8460 | global iter:   5133/  8460 | loss: 0.1097 | ds_loss: 0.0000 | lr: 1.6780e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5134/  8460 | global iter:   5134/  8460 | loss: 0.0278 | ds_loss: 0.0000 | lr: 1.6771e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5135/  8460 | global iter:   5135/  8460 | loss: 0.1995 | ds_loss: 0.0000 | lr: 1.6762e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5136/  8460 | global iter:   5136/  8460 | loss: 0.2626 | ds_loss: 0.0000 | lr: 1.6753e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5136/  8460 | global iter:   5136/  8460 | loss: 0.1499 | ds_loss: 0.0000 | lr: 1.6753e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5137/  8460 | global iter:   5137/  8460 | loss: 0.1264 | ds_loss: 0.0000 | lr: 1.6745e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5138/  8460 | global iter:   5138/  8460 | loss: 0.0828 | ds_loss: 0.0000 | lr: 1.6736e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5139/  8460 | global iter:   5139/  8460 | loss: 0.1245 | ds_loss: 0.0000 | lr: 1.6727e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5140/  8460 | global iter:   5140/  8460 | loss: 0.2247 | ds_loss: 0.0000 | lr: 1.6718e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5140/  8460 | global iter:   5140/  8460 | loss: 0.1396 | ds_loss: 0.0000 | lr: 1.6718e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5141/  8460 | global iter:   5141/  8460 | loss: 0.0449 | ds_loss: 0.0000 | lr: 1.6710e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5142/  8460 | global iter:   5142/  8460 | loss: 0.0857 | ds_loss: 0.0000 | lr: 1.6701e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5143/  8460 | global iter:   5143/  8460 | loss: 0.1464 | ds_loss: 0.0000 | lr: 1.6692e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5144/  8460 | global iter:   5144/  8460 | loss: 0.1615 | ds_loss: 0.0000 | lr: 1.6683e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5144/  8460 | global iter:   5144/  8460 | loss: 0.1096 | ds_loss: 0.0000 | lr: 1.6683e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5145/  8460 | global iter:   5145/  8460 | loss: 0.4298 | ds_loss: 0.0000 | lr: 1.6675e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5146/  8460 | global iter:   5146/  8460 | loss: 0.2173 | ds_loss: 0.0000 | lr: 1.6666e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5147/  8460 | global iter:   5147/  8460 | loss: 0.2646 | ds_loss: 0.0000 | lr: 1.6657e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5148/  8460 | global iter:   5148/  8460 | loss: 0.2052 | ds_loss: 0.0000 | lr: 1.6648e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5148/  8460 | global iter:   5148/  8460 | loss: 0.2792 | ds_loss: 0.0000 | lr: 1.6648e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5149/  8460 | global iter:   5149/  8460 | loss: 0.3463 | ds_loss: 0.0000 | lr: 1.6640e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5150/  8460 | global iter:   5150/  8460 | loss: 0.1291 | ds_loss: 0.0000 | lr: 1.6631e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5151/  8460 | global iter:   5151/  8460 | loss: 0.1481 | ds_loss: 0.0000 | lr: 1.6622e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5152/  8460 | global iter:   5152/  8460 | loss: 0.0495 | ds_loss: 0.0000 | lr: 1.6613e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5152/  8460 | global iter:   5152/  8460 | loss: 0.1683 | ds_loss: 0.0000 | lr: 1.6613e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5153/  8460 | global iter:   5153/  8460 | loss: 0.1069 | ds_loss: 0.0000 | lr: 1.6605e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5154/  8460 | global iter:   5154/  8460 | loss: 0.2996 | ds_loss: 0.0000 | lr: 1.6596e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5155/  8460 | global iter:   5155/  8460 | loss: 0.0161 | ds_loss: 0.0000 | lr: 1.6587e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5156/  8460 | global iter:   5156/  8460 | loss: 0.1903 | ds_loss: 0.0000 | lr: 1.6578e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5156/  8460 | global iter:   5156/  8460 | loss: 0.1532 | ds_loss: 0.0000 | lr: 1.6578e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5157/  8460 | global iter:   5157/  8460 | loss: 0.0679 | ds_loss: 0.0000 | lr: 1.6570e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5158/  8460 | global iter:   5158/  8460 | loss: 0.1359 | ds_loss: 0.0000 | lr: 1.6561e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5159/  8460 | global iter:   5159/  8460 | loss: 0.3117 | ds_loss: 0.0000 | lr: 1.6552e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5160/  8460 | global iter:   5160/  8460 | loss: 0.1261 | ds_loss: 0.0000 | lr: 1.6543e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5160/  8460 | global iter:   5160/  8460 | loss: 0.1604 | ds_loss: 0.0000 | lr: 1.6543e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5161/  8460 | global iter:   5161/  8460 | loss: 0.1636 | ds_loss: 0.0000 | lr: 1.6535e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5162/  8460 | global iter:   5162/  8460 | loss: 0.0902 | ds_loss: 0.0000 | lr: 1.6526e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5163/  8460 | global iter:   5163/  8460 | loss: 0.1210 | ds_loss: 0.0000 | lr: 1.6517e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5164/  8460 | global iter:   5164/  8460 | loss: 0.0890 | ds_loss: 0.0000 | lr: 1.6509e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5164/  8460 | global iter:   5164/  8460 | loss: 0.1159 | ds_loss: 0.0000 | lr: 1.6509e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5165/  8460 | global iter:   5165/  8460 | loss: 0.2103 | ds_loss: 0.0000 | lr: 1.6500e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5166/  8460 | global iter:   5166/  8460 | loss: 0.2694 | ds_loss: 0.0000 | lr: 1.6491e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5167/  8460 | global iter:   5167/  8460 | loss: 0.2128 | ds_loss: 0.0000 | lr: 1.6482e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5168/  8460 | global iter:   5168/  8460 | loss: 0.0910 | ds_loss: 0.0000 | lr: 1.6474e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5168/  8460 | global iter:   5168/  8460 | loss: 0.1959 | ds_loss: 0.0000 | lr: 1.6474e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5169/  8460 | global iter:   5169/  8460 | loss: 0.0215 | ds_loss: 0.0000 | lr: 1.6465e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5170/  8460 | global iter:   5170/  8460 | loss: 0.0467 | ds_loss: 0.0000 | lr: 1.6456e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5171/  8460 | global iter:   5171/  8460 | loss: 0.0525 | ds_loss: 0.0000 | lr: 1.6447e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5172/  8460 | global iter:   5172/  8460 | loss: 0.1382 | ds_loss: 0.0000 | lr: 1.6439e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5172/  8460 | global iter:   5172/  8460 | loss: 0.0648 | ds_loss: 0.0000 | lr: 1.6439e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5173/  8460 | global iter:   5173/  8460 | loss: 0.1240 | ds_loss: 0.0000 | lr: 1.6430e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5174/  8460 | global iter:   5174/  8460 | loss: 0.2093 | ds_loss: 0.0000 | lr: 1.6421e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5175/  8460 | global iter:   5175/  8460 | loss: 0.0862 | ds_loss: 0.0000 | lr: 1.6413e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5176/  8460 | global iter:   5176/  8460 | loss: 0.3631 | ds_loss: 0.0000 | lr: 1.6404e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5176/  8460 | global iter:   5176/  8460 | loss: 0.1956 | ds_loss: 0.0000 | lr: 1.6404e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5177/  8460 | global iter:   5177/  8460 | loss: 0.0942 | ds_loss: 0.0000 | lr: 1.6395e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5178/  8460 | global iter:   5178/  8460 | loss: 0.0716 | ds_loss: 0.0000 | lr: 1.6386e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5179/  8460 | global iter:   5179/  8460 | loss: 0.4987 | ds_loss: 0.0000 | lr: 1.6378e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5180/  8460 | global iter:   5180/  8460 | loss: 0.2475 | ds_loss: 0.0000 | lr: 1.6369e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5180/  8460 | global iter:   5180/  8460 | loss: 0.2280 | ds_loss: 0.0000 | lr: 1.6369e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5181/  8460 | global iter:   5181/  8460 | loss: 0.1237 | ds_loss: 0.0000 | lr: 1.6360e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5182/  8460 | global iter:   5182/  8460 | loss: 0.2200 | ds_loss: 0.0000 | lr: 1.6352e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5183/  8460 | global iter:   5183/  8460 | loss: 0.0589 | ds_loss: 0.0000 | lr: 1.6343e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5184/  8460 | global iter:   5184/  8460 | loss: 0.0879 | ds_loss: 0.0000 | lr: 1.6334e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5184/  8460 | global iter:   5184/  8460 | loss: 0.1226 | ds_loss: 0.0000 | lr: 1.6334e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5185/  8460 | global iter:   5185/  8460 | loss: 0.0704 | ds_loss: 0.0000 | lr: 1.6326e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5186/  8460 | global iter:   5186/  8460 | loss: 0.2158 | ds_loss: 0.0000 | lr: 1.6317e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5187/  8460 | global iter:   5187/  8460 | loss: 0.2411 | ds_loss: 0.0000 | lr: 1.6308e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5188/  8460 | global iter:   5188/  8460 | loss: 0.1997 | ds_loss: 0.0000 | lr: 1.6299e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5188/  8460 | global iter:   5188/  8460 | loss: 0.1817 | ds_loss: 0.0000 | lr: 1.6299e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5189/  8460 | global iter:   5189/  8460 | loss: 0.1769 | ds_loss: 0.0000 | lr: 1.6291e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5190/  8460 | global iter:   5190/  8460 | loss: 0.3158 | ds_loss: 0.0000 | lr: 1.6282e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5191/  8460 | global iter:   5191/  8460 | loss: 0.0497 | ds_loss: 0.0000 | lr: 1.6273e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5192/  8460 | global iter:   5192/  8460 | loss: 0.1314 | ds_loss: 0.0000 | lr: 1.6265e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5192/  8460 | global iter:   5192/  8460 | loss: 0.1684 | ds_loss: 0.0000 | lr: 1.6265e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5193/  8460 | global iter:   5193/  8460 | loss: 0.0939 | ds_loss: 0.0000 | lr: 1.6256e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5194/  8460 | global iter:   5194/  8460 | loss: 0.0363 | ds_loss: 0.0000 | lr: 1.6247e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5195/  8460 | global iter:   5195/  8460 | loss: 0.0076 | ds_loss: 0.0000 | lr: 1.6239e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5196/  8460 | global iter:   5196/  8460 | loss: 0.1016 | ds_loss: 0.0000 | lr: 1.6230e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5196/  8460 | global iter:   5196/  8460 | loss: 0.0599 | ds_loss: 0.0000 | lr: 1.6230e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5197/  8460 | global iter:   5197/  8460 | loss: 0.1850 | ds_loss: 0.0000 | lr: 1.6221e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5198/  8460 | global iter:   5198/  8460 | loss: 0.1995 | ds_loss: 0.0000 | lr: 1.6212e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5199/  8460 | global iter:   5199/  8460 | loss: 0.1916 | ds_loss: 0.0000 | lr: 1.6204e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5200/  8460 | global iter:   5200/  8460 | loss: 0.1510 | ds_loss: 0.0000 | lr: 1.6195e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5200/  8460 | global iter:   5200/  8460 | loss: 0.1818 | ds_loss: 0.0000 | lr: 1.6195e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5201/  8460 | global iter:   5201/  8460 | loss: 0.0941 | ds_loss: 0.0000 | lr: 1.6186e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5202/  8460 | global iter:   5202/  8460 | loss: 0.0611 | ds_loss: 0.0000 | lr: 1.6178e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5203/  8460 | global iter:   5203/  8460 | loss: 0.2387 | ds_loss: 0.0000 | lr: 1.6169e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5204/  8460 | global iter:   5204/  8460 | loss: 0.1568 | ds_loss: 0.0000 | lr: 1.6160e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5204/  8460 | global iter:   5204/  8460 | loss: 0.1377 | ds_loss: 0.0000 | lr: 1.6160e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5205/  8460 | global iter:   5205/  8460 | loss: 0.1229 | ds_loss: 0.0000 | lr: 1.6152e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5206/  8460 | global iter:   5206/  8460 | loss: 0.2204 | ds_loss: 0.0000 | lr: 1.6143e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5207/  8460 | global iter:   5207/  8460 | loss: 0.0468 | ds_loss: 0.0000 | lr: 1.6134e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5208/  8460 | global iter:   5208/  8460 | loss: 0.0414 | ds_loss: 0.0000 | lr: 1.6126e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5208/  8460 | global iter:   5208/  8460 | loss: 0.1079 | ds_loss: 0.0000 | lr: 1.6126e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5209/  8460 | global iter:   5209/  8460 | loss: 0.1209 | ds_loss: 0.0000 | lr: 1.6117e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5210/  8460 | global iter:   5210/  8460 | loss: 0.0600 | ds_loss: 0.0000 | lr: 1.6108e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5211/  8460 | global iter:   5211/  8460 | loss: 0.1389 | ds_loss: 0.0000 | lr: 1.6100e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5212/  8460 | global iter:   5212/  8460 | loss: 0.0238 | ds_loss: 0.0000 | lr: 1.6091e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5212/  8460 | global iter:   5212/  8460 | loss: 0.0859 | ds_loss: 0.0000 | lr: 1.6091e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5213/  8460 | global iter:   5213/  8460 | loss: 0.0825 | ds_loss: 0.0000 | lr: 1.6082e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5214/  8460 | global iter:   5214/  8460 | loss: 0.4956 | ds_loss: 0.0000 | lr: 1.6074e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5215/  8460 | global iter:   5215/  8460 | loss: 0.0138 | ds_loss: 0.0000 | lr: 1.6065e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5216/  8460 | global iter:   5216/  8460 | loss: 0.1753 | ds_loss: 0.0000 | lr: 1.6056e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5216/  8460 | global iter:   5216/  8460 | loss: 0.1918 | ds_loss: 0.0000 | lr: 1.6056e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5217/  8460 | global iter:   5217/  8460 | loss: 0.0976 | ds_loss: 0.0000 | lr: 1.6048e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5218/  8460 | global iter:   5218/  8460 | loss: 0.1306 | ds_loss: 0.0000 | lr: 1.6039e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5219/  8460 | global iter:   5219/  8460 | loss: 0.1799 | ds_loss: 0.0000 | lr: 1.6030e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5220/  8460 | global iter:   5220/  8460 | loss: 0.1641 | ds_loss: 0.0000 | lr: 1.6022e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5220/  8460 | global iter:   5220/  8460 | loss: 0.1430 | ds_loss: 0.0000 | lr: 1.6022e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5221/  8460 | global iter:   5221/  8460 | loss: 0.2207 | ds_loss: 0.0000 | lr: 1.6013e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5222/  8460 | global iter:   5222/  8460 | loss: 0.0645 | ds_loss: 0.0000 | lr: 1.6004e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5223/  8460 | global iter:   5223/  8460 | loss: 0.0379 | ds_loss: 0.0000 | lr: 1.5996e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5224/  8460 | global iter:   5224/  8460 | loss: 0.0952 | ds_loss: 0.0000 | lr: 1.5987e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5224/  8460 | global iter:   5224/  8460 | loss: 0.1046 | ds_loss: 0.0000 | lr: 1.5987e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5225/  8460 | global iter:   5225/  8460 | loss: 0.1092 | ds_loss: 0.0000 | lr: 1.5978e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5226/  8460 | global iter:   5226/  8460 | loss: 0.0445 | ds_loss: 0.0000 | lr: 1.5970e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5227/  8460 | global iter:   5227/  8460 | loss: 0.1011 | ds_loss: 0.0000 | lr: 1.5961e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5228/  8460 | global iter:   5228/  8460 | loss: 0.0753 | ds_loss: 0.0000 | lr: 1.5952e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5228/  8460 | global iter:   5228/  8460 | loss: 0.0826 | ds_loss: 0.0000 | lr: 1.5952e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5229/  8460 | global iter:   5229/  8460 | loss: 0.1473 | ds_loss: 0.0000 | lr: 1.5944e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5230/  8460 | global iter:   5230/  8460 | loss: 0.0969 | ds_loss: 0.0000 | lr: 1.5935e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5231/  8460 | global iter:   5231/  8460 | loss: 0.1678 | ds_loss: 0.0000 | lr: 1.5926e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5232/  8460 | global iter:   5232/  8460 | loss: 0.1743 | ds_loss: 0.0000 | lr: 1.5918e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5232/  8460 | global iter:   5232/  8460 | loss: 0.1466 | ds_loss: 0.0000 | lr: 1.5918e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5233/  8460 | global iter:   5233/  8460 | loss: 0.1174 | ds_loss: 0.0000 | lr: 1.5909e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5234/  8460 | global iter:   5234/  8460 | loss: 0.1560 | ds_loss: 0.0000 | lr: 1.5900e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5235/  8460 | global iter:   5235/  8460 | loss: 0.2697 | ds_loss: 0.0000 | lr: 1.5892e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5236/  8460 | global iter:   5236/  8460 | loss: 0.0926 | ds_loss: 0.0000 | lr: 1.5883e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5236/  8460 | global iter:   5236/  8460 | loss: 0.1589 | ds_loss: 0.0000 | lr: 1.5883e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5237/  8460 | global iter:   5237/  8460 | loss: 0.1554 | ds_loss: 0.0000 | lr: 1.5875e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5238/  8460 | global iter:   5238/  8460 | loss: 0.1739 | ds_loss: 0.0000 | lr: 1.5866e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5239/  8460 | global iter:   5239/  8460 | loss: 0.3061 | ds_loss: 0.0000 | lr: 1.5857e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5240/  8460 | global iter:   5240/  8460 | loss: 0.0327 | ds_loss: 0.0000 | lr: 1.5849e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5240/  8460 | global iter:   5240/  8460 | loss: 0.1670 | ds_loss: 0.0000 | lr: 1.5849e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5241/  8460 | global iter:   5241/  8460 | loss: 0.0864 | ds_loss: 0.0000 | lr: 1.5840e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5242/  8460 | global iter:   5242/  8460 | loss: 0.0043 | ds_loss: 0.0000 | lr: 1.5831e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5243/  8460 | global iter:   5243/  8460 | loss: 0.1068 | ds_loss: 0.0000 | lr: 1.5823e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5244/  8460 | global iter:   5244/  8460 | loss: 0.2773 | ds_loss: 0.0000 | lr: 1.5814e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5244/  8460 | global iter:   5244/  8460 | loss: 0.1187 | ds_loss: 0.0000 | lr: 1.5814e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5245/  8460 | global iter:   5245/  8460 | loss: 0.4029 | ds_loss: 0.0000 | lr: 1.5805e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.000
train | epoch   6 | Iter:   5246/  8460 | global iter:   5246/  8460 | loss: 0.4187 | ds_loss: 0.0000 | lr: 1.5797e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5247/  8460 | global iter:   5247/  8460 | loss: 0.1154 | ds_loss: 0.0000 | lr: 1.5788e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5248/  8460 | global iter:   5248/  8460 | loss: 0.0260 | ds_loss: 0.0000 | lr: 1.5780e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5248/  8460 | global iter:   5248/  8460 | loss: 0.2408 | ds_loss: 0.0000 | lr: 1.5780e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5249/  8460 | global iter:   5249/  8460 | loss: 0.3175 | ds_loss: 0.0000 | lr: 1.5771e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5250/  8460 | global iter:   5250/  8460 | loss: 0.0176 | ds_loss: 0.0000 | lr: 1.5762e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5251/  8460 | global iter:   5251/  8460 | loss: 0.2911 | ds_loss: 0.0000 | lr: 1.5754e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5252/  8460 | global iter:   5252/  8460 | loss: 0.0884 | ds_loss: 0.0000 | lr: 1.5745e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5252/  8460 | global iter:   5252/  8460 | loss: 0.1786 | ds_loss: 0.0000 | lr: 1.5745e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5253/  8460 | global iter:   5253/  8460 | loss: 0.2335 | ds_loss: 0.0000 | lr: 1.5736e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5254/  8460 | global iter:   5254/  8460 | loss: 0.3510 | ds_loss: 0.0000 | lr: 1.5728e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5255/  8460 | global iter:   5255/  8460 | loss: 0.2743 | ds_loss: 0.0000 | lr: 1.5719e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5256/  8460 | global iter:   5256/  8460 | loss: 0.3128 | ds_loss: 0.0000 | lr: 1.5711e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5256/  8460 | global iter:   5256/  8460 | loss: 0.2929 | ds_loss: 0.0000 | lr: 1.5711e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5257/  8460 | global iter:   5257/  8460 | loss: 0.3765 | ds_loss: 0.0000 | lr: 1.5702e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5258/  8460 | global iter:   5258/  8460 | loss: 0.1117 | ds_loss: 0.0000 | lr: 1.5693e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5259/  8460 | global iter:   5259/  8460 | loss: 0.0824 | ds_loss: 0.0000 | lr: 1.5685e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5260/  8460 | global iter:   5260/  8460 | loss: 0.1993 | ds_loss: 0.0000 | lr: 1.5676e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5260/  8460 | global iter:   5260/  8460 | loss: 0.1925 | ds_loss: 0.0000 | lr: 1.5676e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5261/  8460 | global iter:   5261/  8460 | loss: 0.2379 | ds_loss: 0.0000 | lr: 1.5668e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5262/  8460 | global iter:   5262/  8460 | loss: 0.0550 | ds_loss: 0.0000 | lr: 1.5659e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5263/  8460 | global iter:   5263/  8460 | loss: 0.2475 | ds_loss: 0.0000 | lr: 1.5650e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5264/  8460 | global iter:   5264/  8460 | loss: 0.3482 | ds_loss: 0.0000 | lr: 1.5642e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5264/  8460 | global iter:   5264/  8460 | loss: 0.2221 | ds_loss: 0.0000 | lr: 1.5642e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5265/  8460 | global iter:   5265/  8460 | loss: 0.3040 | ds_loss: 0.0000 | lr: 1.5633e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5266/  8460 | global iter:   5266/  8460 | loss: 0.1522 | ds_loss: 0.0000 | lr: 1.5624e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5267/  8460 | global iter:   5267/  8460 | loss: 0.0989 | ds_loss: 0.0000 | lr: 1.5616e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5268/  8460 | global iter:   5268/  8460 | loss: 0.0850 | ds_loss: 0.0000 | lr: 1.5607e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5268/  8460 | global iter:   5268/  8460 | loss: 0.1600 | ds_loss: 0.0000 | lr: 1.5607e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5269/  8460 | global iter:   5269/  8460 | loss: 0.0818 | ds_loss: 0.0000 | lr: 1.5599e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5270/  8460 | global iter:   5270/  8460 | loss: 0.1637 | ds_loss: 0.0000 | lr: 1.5590e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5271/  8460 | global iter:   5271/  8460 | loss: 0.0435 | ds_loss: 0.0000 | lr: 1.5581e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5272/  8460 | global iter:   5272/  8460 | loss: 0.0580 | ds_loss: 0.0000 | lr: 1.5573e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5272/  8460 | global iter:   5272/  8460 | loss: 0.0868 | ds_loss: 0.0000 | lr: 1.5573e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5273/  8460 | global iter:   5273/  8460 | loss: 0.0790 | ds_loss: 0.0000 | lr: 1.5564e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5274/  8460 | global iter:   5274/  8460 | loss: 0.0345 | ds_loss: 0.0000 | lr: 1.5556e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5275/  8460 | global iter:   5275/  8460 | loss: 0.1340 | ds_loss: 0.0000 | lr: 1.5547e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5276/  8460 | global iter:   5276/  8460 | loss: 0.1626 | ds_loss: 0.0000 | lr: 1.5539e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5276/  8460 | global iter:   5276/  8460 | loss: 0.1025 | ds_loss: 0.0000 | lr: 1.5539e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5277/  8460 | global iter:   5277/  8460 | loss: 0.2579 | ds_loss: 0.0000 | lr: 1.5530e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5278/  8460 | global iter:   5278/  8460 | loss: 0.2353 | ds_loss: 0.0000 | lr: 1.5521e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5279/  8460 | global iter:   5279/  8460 | loss: 0.0741 | ds_loss: 0.0000 | lr: 1.5513e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5280/  8460 | global iter:   5280/  8460 | loss: 0.1345 | ds_loss: 0.0000 | lr: 1.5504e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5280/  8460 | global iter:   5280/  8460 | loss: 0.1754 | ds_loss: 0.0000 | lr: 1.5504e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5281/  8460 | global iter:   5281/  8460 | loss: 0.1148 | ds_loss: 0.0000 | lr: 1.5496e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5282/  8460 | global iter:   5282/  8460 | loss: 0.1246 | ds_loss: 0.0000 | lr: 1.5487e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5283/  8460 | global iter:   5283/  8460 | loss: 0.0428 | ds_loss: 0.0000 | lr: 1.5478e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5284/  8460 | global iter:   5284/  8460 | loss: 0.2421 | ds_loss: 0.0000 | lr: 1.5470e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5284/  8460 | global iter:   5284/  8460 | loss: 0.1311 | ds_loss: 0.0000 | lr: 1.5470e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5285/  8460 | global iter:   5285/  8460 | loss: 0.0287 | ds_loss: 0.0000 | lr: 1.5461e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5286/  8460 | global iter:   5286/  8460 | loss: 0.0393 | ds_loss: 0.0000 | lr: 1.5453e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5287/  8460 | global iter:   5287/  8460 | loss: 0.3582 | ds_loss: 0.0000 | lr: 1.5444e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5288/  8460 | global iter:   5288/  8460 | loss: 0.0679 | ds_loss: 0.0000 | lr: 1.5436e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5288/  8460 | global iter:   5288/  8460 | loss: 0.1235 | ds_loss: 0.0000 | lr: 1.5436e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5289/  8460 | global iter:   5289/  8460 | loss: 0.1732 | ds_loss: 0.0000 | lr: 1.5427e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5290/  8460 | global iter:   5290/  8460 | loss: 0.0614 | ds_loss: 0.0000 | lr: 1.5418e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5291/  8460 | global iter:   5291/  8460 | loss: 0.1101 | ds_loss: 0.0000 | lr: 1.5410e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5292/  8460 | global iter:   5292/  8460 | loss: 0.0889 | ds_loss: 0.0000 | lr: 1.5401e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5292/  8460 | global iter:   5292/  8460 | loss: 0.1084 | ds_loss: 0.0000 | lr: 1.5401e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5293/  8460 | global iter:   5293/  8460 | loss: 0.1565 | ds_loss: 0.0000 | lr: 1.5393e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5294/  8460 | global iter:   5294/  8460 | loss: 0.0827 | ds_loss: 0.0000 | lr: 1.5384e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5295/  8460 | global iter:   5295/  8460 | loss: 0.1141 | ds_loss: 0.0000 | lr: 1.5376e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5296/  8460 | global iter:   5296/  8460 | loss: 0.1024 | ds_loss: 0.0000 | lr: 1.5367e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5296/  8460 | global iter:   5296/  8460 | loss: 0.1139 | ds_loss: 0.0000 | lr: 1.5367e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5297/  8460 | global iter:   5297/  8460 | loss: 0.1344 | ds_loss: 0.0000 | lr: 1.5358e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5298/  8460 | global iter:   5298/  8460 | loss: 0.0742 | ds_loss: 0.0000 | lr: 1.5350e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5299/  8460 | global iter:   5299/  8460 | loss: 0.0577 | ds_loss: 0.0000 | lr: 1.5341e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5300/  8460 | global iter:   5300/  8460 | loss: 0.0257 | ds_loss: 0.0000 | lr: 1.5333e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5300/  8460 | global iter:   5300/  8460 | loss: 0.0730 | ds_loss: 0.0000 | lr: 1.5333e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5301/  8460 | global iter:   5301/  8460 | loss: 0.1221 | ds_loss: 0.0000 | lr: 1.5324e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5302/  8460 | global iter:   5302/  8460 | loss: 0.1498 | ds_loss: 0.0000 | lr: 1.5316e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5303/  8460 | global iter:   5303/  8460 | loss: 0.0342 | ds_loss: 0.0000 | lr: 1.5307e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5304/  8460 | global iter:   5304/  8460 | loss: 0.0146 | ds_loss: 0.0000 | lr: 1.5299e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5304/  8460 | global iter:   5304/  8460 | loss: 0.0802 | ds_loss: 0.0000 | lr: 1.5299e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5305/  8460 | global iter:   5305/  8460 | loss: 0.1048 | ds_loss: 0.0000 | lr: 1.5290e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5306/  8460 | global iter:   5306/  8460 | loss: 0.0271 | ds_loss: 0.0000 | lr: 1.5281e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5307/  8460 | global iter:   5307/  8460 | loss: 0.2088 | ds_loss: 0.0000 | lr: 1.5273e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5308/  8460 | global iter:   5308/  8460 | loss: 0.0872 | ds_loss: 0.0000 | lr: 1.5264e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5308/  8460 | global iter:   5308/  8460 | loss: 0.1070 | ds_loss: 0.0000 | lr: 1.5264e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5309/  8460 | global iter:   5309/  8460 | loss: 0.0385 | ds_loss: 0.0000 | lr: 1.5256e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5310/  8460 | global iter:   5310/  8460 | loss: 0.1170 | ds_loss: 0.0000 | lr: 1.5247e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5311/  8460 | global iter:   5311/  8460 | loss: 0.1332 | ds_loss: 0.0000 | lr: 1.5239e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5312/  8460 | global iter:   5312/  8460 | loss: 0.1169 | ds_loss: 0.0000 | lr: 1.5230e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5312/  8460 | global iter:   5312/  8460 | loss: 0.1014 | ds_loss: 0.0000 | lr: 1.5230e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5313/  8460 | global iter:   5313/  8460 | loss: 0.1037 | ds_loss: 0.0000 | lr: 1.5222e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5314/  8460 | global iter:   5314/  8460 | loss: 0.1300 | ds_loss: 0.0000 | lr: 1.5213e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5315/  8460 | global iter:   5315/  8460 | loss: 0.0182 | ds_loss: 0.0000 | lr: 1.5205e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5316/  8460 | global iter:   5316/  8460 | loss: 0.1115 | ds_loss: 0.0000 | lr: 1.5196e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5316/  8460 | global iter:   5316/  8460 | loss: 0.0909 | ds_loss: 0.0000 | lr: 1.5196e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5317/  8460 | global iter:   5317/  8460 | loss: 0.2228 | ds_loss: 0.0000 | lr: 1.5187e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5318/  8460 | global iter:   5318/  8460 | loss: 0.1326 | ds_loss: 0.0000 | lr: 1.5179e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5319/  8460 | global iter:   5319/  8460 | loss: 0.4560 | ds_loss: 0.0000 | lr: 1.5170e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5320/  8460 | global iter:   5320/  8460 | loss: 0.2539 | ds_loss: 0.0000 | lr: 1.5162e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5320/  8460 | global iter:   5320/  8460 | loss: 0.2663 | ds_loss: 0.0000 | lr: 1.5162e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5321/  8460 | global iter:   5321/  8460 | loss: 0.0508 | ds_loss: 0.0000 | lr: 1.5153e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5322/  8460 | global iter:   5322/  8460 | loss: 0.0761 | ds_loss: 0.0000 | lr: 1.5145e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5323/  8460 | global iter:   5323/  8460 | loss: 0.0376 | ds_loss: 0.0000 | lr: 1.5136e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5324/  8460 | global iter:   5324/  8460 | loss: 0.0351 | ds_loss: 0.0000 | lr: 1.5128e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5324/  8460 | global iter:   5324/  8460 | loss: 0.0499 | ds_loss: 0.0000 | lr: 1.5128e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5325/  8460 | global iter:   5325/  8460 | loss: 0.0191 | ds_loss: 0.0000 | lr: 1.5119e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5326/  8460 | global iter:   5326/  8460 | loss: 0.0903 | ds_loss: 0.0000 | lr: 1.5111e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5327/  8460 | global iter:   5327/  8460 | loss: 0.0686 | ds_loss: 0.0000 | lr: 1.5102e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5328/  8460 | global iter:   5328/  8460 | loss: 0.2408 | ds_loss: 0.0000 | lr: 1.5094e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5328/  8460 | global iter:   5328/  8460 | loss: 0.1047 | ds_loss: 0.0000 | lr: 1.5094e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5329/  8460 | global iter:   5329/  8460 | loss: 0.0489 | ds_loss: 0.0000 | lr: 1.5085e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5330/  8460 | global iter:   5330/  8460 | loss: 0.1565 | ds_loss: 0.0000 | lr: 1.5077e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5331/  8460 | global iter:   5331/  8460 | loss: 0.0824 | ds_loss: 0.0000 | lr: 1.5068e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5332/  8460 | global iter:   5332/  8460 | loss: 0.1087 | ds_loss: 0.0000 | lr: 1.5060e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5332/  8460 | global iter:   5332/  8460 | loss: 0.0991 | ds_loss: 0.0000 | lr: 1.5060e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5333/  8460 | global iter:   5333/  8460 | loss: 0.0555 | ds_loss: 0.0000 | lr: 1.5051e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5334/  8460 | global iter:   5334/  8460 | loss: 0.0661 | ds_loss: 0.0000 | lr: 1.5043e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5335/  8460 | global iter:   5335/  8460 | loss: 0.1227 | ds_loss: 0.0000 | lr: 1.5034e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5336/  8460 | global iter:   5336/  8460 | loss: 0.0906 | ds_loss: 0.0000 | lr: 1.5026e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5336/  8460 | global iter:   5336/  8460 | loss: 0.0837 | ds_loss: 0.0000 | lr: 1.5026e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5337/  8460 | global iter:   5337/  8460 | loss: 0.2030 | ds_loss: 0.0000 | lr: 1.5017e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5338/  8460 | global iter:   5338/  8460 | loss: 0.0668 | ds_loss: 0.0000 | lr: 1.5008e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5339/  8460 | global iter:   5339/  8460 | loss: 0.0942 | ds_loss: 0.0000 | lr: 1.5000e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5340/  8460 | global iter:   5340/  8460 | loss: 0.0883 | ds_loss: 0.0000 | lr: 1.4991e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5340/  8460 | global iter:   5340/  8460 | loss: 0.1131 | ds_loss: 0.0000 | lr: 1.4991e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5341/  8460 | global iter:   5341/  8460 | loss: 0.0844 | ds_loss: 0.0000 | lr: 1.4983e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5342/  8460 | global iter:   5342/  8460 | loss: 0.1658 | ds_loss: 0.0000 | lr: 1.4974e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5343/  8460 | global iter:   5343/  8460 | loss: 0.3762 | ds_loss: 0.0000 | lr: 1.4966e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5344/  8460 | global iter:   5344/  8460 | loss: 0.0698 | ds_loss: 0.0000 | lr: 1.4957e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5344/  8460 | global iter:   5344/  8460 | loss: 0.1740 | ds_loss: 0.0000 | lr: 1.4957e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5345/  8460 | global iter:   5345/  8460 | loss: 0.1045 | ds_loss: 0.0000 | lr: 1.4949e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5346/  8460 | global iter:   5346/  8460 | loss: 0.0588 | ds_loss: 0.0000 | lr: 1.4940e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5347/  8460 | global iter:   5347/  8460 | loss: 0.0807 | ds_loss: 0.0000 | lr: 1.4932e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5348/  8460 | global iter:   5348/  8460 | loss: 0.2776 | ds_loss: 0.0000 | lr: 1.4923e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5348/  8460 | global iter:   5348/  8460 | loss: 0.1304 | ds_loss: 0.0000 | lr: 1.4923e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5349/  8460 | global iter:   5349/  8460 | loss: 0.0366 | ds_loss: 0.0000 | lr: 1.4915e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5350/  8460 | global iter:   5350/  8460 | loss: 0.1449 | ds_loss: 0.0000 | lr: 1.4906e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5351/  8460 | global iter:   5351/  8460 | loss: 0.1744 | ds_loss: 0.0000 | lr: 1.4898e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5352/  8460 | global iter:   5352/  8460 | loss: 0.0191 | ds_loss: 0.0000 | lr: 1.4890e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5352/  8460 | global iter:   5352/  8460 | loss: 0.0938 | ds_loss: 0.0000 | lr: 1.4890e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5353/  8460 | global iter:   5353/  8460 | loss: 0.1664 | ds_loss: 0.0000 | lr: 1.4881e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5354/  8460 | global iter:   5354/  8460 | loss: 0.1343 | ds_loss: 0.0000 | lr: 1.4873e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5355/  8460 | global iter:   5355/  8460 | loss: 0.1489 | ds_loss: 0.0000 | lr: 1.4864e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5356/  8460 | global iter:   5356/  8460 | loss: 0.1469 | ds_loss: 0.0000 | lr: 1.4856e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5356/  8460 | global iter:   5356/  8460 | loss: 0.1491 | ds_loss: 0.0000 | lr: 1.4856e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5357/  8460 | global iter:   5357/  8460 | loss: 0.2283 | ds_loss: 0.0000 | lr: 1.4847e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5358/  8460 | global iter:   5358/  8460 | loss: 0.0116 | ds_loss: 0.0000 | lr: 1.4839e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5359/  8460 | global iter:   5359/  8460 | loss: 0.1360 | ds_loss: 0.0000 | lr: 1.4830e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5360/  8460 | global iter:   5360/  8460 | loss: 0.1283 | ds_loss: 0.0000 | lr: 1.4822e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5360/  8460 | global iter:   5360/  8460 | loss: 0.1261 | ds_loss: 0.0000 | lr: 1.4822e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5361/  8460 | global iter:   5361/  8460 | loss: 0.3811 | ds_loss: 0.0000 | lr: 1.4813e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5362/  8460 | global iter:   5362/  8460 | loss: 0.0519 | ds_loss: 0.0000 | lr: 1.4805e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5363/  8460 | global iter:   5363/  8460 | loss: 0.1601 | ds_loss: 0.0000 | lr: 1.4796e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5364/  8460 | global iter:   5364/  8460 | loss: 0.0649 | ds_loss: 0.0000 | lr: 1.4788e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5364/  8460 | global iter:   5364/  8460 | loss: 0.1645 | ds_loss: 0.0000 | lr: 1.4788e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5365/  8460 | global iter:   5365/  8460 | loss: 0.2336 | ds_loss: 0.0000 | lr: 1.4779e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5366/  8460 | global iter:   5366/  8460 | loss: 0.0974 | ds_loss: 0.0000 | lr: 1.4771e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5367/  8460 | global iter:   5367/  8460 | loss: 0.1136 | ds_loss: 0.0000 | lr: 1.4762e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5368/  8460 | global iter:   5368/  8460 | loss: 0.0708 | ds_loss: 0.0000 | lr: 1.4754e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5368/  8460 | global iter:   5368/  8460 | loss: 0.1288 | ds_loss: 0.0000 | lr: 1.4754e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5369/  8460 | global iter:   5369/  8460 | loss: 0.4242 | ds_loss: 0.0000 | lr: 1.4745e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5370/  8460 | global iter:   5370/  8460 | loss: 0.0236 | ds_loss: 0.0000 | lr: 1.4737e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5371/  8460 | global iter:   5371/  8460 | loss: 0.0498 | ds_loss: 0.0000 | lr: 1.4729e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5372/  8460 | global iter:   5372/  8460 | loss: 0.2130 | ds_loss: 0.0000 | lr: 1.4720e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5372/  8460 | global iter:   5372/  8460 | loss: 0.1776 | ds_loss: 0.0000 | lr: 1.4720e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5373/  8460 | global iter:   5373/  8460 | loss: 0.0313 | ds_loss: 0.0000 | lr: 1.4712e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5374/  8460 | global iter:   5374/  8460 | loss: 0.1436 | ds_loss: 0.0000 | lr: 1.4703e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5375/  8460 | global iter:   5375/  8460 | loss: 0.2190 | ds_loss: 0.0000 | lr: 1.4695e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5376/  8460 | global iter:   5376/  8460 | loss: 0.1028 | ds_loss: 0.0000 | lr: 1.4686e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5376/  8460 | global iter:   5376/  8460 | loss: 0.1242 | ds_loss: 0.0000 | lr: 1.4686e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5377/  8460 | global iter:   5377/  8460 | loss: 0.1632 | ds_loss: 0.0000 | lr: 1.4678e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5378/  8460 | global iter:   5378/  8460 | loss: 0.0736 | ds_loss: 0.0000 | lr: 1.4669e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5379/  8460 | global iter:   5379/  8460 | loss: 0.0392 | ds_loss: 0.0000 | lr: 1.4661e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5380/  8460 | global iter:   5380/  8460 | loss: 0.0934 | ds_loss: 0.0000 | lr: 1.4652e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5380/  8460 | global iter:   5380/  8460 | loss: 0.0924 | ds_loss: 0.0000 | lr: 1.4652e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5381/  8460 | global iter:   5381/  8460 | loss: 0.1902 | ds_loss: 0.0000 | lr: 1.4644e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5382/  8460 | global iter:   5382/  8460 | loss: 0.3211 | ds_loss: 0.0000 | lr: 1.4636e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5383/  8460 | global iter:   5383/  8460 | loss: 0.1055 | ds_loss: 0.0000 | lr: 1.4627e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5384/  8460 | global iter:   5384/  8460 | loss: 0.2142 | ds_loss: 0.0000 | lr: 1.4619e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5384/  8460 | global iter:   5384/  8460 | loss: 0.2078 | ds_loss: 0.0000 | lr: 1.4619e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5385/  8460 | global iter:   5385/  8460 | loss: 0.3999 | ds_loss: 0.0000 | lr: 1.4610e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5386/  8460 | global iter:   5386/  8460 | loss: 0.0330 | ds_loss: 0.0000 | lr: 1.4602e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5387/  8460 | global iter:   5387/  8460 | loss: 0.1231 | ds_loss: 0.0000 | lr: 1.4593e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5388/  8460 | global iter:   5388/  8460 | loss: 0.1131 | ds_loss: 0.0000 | lr: 1.4585e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5388/  8460 | global iter:   5388/  8460 | loss: 0.1673 | ds_loss: 0.0000 | lr: 1.4585e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5389/  8460 | global iter:   5389/  8460 | loss: 0.1535 | ds_loss: 0.0000 | lr: 1.4576e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5390/  8460 | global iter:   5390/  8460 | loss: 0.0816 | ds_loss: 0.0000 | lr: 1.4568e-04 | scale:     1.0000 | micro time: 0.430 | step time: 0.000
train | epoch   6 | Iter:   5391/  8460 | global iter:   5391/  8460 | loss: 0.1143 | ds_loss: 0.0000 | lr: 1.4560e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5392/  8460 | global iter:   5392/  8460 | loss: 0.0878 | ds_loss: 0.0000 | lr: 1.4551e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5392/  8460 | global iter:   5392/  8460 | loss: 0.1093 | ds_loss: 0.0000 | lr: 1.4551e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5393/  8460 | global iter:   5393/  8460 | loss: 0.0652 | ds_loss: 0.0000 | lr: 1.4543e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5394/  8460 | global iter:   5394/  8460 | loss: 0.0833 | ds_loss: 0.0000 | lr: 1.4534e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5395/  8460 | global iter:   5395/  8460 | loss: 0.0553 | ds_loss: 0.0000 | lr: 1.4526e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5396/  8460 | global iter:   5396/  8460 | loss: 0.0551 | ds_loss: 0.0000 | lr: 1.4517e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5396/  8460 | global iter:   5396/  8460 | loss: 0.0647 | ds_loss: 0.0000 | lr: 1.4517e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5397/  8460 | global iter:   5397/  8460 | loss: 0.0509 | ds_loss: 0.0000 | lr: 1.4509e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5398/  8460 | global iter:   5398/  8460 | loss: 0.1476 | ds_loss: 0.0000 | lr: 1.4501e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5399/  8460 | global iter:   5399/  8460 | loss: 0.0917 | ds_loss: 0.0000 | lr: 1.4492e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5400/  8460 | global iter:   5400/  8460 | loss: 0.0929 | ds_loss: 0.0000 | lr: 1.4484e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5400/  8460 | global iter:   5400/  8460 | loss: 0.0958 | ds_loss: 0.0000 | lr: 1.4484e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5401/  8460 | global iter:   5401/  8460 | loss: 0.3420 | ds_loss: 0.0000 | lr: 1.4475e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5402/  8460 | global iter:   5402/  8460 | loss: 0.0446 | ds_loss: 0.0000 | lr: 1.4467e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5403/  8460 | global iter:   5403/  8460 | loss: 0.2209 | ds_loss: 0.0000 | lr: 1.4458e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5404/  8460 | global iter:   5404/  8460 | loss: 0.0574 | ds_loss: 0.0000 | lr: 1.4450e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5404/  8460 | global iter:   5404/  8460 | loss: 0.1662 | ds_loss: 0.0000 | lr: 1.4450e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5405/  8460 | global iter:   5405/  8460 | loss: 0.0434 | ds_loss: 0.0000 | lr: 1.4442e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5406/  8460 | global iter:   5406/  8460 | loss: 0.0938 | ds_loss: 0.0000 | lr: 1.4433e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5407/  8460 | global iter:   5407/  8460 | loss: 0.1430 | ds_loss: 0.0000 | lr: 1.4425e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5408/  8460 | global iter:   5408/  8460 | loss: 0.2893 | ds_loss: 0.0000 | lr: 1.4416e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5408/  8460 | global iter:   5408/  8460 | loss: 0.1424 | ds_loss: 0.0000 | lr: 1.4416e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5409/  8460 | global iter:   5409/  8460 | loss: 0.1647 | ds_loss: 0.0000 | lr: 1.4408e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5410/  8460 | global iter:   5410/  8460 | loss: 0.0885 | ds_loss: 0.0000 | lr: 1.4400e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5411/  8460 | global iter:   5411/  8460 | loss: 0.3256 | ds_loss: 0.0000 | lr: 1.4391e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5412/  8460 | global iter:   5412/  8460 | loss: 0.0987 | ds_loss: 0.0000 | lr: 1.4383e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5412/  8460 | global iter:   5412/  8460 | loss: 0.1694 | ds_loss: 0.0000 | lr: 1.4383e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5413/  8460 | global iter:   5413/  8460 | loss: 0.1963 | ds_loss: 0.0000 | lr: 1.4374e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5414/  8460 | global iter:   5414/  8460 | loss: 0.0263 | ds_loss: 0.0000 | lr: 1.4366e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5415/  8460 | global iter:   5415/  8460 | loss: 0.1206 | ds_loss: 0.0000 | lr: 1.4358e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5416/  8460 | global iter:   5416/  8460 | loss: 0.0668 | ds_loss: 0.0000 | lr: 1.4349e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5416/  8460 | global iter:   5416/  8460 | loss: 0.1025 | ds_loss: 0.0000 | lr: 1.4349e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5417/  8460 | global iter:   5417/  8460 | loss: 0.1503 | ds_loss: 0.0000 | lr: 1.4341e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5418/  8460 | global iter:   5418/  8460 | loss: 0.0956 | ds_loss: 0.0000 | lr: 1.4332e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5419/  8460 | global iter:   5419/  8460 | loss: 0.0764 | ds_loss: 0.0000 | lr: 1.4324e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5420/  8460 | global iter:   5420/  8460 | loss: 0.1480 | ds_loss: 0.0000 | lr: 1.4316e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5420/  8460 | global iter:   5420/  8460 | loss: 0.1176 | ds_loss: 0.0000 | lr: 1.4316e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5421/  8460 | global iter:   5421/  8460 | loss: 0.0033 | ds_loss: 0.0000 | lr: 1.4307e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5422/  8460 | global iter:   5422/  8460 | loss: 0.1820 | ds_loss: 0.0000 | lr: 1.4299e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5423/  8460 | global iter:   5423/  8460 | loss: 0.0573 | ds_loss: 0.0000 | lr: 1.4290e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5424/  8460 | global iter:   5424/  8460 | loss: 0.1053 | ds_loss: 0.0000 | lr: 1.4282e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5424/  8460 | global iter:   5424/  8460 | loss: 0.0870 | ds_loss: 0.0000 | lr: 1.4282e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5425/  8460 | global iter:   5425/  8460 | loss: 0.1587 | ds_loss: 0.0000 | lr: 1.4274e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5426/  8460 | global iter:   5426/  8460 | loss: 0.2360 | ds_loss: 0.0000 | lr: 1.4265e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5427/  8460 | global iter:   5427/  8460 | loss: 0.0699 | ds_loss: 0.0000 | lr: 1.4257e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5428/  8460 | global iter:   5428/  8460 | loss: 0.0185 | ds_loss: 0.0000 | lr: 1.4249e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5428/  8460 | global iter:   5428/  8460 | loss: 0.1208 | ds_loss: 0.0000 | lr: 1.4249e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5429/  8460 | global iter:   5429/  8460 | loss: 0.4095 | ds_loss: 0.0000 | lr: 1.4240e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5430/  8460 | global iter:   5430/  8460 | loss: 0.1934 | ds_loss: 0.0000 | lr: 1.4232e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5431/  8460 | global iter:   5431/  8460 | loss: 0.1058 | ds_loss: 0.0000 | lr: 1.4223e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5432/  8460 | global iter:   5432/  8460 | loss: 0.0860 | ds_loss: 0.0000 | lr: 1.4215e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5432/  8460 | global iter:   5432/  8460 | loss: 0.1987 | ds_loss: 0.0000 | lr: 1.4215e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5433/  8460 | global iter:   5433/  8460 | loss: 0.1806 | ds_loss: 0.0000 | lr: 1.4207e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5434/  8460 | global iter:   5434/  8460 | loss: 0.0150 | ds_loss: 0.0000 | lr: 1.4198e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5435/  8460 | global iter:   5435/  8460 | loss: 0.2978 | ds_loss: 0.0000 | lr: 1.4190e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5436/  8460 | global iter:   5436/  8460 | loss: 0.2387 | ds_loss: 0.0000 | lr: 1.4182e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5436/  8460 | global iter:   5436/  8460 | loss: 0.1830 | ds_loss: 0.0000 | lr: 1.4182e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5437/  8460 | global iter:   5437/  8460 | loss: 0.0598 | ds_loss: 0.0000 | lr: 1.4173e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5438/  8460 | global iter:   5438/  8460 | loss: 0.0771 | ds_loss: 0.0000 | lr: 1.4165e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5439/  8460 | global iter:   5439/  8460 | loss: 0.0508 | ds_loss: 0.0000 | lr: 1.4156e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5440/  8460 | global iter:   5440/  8460 | loss: 0.1073 | ds_loss: 0.0000 | lr: 1.4148e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5440/  8460 | global iter:   5440/  8460 | loss: 0.0738 | ds_loss: 0.0000 | lr: 1.4148e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5441/  8460 | global iter:   5441/  8460 | loss: 0.0103 | ds_loss: 0.0000 | lr: 1.4140e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5442/  8460 | global iter:   5442/  8460 | loss: 0.1001 | ds_loss: 0.0000 | lr: 1.4131e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5443/  8460 | global iter:   5443/  8460 | loss: 0.2526 | ds_loss: 0.0000 | lr: 1.4123e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5444/  8460 | global iter:   5444/  8460 | loss: 0.2077 | ds_loss: 0.0000 | lr: 1.4115e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5444/  8460 | global iter:   5444/  8460 | loss: 0.1427 | ds_loss: 0.0000 | lr: 1.4115e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5445/  8460 | global iter:   5445/  8460 | loss: 0.1766 | ds_loss: 0.0000 | lr: 1.4106e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5446/  8460 | global iter:   5446/  8460 | loss: 0.1762 | ds_loss: 0.0000 | lr: 1.4098e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5447/  8460 | global iter:   5447/  8460 | loss: 0.1533 | ds_loss: 0.0000 | lr: 1.4090e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5448/  8460 | global iter:   5448/  8460 | loss: 0.1784 | ds_loss: 0.0000 | lr: 1.4081e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5448/  8460 | global iter:   5448/  8460 | loss: 0.1712 | ds_loss: 0.0000 | lr: 1.4081e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5449/  8460 | global iter:   5449/  8460 | loss: 0.2207 | ds_loss: 0.0000 | lr: 1.4073e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5450/  8460 | global iter:   5450/  8460 | loss: 0.1915 | ds_loss: 0.0000 | lr: 1.4065e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5451/  8460 | global iter:   5451/  8460 | loss: 0.0571 | ds_loss: 0.0000 | lr: 1.4056e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5452/  8460 | global iter:   5452/  8460 | loss: 0.0739 | ds_loss: 0.0000 | lr: 1.4048e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5452/  8460 | global iter:   5452/  8460 | loss: 0.1358 | ds_loss: 0.0000 | lr: 1.4048e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5453/  8460 | global iter:   5453/  8460 | loss: 0.1478 | ds_loss: 0.0000 | lr: 1.4040e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5454/  8460 | global iter:   5454/  8460 | loss: 0.1542 | ds_loss: 0.0000 | lr: 1.4031e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5455/  8460 | global iter:   5455/  8460 | loss: 0.0588 | ds_loss: 0.0000 | lr: 1.4023e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5456/  8460 | global iter:   5456/  8460 | loss: 0.1092 | ds_loss: 0.0000 | lr: 1.4015e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5456/  8460 | global iter:   5456/  8460 | loss: 0.1175 | ds_loss: 0.0000 | lr: 1.4015e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5457/  8460 | global iter:   5457/  8460 | loss: 0.0458 | ds_loss: 0.0000 | lr: 1.4006e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5458/  8460 | global iter:   5458/  8460 | loss: 0.2228 | ds_loss: 0.0000 | lr: 1.3998e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5459/  8460 | global iter:   5459/  8460 | loss: 0.0971 | ds_loss: 0.0000 | lr: 1.3990e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5460/  8460 | global iter:   5460/  8460 | loss: 0.1876 | ds_loss: 0.0000 | lr: 1.3981e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5460/  8460 | global iter:   5460/  8460 | loss: 0.1383 | ds_loss: 0.0000 | lr: 1.3981e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5461/  8460 | global iter:   5461/  8460 | loss: 0.0579 | ds_loss: 0.0000 | lr: 1.3973e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5462/  8460 | global iter:   5462/  8460 | loss: 0.1935 | ds_loss: 0.0000 | lr: 1.3965e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5463/  8460 | global iter:   5463/  8460 | loss: 0.1098 | ds_loss: 0.0000 | lr: 1.3956e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5464/  8460 | global iter:   5464/  8460 | loss: 0.1103 | ds_loss: 0.0000 | lr: 1.3948e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5464/  8460 | global iter:   5464/  8460 | loss: 0.1179 | ds_loss: 0.0000 | lr: 1.3948e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5465/  8460 | global iter:   5465/  8460 | loss: 0.1321 | ds_loss: 0.0000 | lr: 1.3940e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5466/  8460 | global iter:   5466/  8460 | loss: 0.0924 | ds_loss: 0.0000 | lr: 1.3931e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5467/  8460 | global iter:   5467/  8460 | loss: 0.0276 | ds_loss: 0.0000 | lr: 1.3923e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5468/  8460 | global iter:   5468/  8460 | loss: 0.2898 | ds_loss: 0.0000 | lr: 1.3915e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5468/  8460 | global iter:   5468/  8460 | loss: 0.1355 | ds_loss: 0.0000 | lr: 1.3915e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5469/  8460 | global iter:   5469/  8460 | loss: 0.5051 | ds_loss: 0.0000 | lr: 1.3906e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5470/  8460 | global iter:   5470/  8460 | loss: 0.0666 | ds_loss: 0.0000 | lr: 1.3898e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5471/  8460 | global iter:   5471/  8460 | loss: 0.0466 | ds_loss: 0.0000 | lr: 1.3890e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5472/  8460 | global iter:   5472/  8460 | loss: 0.2919 | ds_loss: 0.0000 | lr: 1.3881e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5472/  8460 | global iter:   5472/  8460 | loss: 0.2276 | ds_loss: 0.0000 | lr: 1.3881e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5473/  8460 | global iter:   5473/  8460 | loss: 0.0256 | ds_loss: 0.0000 | lr: 1.3873e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5474/  8460 | global iter:   5474/  8460 | loss: 0.0957 | ds_loss: 0.0000 | lr: 1.3865e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5475/  8460 | global iter:   5475/  8460 | loss: 0.0839 | ds_loss: 0.0000 | lr: 1.3856e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5476/  8460 | global iter:   5476/  8460 | loss: 0.0157 | ds_loss: 0.0000 | lr: 1.3848e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5476/  8460 | global iter:   5476/  8460 | loss: 0.0552 | ds_loss: 0.0000 | lr: 1.3848e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5477/  8460 | global iter:   5477/  8460 | loss: 0.2411 | ds_loss: 0.0000 | lr: 1.3840e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5478/  8460 | global iter:   5478/  8460 | loss: 0.0683 | ds_loss: 0.0000 | lr: 1.3832e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5479/  8460 | global iter:   5479/  8460 | loss: 0.1996 | ds_loss: 0.0000 | lr: 1.3823e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5480/  8460 | global iter:   5480/  8460 | loss: 0.1855 | ds_loss: 0.0000 | lr: 1.3815e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5480/  8460 | global iter:   5480/  8460 | loss: 0.1736 | ds_loss: 0.0000 | lr: 1.3815e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5481/  8460 | global iter:   5481/  8460 | loss: 0.1222 | ds_loss: 0.0000 | lr: 1.3807e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5482/  8460 | global iter:   5482/  8460 | loss: 0.1267 | ds_loss: 0.0000 | lr: 1.3798e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5483/  8460 | global iter:   5483/  8460 | loss: 0.2805 | ds_loss: 0.0000 | lr: 1.3790e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5484/  8460 | global iter:   5484/  8460 | loss: 0.2754 | ds_loss: 0.0000 | lr: 1.3782e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5484/  8460 | global iter:   5484/  8460 | loss: 0.2012 | ds_loss: 0.0000 | lr: 1.3782e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5485/  8460 | global iter:   5485/  8460 | loss: 0.2064 | ds_loss: 0.0000 | lr: 1.3773e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5486/  8460 | global iter:   5486/  8460 | loss: 0.1278 | ds_loss: 0.0000 | lr: 1.3765e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5487/  8460 | global iter:   5487/  8460 | loss: 0.0360 | ds_loss: 0.0000 | lr: 1.3757e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5488/  8460 | global iter:   5488/  8460 | loss: 0.0967 | ds_loss: 0.0000 | lr: 1.3749e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5488/  8460 | global iter:   5488/  8460 | loss: 0.1167 | ds_loss: 0.0000 | lr: 1.3749e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5489/  8460 | global iter:   5489/  8460 | loss: 0.1845 | ds_loss: 0.0000 | lr: 1.3740e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5490/  8460 | global iter:   5490/  8460 | loss: 0.2053 | ds_loss: 0.0000 | lr: 1.3732e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5491/  8460 | global iter:   5491/  8460 | loss: 0.0353 | ds_loss: 0.0000 | lr: 1.3724e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5492/  8460 | global iter:   5492/  8460 | loss: 0.0450 | ds_loss: 0.0000 | lr: 1.3715e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5492/  8460 | global iter:   5492/  8460 | loss: 0.1175 | ds_loss: 0.0000 | lr: 1.3715e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5493/  8460 | global iter:   5493/  8460 | loss: 0.3470 | ds_loss: 0.0000 | lr: 1.3707e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5494/  8460 | global iter:   5494/  8460 | loss: 0.0874 | ds_loss: 0.0000 | lr: 1.3699e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5495/  8460 | global iter:   5495/  8460 | loss: 0.2365 | ds_loss: 0.0000 | lr: 1.3691e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5496/  8460 | global iter:   5496/  8460 | loss: 0.1382 | ds_loss: 0.0000 | lr: 1.3682e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5496/  8460 | global iter:   5496/  8460 | loss: 0.2023 | ds_loss: 0.0000 | lr: 1.3682e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5497/  8460 | global iter:   5497/  8460 | loss: 0.1355 | ds_loss: 0.0000 | lr: 1.3674e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5498/  8460 | global iter:   5498/  8460 | loss: 0.0962 | ds_loss: 0.0000 | lr: 1.3666e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5499/  8460 | global iter:   5499/  8460 | loss: 0.2003 | ds_loss: 0.0000 | lr: 1.3658e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5500/  8460 | global iter:   5500/  8460 | loss: 0.0930 | ds_loss: 0.0000 | lr: 1.3649e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5500/  8460 | global iter:   5500/  8460 | loss: 0.1313 | ds_loss: 0.0000 | lr: 1.3649e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5501/  8460 | global iter:   5501/  8460 | loss: 0.2100 | ds_loss: 0.0000 | lr: 1.3641e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5502/  8460 | global iter:   5502/  8460 | loss: 0.0254 | ds_loss: 0.0000 | lr: 1.3633e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5503/  8460 | global iter:   5503/  8460 | loss: 0.1034 | ds_loss: 0.0000 | lr: 1.3624e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5504/  8460 | global iter:   5504/  8460 | loss: 0.0376 | ds_loss: 0.0000 | lr: 1.3616e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5504/  8460 | global iter:   5504/  8460 | loss: 0.0941 | ds_loss: 0.0000 | lr: 1.3616e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5505/  8460 | global iter:   5505/  8460 | loss: 0.0476 | ds_loss: 0.0000 | lr: 1.3608e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5506/  8460 | global iter:   5506/  8460 | loss: 0.0286 | ds_loss: 0.0000 | lr: 1.3600e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5507/  8460 | global iter:   5507/  8460 | loss: 0.0768 | ds_loss: 0.0000 | lr: 1.3591e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5508/  8460 | global iter:   5508/  8460 | loss: 0.1890 | ds_loss: 0.0000 | lr: 1.3583e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5508/  8460 | global iter:   5508/  8460 | loss: 0.0855 | ds_loss: 0.0000 | lr: 1.3583e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5509/  8460 | global iter:   5509/  8460 | loss: 0.0831 | ds_loss: 0.0000 | lr: 1.3575e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5510/  8460 | global iter:   5510/  8460 | loss: 0.0755 | ds_loss: 0.0000 | lr: 1.3567e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5511/  8460 | global iter:   5511/  8460 | loss: 0.0700 | ds_loss: 0.0000 | lr: 1.3558e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5512/  8460 | global iter:   5512/  8460 | loss: 0.1282 | ds_loss: 0.0000 | lr: 1.3550e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5512/  8460 | global iter:   5512/  8460 | loss: 0.0892 | ds_loss: 0.0000 | lr: 1.3550e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5513/  8460 | global iter:   5513/  8460 | loss: 0.6422 | ds_loss: 0.0000 | lr: 1.3542e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5514/  8460 | global iter:   5514/  8460 | loss: 0.0522 | ds_loss: 0.0000 | lr: 1.3534e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5515/  8460 | global iter:   5515/  8460 | loss: 0.0630 | ds_loss: 0.0000 | lr: 1.3525e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5516/  8460 | global iter:   5516/  8460 | loss: 0.1150 | ds_loss: 0.0000 | lr: 1.3517e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5516/  8460 | global iter:   5516/  8460 | loss: 0.2181 | ds_loss: 0.0000 | lr: 1.3517e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5517/  8460 | global iter:   5517/  8460 | loss: 0.0120 | ds_loss: 0.0000 | lr: 1.3509e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5518/  8460 | global iter:   5518/  8460 | loss: 0.0827 | ds_loss: 0.0000 | lr: 1.3501e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5519/  8460 | global iter:   5519/  8460 | loss: 0.1161 | ds_loss: 0.0000 | lr: 1.3492e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5520/  8460 | global iter:   5520/  8460 | loss: 0.0731 | ds_loss: 0.0000 | lr: 1.3484e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5520/  8460 | global iter:   5520/  8460 | loss: 0.0710 | ds_loss: 0.0000 | lr: 1.3484e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5521/  8460 | global iter:   5521/  8460 | loss: 0.0852 | ds_loss: 0.0000 | lr: 1.3476e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5522/  8460 | global iter:   5522/  8460 | loss: 0.0338 | ds_loss: 0.0000 | lr: 1.3468e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5523/  8460 | global iter:   5523/  8460 | loss: 0.1751 | ds_loss: 0.0000 | lr: 1.3459e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5524/  8460 | global iter:   5524/  8460 | loss: 0.2937 | ds_loss: 0.0000 | lr: 1.3451e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5524/  8460 | global iter:   5524/  8460 | loss: 0.1470 | ds_loss: 0.0000 | lr: 1.3451e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5525/  8460 | global iter:   5525/  8460 | loss: 0.0525 | ds_loss: 0.0000 | lr: 1.3443e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5526/  8460 | global iter:   5526/  8460 | loss: 0.2773 | ds_loss: 0.0000 | lr: 1.3435e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5527/  8460 | global iter:   5527/  8460 | loss: 0.2074 | ds_loss: 0.0000 | lr: 1.3427e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5528/  8460 | global iter:   5528/  8460 | loss: 0.0212 | ds_loss: 0.0000 | lr: 1.3418e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5528/  8460 | global iter:   5528/  8460 | loss: 0.1396 | ds_loss: 0.0000 | lr: 1.3418e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5529/  8460 | global iter:   5529/  8460 | loss: 0.0182 | ds_loss: 0.0000 | lr: 1.3410e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5530/  8460 | global iter:   5530/  8460 | loss: 0.2699 | ds_loss: 0.0000 | lr: 1.3402e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5531/  8460 | global iter:   5531/  8460 | loss: 0.0668 | ds_loss: 0.0000 | lr: 1.3394e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5532/  8460 | global iter:   5532/  8460 | loss: 0.1013 | ds_loss: 0.0000 | lr: 1.3385e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5532/  8460 | global iter:   5532/  8460 | loss: 0.1141 | ds_loss: 0.0000 | lr: 1.3385e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5533/  8460 | global iter:   5533/  8460 | loss: 0.2071 | ds_loss: 0.0000 | lr: 1.3377e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5534/  8460 | global iter:   5534/  8460 | loss: 0.1128 | ds_loss: 0.0000 | lr: 1.3369e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5535/  8460 | global iter:   5535/  8460 | loss: 0.0441 | ds_loss: 0.0000 | lr: 1.3361e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5536/  8460 | global iter:   5536/  8460 | loss: 0.0862 | ds_loss: 0.0000 | lr: 1.3353e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5536/  8460 | global iter:   5536/  8460 | loss: 0.1126 | ds_loss: 0.0000 | lr: 1.3353e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5537/  8460 | global iter:   5537/  8460 | loss: 0.1673 | ds_loss: 0.0000 | lr: 1.3344e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5538/  8460 | global iter:   5538/  8460 | loss: 0.1929 | ds_loss: 0.0000 | lr: 1.3336e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5539/  8460 | global iter:   5539/  8460 | loss: 0.0378 | ds_loss: 0.0000 | lr: 1.3328e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5540/  8460 | global iter:   5540/  8460 | loss: 0.1461 | ds_loss: 0.0000 | lr: 1.3320e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5540/  8460 | global iter:   5540/  8460 | loss: 0.1360 | ds_loss: 0.0000 | lr: 1.3320e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5541/  8460 | global iter:   5541/  8460 | loss: 0.0785 | ds_loss: 0.0000 | lr: 1.3312e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5542/  8460 | global iter:   5542/  8460 | loss: 0.1243 | ds_loss: 0.0000 | lr: 1.3303e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5543/  8460 | global iter:   5543/  8460 | loss: 0.2277 | ds_loss: 0.0000 | lr: 1.3295e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5544/  8460 | global iter:   5544/  8460 | loss: 0.0789 | ds_loss: 0.0000 | lr: 1.3287e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5544/  8460 | global iter:   5544/  8460 | loss: 0.1273 | ds_loss: 0.0000 | lr: 1.3287e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5545/  8460 | global iter:   5545/  8460 | loss: 0.0454 | ds_loss: 0.0000 | lr: 1.3279e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5546/  8460 | global iter:   5546/  8460 | loss: 0.1476 | ds_loss: 0.0000 | lr: 1.3271e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5547/  8460 | global iter:   5547/  8460 | loss: 0.0613 | ds_loss: 0.0000 | lr: 1.3262e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5548/  8460 | global iter:   5548/  8460 | loss: 0.2393 | ds_loss: 0.0000 | lr: 1.3254e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5548/  8460 | global iter:   5548/  8460 | loss: 0.1234 | ds_loss: 0.0000 | lr: 1.3254e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5549/  8460 | global iter:   5549/  8460 | loss: 0.0661 | ds_loss: 0.0000 | lr: 1.3246e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5550/  8460 | global iter:   5550/  8460 | loss: 0.0705 | ds_loss: 0.0000 | lr: 1.3238e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5551/  8460 | global iter:   5551/  8460 | loss: 0.1387 | ds_loss: 0.0000 | lr: 1.3230e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5552/  8460 | global iter:   5552/  8460 | loss: 0.1984 | ds_loss: 0.0000 | lr: 1.3221e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5552/  8460 | global iter:   5552/  8460 | loss: 0.1184 | ds_loss: 0.0000 | lr: 1.3221e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5553/  8460 | global iter:   5553/  8460 | loss: 0.0498 | ds_loss: 0.0000 | lr: 1.3213e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5554/  8460 | global iter:   5554/  8460 | loss: 0.0180 | ds_loss: 0.0000 | lr: 1.3205e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5555/  8460 | global iter:   5555/  8460 | loss: 0.1879 | ds_loss: 0.0000 | lr: 1.3197e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5556/  8460 | global iter:   5556/  8460 | loss: 0.0742 | ds_loss: 0.0000 | lr: 1.3189e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5556/  8460 | global iter:   5556/  8460 | loss: 0.0825 | ds_loss: 0.0000 | lr: 1.3189e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5557/  8460 | global iter:   5557/  8460 | loss: 0.1043 | ds_loss: 0.0000 | lr: 1.3181e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5558/  8460 | global iter:   5558/  8460 | loss: 0.2048 | ds_loss: 0.0000 | lr: 1.3172e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5559/  8460 | global iter:   5559/  8460 | loss: 0.0791 | ds_loss: 0.0000 | lr: 1.3164e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5560/  8460 | global iter:   5560/  8460 | loss: 0.1325 | ds_loss: 0.0000 | lr: 1.3156e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5560/  8460 | global iter:   5560/  8460 | loss: 0.1302 | ds_loss: 0.0000 | lr: 1.3156e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5561/  8460 | global iter:   5561/  8460 | loss: 0.3465 | ds_loss: 0.0000 | lr: 1.3148e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5562/  8460 | global iter:   5562/  8460 | loss: 0.0264 | ds_loss: 0.0000 | lr: 1.3140e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5563/  8460 | global iter:   5563/  8460 | loss: 0.0498 | ds_loss: 0.0000 | lr: 1.3131e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5564/  8460 | global iter:   5564/  8460 | loss: 0.0429 | ds_loss: 0.0000 | lr: 1.3123e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5564/  8460 | global iter:   5564/  8460 | loss: 0.1164 | ds_loss: 0.0000 | lr: 1.3123e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5565/  8460 | global iter:   5565/  8460 | loss: 0.2502 | ds_loss: 0.0000 | lr: 1.3115e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5566/  8460 | global iter:   5566/  8460 | loss: 0.0719 | ds_loss: 0.0000 | lr: 1.3107e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5567/  8460 | global iter:   5567/  8460 | loss: 0.0622 | ds_loss: 0.0000 | lr: 1.3099e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5568/  8460 | global iter:   5568/  8460 | loss: 0.1145 | ds_loss: 0.0000 | lr: 1.3091e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5568/  8460 | global iter:   5568/  8460 | loss: 0.1247 | ds_loss: 0.0000 | lr: 1.3091e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5569/  8460 | global iter:   5569/  8460 | loss: 0.0366 | ds_loss: 0.0000 | lr: 1.3082e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5570/  8460 | global iter:   5570/  8460 | loss: 0.0446 | ds_loss: 0.0000 | lr: 1.3074e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5571/  8460 | global iter:   5571/  8460 | loss: 0.1033 | ds_loss: 0.0000 | lr: 1.3066e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5572/  8460 | global iter:   5572/  8460 | loss: 0.0181 | ds_loss: 0.0000 | lr: 1.3058e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5572/  8460 | global iter:   5572/  8460 | loss: 0.0506 | ds_loss: 0.0000 | lr: 1.3058e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5573/  8460 | global iter:   5573/  8460 | loss: 0.0326 | ds_loss: 0.0000 | lr: 1.3050e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5574/  8460 | global iter:   5574/  8460 | loss: 0.1670 | ds_loss: 0.0000 | lr: 1.3042e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5575/  8460 | global iter:   5575/  8460 | loss: 0.0659 | ds_loss: 0.0000 | lr: 1.3034e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5576/  8460 | global iter:   5576/  8460 | loss: 0.0463 | ds_loss: 0.0000 | lr: 1.3025e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5576/  8460 | global iter:   5576/  8460 | loss: 0.0779 | ds_loss: 0.0000 | lr: 1.3025e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5577/  8460 | global iter:   5577/  8460 | loss: 0.0818 | ds_loss: 0.0000 | lr: 1.3017e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5578/  8460 | global iter:   5578/  8460 | loss: 0.2692 | ds_loss: 0.0000 | lr: 1.3009e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5579/  8460 | global iter:   5579/  8460 | loss: 0.1766 | ds_loss: 0.0000 | lr: 1.3001e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5580/  8460 | global iter:   5580/  8460 | loss: 0.1414 | ds_loss: 0.0000 | lr: 1.2993e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5580/  8460 | global iter:   5580/  8460 | loss: 0.1673 | ds_loss: 0.0000 | lr: 1.2993e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5581/  8460 | global iter:   5581/  8460 | loss: 0.2178 | ds_loss: 0.0000 | lr: 1.2985e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5582/  8460 | global iter:   5582/  8460 | loss: 0.0682 | ds_loss: 0.0000 | lr: 1.2977e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5583/  8460 | global iter:   5583/  8460 | loss: 0.1800 | ds_loss: 0.0000 | lr: 1.2968e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5584/  8460 | global iter:   5584/  8460 | loss: 0.2447 | ds_loss: 0.0000 | lr: 1.2960e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5584/  8460 | global iter:   5584/  8460 | loss: 0.1777 | ds_loss: 0.0000 | lr: 1.2960e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5585/  8460 | global iter:   5585/  8460 | loss: 0.4227 | ds_loss: 0.0000 | lr: 1.2952e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5586/  8460 | global iter:   5586/  8460 | loss: 0.0887 | ds_loss: 0.0000 | lr: 1.2944e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5587/  8460 | global iter:   5587/  8460 | loss: 0.2582 | ds_loss: 0.0000 | lr: 1.2936e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5588/  8460 | global iter:   5588/  8460 | loss: 0.0390 | ds_loss: 0.0000 | lr: 1.2928e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5588/  8460 | global iter:   5588/  8460 | loss: 0.2021 | ds_loss: 0.0000 | lr: 1.2928e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5589/  8460 | global iter:   5589/  8460 | loss: 0.4303 | ds_loss: 0.0000 | lr: 1.2920e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5590/  8460 | global iter:   5590/  8460 | loss: 0.0816 | ds_loss: 0.0000 | lr: 1.2912e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5591/  8460 | global iter:   5591/  8460 | loss: 0.1156 | ds_loss: 0.0000 | lr: 1.2903e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5592/  8460 | global iter:   5592/  8460 | loss: 0.1215 | ds_loss: 0.0000 | lr: 1.2895e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5592/  8460 | global iter:   5592/  8460 | loss: 0.1873 | ds_loss: 0.0000 | lr: 1.2895e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5593/  8460 | global iter:   5593/  8460 | loss: 0.0635 | ds_loss: 0.0000 | lr: 1.2887e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5594/  8460 | global iter:   5594/  8460 | loss: 0.2249 | ds_loss: 0.0000 | lr: 1.2879e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5595/  8460 | global iter:   5595/  8460 | loss: 0.0224 | ds_loss: 0.0000 | lr: 1.2871e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5596/  8460 | global iter:   5596/  8460 | loss: 0.0647 | ds_loss: 0.0000 | lr: 1.2863e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5596/  8460 | global iter:   5596/  8460 | loss: 0.0939 | ds_loss: 0.0000 | lr: 1.2863e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5597/  8460 | global iter:   5597/  8460 | loss: 0.0671 | ds_loss: 0.0000 | lr: 1.2855e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5598/  8460 | global iter:   5598/  8460 | loss: 0.0432 | ds_loss: 0.0000 | lr: 1.2847e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5599/  8460 | global iter:   5599/  8460 | loss: 0.1498 | ds_loss: 0.0000 | lr: 1.2839e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5600/  8460 | global iter:   5600/  8460 | loss: 0.0811 | ds_loss: 0.0000 | lr: 1.2830e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5600/  8460 | global iter:   5600/  8460 | loss: 0.0853 | ds_loss: 0.0000 | lr: 1.2830e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5601/  8460 | global iter:   5601/  8460 | loss: 0.1439 | ds_loss: 0.0000 | lr: 1.2822e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5602/  8460 | global iter:   5602/  8460 | loss: 0.2756 | ds_loss: 0.0000 | lr: 1.2814e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5603/  8460 | global iter:   5603/  8460 | loss: 0.0915 | ds_loss: 0.0000 | lr: 1.2806e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5604/  8460 | global iter:   5604/  8460 | loss: 0.3072 | ds_loss: 0.0000 | lr: 1.2798e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5604/  8460 | global iter:   5604/  8460 | loss: 0.2046 | ds_loss: 0.0000 | lr: 1.2798e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5605/  8460 | global iter:   5605/  8460 | loss: 0.3393 | ds_loss: 0.0000 | lr: 1.2790e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5606/  8460 | global iter:   5606/  8460 | loss: 0.2407 | ds_loss: 0.0000 | lr: 1.2782e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5607/  8460 | global iter:   5607/  8460 | loss: 0.2058 | ds_loss: 0.0000 | lr: 1.2774e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5608/  8460 | global iter:   5608/  8460 | loss: 0.2732 | ds_loss: 0.0000 | lr: 1.2766e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5608/  8460 | global iter:   5608/  8460 | loss: 0.2648 | ds_loss: 0.0000 | lr: 1.2766e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5609/  8460 | global iter:   5609/  8460 | loss: 0.1471 | ds_loss: 0.0000 | lr: 1.2758e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5610/  8460 | global iter:   5610/  8460 | loss: 0.2023 | ds_loss: 0.0000 | lr: 1.2749e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5611/  8460 | global iter:   5611/  8460 | loss: 0.0705 | ds_loss: 0.0000 | lr: 1.2741e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5612/  8460 | global iter:   5612/  8460 | loss: 0.0731 | ds_loss: 0.0000 | lr: 1.2733e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5612/  8460 | global iter:   5612/  8460 | loss: 0.1232 | ds_loss: 0.0000 | lr: 1.2733e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5613/  8460 | global iter:   5613/  8460 | loss: 0.4518 | ds_loss: 0.0000 | lr: 1.2725e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5614/  8460 | global iter:   5614/  8460 | loss: 0.1772 | ds_loss: 0.0000 | lr: 1.2717e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5615/  8460 | global iter:   5615/  8460 | loss: 0.3371 | ds_loss: 0.0000 | lr: 1.2709e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5616/  8460 | global iter:   5616/  8460 | loss: 0.0799 | ds_loss: 0.0000 | lr: 1.2701e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5616/  8460 | global iter:   5616/  8460 | loss: 0.2615 | ds_loss: 0.0000 | lr: 1.2701e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5617/  8460 | global iter:   5617/  8460 | loss: 0.1116 | ds_loss: 0.0000 | lr: 1.2693e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5618/  8460 | global iter:   5618/  8460 | loss: 0.0800 | ds_loss: 0.0000 | lr: 1.2685e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5619/  8460 | global iter:   5619/  8460 | loss: 0.1760 | ds_loss: 0.0000 | lr: 1.2677e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5620/  8460 | global iter:   5620/  8460 | loss: 0.4770 | ds_loss: 0.0000 | lr: 1.2669e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5620/  8460 | global iter:   5620/  8460 | loss: 0.2111 | ds_loss: 0.0000 | lr: 1.2669e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5621/  8460 | global iter:   5621/  8460 | loss: 0.1584 | ds_loss: 0.0000 | lr: 1.2661e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5622/  8460 | global iter:   5622/  8460 | loss: 0.0360 | ds_loss: 0.0000 | lr: 1.2652e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5623/  8460 | global iter:   5623/  8460 | loss: 0.0750 | ds_loss: 0.0000 | lr: 1.2644e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5624/  8460 | global iter:   5624/  8460 | loss: 0.1255 | ds_loss: 0.0000 | lr: 1.2636e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5624/  8460 | global iter:   5624/  8460 | loss: 0.0987 | ds_loss: 0.0000 | lr: 1.2636e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5625/  8460 | global iter:   5625/  8460 | loss: 0.0650 | ds_loss: 0.0000 | lr: 1.2628e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5626/  8460 | global iter:   5626/  8460 | loss: 0.0209 | ds_loss: 0.0000 | lr: 1.2620e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5627/  8460 | global iter:   5627/  8460 | loss: 0.2939 | ds_loss: 0.0000 | lr: 1.2612e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5628/  8460 | global iter:   5628/  8460 | loss: 0.0316 | ds_loss: 0.0000 | lr: 1.2604e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5628/  8460 | global iter:   5628/  8460 | loss: 0.1028 | ds_loss: 0.0000 | lr: 1.2604e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5629/  8460 | global iter:   5629/  8460 | loss: 0.1645 | ds_loss: 0.0000 | lr: 1.2596e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5630/  8460 | global iter:   5630/  8460 | loss: 0.0898 | ds_loss: 0.0000 | lr: 1.2588e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5631/  8460 | global iter:   5631/  8460 | loss: 0.1274 | ds_loss: 0.0000 | lr: 1.2580e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5632/  8460 | global iter:   5632/  8460 | loss: 0.3051 | ds_loss: 0.0000 | lr: 1.2572e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5632/  8460 | global iter:   5632/  8460 | loss: 0.1717 | ds_loss: 0.0000 | lr: 1.2572e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5633/  8460 | global iter:   5633/  8460 | loss: 0.0499 | ds_loss: 0.0000 | lr: 1.2564e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5634/  8460 | global iter:   5634/  8460 | loss: 0.1004 | ds_loss: 0.0000 | lr: 1.2556e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5635/  8460 | global iter:   5635/  8460 | loss: 0.3323 | ds_loss: 0.0000 | lr: 1.2548e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5636/  8460 | global iter:   5636/  8460 | loss: 0.3337 | ds_loss: 0.0000 | lr: 1.2540e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5636/  8460 | global iter:   5636/  8460 | loss: 0.2040 | ds_loss: 0.0000 | lr: 1.2540e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5637/  8460 | global iter:   5637/  8460 | loss: 0.2818 | ds_loss: 0.0000 | lr: 1.2532e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5638/  8460 | global iter:   5638/  8460 | loss: 0.3715 | ds_loss: 0.0000 | lr: 1.2524e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5639/  8460 | global iter:   5639/  8460 | loss: 0.0576 | ds_loss: 0.0000 | lr: 1.2516e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5640/  8460 | global iter:   5640/  8460 | loss: 0.1090 | ds_loss: 0.0000 | lr: 1.2507e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5640/  8460 | global iter:   5640/  8460 | loss: 0.2050 | ds_loss: 0.0000 | lr: 1.2507e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5641/  8460 | global iter:   5641/  8460 | loss: 0.1190 | ds_loss: 0.0000 | lr: 1.2499e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5642/  8460 | global iter:   5642/  8460 | loss: 0.0903 | ds_loss: 0.0000 | lr: 1.2491e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5643/  8460 | global iter:   5643/  8460 | loss: 0.1359 | ds_loss: 0.0000 | lr: 1.2483e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5644/  8460 | global iter:   5644/  8460 | loss: 0.2134 | ds_loss: 0.0000 | lr: 1.2475e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5644/  8460 | global iter:   5644/  8460 | loss: 0.1397 | ds_loss: 0.0000 | lr: 1.2475e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5645/  8460 | global iter:   5645/  8460 | loss: 0.3055 | ds_loss: 0.0000 | lr: 1.2467e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5646/  8460 | global iter:   5646/  8460 | loss: 0.0078 | ds_loss: 0.0000 | lr: 1.2459e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5647/  8460 | global iter:   5647/  8460 | loss: 0.1771 | ds_loss: 0.0000 | lr: 1.2451e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5648/  8460 | global iter:   5648/  8460 | loss: 0.2008 | ds_loss: 0.0000 | lr: 1.2443e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5648/  8460 | global iter:   5648/  8460 | loss: 0.1728 | ds_loss: 0.0000 | lr: 1.2443e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5649/  8460 | global iter:   5649/  8460 | loss: 0.0944 | ds_loss: 0.0000 | lr: 1.2435e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5650/  8460 | global iter:   5650/  8460 | loss: 0.0534 | ds_loss: 0.0000 | lr: 1.2427e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5651/  8460 | global iter:   5651/  8460 | loss: 0.0538 | ds_loss: 0.0000 | lr: 1.2419e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5652/  8460 | global iter:   5652/  8460 | loss: 0.0715 | ds_loss: 0.0000 | lr: 1.2411e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5652/  8460 | global iter:   5652/  8460 | loss: 0.0683 | ds_loss: 0.0000 | lr: 1.2411e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5653/  8460 | global iter:   5653/  8460 | loss: 0.1843 | ds_loss: 0.0000 | lr: 1.2403e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5654/  8460 | global iter:   5654/  8460 | loss: 0.4107 | ds_loss: 0.0000 | lr: 1.2395e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5655/  8460 | global iter:   5655/  8460 | loss: 0.2636 | ds_loss: 0.0000 | lr: 1.2387e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5656/  8460 | global iter:   5656/  8460 | loss: 0.1122 | ds_loss: 0.0000 | lr: 1.2379e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5656/  8460 | global iter:   5656/  8460 | loss: 0.2427 | ds_loss: 0.0000 | lr: 1.2379e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5657/  8460 | global iter:   5657/  8460 | loss: 0.0744 | ds_loss: 0.0000 | lr: 1.2371e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5658/  8460 | global iter:   5658/  8460 | loss: 0.0708 | ds_loss: 0.0000 | lr: 1.2363e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5659/  8460 | global iter:   5659/  8460 | loss: 0.0856 | ds_loss: 0.0000 | lr: 1.2355e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5660/  8460 | global iter:   5660/  8460 | loss: 0.1708 | ds_loss: 0.0000 | lr: 1.2347e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5660/  8460 | global iter:   5660/  8460 | loss: 0.1004 | ds_loss: 0.0000 | lr: 1.2347e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5661/  8460 | global iter:   5661/  8460 | loss: 0.0927 | ds_loss: 0.0000 | lr: 1.2339e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5662/  8460 | global iter:   5662/  8460 | loss: 0.0599 | ds_loss: 0.0000 | lr: 1.2331e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5663/  8460 | global iter:   5663/  8460 | loss: 0.1486 | ds_loss: 0.0000 | lr: 1.2323e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5664/  8460 | global iter:   5664/  8460 | loss: 0.1638 | ds_loss: 0.0000 | lr: 1.2315e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5664/  8460 | global iter:   5664/  8460 | loss: 0.1163 | ds_loss: 0.0000 | lr: 1.2315e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5665/  8460 | global iter:   5665/  8460 | loss: 0.0451 | ds_loss: 0.0000 | lr: 1.2307e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5666/  8460 | global iter:   5666/  8460 | loss: 0.0308 | ds_loss: 0.0000 | lr: 1.2299e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5667/  8460 | global iter:   5667/  8460 | loss: 0.0812 | ds_loss: 0.0000 | lr: 1.2291e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5668/  8460 | global iter:   5668/  8460 | loss: 0.1839 | ds_loss: 0.0000 | lr: 1.2283e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5668/  8460 | global iter:   5668/  8460 | loss: 0.0853 | ds_loss: 0.0000 | lr: 1.2283e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5669/  8460 | global iter:   5669/  8460 | loss: 0.2684 | ds_loss: 0.0000 | lr: 1.2275e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5670/  8460 | global iter:   5670/  8460 | loss: 0.2087 | ds_loss: 0.0000 | lr: 1.2267e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5671/  8460 | global iter:   5671/  8460 | loss: 0.0779 | ds_loss: 0.0000 | lr: 1.2259e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5672/  8460 | global iter:   5672/  8460 | loss: 0.0704 | ds_loss: 0.0000 | lr: 1.2251e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5672/  8460 | global iter:   5672/  8460 | loss: 0.1563 | ds_loss: 0.0000 | lr: 1.2251e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5673/  8460 | global iter:   5673/  8460 | loss: 0.1750 | ds_loss: 0.0000 | lr: 1.2243e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5674/  8460 | global iter:   5674/  8460 | loss: 0.0679 | ds_loss: 0.0000 | lr: 1.2235e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5675/  8460 | global iter:   5675/  8460 | loss: 0.0293 | ds_loss: 0.0000 | lr: 1.2227e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5676/  8460 | global iter:   5676/  8460 | loss: 0.1492 | ds_loss: 0.0000 | lr: 1.2219e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5676/  8460 | global iter:   5676/  8460 | loss: 0.1053 | ds_loss: 0.0000 | lr: 1.2219e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5677/  8460 | global iter:   5677/  8460 | loss: 0.1330 | ds_loss: 0.0000 | lr: 1.2211e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5678/  8460 | global iter:   5678/  8460 | loss: 0.1284 | ds_loss: 0.0000 | lr: 1.2203e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5679/  8460 | global iter:   5679/  8460 | loss: 0.5360 | ds_loss: 0.0000 | lr: 1.2195e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5680/  8460 | global iter:   5680/  8460 | loss: 0.1986 | ds_loss: 0.0000 | lr: 1.2187e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5680/  8460 | global iter:   5680/  8460 | loss: 0.2490 | ds_loss: 0.0000 | lr: 1.2187e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5681/  8460 | global iter:   5681/  8460 | loss: 0.0048 | ds_loss: 0.0000 | lr: 1.2179e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5682/  8460 | global iter:   5682/  8460 | loss: 0.2580 | ds_loss: 0.0000 | lr: 1.2171e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5683/  8460 | global iter:   5683/  8460 | loss: 0.0093 | ds_loss: 0.0000 | lr: 1.2163e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5684/  8460 | global iter:   5684/  8460 | loss: 0.2856 | ds_loss: 0.0000 | lr: 1.2155e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5684/  8460 | global iter:   5684/  8460 | loss: 0.1394 | ds_loss: 0.0000 | lr: 1.2155e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5685/  8460 | global iter:   5685/  8460 | loss: 0.0711 | ds_loss: 0.0000 | lr: 1.2148e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5686/  8460 | global iter:   5686/  8460 | loss: 0.3231 | ds_loss: 0.0000 | lr: 1.2140e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5687/  8460 | global iter:   5687/  8460 | loss: 0.0598 | ds_loss: 0.0000 | lr: 1.2132e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5688/  8460 | global iter:   5688/  8460 | loss: 0.3937 | ds_loss: 0.0000 | lr: 1.2124e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5688/  8460 | global iter:   5688/  8460 | loss: 0.2119 | ds_loss: 0.0000 | lr: 1.2124e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5689/  8460 | global iter:   5689/  8460 | loss: 0.0803 | ds_loss: 0.0000 | lr: 1.2116e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5690/  8460 | global iter:   5690/  8460 | loss: 0.1790 | ds_loss: 0.0000 | lr: 1.2108e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5691/  8460 | global iter:   5691/  8460 | loss: 0.0396 | ds_loss: 0.0000 | lr: 1.2100e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5692/  8460 | global iter:   5692/  8460 | loss: 0.1719 | ds_loss: 0.0000 | lr: 1.2092e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5692/  8460 | global iter:   5692/  8460 | loss: 0.1177 | ds_loss: 0.0000 | lr: 1.2092e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5693/  8460 | global iter:   5693/  8460 | loss: 0.1694 | ds_loss: 0.0000 | lr: 1.2084e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5694/  8460 | global iter:   5694/  8460 | loss: 0.2621 | ds_loss: 0.0000 | lr: 1.2076e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5695/  8460 | global iter:   5695/  8460 | loss: 0.1635 | ds_loss: 0.0000 | lr: 1.2068e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5696/  8460 | global iter:   5696/  8460 | loss: 0.0725 | ds_loss: 0.0000 | lr: 1.2060e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5696/  8460 | global iter:   5696/  8460 | loss: 0.1669 | ds_loss: 0.0000 | lr: 1.2060e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5697/  8460 | global iter:   5697/  8460 | loss: 0.3028 | ds_loss: 0.0000 | lr: 1.2052e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5698/  8460 | global iter:   5698/  8460 | loss: 0.0523 | ds_loss: 0.0000 | lr: 1.2044e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5699/  8460 | global iter:   5699/  8460 | loss: 0.0535 | ds_loss: 0.0000 | lr: 1.2036e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5700/  8460 | global iter:   5700/  8460 | loss: 0.0642 | ds_loss: 0.0000 | lr: 1.2028e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5700/  8460 | global iter:   5700/  8460 | loss: 0.1182 | ds_loss: 0.0000 | lr: 1.2028e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5701/  8460 | global iter:   5701/  8460 | loss: 0.2089 | ds_loss: 0.0000 | lr: 1.2020e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5702/  8460 | global iter:   5702/  8460 | loss: 0.1575 | ds_loss: 0.0000 | lr: 1.2012e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5703/  8460 | global iter:   5703/  8460 | loss: 0.0181 | ds_loss: 0.0000 | lr: 1.2005e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5704/  8460 | global iter:   5704/  8460 | loss: 0.1772 | ds_loss: 0.0000 | lr: 1.1997e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5704/  8460 | global iter:   5704/  8460 | loss: 0.1404 | ds_loss: 0.0000 | lr: 1.1997e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5705/  8460 | global iter:   5705/  8460 | loss: 0.1496 | ds_loss: 0.0000 | lr: 1.1989e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5706/  8460 | global iter:   5706/  8460 | loss: 0.0338 | ds_loss: 0.0000 | lr: 1.1981e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5707/  8460 | global iter:   5707/  8460 | loss: 0.0432 | ds_loss: 0.0000 | lr: 1.1973e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5708/  8460 | global iter:   5708/  8460 | loss: 0.2443 | ds_loss: 0.0000 | lr: 1.1965e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5708/  8460 | global iter:   5708/  8460 | loss: 0.1177 | ds_loss: 0.0000 | lr: 1.1965e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5709/  8460 | global iter:   5709/  8460 | loss: 0.0869 | ds_loss: 0.0000 | lr: 1.1957e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5710/  8460 | global iter:   5710/  8460 | loss: 0.1168 | ds_loss: 0.0000 | lr: 1.1949e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5711/  8460 | global iter:   5711/  8460 | loss: 0.0718 | ds_loss: 0.0000 | lr: 1.1941e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5712/  8460 | global iter:   5712/  8460 | loss: 0.0577 | ds_loss: 0.0000 | lr: 1.1933e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5712/  8460 | global iter:   5712/  8460 | loss: 0.0833 | ds_loss: 0.0000 | lr: 1.1933e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5713/  8460 | global iter:   5713/  8460 | loss: 0.1461 | ds_loss: 0.0000 | lr: 1.1925e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5714/  8460 | global iter:   5714/  8460 | loss: 0.1642 | ds_loss: 0.0000 | lr: 1.1917e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5715/  8460 | global iter:   5715/  8460 | loss: 0.0543 | ds_loss: 0.0000 | lr: 1.1910e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5716/  8460 | global iter:   5716/  8460 | loss: 0.0329 | ds_loss: 0.0000 | lr: 1.1902e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5716/  8460 | global iter:   5716/  8460 | loss: 0.0994 | ds_loss: 0.0000 | lr: 1.1902e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5717/  8460 | global iter:   5717/  8460 | loss: 0.1535 | ds_loss: 0.0000 | lr: 1.1894e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5718/  8460 | global iter:   5718/  8460 | loss: 0.0350 | ds_loss: 0.0000 | lr: 1.1886e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5719/  8460 | global iter:   5719/  8460 | loss: 0.0974 | ds_loss: 0.0000 | lr: 1.1878e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5720/  8460 | global iter:   5720/  8460 | loss: 0.1410 | ds_loss: 0.0000 | lr: 1.1870e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5720/  8460 | global iter:   5720/  8460 | loss: 0.1068 | ds_loss: 0.0000 | lr: 1.1870e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5721/  8460 | global iter:   5721/  8460 | loss: 0.0424 | ds_loss: 0.0000 | lr: 1.1862e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5722/  8460 | global iter:   5722/  8460 | loss: 0.1674 | ds_loss: 0.0000 | lr: 1.1854e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5723/  8460 | global iter:   5723/  8460 | loss: 0.0549 | ds_loss: 0.0000 | lr: 1.1846e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5724/  8460 | global iter:   5724/  8460 | loss: 0.0320 | ds_loss: 0.0000 | lr: 1.1838e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5724/  8460 | global iter:   5724/  8460 | loss: 0.0742 | ds_loss: 0.0000 | lr: 1.1838e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5725/  8460 | global iter:   5725/  8460 | loss: 0.0524 | ds_loss: 0.0000 | lr: 1.1831e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5726/  8460 | global iter:   5726/  8460 | loss: 0.0170 | ds_loss: 0.0000 | lr: 1.1823e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5727/  8460 | global iter:   5727/  8460 | loss: 0.0951 | ds_loss: 0.0000 | lr: 1.1815e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5728/  8460 | global iter:   5728/  8460 | loss: 0.0839 | ds_loss: 0.0000 | lr: 1.1807e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5728/  8460 | global iter:   5728/  8460 | loss: 0.0621 | ds_loss: 0.0000 | lr: 1.1807e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5729/  8460 | global iter:   5729/  8460 | loss: 0.0417 | ds_loss: 0.0000 | lr: 1.1799e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5730/  8460 | global iter:   5730/  8460 | loss: 0.0671 | ds_loss: 0.0000 | lr: 1.1791e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5731/  8460 | global iter:   5731/  8460 | loss: 0.2287 | ds_loss: 0.0000 | lr: 1.1783e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5732/  8460 | global iter:   5732/  8460 | loss: 0.2883 | ds_loss: 0.0000 | lr: 1.1775e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5732/  8460 | global iter:   5732/  8460 | loss: 0.1564 | ds_loss: 0.0000 | lr: 1.1775e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5733/  8460 | global iter:   5733/  8460 | loss: 0.0963 | ds_loss: 0.0000 | lr: 1.1768e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5734/  8460 | global iter:   5734/  8460 | loss: 0.1054 | ds_loss: 0.0000 | lr: 1.1760e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5735/  8460 | global iter:   5735/  8460 | loss: 0.1011 | ds_loss: 0.0000 | lr: 1.1752e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5736/  8460 | global iter:   5736/  8460 | loss: 0.1576 | ds_loss: 0.0000 | lr: 1.1744e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5736/  8460 | global iter:   5736/  8460 | loss: 0.1151 | ds_loss: 0.0000 | lr: 1.1744e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5737/  8460 | global iter:   5737/  8460 | loss: 0.1020 | ds_loss: 0.0000 | lr: 1.1736e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5738/  8460 | global iter:   5738/  8460 | loss: 0.1744 | ds_loss: 0.0000 | lr: 1.1728e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5739/  8460 | global iter:   5739/  8460 | loss: 0.0193 | ds_loss: 0.0000 | lr: 1.1720e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5740/  8460 | global iter:   5740/  8460 | loss: 0.0375 | ds_loss: 0.0000 | lr: 1.1712e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5740/  8460 | global iter:   5740/  8460 | loss: 0.0833 | ds_loss: 0.0000 | lr: 1.1712e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5741/  8460 | global iter:   5741/  8460 | loss: 0.1646 | ds_loss: 0.0000 | lr: 1.1705e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5742/  8460 | global iter:   5742/  8460 | loss: 0.0235 | ds_loss: 0.0000 | lr: 1.1697e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5743/  8460 | global iter:   5743/  8460 | loss: 0.1812 | ds_loss: 0.0000 | lr: 1.1689e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5744/  8460 | global iter:   5744/  8460 | loss: 0.0549 | ds_loss: 0.0000 | lr: 1.1681e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5744/  8460 | global iter:   5744/  8460 | loss: 0.1061 | ds_loss: 0.0000 | lr: 1.1681e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5745/  8460 | global iter:   5745/  8460 | loss: 0.3568 | ds_loss: 0.0000 | lr: 1.1673e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5746/  8460 | global iter:   5746/  8460 | loss: 0.0519 | ds_loss: 0.0000 | lr: 1.1665e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5747/  8460 | global iter:   5747/  8460 | loss: 0.1908 | ds_loss: 0.0000 | lr: 1.1657e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5748/  8460 | global iter:   5748/  8460 | loss: 0.1638 | ds_loss: 0.0000 | lr: 1.1650e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5748/  8460 | global iter:   5748/  8460 | loss: 0.1908 | ds_loss: 0.0000 | lr: 1.1650e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5749/  8460 | global iter:   5749/  8460 | loss: 0.1638 | ds_loss: 0.0000 | lr: 1.1642e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5750/  8460 | global iter:   5750/  8460 | loss: 0.2484 | ds_loss: 0.0000 | lr: 1.1634e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5751/  8460 | global iter:   5751/  8460 | loss: 0.2849 | ds_loss: 0.0000 | lr: 1.1626e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5752/  8460 | global iter:   5752/  8460 | loss: 0.1611 | ds_loss: 0.0000 | lr: 1.1618e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5752/  8460 | global iter:   5752/  8460 | loss: 0.2146 | ds_loss: 0.0000 | lr: 1.1618e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5753/  8460 | global iter:   5753/  8460 | loss: 0.0408 | ds_loss: 0.0000 | lr: 1.1610e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5754/  8460 | global iter:   5754/  8460 | loss: 0.2177 | ds_loss: 0.0000 | lr: 1.1603e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5755/  8460 | global iter:   5755/  8460 | loss: 0.0564 | ds_loss: 0.0000 | lr: 1.1595e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5756/  8460 | global iter:   5756/  8460 | loss: 0.1478 | ds_loss: 0.0000 | lr: 1.1587e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5756/  8460 | global iter:   5756/  8460 | loss: 0.1157 | ds_loss: 0.0000 | lr: 1.1587e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5757/  8460 | global iter:   5757/  8460 | loss: 0.0067 | ds_loss: 0.0000 | lr: 1.1579e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5758/  8460 | global iter:   5758/  8460 | loss: 0.1005 | ds_loss: 0.0000 | lr: 1.1571e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5759/  8460 | global iter:   5759/  8460 | loss: 0.1911 | ds_loss: 0.0000 | lr: 1.1563e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5760/  8460 | global iter:   5760/  8460 | loss: 0.1116 | ds_loss: 0.0000 | lr: 1.1556e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5760/  8460 | global iter:   5760/  8460 | loss: 0.1025 | ds_loss: 0.0000 | lr: 1.1556e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5761/  8460 | global iter:   5761/  8460 | loss: 0.1192 | ds_loss: 0.0000 | lr: 1.1548e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5762/  8460 | global iter:   5762/  8460 | loss: 0.5656 | ds_loss: 0.0000 | lr: 1.1540e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5763/  8460 | global iter:   5763/  8460 | loss: 0.1278 | ds_loss: 0.0000 | lr: 1.1532e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5764/  8460 | global iter:   5764/  8460 | loss: 0.0803 | ds_loss: 0.0000 | lr: 1.1524e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5764/  8460 | global iter:   5764/  8460 | loss: 0.2232 | ds_loss: 0.0000 | lr: 1.1524e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5765/  8460 | global iter:   5765/  8460 | loss: 0.0842 | ds_loss: 0.0000 | lr: 1.1517e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5766/  8460 | global iter:   5766/  8460 | loss: 0.1288 | ds_loss: 0.0000 | lr: 1.1509e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5767/  8460 | global iter:   5767/  8460 | loss: 0.0783 | ds_loss: 0.0000 | lr: 1.1501e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5768/  8460 | global iter:   5768/  8460 | loss: 0.0601 | ds_loss: 0.0000 | lr: 1.1493e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5768/  8460 | global iter:   5768/  8460 | loss: 0.0879 | ds_loss: 0.0000 | lr: 1.1493e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5769/  8460 | global iter:   5769/  8460 | loss: 0.2699 | ds_loss: 0.0000 | lr: 1.1485e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5770/  8460 | global iter:   5770/  8460 | loss: 0.2343 | ds_loss: 0.0000 | lr: 1.1477e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5771/  8460 | global iter:   5771/  8460 | loss: 0.0209 | ds_loss: 0.0000 | lr: 1.1470e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5772/  8460 | global iter:   5772/  8460 | loss: 0.1660 | ds_loss: 0.0000 | lr: 1.1462e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5772/  8460 | global iter:   5772/  8460 | loss: 0.1728 | ds_loss: 0.0000 | lr: 1.1462e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5773/  8460 | global iter:   5773/  8460 | loss: 0.0684 | ds_loss: 0.0000 | lr: 1.1454e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5774/  8460 | global iter:   5774/  8460 | loss: 0.1719 | ds_loss: 0.0000 | lr: 1.1446e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5775/  8460 | global iter:   5775/  8460 | loss: 0.0618 | ds_loss: 0.0000 | lr: 1.1438e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5776/  8460 | global iter:   5776/  8460 | loss: 0.1057 | ds_loss: 0.0000 | lr: 1.1431e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5776/  8460 | global iter:   5776/  8460 | loss: 0.1019 | ds_loss: 0.0000 | lr: 1.1431e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5777/  8460 | global iter:   5777/  8460 | loss: 0.0535 | ds_loss: 0.0000 | lr: 1.1423e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5778/  8460 | global iter:   5778/  8460 | loss: 0.0645 | ds_loss: 0.0000 | lr: 1.1415e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5779/  8460 | global iter:   5779/  8460 | loss: 0.1634 | ds_loss: 0.0000 | lr: 1.1407e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5780/  8460 | global iter:   5780/  8460 | loss: 0.3675 | ds_loss: 0.0000 | lr: 1.1400e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5780/  8460 | global iter:   5780/  8460 | loss: 0.1622 | ds_loss: 0.0000 | lr: 1.1400e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5781/  8460 | global iter:   5781/  8460 | loss: 0.1381 | ds_loss: 0.0000 | lr: 1.1392e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5782/  8460 | global iter:   5782/  8460 | loss: 0.0635 | ds_loss: 0.0000 | lr: 1.1384e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5783/  8460 | global iter:   5783/  8460 | loss: 0.3192 | ds_loss: 0.0000 | lr: 1.1376e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5784/  8460 | global iter:   5784/  8460 | loss: 0.0378 | ds_loss: 0.0000 | lr: 1.1368e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5784/  8460 | global iter:   5784/  8460 | loss: 0.1396 | ds_loss: 0.0000 | lr: 1.1368e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5785/  8460 | global iter:   5785/  8460 | loss: 0.0979 | ds_loss: 0.0000 | lr: 1.1361e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5786/  8460 | global iter:   5786/  8460 | loss: 0.2222 | ds_loss: 0.0000 | lr: 1.1353e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5787/  8460 | global iter:   5787/  8460 | loss: 0.0434 | ds_loss: 0.0000 | lr: 1.1345e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5788/  8460 | global iter:   5788/  8460 | loss: 0.1147 | ds_loss: 0.0000 | lr: 1.1337e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5788/  8460 | global iter:   5788/  8460 | loss: 0.1196 | ds_loss: 0.0000 | lr: 1.1337e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5789/  8460 | global iter:   5789/  8460 | loss: 0.0128 | ds_loss: 0.0000 | lr: 1.1330e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5790/  8460 | global iter:   5790/  8460 | loss: 0.0885 | ds_loss: 0.0000 | lr: 1.1322e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5791/  8460 | global iter:   5791/  8460 | loss: 0.1720 | ds_loss: 0.0000 | lr: 1.1314e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5792/  8460 | global iter:   5792/  8460 | loss: 0.1446 | ds_loss: 0.0000 | lr: 1.1306e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5792/  8460 | global iter:   5792/  8460 | loss: 0.1045 | ds_loss: 0.0000 | lr: 1.1306e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5793/  8460 | global iter:   5793/  8460 | loss: 0.2277 | ds_loss: 0.0000 | lr: 1.1298e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5794/  8460 | global iter:   5794/  8460 | loss: 0.1144 | ds_loss: 0.0000 | lr: 1.1291e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5795/  8460 | global iter:   5795/  8460 | loss: 0.0090 | ds_loss: 0.0000 | lr: 1.1283e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5796/  8460 | global iter:   5796/  8460 | loss: 0.1073 | ds_loss: 0.0000 | lr: 1.1275e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5796/  8460 | global iter:   5796/  8460 | loss: 0.1146 | ds_loss: 0.0000 | lr: 1.1275e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5797/  8460 | global iter:   5797/  8460 | loss: 0.1643 | ds_loss: 0.0000 | lr: 1.1267e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5798/  8460 | global iter:   5798/  8460 | loss: 0.2619 | ds_loss: 0.0000 | lr: 1.1260e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5799/  8460 | global iter:   5799/  8460 | loss: 0.1046 | ds_loss: 0.0000 | lr: 1.1252e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5800/  8460 | global iter:   5800/  8460 | loss: 0.0623 | ds_loss: 0.0000 | lr: 1.1244e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5800/  8460 | global iter:   5800/  8460 | loss: 0.1483 | ds_loss: 0.0000 | lr: 1.1244e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5801/  8460 | global iter:   5801/  8460 | loss: 0.2495 | ds_loss: 0.0000 | lr: 1.1236e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5802/  8460 | global iter:   5802/  8460 | loss: 0.1966 | ds_loss: 0.0000 | lr: 1.1229e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5803/  8460 | global iter:   5803/  8460 | loss: 0.2808 | ds_loss: 0.0000 | lr: 1.1221e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5804/  8460 | global iter:   5804/  8460 | loss: 0.1429 | ds_loss: 0.0000 | lr: 1.1213e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5804/  8460 | global iter:   5804/  8460 | loss: 0.2174 | ds_loss: 0.0000 | lr: 1.1213e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5805/  8460 | global iter:   5805/  8460 | loss: 0.1127 | ds_loss: 0.0000 | lr: 1.1205e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5806/  8460 | global iter:   5806/  8460 | loss: 0.2252 | ds_loss: 0.0000 | lr: 1.1198e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5807/  8460 | global iter:   5807/  8460 | loss: 0.0957 | ds_loss: 0.0000 | lr: 1.1190e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5808/  8460 | global iter:   5808/  8460 | loss: 0.0747 | ds_loss: 0.0000 | lr: 1.1182e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5808/  8460 | global iter:   5808/  8460 | loss: 0.1271 | ds_loss: 0.0000 | lr: 1.1182e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5809/  8460 | global iter:   5809/  8460 | loss: 0.0233 | ds_loss: 0.0000 | lr: 1.1175e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5810/  8460 | global iter:   5810/  8460 | loss: 0.0338 | ds_loss: 0.0000 | lr: 1.1167e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5811/  8460 | global iter:   5811/  8460 | loss: 0.0904 | ds_loss: 0.0000 | lr: 1.1159e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5812/  8460 | global iter:   5812/  8460 | loss: 0.0202 | ds_loss: 0.0000 | lr: 1.1151e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5812/  8460 | global iter:   5812/  8460 | loss: 0.0419 | ds_loss: 0.0000 | lr: 1.1151e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5813/  8460 | global iter:   5813/  8460 | loss: 0.2256 | ds_loss: 0.0000 | lr: 1.1144e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5814/  8460 | global iter:   5814/  8460 | loss: 0.1854 | ds_loss: 0.0000 | lr: 1.1136e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5815/  8460 | global iter:   5815/  8460 | loss: 0.0441 | ds_loss: 0.0000 | lr: 1.1128e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5816/  8460 | global iter:   5816/  8460 | loss: 0.0679 | ds_loss: 0.0000 | lr: 1.1120e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5816/  8460 | global iter:   5816/  8460 | loss: 0.1308 | ds_loss: 0.0000 | lr: 1.1120e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5817/  8460 | global iter:   5817/  8460 | loss: 0.4386 | ds_loss: 0.0000 | lr: 1.1113e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5818/  8460 | global iter:   5818/  8460 | loss: 0.2892 | ds_loss: 0.0000 | lr: 1.1105e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5819/  8460 | global iter:   5819/  8460 | loss: 0.0237 | ds_loss: 0.0000 | lr: 1.1097e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5820/  8460 | global iter:   5820/  8460 | loss: 0.3038 | ds_loss: 0.0000 | lr: 1.1090e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5820/  8460 | global iter:   5820/  8460 | loss: 0.2638 | ds_loss: 0.0000 | lr: 1.1090e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5821/  8460 | global iter:   5821/  8460 | loss: 0.1881 | ds_loss: 0.0000 | lr: 1.1082e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5822/  8460 | global iter:   5822/  8460 | loss: 0.2919 | ds_loss: 0.0000 | lr: 1.1074e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5823/  8460 | global iter:   5823/  8460 | loss: 0.1821 | ds_loss: 0.0000 | lr: 1.1066e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5824/  8460 | global iter:   5824/  8460 | loss: 0.2098 | ds_loss: 0.0000 | lr: 1.1059e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5824/  8460 | global iter:   5824/  8460 | loss: 0.2180 | ds_loss: 0.0000 | lr: 1.1059e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5825/  8460 | global iter:   5825/  8460 | loss: 0.2374 | ds_loss: 0.0000 | lr: 1.1051e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5826/  8460 | global iter:   5826/  8460 | loss: 0.1145 | ds_loss: 0.0000 | lr: 1.1043e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5827/  8460 | global iter:   5827/  8460 | loss: 0.1183 | ds_loss: 0.0000 | lr: 1.1036e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5828/  8460 | global iter:   5828/  8460 | loss: 0.1527 | ds_loss: 0.0000 | lr: 1.1028e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5828/  8460 | global iter:   5828/  8460 | loss: 0.1557 | ds_loss: 0.0000 | lr: 1.1028e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5829/  8460 | global iter:   5829/  8460 | loss: 0.3522 | ds_loss: 0.0000 | lr: 1.1020e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5830/  8460 | global iter:   5830/  8460 | loss: 0.1436 | ds_loss: 0.0000 | lr: 1.1013e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5831/  8460 | global iter:   5831/  8460 | loss: 0.1213 | ds_loss: 0.0000 | lr: 1.1005e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5832/  8460 | global iter:   5832/  8460 | loss: 0.0680 | ds_loss: 0.0000 | lr: 1.0997e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5832/  8460 | global iter:   5832/  8460 | loss: 0.1713 | ds_loss: 0.0000 | lr: 1.0997e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5833/  8460 | global iter:   5833/  8460 | loss: 0.1368 | ds_loss: 0.0000 | lr: 1.0990e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5834/  8460 | global iter:   5834/  8460 | loss: 0.0581 | ds_loss: 0.0000 | lr: 1.0982e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5835/  8460 | global iter:   5835/  8460 | loss: 0.0690 | ds_loss: 0.0000 | lr: 1.0974e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5836/  8460 | global iter:   5836/  8460 | loss: 0.1227 | ds_loss: 0.0000 | lr: 1.0966e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5836/  8460 | global iter:   5836/  8460 | loss: 0.0966 | ds_loss: 0.0000 | lr: 1.0966e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5837/  8460 | global iter:   5837/  8460 | loss: 0.0985 | ds_loss: 0.0000 | lr: 1.0959e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5838/  8460 | global iter:   5838/  8460 | loss: 0.2890 | ds_loss: 0.0000 | lr: 1.0951e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5839/  8460 | global iter:   5839/  8460 | loss: 0.0766 | ds_loss: 0.0000 | lr: 1.0943e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5840/  8460 | global iter:   5840/  8460 | loss: 0.2709 | ds_loss: 0.0000 | lr: 1.0936e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5840/  8460 | global iter:   5840/  8460 | loss: 0.1838 | ds_loss: 0.0000 | lr: 1.0936e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5841/  8460 | global iter:   5841/  8460 | loss: 0.2523 | ds_loss: 0.0000 | lr: 1.0928e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5842/  8460 | global iter:   5842/  8460 | loss: 0.1501 | ds_loss: 0.0000 | lr: 1.0920e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5843/  8460 | global iter:   5843/  8460 | loss: 0.1340 | ds_loss: 0.0000 | lr: 1.0913e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5844/  8460 | global iter:   5844/  8460 | loss: 0.1987 | ds_loss: 0.0000 | lr: 1.0905e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5844/  8460 | global iter:   5844/  8460 | loss: 0.1838 | ds_loss: 0.0000 | lr: 1.0905e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5845/  8460 | global iter:   5845/  8460 | loss: 0.0332 | ds_loss: 0.0000 | lr: 1.0897e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5846/  8460 | global iter:   5846/  8460 | loss: 0.0323 | ds_loss: 0.0000 | lr: 1.0890e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5847/  8460 | global iter:   5847/  8460 | loss: 0.0825 | ds_loss: 0.0000 | lr: 1.0882e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5848/  8460 | global iter:   5848/  8460 | loss: 0.0264 | ds_loss: 0.0000 | lr: 1.0874e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5848/  8460 | global iter:   5848/  8460 | loss: 0.0436 | ds_loss: 0.0000 | lr: 1.0874e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5849/  8460 | global iter:   5849/  8460 | loss: 0.0560 | ds_loss: 0.0000 | lr: 1.0867e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5850/  8460 | global iter:   5850/  8460 | loss: 0.2233 | ds_loss: 0.0000 | lr: 1.0859e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5851/  8460 | global iter:   5851/  8460 | loss: 0.1129 | ds_loss: 0.0000 | lr: 1.0852e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5852/  8460 | global iter:   5852/  8460 | loss: 0.1849 | ds_loss: 0.0000 | lr: 1.0844e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5852/  8460 | global iter:   5852/  8460 | loss: 0.1443 | ds_loss: 0.0000 | lr: 1.0844e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5853/  8460 | global iter:   5853/  8460 | loss: 0.1144 | ds_loss: 0.0000 | lr: 1.0836e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5854/  8460 | global iter:   5854/  8460 | loss: 0.2128 | ds_loss: 0.0000 | lr: 1.0829e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5855/  8460 | global iter:   5855/  8460 | loss: 0.0286 | ds_loss: 0.0000 | lr: 1.0821e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5856/  8460 | global iter:   5856/  8460 | loss: 0.0075 | ds_loss: 0.0000 | lr: 1.0813e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5856/  8460 | global iter:   5856/  8460 | loss: 0.0908 | ds_loss: 0.0000 | lr: 1.0813e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5857/  8460 | global iter:   5857/  8460 | loss: 0.2296 | ds_loss: 0.0000 | lr: 1.0806e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5858/  8460 | global iter:   5858/  8460 | loss: 0.1681 | ds_loss: 0.0000 | lr: 1.0798e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5859/  8460 | global iter:   5859/  8460 | loss: 0.1789 | ds_loss: 0.0000 | lr: 1.0790e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5860/  8460 | global iter:   5860/  8460 | loss: 0.0622 | ds_loss: 0.0000 | lr: 1.0783e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5860/  8460 | global iter:   5860/  8460 | loss: 0.1597 | ds_loss: 0.0000 | lr: 1.0783e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5861/  8460 | global iter:   5861/  8460 | loss: 0.2290 | ds_loss: 0.0000 | lr: 1.0775e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5862/  8460 | global iter:   5862/  8460 | loss: 0.1719 | ds_loss: 0.0000 | lr: 1.0767e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5863/  8460 | global iter:   5863/  8460 | loss: 0.0346 | ds_loss: 0.0000 | lr: 1.0760e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5864/  8460 | global iter:   5864/  8460 | loss: 0.0592 | ds_loss: 0.0000 | lr: 1.0752e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5864/  8460 | global iter:   5864/  8460 | loss: 0.1237 | ds_loss: 0.0000 | lr: 1.0752e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5865/  8460 | global iter:   5865/  8460 | loss: 0.0403 | ds_loss: 0.0000 | lr: 1.0745e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5866/  8460 | global iter:   5866/  8460 | loss: 0.0765 | ds_loss: 0.0000 | lr: 1.0737e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5867/  8460 | global iter:   5867/  8460 | loss: 0.1925 | ds_loss: 0.0000 | lr: 1.0729e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5868/  8460 | global iter:   5868/  8460 | loss: 0.2789 | ds_loss: 0.0000 | lr: 1.0722e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5868/  8460 | global iter:   5868/  8460 | loss: 0.1471 | ds_loss: 0.0000 | lr: 1.0722e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5869/  8460 | global iter:   5869/  8460 | loss: 0.3168 | ds_loss: 0.0000 | lr: 1.0714e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5870/  8460 | global iter:   5870/  8460 | loss: 0.1368 | ds_loss: 0.0000 | lr: 1.0706e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5871/  8460 | global iter:   5871/  8460 | loss: 0.2007 | ds_loss: 0.0000 | lr: 1.0699e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5872/  8460 | global iter:   5872/  8460 | loss: 0.1386 | ds_loss: 0.0000 | lr: 1.0691e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5872/  8460 | global iter:   5872/  8460 | loss: 0.1982 | ds_loss: 0.0000 | lr: 1.0691e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5873/  8460 | global iter:   5873/  8460 | loss: 0.1273 | ds_loss: 0.0000 | lr: 1.0684e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5874/  8460 | global iter:   5874/  8460 | loss: 0.0579 | ds_loss: 0.0000 | lr: 1.0676e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5875/  8460 | global iter:   5875/  8460 | loss: 0.0791 | ds_loss: 0.0000 | lr: 1.0668e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5876/  8460 | global iter:   5876/  8460 | loss: 0.1731 | ds_loss: 0.0000 | lr: 1.0661e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5876/  8460 | global iter:   5876/  8460 | loss: 0.1093 | ds_loss: 0.0000 | lr: 1.0661e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5877/  8460 | global iter:   5877/  8460 | loss: 0.3738 | ds_loss: 0.0000 | lr: 1.0653e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5878/  8460 | global iter:   5878/  8460 | loss: 0.0957 | ds_loss: 0.0000 | lr: 1.0646e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5879/  8460 | global iter:   5879/  8460 | loss: 0.0425 | ds_loss: 0.0000 | lr: 1.0638e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5880/  8460 | global iter:   5880/  8460 | loss: 0.1290 | ds_loss: 0.0000 | lr: 1.0630e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5880/  8460 | global iter:   5880/  8460 | loss: 0.1603 | ds_loss: 0.0000 | lr: 1.0630e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5881/  8460 | global iter:   5881/  8460 | loss: 0.0679 | ds_loss: 0.0000 | lr: 1.0623e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5882/  8460 | global iter:   5882/  8460 | loss: 0.2111 | ds_loss: 0.0000 | lr: 1.0615e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5883/  8460 | global iter:   5883/  8460 | loss: 0.0809 | ds_loss: 0.0000 | lr: 1.0608e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5884/  8460 | global iter:   5884/  8460 | loss: 0.0338 | ds_loss: 0.0000 | lr: 1.0600e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5884/  8460 | global iter:   5884/  8460 | loss: 0.0984 | ds_loss: 0.0000 | lr: 1.0600e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5885/  8460 | global iter:   5885/  8460 | loss: 0.0374 | ds_loss: 0.0000 | lr: 1.0593e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5886/  8460 | global iter:   5886/  8460 | loss: 0.0192 | ds_loss: 0.0000 | lr: 1.0585e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5887/  8460 | global iter:   5887/  8460 | loss: 0.1051 | ds_loss: 0.0000 | lr: 1.0577e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5888/  8460 | global iter:   5888/  8460 | loss: 0.2464 | ds_loss: 0.0000 | lr: 1.0570e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5888/  8460 | global iter:   5888/  8460 | loss: 0.1020 | ds_loss: 0.0000 | lr: 1.0570e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5889/  8460 | global iter:   5889/  8460 | loss: 0.0945 | ds_loss: 0.0000 | lr: 1.0562e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5890/  8460 | global iter:   5890/  8460 | loss: 0.0624 | ds_loss: 0.0000 | lr: 1.0555e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5891/  8460 | global iter:   5891/  8460 | loss: 0.0468 | ds_loss: 0.0000 | lr: 1.0547e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5892/  8460 | global iter:   5892/  8460 | loss: 0.0063 | ds_loss: 0.0000 | lr: 1.0539e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5892/  8460 | global iter:   5892/  8460 | loss: 0.0525 | ds_loss: 0.0000 | lr: 1.0539e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5893/  8460 | global iter:   5893/  8460 | loss: 0.0851 | ds_loss: 0.0000 | lr: 1.0532e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5894/  8460 | global iter:   5894/  8460 | loss: 0.0253 | ds_loss: 0.0000 | lr: 1.0524e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5895/  8460 | global iter:   5895/  8460 | loss: 0.1504 | ds_loss: 0.0000 | lr: 1.0517e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5896/  8460 | global iter:   5896/  8460 | loss: 0.1142 | ds_loss: 0.0000 | lr: 1.0509e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5896/  8460 | global iter:   5896/  8460 | loss: 0.0938 | ds_loss: 0.0000 | lr: 1.0509e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5897/  8460 | global iter:   5897/  8460 | loss: 0.0771 | ds_loss: 0.0000 | lr: 1.0502e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5898/  8460 | global iter:   5898/  8460 | loss: 0.0528 | ds_loss: 0.0000 | lr: 1.0494e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5899/  8460 | global iter:   5899/  8460 | loss: 0.0282 | ds_loss: 0.0000 | lr: 1.0487e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5900/  8460 | global iter:   5900/  8460 | loss: 0.0816 | ds_loss: 0.0000 | lr: 1.0479e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5900/  8460 | global iter:   5900/  8460 | loss: 0.0599 | ds_loss: 0.0000 | lr: 1.0479e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5901/  8460 | global iter:   5901/  8460 | loss: 0.2068 | ds_loss: 0.0000 | lr: 1.0471e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5902/  8460 | global iter:   5902/  8460 | loss: 0.0914 | ds_loss: 0.0000 | lr: 1.0464e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5903/  8460 | global iter:   5903/  8460 | loss: 0.2797 | ds_loss: 0.0000 | lr: 1.0456e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5904/  8460 | global iter:   5904/  8460 | loss: 0.1678 | ds_loss: 0.0000 | lr: 1.0449e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5904/  8460 | global iter:   5904/  8460 | loss: 0.1864 | ds_loss: 0.0000 | lr: 1.0449e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5905/  8460 | global iter:   5905/  8460 | loss: 0.1190 | ds_loss: 0.0000 | lr: 1.0441e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5906/  8460 | global iter:   5906/  8460 | loss: 0.1883 | ds_loss: 0.0000 | lr: 1.0434e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5907/  8460 | global iter:   5907/  8460 | loss: 0.1973 | ds_loss: 0.0000 | lr: 1.0426e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5908/  8460 | global iter:   5908/  8460 | loss: 0.3516 | ds_loss: 0.0000 | lr: 1.0419e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5908/  8460 | global iter:   5908/  8460 | loss: 0.2140 | ds_loss: 0.0000 | lr: 1.0419e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5909/  8460 | global iter:   5909/  8460 | loss: 0.0573 | ds_loss: 0.0000 | lr: 1.0411e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5910/  8460 | global iter:   5910/  8460 | loss: 0.0278 | ds_loss: 0.0000 | lr: 1.0404e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5911/  8460 | global iter:   5911/  8460 | loss: 0.2408 | ds_loss: 0.0000 | lr: 1.0396e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   6 | Iter:   5912/  8460 | global iter:   5912/  8460 | loss: 0.1328 | ds_loss: 0.0000 | lr: 1.0389e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5912/  8460 | global iter:   5912/  8460 | loss: 0.1147 | ds_loss: 0.0000 | lr: 1.0389e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5913/  8460 | global iter:   5913/  8460 | loss: 0.0481 | ds_loss: 0.0000 | lr: 1.0381e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5914/  8460 | global iter:   5914/  8460 | loss: 0.0440 | ds_loss: 0.0000 | lr: 1.0373e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5915/  8460 | global iter:   5915/  8460 | loss: 0.0994 | ds_loss: 0.0000 | lr: 1.0366e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5916/  8460 | global iter:   5916/  8460 | loss: 0.1731 | ds_loss: 0.0000 | lr: 1.0358e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5916/  8460 | global iter:   5916/  8460 | loss: 0.0912 | ds_loss: 0.0000 | lr: 1.0358e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5917/  8460 | global iter:   5917/  8460 | loss: 0.1539 | ds_loss: 0.0000 | lr: 1.0351e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5918/  8460 | global iter:   5918/  8460 | loss: 0.1259 | ds_loss: 0.0000 | lr: 1.0343e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5919/  8460 | global iter:   5919/  8460 | loss: 0.0528 | ds_loss: 0.0000 | lr: 1.0336e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5920/  8460 | global iter:   5920/  8460 | loss: 0.2819 | ds_loss: 0.0000 | lr: 1.0328e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5920/  8460 | global iter:   5920/  8460 | loss: 0.1536 | ds_loss: 0.0000 | lr: 1.0328e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5921/  8460 | global iter:   5921/  8460 | loss: 0.2315 | ds_loss: 0.0000 | lr: 1.0321e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5922/  8460 | global iter:   5922/  8460 | loss: 0.0660 | ds_loss: 0.0000 | lr: 1.0313e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5923/  8460 | global iter:   5923/  8460 | loss: 0.1554 | ds_loss: 0.0000 | lr: 1.0306e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5924/  8460 | global iter:   5924/  8460 | loss: 0.1480 | ds_loss: 0.0000 | lr: 1.0298e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5924/  8460 | global iter:   5924/  8460 | loss: 0.1502 | ds_loss: 0.0000 | lr: 1.0298e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5925/  8460 | global iter:   5925/  8460 | loss: 0.4027 | ds_loss: 0.0000 | lr: 1.0291e-04 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   6 | Iter:   5926/  8460 | global iter:   5926/  8460 | loss: 0.1666 | ds_loss: 0.0000 | lr: 1.0283e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5927/  8460 | global iter:   5927/  8460 | loss: 0.0965 | ds_loss: 0.0000 | lr: 1.0276e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   6 | Iter:   5928/  8460 | global iter:   5928/  8460 | loss: 0.1498 | ds_loss: 0.0000 | lr: 1.0268e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   6 | Iter:   5928/  8460 | global iter:   5928/  8460 | loss: 0.2039 | ds_loss: 0.0000 | lr: 1.0268e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   6 | Iter:   5929/  8460 | global iter:   5929/  8460 | loss: 0.1551 | ds_loss: 0.0000 | lr: 1.0261e-04 | scale:     1.0000 | micro time: 0.366 | step time: 0.000
Sun Apr  6 21:35:07 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla P100-PCIE-12GB           Off |   00000000:81:00.0 Off |                    0 |
| N/A   50C    P0             38W /  250W |    8807MiB /  12288MiB |    100%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A    244677      C   ...project_distillLLM/venv/bin/python3       8804MiB |
+-----------------------------------------------------------------------------------------+

train | epoch   7 | Iter:   5930/  8460 | global iter:   5930/  8460 | loss: 0.0447 | ds_loss: 0.0000 | lr: 1.0253e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5931/  8460 | global iter:   5931/  8460 | loss: 0.0649 | ds_loss: 0.0000 | lr: 1.0246e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5932/  8460 | global iter:   5932/  8460 | loss: 0.0414 | ds_loss: 0.0000 | lr: 1.0238e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   5932/  8460 | global iter:   5932/  8460 | loss: 0.0765 | ds_loss: 0.0000 | lr: 1.0238e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.412
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   5933/  8460 | global iter:   5933/  8460 | loss: 0.0195 | ds_loss: 0.0000 | lr: 1.0231e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   5934/  8460 | global iter:   5934/  8460 | loss: 0.1057 | ds_loss: 0.0000 | lr: 1.0223e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   5935/  8460 | global iter:   5935/  8460 | loss: 0.0694 | ds_loss: 0.0000 | lr: 1.0216e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   5936/  8460 | global iter:   5936/  8460 | loss: 0.0837 | ds_loss: 0.0000 | lr: 1.0208e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   5936/  8460 | global iter:   5936/  8460 | loss: 0.0696 | ds_loss: 0.0000 | lr: 1.0208e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   5937/  8460 | global iter:   5937/  8460 | loss: 0.1849 | ds_loss: 0.0000 | lr: 1.0201e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5938/  8460 | global iter:   5938/  8460 | loss: 0.0771 | ds_loss: 0.0000 | lr: 1.0193e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5939/  8460 | global iter:   5939/  8460 | loss: 0.0685 | ds_loss: 0.0000 | lr: 1.0186e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5940/  8460 | global iter:   5940/  8460 | loss: 0.0372 | ds_loss: 0.0000 | lr: 1.0178e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   5940/  8460 | global iter:   5940/  8460 | loss: 0.0919 | ds_loss: 0.0000 | lr: 1.0178e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   5941/  8460 | global iter:   5941/  8460 | loss: 0.2634 | ds_loss: 0.0000 | lr: 1.0171e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5942/  8460 | global iter:   5942/  8460 | loss: 0.0725 | ds_loss: 0.0000 | lr: 1.0164e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   5943/  8460 | global iter:   5943/  8460 | loss: 0.1649 | ds_loss: 0.0000 | lr: 1.0156e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   5944/  8460 | global iter:   5944/  8460 | loss: 0.1032 | ds_loss: 0.0000 | lr: 1.0149e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   5944/  8460 | global iter:   5944/  8460 | loss: 0.1510 | ds_loss: 0.0000 | lr: 1.0149e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   5945/  8460 | global iter:   5945/  8460 | loss: 0.1421 | ds_loss: 0.0000 | lr: 1.0141e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   5946/  8460 | global iter:   5946/  8460 | loss: 0.1063 | ds_loss: 0.0000 | lr: 1.0134e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5947/  8460 | global iter:   5947/  8460 | loss: 0.1043 | ds_loss: 0.0000 | lr: 1.0126e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   5948/  8460 | global iter:   5948/  8460 | loss: 0.0726 | ds_loss: 0.0000 | lr: 1.0119e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   5948/  8460 | global iter:   5948/  8460 | loss: 0.1063 | ds_loss: 0.0000 | lr: 1.0119e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   5949/  8460 | global iter:   5949/  8460 | loss: 0.0685 | ds_loss: 0.0000 | lr: 1.0111e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5950/  8460 | global iter:   5950/  8460 | loss: 0.2378 | ds_loss: 0.0000 | lr: 1.0104e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5951/  8460 | global iter:   5951/  8460 | loss: 0.0602 | ds_loss: 0.0000 | lr: 1.0096e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5952/  8460 | global iter:   5952/  8460 | loss: 0.0869 | ds_loss: 0.0000 | lr: 1.0089e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   5952/  8460 | global iter:   5952/  8460 | loss: 0.1134 | ds_loss: 0.0000 | lr: 1.0089e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   5953/  8460 | global iter:   5953/  8460 | loss: 0.1600 | ds_loss: 0.0000 | lr: 1.0082e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5954/  8460 | global iter:   5954/  8460 | loss: 0.0621 | ds_loss: 0.0000 | lr: 1.0074e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5955/  8460 | global iter:   5955/  8460 | loss: 0.1093 | ds_loss: 0.0000 | lr: 1.0067e-04 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   5956/  8460 | global iter:   5956/  8460 | loss: 0.0064 | ds_loss: 0.0000 | lr: 1.0059e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   5956/  8460 | global iter:   5956/  8460 | loss: 0.0844 | ds_loss: 0.0000 | lr: 1.0059e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   5957/  8460 | global iter:   5957/  8460 | loss: 0.0538 | ds_loss: 0.0000 | lr: 1.0052e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5958/  8460 | global iter:   5958/  8460 | loss: 0.0692 | ds_loss: 0.0000 | lr: 1.0044e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5959/  8460 | global iter:   5959/  8460 | loss: 0.0190 | ds_loss: 0.0000 | lr: 1.0037e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5960/  8460 | global iter:   5960/  8460 | loss: 0.0049 | ds_loss: 0.0000 | lr: 1.0029e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   5960/  8460 | global iter:   5960/  8460 | loss: 0.0367 | ds_loss: 0.0000 | lr: 1.0029e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   5961/  8460 | global iter:   5961/  8460 | loss: 0.3194 | ds_loss: 0.0000 | lr: 1.0022e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5962/  8460 | global iter:   5962/  8460 | loss: 0.1873 | ds_loss: 0.0000 | lr: 1.0015e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5963/  8460 | global iter:   5963/  8460 | loss: 0.0812 | ds_loss: 0.0000 | lr: 1.0007e-04 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5964/  8460 | global iter:   5964/  8460 | loss: 0.0876 | ds_loss: 0.0000 | lr: 9.9997e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   5964/  8460 | global iter:   5964/  8460 | loss: 0.1689 | ds_loss: 0.0000 | lr: 9.9997e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   5965/  8460 | global iter:   5965/  8460 | loss: 0.0491 | ds_loss: 0.0000 | lr: 9.9923e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5966/  8460 | global iter:   5966/  8460 | loss: 0.0238 | ds_loss: 0.0000 | lr: 9.9849e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5967/  8460 | global iter:   5967/  8460 | loss: 0.1588 | ds_loss: 0.0000 | lr: 9.9775e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5968/  8460 | global iter:   5968/  8460 | loss: 0.1021 | ds_loss: 0.0000 | lr: 9.9700e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   5968/  8460 | global iter:   5968/  8460 | loss: 0.0834 | ds_loss: 0.0000 | lr: 9.9700e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   5969/  8460 | global iter:   5969/  8460 | loss: 0.0619 | ds_loss: 0.0000 | lr: 9.9626e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5970/  8460 | global iter:   5970/  8460 | loss: 0.1090 | ds_loss: 0.0000 | lr: 9.9552e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5971/  8460 | global iter:   5971/  8460 | loss: 0.1874 | ds_loss: 0.0000 | lr: 9.9478e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5972/  8460 | global iter:   5972/  8460 | loss: 0.1037 | ds_loss: 0.0000 | lr: 9.9404e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   5972/  8460 | global iter:   5972/  8460 | loss: 0.1155 | ds_loss: 0.0000 | lr: 9.9404e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   5973/  8460 | global iter:   5973/  8460 | loss: 0.2107 | ds_loss: 0.0000 | lr: 9.9330e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5974/  8460 | global iter:   5974/  8460 | loss: 0.2390 | ds_loss: 0.0000 | lr: 9.9256e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5975/  8460 | global iter:   5975/  8460 | loss: 0.0061 | ds_loss: 0.0000 | lr: 9.9182e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   5976/  8460 | global iter:   5976/  8460 | loss: 0.1314 | ds_loss: 0.0000 | lr: 9.9108e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   5976/  8460 | global iter:   5976/  8460 | loss: 0.1468 | ds_loss: 0.0000 | lr: 9.9108e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   5977/  8460 | global iter:   5977/  8460 | loss: 0.0343 | ds_loss: 0.0000 | lr: 9.9034e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5978/  8460 | global iter:   5978/  8460 | loss: 0.0755 | ds_loss: 0.0000 | lr: 9.8960e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5979/  8460 | global iter:   5979/  8460 | loss: 0.0108 | ds_loss: 0.0000 | lr: 9.8886e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   5980/  8460 | global iter:   5980/  8460 | loss: 0.0876 | ds_loss: 0.0000 | lr: 9.8812e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   5980/  8460 | global iter:   5980/  8460 | loss: 0.0520 | ds_loss: 0.0000 | lr: 9.8812e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   5981/  8460 | global iter:   5981/  8460 | loss: 0.0361 | ds_loss: 0.0000 | lr: 9.8738e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   5982/  8460 | global iter:   5982/  8460 | loss: 0.0976 | ds_loss: 0.0000 | lr: 9.8664e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5983/  8460 | global iter:   5983/  8460 | loss: 0.0118 | ds_loss: 0.0000 | lr: 9.8591e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5984/  8460 | global iter:   5984/  8460 | loss: 0.0330 | ds_loss: 0.0000 | lr: 9.8517e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   5984/  8460 | global iter:   5984/  8460 | loss: 0.0447 | ds_loss: 0.0000 | lr: 9.8517e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   5985/  8460 | global iter:   5985/  8460 | loss: 0.1800 | ds_loss: 0.0000 | lr: 9.8443e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5986/  8460 | global iter:   5986/  8460 | loss: 0.0887 | ds_loss: 0.0000 | lr: 9.8369e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   5987/  8460 | global iter:   5987/  8460 | loss: 0.1508 | ds_loss: 0.0000 | lr: 9.8295e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5988/  8460 | global iter:   5988/  8460 | loss: 0.1169 | ds_loss: 0.0000 | lr: 9.8222e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   5988/  8460 | global iter:   5988/  8460 | loss: 0.1341 | ds_loss: 0.0000 | lr: 9.8222e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   5989/  8460 | global iter:   5989/  8460 | loss: 0.0856 | ds_loss: 0.0000 | lr: 9.8148e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5990/  8460 | global iter:   5990/  8460 | loss: 0.0304 | ds_loss: 0.0000 | lr: 9.8074e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   5991/  8460 | global iter:   5991/  8460 | loss: 0.1357 | ds_loss: 0.0000 | lr: 9.8001e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5992/  8460 | global iter:   5992/  8460 | loss: 0.0793 | ds_loss: 0.0000 | lr: 9.7927e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   5992/  8460 | global iter:   5992/  8460 | loss: 0.0828 | ds_loss: 0.0000 | lr: 9.7927e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   5993/  8460 | global iter:   5993/  8460 | loss: 0.1294 | ds_loss: 0.0000 | lr: 9.7853e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   5994/  8460 | global iter:   5994/  8460 | loss: 0.0946 | ds_loss: 0.0000 | lr: 9.7780e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5995/  8460 | global iter:   5995/  8460 | loss: 0.0766 | ds_loss: 0.0000 | lr: 9.7706e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5996/  8460 | global iter:   5996/  8460 | loss: 0.1176 | ds_loss: 0.0000 | lr: 9.7632e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   5996/  8460 | global iter:   5996/  8460 | loss: 0.1046 | ds_loss: 0.0000 | lr: 9.7632e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   5997/  8460 | global iter:   5997/  8460 | loss: 0.1283 | ds_loss: 0.0000 | lr: 9.7559e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5998/  8460 | global iter:   5998/  8460 | loss: 0.1826 | ds_loss: 0.0000 | lr: 9.7485e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   5999/  8460 | global iter:   5999/  8460 | loss: 0.0404 | ds_loss: 0.0000 | lr: 9.7412e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6000/  8460 | global iter:   6000/  8460 | loss: 0.0435 | ds_loss: 0.0000 | lr: 9.7338e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6000/  8460 | global iter:   6000/  8460 | loss: 0.0987 | ds_loss: 0.0000 | lr: 9.7338e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6001/  8460 | global iter:   6001/  8460 | loss: 0.0482 | ds_loss: 0.0000 | lr: 9.7265e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6002/  8460 | global iter:   6002/  8460 | loss: 0.0717 | ds_loss: 0.0000 | lr: 9.7191e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6003/  8460 | global iter:   6003/  8460 | loss: 0.1820 | ds_loss: 0.0000 | lr: 9.7118e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6004/  8460 | global iter:   6004/  8460 | loss: 0.1615 | ds_loss: 0.0000 | lr: 9.7045e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6004/  8460 | global iter:   6004/  8460 | loss: 0.1158 | ds_loss: 0.0000 | lr: 9.7045e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6005/  8460 | global iter:   6005/  8460 | loss: 0.0216 | ds_loss: 0.0000 | lr: 9.6971e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6006/  8460 | global iter:   6006/  8460 | loss: 0.0599 | ds_loss: 0.0000 | lr: 9.6898e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6007/  8460 | global iter:   6007/  8460 | loss: 0.0892 | ds_loss: 0.0000 | lr: 9.6825e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6008/  8460 | global iter:   6008/  8460 | loss: 0.0733 | ds_loss: 0.0000 | lr: 9.6751e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6008/  8460 | global iter:   6008/  8460 | loss: 0.0610 | ds_loss: 0.0000 | lr: 9.6751e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6009/  8460 | global iter:   6009/  8460 | loss: 0.1485 | ds_loss: 0.0000 | lr: 9.6678e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6010/  8460 | global iter:   6010/  8460 | loss: 0.0706 | ds_loss: 0.0000 | lr: 9.6605e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6011/  8460 | global iter:   6011/  8460 | loss: 0.1040 | ds_loss: 0.0000 | lr: 9.6531e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6012/  8460 | global iter:   6012/  8460 | loss: 0.0361 | ds_loss: 0.0000 | lr: 9.6458e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6012/  8460 | global iter:   6012/  8460 | loss: 0.0898 | ds_loss: 0.0000 | lr: 9.6458e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6013/  8460 | global iter:   6013/  8460 | loss: 0.0238 | ds_loss: 0.0000 | lr: 9.6385e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6014/  8460 | global iter:   6014/  8460 | loss: 0.1752 | ds_loss: 0.0000 | lr: 9.6312e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6015/  8460 | global iter:   6015/  8460 | loss: 0.0650 | ds_loss: 0.0000 | lr: 9.6239e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6016/  8460 | global iter:   6016/  8460 | loss: 0.0652 | ds_loss: 0.0000 | lr: 9.6165e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6016/  8460 | global iter:   6016/  8460 | loss: 0.0823 | ds_loss: 0.0000 | lr: 9.6165e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6017/  8460 | global iter:   6017/  8460 | loss: 0.2184 | ds_loss: 0.0000 | lr: 9.6092e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6018/  8460 | global iter:   6018/  8460 | loss: 0.1222 | ds_loss: 0.0000 | lr: 9.6019e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6019/  8460 | global iter:   6019/  8460 | loss: 0.0774 | ds_loss: 0.0000 | lr: 9.5946e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6020/  8460 | global iter:   6020/  8460 | loss: 0.0747 | ds_loss: 0.0000 | lr: 9.5873e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6020/  8460 | global iter:   6020/  8460 | loss: 0.1232 | ds_loss: 0.0000 | lr: 9.5873e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6021/  8460 | global iter:   6021/  8460 | loss: 0.0125 | ds_loss: 0.0000 | lr: 9.5800e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6022/  8460 | global iter:   6022/  8460 | loss: 0.2497 | ds_loss: 0.0000 | lr: 9.5727e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6023/  8460 | global iter:   6023/  8460 | loss: 0.1635 | ds_loss: 0.0000 | lr: 9.5654e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6024/  8460 | global iter:   6024/  8460 | loss: 0.0554 | ds_loss: 0.0000 | lr: 9.5581e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6024/  8460 | global iter:   6024/  8460 | loss: 0.1203 | ds_loss: 0.0000 | lr: 9.5581e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6025/  8460 | global iter:   6025/  8460 | loss: 0.0184 | ds_loss: 0.0000 | lr: 9.5508e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6026/  8460 | global iter:   6026/  8460 | loss: 0.0934 | ds_loss: 0.0000 | lr: 9.5435e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6027/  8460 | global iter:   6027/  8460 | loss: 0.4029 | ds_loss: 0.0000 | lr: 9.5362e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6028/  8460 | global iter:   6028/  8460 | loss: 0.0213 | ds_loss: 0.0000 | lr: 9.5289e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6028/  8460 | global iter:   6028/  8460 | loss: 0.1340 | ds_loss: 0.0000 | lr: 9.5289e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6029/  8460 | global iter:   6029/  8460 | loss: 0.0706 | ds_loss: 0.0000 | lr: 9.5216e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6030/  8460 | global iter:   6030/  8460 | loss: 0.3512 | ds_loss: 0.0000 | lr: 9.5144e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6031/  8460 | global iter:   6031/  8460 | loss: 0.1116 | ds_loss: 0.0000 | lr: 9.5071e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6032/  8460 | global iter:   6032/  8460 | loss: 0.0598 | ds_loss: 0.0000 | lr: 9.4998e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6032/  8460 | global iter:   6032/  8460 | loss: 0.1483 | ds_loss: 0.0000 | lr: 9.4998e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6033/  8460 | global iter:   6033/  8460 | loss: 0.2977 | ds_loss: 0.0000 | lr: 9.4925e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6034/  8460 | global iter:   6034/  8460 | loss: 0.1158 | ds_loss: 0.0000 | lr: 9.4852e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6035/  8460 | global iter:   6035/  8460 | loss: 0.2508 | ds_loss: 0.0000 | lr: 9.4780e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6036/  8460 | global iter:   6036/  8460 | loss: 0.0531 | ds_loss: 0.0000 | lr: 9.4707e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6036/  8460 | global iter:   6036/  8460 | loss: 0.1794 | ds_loss: 0.0000 | lr: 9.4707e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6037/  8460 | global iter:   6037/  8460 | loss: 0.0860 | ds_loss: 0.0000 | lr: 9.4634e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6038/  8460 | global iter:   6038/  8460 | loss: 0.0501 | ds_loss: 0.0000 | lr: 9.4561e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6039/  8460 | global iter:   6039/  8460 | loss: 0.0868 | ds_loss: 0.0000 | lr: 9.4489e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6040/  8460 | global iter:   6040/  8460 | loss: 0.0667 | ds_loss: 0.0000 | lr: 9.4416e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6040/  8460 | global iter:   6040/  8460 | loss: 0.0724 | ds_loss: 0.0000 | lr: 9.4416e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6041/  8460 | global iter:   6041/  8460 | loss: 0.0672 | ds_loss: 0.0000 | lr: 9.4344e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6042/  8460 | global iter:   6042/  8460 | loss: 0.1765 | ds_loss: 0.0000 | lr: 9.4271e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6043/  8460 | global iter:   6043/  8460 | loss: 0.0561 | ds_loss: 0.0000 | lr: 9.4198e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6044/  8460 | global iter:   6044/  8460 | loss: 0.0843 | ds_loss: 0.0000 | lr: 9.4126e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6044/  8460 | global iter:   6044/  8460 | loss: 0.0960 | ds_loss: 0.0000 | lr: 9.4126e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6045/  8460 | global iter:   6045/  8460 | loss: 0.0264 | ds_loss: 0.0000 | lr: 9.4053e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6046/  8460 | global iter:   6046/  8460 | loss: 0.0657 | ds_loss: 0.0000 | lr: 9.3981e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6047/  8460 | global iter:   6047/  8460 | loss: 0.0384 | ds_loss: 0.0000 | lr: 9.3908e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6048/  8460 | global iter:   6048/  8460 | loss: 0.0310 | ds_loss: 0.0000 | lr: 9.3836e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6048/  8460 | global iter:   6048/  8460 | loss: 0.0404 | ds_loss: 0.0000 | lr: 9.3836e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6049/  8460 | global iter:   6049/  8460 | loss: 0.0844 | ds_loss: 0.0000 | lr: 9.3763e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6050/  8460 | global iter:   6050/  8460 | loss: 0.1479 | ds_loss: 0.0000 | lr: 9.3691e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6051/  8460 | global iter:   6051/  8460 | loss: 0.1735 | ds_loss: 0.0000 | lr: 9.3619e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6052/  8460 | global iter:   6052/  8460 | loss: 0.0357 | ds_loss: 0.0000 | lr: 9.3546e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6052/  8460 | global iter:   6052/  8460 | loss: 0.1104 | ds_loss: 0.0000 | lr: 9.3546e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6053/  8460 | global iter:   6053/  8460 | loss: 0.1514 | ds_loss: 0.0000 | lr: 9.3474e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6054/  8460 | global iter:   6054/  8460 | loss: 0.0614 | ds_loss: 0.0000 | lr: 9.3401e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6055/  8460 | global iter:   6055/  8460 | loss: 0.4200 | ds_loss: 0.0000 | lr: 9.3329e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6056/  8460 | global iter:   6056/  8460 | loss: 0.0232 | ds_loss: 0.0000 | lr: 9.3257e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6056/  8460 | global iter:   6056/  8460 | loss: 0.1640 | ds_loss: 0.0000 | lr: 9.3257e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6057/  8460 | global iter:   6057/  8460 | loss: 0.0589 | ds_loss: 0.0000 | lr: 9.3185e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6058/  8460 | global iter:   6058/  8460 | loss: 0.1153 | ds_loss: 0.0000 | lr: 9.3112e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6059/  8460 | global iter:   6059/  8460 | loss: 0.0582 | ds_loss: 0.0000 | lr: 9.3040e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6060/  8460 | global iter:   6060/  8460 | loss: 0.0906 | ds_loss: 0.0000 | lr: 9.2968e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6060/  8460 | global iter:   6060/  8460 | loss: 0.0808 | ds_loss: 0.0000 | lr: 9.2968e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6061/  8460 | global iter:   6061/  8460 | loss: 0.0352 | ds_loss: 0.0000 | lr: 9.2896e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6062/  8460 | global iter:   6062/  8460 | loss: 0.0348 | ds_loss: 0.0000 | lr: 9.2824e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6063/  8460 | global iter:   6063/  8460 | loss: 0.1397 | ds_loss: 0.0000 | lr: 9.2751e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6064/  8460 | global iter:   6064/  8460 | loss: 0.0740 | ds_loss: 0.0000 | lr: 9.2679e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6064/  8460 | global iter:   6064/  8460 | loss: 0.0709 | ds_loss: 0.0000 | lr: 9.2679e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6065/  8460 | global iter:   6065/  8460 | loss: 0.0924 | ds_loss: 0.0000 | lr: 9.2607e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6066/  8460 | global iter:   6066/  8460 | loss: 0.0302 | ds_loss: 0.0000 | lr: 9.2535e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6067/  8460 | global iter:   6067/  8460 | loss: 0.2226 | ds_loss: 0.0000 | lr: 9.2463e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6068/  8460 | global iter:   6068/  8460 | loss: 0.0439 | ds_loss: 0.0000 | lr: 9.2391e-05 | scale:     1.0000 | micro time: 0.430 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6068/  8460 | global iter:   6068/  8460 | loss: 0.0973 | ds_loss: 0.0000 | lr: 9.2391e-05 | scale:     1.0000 | micro time: 0.430 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6069/  8460 | global iter:   6069/  8460 | loss: 0.1938 | ds_loss: 0.0000 | lr: 9.2319e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6070/  8460 | global iter:   6070/  8460 | loss: 0.1072 | ds_loss: 0.0000 | lr: 9.2247e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6071/  8460 | global iter:   6071/  8460 | loss: 0.1716 | ds_loss: 0.0000 | lr: 9.2175e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6072/  8460 | global iter:   6072/  8460 | loss: 0.0863 | ds_loss: 0.0000 | lr: 9.2103e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6072/  8460 | global iter:   6072/  8460 | loss: 0.1397 | ds_loss: 0.0000 | lr: 9.2103e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6073/  8460 | global iter:   6073/  8460 | loss: 0.1814 | ds_loss: 0.0000 | lr: 9.2031e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6074/  8460 | global iter:   6074/  8460 | loss: 0.0358 | ds_loss: 0.0000 | lr: 9.1959e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6075/  8460 | global iter:   6075/  8460 | loss: 0.0296 | ds_loss: 0.0000 | lr: 9.1887e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6076/  8460 | global iter:   6076/  8460 | loss: 0.1413 | ds_loss: 0.0000 | lr: 9.1815e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6076/  8460 | global iter:   6076/  8460 | loss: 0.0970 | ds_loss: 0.0000 | lr: 9.1815e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6077/  8460 | global iter:   6077/  8460 | loss: 0.0406 | ds_loss: 0.0000 | lr: 9.1744e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6078/  8460 | global iter:   6078/  8460 | loss: 0.1033 | ds_loss: 0.0000 | lr: 9.1672e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6079/  8460 | global iter:   6079/  8460 | loss: 0.0810 | ds_loss: 0.0000 | lr: 9.1600e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6080/  8460 | global iter:   6080/  8460 | loss: 0.0083 | ds_loss: 0.0000 | lr: 9.1528e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6080/  8460 | global iter:   6080/  8460 | loss: 0.0583 | ds_loss: 0.0000 | lr: 9.1528e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6081/  8460 | global iter:   6081/  8460 | loss: 0.0569 | ds_loss: 0.0000 | lr: 9.1456e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6082/  8460 | global iter:   6082/  8460 | loss: 0.0039 | ds_loss: 0.0000 | lr: 9.1385e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6083/  8460 | global iter:   6083/  8460 | loss: 0.0737 | ds_loss: 0.0000 | lr: 9.1313e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6084/  8460 | global iter:   6084/  8460 | loss: 0.0553 | ds_loss: 0.0000 | lr: 9.1241e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6084/  8460 | global iter:   6084/  8460 | loss: 0.0475 | ds_loss: 0.0000 | lr: 9.1241e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6085/  8460 | global iter:   6085/  8460 | loss: 0.0354 | ds_loss: 0.0000 | lr: 9.1170e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6086/  8460 | global iter:   6086/  8460 | loss: 0.1115 | ds_loss: 0.0000 | lr: 9.1098e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6087/  8460 | global iter:   6087/  8460 | loss: 0.0455 | ds_loss: 0.0000 | lr: 9.1026e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6088/  8460 | global iter:   6088/  8460 | loss: 0.0041 | ds_loss: 0.0000 | lr: 9.0955e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6088/  8460 | global iter:   6088/  8460 | loss: 0.0491 | ds_loss: 0.0000 | lr: 9.0955e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6089/  8460 | global iter:   6089/  8460 | loss: 0.1572 | ds_loss: 0.0000 | lr: 9.0883e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6090/  8460 | global iter:   6090/  8460 | loss: 0.1088 | ds_loss: 0.0000 | lr: 9.0812e-05 | scale:     1.0000 | micro time: 0.430 | step time: 0.000
train | epoch   7 | Iter:   6091/  8460 | global iter:   6091/  8460 | loss: 0.1454 | ds_loss: 0.0000 | lr: 9.0740e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6092/  8460 | global iter:   6092/  8460 | loss: 0.1212 | ds_loss: 0.0000 | lr: 9.0669e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6092/  8460 | global iter:   6092/  8460 | loss: 0.1331 | ds_loss: 0.0000 | lr: 9.0669e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6093/  8460 | global iter:   6093/  8460 | loss: 0.0322 | ds_loss: 0.0000 | lr: 9.0597e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6094/  8460 | global iter:   6094/  8460 | loss: 0.1318 | ds_loss: 0.0000 | lr: 9.0526e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6095/  8460 | global iter:   6095/  8460 | loss: 0.0063 | ds_loss: 0.0000 | lr: 9.0454e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6096/  8460 | global iter:   6096/  8460 | loss: 0.0354 | ds_loss: 0.0000 | lr: 9.0383e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6096/  8460 | global iter:   6096/  8460 | loss: 0.0514 | ds_loss: 0.0000 | lr: 9.0383e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6097/  8460 | global iter:   6097/  8460 | loss: 0.1764 | ds_loss: 0.0000 | lr: 9.0311e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6098/  8460 | global iter:   6098/  8460 | loss: 0.1130 | ds_loss: 0.0000 | lr: 9.0240e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6099/  8460 | global iter:   6099/  8460 | loss: 0.1186 | ds_loss: 0.0000 | lr: 9.0169e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6100/  8460 | global iter:   6100/  8460 | loss: 0.0241 | ds_loss: 0.0000 | lr: 9.0097e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6100/  8460 | global iter:   6100/  8460 | loss: 0.1080 | ds_loss: 0.0000 | lr: 9.0097e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6101/  8460 | global iter:   6101/  8460 | loss: 0.0856 | ds_loss: 0.0000 | lr: 9.0026e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6102/  8460 | global iter:   6102/  8460 | loss: 0.0580 | ds_loss: 0.0000 | lr: 8.9955e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6103/  8460 | global iter:   6103/  8460 | loss: 0.1092 | ds_loss: 0.0000 | lr: 8.9883e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6104/  8460 | global iter:   6104/  8460 | loss: 0.0445 | ds_loss: 0.0000 | lr: 8.9812e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6104/  8460 | global iter:   6104/  8460 | loss: 0.0743 | ds_loss: 0.0000 | lr: 8.9812e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6105/  8460 | global iter:   6105/  8460 | loss: 0.0495 | ds_loss: 0.0000 | lr: 8.9741e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6106/  8460 | global iter:   6106/  8460 | loss: 0.0599 | ds_loss: 0.0000 | lr: 8.9670e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6107/  8460 | global iter:   6107/  8460 | loss: 0.0767 | ds_loss: 0.0000 | lr: 8.9599e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6108/  8460 | global iter:   6108/  8460 | loss: 0.0565 | ds_loss: 0.0000 | lr: 8.9527e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6108/  8460 | global iter:   6108/  8460 | loss: 0.0606 | ds_loss: 0.0000 | lr: 8.9527e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6109/  8460 | global iter:   6109/  8460 | loss: 0.1841 | ds_loss: 0.0000 | lr: 8.9456e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6110/  8460 | global iter:   6110/  8460 | loss: 0.0608 | ds_loss: 0.0000 | lr: 8.9385e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6111/  8460 | global iter:   6111/  8460 | loss: 0.0332 | ds_loss: 0.0000 | lr: 8.9314e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6112/  8460 | global iter:   6112/  8460 | loss: 0.0733 | ds_loss: 0.0000 | lr: 8.9243e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6112/  8460 | global iter:   6112/  8460 | loss: 0.0879 | ds_loss: 0.0000 | lr: 8.9243e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6113/  8460 | global iter:   6113/  8460 | loss: 0.1552 | ds_loss: 0.0000 | lr: 8.9172e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6114/  8460 | global iter:   6114/  8460 | loss: 0.0963 | ds_loss: 0.0000 | lr: 8.9101e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6115/  8460 | global iter:   6115/  8460 | loss: 0.0902 | ds_loss: 0.0000 | lr: 8.9030e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6116/  8460 | global iter:   6116/  8460 | loss: 0.0985 | ds_loss: 0.0000 | lr: 8.8959e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6116/  8460 | global iter:   6116/  8460 | loss: 0.1101 | ds_loss: 0.0000 | lr: 8.8959e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6117/  8460 | global iter:   6117/  8460 | loss: 0.0914 | ds_loss: 0.0000 | lr: 8.8888e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6118/  8460 | global iter:   6118/  8460 | loss: 0.3509 | ds_loss: 0.0000 | lr: 8.8817e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6119/  8460 | global iter:   6119/  8460 | loss: 0.1373 | ds_loss: 0.0000 | lr: 8.8746e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6120/  8460 | global iter:   6120/  8460 | loss: 0.0468 | ds_loss: 0.0000 | lr: 8.8675e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6120/  8460 | global iter:   6120/  8460 | loss: 0.1566 | ds_loss: 0.0000 | lr: 8.8675e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6121/  8460 | global iter:   6121/  8460 | loss: 0.0237 | ds_loss: 0.0000 | lr: 8.8604e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6122/  8460 | global iter:   6122/  8460 | loss: 0.0563 | ds_loss: 0.0000 | lr: 8.8534e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6123/  8460 | global iter:   6123/  8460 | loss: 0.0834 | ds_loss: 0.0000 | lr: 8.8463e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6124/  8460 | global iter:   6124/  8460 | loss: 0.0340 | ds_loss: 0.0000 | lr: 8.8392e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6124/  8460 | global iter:   6124/  8460 | loss: 0.0493 | ds_loss: 0.0000 | lr: 8.8392e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6125/  8460 | global iter:   6125/  8460 | loss: 0.0445 | ds_loss: 0.0000 | lr: 8.8321e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6126/  8460 | global iter:   6126/  8460 | loss: 0.1035 | ds_loss: 0.0000 | lr: 8.8250e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6127/  8460 | global iter:   6127/  8460 | loss: 0.0478 | ds_loss: 0.0000 | lr: 8.8180e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6128/  8460 | global iter:   6128/  8460 | loss: 0.1372 | ds_loss: 0.0000 | lr: 8.8109e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6128/  8460 | global iter:   6128/  8460 | loss: 0.0833 | ds_loss: 0.0000 | lr: 8.8109e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6129/  8460 | global iter:   6129/  8460 | loss: 0.0585 | ds_loss: 0.0000 | lr: 8.8038e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6130/  8460 | global iter:   6130/  8460 | loss: 0.0563 | ds_loss: 0.0000 | lr: 8.7968e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6131/  8460 | global iter:   6131/  8460 | loss: 0.0765 | ds_loss: 0.0000 | lr: 8.7897e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6132/  8460 | global iter:   6132/  8460 | loss: 0.0029 | ds_loss: 0.0000 | lr: 8.7826e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6132/  8460 | global iter:   6132/  8460 | loss: 0.0486 | ds_loss: 0.0000 | lr: 8.7826e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6133/  8460 | global iter:   6133/  8460 | loss: 0.0790 | ds_loss: 0.0000 | lr: 8.7756e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6134/  8460 | global iter:   6134/  8460 | loss: 0.0346 | ds_loss: 0.0000 | lr: 8.7685e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6135/  8460 | global iter:   6135/  8460 | loss: 0.0648 | ds_loss: 0.0000 | lr: 8.7615e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6136/  8460 | global iter:   6136/  8460 | loss: 0.0434 | ds_loss: 0.0000 | lr: 8.7544e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6136/  8460 | global iter:   6136/  8460 | loss: 0.0555 | ds_loss: 0.0000 | lr: 8.7544e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6137/  8460 | global iter:   6137/  8460 | loss: 0.0580 | ds_loss: 0.0000 | lr: 8.7474e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6138/  8460 | global iter:   6138/  8460 | loss: 0.1486 | ds_loss: 0.0000 | lr: 8.7403e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6139/  8460 | global iter:   6139/  8460 | loss: 0.0235 | ds_loss: 0.0000 | lr: 8.7333e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6140/  8460 | global iter:   6140/  8460 | loss: 0.1139 | ds_loss: 0.0000 | lr: 8.7262e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6140/  8460 | global iter:   6140/  8460 | loss: 0.0860 | ds_loss: 0.0000 | lr: 8.7262e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6141/  8460 | global iter:   6141/  8460 | loss: 0.0868 | ds_loss: 0.0000 | lr: 8.7192e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6142/  8460 | global iter:   6142/  8460 | loss: 0.0144 | ds_loss: 0.0000 | lr: 8.7121e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6143/  8460 | global iter:   6143/  8460 | loss: 0.0444 | ds_loss: 0.0000 | lr: 8.7051e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6144/  8460 | global iter:   6144/  8460 | loss: 0.2308 | ds_loss: 0.0000 | lr: 8.6981e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6144/  8460 | global iter:   6144/  8460 | loss: 0.0941 | ds_loss: 0.0000 | lr: 8.6981e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6145/  8460 | global iter:   6145/  8460 | loss: 0.0051 | ds_loss: 0.0000 | lr: 8.6910e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6146/  8460 | global iter:   6146/  8460 | loss: 0.0146 | ds_loss: 0.0000 | lr: 8.6840e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6147/  8460 | global iter:   6147/  8460 | loss: 0.2752 | ds_loss: 0.0000 | lr: 8.6770e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6148/  8460 | global iter:   6148/  8460 | loss: 0.0286 | ds_loss: 0.0000 | lr: 8.6699e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6148/  8460 | global iter:   6148/  8460 | loss: 0.0809 | ds_loss: 0.0000 | lr: 8.6699e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6149/  8460 | global iter:   6149/  8460 | loss: 0.1279 | ds_loss: 0.0000 | lr: 8.6629e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6150/  8460 | global iter:   6150/  8460 | loss: 0.1573 | ds_loss: 0.0000 | lr: 8.6559e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6151/  8460 | global iter:   6151/  8460 | loss: 0.0177 | ds_loss: 0.0000 | lr: 8.6489e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6152/  8460 | global iter:   6152/  8460 | loss: 0.0166 | ds_loss: 0.0000 | lr: 8.6419e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6152/  8460 | global iter:   6152/  8460 | loss: 0.0799 | ds_loss: 0.0000 | lr: 8.6419e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6153/  8460 | global iter:   6153/  8460 | loss: 0.1963 | ds_loss: 0.0000 | lr: 8.6348e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6154/  8460 | global iter:   6154/  8460 | loss: 0.0291 | ds_loss: 0.0000 | lr: 8.6278e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6155/  8460 | global iter:   6155/  8460 | loss: 0.1133 | ds_loss: 0.0000 | lr: 8.6208e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6156/  8460 | global iter:   6156/  8460 | loss: 0.0950 | ds_loss: 0.0000 | lr: 8.6138e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6156/  8460 | global iter:   6156/  8460 | loss: 0.1084 | ds_loss: 0.0000 | lr: 8.6138e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6157/  8460 | global iter:   6157/  8460 | loss: 0.1028 | ds_loss: 0.0000 | lr: 8.6068e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6158/  8460 | global iter:   6158/  8460 | loss: 0.1117 | ds_loss: 0.0000 | lr: 8.5998e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6159/  8460 | global iter:   6159/  8460 | loss: 0.1513 | ds_loss: 0.0000 | lr: 8.5928e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6160/  8460 | global iter:   6160/  8460 | loss: 0.1607 | ds_loss: 0.0000 | lr: 8.5858e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6160/  8460 | global iter:   6160/  8460 | loss: 0.1316 | ds_loss: 0.0000 | lr: 8.5858e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6161/  8460 | global iter:   6161/  8460 | loss: 0.1601 | ds_loss: 0.0000 | lr: 8.5788e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6162/  8460 | global iter:   6162/  8460 | loss: 0.1173 | ds_loss: 0.0000 | lr: 8.5718e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6163/  8460 | global iter:   6163/  8460 | loss: 0.0464 | ds_loss: 0.0000 | lr: 8.5648e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6164/  8460 | global iter:   6164/  8460 | loss: 0.0599 | ds_loss: 0.0000 | lr: 8.5578e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6164/  8460 | global iter:   6164/  8460 | loss: 0.0959 | ds_loss: 0.0000 | lr: 8.5578e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6165/  8460 | global iter:   6165/  8460 | loss: 0.1019 | ds_loss: 0.0000 | lr: 8.5508e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6166/  8460 | global iter:   6166/  8460 | loss: 0.1324 | ds_loss: 0.0000 | lr: 8.5439e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6167/  8460 | global iter:   6167/  8460 | loss: 0.2094 | ds_loss: 0.0000 | lr: 8.5369e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6168/  8460 | global iter:   6168/  8460 | loss: 0.0503 | ds_loss: 0.0000 | lr: 8.5299e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6168/  8460 | global iter:   6168/  8460 | loss: 0.1235 | ds_loss: 0.0000 | lr: 8.5299e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6169/  8460 | global iter:   6169/  8460 | loss: 0.0366 | ds_loss: 0.0000 | lr: 8.5229e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6170/  8460 | global iter:   6170/  8460 | loss: 0.1943 | ds_loss: 0.0000 | lr: 8.5159e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6171/  8460 | global iter:   6171/  8460 | loss: 0.1273 | ds_loss: 0.0000 | lr: 8.5090e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6172/  8460 | global iter:   6172/  8460 | loss: 0.1116 | ds_loss: 0.0000 | lr: 8.5020e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6172/  8460 | global iter:   6172/  8460 | loss: 0.1174 | ds_loss: 0.0000 | lr: 8.5020e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6173/  8460 | global iter:   6173/  8460 | loss: 0.0651 | ds_loss: 0.0000 | lr: 8.4950e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6174/  8460 | global iter:   6174/  8460 | loss: 0.2134 | ds_loss: 0.0000 | lr: 8.4880e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6175/  8460 | global iter:   6175/  8460 | loss: 0.0231 | ds_loss: 0.0000 | lr: 8.4811e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6176/  8460 | global iter:   6176/  8460 | loss: 0.1367 | ds_loss: 0.0000 | lr: 8.4741e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6176/  8460 | global iter:   6176/  8460 | loss: 0.1096 | ds_loss: 0.0000 | lr: 8.4741e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6177/  8460 | global iter:   6177/  8460 | loss: 0.0242 | ds_loss: 0.0000 | lr: 8.4672e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6178/  8460 | global iter:   6178/  8460 | loss: 0.0651 | ds_loss: 0.0000 | lr: 8.4602e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6179/  8460 | global iter:   6179/  8460 | loss: 0.1214 | ds_loss: 0.0000 | lr: 8.4532e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6180/  8460 | global iter:   6180/  8460 | loss: 0.0603 | ds_loss: 0.0000 | lr: 8.4463e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6180/  8460 | global iter:   6180/  8460 | loss: 0.0677 | ds_loss: 0.0000 | lr: 8.4463e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6181/  8460 | global iter:   6181/  8460 | loss: 0.0230 | ds_loss: 0.0000 | lr: 8.4393e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6182/  8460 | global iter:   6182/  8460 | loss: 0.0067 | ds_loss: 0.0000 | lr: 8.4324e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6183/  8460 | global iter:   6183/  8460 | loss: 0.0342 | ds_loss: 0.0000 | lr: 8.4254e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6184/  8460 | global iter:   6184/  8460 | loss: 0.0254 | ds_loss: 0.0000 | lr: 8.4185e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6184/  8460 | global iter:   6184/  8460 | loss: 0.0223 | ds_loss: 0.0000 | lr: 8.4185e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6185/  8460 | global iter:   6185/  8460 | loss: 0.0873 | ds_loss: 0.0000 | lr: 8.4116e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6186/  8460 | global iter:   6186/  8460 | loss: 0.0691 | ds_loss: 0.0000 | lr: 8.4046e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6187/  8460 | global iter:   6187/  8460 | loss: 0.1729 | ds_loss: 0.0000 | lr: 8.3977e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6188/  8460 | global iter:   6188/  8460 | loss: 0.0579 | ds_loss: 0.0000 | lr: 8.3907e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6188/  8460 | global iter:   6188/  8460 | loss: 0.0968 | ds_loss: 0.0000 | lr: 8.3907e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6189/  8460 | global iter:   6189/  8460 | loss: 0.2991 | ds_loss: 0.0000 | lr: 8.3838e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6190/  8460 | global iter:   6190/  8460 | loss: 0.0878 | ds_loss: 0.0000 | lr: 8.3769e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6191/  8460 | global iter:   6191/  8460 | loss: 0.1402 | ds_loss: 0.0000 | lr: 8.3699e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6192/  8460 | global iter:   6192/  8460 | loss: 0.1400 | ds_loss: 0.0000 | lr: 8.3630e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6192/  8460 | global iter:   6192/  8460 | loss: 0.1668 | ds_loss: 0.0000 | lr: 8.3630e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6193/  8460 | global iter:   6193/  8460 | loss: 0.0886 | ds_loss: 0.0000 | lr: 8.3561e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6194/  8460 | global iter:   6194/  8460 | loss: 0.1349 | ds_loss: 0.0000 | lr: 8.3492e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6195/  8460 | global iter:   6195/  8460 | loss: 0.0887 | ds_loss: 0.0000 | lr: 8.3423e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6196/  8460 | global iter:   6196/  8460 | loss: 0.0517 | ds_loss: 0.0000 | lr: 8.3353e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6196/  8460 | global iter:   6196/  8460 | loss: 0.0910 | ds_loss: 0.0000 | lr: 8.3353e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6197/  8460 | global iter:   6197/  8460 | loss: 0.1023 | ds_loss: 0.0000 | lr: 8.3284e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6198/  8460 | global iter:   6198/  8460 | loss: 0.0436 | ds_loss: 0.0000 | lr: 8.3215e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6199/  8460 | global iter:   6199/  8460 | loss: 0.0810 | ds_loss: 0.0000 | lr: 8.3146e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6200/  8460 | global iter:   6200/  8460 | loss: 0.0578 | ds_loss: 0.0000 | lr: 8.3077e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6200/  8460 | global iter:   6200/  8460 | loss: 0.0712 | ds_loss: 0.0000 | lr: 8.3077e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6201/  8460 | global iter:   6201/  8460 | loss: 0.0741 | ds_loss: 0.0000 | lr: 8.3008e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6202/  8460 | global iter:   6202/  8460 | loss: 0.0903 | ds_loss: 0.0000 | lr: 8.2939e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6203/  8460 | global iter:   6203/  8460 | loss: 0.0463 | ds_loss: 0.0000 | lr: 8.2870e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6204/  8460 | global iter:   6204/  8460 | loss: 0.2586 | ds_loss: 0.0000 | lr: 8.2801e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6204/  8460 | global iter:   6204/  8460 | loss: 0.1173 | ds_loss: 0.0000 | lr: 8.2801e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6205/  8460 | global iter:   6205/  8460 | loss: 0.0885 | ds_loss: 0.0000 | lr: 8.2732e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6206/  8460 | global iter:   6206/  8460 | loss: 0.0152 | ds_loss: 0.0000 | lr: 8.2663e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6207/  8460 | global iter:   6207/  8460 | loss: 0.0578 | ds_loss: 0.0000 | lr: 8.2594e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6208/  8460 | global iter:   6208/  8460 | loss: 0.0810 | ds_loss: 0.0000 | lr: 8.2525e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6208/  8460 | global iter:   6208/  8460 | loss: 0.0606 | ds_loss: 0.0000 | lr: 8.2525e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6209/  8460 | global iter:   6209/  8460 | loss: 0.2244 | ds_loss: 0.0000 | lr: 8.2456e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6210/  8460 | global iter:   6210/  8460 | loss: 0.0906 | ds_loss: 0.0000 | lr: 8.2387e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6211/  8460 | global iter:   6211/  8460 | loss: 0.0332 | ds_loss: 0.0000 | lr: 8.2319e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6212/  8460 | global iter:   6212/  8460 | loss: 0.0993 | ds_loss: 0.0000 | lr: 8.2250e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6212/  8460 | global iter:   6212/  8460 | loss: 0.1119 | ds_loss: 0.0000 | lr: 8.2250e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6213/  8460 | global iter:   6213/  8460 | loss: 0.0064 | ds_loss: 0.0000 | lr: 8.2181e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6214/  8460 | global iter:   6214/  8460 | loss: 0.0350 | ds_loss: 0.0000 | lr: 8.2112e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6215/  8460 | global iter:   6215/  8460 | loss: 0.2140 | ds_loss: 0.0000 | lr: 8.2043e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6216/  8460 | global iter:   6216/  8460 | loss: 0.0415 | ds_loss: 0.0000 | lr: 8.1975e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6216/  8460 | global iter:   6216/  8460 | loss: 0.0742 | ds_loss: 0.0000 | lr: 8.1975e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6217/  8460 | global iter:   6217/  8460 | loss: 0.0433 | ds_loss: 0.0000 | lr: 8.1906e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6218/  8460 | global iter:   6218/  8460 | loss: 0.0820 | ds_loss: 0.0000 | lr: 8.1837e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6219/  8460 | global iter:   6219/  8460 | loss: 0.2258 | ds_loss: 0.0000 | lr: 8.1769e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6220/  8460 | global iter:   6220/  8460 | loss: 0.1441 | ds_loss: 0.0000 | lr: 8.1700e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6220/  8460 | global iter:   6220/  8460 | loss: 0.1238 | ds_loss: 0.0000 | lr: 8.1700e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6221/  8460 | global iter:   6221/  8460 | loss: 0.0094 | ds_loss: 0.0000 | lr: 8.1632e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6222/  8460 | global iter:   6222/  8460 | loss: 0.1050 | ds_loss: 0.0000 | lr: 8.1563e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6223/  8460 | global iter:   6223/  8460 | loss: 0.0395 | ds_loss: 0.0000 | lr: 8.1494e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6224/  8460 | global iter:   6224/  8460 | loss: 0.1437 | ds_loss: 0.0000 | lr: 8.1426e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6224/  8460 | global iter:   6224/  8460 | loss: 0.0744 | ds_loss: 0.0000 | lr: 8.1426e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6225/  8460 | global iter:   6225/  8460 | loss: 0.0597 | ds_loss: 0.0000 | lr: 8.1357e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6226/  8460 | global iter:   6226/  8460 | loss: 0.1361 | ds_loss: 0.0000 | lr: 8.1289e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6227/  8460 | global iter:   6227/  8460 | loss: 0.0600 | ds_loss: 0.0000 | lr: 8.1220e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6228/  8460 | global iter:   6228/  8460 | loss: 0.0519 | ds_loss: 0.0000 | lr: 8.1152e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6228/  8460 | global iter:   6228/  8460 | loss: 0.0769 | ds_loss: 0.0000 | lr: 8.1152e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6229/  8460 | global iter:   6229/  8460 | loss: 0.0708 | ds_loss: 0.0000 | lr: 8.1084e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6230/  8460 | global iter:   6230/  8460 | loss: 0.2534 | ds_loss: 0.0000 | lr: 8.1015e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6231/  8460 | global iter:   6231/  8460 | loss: 0.1146 | ds_loss: 0.0000 | lr: 8.0947e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6232/  8460 | global iter:   6232/  8460 | loss: 0.0223 | ds_loss: 0.0000 | lr: 8.0879e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6232/  8460 | global iter:   6232/  8460 | loss: 0.1153 | ds_loss: 0.0000 | lr: 8.0879e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6233/  8460 | global iter:   6233/  8460 | loss: 0.2177 | ds_loss: 0.0000 | lr: 8.0810e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6234/  8460 | global iter:   6234/  8460 | loss: 0.2424 | ds_loss: 0.0000 | lr: 8.0742e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6235/  8460 | global iter:   6235/  8460 | loss: 0.0665 | ds_loss: 0.0000 | lr: 8.0674e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6236/  8460 | global iter:   6236/  8460 | loss: 0.0712 | ds_loss: 0.0000 | lr: 8.0605e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6236/  8460 | global iter:   6236/  8460 | loss: 0.1495 | ds_loss: 0.0000 | lr: 8.0605e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6237/  8460 | global iter:   6237/  8460 | loss: 0.1392 | ds_loss: 0.0000 | lr: 8.0537e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6238/  8460 | global iter:   6238/  8460 | loss: 0.1085 | ds_loss: 0.0000 | lr: 8.0469e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6239/  8460 | global iter:   6239/  8460 | loss: 0.0761 | ds_loss: 0.0000 | lr: 8.0401e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6240/  8460 | global iter:   6240/  8460 | loss: 0.1269 | ds_loss: 0.0000 | lr: 8.0333e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6240/  8460 | global iter:   6240/  8460 | loss: 0.1127 | ds_loss: 0.0000 | lr: 8.0333e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6241/  8460 | global iter:   6241/  8460 | loss: 0.1986 | ds_loss: 0.0000 | lr: 8.0265e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6242/  8460 | global iter:   6242/  8460 | loss: 0.0260 | ds_loss: 0.0000 | lr: 8.0196e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6243/  8460 | global iter:   6243/  8460 | loss: 0.1447 | ds_loss: 0.0000 | lr: 8.0128e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6244/  8460 | global iter:   6244/  8460 | loss: 0.0210 | ds_loss: 0.0000 | lr: 8.0060e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6244/  8460 | global iter:   6244/  8460 | loss: 0.0976 | ds_loss: 0.0000 | lr: 8.0060e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6245/  8460 | global iter:   6245/  8460 | loss: 0.1387 | ds_loss: 0.0000 | lr: 7.9992e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6246/  8460 | global iter:   6246/  8460 | loss: 0.0586 | ds_loss: 0.0000 | lr: 7.9924e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6247/  8460 | global iter:   6247/  8460 | loss: 0.2306 | ds_loss: 0.0000 | lr: 7.9856e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6248/  8460 | global iter:   6248/  8460 | loss: 0.0195 | ds_loss: 0.0000 | lr: 7.9788e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6248/  8460 | global iter:   6248/  8460 | loss: 0.1119 | ds_loss: 0.0000 | lr: 7.9788e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6249/  8460 | global iter:   6249/  8460 | loss: 0.0304 | ds_loss: 0.0000 | lr: 7.9720e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6250/  8460 | global iter:   6250/  8460 | loss: 0.0484 | ds_loss: 0.0000 | lr: 7.9652e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6251/  8460 | global iter:   6251/  8460 | loss: 0.0241 | ds_loss: 0.0000 | lr: 7.9585e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6252/  8460 | global iter:   6252/  8460 | loss: 0.0993 | ds_loss: 0.0000 | lr: 7.9517e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6252/  8460 | global iter:   6252/  8460 | loss: 0.0506 | ds_loss: 0.0000 | lr: 7.9517e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6253/  8460 | global iter:   6253/  8460 | loss: 0.0228 | ds_loss: 0.0000 | lr: 7.9449e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6254/  8460 | global iter:   6254/  8460 | loss: 0.0542 | ds_loss: 0.0000 | lr: 7.9381e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6255/  8460 | global iter:   6255/  8460 | loss: 0.1081 | ds_loss: 0.0000 | lr: 7.9313e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6256/  8460 | global iter:   6256/  8460 | loss: 0.3018 | ds_loss: 0.0000 | lr: 7.9245e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6256/  8460 | global iter:   6256/  8460 | loss: 0.1217 | ds_loss: 0.0000 | lr: 7.9245e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6257/  8460 | global iter:   6257/  8460 | loss: 0.0389 | ds_loss: 0.0000 | lr: 7.9178e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6258/  8460 | global iter:   6258/  8460 | loss: 0.0742 | ds_loss: 0.0000 | lr: 7.9110e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6259/  8460 | global iter:   6259/  8460 | loss: 0.0180 | ds_loss: 0.0000 | lr: 7.9042e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6260/  8460 | global iter:   6260/  8460 | loss: 0.0223 | ds_loss: 0.0000 | lr: 7.8975e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6260/  8460 | global iter:   6260/  8460 | loss: 0.0383 | ds_loss: 0.0000 | lr: 7.8975e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6261/  8460 | global iter:   6261/  8460 | loss: 0.0389 | ds_loss: 0.0000 | lr: 7.8907e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6262/  8460 | global iter:   6262/  8460 | loss: 0.0335 | ds_loss: 0.0000 | lr: 7.8839e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6263/  8460 | global iter:   6263/  8460 | loss: 0.1895 | ds_loss: 0.0000 | lr: 7.8772e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6264/  8460 | global iter:   6264/  8460 | loss: 0.0157 | ds_loss: 0.0000 | lr: 7.8704e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6264/  8460 | global iter:   6264/  8460 | loss: 0.0694 | ds_loss: 0.0000 | lr: 7.8704e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6265/  8460 | global iter:   6265/  8460 | loss: 0.1094 | ds_loss: 0.0000 | lr: 7.8636e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6266/  8460 | global iter:   6266/  8460 | loss: 0.0332 | ds_loss: 0.0000 | lr: 7.8569e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6267/  8460 | global iter:   6267/  8460 | loss: 0.0762 | ds_loss: 0.0000 | lr: 7.8501e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6268/  8460 | global iter:   6268/  8460 | loss: 0.0903 | ds_loss: 0.0000 | lr: 7.8434e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6268/  8460 | global iter:   6268/  8460 | loss: 0.0773 | ds_loss: 0.0000 | lr: 7.8434e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6269/  8460 | global iter:   6269/  8460 | loss: 0.0328 | ds_loss: 0.0000 | lr: 7.8366e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6270/  8460 | global iter:   6270/  8460 | loss: 0.1082 | ds_loss: 0.0000 | lr: 7.8299e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6271/  8460 | global iter:   6271/  8460 | loss: 0.0972 | ds_loss: 0.0000 | lr: 7.8232e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6272/  8460 | global iter:   6272/  8460 | loss: 0.0951 | ds_loss: 0.0000 | lr: 7.8164e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6272/  8460 | global iter:   6272/  8460 | loss: 0.0833 | ds_loss: 0.0000 | lr: 7.8164e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6273/  8460 | global iter:   6273/  8460 | loss: 0.0502 | ds_loss: 0.0000 | lr: 7.8097e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6274/  8460 | global iter:   6274/  8460 | loss: 0.0523 | ds_loss: 0.0000 | lr: 7.8029e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6275/  8460 | global iter:   6275/  8460 | loss: 0.1983 | ds_loss: 0.0000 | lr: 7.7962e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6276/  8460 | global iter:   6276/  8460 | loss: 0.1113 | ds_loss: 0.0000 | lr: 7.7895e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6276/  8460 | global iter:   6276/  8460 | loss: 0.1030 | ds_loss: 0.0000 | lr: 7.7895e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6277/  8460 | global iter:   6277/  8460 | loss: 0.1761 | ds_loss: 0.0000 | lr: 7.7828e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6278/  8460 | global iter:   6278/  8460 | loss: 0.0790 | ds_loss: 0.0000 | lr: 7.7760e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6279/  8460 | global iter:   6279/  8460 | loss: 0.0672 | ds_loss: 0.0000 | lr: 7.7693e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6280/  8460 | global iter:   6280/  8460 | loss: 0.2201 | ds_loss: 0.0000 | lr: 7.7626e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6280/  8460 | global iter:   6280/  8460 | loss: 0.1356 | ds_loss: 0.0000 | lr: 7.7626e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6281/  8460 | global iter:   6281/  8460 | loss: 0.1860 | ds_loss: 0.0000 | lr: 7.7559e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6282/  8460 | global iter:   6282/  8460 | loss: 0.1288 | ds_loss: 0.0000 | lr: 7.7491e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6283/  8460 | global iter:   6283/  8460 | loss: 0.1787 | ds_loss: 0.0000 | lr: 7.7424e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6284/  8460 | global iter:   6284/  8460 | loss: 0.0285 | ds_loss: 0.0000 | lr: 7.7357e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6284/  8460 | global iter:   6284/  8460 | loss: 0.1305 | ds_loss: 0.0000 | lr: 7.7357e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6285/  8460 | global iter:   6285/  8460 | loss: 0.0219 | ds_loss: 0.0000 | lr: 7.7290e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6286/  8460 | global iter:   6286/  8460 | loss: 0.0424 | ds_loss: 0.0000 | lr: 7.7223e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6287/  8460 | global iter:   6287/  8460 | loss: 0.2291 | ds_loss: 0.0000 | lr: 7.7156e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6288/  8460 | global iter:   6288/  8460 | loss: 0.0372 | ds_loss: 0.0000 | lr: 7.7089e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6288/  8460 | global iter:   6288/  8460 | loss: 0.0826 | ds_loss: 0.0000 | lr: 7.7089e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6289/  8460 | global iter:   6289/  8460 | loss: 0.1447 | ds_loss: 0.0000 | lr: 7.7022e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6290/  8460 | global iter:   6290/  8460 | loss: 0.0509 | ds_loss: 0.0000 | lr: 7.6955e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6291/  8460 | global iter:   6291/  8460 | loss: 0.0355 | ds_loss: 0.0000 | lr: 7.6888e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6292/  8460 | global iter:   6292/  8460 | loss: 0.1430 | ds_loss: 0.0000 | lr: 7.6821e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6292/  8460 | global iter:   6292/  8460 | loss: 0.0935 | ds_loss: 0.0000 | lr: 7.6821e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6293/  8460 | global iter:   6293/  8460 | loss: 0.0376 | ds_loss: 0.0000 | lr: 7.6754e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6294/  8460 | global iter:   6294/  8460 | loss: 0.0625 | ds_loss: 0.0000 | lr: 7.6687e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6295/  8460 | global iter:   6295/  8460 | loss: 0.0296 | ds_loss: 0.0000 | lr: 7.6621e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6296/  8460 | global iter:   6296/  8460 | loss: 0.0833 | ds_loss: 0.0000 | lr: 7.6554e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6296/  8460 | global iter:   6296/  8460 | loss: 0.0532 | ds_loss: 0.0000 | lr: 7.6554e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6297/  8460 | global iter:   6297/  8460 | loss: 0.1710 | ds_loss: 0.0000 | lr: 7.6487e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6298/  8460 | global iter:   6298/  8460 | loss: 0.1008 | ds_loss: 0.0000 | lr: 7.6420e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6299/  8460 | global iter:   6299/  8460 | loss: 0.2708 | ds_loss: 0.0000 | lr: 7.6353e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6300/  8460 | global iter:   6300/  8460 | loss: 0.1182 | ds_loss: 0.0000 | lr: 7.6287e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6300/  8460 | global iter:   6300/  8460 | loss: 0.1652 | ds_loss: 0.0000 | lr: 7.6287e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6301/  8460 | global iter:   6301/  8460 | loss: 0.0199 | ds_loss: 0.0000 | lr: 7.6220e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6302/  8460 | global iter:   6302/  8460 | loss: 0.0623 | ds_loss: 0.0000 | lr: 7.6153e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6303/  8460 | global iter:   6303/  8460 | loss: 0.0226 | ds_loss: 0.0000 | lr: 7.6087e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6304/  8460 | global iter:   6304/  8460 | loss: 0.0766 | ds_loss: 0.0000 | lr: 7.6020e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6304/  8460 | global iter:   6304/  8460 | loss: 0.0454 | ds_loss: 0.0000 | lr: 7.6020e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6305/  8460 | global iter:   6305/  8460 | loss: 0.1668 | ds_loss: 0.0000 | lr: 7.5953e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6306/  8460 | global iter:   6306/  8460 | loss: 0.1230 | ds_loss: 0.0000 | lr: 7.5887e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6307/  8460 | global iter:   6307/  8460 | loss: 0.0248 | ds_loss: 0.0000 | lr: 7.5820e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6308/  8460 | global iter:   6308/  8460 | loss: 0.0853 | ds_loss: 0.0000 | lr: 7.5754e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6308/  8460 | global iter:   6308/  8460 | loss: 0.1000 | ds_loss: 0.0000 | lr: 7.5754e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6309/  8460 | global iter:   6309/  8460 | loss: 0.0879 | ds_loss: 0.0000 | lr: 7.5687e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6310/  8460 | global iter:   6310/  8460 | loss: 0.1622 | ds_loss: 0.0000 | lr: 7.5621e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6311/  8460 | global iter:   6311/  8460 | loss: 0.0995 | ds_loss: 0.0000 | lr: 7.5554e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6312/  8460 | global iter:   6312/  8460 | loss: 0.2380 | ds_loss: 0.0000 | lr: 7.5488e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6312/  8460 | global iter:   6312/  8460 | loss: 0.1469 | ds_loss: 0.0000 | lr: 7.5488e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6313/  8460 | global iter:   6313/  8460 | loss: 0.1823 | ds_loss: 0.0000 | lr: 7.5421e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6314/  8460 | global iter:   6314/  8460 | loss: 0.0850 | ds_loss: 0.0000 | lr: 7.5355e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6315/  8460 | global iter:   6315/  8460 | loss: 0.0862 | ds_loss: 0.0000 | lr: 7.5289e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6316/  8460 | global iter:   6316/  8460 | loss: 0.2281 | ds_loss: 0.0000 | lr: 7.5222e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6316/  8460 | global iter:   6316/  8460 | loss: 0.1454 | ds_loss: 0.0000 | lr: 7.5222e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6317/  8460 | global iter:   6317/  8460 | loss: 0.2346 | ds_loss: 0.0000 | lr: 7.5156e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6318/  8460 | global iter:   6318/  8460 | loss: 0.0112 | ds_loss: 0.0000 | lr: 7.5090e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6319/  8460 | global iter:   6319/  8460 | loss: 0.0672 | ds_loss: 0.0000 | lr: 7.5023e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6320/  8460 | global iter:   6320/  8460 | loss: 0.1023 | ds_loss: 0.0000 | lr: 7.4957e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6320/  8460 | global iter:   6320/  8460 | loss: 0.1039 | ds_loss: 0.0000 | lr: 7.4957e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6321/  8460 | global iter:   6321/  8460 | loss: 0.0299 | ds_loss: 0.0000 | lr: 7.4891e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6322/  8460 | global iter:   6322/  8460 | loss: 0.1858 | ds_loss: 0.0000 | lr: 7.4825e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6323/  8460 | global iter:   6323/  8460 | loss: 0.0775 | ds_loss: 0.0000 | lr: 7.4758e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6324/  8460 | global iter:   6324/  8460 | loss: 0.0833 | ds_loss: 0.0000 | lr: 7.4692e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6324/  8460 | global iter:   6324/  8460 | loss: 0.0941 | ds_loss: 0.0000 | lr: 7.4692e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6325/  8460 | global iter:   6325/  8460 | loss: 0.0480 | ds_loss: 0.0000 | lr: 7.4626e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6326/  8460 | global iter:   6326/  8460 | loss: 0.1503 | ds_loss: 0.0000 | lr: 7.4560e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6327/  8460 | global iter:   6327/  8460 | loss: 0.0300 | ds_loss: 0.0000 | lr: 7.4494e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6328/  8460 | global iter:   6328/  8460 | loss: 0.0194 | ds_loss: 0.0000 | lr: 7.4428e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6328/  8460 | global iter:   6328/  8460 | loss: 0.0619 | ds_loss: 0.0000 | lr: 7.4428e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6329/  8460 | global iter:   6329/  8460 | loss: 0.0562 | ds_loss: 0.0000 | lr: 7.4362e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6330/  8460 | global iter:   6330/  8460 | loss: 0.2401 | ds_loss: 0.0000 | lr: 7.4296e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6331/  8460 | global iter:   6331/  8460 | loss: 0.0475 | ds_loss: 0.0000 | lr: 7.4230e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6332/  8460 | global iter:   6332/  8460 | loss: 0.0172 | ds_loss: 0.0000 | lr: 7.4164e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6332/  8460 | global iter:   6332/  8460 | loss: 0.0903 | ds_loss: 0.0000 | lr: 7.4164e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6333/  8460 | global iter:   6333/  8460 | loss: 0.0389 | ds_loss: 0.0000 | lr: 7.4098e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6334/  8460 | global iter:   6334/  8460 | loss: 0.0544 | ds_loss: 0.0000 | lr: 7.4032e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6335/  8460 | global iter:   6335/  8460 | loss: 0.0560 | ds_loss: 0.0000 | lr: 7.3966e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6336/  8460 | global iter:   6336/  8460 | loss: 0.0386 | ds_loss: 0.0000 | lr: 7.3900e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6336/  8460 | global iter:   6336/  8460 | loss: 0.0470 | ds_loss: 0.0000 | lr: 7.3900e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6337/  8460 | global iter:   6337/  8460 | loss: 0.0764 | ds_loss: 0.0000 | lr: 7.3834e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6338/  8460 | global iter:   6338/  8460 | loss: 0.0715 | ds_loss: 0.0000 | lr: 7.3769e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6339/  8460 | global iter:   6339/  8460 | loss: 0.0207 | ds_loss: 0.0000 | lr: 7.3703e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6340/  8460 | global iter:   6340/  8460 | loss: 0.0066 | ds_loss: 0.0000 | lr: 7.3637e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6340/  8460 | global iter:   6340/  8460 | loss: 0.0438 | ds_loss: 0.0000 | lr: 7.3637e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6341/  8460 | global iter:   6341/  8460 | loss: 0.0044 | ds_loss: 0.0000 | lr: 7.3571e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6342/  8460 | global iter:   6342/  8460 | loss: 0.2428 | ds_loss: 0.0000 | lr: 7.3506e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6343/  8460 | global iter:   6343/  8460 | loss: 0.0455 | ds_loss: 0.0000 | lr: 7.3440e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6344/  8460 | global iter:   6344/  8460 | loss: 0.1885 | ds_loss: 0.0000 | lr: 7.3374e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6344/  8460 | global iter:   6344/  8460 | loss: 0.1203 | ds_loss: 0.0000 | lr: 7.3374e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6345/  8460 | global iter:   6345/  8460 | loss: 0.0949 | ds_loss: 0.0000 | lr: 7.3309e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6346/  8460 | global iter:   6346/  8460 | loss: 0.0491 | ds_loss: 0.0000 | lr: 7.3243e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6347/  8460 | global iter:   6347/  8460 | loss: 0.0224 | ds_loss: 0.0000 | lr: 7.3177e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6348/  8460 | global iter:   6348/  8460 | loss: 0.2632 | ds_loss: 0.0000 | lr: 7.3112e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6348/  8460 | global iter:   6348/  8460 | loss: 0.1074 | ds_loss: 0.0000 | lr: 7.3112e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6349/  8460 | global iter:   6349/  8460 | loss: 0.0563 | ds_loss: 0.0000 | lr: 7.3046e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6350/  8460 | global iter:   6350/  8460 | loss: 0.0379 | ds_loss: 0.0000 | lr: 7.2981e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6351/  8460 | global iter:   6351/  8460 | loss: 0.1418 | ds_loss: 0.0000 | lr: 7.2915e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6352/  8460 | global iter:   6352/  8460 | loss: 0.2969 | ds_loss: 0.0000 | lr: 7.2850e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6352/  8460 | global iter:   6352/  8460 | loss: 0.1332 | ds_loss: 0.0000 | lr: 7.2850e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6353/  8460 | global iter:   6353/  8460 | loss: 0.1367 | ds_loss: 0.0000 | lr: 7.2784e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6354/  8460 | global iter:   6354/  8460 | loss: 0.1031 | ds_loss: 0.0000 | lr: 7.2719e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6355/  8460 | global iter:   6355/  8460 | loss: 0.0514 | ds_loss: 0.0000 | lr: 7.2654e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6356/  8460 | global iter:   6356/  8460 | loss: 0.1047 | ds_loss: 0.0000 | lr: 7.2588e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6356/  8460 | global iter:   6356/  8460 | loss: 0.0990 | ds_loss: 0.0000 | lr: 7.2588e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6357/  8460 | global iter:   6357/  8460 | loss: 0.1216 | ds_loss: 0.0000 | lr: 7.2523e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6358/  8460 | global iter:   6358/  8460 | loss: 0.0466 | ds_loss: 0.0000 | lr: 7.2458e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6359/  8460 | global iter:   6359/  8460 | loss: 0.0584 | ds_loss: 0.0000 | lr: 7.2392e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6360/  8460 | global iter:   6360/  8460 | loss: 0.0825 | ds_loss: 0.0000 | lr: 7.2327e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6360/  8460 | global iter:   6360/  8460 | loss: 0.0773 | ds_loss: 0.0000 | lr: 7.2327e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6361/  8460 | global iter:   6361/  8460 | loss: 0.0211 | ds_loss: 0.0000 | lr: 7.2262e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6362/  8460 | global iter:   6362/  8460 | loss: 0.0317 | ds_loss: 0.0000 | lr: 7.2196e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6363/  8460 | global iter:   6363/  8460 | loss: 0.1223 | ds_loss: 0.0000 | lr: 7.2131e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6364/  8460 | global iter:   6364/  8460 | loss: 0.0823 | ds_loss: 0.0000 | lr: 7.2066e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6364/  8460 | global iter:   6364/  8460 | loss: 0.0643 | ds_loss: 0.0000 | lr: 7.2066e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6365/  8460 | global iter:   6365/  8460 | loss: 0.0081 | ds_loss: 0.0000 | lr: 7.2001e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6366/  8460 | global iter:   6366/  8460 | loss: 0.0321 | ds_loss: 0.0000 | lr: 7.1936e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6367/  8460 | global iter:   6367/  8460 | loss: 0.1339 | ds_loss: 0.0000 | lr: 7.1871e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6368/  8460 | global iter:   6368/  8460 | loss: 0.0412 | ds_loss: 0.0000 | lr: 7.1806e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6368/  8460 | global iter:   6368/  8460 | loss: 0.0538 | ds_loss: 0.0000 | lr: 7.1806e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6369/  8460 | global iter:   6369/  8460 | loss: 0.2204 | ds_loss: 0.0000 | lr: 7.1741e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6370/  8460 | global iter:   6370/  8460 | loss: 0.0221 | ds_loss: 0.0000 | lr: 7.1675e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6371/  8460 | global iter:   6371/  8460 | loss: 0.0087 | ds_loss: 0.0000 | lr: 7.1610e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6372/  8460 | global iter:   6372/  8460 | loss: 0.0788 | ds_loss: 0.0000 | lr: 7.1546e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6372/  8460 | global iter:   6372/  8460 | loss: 0.0825 | ds_loss: 0.0000 | lr: 7.1546e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6373/  8460 | global iter:   6373/  8460 | loss: 0.0399 | ds_loss: 0.0000 | lr: 7.1481e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6374/  8460 | global iter:   6374/  8460 | loss: 0.1103 | ds_loss: 0.0000 | lr: 7.1416e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6375/  8460 | global iter:   6375/  8460 | loss: 0.0063 | ds_loss: 0.0000 | lr: 7.1351e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6376/  8460 | global iter:   6376/  8460 | loss: 0.1251 | ds_loss: 0.0000 | lr: 7.1286e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6376/  8460 | global iter:   6376/  8460 | loss: 0.0704 | ds_loss: 0.0000 | lr: 7.1286e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6377/  8460 | global iter:   6377/  8460 | loss: 0.0850 | ds_loss: 0.0000 | lr: 7.1221e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6378/  8460 | global iter:   6378/  8460 | loss: 0.0632 | ds_loss: 0.0000 | lr: 7.1156e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6379/  8460 | global iter:   6379/  8460 | loss: 0.0325 | ds_loss: 0.0000 | lr: 7.1091e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6380/  8460 | global iter:   6380/  8460 | loss: 0.0612 | ds_loss: 0.0000 | lr: 7.1027e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6380/  8460 | global iter:   6380/  8460 | loss: 0.0605 | ds_loss: 0.0000 | lr: 7.1027e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6381/  8460 | global iter:   6381/  8460 | loss: 0.0423 | ds_loss: 0.0000 | lr: 7.0962e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6382/  8460 | global iter:   6382/  8460 | loss: 0.0605 | ds_loss: 0.0000 | lr: 7.0897e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6383/  8460 | global iter:   6383/  8460 | loss: 0.0085 | ds_loss: 0.0000 | lr: 7.0832e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6384/  8460 | global iter:   6384/  8460 | loss: 0.0682 | ds_loss: 0.0000 | lr: 7.0768e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6384/  8460 | global iter:   6384/  8460 | loss: 0.0449 | ds_loss: 0.0000 | lr: 7.0768e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6385/  8460 | global iter:   6385/  8460 | loss: 0.0136 | ds_loss: 0.0000 | lr: 7.0703e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6386/  8460 | global iter:   6386/  8460 | loss: 0.0346 | ds_loss: 0.0000 | lr: 7.0638e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6387/  8460 | global iter:   6387/  8460 | loss: 0.0468 | ds_loss: 0.0000 | lr: 7.0574e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6388/  8460 | global iter:   6388/  8460 | loss: 0.2057 | ds_loss: 0.0000 | lr: 7.0509e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6388/  8460 | global iter:   6388/  8460 | loss: 0.0752 | ds_loss: 0.0000 | lr: 7.0509e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6389/  8460 | global iter:   6389/  8460 | loss: 0.2231 | ds_loss: 0.0000 | lr: 7.0445e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6390/  8460 | global iter:   6390/  8460 | loss: 0.2030 | ds_loss: 0.0000 | lr: 7.0380e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6391/  8460 | global iter:   6391/  8460 | loss: 0.0217 | ds_loss: 0.0000 | lr: 7.0316e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6392/  8460 | global iter:   6392/  8460 | loss: 0.0588 | ds_loss: 0.0000 | lr: 7.0251e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6392/  8460 | global iter:   6392/  8460 | loss: 0.1266 | ds_loss: 0.0000 | lr: 7.0251e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6393/  8460 | global iter:   6393/  8460 | loss: 0.0387 | ds_loss: 0.0000 | lr: 7.0187e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6394/  8460 | global iter:   6394/  8460 | loss: 0.1033 | ds_loss: 0.0000 | lr: 7.0122e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6395/  8460 | global iter:   6395/  8460 | loss: 0.0283 | ds_loss: 0.0000 | lr: 7.0058e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6396/  8460 | global iter:   6396/  8460 | loss: 0.0462 | ds_loss: 0.0000 | lr: 6.9993e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6396/  8460 | global iter:   6396/  8460 | loss: 0.0541 | ds_loss: 0.0000 | lr: 6.9993e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6397/  8460 | global iter:   6397/  8460 | loss: 0.0549 | ds_loss: 0.0000 | lr: 6.9929e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6398/  8460 | global iter:   6398/  8460 | loss: 0.1535 | ds_loss: 0.0000 | lr: 6.9865e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6399/  8460 | global iter:   6399/  8460 | loss: 0.0974 | ds_loss: 0.0000 | lr: 6.9800e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6400/  8460 | global iter:   6400/  8460 | loss: 0.0794 | ds_loss: 0.0000 | lr: 6.9736e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6400/  8460 | global iter:   6400/  8460 | loss: 0.0963 | ds_loss: 0.0000 | lr: 6.9736e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6401/  8460 | global iter:   6401/  8460 | loss: 0.0495 | ds_loss: 0.0000 | lr: 6.9672e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6402/  8460 | global iter:   6402/  8460 | loss: 0.0344 | ds_loss: 0.0000 | lr: 6.9607e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6403/  8460 | global iter:   6403/  8460 | loss: 0.1206 | ds_loss: 0.0000 | lr: 6.9543e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6404/  8460 | global iter:   6404/  8460 | loss: 0.0723 | ds_loss: 0.0000 | lr: 6.9479e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6404/  8460 | global iter:   6404/  8460 | loss: 0.0692 | ds_loss: 0.0000 | lr: 6.9479e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6405/  8460 | global iter:   6405/  8460 | loss: 0.0755 | ds_loss: 0.0000 | lr: 6.9415e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6406/  8460 | global iter:   6406/  8460 | loss: 0.1816 | ds_loss: 0.0000 | lr: 6.9351e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6407/  8460 | global iter:   6407/  8460 | loss: 0.1300 | ds_loss: 0.0000 | lr: 6.9287e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6408/  8460 | global iter:   6408/  8460 | loss: 0.0959 | ds_loss: 0.0000 | lr: 6.9223e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6408/  8460 | global iter:   6408/  8460 | loss: 0.1207 | ds_loss: 0.0000 | lr: 6.9223e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6409/  8460 | global iter:   6409/  8460 | loss: 0.1978 | ds_loss: 0.0000 | lr: 6.9159e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6410/  8460 | global iter:   6410/  8460 | loss: 0.2447 | ds_loss: 0.0000 | lr: 6.9094e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6411/  8460 | global iter:   6411/  8460 | loss: 0.0766 | ds_loss: 0.0000 | lr: 6.9030e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6412/  8460 | global iter:   6412/  8460 | loss: 0.1284 | ds_loss: 0.0000 | lr: 6.8966e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6412/  8460 | global iter:   6412/  8460 | loss: 0.1619 | ds_loss: 0.0000 | lr: 6.8966e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6413/  8460 | global iter:   6413/  8460 | loss: 0.0306 | ds_loss: 0.0000 | lr: 6.8902e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6414/  8460 | global iter:   6414/  8460 | loss: 0.0229 | ds_loss: 0.0000 | lr: 6.8839e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6415/  8460 | global iter:   6415/  8460 | loss: 0.0471 | ds_loss: 0.0000 | lr: 6.8775e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6416/  8460 | global iter:   6416/  8460 | loss: 0.0577 | ds_loss: 0.0000 | lr: 6.8711e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6416/  8460 | global iter:   6416/  8460 | loss: 0.0396 | ds_loss: 0.0000 | lr: 6.8711e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6417/  8460 | global iter:   6417/  8460 | loss: 0.0794 | ds_loss: 0.0000 | lr: 6.8647e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6418/  8460 | global iter:   6418/  8460 | loss: 0.0893 | ds_loss: 0.0000 | lr: 6.8583e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6419/  8460 | global iter:   6419/  8460 | loss: 0.0263 | ds_loss: 0.0000 | lr: 6.8519e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6420/  8460 | global iter:   6420/  8460 | loss: 0.1026 | ds_loss: 0.0000 | lr: 6.8455e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6420/  8460 | global iter:   6420/  8460 | loss: 0.0744 | ds_loss: 0.0000 | lr: 6.8455e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6421/  8460 | global iter:   6421/  8460 | loss: 0.0173 | ds_loss: 0.0000 | lr: 6.8392e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6422/  8460 | global iter:   6422/  8460 | loss: 0.1697 | ds_loss: 0.0000 | lr: 6.8328e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6423/  8460 | global iter:   6423/  8460 | loss: 0.1030 | ds_loss: 0.0000 | lr: 6.8264e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6424/  8460 | global iter:   6424/  8460 | loss: 0.0090 | ds_loss: 0.0000 | lr: 6.8201e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6424/  8460 | global iter:   6424/  8460 | loss: 0.0747 | ds_loss: 0.0000 | lr: 6.8201e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6425/  8460 | global iter:   6425/  8460 | loss: 0.0568 | ds_loss: 0.0000 | lr: 6.8137e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6426/  8460 | global iter:   6426/  8460 | loss: 0.0344 | ds_loss: 0.0000 | lr: 6.8073e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6427/  8460 | global iter:   6427/  8460 | loss: 0.4865 | ds_loss: 0.0000 | lr: 6.8010e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6428/  8460 | global iter:   6428/  8460 | loss: 0.0224 | ds_loss: 0.0000 | lr: 6.7946e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6428/  8460 | global iter:   6428/  8460 | loss: 0.1500 | ds_loss: 0.0000 | lr: 6.7946e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6429/  8460 | global iter:   6429/  8460 | loss: 0.0559 | ds_loss: 0.0000 | lr: 6.7882e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6430/  8460 | global iter:   6430/  8460 | loss: 0.0808 | ds_loss: 0.0000 | lr: 6.7819e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6431/  8460 | global iter:   6431/  8460 | loss: 0.0306 | ds_loss: 0.0000 | lr: 6.7755e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6432/  8460 | global iter:   6432/  8460 | loss: 0.0095 | ds_loss: 0.0000 | lr: 6.7692e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6432/  8460 | global iter:   6432/  8460 | loss: 0.0442 | ds_loss: 0.0000 | lr: 6.7692e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6433/  8460 | global iter:   6433/  8460 | loss: 0.0538 | ds_loss: 0.0000 | lr: 6.7628e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6434/  8460 | global iter:   6434/  8460 | loss: 0.0316 | ds_loss: 0.0000 | lr: 6.7565e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6435/  8460 | global iter:   6435/  8460 | loss: 0.1409 | ds_loss: 0.0000 | lr: 6.7502e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6436/  8460 | global iter:   6436/  8460 | loss: 0.0876 | ds_loss: 0.0000 | lr: 6.7438e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6436/  8460 | global iter:   6436/  8460 | loss: 0.0785 | ds_loss: 0.0000 | lr: 6.7438e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6437/  8460 | global iter:   6437/  8460 | loss: 0.0241 | ds_loss: 0.0000 | lr: 6.7375e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6438/  8460 | global iter:   6438/  8460 | loss: 0.1802 | ds_loss: 0.0000 | lr: 6.7311e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6439/  8460 | global iter:   6439/  8460 | loss: 0.0208 | ds_loss: 0.0000 | lr: 6.7248e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6440/  8460 | global iter:   6440/  8460 | loss: 0.0740 | ds_loss: 0.0000 | lr: 6.7185e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6440/  8460 | global iter:   6440/  8460 | loss: 0.0748 | ds_loss: 0.0000 | lr: 6.7185e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6441/  8460 | global iter:   6441/  8460 | loss: 0.0543 | ds_loss: 0.0000 | lr: 6.7122e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6442/  8460 | global iter:   6442/  8460 | loss: 0.3171 | ds_loss: 0.0000 | lr: 6.7058e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6443/  8460 | global iter:   6443/  8460 | loss: 0.1130 | ds_loss: 0.0000 | lr: 6.6995e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6444/  8460 | global iter:   6444/  8460 | loss: 0.2984 | ds_loss: 0.0000 | lr: 6.6932e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6444/  8460 | global iter:   6444/  8460 | loss: 0.1957 | ds_loss: 0.0000 | lr: 6.6932e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6445/  8460 | global iter:   6445/  8460 | loss: 0.0733 | ds_loss: 0.0000 | lr: 6.6869e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6446/  8460 | global iter:   6446/  8460 | loss: 0.0778 | ds_loss: 0.0000 | lr: 6.6806e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6447/  8460 | global iter:   6447/  8460 | loss: 0.1024 | ds_loss: 0.0000 | lr: 6.6743e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6448/  8460 | global iter:   6448/  8460 | loss: 0.0168 | ds_loss: 0.0000 | lr: 6.6679e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6448/  8460 | global iter:   6448/  8460 | loss: 0.0676 | ds_loss: 0.0000 | lr: 6.6679e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6449/  8460 | global iter:   6449/  8460 | loss: 0.1722 | ds_loss: 0.0000 | lr: 6.6616e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6450/  8460 | global iter:   6450/  8460 | loss: 0.0159 | ds_loss: 0.0000 | lr: 6.6553e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6451/  8460 | global iter:   6451/  8460 | loss: 0.1456 | ds_loss: 0.0000 | lr: 6.6490e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6452/  8460 | global iter:   6452/  8460 | loss: 0.1058 | ds_loss: 0.0000 | lr: 6.6427e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6452/  8460 | global iter:   6452/  8460 | loss: 0.1099 | ds_loss: 0.0000 | lr: 6.6427e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6453/  8460 | global iter:   6453/  8460 | loss: 0.0587 | ds_loss: 0.0000 | lr: 6.6364e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6454/  8460 | global iter:   6454/  8460 | loss: 0.0534 | ds_loss: 0.0000 | lr: 6.6301e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6455/  8460 | global iter:   6455/  8460 | loss: 0.0254 | ds_loss: 0.0000 | lr: 6.6239e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6456/  8460 | global iter:   6456/  8460 | loss: 0.0128 | ds_loss: 0.0000 | lr: 6.6176e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6456/  8460 | global iter:   6456/  8460 | loss: 0.0376 | ds_loss: 0.0000 | lr: 6.6176e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6457/  8460 | global iter:   6457/  8460 | loss: 0.1523 | ds_loss: 0.0000 | lr: 6.6113e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6458/  8460 | global iter:   6458/  8460 | loss: 0.0877 | ds_loss: 0.0000 | lr: 6.6050e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6459/  8460 | global iter:   6459/  8460 | loss: 0.1141 | ds_loss: 0.0000 | lr: 6.5987e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6460/  8460 | global iter:   6460/  8460 | loss: 0.0499 | ds_loss: 0.0000 | lr: 6.5924e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6460/  8460 | global iter:   6460/  8460 | loss: 0.1010 | ds_loss: 0.0000 | lr: 6.5924e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6461/  8460 | global iter:   6461/  8460 | loss: 0.0768 | ds_loss: 0.0000 | lr: 6.5862e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6462/  8460 | global iter:   6462/  8460 | loss: 0.0775 | ds_loss: 0.0000 | lr: 6.5799e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6463/  8460 | global iter:   6463/  8460 | loss: 0.0717 | ds_loss: 0.0000 | lr: 6.5736e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6464/  8460 | global iter:   6464/  8460 | loss: 0.0311 | ds_loss: 0.0000 | lr: 6.5673e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6464/  8460 | global iter:   6464/  8460 | loss: 0.0643 | ds_loss: 0.0000 | lr: 6.5673e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6465/  8460 | global iter:   6465/  8460 | loss: 0.0677 | ds_loss: 0.0000 | lr: 6.5611e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6466/  8460 | global iter:   6466/  8460 | loss: 0.0306 | ds_loss: 0.0000 | lr: 6.5548e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6467/  8460 | global iter:   6467/  8460 | loss: 0.1159 | ds_loss: 0.0000 | lr: 6.5486e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6468/  8460 | global iter:   6468/  8460 | loss: 0.0140 | ds_loss: 0.0000 | lr: 6.5423e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6468/  8460 | global iter:   6468/  8460 | loss: 0.0570 | ds_loss: 0.0000 | lr: 6.5423e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6469/  8460 | global iter:   6469/  8460 | loss: 0.0387 | ds_loss: 0.0000 | lr: 6.5360e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6470/  8460 | global iter:   6470/  8460 | loss: 0.0036 | ds_loss: 0.0000 | lr: 6.5298e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6471/  8460 | global iter:   6471/  8460 | loss: 0.0391 | ds_loss: 0.0000 | lr: 6.5235e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6472/  8460 | global iter:   6472/  8460 | loss: 0.0716 | ds_loss: 0.0000 | lr: 6.5173e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6472/  8460 | global iter:   6472/  8460 | loss: 0.0382 | ds_loss: 0.0000 | lr: 6.5173e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6473/  8460 | global iter:   6473/  8460 | loss: 0.1243 | ds_loss: 0.0000 | lr: 6.5111e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6474/  8460 | global iter:   6474/  8460 | loss: 0.0802 | ds_loss: 0.0000 | lr: 6.5048e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6475/  8460 | global iter:   6475/  8460 | loss: 0.0821 | ds_loss: 0.0000 | lr: 6.4986e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6476/  8460 | global iter:   6476/  8460 | loss: 0.0450 | ds_loss: 0.0000 | lr: 6.4923e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6476/  8460 | global iter:   6476/  8460 | loss: 0.0829 | ds_loss: 0.0000 | lr: 6.4923e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6477/  8460 | global iter:   6477/  8460 | loss: 0.1922 | ds_loss: 0.0000 | lr: 6.4861e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6478/  8460 | global iter:   6478/  8460 | loss: 0.0419 | ds_loss: 0.0000 | lr: 6.4799e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6479/  8460 | global iter:   6479/  8460 | loss: 0.0811 | ds_loss: 0.0000 | lr: 6.4736e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6480/  8460 | global iter:   6480/  8460 | loss: 0.0479 | ds_loss: 0.0000 | lr: 6.4674e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6480/  8460 | global iter:   6480/  8460 | loss: 0.0908 | ds_loss: 0.0000 | lr: 6.4674e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6481/  8460 | global iter:   6481/  8460 | loss: 0.1121 | ds_loss: 0.0000 | lr: 6.4612e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6482/  8460 | global iter:   6482/  8460 | loss: 0.2088 | ds_loss: 0.0000 | lr: 6.4550e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6483/  8460 | global iter:   6483/  8460 | loss: 0.1309 | ds_loss: 0.0000 | lr: 6.4487e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6484/  8460 | global iter:   6484/  8460 | loss: 0.0976 | ds_loss: 0.0000 | lr: 6.4425e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6484/  8460 | global iter:   6484/  8460 | loss: 0.1373 | ds_loss: 0.0000 | lr: 6.4425e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6485/  8460 | global iter:   6485/  8460 | loss: 0.0352 | ds_loss: 0.0000 | lr: 6.4363e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6486/  8460 | global iter:   6486/  8460 | loss: 0.0359 | ds_loss: 0.0000 | lr: 6.4301e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6487/  8460 | global iter:   6487/  8460 | loss: 0.1628 | ds_loss: 0.0000 | lr: 6.4239e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6488/  8460 | global iter:   6488/  8460 | loss: 0.0078 | ds_loss: 0.0000 | lr: 6.4177e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6488/  8460 | global iter:   6488/  8460 | loss: 0.0604 | ds_loss: 0.0000 | lr: 6.4177e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6489/  8460 | global iter:   6489/  8460 | loss: 0.0634 | ds_loss: 0.0000 | lr: 6.4115e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6490/  8460 | global iter:   6490/  8460 | loss: 0.0388 | ds_loss: 0.0000 | lr: 6.4053e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6491/  8460 | global iter:   6491/  8460 | loss: 0.0712 | ds_loss: 0.0000 | lr: 6.3991e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6492/  8460 | global iter:   6492/  8460 | loss: 0.0337 | ds_loss: 0.0000 | lr: 6.3929e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6492/  8460 | global iter:   6492/  8460 | loss: 0.0518 | ds_loss: 0.0000 | lr: 6.3929e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6493/  8460 | global iter:   6493/  8460 | loss: 0.0152 | ds_loss: 0.0000 | lr: 6.3867e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6494/  8460 | global iter:   6494/  8460 | loss: 0.0428 | ds_loss: 0.0000 | lr: 6.3805e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6495/  8460 | global iter:   6495/  8460 | loss: 0.0790 | ds_loss: 0.0000 | lr: 6.3743e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6496/  8460 | global iter:   6496/  8460 | loss: 0.0978 | ds_loss: 0.0000 | lr: 6.3681e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6496/  8460 | global iter:   6496/  8460 | loss: 0.0587 | ds_loss: 0.0000 | lr: 6.3681e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6497/  8460 | global iter:   6497/  8460 | loss: 0.1537 | ds_loss: 0.0000 | lr: 6.3619e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6498/  8460 | global iter:   6498/  8460 | loss: 0.1412 | ds_loss: 0.0000 | lr: 6.3558e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6499/  8460 | global iter:   6499/  8460 | loss: 0.0035 | ds_loss: 0.0000 | lr: 6.3496e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6500/  8460 | global iter:   6500/  8460 | loss: 0.1244 | ds_loss: 0.0000 | lr: 6.3434e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6500/  8460 | global iter:   6500/  8460 | loss: 0.1057 | ds_loss: 0.0000 | lr: 6.3434e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6501/  8460 | global iter:   6501/  8460 | loss: 0.1417 | ds_loss: 0.0000 | lr: 6.3372e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6502/  8460 | global iter:   6502/  8460 | loss: 0.1696 | ds_loss: 0.0000 | lr: 6.3311e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6503/  8460 | global iter:   6503/  8460 | loss: 0.0347 | ds_loss: 0.0000 | lr: 6.3249e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6504/  8460 | global iter:   6504/  8460 | loss: 0.1769 | ds_loss: 0.0000 | lr: 6.3187e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6504/  8460 | global iter:   6504/  8460 | loss: 0.1307 | ds_loss: 0.0000 | lr: 6.3187e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6505/  8460 | global iter:   6505/  8460 | loss: 0.0721 | ds_loss: 0.0000 | lr: 6.3126e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6506/  8460 | global iter:   6506/  8460 | loss: 0.1465 | ds_loss: 0.0000 | lr: 6.3064e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6507/  8460 | global iter:   6507/  8460 | loss: 0.0373 | ds_loss: 0.0000 | lr: 6.3002e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6508/  8460 | global iter:   6508/  8460 | loss: 0.0598 | ds_loss: 0.0000 | lr: 6.2941e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6508/  8460 | global iter:   6508/  8460 | loss: 0.0789 | ds_loss: 0.0000 | lr: 6.2941e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6509/  8460 | global iter:   6509/  8460 | loss: 0.0418 | ds_loss: 0.0000 | lr: 6.2879e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6510/  8460 | global iter:   6510/  8460 | loss: 0.1247 | ds_loss: 0.0000 | lr: 6.2818e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6511/  8460 | global iter:   6511/  8460 | loss: 0.1203 | ds_loss: 0.0000 | lr: 6.2756e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6512/  8460 | global iter:   6512/  8460 | loss: 0.0091 | ds_loss: 0.0000 | lr: 6.2695e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6512/  8460 | global iter:   6512/  8460 | loss: 0.0740 | ds_loss: 0.0000 | lr: 6.2695e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6513/  8460 | global iter:   6513/  8460 | loss: 0.1363 | ds_loss: 0.0000 | lr: 6.2633e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6514/  8460 | global iter:   6514/  8460 | loss: 0.0777 | ds_loss: 0.0000 | lr: 6.2572e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6515/  8460 | global iter:   6515/  8460 | loss: 0.0459 | ds_loss: 0.0000 | lr: 6.2511e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6516/  8460 | global iter:   6516/  8460 | loss: 0.0109 | ds_loss: 0.0000 | lr: 6.2449e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6516/  8460 | global iter:   6516/  8460 | loss: 0.0677 | ds_loss: 0.0000 | lr: 6.2449e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6517/  8460 | global iter:   6517/  8460 | loss: 0.0788 | ds_loss: 0.0000 | lr: 6.2388e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6518/  8460 | global iter:   6518/  8460 | loss: 0.2217 | ds_loss: 0.0000 | lr: 6.2327e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6519/  8460 | global iter:   6519/  8460 | loss: 0.0734 | ds_loss: 0.0000 | lr: 6.2265e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6520/  8460 | global iter:   6520/  8460 | loss: 0.0125 | ds_loss: 0.0000 | lr: 6.2204e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6520/  8460 | global iter:   6520/  8460 | loss: 0.0966 | ds_loss: 0.0000 | lr: 6.2204e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6521/  8460 | global iter:   6521/  8460 | loss: 0.0181 | ds_loss: 0.0000 | lr: 6.2143e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6522/  8460 | global iter:   6522/  8460 | loss: 0.1821 | ds_loss: 0.0000 | lr: 6.2082e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6523/  8460 | global iter:   6523/  8460 | loss: 0.0326 | ds_loss: 0.0000 | lr: 6.2021e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6524/  8460 | global iter:   6524/  8460 | loss: 0.1006 | ds_loss: 0.0000 | lr: 6.1959e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6524/  8460 | global iter:   6524/  8460 | loss: 0.0834 | ds_loss: 0.0000 | lr: 6.1959e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6525/  8460 | global iter:   6525/  8460 | loss: 0.0725 | ds_loss: 0.0000 | lr: 6.1898e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6526/  8460 | global iter:   6526/  8460 | loss: 0.0350 | ds_loss: 0.0000 | lr: 6.1837e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6527/  8460 | global iter:   6527/  8460 | loss: 0.0598 | ds_loss: 0.0000 | lr: 6.1776e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6528/  8460 | global iter:   6528/  8460 | loss: 0.0298 | ds_loss: 0.0000 | lr: 6.1715e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6528/  8460 | global iter:   6528/  8460 | loss: 0.0493 | ds_loss: 0.0000 | lr: 6.1715e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6529/  8460 | global iter:   6529/  8460 | loss: 0.0813 | ds_loss: 0.0000 | lr: 6.1654e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6530/  8460 | global iter:   6530/  8460 | loss: 0.0343 | ds_loss: 0.0000 | lr: 6.1593e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6531/  8460 | global iter:   6531/  8460 | loss: 0.0308 | ds_loss: 0.0000 | lr: 6.1532e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6532/  8460 | global iter:   6532/  8460 | loss: 0.0758 | ds_loss: 0.0000 | lr: 6.1471e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6532/  8460 | global iter:   6532/  8460 | loss: 0.0556 | ds_loss: 0.0000 | lr: 6.1471e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6533/  8460 | global iter:   6533/  8460 | loss: 0.0126 | ds_loss: 0.0000 | lr: 6.1410e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6534/  8460 | global iter:   6534/  8460 | loss: 0.0656 | ds_loss: 0.0000 | lr: 6.1349e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6535/  8460 | global iter:   6535/  8460 | loss: 0.1935 | ds_loss: 0.0000 | lr: 6.1289e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6536/  8460 | global iter:   6536/  8460 | loss: 0.2051 | ds_loss: 0.0000 | lr: 6.1228e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6536/  8460 | global iter:   6536/  8460 | loss: 0.1192 | ds_loss: 0.0000 | lr: 6.1228e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6537/  8460 | global iter:   6537/  8460 | loss: 0.0216 | ds_loss: 0.0000 | lr: 6.1167e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6538/  8460 | global iter:   6538/  8460 | loss: 0.0433 | ds_loss: 0.0000 | lr: 6.1106e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6539/  8460 | global iter:   6539/  8460 | loss: 0.2675 | ds_loss: 0.0000 | lr: 6.1045e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6540/  8460 | global iter:   6540/  8460 | loss: 0.2029 | ds_loss: 0.0000 | lr: 6.0985e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6540/  8460 | global iter:   6540/  8460 | loss: 0.1338 | ds_loss: 0.0000 | lr: 6.0985e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6541/  8460 | global iter:   6541/  8460 | loss: 0.1176 | ds_loss: 0.0000 | lr: 6.0924e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6542/  8460 | global iter:   6542/  8460 | loss: 0.0939 | ds_loss: 0.0000 | lr: 6.0863e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6543/  8460 | global iter:   6543/  8460 | loss: 0.0190 | ds_loss: 0.0000 | lr: 6.0803e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6544/  8460 | global iter:   6544/  8460 | loss: 0.1132 | ds_loss: 0.0000 | lr: 6.0742e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6544/  8460 | global iter:   6544/  8460 | loss: 0.0859 | ds_loss: 0.0000 | lr: 6.0742e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6545/  8460 | global iter:   6545/  8460 | loss: 0.1032 | ds_loss: 0.0000 | lr: 6.0681e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6546/  8460 | global iter:   6546/  8460 | loss: 0.0748 | ds_loss: 0.0000 | lr: 6.0621e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6547/  8460 | global iter:   6547/  8460 | loss: 0.0824 | ds_loss: 0.0000 | lr: 6.0560e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6548/  8460 | global iter:   6548/  8460 | loss: 0.0695 | ds_loss: 0.0000 | lr: 6.0500e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6548/  8460 | global iter:   6548/  8460 | loss: 0.0825 | ds_loss: 0.0000 | lr: 6.0500e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6549/  8460 | global iter:   6549/  8460 | loss: 0.0622 | ds_loss: 0.0000 | lr: 6.0439e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6550/  8460 | global iter:   6550/  8460 | loss: 0.1486 | ds_loss: 0.0000 | lr: 6.0379e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6551/  8460 | global iter:   6551/  8460 | loss: 0.0600 | ds_loss: 0.0000 | lr: 6.0318e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6552/  8460 | global iter:   6552/  8460 | loss: 0.0637 | ds_loss: 0.0000 | lr: 6.0258e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6552/  8460 | global iter:   6552/  8460 | loss: 0.0836 | ds_loss: 0.0000 | lr: 6.0258e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6553/  8460 | global iter:   6553/  8460 | loss: 0.1742 | ds_loss: 0.0000 | lr: 6.0198e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6554/  8460 | global iter:   6554/  8460 | loss: 0.0670 | ds_loss: 0.0000 | lr: 6.0137e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6555/  8460 | global iter:   6555/  8460 | loss: 0.0911 | ds_loss: 0.0000 | lr: 6.0077e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6556/  8460 | global iter:   6556/  8460 | loss: 0.2752 | ds_loss: 0.0000 | lr: 6.0017e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6556/  8460 | global iter:   6556/  8460 | loss: 0.1519 | ds_loss: 0.0000 | lr: 6.0017e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6557/  8460 | global iter:   6557/  8460 | loss: 0.1116 | ds_loss: 0.0000 | lr: 5.9956e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6558/  8460 | global iter:   6558/  8460 | loss: 0.0179 | ds_loss: 0.0000 | lr: 5.9896e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6559/  8460 | global iter:   6559/  8460 | loss: 0.0247 | ds_loss: 0.0000 | lr: 5.9836e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6560/  8460 | global iter:   6560/  8460 | loss: 0.0627 | ds_loss: 0.0000 | lr: 5.9776e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6560/  8460 | global iter:   6560/  8460 | loss: 0.0542 | ds_loss: 0.0000 | lr: 5.9776e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6561/  8460 | global iter:   6561/  8460 | loss: 0.0806 | ds_loss: 0.0000 | lr: 5.9716e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6562/  8460 | global iter:   6562/  8460 | loss: 0.0689 | ds_loss: 0.0000 | lr: 5.9655e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6563/  8460 | global iter:   6563/  8460 | loss: 0.0272 | ds_loss: 0.0000 | lr: 5.9595e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6564/  8460 | global iter:   6564/  8460 | loss: 0.0354 | ds_loss: 0.0000 | lr: 5.9535e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6564/  8460 | global iter:   6564/  8460 | loss: 0.0530 | ds_loss: 0.0000 | lr: 5.9535e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6565/  8460 | global iter:   6565/  8460 | loss: 0.1095 | ds_loss: 0.0000 | lr: 5.9475e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6566/  8460 | global iter:   6566/  8460 | loss: 0.0111 | ds_loss: 0.0000 | lr: 5.9415e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6567/  8460 | global iter:   6567/  8460 | loss: 0.0424 | ds_loss: 0.0000 | lr: 5.9355e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6568/  8460 | global iter:   6568/  8460 | loss: 0.1819 | ds_loss: 0.0000 | lr: 5.9295e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6568/  8460 | global iter:   6568/  8460 | loss: 0.0862 | ds_loss: 0.0000 | lr: 5.9295e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6569/  8460 | global iter:   6569/  8460 | loss: 0.1720 | ds_loss: 0.0000 | lr: 5.9235e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6570/  8460 | global iter:   6570/  8460 | loss: 0.0061 | ds_loss: 0.0000 | lr: 5.9175e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6571/  8460 | global iter:   6571/  8460 | loss: 0.0159 | ds_loss: 0.0000 | lr: 5.9115e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6572/  8460 | global iter:   6572/  8460 | loss: 0.0208 | ds_loss: 0.0000 | lr: 5.9055e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6572/  8460 | global iter:   6572/  8460 | loss: 0.0537 | ds_loss: 0.0000 | lr: 5.9055e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6573/  8460 | global iter:   6573/  8460 | loss: 0.0133 | ds_loss: 0.0000 | lr: 5.8995e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6574/  8460 | global iter:   6574/  8460 | loss: 0.1834 | ds_loss: 0.0000 | lr: 5.8936e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6575/  8460 | global iter:   6575/  8460 | loss: 0.0850 | ds_loss: 0.0000 | lr: 5.8876e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6576/  8460 | global iter:   6576/  8460 | loss: 0.0992 | ds_loss: 0.0000 | lr: 5.8816e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6576/  8460 | global iter:   6576/  8460 | loss: 0.0952 | ds_loss: 0.0000 | lr: 5.8816e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6577/  8460 | global iter:   6577/  8460 | loss: 0.0066 | ds_loss: 0.0000 | lr: 5.8756e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6578/  8460 | global iter:   6578/  8460 | loss: 0.0032 | ds_loss: 0.0000 | lr: 5.8697e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6579/  8460 | global iter:   6579/  8460 | loss: 0.0737 | ds_loss: 0.0000 | lr: 5.8637e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6580/  8460 | global iter:   6580/  8460 | loss: 0.1076 | ds_loss: 0.0000 | lr: 5.8577e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6580/  8460 | global iter:   6580/  8460 | loss: 0.0478 | ds_loss: 0.0000 | lr: 5.8577e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6581/  8460 | global iter:   6581/  8460 | loss: 0.2110 | ds_loss: 0.0000 | lr: 5.8518e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6582/  8460 | global iter:   6582/  8460 | loss: 0.0176 | ds_loss: 0.0000 | lr: 5.8458e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6583/  8460 | global iter:   6583/  8460 | loss: 0.0066 | ds_loss: 0.0000 | lr: 5.8398e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6584/  8460 | global iter:   6584/  8460 | loss: 0.1320 | ds_loss: 0.0000 | lr: 5.8339e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6584/  8460 | global iter:   6584/  8460 | loss: 0.0918 | ds_loss: 0.0000 | lr: 5.8339e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6585/  8460 | global iter:   6585/  8460 | loss: 0.0841 | ds_loss: 0.0000 | lr: 5.8279e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6586/  8460 | global iter:   6586/  8460 | loss: 0.1781 | ds_loss: 0.0000 | lr: 5.8220e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6587/  8460 | global iter:   6587/  8460 | loss: 0.0880 | ds_loss: 0.0000 | lr: 5.8160e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6588/  8460 | global iter:   6588/  8460 | loss: 0.0860 | ds_loss: 0.0000 | lr: 5.8101e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6588/  8460 | global iter:   6588/  8460 | loss: 0.1090 | ds_loss: 0.0000 | lr: 5.8101e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6589/  8460 | global iter:   6589/  8460 | loss: 0.1095 | ds_loss: 0.0000 | lr: 5.8041e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6590/  8460 | global iter:   6590/  8460 | loss: 0.1048 | ds_loss: 0.0000 | lr: 5.7982e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6591/  8460 | global iter:   6591/  8460 | loss: 0.0498 | ds_loss: 0.0000 | lr: 5.7923e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6592/  8460 | global iter:   6592/  8460 | loss: 0.0448 | ds_loss: 0.0000 | lr: 5.7863e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6592/  8460 | global iter:   6592/  8460 | loss: 0.0772 | ds_loss: 0.0000 | lr: 5.7863e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6593/  8460 | global iter:   6593/  8460 | loss: 0.0241 | ds_loss: 0.0000 | lr: 5.7804e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6594/  8460 | global iter:   6594/  8460 | loss: 0.0311 | ds_loss: 0.0000 | lr: 5.7745e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6595/  8460 | global iter:   6595/  8460 | loss: 0.0640 | ds_loss: 0.0000 | lr: 5.7685e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6596/  8460 | global iter:   6596/  8460 | loss: 0.0280 | ds_loss: 0.0000 | lr: 5.7626e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6596/  8460 | global iter:   6596/  8460 | loss: 0.0368 | ds_loss: 0.0000 | lr: 5.7626e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6597/  8460 | global iter:   6597/  8460 | loss: 0.0592 | ds_loss: 0.0000 | lr: 5.7567e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6598/  8460 | global iter:   6598/  8460 | loss: 0.1347 | ds_loss: 0.0000 | lr: 5.7508e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6599/  8460 | global iter:   6599/  8460 | loss: 0.0556 | ds_loss: 0.0000 | lr: 5.7448e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6600/  8460 | global iter:   6600/  8460 | loss: 0.0609 | ds_loss: 0.0000 | lr: 5.7389e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6600/  8460 | global iter:   6600/  8460 | loss: 0.0776 | ds_loss: 0.0000 | lr: 5.7389e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6601/  8460 | global iter:   6601/  8460 | loss: 0.0969 | ds_loss: 0.0000 | lr: 5.7330e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6602/  8460 | global iter:   6602/  8460 | loss: 0.1174 | ds_loss: 0.0000 | lr: 5.7271e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6603/  8460 | global iter:   6603/  8460 | loss: 0.2842 | ds_loss: 0.0000 | lr: 5.7212e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6604/  8460 | global iter:   6604/  8460 | loss: 0.0831 | ds_loss: 0.0000 | lr: 5.7153e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6604/  8460 | global iter:   6604/  8460 | loss: 0.1454 | ds_loss: 0.0000 | lr: 5.7153e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6605/  8460 | global iter:   6605/  8460 | loss: 0.0625 | ds_loss: 0.0000 | lr: 5.7094e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6606/  8460 | global iter:   6606/  8460 | loss: 0.0263 | ds_loss: 0.0000 | lr: 5.7035e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6607/  8460 | global iter:   6607/  8460 | loss: 0.1030 | ds_loss: 0.0000 | lr: 5.6976e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6608/  8460 | global iter:   6608/  8460 | loss: 0.0535 | ds_loss: 0.0000 | lr: 5.6917e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6608/  8460 | global iter:   6608/  8460 | loss: 0.0613 | ds_loss: 0.0000 | lr: 5.6917e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6609/  8460 | global iter:   6609/  8460 | loss: 0.0626 | ds_loss: 0.0000 | lr: 5.6858e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6610/  8460 | global iter:   6610/  8460 | loss: 0.0569 | ds_loss: 0.0000 | lr: 5.6799e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6611/  8460 | global iter:   6611/  8460 | loss: 0.1864 | ds_loss: 0.0000 | lr: 5.6740e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6612/  8460 | global iter:   6612/  8460 | loss: 0.0450 | ds_loss: 0.0000 | lr: 5.6682e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6612/  8460 | global iter:   6612/  8460 | loss: 0.0877 | ds_loss: 0.0000 | lr: 5.6682e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6613/  8460 | global iter:   6613/  8460 | loss: 0.0262 | ds_loss: 0.0000 | lr: 5.6623e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6614/  8460 | global iter:   6614/  8460 | loss: 0.0738 | ds_loss: 0.0000 | lr: 5.6564e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6615/  8460 | global iter:   6615/  8460 | loss: 0.0399 | ds_loss: 0.0000 | lr: 5.6505e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6616/  8460 | global iter:   6616/  8460 | loss: 0.0302 | ds_loss: 0.0000 | lr: 5.6447e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6616/  8460 | global iter:   6616/  8460 | loss: 0.0426 | ds_loss: 0.0000 | lr: 5.6447e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6617/  8460 | global iter:   6617/  8460 | loss: 0.0898 | ds_loss: 0.0000 | lr: 5.6388e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6618/  8460 | global iter:   6618/  8460 | loss: 0.0347 | ds_loss: 0.0000 | lr: 5.6329e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6619/  8460 | global iter:   6619/  8460 | loss: 0.0250 | ds_loss: 0.0000 | lr: 5.6271e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6620/  8460 | global iter:   6620/  8460 | loss: 0.0544 | ds_loss: 0.0000 | lr: 5.6212e-05 | scale:     1.0000 | micro time: 0.431 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6620/  8460 | global iter:   6620/  8460 | loss: 0.0509 | ds_loss: 0.0000 | lr: 5.6212e-05 | scale:     1.0000 | micro time: 0.431 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6621/  8460 | global iter:   6621/  8460 | loss: 0.1380 | ds_loss: 0.0000 | lr: 5.6153e-05 | scale:     1.0000 | micro time: 0.435 | step time: 0.000
train | epoch   7 | Iter:   6622/  8460 | global iter:   6622/  8460 | loss: 0.2899 | ds_loss: 0.0000 | lr: 5.6095e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6623/  8460 | global iter:   6623/  8460 | loss: 0.0560 | ds_loss: 0.0000 | lr: 5.6036e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6624/  8460 | global iter:   6624/  8460 | loss: 0.0729 | ds_loss: 0.0000 | lr: 5.5978e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6624/  8460 | global iter:   6624/  8460 | loss: 0.1392 | ds_loss: 0.0000 | lr: 5.5978e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.430
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6625/  8460 | global iter:   6625/  8460 | loss: 0.1278 | ds_loss: 0.0000 | lr: 5.5919e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6626/  8460 | global iter:   6626/  8460 | loss: 0.1228 | ds_loss: 0.0000 | lr: 5.5861e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6627/  8460 | global iter:   6627/  8460 | loss: 0.2049 | ds_loss: 0.0000 | lr: 5.5802e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6628/  8460 | global iter:   6628/  8460 | loss: 0.0740 | ds_loss: 0.0000 | lr: 5.5744e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6628/  8460 | global iter:   6628/  8460 | loss: 0.1324 | ds_loss: 0.0000 | lr: 5.5744e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6629/  8460 | global iter:   6629/  8460 | loss: 0.1664 | ds_loss: 0.0000 | lr: 5.5686e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6630/  8460 | global iter:   6630/  8460 | loss: 0.0035 | ds_loss: 0.0000 | lr: 5.5627e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6631/  8460 | global iter:   6631/  8460 | loss: 0.0379 | ds_loss: 0.0000 | lr: 5.5569e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6632/  8460 | global iter:   6632/  8460 | loss: 0.0791 | ds_loss: 0.0000 | lr: 5.5511e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6632/  8460 | global iter:   6632/  8460 | loss: 0.0717 | ds_loss: 0.0000 | lr: 5.5511e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6633/  8460 | global iter:   6633/  8460 | loss: 0.0744 | ds_loss: 0.0000 | lr: 5.5452e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6634/  8460 | global iter:   6634/  8460 | loss: 0.0296 | ds_loss: 0.0000 | lr: 5.5394e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6635/  8460 | global iter:   6635/  8460 | loss: 0.0551 | ds_loss: 0.0000 | lr: 5.5336e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6636/  8460 | global iter:   6636/  8460 | loss: 0.1961 | ds_loss: 0.0000 | lr: 5.5278e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6636/  8460 | global iter:   6636/  8460 | loss: 0.0888 | ds_loss: 0.0000 | lr: 5.5278e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6637/  8460 | global iter:   6637/  8460 | loss: 0.0234 | ds_loss: 0.0000 | lr: 5.5220e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6638/  8460 | global iter:   6638/  8460 | loss: 0.2694 | ds_loss: 0.0000 | lr: 5.5161e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6639/  8460 | global iter:   6639/  8460 | loss: 0.0523 | ds_loss: 0.0000 | lr: 5.5103e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6640/  8460 | global iter:   6640/  8460 | loss: 0.1306 | ds_loss: 0.0000 | lr: 5.5045e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6640/  8460 | global iter:   6640/  8460 | loss: 0.1189 | ds_loss: 0.0000 | lr: 5.5045e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6641/  8460 | global iter:   6641/  8460 | loss: 0.1005 | ds_loss: 0.0000 | lr: 5.4987e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6642/  8460 | global iter:   6642/  8460 | loss: 0.0450 | ds_loss: 0.0000 | lr: 5.4929e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6643/  8460 | global iter:   6643/  8460 | loss: 0.1098 | ds_loss: 0.0000 | lr: 5.4871e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6644/  8460 | global iter:   6644/  8460 | loss: 0.0183 | ds_loss: 0.0000 | lr: 5.4813e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6644/  8460 | global iter:   6644/  8460 | loss: 0.0684 | ds_loss: 0.0000 | lr: 5.4813e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6645/  8460 | global iter:   6645/  8460 | loss: 0.1803 | ds_loss: 0.0000 | lr: 5.4755e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6646/  8460 | global iter:   6646/  8460 | loss: 0.1611 | ds_loss: 0.0000 | lr: 5.4697e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6647/  8460 | global iter:   6647/  8460 | loss: 0.0587 | ds_loss: 0.0000 | lr: 5.4639e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6648/  8460 | global iter:   6648/  8460 | loss: 0.0678 | ds_loss: 0.0000 | lr: 5.4582e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6648/  8460 | global iter:   6648/  8460 | loss: 0.1170 | ds_loss: 0.0000 | lr: 5.4582e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6649/  8460 | global iter:   6649/  8460 | loss: 0.0334 | ds_loss: 0.0000 | lr: 5.4524e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6650/  8460 | global iter:   6650/  8460 | loss: 0.1079 | ds_loss: 0.0000 | lr: 5.4466e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6651/  8460 | global iter:   6651/  8460 | loss: 0.0630 | ds_loss: 0.0000 | lr: 5.4408e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6652/  8460 | global iter:   6652/  8460 | loss: 0.0198 | ds_loss: 0.0000 | lr: 5.4350e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6652/  8460 | global iter:   6652/  8460 | loss: 0.0560 | ds_loss: 0.0000 | lr: 5.4350e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6653/  8460 | global iter:   6653/  8460 | loss: 0.1117 | ds_loss: 0.0000 | lr: 5.4293e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6654/  8460 | global iter:   6654/  8460 | loss: 0.1173 | ds_loss: 0.0000 | lr: 5.4235e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6655/  8460 | global iter:   6655/  8460 | loss: 0.0994 | ds_loss: 0.0000 | lr: 5.4177e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6656/  8460 | global iter:   6656/  8460 | loss: 0.0759 | ds_loss: 0.0000 | lr: 5.4120e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6656/  8460 | global iter:   6656/  8460 | loss: 0.1011 | ds_loss: 0.0000 | lr: 5.4120e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6657/  8460 | global iter:   6657/  8460 | loss: 0.0873 | ds_loss: 0.0000 | lr: 5.4062e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6658/  8460 | global iter:   6658/  8460 | loss: 0.0276 | ds_loss: 0.0000 | lr: 5.4004e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6659/  8460 | global iter:   6659/  8460 | loss: 0.0224 | ds_loss: 0.0000 | lr: 5.3947e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6660/  8460 | global iter:   6660/  8460 | loss: 0.1350 | ds_loss: 0.0000 | lr: 5.3889e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6660/  8460 | global iter:   6660/  8460 | loss: 0.0681 | ds_loss: 0.0000 | lr: 5.3889e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6661/  8460 | global iter:   6661/  8460 | loss: 0.0530 | ds_loss: 0.0000 | lr: 5.3832e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6662/  8460 | global iter:   6662/  8460 | loss: 0.2561 | ds_loss: 0.0000 | lr: 5.3774e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6663/  8460 | global iter:   6663/  8460 | loss: 0.0689 | ds_loss: 0.0000 | lr: 5.3717e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6664/  8460 | global iter:   6664/  8460 | loss: 0.0312 | ds_loss: 0.0000 | lr: 5.3660e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6664/  8460 | global iter:   6664/  8460 | loss: 0.1023 | ds_loss: 0.0000 | lr: 5.3660e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6665/  8460 | global iter:   6665/  8460 | loss: 0.0709 | ds_loss: 0.0000 | lr: 5.3602e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6666/  8460 | global iter:   6666/  8460 | loss: 0.0710 | ds_loss: 0.0000 | lr: 5.3545e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6667/  8460 | global iter:   6667/  8460 | loss: 0.0230 | ds_loss: 0.0000 | lr: 5.3487e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6668/  8460 | global iter:   6668/  8460 | loss: 0.0434 | ds_loss: 0.0000 | lr: 5.3430e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6668/  8460 | global iter:   6668/  8460 | loss: 0.0520 | ds_loss: 0.0000 | lr: 5.3430e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6669/  8460 | global iter:   6669/  8460 | loss: 0.1108 | ds_loss: 0.0000 | lr: 5.3373e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6670/  8460 | global iter:   6670/  8460 | loss: 0.0434 | ds_loss: 0.0000 | lr: 5.3316e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6671/  8460 | global iter:   6671/  8460 | loss: 0.0873 | ds_loss: 0.0000 | lr: 5.3258e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6672/  8460 | global iter:   6672/  8460 | loss: 0.2815 | ds_loss: 0.0000 | lr: 5.3201e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6672/  8460 | global iter:   6672/  8460 | loss: 0.1308 | ds_loss: 0.0000 | lr: 5.3201e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6673/  8460 | global iter:   6673/  8460 | loss: 0.0392 | ds_loss: 0.0000 | lr: 5.3144e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6674/  8460 | global iter:   6674/  8460 | loss: 0.0390 | ds_loss: 0.0000 | lr: 5.3087e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6675/  8460 | global iter:   6675/  8460 | loss: 0.1402 | ds_loss: 0.0000 | lr: 5.3030e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6676/  8460 | global iter:   6676/  8460 | loss: 0.1850 | ds_loss: 0.0000 | lr: 5.2972e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6676/  8460 | global iter:   6676/  8460 | loss: 0.1009 | ds_loss: 0.0000 | lr: 5.2972e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6677/  8460 | global iter:   6677/  8460 | loss: 0.0622 | ds_loss: 0.0000 | lr: 5.2915e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6678/  8460 | global iter:   6678/  8460 | loss: 0.1553 | ds_loss: 0.0000 | lr: 5.2858e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6679/  8460 | global iter:   6679/  8460 | loss: 0.0467 | ds_loss: 0.0000 | lr: 5.2801e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6680/  8460 | global iter:   6680/  8460 | loss: 0.0948 | ds_loss: 0.0000 | lr: 5.2744e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6680/  8460 | global iter:   6680/  8460 | loss: 0.0897 | ds_loss: 0.0000 | lr: 5.2744e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6681/  8460 | global iter:   6681/  8460 | loss: 0.0554 | ds_loss: 0.0000 | lr: 5.2687e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6682/  8460 | global iter:   6682/  8460 | loss: 0.1532 | ds_loss: 0.0000 | lr: 5.2630e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6683/  8460 | global iter:   6683/  8460 | loss: 0.0127 | ds_loss: 0.0000 | lr: 5.2574e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6684/  8460 | global iter:   6684/  8460 | loss: 0.0691 | ds_loss: 0.0000 | lr: 5.2517e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6684/  8460 | global iter:   6684/  8460 | loss: 0.0726 | ds_loss: 0.0000 | lr: 5.2517e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6685/  8460 | global iter:   6685/  8460 | loss: 0.0601 | ds_loss: 0.0000 | lr: 5.2460e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6686/  8460 | global iter:   6686/  8460 | loss: 0.0742 | ds_loss: 0.0000 | lr: 5.2403e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6687/  8460 | global iter:   6687/  8460 | loss: 0.1265 | ds_loss: 0.0000 | lr: 5.2346e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6688/  8460 | global iter:   6688/  8460 | loss: 0.0389 | ds_loss: 0.0000 | lr: 5.2289e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6688/  8460 | global iter:   6688/  8460 | loss: 0.0749 | ds_loss: 0.0000 | lr: 5.2289e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6689/  8460 | global iter:   6689/  8460 | loss: 0.0552 | ds_loss: 0.0000 | lr: 5.2233e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6690/  8460 | global iter:   6690/  8460 | loss: 0.1346 | ds_loss: 0.0000 | lr: 5.2176e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6691/  8460 | global iter:   6691/  8460 | loss: 0.0163 | ds_loss: 0.0000 | lr: 5.2119e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6692/  8460 | global iter:   6692/  8460 | loss: 0.0423 | ds_loss: 0.0000 | lr: 5.2063e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6692/  8460 | global iter:   6692/  8460 | loss: 0.0621 | ds_loss: 0.0000 | lr: 5.2063e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6693/  8460 | global iter:   6693/  8460 | loss: 0.2561 | ds_loss: 0.0000 | lr: 5.2006e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6694/  8460 | global iter:   6694/  8460 | loss: 0.0230 | ds_loss: 0.0000 | lr: 5.1949e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6695/  8460 | global iter:   6695/  8460 | loss: 0.0648 | ds_loss: 0.0000 | lr: 5.1893e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6696/  8460 | global iter:   6696/  8460 | loss: 0.0217 | ds_loss: 0.0000 | lr: 5.1836e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6696/  8460 | global iter:   6696/  8460 | loss: 0.0914 | ds_loss: 0.0000 | lr: 5.1836e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6697/  8460 | global iter:   6697/  8460 | loss: 0.0618 | ds_loss: 0.0000 | lr: 5.1780e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6698/  8460 | global iter:   6698/  8460 | loss: 0.0804 | ds_loss: 0.0000 | lr: 5.1723e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6699/  8460 | global iter:   6699/  8460 | loss: 0.1101 | ds_loss: 0.0000 | lr: 5.1667e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6700/  8460 | global iter:   6700/  8460 | loss: 0.0067 | ds_loss: 0.0000 | lr: 5.1610e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6700/  8460 | global iter:   6700/  8460 | loss: 0.0648 | ds_loss: 0.0000 | lr: 5.1610e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6701/  8460 | global iter:   6701/  8460 | loss: 0.0152 | ds_loss: 0.0000 | lr: 5.1554e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6702/  8460 | global iter:   6702/  8460 | loss: 0.0627 | ds_loss: 0.0000 | lr: 5.1497e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6703/  8460 | global iter:   6703/  8460 | loss: 0.0707 | ds_loss: 0.0000 | lr: 5.1441e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6704/  8460 | global iter:   6704/  8460 | loss: 0.0732 | ds_loss: 0.0000 | lr: 5.1385e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6704/  8460 | global iter:   6704/  8460 | loss: 0.0555 | ds_loss: 0.0000 | lr: 5.1385e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6705/  8460 | global iter:   6705/  8460 | loss: 0.0201 | ds_loss: 0.0000 | lr: 5.1328e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6706/  8460 | global iter:   6706/  8460 | loss: 0.0347 | ds_loss: 0.0000 | lr: 5.1272e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6707/  8460 | global iter:   6707/  8460 | loss: 0.1933 | ds_loss: 0.0000 | lr: 5.1216e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6708/  8460 | global iter:   6708/  8460 | loss: 0.3715 | ds_loss: 0.0000 | lr: 5.1160e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6708/  8460 | global iter:   6708/  8460 | loss: 0.1549 | ds_loss: 0.0000 | lr: 5.1160e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6709/  8460 | global iter:   6709/  8460 | loss: 0.0480 | ds_loss: 0.0000 | lr: 5.1103e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6710/  8460 | global iter:   6710/  8460 | loss: 0.1682 | ds_loss: 0.0000 | lr: 5.1047e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6711/  8460 | global iter:   6711/  8460 | loss: 0.0078 | ds_loss: 0.0000 | lr: 5.0991e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6712/  8460 | global iter:   6712/  8460 | loss: 0.3281 | ds_loss: 0.0000 | lr: 5.0935e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6712/  8460 | global iter:   6712/  8460 | loss: 0.1380 | ds_loss: 0.0000 | lr: 5.0935e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6713/  8460 | global iter:   6713/  8460 | loss: 0.1376 | ds_loss: 0.0000 | lr: 5.0879e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6714/  8460 | global iter:   6714/  8460 | loss: 0.0157 | ds_loss: 0.0000 | lr: 5.0823e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6715/  8460 | global iter:   6715/  8460 | loss: 0.0839 | ds_loss: 0.0000 | lr: 5.0767e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6716/  8460 | global iter:   6716/  8460 | loss: 0.2181 | ds_loss: 0.0000 | lr: 5.0711e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6716/  8460 | global iter:   6716/  8460 | loss: 0.1138 | ds_loss: 0.0000 | lr: 5.0711e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6717/  8460 | global iter:   6717/  8460 | loss: 0.0640 | ds_loss: 0.0000 | lr: 5.0655e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6718/  8460 | global iter:   6718/  8460 | loss: 0.0043 | ds_loss: 0.0000 | lr: 5.0599e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6719/  8460 | global iter:   6719/  8460 | loss: 0.0110 | ds_loss: 0.0000 | lr: 5.0543e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6720/  8460 | global iter:   6720/  8460 | loss: 0.2463 | ds_loss: 0.0000 | lr: 5.0487e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6720/  8460 | global iter:   6720/  8460 | loss: 0.0814 | ds_loss: 0.0000 | lr: 5.0487e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6721/  8460 | global iter:   6721/  8460 | loss: 0.0029 | ds_loss: 0.0000 | lr: 5.0431e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6722/  8460 | global iter:   6722/  8460 | loss: 0.0972 | ds_loss: 0.0000 | lr: 5.0375e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6723/  8460 | global iter:   6723/  8460 | loss: 0.1264 | ds_loss: 0.0000 | lr: 5.0319e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6724/  8460 | global iter:   6724/  8460 | loss: 0.0427 | ds_loss: 0.0000 | lr: 5.0264e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6724/  8460 | global iter:   6724/  8460 | loss: 0.0673 | ds_loss: 0.0000 | lr: 5.0264e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6725/  8460 | global iter:   6725/  8460 | loss: 0.1214 | ds_loss: 0.0000 | lr: 5.0208e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6726/  8460 | global iter:   6726/  8460 | loss: 0.0250 | ds_loss: 0.0000 | lr: 5.0152e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6727/  8460 | global iter:   6727/  8460 | loss: 0.0057 | ds_loss: 0.0000 | lr: 5.0096e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6728/  8460 | global iter:   6728/  8460 | loss: 0.0555 | ds_loss: 0.0000 | lr: 5.0041e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6728/  8460 | global iter:   6728/  8460 | loss: 0.0519 | ds_loss: 0.0000 | lr: 5.0041e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6729/  8460 | global iter:   6729/  8460 | loss: 0.0042 | ds_loss: 0.0000 | lr: 4.9985e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6730/  8460 | global iter:   6730/  8460 | loss: 0.0562 | ds_loss: 0.0000 | lr: 4.9929e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6731/  8460 | global iter:   6731/  8460 | loss: 0.1124 | ds_loss: 0.0000 | lr: 4.9874e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6732/  8460 | global iter:   6732/  8460 | loss: 0.0182 | ds_loss: 0.0000 | lr: 4.9818e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6732/  8460 | global iter:   6732/  8460 | loss: 0.0477 | ds_loss: 0.0000 | lr: 4.9818e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6733/  8460 | global iter:   6733/  8460 | loss: 0.3313 | ds_loss: 0.0000 | lr: 4.9763e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6734/  8460 | global iter:   6734/  8460 | loss: 0.0826 | ds_loss: 0.0000 | lr: 4.9707e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6735/  8460 | global iter:   6735/  8460 | loss: 0.0225 | ds_loss: 0.0000 | lr: 4.9652e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6736/  8460 | global iter:   6736/  8460 | loss: 0.1184 | ds_loss: 0.0000 | lr: 4.9596e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6736/  8460 | global iter:   6736/  8460 | loss: 0.1387 | ds_loss: 0.0000 | lr: 4.9596e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6737/  8460 | global iter:   6737/  8460 | loss: 0.0121 | ds_loss: 0.0000 | lr: 4.9541e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6738/  8460 | global iter:   6738/  8460 | loss: 0.0504 | ds_loss: 0.0000 | lr: 4.9485e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6739/  8460 | global iter:   6739/  8460 | loss: 0.0257 | ds_loss: 0.0000 | lr: 4.9430e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6740/  8460 | global iter:   6740/  8460 | loss: 0.0262 | ds_loss: 0.0000 | lr: 4.9375e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6740/  8460 | global iter:   6740/  8460 | loss: 0.0286 | ds_loss: 0.0000 | lr: 4.9375e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6741/  8460 | global iter:   6741/  8460 | loss: 0.1100 | ds_loss: 0.0000 | lr: 4.9319e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6742/  8460 | global iter:   6742/  8460 | loss: 0.0403 | ds_loss: 0.0000 | lr: 4.9264e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6743/  8460 | global iter:   6743/  8460 | loss: 0.1888 | ds_loss: 0.0000 | lr: 4.9209e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6744/  8460 | global iter:   6744/  8460 | loss: 0.0362 | ds_loss: 0.0000 | lr: 4.9154e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6744/  8460 | global iter:   6744/  8460 | loss: 0.0938 | ds_loss: 0.0000 | lr: 4.9154e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6745/  8460 | global iter:   6745/  8460 | loss: 0.1904 | ds_loss: 0.0000 | lr: 4.9098e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6746/  8460 | global iter:   6746/  8460 | loss: 0.1473 | ds_loss: 0.0000 | lr: 4.9043e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6747/  8460 | global iter:   6747/  8460 | loss: 0.0556 | ds_loss: 0.0000 | lr: 4.8988e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6748/  8460 | global iter:   6748/  8460 | loss: 0.0683 | ds_loss: 0.0000 | lr: 4.8933e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6748/  8460 | global iter:   6748/  8460 | loss: 0.1154 | ds_loss: 0.0000 | lr: 4.8933e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6749/  8460 | global iter:   6749/  8460 | loss: 0.1062 | ds_loss: 0.0000 | lr: 4.8878e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6750/  8460 | global iter:   6750/  8460 | loss: 0.0570 | ds_loss: 0.0000 | lr: 4.8823e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6751/  8460 | global iter:   6751/  8460 | loss: 0.1010 | ds_loss: 0.0000 | lr: 4.8768e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6752/  8460 | global iter:   6752/  8460 | loss: 0.0542 | ds_loss: 0.0000 | lr: 4.8713e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6752/  8460 | global iter:   6752/  8460 | loss: 0.0796 | ds_loss: 0.0000 | lr: 4.8713e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6753/  8460 | global iter:   6753/  8460 | loss: 0.1042 | ds_loss: 0.0000 | lr: 4.8658e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6754/  8460 | global iter:   6754/  8460 | loss: 0.1084 | ds_loss: 0.0000 | lr: 4.8603e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6755/  8460 | global iter:   6755/  8460 | loss: 0.1851 | ds_loss: 0.0000 | lr: 4.8548e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6756/  8460 | global iter:   6756/  8460 | loss: 0.2071 | ds_loss: 0.0000 | lr: 4.8493e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6756/  8460 | global iter:   6756/  8460 | loss: 0.1512 | ds_loss: 0.0000 | lr: 4.8493e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6757/  8460 | global iter:   6757/  8460 | loss: 0.1537 | ds_loss: 0.0000 | lr: 4.8438e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6758/  8460 | global iter:   6758/  8460 | loss: 0.1103 | ds_loss: 0.0000 | lr: 4.8383e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6759/  8460 | global iter:   6759/  8460 | loss: 0.0153 | ds_loss: 0.0000 | lr: 4.8328e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   7 | Iter:   6760/  8460 | global iter:   6760/  8460 | loss: 0.0783 | ds_loss: 0.0000 | lr: 4.8274e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6760/  8460 | global iter:   6760/  8460 | loss: 0.0894 | ds_loss: 0.0000 | lr: 4.8274e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6761/  8460 | global iter:   6761/  8460 | loss: 0.0153 | ds_loss: 0.0000 | lr: 4.8219e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6762/  8460 | global iter:   6762/  8460 | loss: 0.0929 | ds_loss: 0.0000 | lr: 4.8164e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6763/  8460 | global iter:   6763/  8460 | loss: 0.0171 | ds_loss: 0.0000 | lr: 4.8109e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6764/  8460 | global iter:   6764/  8460 | loss: 0.0644 | ds_loss: 0.0000 | lr: 4.8055e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6764/  8460 | global iter:   6764/  8460 | loss: 0.0474 | ds_loss: 0.0000 | lr: 4.8055e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6765/  8460 | global iter:   6765/  8460 | loss: 0.3106 | ds_loss: 0.0000 | lr: 4.8000e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6766/  8460 | global iter:   6766/  8460 | loss: 0.1718 | ds_loss: 0.0000 | lr: 4.7945e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6767/  8460 | global iter:   6767/  8460 | loss: 0.1472 | ds_loss: 0.0000 | lr: 4.7891e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6768/  8460 | global iter:   6768/  8460 | loss: 0.0509 | ds_loss: 0.0000 | lr: 4.7836e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6768/  8460 | global iter:   6768/  8460 | loss: 0.1701 | ds_loss: 0.0000 | lr: 4.7836e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6769/  8460 | global iter:   6769/  8460 | loss: 0.3605 | ds_loss: 0.0000 | lr: 4.7782e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6770/  8460 | global iter:   6770/  8460 | loss: 0.0537 | ds_loss: 0.0000 | lr: 4.7727e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6771/  8460 | global iter:   6771/  8460 | loss: 0.0427 | ds_loss: 0.0000 | lr: 4.7673e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6772/  8460 | global iter:   6772/  8460 | loss: 0.0403 | ds_loss: 0.0000 | lr: 4.7618e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6772/  8460 | global iter:   6772/  8460 | loss: 0.1243 | ds_loss: 0.0000 | lr: 4.7618e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   7 | Iter:   6773/  8460 | global iter:   6773/  8460 | loss: 0.0398 | ds_loss: 0.0000 | lr: 4.7564e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6774/  8460 | global iter:   6774/  8460 | loss: 0.0200 | ds_loss: 0.0000 | lr: 4.7509e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   7 | Iter:   6775/  8460 | global iter:   6775/  8460 | loss: 0.0189 | ds_loss: 0.0000 | lr: 4.7455e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   7 | Iter:   6776/  8460 | global iter:   6776/  8460 | loss: 0.0704 | ds_loss: 0.0000 | lr: 4.7401e-05 | scale:     1.0000 | micro time: 0.366 | step time: 0.000
****************************************************************************************************
train | epoch   7 | Iter:   6776/  8460 | global iter:   6776/  8460 | loss: 0.0373 | ds_loss: 0.0000 | lr: 4.7401e-05 | scale:     1.0000 | micro time: 0.366 | step time: 0.412
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
Sun Apr  6 21:41:10 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla P100-PCIE-12GB           Off |   00000000:81:00.0 Off |                    0 |
| N/A   50C    P0             38W /  250W |    8807MiB /  12288MiB |     55%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A    244677      C   ...project_distillLLM/venv/bin/python3       8804MiB |
+-----------------------------------------------------------------------------------------+

train | epoch   8 | Iter:   6777/  8460 | global iter:   6777/  8460 | loss: 0.0774 | ds_loss: 0.0000 | lr: 4.7346e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6778/  8460 | global iter:   6778/  8460 | loss: 0.0759 | ds_loss: 0.0000 | lr: 4.7292e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6779/  8460 | global iter:   6779/  8460 | loss: 0.1491 | ds_loss: 0.0000 | lr: 4.7238e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6780/  8460 | global iter:   6780/  8460 | loss: 0.0426 | ds_loss: 0.0000 | lr: 4.7184e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6780/  8460 | global iter:   6780/  8460 | loss: 0.0862 | ds_loss: 0.0000 | lr: 4.7184e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6781/  8460 | global iter:   6781/  8460 | loss: 0.0680 | ds_loss: 0.0000 | lr: 4.7129e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6782/  8460 | global iter:   6782/  8460 | loss: 0.0296 | ds_loss: 0.0000 | lr: 4.7075e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6783/  8460 | global iter:   6783/  8460 | loss: 0.0358 | ds_loss: 0.0000 | lr: 4.7021e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6784/  8460 | global iter:   6784/  8460 | loss: 0.0168 | ds_loss: 0.0000 | lr: 4.6967e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6784/  8460 | global iter:   6784/  8460 | loss: 0.0376 | ds_loss: 0.0000 | lr: 4.6967e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6785/  8460 | global iter:   6785/  8460 | loss: 0.0053 | ds_loss: 0.0000 | lr: 4.6913e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6786/  8460 | global iter:   6786/  8460 | loss: 0.0675 | ds_loss: 0.0000 | lr: 4.6859e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6787/  8460 | global iter:   6787/  8460 | loss: 0.0821 | ds_loss: 0.0000 | lr: 4.6805e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6788/  8460 | global iter:   6788/  8460 | loss: 0.0409 | ds_loss: 0.0000 | lr: 4.6751e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6788/  8460 | global iter:   6788/  8460 | loss: 0.0489 | ds_loss: 0.0000 | lr: 4.6751e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6789/  8460 | global iter:   6789/  8460 | loss: 0.0485 | ds_loss: 0.0000 | lr: 4.6697e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6790/  8460 | global iter:   6790/  8460 | loss: 0.0464 | ds_loss: 0.0000 | lr: 4.6643e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6791/  8460 | global iter:   6791/  8460 | loss: 0.0453 | ds_loss: 0.0000 | lr: 4.6589e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6792/  8460 | global iter:   6792/  8460 | loss: 0.0295 | ds_loss: 0.0000 | lr: 4.6535e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6792/  8460 | global iter:   6792/  8460 | loss: 0.0424 | ds_loss: 0.0000 | lr: 4.6535e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6793/  8460 | global iter:   6793/  8460 | loss: 0.0298 | ds_loss: 0.0000 | lr: 4.6481e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6794/  8460 | global iter:   6794/  8460 | loss: 0.0337 | ds_loss: 0.0000 | lr: 4.6427e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6795/  8460 | global iter:   6795/  8460 | loss: 0.0918 | ds_loss: 0.0000 | lr: 4.6373e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6796/  8460 | global iter:   6796/  8460 | loss: 0.1035 | ds_loss: 0.0000 | lr: 4.6320e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6796/  8460 | global iter:   6796/  8460 | loss: 0.0647 | ds_loss: 0.0000 | lr: 4.6320e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6797/  8460 | global iter:   6797/  8460 | loss: 0.0208 | ds_loss: 0.0000 | lr: 4.6266e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6798/  8460 | global iter:   6798/  8460 | loss: 0.0139 | ds_loss: 0.0000 | lr: 4.6212e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6799/  8460 | global iter:   6799/  8460 | loss: 0.0538 | ds_loss: 0.0000 | lr: 4.6158e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6800/  8460 | global iter:   6800/  8460 | loss: 0.0056 | ds_loss: 0.0000 | lr: 4.6105e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6800/  8460 | global iter:   6800/  8460 | loss: 0.0235 | ds_loss: 0.0000 | lr: 4.6105e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6801/  8460 | global iter:   6801/  8460 | loss: 0.1513 | ds_loss: 0.0000 | lr: 4.6051e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6802/  8460 | global iter:   6802/  8460 | loss: 0.0840 | ds_loss: 0.0000 | lr: 4.5997e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6803/  8460 | global iter:   6803/  8460 | loss: 0.0620 | ds_loss: 0.0000 | lr: 4.5944e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6804/  8460 | global iter:   6804/  8460 | loss: 0.0487 | ds_loss: 0.0000 | lr: 4.5890e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6804/  8460 | global iter:   6804/  8460 | loss: 0.0865 | ds_loss: 0.0000 | lr: 4.5890e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6805/  8460 | global iter:   6805/  8460 | loss: 0.1778 | ds_loss: 0.0000 | lr: 4.5837e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6806/  8460 | global iter:   6806/  8460 | loss: 0.0164 | ds_loss: 0.0000 | lr: 4.5783e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   6807/  8460 | global iter:   6807/  8460 | loss: 0.0060 | ds_loss: 0.0000 | lr: 4.5730e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6808/  8460 | global iter:   6808/  8460 | loss: 0.0224 | ds_loss: 0.0000 | lr: 4.5676e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6808/  8460 | global iter:   6808/  8460 | loss: 0.0557 | ds_loss: 0.0000 | lr: 4.5676e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6809/  8460 | global iter:   6809/  8460 | loss: 0.1220 | ds_loss: 0.0000 | lr: 4.5623e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6810/  8460 | global iter:   6810/  8460 | loss: 0.0107 | ds_loss: 0.0000 | lr: 4.5569e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   6811/  8460 | global iter:   6811/  8460 | loss: 0.0952 | ds_loss: 0.0000 | lr: 4.5516e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   6812/  8460 | global iter:   6812/  8460 | loss: 0.0356 | ds_loss: 0.0000 | lr: 4.5463e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6812/  8460 | global iter:   6812/  8460 | loss: 0.0659 | ds_loss: 0.0000 | lr: 4.5463e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6813/  8460 | global iter:   6813/  8460 | loss: 0.0854 | ds_loss: 0.0000 | lr: 4.5409e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   6814/  8460 | global iter:   6814/  8460 | loss: 0.0618 | ds_loss: 0.0000 | lr: 4.5356e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6815/  8460 | global iter:   6815/  8460 | loss: 0.1122 | ds_loss: 0.0000 | lr: 4.5303e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6816/  8460 | global iter:   6816/  8460 | loss: 0.0920 | ds_loss: 0.0000 | lr: 4.5250e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6816/  8460 | global iter:   6816/  8460 | loss: 0.0879 | ds_loss: 0.0000 | lr: 4.5250e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6817/  8460 | global iter:   6817/  8460 | loss: 0.0082 | ds_loss: 0.0000 | lr: 4.5197e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6818/  8460 | global iter:   6818/  8460 | loss: 0.0401 | ds_loss: 0.0000 | lr: 4.5143e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6819/  8460 | global iter:   6819/  8460 | loss: 0.0373 | ds_loss: 0.0000 | lr: 4.5090e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6820/  8460 | global iter:   6820/  8460 | loss: 0.0421 | ds_loss: 0.0000 | lr: 4.5037e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6820/  8460 | global iter:   6820/  8460 | loss: 0.0319 | ds_loss: 0.0000 | lr: 4.5037e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6821/  8460 | global iter:   6821/  8460 | loss: 0.0412 | ds_loss: 0.0000 | lr: 4.4984e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6822/  8460 | global iter:   6822/  8460 | loss: 0.0284 | ds_loss: 0.0000 | lr: 4.4931e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6823/  8460 | global iter:   6823/  8460 | loss: 0.0450 | ds_loss: 0.0000 | lr: 4.4878e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6824/  8460 | global iter:   6824/  8460 | loss: 0.0518 | ds_loss: 0.0000 | lr: 4.4825e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6824/  8460 | global iter:   6824/  8460 | loss: 0.0416 | ds_loss: 0.0000 | lr: 4.4825e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6825/  8460 | global iter:   6825/  8460 | loss: 0.0882 | ds_loss: 0.0000 | lr: 4.4772e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6826/  8460 | global iter:   6826/  8460 | loss: 0.0080 | ds_loss: 0.0000 | lr: 4.4719e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6827/  8460 | global iter:   6827/  8460 | loss: 0.0090 | ds_loss: 0.0000 | lr: 4.4666e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6828/  8460 | global iter:   6828/  8460 | loss: 0.0767 | ds_loss: 0.0000 | lr: 4.4613e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6828/  8460 | global iter:   6828/  8460 | loss: 0.0455 | ds_loss: 0.0000 | lr: 4.4613e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6829/  8460 | global iter:   6829/  8460 | loss: 0.0540 | ds_loss: 0.0000 | lr: 4.4560e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6830/  8460 | global iter:   6830/  8460 | loss: 0.0347 | ds_loss: 0.0000 | lr: 4.4508e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6831/  8460 | global iter:   6831/  8460 | loss: 0.0318 | ds_loss: 0.0000 | lr: 4.4455e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6832/  8460 | global iter:   6832/  8460 | loss: 0.1102 | ds_loss: 0.0000 | lr: 4.4402e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6832/  8460 | global iter:   6832/  8460 | loss: 0.0577 | ds_loss: 0.0000 | lr: 4.4402e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6833/  8460 | global iter:   6833/  8460 | loss: 0.0153 | ds_loss: 0.0000 | lr: 4.4349e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6834/  8460 | global iter:   6834/  8460 | loss: 0.0193 | ds_loss: 0.0000 | lr: 4.4297e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6835/  8460 | global iter:   6835/  8460 | loss: 0.1194 | ds_loss: 0.0000 | lr: 4.4244e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6836/  8460 | global iter:   6836/  8460 | loss: 0.0468 | ds_loss: 0.0000 | lr: 4.4191e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6836/  8460 | global iter:   6836/  8460 | loss: 0.0502 | ds_loss: 0.0000 | lr: 4.4191e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6837/  8460 | global iter:   6837/  8460 | loss: 0.0660 | ds_loss: 0.0000 | lr: 4.4139e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6838/  8460 | global iter:   6838/  8460 | loss: 0.0718 | ds_loss: 0.0000 | lr: 4.4086e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6839/  8460 | global iter:   6839/  8460 | loss: 0.0802 | ds_loss: 0.0000 | lr: 4.4033e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6840/  8460 | global iter:   6840/  8460 | loss: 0.0102 | ds_loss: 0.0000 | lr: 4.3981e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6840/  8460 | global iter:   6840/  8460 | loss: 0.0571 | ds_loss: 0.0000 | lr: 4.3981e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6841/  8460 | global iter:   6841/  8460 | loss: 0.0278 | ds_loss: 0.0000 | lr: 4.3928e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6842/  8460 | global iter:   6842/  8460 | loss: 0.0257 | ds_loss: 0.0000 | lr: 4.3876e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6843/  8460 | global iter:   6843/  8460 | loss: 0.0056 | ds_loss: 0.0000 | lr: 4.3823e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6844/  8460 | global iter:   6844/  8460 | loss: 0.1026 | ds_loss: 0.0000 | lr: 4.3771e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6844/  8460 | global iter:   6844/  8460 | loss: 0.0404 | ds_loss: 0.0000 | lr: 4.3771e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6845/  8460 | global iter:   6845/  8460 | loss: 0.1087 | ds_loss: 0.0000 | lr: 4.3719e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6846/  8460 | global iter:   6846/  8460 | loss: 0.2748 | ds_loss: 0.0000 | lr: 4.3666e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6847/  8460 | global iter:   6847/  8460 | loss: 0.0030 | ds_loss: 0.0000 | lr: 4.3614e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6848/  8460 | global iter:   6848/  8460 | loss: 0.0294 | ds_loss: 0.0000 | lr: 4.3562e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6848/  8460 | global iter:   6848/  8460 | loss: 0.1040 | ds_loss: 0.0000 | lr: 4.3562e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6849/  8460 | global iter:   6849/  8460 | loss: 0.0577 | ds_loss: 0.0000 | lr: 4.3509e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6850/  8460 | global iter:   6850/  8460 | loss: 0.0703 | ds_loss: 0.0000 | lr: 4.3457e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6851/  8460 | global iter:   6851/  8460 | loss: 0.0152 | ds_loss: 0.0000 | lr: 4.3405e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6852/  8460 | global iter:   6852/  8460 | loss: 0.1684 | ds_loss: 0.0000 | lr: 4.3353e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6852/  8460 | global iter:   6852/  8460 | loss: 0.0779 | ds_loss: 0.0000 | lr: 4.3353e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6853/  8460 | global iter:   6853/  8460 | loss: 0.0331 | ds_loss: 0.0000 | lr: 4.3300e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6854/  8460 | global iter:   6854/  8460 | loss: 0.0189 | ds_loss: 0.0000 | lr: 4.3248e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6855/  8460 | global iter:   6855/  8460 | loss: 0.0125 | ds_loss: 0.0000 | lr: 4.3196e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6856/  8460 | global iter:   6856/  8460 | loss: 0.1822 | ds_loss: 0.0000 | lr: 4.3144e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6856/  8460 | global iter:   6856/  8460 | loss: 0.0617 | ds_loss: 0.0000 | lr: 4.3144e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6857/  8460 | global iter:   6857/  8460 | loss: 0.0823 | ds_loss: 0.0000 | lr: 4.3092e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6858/  8460 | global iter:   6858/  8460 | loss: 0.0427 | ds_loss: 0.0000 | lr: 4.3040e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6859/  8460 | global iter:   6859/  8460 | loss: 0.1161 | ds_loss: 0.0000 | lr: 4.2988e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   6860/  8460 | global iter:   6860/  8460 | loss: 0.0308 | ds_loss: 0.0000 | lr: 4.2936e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6860/  8460 | global iter:   6860/  8460 | loss: 0.0680 | ds_loss: 0.0000 | lr: 4.2936e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6861/  8460 | global iter:   6861/  8460 | loss: 0.1048 | ds_loss: 0.0000 | lr: 4.2884e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6862/  8460 | global iter:   6862/  8460 | loss: 0.0118 | ds_loss: 0.0000 | lr: 4.2832e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6863/  8460 | global iter:   6863/  8460 | loss: 0.0666 | ds_loss: 0.0000 | lr: 4.2780e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6864/  8460 | global iter:   6864/  8460 | loss: 0.0792 | ds_loss: 0.0000 | lr: 4.2728e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6864/  8460 | global iter:   6864/  8460 | loss: 0.0656 | ds_loss: 0.0000 | lr: 4.2728e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6865/  8460 | global iter:   6865/  8460 | loss: 0.0311 | ds_loss: 0.0000 | lr: 4.2676e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6866/  8460 | global iter:   6866/  8460 | loss: 0.0360 | ds_loss: 0.0000 | lr: 4.2625e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6867/  8460 | global iter:   6867/  8460 | loss: 0.0043 | ds_loss: 0.0000 | lr: 4.2573e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6868/  8460 | global iter:   6868/  8460 | loss: 0.1241 | ds_loss: 0.0000 | lr: 4.2521e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6868/  8460 | global iter:   6868/  8460 | loss: 0.0489 | ds_loss: 0.0000 | lr: 4.2521e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6869/  8460 | global iter:   6869/  8460 | loss: 0.0263 | ds_loss: 0.0000 | lr: 4.2469e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6870/  8460 | global iter:   6870/  8460 | loss: 0.0774 | ds_loss: 0.0000 | lr: 4.2418e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6871/  8460 | global iter:   6871/  8460 | loss: 0.0535 | ds_loss: 0.0000 | lr: 4.2366e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6872/  8460 | global iter:   6872/  8460 | loss: 0.0162 | ds_loss: 0.0000 | lr: 4.2314e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6872/  8460 | global iter:   6872/  8460 | loss: 0.0433 | ds_loss: 0.0000 | lr: 4.2314e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6873/  8460 | global iter:   6873/  8460 | loss: 0.1430 | ds_loss: 0.0000 | lr: 4.2263e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6874/  8460 | global iter:   6874/  8460 | loss: 0.1499 | ds_loss: 0.0000 | lr: 4.2211e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6875/  8460 | global iter:   6875/  8460 | loss: 0.0878 | ds_loss: 0.0000 | lr: 4.2160e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6876/  8460 | global iter:   6876/  8460 | loss: 0.0356 | ds_loss: 0.0000 | lr: 4.2108e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6876/  8460 | global iter:   6876/  8460 | loss: 0.1041 | ds_loss: 0.0000 | lr: 4.2108e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6877/  8460 | global iter:   6877/  8460 | loss: 0.1178 | ds_loss: 0.0000 | lr: 4.2057e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6878/  8460 | global iter:   6878/  8460 | loss: 0.0377 | ds_loss: 0.0000 | lr: 4.2005e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6879/  8460 | global iter:   6879/  8460 | loss: 0.0519 | ds_loss: 0.0000 | lr: 4.1954e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6880/  8460 | global iter:   6880/  8460 | loss: 0.1193 | ds_loss: 0.0000 | lr: 4.1902e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6880/  8460 | global iter:   6880/  8460 | loss: 0.0817 | ds_loss: 0.0000 | lr: 4.1902e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6881/  8460 | global iter:   6881/  8460 | loss: 0.1167 | ds_loss: 0.0000 | lr: 4.1851e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6882/  8460 | global iter:   6882/  8460 | loss: 0.0423 | ds_loss: 0.0000 | lr: 4.1800e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   6883/  8460 | global iter:   6883/  8460 | loss: 0.0067 | ds_loss: 0.0000 | lr: 4.1748e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6884/  8460 | global iter:   6884/  8460 | loss: 0.1573 | ds_loss: 0.0000 | lr: 4.1697e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6884/  8460 | global iter:   6884/  8460 | loss: 0.0808 | ds_loss: 0.0000 | lr: 4.1697e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6885/  8460 | global iter:   6885/  8460 | loss: 0.0598 | ds_loss: 0.0000 | lr: 4.1646e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6886/  8460 | global iter:   6886/  8460 | loss: 0.1704 | ds_loss: 0.0000 | lr: 4.1595e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6887/  8460 | global iter:   6887/  8460 | loss: 0.0427 | ds_loss: 0.0000 | lr: 4.1543e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6888/  8460 | global iter:   6888/  8460 | loss: 0.0770 | ds_loss: 0.0000 | lr: 4.1492e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6888/  8460 | global iter:   6888/  8460 | loss: 0.0875 | ds_loss: 0.0000 | lr: 4.1492e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6889/  8460 | global iter:   6889/  8460 | loss: 0.0095 | ds_loss: 0.0000 | lr: 4.1441e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6890/  8460 | global iter:   6890/  8460 | loss: 0.0456 | ds_loss: 0.0000 | lr: 4.1390e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6891/  8460 | global iter:   6891/  8460 | loss: 0.0194 | ds_loss: 0.0000 | lr: 4.1339e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6892/  8460 | global iter:   6892/  8460 | loss: 0.0123 | ds_loss: 0.0000 | lr: 4.1288e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6892/  8460 | global iter:   6892/  8460 | loss: 0.0217 | ds_loss: 0.0000 | lr: 4.1288e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6893/  8460 | global iter:   6893/  8460 | loss: 0.0913 | ds_loss: 0.0000 | lr: 4.1237e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6894/  8460 | global iter:   6894/  8460 | loss: 0.0438 | ds_loss: 0.0000 | lr: 4.1186e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6895/  8460 | global iter:   6895/  8460 | loss: 0.0120 | ds_loss: 0.0000 | lr: 4.1135e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6896/  8460 | global iter:   6896/  8460 | loss: 0.1489 | ds_loss: 0.0000 | lr: 4.1084e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6896/  8460 | global iter:   6896/  8460 | loss: 0.0740 | ds_loss: 0.0000 | lr: 4.1084e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6897/  8460 | global iter:   6897/  8460 | loss: 0.0169 | ds_loss: 0.0000 | lr: 4.1033e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6898/  8460 | global iter:   6898/  8460 | loss: 0.0688 | ds_loss: 0.0000 | lr: 4.0982e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6899/  8460 | global iter:   6899/  8460 | loss: 0.0276 | ds_loss: 0.0000 | lr: 4.0931e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6900/  8460 | global iter:   6900/  8460 | loss: 0.0997 | ds_loss: 0.0000 | lr: 4.0880e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6900/  8460 | global iter:   6900/  8460 | loss: 0.0532 | ds_loss: 0.0000 | lr: 4.0880e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6901/  8460 | global iter:   6901/  8460 | loss: 0.0135 | ds_loss: 0.0000 | lr: 4.0830e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6902/  8460 | global iter:   6902/  8460 | loss: 0.0005 | ds_loss: 0.0000 | lr: 4.0779e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6903/  8460 | global iter:   6903/  8460 | loss: 0.2595 | ds_loss: 0.0000 | lr: 4.0728e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6904/  8460 | global iter:   6904/  8460 | loss: 0.0226 | ds_loss: 0.0000 | lr: 4.0677e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6904/  8460 | global iter:   6904/  8460 | loss: 0.0740 | ds_loss: 0.0000 | lr: 4.0677e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6905/  8460 | global iter:   6905/  8460 | loss: 0.0527 | ds_loss: 0.0000 | lr: 4.0627e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6906/  8460 | global iter:   6906/  8460 | loss: 0.1016 | ds_loss: 0.0000 | lr: 4.0576e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   6907/  8460 | global iter:   6907/  8460 | loss: 0.0493 | ds_loss: 0.0000 | lr: 4.0525e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   6908/  8460 | global iter:   6908/  8460 | loss: 0.0342 | ds_loss: 0.0000 | lr: 4.0475e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6908/  8460 | global iter:   6908/  8460 | loss: 0.0595 | ds_loss: 0.0000 | lr: 4.0475e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6909/  8460 | global iter:   6909/  8460 | loss: 0.1325 | ds_loss: 0.0000 | lr: 4.0424e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6910/  8460 | global iter:   6910/  8460 | loss: 0.0214 | ds_loss: 0.0000 | lr: 4.0374e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6911/  8460 | global iter:   6911/  8460 | loss: 0.0867 | ds_loss: 0.0000 | lr: 4.0323e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6912/  8460 | global iter:   6912/  8460 | loss: 0.1145 | ds_loss: 0.0000 | lr: 4.0273e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6912/  8460 | global iter:   6912/  8460 | loss: 0.0888 | ds_loss: 0.0000 | lr: 4.0273e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6913/  8460 | global iter:   6913/  8460 | loss: 0.0301 | ds_loss: 0.0000 | lr: 4.0222e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6914/  8460 | global iter:   6914/  8460 | loss: 0.1182 | ds_loss: 0.0000 | lr: 4.0172e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6915/  8460 | global iter:   6915/  8460 | loss: 0.0158 | ds_loss: 0.0000 | lr: 4.0121e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6916/  8460 | global iter:   6916/  8460 | loss: 0.0366 | ds_loss: 0.0000 | lr: 4.0071e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6916/  8460 | global iter:   6916/  8460 | loss: 0.0502 | ds_loss: 0.0000 | lr: 4.0071e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6917/  8460 | global iter:   6917/  8460 | loss: 0.0667 | ds_loss: 0.0000 | lr: 4.0021e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6918/  8460 | global iter:   6918/  8460 | loss: 0.0298 | ds_loss: 0.0000 | lr: 3.9970e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6919/  8460 | global iter:   6919/  8460 | loss: 0.0114 | ds_loss: 0.0000 | lr: 3.9920e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6920/  8460 | global iter:   6920/  8460 | loss: 0.0545 | ds_loss: 0.0000 | lr: 3.9870e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6920/  8460 | global iter:   6920/  8460 | loss: 0.0406 | ds_loss: 0.0000 | lr: 3.9870e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6921/  8460 | global iter:   6921/  8460 | loss: 0.1099 | ds_loss: 0.0000 | lr: 3.9820e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6922/  8460 | global iter:   6922/  8460 | loss: 0.0688 | ds_loss: 0.0000 | lr: 3.9770e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6923/  8460 | global iter:   6923/  8460 | loss: 0.0681 | ds_loss: 0.0000 | lr: 3.9719e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6924/  8460 | global iter:   6924/  8460 | loss: 0.0066 | ds_loss: 0.0000 | lr: 3.9669e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6924/  8460 | global iter:   6924/  8460 | loss: 0.0633 | ds_loss: 0.0000 | lr: 3.9669e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6925/  8460 | global iter:   6925/  8460 | loss: 0.0179 | ds_loss: 0.0000 | lr: 3.9619e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6926/  8460 | global iter:   6926/  8460 | loss: 0.0248 | ds_loss: 0.0000 | lr: 3.9569e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6927/  8460 | global iter:   6927/  8460 | loss: 0.0227 | ds_loss: 0.0000 | lr: 3.9519e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6928/  8460 | global iter:   6928/  8460 | loss: 0.0536 | ds_loss: 0.0000 | lr: 3.9469e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6928/  8460 | global iter:   6928/  8460 | loss: 0.0298 | ds_loss: 0.0000 | lr: 3.9469e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6929/  8460 | global iter:   6929/  8460 | loss: 0.0505 | ds_loss: 0.0000 | lr: 3.9419e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6930/  8460 | global iter:   6930/  8460 | loss: 0.0040 | ds_loss: 0.0000 | lr: 3.9369e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6931/  8460 | global iter:   6931/  8460 | loss: 0.0079 | ds_loss: 0.0000 | lr: 3.9319e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6932/  8460 | global iter:   6932/  8460 | loss: 0.0547 | ds_loss: 0.0000 | lr: 3.9269e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6932/  8460 | global iter:   6932/  8460 | loss: 0.0293 | ds_loss: 0.0000 | lr: 3.9269e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6933/  8460 | global iter:   6933/  8460 | loss: 0.0215 | ds_loss: 0.0000 | lr: 3.9219e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6934/  8460 | global iter:   6934/  8460 | loss: 0.0163 | ds_loss: 0.0000 | lr: 3.9170e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6935/  8460 | global iter:   6935/  8460 | loss: 0.0045 | ds_loss: 0.0000 | lr: 3.9120e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6936/  8460 | global iter:   6936/  8460 | loss: 0.0649 | ds_loss: 0.0000 | lr: 3.9070e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6936/  8460 | global iter:   6936/  8460 | loss: 0.0268 | ds_loss: 0.0000 | lr: 3.9070e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6937/  8460 | global iter:   6937/  8460 | loss: 0.2072 | ds_loss: 0.0000 | lr: 3.9020e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6938/  8460 | global iter:   6938/  8460 | loss: 0.0380 | ds_loss: 0.0000 | lr: 3.8970e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6939/  8460 | global iter:   6939/  8460 | loss: 0.0458 | ds_loss: 0.0000 | lr: 3.8921e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6940/  8460 | global iter:   6940/  8460 | loss: 0.0469 | ds_loss: 0.0000 | lr: 3.8871e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6940/  8460 | global iter:   6940/  8460 | loss: 0.0845 | ds_loss: 0.0000 | lr: 3.8871e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6941/  8460 | global iter:   6941/  8460 | loss: 0.0313 | ds_loss: 0.0000 | lr: 3.8821e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6942/  8460 | global iter:   6942/  8460 | loss: 0.0287 | ds_loss: 0.0000 | lr: 3.8772e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6943/  8460 | global iter:   6943/  8460 | loss: 0.0179 | ds_loss: 0.0000 | lr: 3.8722e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6944/  8460 | global iter:   6944/  8460 | loss: 0.0490 | ds_loss: 0.0000 | lr: 3.8673e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6944/  8460 | global iter:   6944/  8460 | loss: 0.0317 | ds_loss: 0.0000 | lr: 3.8673e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6945/  8460 | global iter:   6945/  8460 | loss: 0.0039 | ds_loss: 0.0000 | lr: 3.8623e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6946/  8460 | global iter:   6946/  8460 | loss: 0.0205 | ds_loss: 0.0000 | lr: 3.8574e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6947/  8460 | global iter:   6947/  8460 | loss: 0.0016 | ds_loss: 0.0000 | lr: 3.8524e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6948/  8460 | global iter:   6948/  8460 | loss: 0.0169 | ds_loss: 0.0000 | lr: 3.8475e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6948/  8460 | global iter:   6948/  8460 | loss: 0.0107 | ds_loss: 0.0000 | lr: 3.8475e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6949/  8460 | global iter:   6949/  8460 | loss: 0.1699 | ds_loss: 0.0000 | lr: 3.8425e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6950/  8460 | global iter:   6950/  8460 | loss: 0.0615 | ds_loss: 0.0000 | lr: 3.8376e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6951/  8460 | global iter:   6951/  8460 | loss: 0.0280 | ds_loss: 0.0000 | lr: 3.8327e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6952/  8460 | global iter:   6952/  8460 | loss: 0.0527 | ds_loss: 0.0000 | lr: 3.8277e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6952/  8460 | global iter:   6952/  8460 | loss: 0.0780 | ds_loss: 0.0000 | lr: 3.8277e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6953/  8460 | global iter:   6953/  8460 | loss: 0.0133 | ds_loss: 0.0000 | lr: 3.8228e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6954/  8460 | global iter:   6954/  8460 | loss: 0.0089 | ds_loss: 0.0000 | lr: 3.8179e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6955/  8460 | global iter:   6955/  8460 | loss: 0.0068 | ds_loss: 0.0000 | lr: 3.8130e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6956/  8460 | global iter:   6956/  8460 | loss: 0.0230 | ds_loss: 0.0000 | lr: 3.8080e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6956/  8460 | global iter:   6956/  8460 | loss: 0.0130 | ds_loss: 0.0000 | lr: 3.8080e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6957/  8460 | global iter:   6957/  8460 | loss: 0.0090 | ds_loss: 0.0000 | lr: 3.8031e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   6958/  8460 | global iter:   6958/  8460 | loss: 0.1258 | ds_loss: 0.0000 | lr: 3.7982e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6959/  8460 | global iter:   6959/  8460 | loss: 0.0917 | ds_loss: 0.0000 | lr: 3.7933e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6960/  8460 | global iter:   6960/  8460 | loss: 0.1658 | ds_loss: 0.0000 | lr: 3.7884e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6960/  8460 | global iter:   6960/  8460 | loss: 0.0981 | ds_loss: 0.0000 | lr: 3.7884e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6961/  8460 | global iter:   6961/  8460 | loss: 0.0412 | ds_loss: 0.0000 | lr: 3.7835e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6962/  8460 | global iter:   6962/  8460 | loss: 0.0491 | ds_loss: 0.0000 | lr: 3.7786e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6963/  8460 | global iter:   6963/  8460 | loss: 0.0010 | ds_loss: 0.0000 | lr: 3.7737e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6964/  8460 | global iter:   6964/  8460 | loss: 0.0067 | ds_loss: 0.0000 | lr: 3.7688e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6964/  8460 | global iter:   6964/  8460 | loss: 0.0245 | ds_loss: 0.0000 | lr: 3.7688e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6965/  8460 | global iter:   6965/  8460 | loss: 0.0016 | ds_loss: 0.0000 | lr: 3.7639e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6966/  8460 | global iter:   6966/  8460 | loss: 0.2177 | ds_loss: 0.0000 | lr: 3.7590e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6967/  8460 | global iter:   6967/  8460 | loss: 0.0349 | ds_loss: 0.0000 | lr: 3.7541e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6968/  8460 | global iter:   6968/  8460 | loss: 0.0861 | ds_loss: 0.0000 | lr: 3.7492e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6968/  8460 | global iter:   6968/  8460 | loss: 0.0851 | ds_loss: 0.0000 | lr: 3.7492e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6969/  8460 | global iter:   6969/  8460 | loss: 0.0888 | ds_loss: 0.0000 | lr: 3.7443e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6970/  8460 | global iter:   6970/  8460 | loss: 0.0650 | ds_loss: 0.0000 | lr: 3.7395e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6971/  8460 | global iter:   6971/  8460 | loss: 0.0091 | ds_loss: 0.0000 | lr: 3.7346e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6972/  8460 | global iter:   6972/  8460 | loss: 0.0378 | ds_loss: 0.0000 | lr: 3.7297e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6972/  8460 | global iter:   6972/  8460 | loss: 0.0502 | ds_loss: 0.0000 | lr: 3.7297e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6973/  8460 | global iter:   6973/  8460 | loss: 0.0524 | ds_loss: 0.0000 | lr: 3.7248e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6974/  8460 | global iter:   6974/  8460 | loss: 0.0655 | ds_loss: 0.0000 | lr: 3.7200e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6975/  8460 | global iter:   6975/  8460 | loss: 0.0820 | ds_loss: 0.0000 | lr: 3.7151e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6976/  8460 | global iter:   6976/  8460 | loss: 0.0186 | ds_loss: 0.0000 | lr: 3.7103e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6976/  8460 | global iter:   6976/  8460 | loss: 0.0546 | ds_loss: 0.0000 | lr: 3.7103e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6977/  8460 | global iter:   6977/  8460 | loss: 0.1158 | ds_loss: 0.0000 | lr: 3.7054e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6978/  8460 | global iter:   6978/  8460 | loss: 0.0438 | ds_loss: 0.0000 | lr: 3.7005e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6979/  8460 | global iter:   6979/  8460 | loss: 0.1035 | ds_loss: 0.0000 | lr: 3.6957e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   6980/  8460 | global iter:   6980/  8460 | loss: 0.1035 | ds_loss: 0.0000 | lr: 3.6908e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6980/  8460 | global iter:   6980/  8460 | loss: 0.0917 | ds_loss: 0.0000 | lr: 3.6908e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6981/  8460 | global iter:   6981/  8460 | loss: 0.0254 | ds_loss: 0.0000 | lr: 3.6860e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6982/  8460 | global iter:   6982/  8460 | loss: 0.0172 | ds_loss: 0.0000 | lr: 3.6811e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6983/  8460 | global iter:   6983/  8460 | loss: 0.0124 | ds_loss: 0.0000 | lr: 3.6763e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6984/  8460 | global iter:   6984/  8460 | loss: 0.0497 | ds_loss: 0.0000 | lr: 3.6715e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6984/  8460 | global iter:   6984/  8460 | loss: 0.0262 | ds_loss: 0.0000 | lr: 3.6715e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6985/  8460 | global iter:   6985/  8460 | loss: 0.0705 | ds_loss: 0.0000 | lr: 3.6666e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6986/  8460 | global iter:   6986/  8460 | loss: 0.0396 | ds_loss: 0.0000 | lr: 3.6618e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6987/  8460 | global iter:   6987/  8460 | loss: 0.0590 | ds_loss: 0.0000 | lr: 3.6570e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6988/  8460 | global iter:   6988/  8460 | loss: 0.1414 | ds_loss: 0.0000 | lr: 3.6521e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6988/  8460 | global iter:   6988/  8460 | loss: 0.0776 | ds_loss: 0.0000 | lr: 3.6521e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6989/  8460 | global iter:   6989/  8460 | loss: 0.0451 | ds_loss: 0.0000 | lr: 3.6473e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6990/  8460 | global iter:   6990/  8460 | loss: 0.0404 | ds_loss: 0.0000 | lr: 3.6425e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6991/  8460 | global iter:   6991/  8460 | loss: 0.0890 | ds_loss: 0.0000 | lr: 3.6377e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6992/  8460 | global iter:   6992/  8460 | loss: 0.0070 | ds_loss: 0.0000 | lr: 3.6329e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6992/  8460 | global iter:   6992/  8460 | loss: 0.0454 | ds_loss: 0.0000 | lr: 3.6329e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6993/  8460 | global iter:   6993/  8460 | loss: 0.1244 | ds_loss: 0.0000 | lr: 3.6281e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6994/  8460 | global iter:   6994/  8460 | loss: 0.0319 | ds_loss: 0.0000 | lr: 3.6232e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6995/  8460 | global iter:   6995/  8460 | loss: 0.0557 | ds_loss: 0.0000 | lr: 3.6184e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   6996/  8460 | global iter:   6996/  8460 | loss: 0.0072 | ds_loss: 0.0000 | lr: 3.6136e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   6996/  8460 | global iter:   6996/  8460 | loss: 0.0548 | ds_loss: 0.0000 | lr: 3.6136e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   6997/  8460 | global iter:   6997/  8460 | loss: 0.0049 | ds_loss: 0.0000 | lr: 3.6088e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6998/  8460 | global iter:   6998/  8460 | loss: 0.0978 | ds_loss: 0.0000 | lr: 3.6040e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   6999/  8460 | global iter:   6999/  8460 | loss: 0.0109 | ds_loss: 0.0000 | lr: 3.5992e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7000/  8460 | global iter:   7000/  8460 | loss: 0.0786 | ds_loss: 0.0000 | lr: 3.5945e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7000/  8460 | global iter:   7000/  8460 | loss: 0.0480 | ds_loss: 0.0000 | lr: 3.5945e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7001/  8460 | global iter:   7001/  8460 | loss: 0.0120 | ds_loss: 0.0000 | lr: 3.5897e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7002/  8460 | global iter:   7002/  8460 | loss: 0.0261 | ds_loss: 0.0000 | lr: 3.5849e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7003/  8460 | global iter:   7003/  8460 | loss: 0.0243 | ds_loss: 0.0000 | lr: 3.5801e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7004/  8460 | global iter:   7004/  8460 | loss: 0.0738 | ds_loss: 0.0000 | lr: 3.5753e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7004/  8460 | global iter:   7004/  8460 | loss: 0.0341 | ds_loss: 0.0000 | lr: 3.5753e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7005/  8460 | global iter:   7005/  8460 | loss: 0.0387 | ds_loss: 0.0000 | lr: 3.5705e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7006/  8460 | global iter:   7006/  8460 | loss: 0.0474 | ds_loss: 0.0000 | lr: 3.5658e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7007/  8460 | global iter:   7007/  8460 | loss: 0.0655 | ds_loss: 0.0000 | lr: 3.5610e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7008/  8460 | global iter:   7008/  8460 | loss: 0.2370 | ds_loss: 0.0000 | lr: 3.5562e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7008/  8460 | global iter:   7008/  8460 | loss: 0.0972 | ds_loss: 0.0000 | lr: 3.5562e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7009/  8460 | global iter:   7009/  8460 | loss: 0.1280 | ds_loss: 0.0000 | lr: 3.5515e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7010/  8460 | global iter:   7010/  8460 | loss: 0.0170 | ds_loss: 0.0000 | lr: 3.5467e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7011/  8460 | global iter:   7011/  8460 | loss: 0.1616 | ds_loss: 0.0000 | lr: 3.5420e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7012/  8460 | global iter:   7012/  8460 | loss: 0.0184 | ds_loss: 0.0000 | lr: 3.5372e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7012/  8460 | global iter:   7012/  8460 | loss: 0.0813 | ds_loss: 0.0000 | lr: 3.5372e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7013/  8460 | global iter:   7013/  8460 | loss: 0.0527 | ds_loss: 0.0000 | lr: 3.5324e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7014/  8460 | global iter:   7014/  8460 | loss: 0.1057 | ds_loss: 0.0000 | lr: 3.5277e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7015/  8460 | global iter:   7015/  8460 | loss: 0.0649 | ds_loss: 0.0000 | lr: 3.5230e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7016/  8460 | global iter:   7016/  8460 | loss: 0.0450 | ds_loss: 0.0000 | lr: 3.5182e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7016/  8460 | global iter:   7016/  8460 | loss: 0.0671 | ds_loss: 0.0000 | lr: 3.5182e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7017/  8460 | global iter:   7017/  8460 | loss: 0.0468 | ds_loss: 0.0000 | lr: 3.5135e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7018/  8460 | global iter:   7018/  8460 | loss: 0.1736 | ds_loss: 0.0000 | lr: 3.5087e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7019/  8460 | global iter:   7019/  8460 | loss: 0.0505 | ds_loss: 0.0000 | lr: 3.5040e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7020/  8460 | global iter:   7020/  8460 | loss: 0.0338 | ds_loss: 0.0000 | lr: 3.4993e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7020/  8460 | global iter:   7020/  8460 | loss: 0.0762 | ds_loss: 0.0000 | lr: 3.4993e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7021/  8460 | global iter:   7021/  8460 | loss: 0.0075 | ds_loss: 0.0000 | lr: 3.4945e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7022/  8460 | global iter:   7022/  8460 | loss: 0.0099 | ds_loss: 0.0000 | lr: 3.4898e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7023/  8460 | global iter:   7023/  8460 | loss: 0.0284 | ds_loss: 0.0000 | lr: 3.4851e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7024/  8460 | global iter:   7024/  8460 | loss: 0.0325 | ds_loss: 0.0000 | lr: 3.4804e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7024/  8460 | global iter:   7024/  8460 | loss: 0.0196 | ds_loss: 0.0000 | lr: 3.4804e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7025/  8460 | global iter:   7025/  8460 | loss: 0.0443 | ds_loss: 0.0000 | lr: 3.4756e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7026/  8460 | global iter:   7026/  8460 | loss: 0.1016 | ds_loss: 0.0000 | lr: 3.4709e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7027/  8460 | global iter:   7027/  8460 | loss: 0.0565 | ds_loss: 0.0000 | lr: 3.4662e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7028/  8460 | global iter:   7028/  8460 | loss: 0.0090 | ds_loss: 0.0000 | lr: 3.4615e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7028/  8460 | global iter:   7028/  8460 | loss: 0.0528 | ds_loss: 0.0000 | lr: 3.4615e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7029/  8460 | global iter:   7029/  8460 | loss: 0.0452 | ds_loss: 0.0000 | lr: 3.4568e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7030/  8460 | global iter:   7030/  8460 | loss: 0.0404 | ds_loss: 0.0000 | lr: 3.4521e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7031/  8460 | global iter:   7031/  8460 | loss: 0.0197 | ds_loss: 0.0000 | lr: 3.4474e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7032/  8460 | global iter:   7032/  8460 | loss: 0.0625 | ds_loss: 0.0000 | lr: 3.4427e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7032/  8460 | global iter:   7032/  8460 | loss: 0.0420 | ds_loss: 0.0000 | lr: 3.4427e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7033/  8460 | global iter:   7033/  8460 | loss: 0.0171 | ds_loss: 0.0000 | lr: 3.4380e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7034/  8460 | global iter:   7034/  8460 | loss: 0.0756 | ds_loss: 0.0000 | lr: 3.4333e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7035/  8460 | global iter:   7035/  8460 | loss: 0.0100 | ds_loss: 0.0000 | lr: 3.4286e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7036/  8460 | global iter:   7036/  8460 | loss: 0.0418 | ds_loss: 0.0000 | lr: 3.4240e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7036/  8460 | global iter:   7036/  8460 | loss: 0.0361 | ds_loss: 0.0000 | lr: 3.4240e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7037/  8460 | global iter:   7037/  8460 | loss: 0.0094 | ds_loss: 0.0000 | lr: 3.4193e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7038/  8460 | global iter:   7038/  8460 | loss: 0.0178 | ds_loss: 0.0000 | lr: 3.4146e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7039/  8460 | global iter:   7039/  8460 | loss: 0.0774 | ds_loss: 0.0000 | lr: 3.4099e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7040/  8460 | global iter:   7040/  8460 | loss: 0.0120 | ds_loss: 0.0000 | lr: 3.4053e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7040/  8460 | global iter:   7040/  8460 | loss: 0.0292 | ds_loss: 0.0000 | lr: 3.4053e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7041/  8460 | global iter:   7041/  8460 | loss: 0.0120 | ds_loss: 0.0000 | lr: 3.4006e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7042/  8460 | global iter:   7042/  8460 | loss: 0.0723 | ds_loss: 0.0000 | lr: 3.3959e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7043/  8460 | global iter:   7043/  8460 | loss: 0.0902 | ds_loss: 0.0000 | lr: 3.3913e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7044/  8460 | global iter:   7044/  8460 | loss: 0.0318 | ds_loss: 0.0000 | lr: 3.3866e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7044/  8460 | global iter:   7044/  8460 | loss: 0.0516 | ds_loss: 0.0000 | lr: 3.3866e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7045/  8460 | global iter:   7045/  8460 | loss: 0.0228 | ds_loss: 0.0000 | lr: 3.3819e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7046/  8460 | global iter:   7046/  8460 | loss: 0.0140 | ds_loss: 0.0000 | lr: 3.3773e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7047/  8460 | global iter:   7047/  8460 | loss: 0.0012 | ds_loss: 0.0000 | lr: 3.3726e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7048/  8460 | global iter:   7048/  8460 | loss: 0.1156 | ds_loss: 0.0000 | lr: 3.3680e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7048/  8460 | global iter:   7048/  8460 | loss: 0.0384 | ds_loss: 0.0000 | lr: 3.3680e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7049/  8460 | global iter:   7049/  8460 | loss: 0.0519 | ds_loss: 0.0000 | lr: 3.3633e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7050/  8460 | global iter:   7050/  8460 | loss: 0.0198 | ds_loss: 0.0000 | lr: 3.3587e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7051/  8460 | global iter:   7051/  8460 | loss: 0.0409 | ds_loss: 0.0000 | lr: 3.3541e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7052/  8460 | global iter:   7052/  8460 | loss: 0.0134 | ds_loss: 0.0000 | lr: 3.3494e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7052/  8460 | global iter:   7052/  8460 | loss: 0.0315 | ds_loss: 0.0000 | lr: 3.3494e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7053/  8460 | global iter:   7053/  8460 | loss: 0.1351 | ds_loss: 0.0000 | lr: 3.3448e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7054/  8460 | global iter:   7054/  8460 | loss: 0.1046 | ds_loss: 0.0000 | lr: 3.3402e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7055/  8460 | global iter:   7055/  8460 | loss: 0.0136 | ds_loss: 0.0000 | lr: 3.3355e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7056/  8460 | global iter:   7056/  8460 | loss: 0.1092 | ds_loss: 0.0000 | lr: 3.3309e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7056/  8460 | global iter:   7056/  8460 | loss: 0.0906 | ds_loss: 0.0000 | lr: 3.3309e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7057/  8460 | global iter:   7057/  8460 | loss: 0.0439 | ds_loss: 0.0000 | lr: 3.3263e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7058/  8460 | global iter:   7058/  8460 | loss: 0.0807 | ds_loss: 0.0000 | lr: 3.3217e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7059/  8460 | global iter:   7059/  8460 | loss: 0.0242 | ds_loss: 0.0000 | lr: 3.3170e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7060/  8460 | global iter:   7060/  8460 | loss: 0.0418 | ds_loss: 0.0000 | lr: 3.3124e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7060/  8460 | global iter:   7060/  8460 | loss: 0.0477 | ds_loss: 0.0000 | lr: 3.3124e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7061/  8460 | global iter:   7061/  8460 | loss: 0.0792 | ds_loss: 0.0000 | lr: 3.3078e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7062/  8460 | global iter:   7062/  8460 | loss: 0.1252 | ds_loss: 0.0000 | lr: 3.3032e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7063/  8460 | global iter:   7063/  8460 | loss: 0.0461 | ds_loss: 0.0000 | lr: 3.2986e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7064/  8460 | global iter:   7064/  8460 | loss: 0.0288 | ds_loss: 0.0000 | lr: 3.2940e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7064/  8460 | global iter:   7064/  8460 | loss: 0.0698 | ds_loss: 0.0000 | lr: 3.2940e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7065/  8460 | global iter:   7065/  8460 | loss: 0.0127 | ds_loss: 0.0000 | lr: 3.2894e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7066/  8460 | global iter:   7066/  8460 | loss: 0.0116 | ds_loss: 0.0000 | lr: 3.2848e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7067/  8460 | global iter:   7067/  8460 | loss: 0.1616 | ds_loss: 0.0000 | lr: 3.2802e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7068/  8460 | global iter:   7068/  8460 | loss: 0.0223 | ds_loss: 0.0000 | lr: 3.2756e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7068/  8460 | global iter:   7068/  8460 | loss: 0.0521 | ds_loss: 0.0000 | lr: 3.2756e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7069/  8460 | global iter:   7069/  8460 | loss: 0.0591 | ds_loss: 0.0000 | lr: 3.2711e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7070/  8460 | global iter:   7070/  8460 | loss: 0.0592 | ds_loss: 0.0000 | lr: 3.2665e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7071/  8460 | global iter:   7071/  8460 | loss: 0.0802 | ds_loss: 0.0000 | lr: 3.2619e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7072/  8460 | global iter:   7072/  8460 | loss: 0.0298 | ds_loss: 0.0000 | lr: 3.2573e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7072/  8460 | global iter:   7072/  8460 | loss: 0.0571 | ds_loss: 0.0000 | lr: 3.2573e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7073/  8460 | global iter:   7073/  8460 | loss: 0.0741 | ds_loss: 0.0000 | lr: 3.2527e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7074/  8460 | global iter:   7074/  8460 | loss: 0.0600 | ds_loss: 0.0000 | lr: 3.2482e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7075/  8460 | global iter:   7075/  8460 | loss: 0.1671 | ds_loss: 0.0000 | lr: 3.2436e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7076/  8460 | global iter:   7076/  8460 | loss: 0.0718 | ds_loss: 0.0000 | lr: 3.2390e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7076/  8460 | global iter:   7076/  8460 | loss: 0.0932 | ds_loss: 0.0000 | lr: 3.2390e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7077/  8460 | global iter:   7077/  8460 | loss: 0.0983 | ds_loss: 0.0000 | lr: 3.2345e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7078/  8460 | global iter:   7078/  8460 | loss: 0.0092 | ds_loss: 0.0000 | lr: 3.2299e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7079/  8460 | global iter:   7079/  8460 | loss: 0.0296 | ds_loss: 0.0000 | lr: 3.2254e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7080/  8460 | global iter:   7080/  8460 | loss: 0.0429 | ds_loss: 0.0000 | lr: 3.2208e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7080/  8460 | global iter:   7080/  8460 | loss: 0.0450 | ds_loss: 0.0000 | lr: 3.2208e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7081/  8460 | global iter:   7081/  8460 | loss: 0.0319 | ds_loss: 0.0000 | lr: 3.2163e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7082/  8460 | global iter:   7082/  8460 | loss: 0.0781 | ds_loss: 0.0000 | lr: 3.2117e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7083/  8460 | global iter:   7083/  8460 | loss: 0.0177 | ds_loss: 0.0000 | lr: 3.2072e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7084/  8460 | global iter:   7084/  8460 | loss: 0.1144 | ds_loss: 0.0000 | lr: 3.2026e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7084/  8460 | global iter:   7084/  8460 | loss: 0.0605 | ds_loss: 0.0000 | lr: 3.2026e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7085/  8460 | global iter:   7085/  8460 | loss: 0.0945 | ds_loss: 0.0000 | lr: 3.1981e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7086/  8460 | global iter:   7086/  8460 | loss: 0.0699 | ds_loss: 0.0000 | lr: 3.1936e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7087/  8460 | global iter:   7087/  8460 | loss: 0.1174 | ds_loss: 0.0000 | lr: 3.1890e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7088/  8460 | global iter:   7088/  8460 | loss: 0.0508 | ds_loss: 0.0000 | lr: 3.1845e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7088/  8460 | global iter:   7088/  8460 | loss: 0.0831 | ds_loss: 0.0000 | lr: 3.1845e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7089/  8460 | global iter:   7089/  8460 | loss: 0.0421 | ds_loss: 0.0000 | lr: 3.1800e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7090/  8460 | global iter:   7090/  8460 | loss: 0.0493 | ds_loss: 0.0000 | lr: 3.1755e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7091/  8460 | global iter:   7091/  8460 | loss: 0.0210 | ds_loss: 0.0000 | lr: 3.1709e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7092/  8460 | global iter:   7092/  8460 | loss: 0.0164 | ds_loss: 0.0000 | lr: 3.1664e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7092/  8460 | global iter:   7092/  8460 | loss: 0.0322 | ds_loss: 0.0000 | lr: 3.1664e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7093/  8460 | global iter:   7093/  8460 | loss: 0.0535 | ds_loss: 0.0000 | lr: 3.1619e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7094/  8460 | global iter:   7094/  8460 | loss: 0.0470 | ds_loss: 0.0000 | lr: 3.1574e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7095/  8460 | global iter:   7095/  8460 | loss: 0.0394 | ds_loss: 0.0000 | lr: 3.1529e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7096/  8460 | global iter:   7096/  8460 | loss: 0.0243 | ds_loss: 0.0000 | lr: 3.1484e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7096/  8460 | global iter:   7096/  8460 | loss: 0.0410 | ds_loss: 0.0000 | lr: 3.1484e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7097/  8460 | global iter:   7097/  8460 | loss: 0.0094 | ds_loss: 0.0000 | lr: 3.1439e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7098/  8460 | global iter:   7098/  8460 | loss: 0.1802 | ds_loss: 0.0000 | lr: 3.1394e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7099/  8460 | global iter:   7099/  8460 | loss: 0.1043 | ds_loss: 0.0000 | lr: 3.1349e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7100/  8460 | global iter:   7100/  8460 | loss: 0.0293 | ds_loss: 0.0000 | lr: 3.1304e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7100/  8460 | global iter:   7100/  8460 | loss: 0.0808 | ds_loss: 0.0000 | lr: 3.1304e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7101/  8460 | global iter:   7101/  8460 | loss: 0.0621 | ds_loss: 0.0000 | lr: 3.1259e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7102/  8460 | global iter:   7102/  8460 | loss: 0.0443 | ds_loss: 0.0000 | lr: 3.1214e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7103/  8460 | global iter:   7103/  8460 | loss: 0.0247 | ds_loss: 0.0000 | lr: 3.1169e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7104/  8460 | global iter:   7104/  8460 | loss: 0.0278 | ds_loss: 0.0000 | lr: 3.1125e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7104/  8460 | global iter:   7104/  8460 | loss: 0.0398 | ds_loss: 0.0000 | lr: 3.1125e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7105/  8460 | global iter:   7105/  8460 | loss: 0.0313 | ds_loss: 0.0000 | lr: 3.1080e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7106/  8460 | global iter:   7106/  8460 | loss: 0.0520 | ds_loss: 0.0000 | lr: 3.1035e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7107/  8460 | global iter:   7107/  8460 | loss: 0.0835 | ds_loss: 0.0000 | lr: 3.0990e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7108/  8460 | global iter:   7108/  8460 | loss: 0.0316 | ds_loss: 0.0000 | lr: 3.0946e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7108/  8460 | global iter:   7108/  8460 | loss: 0.0496 | ds_loss: 0.0000 | lr: 3.0946e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7109/  8460 | global iter:   7109/  8460 | loss: 0.0088 | ds_loss: 0.0000 | lr: 3.0901e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7110/  8460 | global iter:   7110/  8460 | loss: 0.0092 | ds_loss: 0.0000 | lr: 3.0856e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7111/  8460 | global iter:   7111/  8460 | loss: 0.0901 | ds_loss: 0.0000 | lr: 3.0812e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7112/  8460 | global iter:   7112/  8460 | loss: 0.0551 | ds_loss: 0.0000 | lr: 3.0767e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7112/  8460 | global iter:   7112/  8460 | loss: 0.0408 | ds_loss: 0.0000 | lr: 3.0767e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7113/  8460 | global iter:   7113/  8460 | loss: 0.0640 | ds_loss: 0.0000 | lr: 3.0723e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7114/  8460 | global iter:   7114/  8460 | loss: 0.0612 | ds_loss: 0.0000 | lr: 3.0678e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7115/  8460 | global iter:   7115/  8460 | loss: 0.0990 | ds_loss: 0.0000 | lr: 3.0634e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7116/  8460 | global iter:   7116/  8460 | loss: 0.1431 | ds_loss: 0.0000 | lr: 3.0589e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7116/  8460 | global iter:   7116/  8460 | loss: 0.0918 | ds_loss: 0.0000 | lr: 3.0589e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7117/  8460 | global iter:   7117/  8460 | loss: 0.0332 | ds_loss: 0.0000 | lr: 3.0545e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7118/  8460 | global iter:   7118/  8460 | loss: 0.0243 | ds_loss: 0.0000 | lr: 3.0500e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7119/  8460 | global iter:   7119/  8460 | loss: 0.0552 | ds_loss: 0.0000 | lr: 3.0456e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7120/  8460 | global iter:   7120/  8460 | loss: 0.0424 | ds_loss: 0.0000 | lr: 3.0412e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7120/  8460 | global iter:   7120/  8460 | loss: 0.0388 | ds_loss: 0.0000 | lr: 3.0412e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7121/  8460 | global iter:   7121/  8460 | loss: 0.0212 | ds_loss: 0.0000 | lr: 3.0368e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7122/  8460 | global iter:   7122/  8460 | loss: 0.0407 | ds_loss: 0.0000 | lr: 3.0323e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7123/  8460 | global iter:   7123/  8460 | loss: 0.0500 | ds_loss: 0.0000 | lr: 3.0279e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7124/  8460 | global iter:   7124/  8460 | loss: 0.1027 | ds_loss: 0.0000 | lr: 3.0235e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7124/  8460 | global iter:   7124/  8460 | loss: 0.0536 | ds_loss: 0.0000 | lr: 3.0235e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7125/  8460 | global iter:   7125/  8460 | loss: 0.0704 | ds_loss: 0.0000 | lr: 3.0191e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7126/  8460 | global iter:   7126/  8460 | loss: 0.0534 | ds_loss: 0.0000 | lr: 3.0147e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7127/  8460 | global iter:   7127/  8460 | loss: 0.0641 | ds_loss: 0.0000 | lr: 3.0102e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7128/  8460 | global iter:   7128/  8460 | loss: 0.0415 | ds_loss: 0.0000 | lr: 3.0058e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7128/  8460 | global iter:   7128/  8460 | loss: 0.0574 | ds_loss: 0.0000 | lr: 3.0058e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7129/  8460 | global iter:   7129/  8460 | loss: 0.0679 | ds_loss: 0.0000 | lr: 3.0014e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7130/  8460 | global iter:   7130/  8460 | loss: 0.0189 | ds_loss: 0.0000 | lr: 2.9970e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7131/  8460 | global iter:   7131/  8460 | loss: 0.0717 | ds_loss: 0.0000 | lr: 2.9926e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7132/  8460 | global iter:   7132/  8460 | loss: 0.0114 | ds_loss: 0.0000 | lr: 2.9882e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7132/  8460 | global iter:   7132/  8460 | loss: 0.0425 | ds_loss: 0.0000 | lr: 2.9882e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7133/  8460 | global iter:   7133/  8460 | loss: 0.0067 | ds_loss: 0.0000 | lr: 2.9838e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7134/  8460 | global iter:   7134/  8460 | loss: 0.0291 | ds_loss: 0.0000 | lr: 2.9795e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7135/  8460 | global iter:   7135/  8460 | loss: 0.0314 | ds_loss: 0.0000 | lr: 2.9751e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7136/  8460 | global iter:   7136/  8460 | loss: 0.0131 | ds_loss: 0.0000 | lr: 2.9707e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7136/  8460 | global iter:   7136/  8460 | loss: 0.0201 | ds_loss: 0.0000 | lr: 2.9707e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7137/  8460 | global iter:   7137/  8460 | loss: 0.0316 | ds_loss: 0.0000 | lr: 2.9663e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7138/  8460 | global iter:   7138/  8460 | loss: 0.0019 | ds_loss: 0.0000 | lr: 2.9619e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7139/  8460 | global iter:   7139/  8460 | loss: 0.0794 | ds_loss: 0.0000 | lr: 2.9576e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7140/  8460 | global iter:   7140/  8460 | loss: 0.0220 | ds_loss: 0.0000 | lr: 2.9532e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7140/  8460 | global iter:   7140/  8460 | loss: 0.0337 | ds_loss: 0.0000 | lr: 2.9532e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7141/  8460 | global iter:   7141/  8460 | loss: 0.1809 | ds_loss: 0.0000 | lr: 2.9488e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7142/  8460 | global iter:   7142/  8460 | loss: 0.0660 | ds_loss: 0.0000 | lr: 2.9444e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7143/  8460 | global iter:   7143/  8460 | loss: 0.1276 | ds_loss: 0.0000 | lr: 2.9401e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7144/  8460 | global iter:   7144/  8460 | loss: 0.1206 | ds_loss: 0.0000 | lr: 2.9357e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7144/  8460 | global iter:   7144/  8460 | loss: 0.1238 | ds_loss: 0.0000 | lr: 2.9357e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7145/  8460 | global iter:   7145/  8460 | loss: 0.1507 | ds_loss: 0.0000 | lr: 2.9314e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7146/  8460 | global iter:   7146/  8460 | loss: 0.0578 | ds_loss: 0.0000 | lr: 2.9270e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7147/  8460 | global iter:   7147/  8460 | loss: 0.0287 | ds_loss: 0.0000 | lr: 2.9227e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7148/  8460 | global iter:   7148/  8460 | loss: 0.0945 | ds_loss: 0.0000 | lr: 2.9183e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7148/  8460 | global iter:   7148/  8460 | loss: 0.0829 | ds_loss: 0.0000 | lr: 2.9183e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7149/  8460 | global iter:   7149/  8460 | loss: 0.0336 | ds_loss: 0.0000 | lr: 2.9140e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7150/  8460 | global iter:   7150/  8460 | loss: 0.0475 | ds_loss: 0.0000 | lr: 2.9096e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7151/  8460 | global iter:   7151/  8460 | loss: 0.0304 | ds_loss: 0.0000 | lr: 2.9053e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7152/  8460 | global iter:   7152/  8460 | loss: 0.1363 | ds_loss: 0.0000 | lr: 2.9010e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7152/  8460 | global iter:   7152/  8460 | loss: 0.0620 | ds_loss: 0.0000 | lr: 2.9010e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7153/  8460 | global iter:   7153/  8460 | loss: 0.0631 | ds_loss: 0.0000 | lr: 2.8966e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7154/  8460 | global iter:   7154/  8460 | loss: 0.0651 | ds_loss: 0.0000 | lr: 2.8923e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7155/  8460 | global iter:   7155/  8460 | loss: 0.0811 | ds_loss: 0.0000 | lr: 2.8880e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7156/  8460 | global iter:   7156/  8460 | loss: 0.0232 | ds_loss: 0.0000 | lr: 2.8837e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7156/  8460 | global iter:   7156/  8460 | loss: 0.0581 | ds_loss: 0.0000 | lr: 2.8837e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7157/  8460 | global iter:   7157/  8460 | loss: 0.0188 | ds_loss: 0.0000 | lr: 2.8793e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7158/  8460 | global iter:   7158/  8460 | loss: 0.0077 | ds_loss: 0.0000 | lr: 2.8750e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7159/  8460 | global iter:   7159/  8460 | loss: 0.0842 | ds_loss: 0.0000 | lr: 2.8707e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7160/  8460 | global iter:   7160/  8460 | loss: 0.0379 | ds_loss: 0.0000 | lr: 2.8664e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7160/  8460 | global iter:   7160/  8460 | loss: 0.0372 | ds_loss: 0.0000 | lr: 2.8664e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7161/  8460 | global iter:   7161/  8460 | loss: 0.2103 | ds_loss: 0.0000 | lr: 2.8621e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7162/  8460 | global iter:   7162/  8460 | loss: 0.0089 | ds_loss: 0.0000 | lr: 2.8578e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7163/  8460 | global iter:   7163/  8460 | loss: 0.0709 | ds_loss: 0.0000 | lr: 2.8535e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7164/  8460 | global iter:   7164/  8460 | loss: 0.0017 | ds_loss: 0.0000 | lr: 2.8492e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7164/  8460 | global iter:   7164/  8460 | loss: 0.0729 | ds_loss: 0.0000 | lr: 2.8492e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7165/  8460 | global iter:   7165/  8460 | loss: 0.0185 | ds_loss: 0.0000 | lr: 2.8449e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7166/  8460 | global iter:   7166/  8460 | loss: 0.0311 | ds_loss: 0.0000 | lr: 2.8406e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7167/  8460 | global iter:   7167/  8460 | loss: 0.0350 | ds_loss: 0.0000 | lr: 2.8363e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7168/  8460 | global iter:   7168/  8460 | loss: 0.0292 | ds_loss: 0.0000 | lr: 2.8320e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7168/  8460 | global iter:   7168/  8460 | loss: 0.0285 | ds_loss: 0.0000 | lr: 2.8320e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7169/  8460 | global iter:   7169/  8460 | loss: 0.0210 | ds_loss: 0.0000 | lr: 2.8277e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7170/  8460 | global iter:   7170/  8460 | loss: 0.0951 | ds_loss: 0.0000 | lr: 2.8235e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7171/  8460 | global iter:   7171/  8460 | loss: 0.0144 | ds_loss: 0.0000 | lr: 2.8192e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7172/  8460 | global iter:   7172/  8460 | loss: 0.0463 | ds_loss: 0.0000 | lr: 2.8149e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7172/  8460 | global iter:   7172/  8460 | loss: 0.0442 | ds_loss: 0.0000 | lr: 2.8149e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7173/  8460 | global iter:   7173/  8460 | loss: 0.0615 | ds_loss: 0.0000 | lr: 2.8106e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7174/  8460 | global iter:   7174/  8460 | loss: 0.0170 | ds_loss: 0.0000 | lr: 2.8064e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7175/  8460 | global iter:   7175/  8460 | loss: 0.0055 | ds_loss: 0.0000 | lr: 2.8021e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7176/  8460 | global iter:   7176/  8460 | loss: 0.0432 | ds_loss: 0.0000 | lr: 2.7978e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7176/  8460 | global iter:   7176/  8460 | loss: 0.0318 | ds_loss: 0.0000 | lr: 2.7978e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7177/  8460 | global iter:   7177/  8460 | loss: 0.0870 | ds_loss: 0.0000 | lr: 2.7936e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7178/  8460 | global iter:   7178/  8460 | loss: 0.0984 | ds_loss: 0.0000 | lr: 2.7893e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7179/  8460 | global iter:   7179/  8460 | loss: 0.0689 | ds_loss: 0.0000 | lr: 2.7851e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7180/  8460 | global iter:   7180/  8460 | loss: 0.0432 | ds_loss: 0.0000 | lr: 2.7808e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7180/  8460 | global iter:   7180/  8460 | loss: 0.0744 | ds_loss: 0.0000 | lr: 2.7808e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7181/  8460 | global iter:   7181/  8460 | loss: 0.0257 | ds_loss: 0.0000 | lr: 2.7766e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7182/  8460 | global iter:   7182/  8460 | loss: 0.0267 | ds_loss: 0.0000 | lr: 2.7723e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7183/  8460 | global iter:   7183/  8460 | loss: 0.0565 | ds_loss: 0.0000 | lr: 2.7681e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7184/  8460 | global iter:   7184/  8460 | loss: 0.1820 | ds_loss: 0.0000 | lr: 2.7639e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7184/  8460 | global iter:   7184/  8460 | loss: 0.0727 | ds_loss: 0.0000 | lr: 2.7639e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7185/  8460 | global iter:   7185/  8460 | loss: 0.0493 | ds_loss: 0.0000 | lr: 2.7596e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7186/  8460 | global iter:   7186/  8460 | loss: 0.0250 | ds_loss: 0.0000 | lr: 2.7554e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7187/  8460 | global iter:   7187/  8460 | loss: 0.0860 | ds_loss: 0.0000 | lr: 2.7512e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7188/  8460 | global iter:   7188/  8460 | loss: 0.0717 | ds_loss: 0.0000 | lr: 2.7469e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7188/  8460 | global iter:   7188/  8460 | loss: 0.0580 | ds_loss: 0.0000 | lr: 2.7469e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7189/  8460 | global iter:   7189/  8460 | loss: 0.0072 | ds_loss: 0.0000 | lr: 2.7427e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7190/  8460 | global iter:   7190/  8460 | loss: 0.0504 | ds_loss: 0.0000 | lr: 2.7385e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7191/  8460 | global iter:   7191/  8460 | loss: 0.0768 | ds_loss: 0.0000 | lr: 2.7343e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7192/  8460 | global iter:   7192/  8460 | loss: 0.0152 | ds_loss: 0.0000 | lr: 2.7301e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7192/  8460 | global iter:   7192/  8460 | loss: 0.0374 | ds_loss: 0.0000 | lr: 2.7301e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7193/  8460 | global iter:   7193/  8460 | loss: 0.0096 | ds_loss: 0.0000 | lr: 2.7259e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7194/  8460 | global iter:   7194/  8460 | loss: 0.0399 | ds_loss: 0.0000 | lr: 2.7217e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7195/  8460 | global iter:   7195/  8460 | loss: 0.0133 | ds_loss: 0.0000 | lr: 2.7175e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7196/  8460 | global iter:   7196/  8460 | loss: 0.0098 | ds_loss: 0.0000 | lr: 2.7133e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7196/  8460 | global iter:   7196/  8460 | loss: 0.0181 | ds_loss: 0.0000 | lr: 2.7133e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7197/  8460 | global iter:   7197/  8460 | loss: 0.0501 | ds_loss: 0.0000 | lr: 2.7091e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7198/  8460 | global iter:   7198/  8460 | loss: 0.0470 | ds_loss: 0.0000 | lr: 2.7049e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7199/  8460 | global iter:   7199/  8460 | loss: 0.1691 | ds_loss: 0.0000 | lr: 2.7007e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7200/  8460 | global iter:   7200/  8460 | loss: 0.0445 | ds_loss: 0.0000 | lr: 2.6965e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7200/  8460 | global iter:   7200/  8460 | loss: 0.0777 | ds_loss: 0.0000 | lr: 2.6965e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7201/  8460 | global iter:   7201/  8460 | loss: 0.0272 | ds_loss: 0.0000 | lr: 2.6923e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7202/  8460 | global iter:   7202/  8460 | loss: 0.0009 | ds_loss: 0.0000 | lr: 2.6881e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7203/  8460 | global iter:   7203/  8460 | loss: 0.0123 | ds_loss: 0.0000 | lr: 2.6839e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7204/  8460 | global iter:   7204/  8460 | loss: 0.0323 | ds_loss: 0.0000 | lr: 2.6798e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7204/  8460 | global iter:   7204/  8460 | loss: 0.0182 | ds_loss: 0.0000 | lr: 2.6798e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7205/  8460 | global iter:   7205/  8460 | loss: 0.0928 | ds_loss: 0.0000 | lr: 2.6756e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7206/  8460 | global iter:   7206/  8460 | loss: 0.0407 | ds_loss: 0.0000 | lr: 2.6714e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7207/  8460 | global iter:   7207/  8460 | loss: 0.0170 | ds_loss: 0.0000 | lr: 2.6673e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7208/  8460 | global iter:   7208/  8460 | loss: 0.0212 | ds_loss: 0.0000 | lr: 2.6631e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7208/  8460 | global iter:   7208/  8460 | loss: 0.0429 | ds_loss: 0.0000 | lr: 2.6631e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7209/  8460 | global iter:   7209/  8460 | loss: 0.0838 | ds_loss: 0.0000 | lr: 2.6589e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7210/  8460 | global iter:   7210/  8460 | loss: 0.0364 | ds_loss: 0.0000 | lr: 2.6548e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7211/  8460 | global iter:   7211/  8460 | loss: 0.0528 | ds_loss: 0.0000 | lr: 2.6506e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7212/  8460 | global iter:   7212/  8460 | loss: 0.0039 | ds_loss: 0.0000 | lr: 2.6465e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7212/  8460 | global iter:   7212/  8460 | loss: 0.0442 | ds_loss: 0.0000 | lr: 2.6465e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7213/  8460 | global iter:   7213/  8460 | loss: 0.0319 | ds_loss: 0.0000 | lr: 2.6423e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7214/  8460 | global iter:   7214/  8460 | loss: 0.0890 | ds_loss: 0.0000 | lr: 2.6382e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7215/  8460 | global iter:   7215/  8460 | loss: 0.0056 | ds_loss: 0.0000 | lr: 2.6340e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7216/  8460 | global iter:   7216/  8460 | loss: 0.0685 | ds_loss: 0.0000 | lr: 2.6299e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7216/  8460 | global iter:   7216/  8460 | loss: 0.0488 | ds_loss: 0.0000 | lr: 2.6299e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7217/  8460 | global iter:   7217/  8460 | loss: 0.0286 | ds_loss: 0.0000 | lr: 2.6258e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7218/  8460 | global iter:   7218/  8460 | loss: 0.0397 | ds_loss: 0.0000 | lr: 2.6216e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7219/  8460 | global iter:   7219/  8460 | loss: 0.0268 | ds_loss: 0.0000 | lr: 2.6175e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7220/  8460 | global iter:   7220/  8460 | loss: 0.0042 | ds_loss: 0.0000 | lr: 2.6134e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7220/  8460 | global iter:   7220/  8460 | loss: 0.0248 | ds_loss: 0.0000 | lr: 2.6134e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7221/  8460 | global iter:   7221/  8460 | loss: 0.0169 | ds_loss: 0.0000 | lr: 2.6093e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7222/  8460 | global iter:   7222/  8460 | loss: 0.0795 | ds_loss: 0.0000 | lr: 2.6051e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7223/  8460 | global iter:   7223/  8460 | loss: 0.0165 | ds_loss: 0.0000 | lr: 2.6010e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7224/  8460 | global iter:   7224/  8460 | loss: 0.2143 | ds_loss: 0.0000 | lr: 2.5969e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7224/  8460 | global iter:   7224/  8460 | loss: 0.0818 | ds_loss: 0.0000 | lr: 2.5969e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7225/  8460 | global iter:   7225/  8460 | loss: 0.0045 | ds_loss: 0.0000 | lr: 2.5928e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7226/  8460 | global iter:   7226/  8460 | loss: 0.0035 | ds_loss: 0.0000 | lr: 2.5887e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7227/  8460 | global iter:   7227/  8460 | loss: 0.0632 | ds_loss: 0.0000 | lr: 2.5846e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7228/  8460 | global iter:   7228/  8460 | loss: 0.0746 | ds_loss: 0.0000 | lr: 2.5805e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7228/  8460 | global iter:   7228/  8460 | loss: 0.0365 | ds_loss: 0.0000 | lr: 2.5805e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7229/  8460 | global iter:   7229/  8460 | loss: 0.0361 | ds_loss: 0.0000 | lr: 2.5764e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7230/  8460 | global iter:   7230/  8460 | loss: 0.0696 | ds_loss: 0.0000 | lr: 2.5723e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7231/  8460 | global iter:   7231/  8460 | loss: 0.0612 | ds_loss: 0.0000 | lr: 2.5682e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7232/  8460 | global iter:   7232/  8460 | loss: 0.0151 | ds_loss: 0.0000 | lr: 2.5641e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7232/  8460 | global iter:   7232/  8460 | loss: 0.0455 | ds_loss: 0.0000 | lr: 2.5641e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7233/  8460 | global iter:   7233/  8460 | loss: 0.1499 | ds_loss: 0.0000 | lr: 2.5600e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7234/  8460 | global iter:   7234/  8460 | loss: 0.0231 | ds_loss: 0.0000 | lr: 2.5559e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7235/  8460 | global iter:   7235/  8460 | loss: 0.0174 | ds_loss: 0.0000 | lr: 2.5519e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7236/  8460 | global iter:   7236/  8460 | loss: 0.0349 | ds_loss: 0.0000 | lr: 2.5478e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7236/  8460 | global iter:   7236/  8460 | loss: 0.0563 | ds_loss: 0.0000 | lr: 2.5478e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7237/  8460 | global iter:   7237/  8460 | loss: 0.0134 | ds_loss: 0.0000 | lr: 2.5437e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7238/  8460 | global iter:   7238/  8460 | loss: 0.0359 | ds_loss: 0.0000 | lr: 2.5396e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7239/  8460 | global iter:   7239/  8460 | loss: 0.0646 | ds_loss: 0.0000 | lr: 2.5356e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7240/  8460 | global iter:   7240/  8460 | loss: 0.0481 | ds_loss: 0.0000 | lr: 2.5315e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7240/  8460 | global iter:   7240/  8460 | loss: 0.0405 | ds_loss: 0.0000 | lr: 2.5315e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7241/  8460 | global iter:   7241/  8460 | loss: 0.0289 | ds_loss: 0.0000 | lr: 2.5275e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7242/  8460 | global iter:   7242/  8460 | loss: 0.0282 | ds_loss: 0.0000 | lr: 2.5234e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7243/  8460 | global iter:   7243/  8460 | loss: 0.1366 | ds_loss: 0.0000 | lr: 2.5193e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7244/  8460 | global iter:   7244/  8460 | loss: 0.0894 | ds_loss: 0.0000 | lr: 2.5153e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7244/  8460 | global iter:   7244/  8460 | loss: 0.0708 | ds_loss: 0.0000 | lr: 2.5153e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7245/  8460 | global iter:   7245/  8460 | loss: 0.2072 | ds_loss: 0.0000 | lr: 2.5112e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7246/  8460 | global iter:   7246/  8460 | loss: 0.0721 | ds_loss: 0.0000 | lr: 2.5072e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7247/  8460 | global iter:   7247/  8460 | loss: 0.0032 | ds_loss: 0.0000 | lr: 2.5031e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7248/  8460 | global iter:   7248/  8460 | loss: 0.0234 | ds_loss: 0.0000 | lr: 2.4991e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7248/  8460 | global iter:   7248/  8460 | loss: 0.0765 | ds_loss: 0.0000 | lr: 2.4991e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7249/  8460 | global iter:   7249/  8460 | loss: 0.0323 | ds_loss: 0.0000 | lr: 2.4951e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7250/  8460 | global iter:   7250/  8460 | loss: 0.0567 | ds_loss: 0.0000 | lr: 2.4910e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7251/  8460 | global iter:   7251/  8460 | loss: 0.0606 | ds_loss: 0.0000 | lr: 2.4870e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7252/  8460 | global iter:   7252/  8460 | loss: 0.0253 | ds_loss: 0.0000 | lr: 2.4830e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7252/  8460 | global iter:   7252/  8460 | loss: 0.0437 | ds_loss: 0.0000 | lr: 2.4830e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7253/  8460 | global iter:   7253/  8460 | loss: 0.0331 | ds_loss: 0.0000 | lr: 2.4790e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7254/  8460 | global iter:   7254/  8460 | loss: 0.1083 | ds_loss: 0.0000 | lr: 2.4749e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7255/  8460 | global iter:   7255/  8460 | loss: 0.1829 | ds_loss: 0.0000 | lr: 2.4709e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7256/  8460 | global iter:   7256/  8460 | loss: 0.0216 | ds_loss: 0.0000 | lr: 2.4669e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7256/  8460 | global iter:   7256/  8460 | loss: 0.0865 | ds_loss: 0.0000 | lr: 2.4669e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7257/  8460 | global iter:   7257/  8460 | loss: 0.0757 | ds_loss: 0.0000 | lr: 2.4629e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7258/  8460 | global iter:   7258/  8460 | loss: 0.1502 | ds_loss: 0.0000 | lr: 2.4589e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7259/  8460 | global iter:   7259/  8460 | loss: 0.0149 | ds_loss: 0.0000 | lr: 2.4549e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7260/  8460 | global iter:   7260/  8460 | loss: 0.2256 | ds_loss: 0.0000 | lr: 2.4509e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7260/  8460 | global iter:   7260/  8460 | loss: 0.1166 | ds_loss: 0.0000 | lr: 2.4509e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7261/  8460 | global iter:   7261/  8460 | loss: 0.0663 | ds_loss: 0.0000 | lr: 2.4469e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7262/  8460 | global iter:   7262/  8460 | loss: 0.0196 | ds_loss: 0.0000 | lr: 2.4429e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7263/  8460 | global iter:   7263/  8460 | loss: 0.0027 | ds_loss: 0.0000 | lr: 2.4389e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7264/  8460 | global iter:   7264/  8460 | loss: 0.0264 | ds_loss: 0.0000 | lr: 2.4349e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7264/  8460 | global iter:   7264/  8460 | loss: 0.0287 | ds_loss: 0.0000 | lr: 2.4349e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7265/  8460 | global iter:   7265/  8460 | loss: 0.1981 | ds_loss: 0.0000 | lr: 2.4309e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7266/  8460 | global iter:   7266/  8460 | loss: 0.0224 | ds_loss: 0.0000 | lr: 2.4269e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7267/  8460 | global iter:   7267/  8460 | loss: 0.0257 | ds_loss: 0.0000 | lr: 2.4230e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7268/  8460 | global iter:   7268/  8460 | loss: 0.0457 | ds_loss: 0.0000 | lr: 2.4190e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7268/  8460 | global iter:   7268/  8460 | loss: 0.0730 | ds_loss: 0.0000 | lr: 2.4190e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7269/  8460 | global iter:   7269/  8460 | loss: 0.0821 | ds_loss: 0.0000 | lr: 2.4150e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7270/  8460 | global iter:   7270/  8460 | loss: 0.1049 | ds_loss: 0.0000 | lr: 2.4110e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7271/  8460 | global iter:   7271/  8460 | loss: 0.0214 | ds_loss: 0.0000 | lr: 2.4071e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7272/  8460 | global iter:   7272/  8460 | loss: 0.0472 | ds_loss: 0.0000 | lr: 2.4031e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7272/  8460 | global iter:   7272/  8460 | loss: 0.0639 | ds_loss: 0.0000 | lr: 2.4031e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7273/  8460 | global iter:   7273/  8460 | loss: 0.0605 | ds_loss: 0.0000 | lr: 2.3991e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7274/  8460 | global iter:   7274/  8460 | loss: 0.0681 | ds_loss: 0.0000 | lr: 2.3952e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7275/  8460 | global iter:   7275/  8460 | loss: 0.0228 | ds_loss: 0.0000 | lr: 2.3912e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7276/  8460 | global iter:   7276/  8460 | loss: 0.0797 | ds_loss: 0.0000 | lr: 2.3873e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7276/  8460 | global iter:   7276/  8460 | loss: 0.0578 | ds_loss: 0.0000 | lr: 2.3873e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7277/  8460 | global iter:   7277/  8460 | loss: 0.0580 | ds_loss: 0.0000 | lr: 2.3833e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7278/  8460 | global iter:   7278/  8460 | loss: 0.0243 | ds_loss: 0.0000 | lr: 2.3794e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7279/  8460 | global iter:   7279/  8460 | loss: 0.0698 | ds_loss: 0.0000 | lr: 2.3754e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7280/  8460 | global iter:   7280/  8460 | loss: 0.0976 | ds_loss: 0.0000 | lr: 2.3715e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7280/  8460 | global iter:   7280/  8460 | loss: 0.0624 | ds_loss: 0.0000 | lr: 2.3715e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7281/  8460 | global iter:   7281/  8460 | loss: 0.0119 | ds_loss: 0.0000 | lr: 2.3676e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7282/  8460 | global iter:   7282/  8460 | loss: 0.0324 | ds_loss: 0.0000 | lr: 2.3636e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7283/  8460 | global iter:   7283/  8460 | loss: 0.0548 | ds_loss: 0.0000 | lr: 2.3597e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7284/  8460 | global iter:   7284/  8460 | loss: 0.0497 | ds_loss: 0.0000 | lr: 2.3558e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7284/  8460 | global iter:   7284/  8460 | loss: 0.0372 | ds_loss: 0.0000 | lr: 2.3558e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7285/  8460 | global iter:   7285/  8460 | loss: 0.0244 | ds_loss: 0.0000 | lr: 2.3518e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7286/  8460 | global iter:   7286/  8460 | loss: 0.1787 | ds_loss: 0.0000 | lr: 2.3479e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7287/  8460 | global iter:   7287/  8460 | loss: 0.0509 | ds_loss: 0.0000 | lr: 2.3440e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7288/  8460 | global iter:   7288/  8460 | loss: 0.0391 | ds_loss: 0.0000 | lr: 2.3401e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7288/  8460 | global iter:   7288/  8460 | loss: 0.0733 | ds_loss: 0.0000 | lr: 2.3401e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7289/  8460 | global iter:   7289/  8460 | loss: 0.0331 | ds_loss: 0.0000 | lr: 2.3362e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7290/  8460 | global iter:   7290/  8460 | loss: 0.0979 | ds_loss: 0.0000 | lr: 2.3323e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7291/  8460 | global iter:   7291/  8460 | loss: 0.0513 | ds_loss: 0.0000 | lr: 2.3284e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7292/  8460 | global iter:   7292/  8460 | loss: 0.0902 | ds_loss: 0.0000 | lr: 2.3245e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7292/  8460 | global iter:   7292/  8460 | loss: 0.0681 | ds_loss: 0.0000 | lr: 2.3245e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7293/  8460 | global iter:   7293/  8460 | loss: 0.0066 | ds_loss: 0.0000 | lr: 2.3206e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7294/  8460 | global iter:   7294/  8460 | loss: 0.1708 | ds_loss: 0.0000 | lr: 2.3167e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7295/  8460 | global iter:   7295/  8460 | loss: 0.0252 | ds_loss: 0.0000 | lr: 2.3128e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7296/  8460 | global iter:   7296/  8460 | loss: 0.0742 | ds_loss: 0.0000 | lr: 2.3089e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7296/  8460 | global iter:   7296/  8460 | loss: 0.0692 | ds_loss: 0.0000 | lr: 2.3089e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7297/  8460 | global iter:   7297/  8460 | loss: 0.0284 | ds_loss: 0.0000 | lr: 2.3050e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7298/  8460 | global iter:   7298/  8460 | loss: 0.0820 | ds_loss: 0.0000 | lr: 2.3011e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7299/  8460 | global iter:   7299/  8460 | loss: 0.0156 | ds_loss: 0.0000 | lr: 2.2972e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7300/  8460 | global iter:   7300/  8460 | loss: 0.1186 | ds_loss: 0.0000 | lr: 2.2933e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7300/  8460 | global iter:   7300/  8460 | loss: 0.0612 | ds_loss: 0.0000 | lr: 2.2933e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7301/  8460 | global iter:   7301/  8460 | loss: 0.0229 | ds_loss: 0.0000 | lr: 2.2895e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7302/  8460 | global iter:   7302/  8460 | loss: 0.0179 | ds_loss: 0.0000 | lr: 2.2856e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7303/  8460 | global iter:   7303/  8460 | loss: 0.0208 | ds_loss: 0.0000 | lr: 2.2817e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7304/  8460 | global iter:   7304/  8460 | loss: 0.2106 | ds_loss: 0.0000 | lr: 2.2779e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7304/  8460 | global iter:   7304/  8460 | loss: 0.0680 | ds_loss: 0.0000 | lr: 2.2779e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7305/  8460 | global iter:   7305/  8460 | loss: 0.0014 | ds_loss: 0.0000 | lr: 2.2740e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7306/  8460 | global iter:   7306/  8460 | loss: 0.1874 | ds_loss: 0.0000 | lr: 2.2702e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7307/  8460 | global iter:   7307/  8460 | loss: 0.0553 | ds_loss: 0.0000 | lr: 2.2663e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7308/  8460 | global iter:   7308/  8460 | loss: 0.1364 | ds_loss: 0.0000 | lr: 2.2624e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7308/  8460 | global iter:   7308/  8460 | loss: 0.0951 | ds_loss: 0.0000 | lr: 2.2624e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7309/  8460 | global iter:   7309/  8460 | loss: 0.0615 | ds_loss: 0.0000 | lr: 2.2586e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7310/  8460 | global iter:   7310/  8460 | loss: 0.0366 | ds_loss: 0.0000 | lr: 2.2547e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7311/  8460 | global iter:   7311/  8460 | loss: 0.0412 | ds_loss: 0.0000 | lr: 2.2509e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7312/  8460 | global iter:   7312/  8460 | loss: 0.0677 | ds_loss: 0.0000 | lr: 2.2471e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7312/  8460 | global iter:   7312/  8460 | loss: 0.0518 | ds_loss: 0.0000 | lr: 2.2471e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7313/  8460 | global iter:   7313/  8460 | loss: 0.0392 | ds_loss: 0.0000 | lr: 2.2432e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7314/  8460 | global iter:   7314/  8460 | loss: 0.0545 | ds_loss: 0.0000 | lr: 2.2394e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7315/  8460 | global iter:   7315/  8460 | loss: 0.0313 | ds_loss: 0.0000 | lr: 2.2356e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7316/  8460 | global iter:   7316/  8460 | loss: 0.0341 | ds_loss: 0.0000 | lr: 2.2317e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7316/  8460 | global iter:   7316/  8460 | loss: 0.0397 | ds_loss: 0.0000 | lr: 2.2317e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7317/  8460 | global iter:   7317/  8460 | loss: 0.1138 | ds_loss: 0.0000 | lr: 2.2279e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7318/  8460 | global iter:   7318/  8460 | loss: 0.0028 | ds_loss: 0.0000 | lr: 2.2241e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7319/  8460 | global iter:   7319/  8460 | loss: 0.0064 | ds_loss: 0.0000 | lr: 2.2203e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7320/  8460 | global iter:   7320/  8460 | loss: 0.0887 | ds_loss: 0.0000 | lr: 2.2165e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7320/  8460 | global iter:   7320/  8460 | loss: 0.0529 | ds_loss: 0.0000 | lr: 2.2165e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7321/  8460 | global iter:   7321/  8460 | loss: 0.0927 | ds_loss: 0.0000 | lr: 2.2126e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7322/  8460 | global iter:   7322/  8460 | loss: 0.1105 | ds_loss: 0.0000 | lr: 2.2088e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7323/  8460 | global iter:   7323/  8460 | loss: 0.1096 | ds_loss: 0.0000 | lr: 2.2050e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7324/  8460 | global iter:   7324/  8460 | loss: 0.0988 | ds_loss: 0.0000 | lr: 2.2012e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7324/  8460 | global iter:   7324/  8460 | loss: 0.1029 | ds_loss: 0.0000 | lr: 2.2012e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7325/  8460 | global iter:   7325/  8460 | loss: 0.0161 | ds_loss: 0.0000 | lr: 2.1974e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7326/  8460 | global iter:   7326/  8460 | loss: 0.0051 | ds_loss: 0.0000 | lr: 2.1936e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7327/  8460 | global iter:   7327/  8460 | loss: 0.0612 | ds_loss: 0.0000 | lr: 2.1898e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7328/  8460 | global iter:   7328/  8460 | loss: 0.0025 | ds_loss: 0.0000 | lr: 2.1861e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7328/  8460 | global iter:   7328/  8460 | loss: 0.0212 | ds_loss: 0.0000 | lr: 2.1861e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7329/  8460 | global iter:   7329/  8460 | loss: 0.0266 | ds_loss: 0.0000 | lr: 2.1823e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7330/  8460 | global iter:   7330/  8460 | loss: 0.0338 | ds_loss: 0.0000 | lr: 2.1785e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7331/  8460 | global iter:   7331/  8460 | loss: 0.0162 | ds_loss: 0.0000 | lr: 2.1747e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7332/  8460 | global iter:   7332/  8460 | loss: 0.0777 | ds_loss: 0.0000 | lr: 2.1709e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7332/  8460 | global iter:   7332/  8460 | loss: 0.0386 | ds_loss: 0.0000 | lr: 2.1709e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7333/  8460 | global iter:   7333/  8460 | loss: 0.0041 | ds_loss: 0.0000 | lr: 2.1672e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7334/  8460 | global iter:   7334/  8460 | loss: 0.2337 | ds_loss: 0.0000 | lr: 2.1634e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7335/  8460 | global iter:   7335/  8460 | loss: 0.1285 | ds_loss: 0.0000 | lr: 2.1596e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7336/  8460 | global iter:   7336/  8460 | loss: 0.0312 | ds_loss: 0.0000 | lr: 2.1559e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7336/  8460 | global iter:   7336/  8460 | loss: 0.0994 | ds_loss: 0.0000 | lr: 2.1559e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7337/  8460 | global iter:   7337/  8460 | loss: 0.0307 | ds_loss: 0.0000 | lr: 2.1521e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7338/  8460 | global iter:   7338/  8460 | loss: 0.0319 | ds_loss: 0.0000 | lr: 2.1483e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7339/  8460 | global iter:   7339/  8460 | loss: 0.0553 | ds_loss: 0.0000 | lr: 2.1446e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7340/  8460 | global iter:   7340/  8460 | loss: 0.0612 | ds_loss: 0.0000 | lr: 2.1408e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7340/  8460 | global iter:   7340/  8460 | loss: 0.0448 | ds_loss: 0.0000 | lr: 2.1408e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7341/  8460 | global iter:   7341/  8460 | loss: 0.0978 | ds_loss: 0.0000 | lr: 2.1371e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7342/  8460 | global iter:   7342/  8460 | loss: 0.0360 | ds_loss: 0.0000 | lr: 2.1333e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7343/  8460 | global iter:   7343/  8460 | loss: 0.0156 | ds_loss: 0.0000 | lr: 2.1296e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7344/  8460 | global iter:   7344/  8460 | loss: 0.0450 | ds_loss: 0.0000 | lr: 2.1259e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7344/  8460 | global iter:   7344/  8460 | loss: 0.0486 | ds_loss: 0.0000 | lr: 2.1259e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7345/  8460 | global iter:   7345/  8460 | loss: 0.0331 | ds_loss: 0.0000 | lr: 2.1221e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7346/  8460 | global iter:   7346/  8460 | loss: 0.0462 | ds_loss: 0.0000 | lr: 2.1184e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7347/  8460 | global iter:   7347/  8460 | loss: 0.0311 | ds_loss: 0.0000 | lr: 2.1147e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7348/  8460 | global iter:   7348/  8460 | loss: 0.0105 | ds_loss: 0.0000 | lr: 2.1109e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7348/  8460 | global iter:   7348/  8460 | loss: 0.0302 | ds_loss: 0.0000 | lr: 2.1109e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7349/  8460 | global iter:   7349/  8460 | loss: 0.0134 | ds_loss: 0.0000 | lr: 2.1072e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7350/  8460 | global iter:   7350/  8460 | loss: 0.1123 | ds_loss: 0.0000 | lr: 2.1035e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7351/  8460 | global iter:   7351/  8460 | loss: 0.0527 | ds_loss: 0.0000 | lr: 2.0998e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7352/  8460 | global iter:   7352/  8460 | loss: 0.0808 | ds_loss: 0.0000 | lr: 2.0961e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7352/  8460 | global iter:   7352/  8460 | loss: 0.0648 | ds_loss: 0.0000 | lr: 2.0961e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7353/  8460 | global iter:   7353/  8460 | loss: 0.1097 | ds_loss: 0.0000 | lr: 2.0923e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7354/  8460 | global iter:   7354/  8460 | loss: 0.0128 | ds_loss: 0.0000 | lr: 2.0886e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7355/  8460 | global iter:   7355/  8460 | loss: 0.1509 | ds_loss: 0.0000 | lr: 2.0849e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7356/  8460 | global iter:   7356/  8460 | loss: 0.0313 | ds_loss: 0.0000 | lr: 2.0812e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7356/  8460 | global iter:   7356/  8460 | loss: 0.0762 | ds_loss: 0.0000 | lr: 2.0812e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7357/  8460 | global iter:   7357/  8460 | loss: 0.0207 | ds_loss: 0.0000 | lr: 2.0775e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7358/  8460 | global iter:   7358/  8460 | loss: 0.0142 | ds_loss: 0.0000 | lr: 2.0738e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7359/  8460 | global iter:   7359/  8460 | loss: 0.1065 | ds_loss: 0.0000 | lr: 2.0701e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7360/  8460 | global iter:   7360/  8460 | loss: 0.0260 | ds_loss: 0.0000 | lr: 2.0665e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7360/  8460 | global iter:   7360/  8460 | loss: 0.0418 | ds_loss: 0.0000 | lr: 2.0665e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7361/  8460 | global iter:   7361/  8460 | loss: 0.0393 | ds_loss: 0.0000 | lr: 2.0628e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7362/  8460 | global iter:   7362/  8460 | loss: 0.1148 | ds_loss: 0.0000 | lr: 2.0591e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7363/  8460 | global iter:   7363/  8460 | loss: 0.0440 | ds_loss: 0.0000 | lr: 2.0554e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7364/  8460 | global iter:   7364/  8460 | loss: 0.1646 | ds_loss: 0.0000 | lr: 2.0517e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7364/  8460 | global iter:   7364/  8460 | loss: 0.0907 | ds_loss: 0.0000 | lr: 2.0517e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7365/  8460 | global iter:   7365/  8460 | loss: 0.1376 | ds_loss: 0.0000 | lr: 2.0481e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7366/  8460 | global iter:   7366/  8460 | loss: 0.0246 | ds_loss: 0.0000 | lr: 2.0444e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7367/  8460 | global iter:   7367/  8460 | loss: 0.0179 | ds_loss: 0.0000 | lr: 2.0407e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7368/  8460 | global iter:   7368/  8460 | loss: 0.0186 | ds_loss: 0.0000 | lr: 2.0371e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7368/  8460 | global iter:   7368/  8460 | loss: 0.0497 | ds_loss: 0.0000 | lr: 2.0371e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7369/  8460 | global iter:   7369/  8460 | loss: 0.0807 | ds_loss: 0.0000 | lr: 2.0334e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7370/  8460 | global iter:   7370/  8460 | loss: 0.0316 | ds_loss: 0.0000 | lr: 2.0297e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7371/  8460 | global iter:   7371/  8460 | loss: 0.0245 | ds_loss: 0.0000 | lr: 2.0261e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7372/  8460 | global iter:   7372/  8460 | loss: 0.1568 | ds_loss: 0.0000 | lr: 2.0224e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7372/  8460 | global iter:   7372/  8460 | loss: 0.0734 | ds_loss: 0.0000 | lr: 2.0224e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7373/  8460 | global iter:   7373/  8460 | loss: 0.0962 | ds_loss: 0.0000 | lr: 2.0188e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7374/  8460 | global iter:   7374/  8460 | loss: 0.0171 | ds_loss: 0.0000 | lr: 2.0152e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7375/  8460 | global iter:   7375/  8460 | loss: 0.1438 | ds_loss: 0.0000 | lr: 2.0115e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7376/  8460 | global iter:   7376/  8460 | loss: 0.1779 | ds_loss: 0.0000 | lr: 2.0079e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7376/  8460 | global iter:   7376/  8460 | loss: 0.1087 | ds_loss: 0.0000 | lr: 2.0079e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7377/  8460 | global iter:   7377/  8460 | loss: 0.0201 | ds_loss: 0.0000 | lr: 2.0042e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7378/  8460 | global iter:   7378/  8460 | loss: 0.0796 | ds_loss: 0.0000 | lr: 2.0006e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7379/  8460 | global iter:   7379/  8460 | loss: 0.0192 | ds_loss: 0.0000 | lr: 1.9970e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7380/  8460 | global iter:   7380/  8460 | loss: 0.0349 | ds_loss: 0.0000 | lr: 1.9934e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7380/  8460 | global iter:   7380/  8460 | loss: 0.0385 | ds_loss: 0.0000 | lr: 1.9934e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7381/  8460 | global iter:   7381/  8460 | loss: 0.1201 | ds_loss: 0.0000 | lr: 1.9897e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7382/  8460 | global iter:   7382/  8460 | loss: 0.0566 | ds_loss: 0.0000 | lr: 1.9861e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7383/  8460 | global iter:   7383/  8460 | loss: 0.0609 | ds_loss: 0.0000 | lr: 1.9825e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7384/  8460 | global iter:   7384/  8460 | loss: 0.0812 | ds_loss: 0.0000 | lr: 1.9789e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7384/  8460 | global iter:   7384/  8460 | loss: 0.0797 | ds_loss: 0.0000 | lr: 1.9789e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7385/  8460 | global iter:   7385/  8460 | loss: 0.1736 | ds_loss: 0.0000 | lr: 1.9753e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7386/  8460 | global iter:   7386/  8460 | loss: 0.0032 | ds_loss: 0.0000 | lr: 1.9717e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7387/  8460 | global iter:   7387/  8460 | loss: 0.0127 | ds_loss: 0.0000 | lr: 1.9681e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7388/  8460 | global iter:   7388/  8460 | loss: 0.0254 | ds_loss: 0.0000 | lr: 1.9645e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7388/  8460 | global iter:   7388/  8460 | loss: 0.0537 | ds_loss: 0.0000 | lr: 1.9645e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7389/  8460 | global iter:   7389/  8460 | loss: 0.0068 | ds_loss: 0.0000 | lr: 1.9609e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7390/  8460 | global iter:   7390/  8460 | loss: 0.0246 | ds_loss: 0.0000 | lr: 1.9573e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7391/  8460 | global iter:   7391/  8460 | loss: 0.0365 | ds_loss: 0.0000 | lr: 1.9537e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7392/  8460 | global iter:   7392/  8460 | loss: 0.0237 | ds_loss: 0.0000 | lr: 1.9501e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7392/  8460 | global iter:   7392/  8460 | loss: 0.0229 | ds_loss: 0.0000 | lr: 1.9501e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7393/  8460 | global iter:   7393/  8460 | loss: 0.0025 | ds_loss: 0.0000 | lr: 1.9465e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7394/  8460 | global iter:   7394/  8460 | loss: 0.0622 | ds_loss: 0.0000 | lr: 1.9429e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7395/  8460 | global iter:   7395/  8460 | loss: 0.0426 | ds_loss: 0.0000 | lr: 1.9394e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7396/  8460 | global iter:   7396/  8460 | loss: 0.0386 | ds_loss: 0.0000 | lr: 1.9358e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7396/  8460 | global iter:   7396/  8460 | loss: 0.0365 | ds_loss: 0.0000 | lr: 1.9358e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7397/  8460 | global iter:   7397/  8460 | loss: 0.0115 | ds_loss: 0.0000 | lr: 1.9322e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7398/  8460 | global iter:   7398/  8460 | loss: 0.0189 | ds_loss: 0.0000 | lr: 1.9286e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7399/  8460 | global iter:   7399/  8460 | loss: 0.0513 | ds_loss: 0.0000 | lr: 1.9251e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7400/  8460 | global iter:   7400/  8460 | loss: 0.0292 | ds_loss: 0.0000 | lr: 1.9215e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7400/  8460 | global iter:   7400/  8460 | loss: 0.0277 | ds_loss: 0.0000 | lr: 1.9215e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7401/  8460 | global iter:   7401/  8460 | loss: 0.0081 | ds_loss: 0.0000 | lr: 1.9180e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7402/  8460 | global iter:   7402/  8460 | loss: 0.0186 | ds_loss: 0.0000 | lr: 1.9144e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7403/  8460 | global iter:   7403/  8460 | loss: 0.0604 | ds_loss: 0.0000 | lr: 1.9109e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7404/  8460 | global iter:   7404/  8460 | loss: 0.0397 | ds_loss: 0.0000 | lr: 1.9073e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7404/  8460 | global iter:   7404/  8460 | loss: 0.0317 | ds_loss: 0.0000 | lr: 1.9073e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7405/  8460 | global iter:   7405/  8460 | loss: 0.0483 | ds_loss: 0.0000 | lr: 1.9038e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7406/  8460 | global iter:   7406/  8460 | loss: 0.0517 | ds_loss: 0.0000 | lr: 1.9002e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7407/  8460 | global iter:   7407/  8460 | loss: 0.0377 | ds_loss: 0.0000 | lr: 1.8967e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7408/  8460 | global iter:   7408/  8460 | loss: 0.0468 | ds_loss: 0.0000 | lr: 1.8931e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7408/  8460 | global iter:   7408/  8460 | loss: 0.0461 | ds_loss: 0.0000 | lr: 1.8931e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7409/  8460 | global iter:   7409/  8460 | loss: 0.0246 | ds_loss: 0.0000 | lr: 1.8896e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7410/  8460 | global iter:   7410/  8460 | loss: 0.0126 | ds_loss: 0.0000 | lr: 1.8861e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7411/  8460 | global iter:   7411/  8460 | loss: 0.0179 | ds_loss: 0.0000 | lr: 1.8826e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7412/  8460 | global iter:   7412/  8460 | loss: 0.0160 | ds_loss: 0.0000 | lr: 1.8790e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7412/  8460 | global iter:   7412/  8460 | loss: 0.0178 | ds_loss: 0.0000 | lr: 1.8790e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7413/  8460 | global iter:   7413/  8460 | loss: 0.0317 | ds_loss: 0.0000 | lr: 1.8755e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7414/  8460 | global iter:   7414/  8460 | loss: 0.0131 | ds_loss: 0.0000 | lr: 1.8720e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7415/  8460 | global iter:   7415/  8460 | loss: 0.0103 | ds_loss: 0.0000 | lr: 1.8685e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7416/  8460 | global iter:   7416/  8460 | loss: 0.0314 | ds_loss: 0.0000 | lr: 1.8650e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7416/  8460 | global iter:   7416/  8460 | loss: 0.0216 | ds_loss: 0.0000 | lr: 1.8650e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7417/  8460 | global iter:   7417/  8460 | loss: 0.0033 | ds_loss: 0.0000 | lr: 1.8615e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7418/  8460 | global iter:   7418/  8460 | loss: 0.0277 | ds_loss: 0.0000 | lr: 1.8580e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7419/  8460 | global iter:   7419/  8460 | loss: 0.0180 | ds_loss: 0.0000 | lr: 1.8545e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7420/  8460 | global iter:   7420/  8460 | loss: 0.0238 | ds_loss: 0.0000 | lr: 1.8510e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7420/  8460 | global iter:   7420/  8460 | loss: 0.0182 | ds_loss: 0.0000 | lr: 1.8510e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7421/  8460 | global iter:   7421/  8460 | loss: 0.0286 | ds_loss: 0.0000 | lr: 1.8475e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7422/  8460 | global iter:   7422/  8460 | loss: 0.0195 | ds_loss: 0.0000 | lr: 1.8440e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7423/  8460 | global iter:   7423/  8460 | loss: 0.2692 | ds_loss: 0.0000 | lr: 1.8405e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7424/  8460 | global iter:   7424/  8460 | loss: 0.0560 | ds_loss: 0.0000 | lr: 1.8370e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7424/  8460 | global iter:   7424/  8460 | loss: 0.0933 | ds_loss: 0.0000 | lr: 1.8370e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7425/  8460 | global iter:   7425/  8460 | loss: 0.0660 | ds_loss: 0.0000 | lr: 1.8335e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7426/  8460 | global iter:   7426/  8460 | loss: 0.0230 | ds_loss: 0.0000 | lr: 1.8300e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7427/  8460 | global iter:   7427/  8460 | loss: 0.0927 | ds_loss: 0.0000 | lr: 1.8266e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7428/  8460 | global iter:   7428/  8460 | loss: 0.0312 | ds_loss: 0.0000 | lr: 1.8231e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7428/  8460 | global iter:   7428/  8460 | loss: 0.0532 | ds_loss: 0.0000 | lr: 1.8231e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7429/  8460 | global iter:   7429/  8460 | loss: 0.0723 | ds_loss: 0.0000 | lr: 1.8196e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7430/  8460 | global iter:   7430/  8460 | loss: 0.1164 | ds_loss: 0.0000 | lr: 1.8162e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7431/  8460 | global iter:   7431/  8460 | loss: 0.0660 | ds_loss: 0.0000 | lr: 1.8127e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7432/  8460 | global iter:   7432/  8460 | loss: 0.0970 | ds_loss: 0.0000 | lr: 1.8092e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7432/  8460 | global iter:   7432/  8460 | loss: 0.0879 | ds_loss: 0.0000 | lr: 1.8092e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7433/  8460 | global iter:   7433/  8460 | loss: 0.0279 | ds_loss: 0.0000 | lr: 1.8058e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7434/  8460 | global iter:   7434/  8460 | loss: 0.1757 | ds_loss: 0.0000 | lr: 1.8023e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7435/  8460 | global iter:   7435/  8460 | loss: 0.0447 | ds_loss: 0.0000 | lr: 1.7989e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7436/  8460 | global iter:   7436/  8460 | loss: 0.1126 | ds_loss: 0.0000 | lr: 1.7954e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7436/  8460 | global iter:   7436/  8460 | loss: 0.0902 | ds_loss: 0.0000 | lr: 1.7954e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7437/  8460 | global iter:   7437/  8460 | loss: 0.0543 | ds_loss: 0.0000 | lr: 1.7920e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7438/  8460 | global iter:   7438/  8460 | loss: 0.0247 | ds_loss: 0.0000 | lr: 1.7885e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7439/  8460 | global iter:   7439/  8460 | loss: 0.0268 | ds_loss: 0.0000 | lr: 1.7851e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7440/  8460 | global iter:   7440/  8460 | loss: 0.0340 | ds_loss: 0.0000 | lr: 1.7817e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7440/  8460 | global iter:   7440/  8460 | loss: 0.0349 | ds_loss: 0.0000 | lr: 1.7817e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7441/  8460 | global iter:   7441/  8460 | loss: 0.0601 | ds_loss: 0.0000 | lr: 1.7782e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7442/  8460 | global iter:   7442/  8460 | loss: 0.0432 | ds_loss: 0.0000 | lr: 1.7748e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7443/  8460 | global iter:   7443/  8460 | loss: 0.1069 | ds_loss: 0.0000 | lr: 1.7714e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7444/  8460 | global iter:   7444/  8460 | loss: 0.0320 | ds_loss: 0.0000 | lr: 1.7680e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7444/  8460 | global iter:   7444/  8460 | loss: 0.0605 | ds_loss: 0.0000 | lr: 1.7680e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7445/  8460 | global iter:   7445/  8460 | loss: 0.0019 | ds_loss: 0.0000 | lr: 1.7646e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7446/  8460 | global iter:   7446/  8460 | loss: 0.0265 | ds_loss: 0.0000 | lr: 1.7611e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7447/  8460 | global iter:   7447/  8460 | loss: 0.0116 | ds_loss: 0.0000 | lr: 1.7577e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7448/  8460 | global iter:   7448/  8460 | loss: 0.0288 | ds_loss: 0.0000 | lr: 1.7543e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7448/  8460 | global iter:   7448/  8460 | loss: 0.0172 | ds_loss: 0.0000 | lr: 1.7543e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7449/  8460 | global iter:   7449/  8460 | loss: 0.0077 | ds_loss: 0.0000 | lr: 1.7509e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7450/  8460 | global iter:   7450/  8460 | loss: 0.0330 | ds_loss: 0.0000 | lr: 1.7475e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7451/  8460 | global iter:   7451/  8460 | loss: 0.0282 | ds_loss: 0.0000 | lr: 1.7441e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7452/  8460 | global iter:   7452/  8460 | loss: 0.0137 | ds_loss: 0.0000 | lr: 1.7407e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7452/  8460 | global iter:   7452/  8460 | loss: 0.0207 | ds_loss: 0.0000 | lr: 1.7407e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7453/  8460 | global iter:   7453/  8460 | loss: 0.0740 | ds_loss: 0.0000 | lr: 1.7373e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7454/  8460 | global iter:   7454/  8460 | loss: 0.2897 | ds_loss: 0.0000 | lr: 1.7339e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7455/  8460 | global iter:   7455/  8460 | loss: 0.0055 | ds_loss: 0.0000 | lr: 1.7306e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7456/  8460 | global iter:   7456/  8460 | loss: 0.0514 | ds_loss: 0.0000 | lr: 1.7272e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7456/  8460 | global iter:   7456/  8460 | loss: 0.1052 | ds_loss: 0.0000 | lr: 1.7272e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7457/  8460 | global iter:   7457/  8460 | loss: 0.0168 | ds_loss: 0.0000 | lr: 1.7238e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7458/  8460 | global iter:   7458/  8460 | loss: 0.0276 | ds_loss: 0.0000 | lr: 1.7204e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7459/  8460 | global iter:   7459/  8460 | loss: 0.0069 | ds_loss: 0.0000 | lr: 1.7170e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7460/  8460 | global iter:   7460/  8460 | loss: 0.0209 | ds_loss: 0.0000 | lr: 1.7137e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7460/  8460 | global iter:   7460/  8460 | loss: 0.0181 | ds_loss: 0.0000 | lr: 1.7137e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7461/  8460 | global iter:   7461/  8460 | loss: 0.0242 | ds_loss: 0.0000 | lr: 1.7103e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7462/  8460 | global iter:   7462/  8460 | loss: 0.0260 | ds_loss: 0.0000 | lr: 1.7069e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7463/  8460 | global iter:   7463/  8460 | loss: 0.0478 | ds_loss: 0.0000 | lr: 1.7036e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7464/  8460 | global iter:   7464/  8460 | loss: 0.0444 | ds_loss: 0.0000 | lr: 1.7002e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7464/  8460 | global iter:   7464/  8460 | loss: 0.0356 | ds_loss: 0.0000 | lr: 1.7002e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7465/  8460 | global iter:   7465/  8460 | loss: 0.0020 | ds_loss: 0.0000 | lr: 1.6969e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7466/  8460 | global iter:   7466/  8460 | loss: 0.0562 | ds_loss: 0.0000 | lr: 1.6935e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7467/  8460 | global iter:   7467/  8460 | loss: 0.0150 | ds_loss: 0.0000 | lr: 1.6902e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7468/  8460 | global iter:   7468/  8460 | loss: 0.1720 | ds_loss: 0.0000 | lr: 1.6868e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7468/  8460 | global iter:   7468/  8460 | loss: 0.0613 | ds_loss: 0.0000 | lr: 1.6868e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7469/  8460 | global iter:   7469/  8460 | loss: 0.0153 | ds_loss: 0.0000 | lr: 1.6835e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7470/  8460 | global iter:   7470/  8460 | loss: 0.0629 | ds_loss: 0.0000 | lr: 1.6802e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7471/  8460 | global iter:   7471/  8460 | loss: 0.0250 | ds_loss: 0.0000 | lr: 1.6768e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7472/  8460 | global iter:   7472/  8460 | loss: 0.0242 | ds_loss: 0.0000 | lr: 1.6735e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7472/  8460 | global iter:   7472/  8460 | loss: 0.0318 | ds_loss: 0.0000 | lr: 1.6735e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7473/  8460 | global iter:   7473/  8460 | loss: 0.0121 | ds_loss: 0.0000 | lr: 1.6702e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7474/  8460 | global iter:   7474/  8460 | loss: 0.0518 | ds_loss: 0.0000 | lr: 1.6668e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7475/  8460 | global iter:   7475/  8460 | loss: 0.0611 | ds_loss: 0.0000 | lr: 1.6635e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7476/  8460 | global iter:   7476/  8460 | loss: 0.0387 | ds_loss: 0.0000 | lr: 1.6602e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7476/  8460 | global iter:   7476/  8460 | loss: 0.0409 | ds_loss: 0.0000 | lr: 1.6602e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7477/  8460 | global iter:   7477/  8460 | loss: 0.0067 | ds_loss: 0.0000 | lr: 1.6569e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7478/  8460 | global iter:   7478/  8460 | loss: 0.0163 | ds_loss: 0.0000 | lr: 1.6536e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7479/  8460 | global iter:   7479/  8460 | loss: 0.0391 | ds_loss: 0.0000 | lr: 1.6503e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7480/  8460 | global iter:   7480/  8460 | loss: 0.0829 | ds_loss: 0.0000 | lr: 1.6470e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7480/  8460 | global iter:   7480/  8460 | loss: 0.0362 | ds_loss: 0.0000 | lr: 1.6470e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7481/  8460 | global iter:   7481/  8460 | loss: 0.0430 | ds_loss: 0.0000 | lr: 1.6436e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7482/  8460 | global iter:   7482/  8460 | loss: 0.0183 | ds_loss: 0.0000 | lr: 1.6404e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7483/  8460 | global iter:   7483/  8460 | loss: 0.0090 | ds_loss: 0.0000 | lr: 1.6371e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7484/  8460 | global iter:   7484/  8460 | loss: 0.0100 | ds_loss: 0.0000 | lr: 1.6338e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7484/  8460 | global iter:   7484/  8460 | loss: 0.0201 | ds_loss: 0.0000 | lr: 1.6338e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7485/  8460 | global iter:   7485/  8460 | loss: 0.0650 | ds_loss: 0.0000 | lr: 1.6305e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7486/  8460 | global iter:   7486/  8460 | loss: 0.0267 | ds_loss: 0.0000 | lr: 1.6272e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7487/  8460 | global iter:   7487/  8460 | loss: 0.1253 | ds_loss: 0.0000 | lr: 1.6239e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7488/  8460 | global iter:   7488/  8460 | loss: 0.0429 | ds_loss: 0.0000 | lr: 1.6206e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7488/  8460 | global iter:   7488/  8460 | loss: 0.0650 | ds_loss: 0.0000 | lr: 1.6206e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7489/  8460 | global iter:   7489/  8460 | loss: 0.0612 | ds_loss: 0.0000 | lr: 1.6173e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7490/  8460 | global iter:   7490/  8460 | loss: 0.0257 | ds_loss: 0.0000 | lr: 1.6141e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7491/  8460 | global iter:   7491/  8460 | loss: 0.0853 | ds_loss: 0.0000 | lr: 1.6108e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7492/  8460 | global iter:   7492/  8460 | loss: 0.0643 | ds_loss: 0.0000 | lr: 1.6075e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7492/  8460 | global iter:   7492/  8460 | loss: 0.0591 | ds_loss: 0.0000 | lr: 1.6075e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7493/  8460 | global iter:   7493/  8460 | loss: 0.0293 | ds_loss: 0.0000 | lr: 1.6043e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7494/  8460 | global iter:   7494/  8460 | loss: 0.0620 | ds_loss: 0.0000 | lr: 1.6010e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7495/  8460 | global iter:   7495/  8460 | loss: 0.0740 | ds_loss: 0.0000 | lr: 1.5978e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7496/  8460 | global iter:   7496/  8460 | loss: 0.0088 | ds_loss: 0.0000 | lr: 1.5945e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7496/  8460 | global iter:   7496/  8460 | loss: 0.0435 | ds_loss: 0.0000 | lr: 1.5945e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7497/  8460 | global iter:   7497/  8460 | loss: 0.1467 | ds_loss: 0.0000 | lr: 1.5913e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7498/  8460 | global iter:   7498/  8460 | loss: 0.0032 | ds_loss: 0.0000 | lr: 1.5880e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7499/  8460 | global iter:   7499/  8460 | loss: 0.0899 | ds_loss: 0.0000 | lr: 1.5848e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7500/  8460 | global iter:   7500/  8460 | loss: 0.0244 | ds_loss: 0.0000 | lr: 1.5815e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7500/  8460 | global iter:   7500/  8460 | loss: 0.0660 | ds_loss: 0.0000 | lr: 1.5815e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7501/  8460 | global iter:   7501/  8460 | loss: 0.0710 | ds_loss: 0.0000 | lr: 1.5783e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7502/  8460 | global iter:   7502/  8460 | loss: 0.0239 | ds_loss: 0.0000 | lr: 1.5750e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7503/  8460 | global iter:   7503/  8460 | loss: 0.1369 | ds_loss: 0.0000 | lr: 1.5718e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7504/  8460 | global iter:   7504/  8460 | loss: 0.0048 | ds_loss: 0.0000 | lr: 1.5686e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7504/  8460 | global iter:   7504/  8460 | loss: 0.0592 | ds_loss: 0.0000 | lr: 1.5686e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7505/  8460 | global iter:   7505/  8460 | loss: 0.0408 | ds_loss: 0.0000 | lr: 1.5654e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7506/  8460 | global iter:   7506/  8460 | loss: 0.0053 | ds_loss: 0.0000 | lr: 1.5621e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7507/  8460 | global iter:   7507/  8460 | loss: 0.0215 | ds_loss: 0.0000 | lr: 1.5589e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7508/  8460 | global iter:   7508/  8460 | loss: 0.0220 | ds_loss: 0.0000 | lr: 1.5557e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7508/  8460 | global iter:   7508/  8460 | loss: 0.0224 | ds_loss: 0.0000 | lr: 1.5557e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7509/  8460 | global iter:   7509/  8460 | loss: 0.0541 | ds_loss: 0.0000 | lr: 1.5525e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7510/  8460 | global iter:   7510/  8460 | loss: 0.0229 | ds_loss: 0.0000 | lr: 1.5493e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7511/  8460 | global iter:   7511/  8460 | loss: 0.0568 | ds_loss: 0.0000 | lr: 1.5461e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7512/  8460 | global iter:   7512/  8460 | loss: 0.0680 | ds_loss: 0.0000 | lr: 1.5429e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7512/  8460 | global iter:   7512/  8460 | loss: 0.0504 | ds_loss: 0.0000 | lr: 1.5429e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7513/  8460 | global iter:   7513/  8460 | loss: 0.2604 | ds_loss: 0.0000 | lr: 1.5397e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7514/  8460 | global iter:   7514/  8460 | loss: 0.0477 | ds_loss: 0.0000 | lr: 1.5365e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7515/  8460 | global iter:   7515/  8460 | loss: 0.0669 | ds_loss: 0.0000 | lr: 1.5333e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7516/  8460 | global iter:   7516/  8460 | loss: 0.0387 | ds_loss: 0.0000 | lr: 1.5301e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7516/  8460 | global iter:   7516/  8460 | loss: 0.1034 | ds_loss: 0.0000 | lr: 1.5301e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7517/  8460 | global iter:   7517/  8460 | loss: 0.0018 | ds_loss: 0.0000 | lr: 1.5269e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7518/  8460 | global iter:   7518/  8460 | loss: 0.0029 | ds_loss: 0.0000 | lr: 1.5237e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7519/  8460 | global iter:   7519/  8460 | loss: 0.0575 | ds_loss: 0.0000 | lr: 1.5206e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7520/  8460 | global iter:   7520/  8460 | loss: 0.1845 | ds_loss: 0.0000 | lr: 1.5174e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7520/  8460 | global iter:   7520/  8460 | loss: 0.0617 | ds_loss: 0.0000 | lr: 1.5174e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7521/  8460 | global iter:   7521/  8460 | loss: 0.1728 | ds_loss: 0.0000 | lr: 1.5142e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7522/  8460 | global iter:   7522/  8460 | loss: 0.0701 | ds_loss: 0.0000 | lr: 1.5110e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7523/  8460 | global iter:   7523/  8460 | loss: 0.0053 | ds_loss: 0.0000 | lr: 1.5079e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7524/  8460 | global iter:   7524/  8460 | loss: 0.0107 | ds_loss: 0.0000 | lr: 1.5047e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7524/  8460 | global iter:   7524/  8460 | loss: 0.0647 | ds_loss: 0.0000 | lr: 1.5047e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7525/  8460 | global iter:   7525/  8460 | loss: 0.3033 | ds_loss: 0.0000 | lr: 1.5016e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7526/  8460 | global iter:   7526/  8460 | loss: 0.0292 | ds_loss: 0.0000 | lr: 1.4984e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7527/  8460 | global iter:   7527/  8460 | loss: 0.1406 | ds_loss: 0.0000 | lr: 1.4952e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7528/  8460 | global iter:   7528/  8460 | loss: 0.0243 | ds_loss: 0.0000 | lr: 1.4921e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7528/  8460 | global iter:   7528/  8460 | loss: 0.1243 | ds_loss: 0.0000 | lr: 1.4921e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7529/  8460 | global iter:   7529/  8460 | loss: 0.0929 | ds_loss: 0.0000 | lr: 1.4889e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7530/  8460 | global iter:   7530/  8460 | loss: 0.0669 | ds_loss: 0.0000 | lr: 1.4858e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7531/  8460 | global iter:   7531/  8460 | loss: 0.0602 | ds_loss: 0.0000 | lr: 1.4827e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7532/  8460 | global iter:   7532/  8460 | loss: 0.0331 | ds_loss: 0.0000 | lr: 1.4795e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7532/  8460 | global iter:   7532/  8460 | loss: 0.0633 | ds_loss: 0.0000 | lr: 1.4795e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7533/  8460 | global iter:   7533/  8460 | loss: 0.0697 | ds_loss: 0.0000 | lr: 1.4764e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7534/  8460 | global iter:   7534/  8460 | loss: 0.0256 | ds_loss: 0.0000 | lr: 1.4733e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7535/  8460 | global iter:   7535/  8460 | loss: 0.0998 | ds_loss: 0.0000 | lr: 1.4701e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7536/  8460 | global iter:   7536/  8460 | loss: 0.0144 | ds_loss: 0.0000 | lr: 1.4670e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7536/  8460 | global iter:   7536/  8460 | loss: 0.0524 | ds_loss: 0.0000 | lr: 1.4670e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7537/  8460 | global iter:   7537/  8460 | loss: 0.0977 | ds_loss: 0.0000 | lr: 1.4639e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7538/  8460 | global iter:   7538/  8460 | loss: 0.0885 | ds_loss: 0.0000 | lr: 1.4608e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7539/  8460 | global iter:   7539/  8460 | loss: 0.0017 | ds_loss: 0.0000 | lr: 1.4577e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7540/  8460 | global iter:   7540/  8460 | loss: 0.0447 | ds_loss: 0.0000 | lr: 1.4545e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7540/  8460 | global iter:   7540/  8460 | loss: 0.0582 | ds_loss: 0.0000 | lr: 1.4545e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7541/  8460 | global iter:   7541/  8460 | loss: 0.0134 | ds_loss: 0.0000 | lr: 1.4514e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7542/  8460 | global iter:   7542/  8460 | loss: 0.0228 | ds_loss: 0.0000 | lr: 1.4483e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7543/  8460 | global iter:   7543/  8460 | loss: 0.0071 | ds_loss: 0.0000 | lr: 1.4452e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7544/  8460 | global iter:   7544/  8460 | loss: 0.0467 | ds_loss: 0.0000 | lr: 1.4421e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7544/  8460 | global iter:   7544/  8460 | loss: 0.0225 | ds_loss: 0.0000 | lr: 1.4421e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7545/  8460 | global iter:   7545/  8460 | loss: 0.0472 | ds_loss: 0.0000 | lr: 1.4390e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7546/  8460 | global iter:   7546/  8460 | loss: 0.0114 | ds_loss: 0.0000 | lr: 1.4359e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7547/  8460 | global iter:   7547/  8460 | loss: 0.1697 | ds_loss: 0.0000 | lr: 1.4329e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7548/  8460 | global iter:   7548/  8460 | loss: 0.0100 | ds_loss: 0.0000 | lr: 1.4298e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7548/  8460 | global iter:   7548/  8460 | loss: 0.0596 | ds_loss: 0.0000 | lr: 1.4298e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7549/  8460 | global iter:   7549/  8460 | loss: 0.0498 | ds_loss: 0.0000 | lr: 1.4267e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7550/  8460 | global iter:   7550/  8460 | loss: 0.0838 | ds_loss: 0.0000 | lr: 1.4236e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7551/  8460 | global iter:   7551/  8460 | loss: 0.0099 | ds_loss: 0.0000 | lr: 1.4205e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7552/  8460 | global iter:   7552/  8460 | loss: 0.0924 | ds_loss: 0.0000 | lr: 1.4175e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7552/  8460 | global iter:   7552/  8460 | loss: 0.0590 | ds_loss: 0.0000 | lr: 1.4175e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7553/  8460 | global iter:   7553/  8460 | loss: 0.0852 | ds_loss: 0.0000 | lr: 1.4144e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7554/  8460 | global iter:   7554/  8460 | loss: 0.1680 | ds_loss: 0.0000 | lr: 1.4113e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7555/  8460 | global iter:   7555/  8460 | loss: 0.0722 | ds_loss: 0.0000 | lr: 1.4083e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7556/  8460 | global iter:   7556/  8460 | loss: 0.0085 | ds_loss: 0.0000 | lr: 1.4052e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7556/  8460 | global iter:   7556/  8460 | loss: 0.0835 | ds_loss: 0.0000 | lr: 1.4052e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7557/  8460 | global iter:   7557/  8460 | loss: 0.0185 | ds_loss: 0.0000 | lr: 1.4021e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7558/  8460 | global iter:   7558/  8460 | loss: 0.1270 | ds_loss: 0.0000 | lr: 1.3991e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7559/  8460 | global iter:   7559/  8460 | loss: 0.0318 | ds_loss: 0.0000 | lr: 1.3960e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7560/  8460 | global iter:   7560/  8460 | loss: 0.0422 | ds_loss: 0.0000 | lr: 1.3930e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7560/  8460 | global iter:   7560/  8460 | loss: 0.0549 | ds_loss: 0.0000 | lr: 1.3930e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7561/  8460 | global iter:   7561/  8460 | loss: 0.0961 | ds_loss: 0.0000 | lr: 1.3900e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7562/  8460 | global iter:   7562/  8460 | loss: 0.0370 | ds_loss: 0.0000 | lr: 1.3869e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7563/  8460 | global iter:   7563/  8460 | loss: 0.0395 | ds_loss: 0.0000 | lr: 1.3839e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7564/  8460 | global iter:   7564/  8460 | loss: 0.0255 | ds_loss: 0.0000 | lr: 1.3808e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7564/  8460 | global iter:   7564/  8460 | loss: 0.0495 | ds_loss: 0.0000 | lr: 1.3808e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7565/  8460 | global iter:   7565/  8460 | loss: 0.0576 | ds_loss: 0.0000 | lr: 1.3778e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7566/  8460 | global iter:   7566/  8460 | loss: 0.0419 | ds_loss: 0.0000 | lr: 1.3748e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7567/  8460 | global iter:   7567/  8460 | loss: 0.0292 | ds_loss: 0.0000 | lr: 1.3718e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7568/  8460 | global iter:   7568/  8460 | loss: 0.0527 | ds_loss: 0.0000 | lr: 1.3687e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7568/  8460 | global iter:   7568/  8460 | loss: 0.0454 | ds_loss: 0.0000 | lr: 1.3687e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7569/  8460 | global iter:   7569/  8460 | loss: 0.0245 | ds_loss: 0.0000 | lr: 1.3657e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7570/  8460 | global iter:   7570/  8460 | loss: 0.0324 | ds_loss: 0.0000 | lr: 1.3627e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7571/  8460 | global iter:   7571/  8460 | loss: 0.0278 | ds_loss: 0.0000 | lr: 1.3597e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7572/  8460 | global iter:   7572/  8460 | loss: 0.0344 | ds_loss: 0.0000 | lr: 1.3567e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7572/  8460 | global iter:   7572/  8460 | loss: 0.0298 | ds_loss: 0.0000 | lr: 1.3567e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7573/  8460 | global iter:   7573/  8460 | loss: 0.0751 | ds_loss: 0.0000 | lr: 1.3537e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7574/  8460 | global iter:   7574/  8460 | loss: 0.0220 | ds_loss: 0.0000 | lr: 1.3507e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7575/  8460 | global iter:   7575/  8460 | loss: 0.0874 | ds_loss: 0.0000 | lr: 1.3477e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7576/  8460 | global iter:   7576/  8460 | loss: 0.0159 | ds_loss: 0.0000 | lr: 1.3447e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7576/  8460 | global iter:   7576/  8460 | loss: 0.0501 | ds_loss: 0.0000 | lr: 1.3447e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7577/  8460 | global iter:   7577/  8460 | loss: 0.0305 | ds_loss: 0.0000 | lr: 1.3417e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7578/  8460 | global iter:   7578/  8460 | loss: 0.0440 | ds_loss: 0.0000 | lr: 1.3387e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7579/  8460 | global iter:   7579/  8460 | loss: 0.0254 | ds_loss: 0.0000 | lr: 1.3357e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7580/  8460 | global iter:   7580/  8460 | loss: 0.1132 | ds_loss: 0.0000 | lr: 1.3328e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7580/  8460 | global iter:   7580/  8460 | loss: 0.0533 | ds_loss: 0.0000 | lr: 1.3328e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7581/  8460 | global iter:   7581/  8460 | loss: 0.0160 | ds_loss: 0.0000 | lr: 1.3298e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7582/  8460 | global iter:   7582/  8460 | loss: 0.0096 | ds_loss: 0.0000 | lr: 1.3268e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7583/  8460 | global iter:   7583/  8460 | loss: 0.0366 | ds_loss: 0.0000 | lr: 1.3238e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7584/  8460 | global iter:   7584/  8460 | loss: 0.0269 | ds_loss: 0.0000 | lr: 1.3209e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7584/  8460 | global iter:   7584/  8460 | loss: 0.0223 | ds_loss: 0.0000 | lr: 1.3209e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7585/  8460 | global iter:   7585/  8460 | loss: 0.0069 | ds_loss: 0.0000 | lr: 1.3179e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7586/  8460 | global iter:   7586/  8460 | loss: 0.0440 | ds_loss: 0.0000 | lr: 1.3149e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7587/  8460 | global iter:   7587/  8460 | loss: 0.1890 | ds_loss: 0.0000 | lr: 1.3120e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7588/  8460 | global iter:   7588/  8460 | loss: 0.0582 | ds_loss: 0.0000 | lr: 1.3090e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7588/  8460 | global iter:   7588/  8460 | loss: 0.0745 | ds_loss: 0.0000 | lr: 1.3090e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7589/  8460 | global iter:   7589/  8460 | loss: 0.1391 | ds_loss: 0.0000 | lr: 1.3061e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7590/  8460 | global iter:   7590/  8460 | loss: 0.0555 | ds_loss: 0.0000 | lr: 1.3031e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7591/  8460 | global iter:   7591/  8460 | loss: 0.0438 | ds_loss: 0.0000 | lr: 1.3002e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7592/  8460 | global iter:   7592/  8460 | loss: 0.0311 | ds_loss: 0.0000 | lr: 1.2972e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7592/  8460 | global iter:   7592/  8460 | loss: 0.0674 | ds_loss: 0.0000 | lr: 1.2972e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7593/  8460 | global iter:   7593/  8460 | loss: 0.0460 | ds_loss: 0.0000 | lr: 1.2943e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7594/  8460 | global iter:   7594/  8460 | loss: 0.0226 | ds_loss: 0.0000 | lr: 1.2914e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7595/  8460 | global iter:   7595/  8460 | loss: 0.0141 | ds_loss: 0.0000 | lr: 1.2884e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7596/  8460 | global iter:   7596/  8460 | loss: 0.0357 | ds_loss: 0.0000 | lr: 1.2855e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7596/  8460 | global iter:   7596/  8460 | loss: 0.0296 | ds_loss: 0.0000 | lr: 1.2855e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7597/  8460 | global iter:   7597/  8460 | loss: 0.0078 | ds_loss: 0.0000 | lr: 1.2826e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7598/  8460 | global iter:   7598/  8460 | loss: 0.0368 | ds_loss: 0.0000 | lr: 1.2797e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7599/  8460 | global iter:   7599/  8460 | loss: 0.0459 | ds_loss: 0.0000 | lr: 1.2767e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7600/  8460 | global iter:   7600/  8460 | loss: 0.0924 | ds_loss: 0.0000 | lr: 1.2738e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7600/  8460 | global iter:   7600/  8460 | loss: 0.0457 | ds_loss: 0.0000 | lr: 1.2738e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7601/  8460 | global iter:   7601/  8460 | loss: 0.0107 | ds_loss: 0.0000 | lr: 1.2709e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7602/  8460 | global iter:   7602/  8460 | loss: 0.0209 | ds_loss: 0.0000 | lr: 1.2680e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7603/  8460 | global iter:   7603/  8460 | loss: 0.0175 | ds_loss: 0.0000 | lr: 1.2651e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7604/  8460 | global iter:   7604/  8460 | loss: 0.2005 | ds_loss: 0.0000 | lr: 1.2622e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7604/  8460 | global iter:   7604/  8460 | loss: 0.0624 | ds_loss: 0.0000 | lr: 1.2622e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7605/  8460 | global iter:   7605/  8460 | loss: 0.0304 | ds_loss: 0.0000 | lr: 1.2593e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7606/  8460 | global iter:   7606/  8460 | loss: 0.1777 | ds_loss: 0.0000 | lr: 1.2564e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7607/  8460 | global iter:   7607/  8460 | loss: 0.0459 | ds_loss: 0.0000 | lr: 1.2535e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7608/  8460 | global iter:   7608/  8460 | loss: 0.0351 | ds_loss: 0.0000 | lr: 1.2506e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7608/  8460 | global iter:   7608/  8460 | loss: 0.0723 | ds_loss: 0.0000 | lr: 1.2506e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7609/  8460 | global iter:   7609/  8460 | loss: 0.0608 | ds_loss: 0.0000 | lr: 1.2477e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7610/  8460 | global iter:   7610/  8460 | loss: 0.1570 | ds_loss: 0.0000 | lr: 1.2448e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7611/  8460 | global iter:   7611/  8460 | loss: 0.0837 | ds_loss: 0.0000 | lr: 1.2420e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7612/  8460 | global iter:   7612/  8460 | loss: 0.1174 | ds_loss: 0.0000 | lr: 1.2391e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7612/  8460 | global iter:   7612/  8460 | loss: 0.1048 | ds_loss: 0.0000 | lr: 1.2391e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7613/  8460 | global iter:   7613/  8460 | loss: 0.0490 | ds_loss: 0.0000 | lr: 1.2362e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   8 | Iter:   7614/  8460 | global iter:   7614/  8460 | loss: 0.2496 | ds_loss: 0.0000 | lr: 1.2333e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7615/  8460 | global iter:   7615/  8460 | loss: 0.0188 | ds_loss: 0.0000 | lr: 1.2305e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7616/  8460 | global iter:   7616/  8460 | loss: 0.0422 | ds_loss: 0.0000 | lr: 1.2276e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7616/  8460 | global iter:   7616/  8460 | loss: 0.0899 | ds_loss: 0.0000 | lr: 1.2276e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7617/  8460 | global iter:   7617/  8460 | loss: 0.0125 | ds_loss: 0.0000 | lr: 1.2248e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7618/  8460 | global iter:   7618/  8460 | loss: 0.0291 | ds_loss: 0.0000 | lr: 1.2219e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7619/  8460 | global iter:   7619/  8460 | loss: 0.0370 | ds_loss: 0.0000 | lr: 1.2190e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   8 | Iter:   7620/  8460 | global iter:   7620/  8460 | loss: 0.0181 | ds_loss: 0.0000 | lr: 1.2162e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   8 | Iter:   7620/  8460 | global iter:   7620/  8460 | loss: 0.0242 | ds_loss: 0.0000 | lr: 1.2162e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   8 | Iter:   7621/  8460 | global iter:   7621/  8460 | loss: 0.0429 | ds_loss: 0.0000 | lr: 1.2133e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7622/  8460 | global iter:   7622/  8460 | loss: 0.0186 | ds_loss: 0.0000 | lr: 1.2105e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   8 | Iter:   7623/  8460 | global iter:   7623/  8460 | loss: 0.0088 | ds_loss: 0.0000 | lr: 1.2077e-05 | scale:     1.0000 | micro time: 0.366 | step time: 0.000
Sun Apr  6 21:47:14 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla P100-PCIE-12GB           Off |   00000000:81:00.0 Off |                    0 |
| N/A   52C    P0             39W /  250W |    8807MiB /  12288MiB |    100%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A    244677      C   ...project_distillLLM/venv/bin/python3       8804MiB |
+-----------------------------------------------------------------------------------------+

train | epoch   9 | Iter:   7624/  8460 | global iter:   7624/  8460 | loss: 0.0182 | ds_loss: 0.0000 | lr: 1.2048e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7624/  8460 | global iter:   7624/  8460 | loss: 0.0221 | ds_loss: 0.0000 | lr: 1.2048e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.413
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7625/  8460 | global iter:   7625/  8460 | loss: 0.0411 | ds_loss: 0.0000 | lr: 1.2020e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7626/  8460 | global iter:   7626/  8460 | loss: 0.0360 | ds_loss: 0.0000 | lr: 1.1992e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7627/  8460 | global iter:   7627/  8460 | loss: 0.0594 | ds_loss: 0.0000 | lr: 1.1963e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7628/  8460 | global iter:   7628/  8460 | loss: 0.0533 | ds_loss: 0.0000 | lr: 1.1935e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7628/  8460 | global iter:   7628/  8460 | loss: 0.0475 | ds_loss: 0.0000 | lr: 1.1935e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7629/  8460 | global iter:   7629/  8460 | loss: 0.0520 | ds_loss: 0.0000 | lr: 1.1907e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7630/  8460 | global iter:   7630/  8460 | loss: 0.1112 | ds_loss: 0.0000 | lr: 1.1879e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7631/  8460 | global iter:   7631/  8460 | loss: 0.0426 | ds_loss: 0.0000 | lr: 1.1851e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7632/  8460 | global iter:   7632/  8460 | loss: 0.0723 | ds_loss: 0.0000 | lr: 1.1822e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7632/  8460 | global iter:   7632/  8460 | loss: 0.0695 | ds_loss: 0.0000 | lr: 1.1822e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7633/  8460 | global iter:   7633/  8460 | loss: 0.1099 | ds_loss: 0.0000 | lr: 1.1794e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7634/  8460 | global iter:   7634/  8460 | loss: 0.0387 | ds_loss: 0.0000 | lr: 1.1766e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7635/  8460 | global iter:   7635/  8460 | loss: 0.0858 | ds_loss: 0.0000 | lr: 1.1738e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7636/  8460 | global iter:   7636/  8460 | loss: 0.0275 | ds_loss: 0.0000 | lr: 1.1710e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7636/  8460 | global iter:   7636/  8460 | loss: 0.0655 | ds_loss: 0.0000 | lr: 1.1710e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7637/  8460 | global iter:   7637/  8460 | loss: 0.0257 | ds_loss: 0.0000 | lr: 1.1682e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7638/  8460 | global iter:   7638/  8460 | loss: 0.0284 | ds_loss: 0.0000 | lr: 1.1654e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7639/  8460 | global iter:   7639/  8460 | loss: 0.0527 | ds_loss: 0.0000 | lr: 1.1627e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7640/  8460 | global iter:   7640/  8460 | loss: 0.0416 | ds_loss: 0.0000 | lr: 1.1599e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7640/  8460 | global iter:   7640/  8460 | loss: 0.0371 | ds_loss: 0.0000 | lr: 1.1599e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7641/  8460 | global iter:   7641/  8460 | loss: 0.0201 | ds_loss: 0.0000 | lr: 1.1571e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7642/  8460 | global iter:   7642/  8460 | loss: 0.0227 | ds_loss: 0.0000 | lr: 1.1543e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7643/  8460 | global iter:   7643/  8460 | loss: 0.0393 | ds_loss: 0.0000 | lr: 1.1515e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7644/  8460 | global iter:   7644/  8460 | loss: 0.0028 | ds_loss: 0.0000 | lr: 1.1488e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7644/  8460 | global iter:   7644/  8460 | loss: 0.0212 | ds_loss: 0.0000 | lr: 1.1488e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7645/  8460 | global iter:   7645/  8460 | loss: 0.0293 | ds_loss: 0.0000 | lr: 1.1460e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7646/  8460 | global iter:   7646/  8460 | loss: 0.0053 | ds_loss: 0.0000 | lr: 1.1432e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7647/  8460 | global iter:   7647/  8460 | loss: 0.0375 | ds_loss: 0.0000 | lr: 1.1405e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7648/  8460 | global iter:   7648/  8460 | loss: 0.0235 | ds_loss: 0.0000 | lr: 1.1377e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7648/  8460 | global iter:   7648/  8460 | loss: 0.0239 | ds_loss: 0.0000 | lr: 1.1377e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7649/  8460 | global iter:   7649/  8460 | loss: 0.0810 | ds_loss: 0.0000 | lr: 1.1350e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7650/  8460 | global iter:   7650/  8460 | loss: 0.0166 | ds_loss: 0.0000 | lr: 1.1322e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7651/  8460 | global iter:   7651/  8460 | loss: 0.0393 | ds_loss: 0.0000 | lr: 1.1295e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7652/  8460 | global iter:   7652/  8460 | loss: 0.0530 | ds_loss: 0.0000 | lr: 1.1267e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7652/  8460 | global iter:   7652/  8460 | loss: 0.0475 | ds_loss: 0.0000 | lr: 1.1267e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7653/  8460 | global iter:   7653/  8460 | loss: 0.1009 | ds_loss: 0.0000 | lr: 1.1240e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7654/  8460 | global iter:   7654/  8460 | loss: 0.0043 | ds_loss: 0.0000 | lr: 1.1212e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7655/  8460 | global iter:   7655/  8460 | loss: 0.0159 | ds_loss: 0.0000 | lr: 1.1185e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7656/  8460 | global iter:   7656/  8460 | loss: 0.0440 | ds_loss: 0.0000 | lr: 1.1158e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7656/  8460 | global iter:   7656/  8460 | loss: 0.0413 | ds_loss: 0.0000 | lr: 1.1158e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7657/  8460 | global iter:   7657/  8460 | loss: 0.0964 | ds_loss: 0.0000 | lr: 1.1130e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7658/  8460 | global iter:   7658/  8460 | loss: 0.0841 | ds_loss: 0.0000 | lr: 1.1103e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7659/  8460 | global iter:   7659/  8460 | loss: 0.0156 | ds_loss: 0.0000 | lr: 1.1076e-05 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   7660/  8460 | global iter:   7660/  8460 | loss: 0.0665 | ds_loss: 0.0000 | lr: 1.1049e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7660/  8460 | global iter:   7660/  8460 | loss: 0.0657 | ds_loss: 0.0000 | lr: 1.1049e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7661/  8460 | global iter:   7661/  8460 | loss: 0.0337 | ds_loss: 0.0000 | lr: 1.1022e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7662/  8460 | global iter:   7662/  8460 | loss: 0.0277 | ds_loss: 0.0000 | lr: 1.0995e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7663/  8460 | global iter:   7663/  8460 | loss: 0.0089 | ds_loss: 0.0000 | lr: 1.0967e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7664/  8460 | global iter:   7664/  8460 | loss: 0.0014 | ds_loss: 0.0000 | lr: 1.0940e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7664/  8460 | global iter:   7664/  8460 | loss: 0.0179 | ds_loss: 0.0000 | lr: 1.0940e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7665/  8460 | global iter:   7665/  8460 | loss: 0.0447 | ds_loss: 0.0000 | lr: 1.0913e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7666/  8460 | global iter:   7666/  8460 | loss: 0.0113 | ds_loss: 0.0000 | lr: 1.0886e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7667/  8460 | global iter:   7667/  8460 | loss: 0.0009 | ds_loss: 0.0000 | lr: 1.0859e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7668/  8460 | global iter:   7668/  8460 | loss: 0.0269 | ds_loss: 0.0000 | lr: 1.0832e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7668/  8460 | global iter:   7668/  8460 | loss: 0.0210 | ds_loss: 0.0000 | lr: 1.0832e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7669/  8460 | global iter:   7669/  8460 | loss: 0.0573 | ds_loss: 0.0000 | lr: 1.0806e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7670/  8460 | global iter:   7670/  8460 | loss: 0.0464 | ds_loss: 0.0000 | lr: 1.0779e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7671/  8460 | global iter:   7671/  8460 | loss: 0.0325 | ds_loss: 0.0000 | lr: 1.0752e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7672/  8460 | global iter:   7672/  8460 | loss: 0.0837 | ds_loss: 0.0000 | lr: 1.0725e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7672/  8460 | global iter:   7672/  8460 | loss: 0.0550 | ds_loss: 0.0000 | lr: 1.0725e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7673/  8460 | global iter:   7673/  8460 | loss: 0.0265 | ds_loss: 0.0000 | lr: 1.0698e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7674/  8460 | global iter:   7674/  8460 | loss: 0.0399 | ds_loss: 0.0000 | lr: 1.0672e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7675/  8460 | global iter:   7675/  8460 | loss: 0.0473 | ds_loss: 0.0000 | lr: 1.0645e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7676/  8460 | global iter:   7676/  8460 | loss: 0.0987 | ds_loss: 0.0000 | lr: 1.0618e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7676/  8460 | global iter:   7676/  8460 | loss: 0.0531 | ds_loss: 0.0000 | lr: 1.0618e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7677/  8460 | global iter:   7677/  8460 | loss: 0.0217 | ds_loss: 0.0000 | lr: 1.0592e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7678/  8460 | global iter:   7678/  8460 | loss: 0.0345 | ds_loss: 0.0000 | lr: 1.0565e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7679/  8460 | global iter:   7679/  8460 | loss: 0.0435 | ds_loss: 0.0000 | lr: 1.0538e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7680/  8460 | global iter:   7680/  8460 | loss: 0.0030 | ds_loss: 0.0000 | lr: 1.0512e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7680/  8460 | global iter:   7680/  8460 | loss: 0.0257 | ds_loss: 0.0000 | lr: 1.0512e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7681/  8460 | global iter:   7681/  8460 | loss: 0.0180 | ds_loss: 0.0000 | lr: 1.0485e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7682/  8460 | global iter:   7682/  8460 | loss: 0.1372 | ds_loss: 0.0000 | lr: 1.0459e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7683/  8460 | global iter:   7683/  8460 | loss: 0.0254 | ds_loss: 0.0000 | lr: 1.0433e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7684/  8460 | global iter:   7684/  8460 | loss: 0.0377 | ds_loss: 0.0000 | lr: 1.0406e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7684/  8460 | global iter:   7684/  8460 | loss: 0.0546 | ds_loss: 0.0000 | lr: 1.0406e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7685/  8460 | global iter:   7685/  8460 | loss: 0.0544 | ds_loss: 0.0000 | lr: 1.0380e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7686/  8460 | global iter:   7686/  8460 | loss: 0.0023 | ds_loss: 0.0000 | lr: 1.0354e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7687/  8460 | global iter:   7687/  8460 | loss: 0.0672 | ds_loss: 0.0000 | lr: 1.0327e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7688/  8460 | global iter:   7688/  8460 | loss: 0.0176 | ds_loss: 0.0000 | lr: 1.0301e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7688/  8460 | global iter:   7688/  8460 | loss: 0.0354 | ds_loss: 0.0000 | lr: 1.0301e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7689/  8460 | global iter:   7689/  8460 | loss: 0.0314 | ds_loss: 0.0000 | lr: 1.0275e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7690/  8460 | global iter:   7690/  8460 | loss: 0.0068 | ds_loss: 0.0000 | lr: 1.0249e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7691/  8460 | global iter:   7691/  8460 | loss: 0.0249 | ds_loss: 0.0000 | lr: 1.0222e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7692/  8460 | global iter:   7692/  8460 | loss: 0.0032 | ds_loss: 0.0000 | lr: 1.0196e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7692/  8460 | global iter:   7692/  8460 | loss: 0.0165 | ds_loss: 0.0000 | lr: 1.0196e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7693/  8460 | global iter:   7693/  8460 | loss: 0.1324 | ds_loss: 0.0000 | lr: 1.0170e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7694/  8460 | global iter:   7694/  8460 | loss: 0.0057 | ds_loss: 0.0000 | lr: 1.0144e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7695/  8460 | global iter:   7695/  8460 | loss: 0.0133 | ds_loss: 0.0000 | lr: 1.0118e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7696/  8460 | global iter:   7696/  8460 | loss: 0.0348 | ds_loss: 0.0000 | lr: 1.0092e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7696/  8460 | global iter:   7696/  8460 | loss: 0.0465 | ds_loss: 0.0000 | lr: 1.0092e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7697/  8460 | global iter:   7697/  8460 | loss: 0.0204 | ds_loss: 0.0000 | lr: 1.0066e-05 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7698/  8460 | global iter:   7698/  8460 | loss: 0.0172 | ds_loss: 0.0000 | lr: 1.0040e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7699/  8460 | global iter:   7699/  8460 | loss: 0.0715 | ds_loss: 0.0000 | lr: 1.0014e-05 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7700/  8460 | global iter:   7700/  8460 | loss: 0.0904 | ds_loss: 0.0000 | lr: 9.9884e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7700/  8460 | global iter:   7700/  8460 | loss: 0.0499 | ds_loss: 0.0000 | lr: 9.9884e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7701/  8460 | global iter:   7701/  8460 | loss: 0.1621 | ds_loss: 0.0000 | lr: 9.9625e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7702/  8460 | global iter:   7702/  8460 | loss: 0.0649 | ds_loss: 0.0000 | lr: 9.9367e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7703/  8460 | global iter:   7703/  8460 | loss: 0.0100 | ds_loss: 0.0000 | lr: 9.9110e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7704/  8460 | global iter:   7704/  8460 | loss: 0.1413 | ds_loss: 0.0000 | lr: 9.8852e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7704/  8460 | global iter:   7704/  8460 | loss: 0.0946 | ds_loss: 0.0000 | lr: 9.8852e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7705/  8460 | global iter:   7705/  8460 | loss: 0.0871 | ds_loss: 0.0000 | lr: 9.8595e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   7706/  8460 | global iter:   7706/  8460 | loss: 0.0331 | ds_loss: 0.0000 | lr: 9.8339e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   7707/  8460 | global iter:   7707/  8460 | loss: 0.0703 | ds_loss: 0.0000 | lr: 9.8082e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7708/  8460 | global iter:   7708/  8460 | loss: 0.0424 | ds_loss: 0.0000 | lr: 9.7826e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7708/  8460 | global iter:   7708/  8460 | loss: 0.0582 | ds_loss: 0.0000 | lr: 9.7826e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7709/  8460 | global iter:   7709/  8460 | loss: 0.0434 | ds_loss: 0.0000 | lr: 9.7571e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7710/  8460 | global iter:   7710/  8460 | loss: 0.0097 | ds_loss: 0.0000 | lr: 9.7315e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7711/  8460 | global iter:   7711/  8460 | loss: 0.0974 | ds_loss: 0.0000 | lr: 9.7060e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7712/  8460 | global iter:   7712/  8460 | loss: 0.0913 | ds_loss: 0.0000 | lr: 9.6806e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7712/  8460 | global iter:   7712/  8460 | loss: 0.0604 | ds_loss: 0.0000 | lr: 9.6806e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7713/  8460 | global iter:   7713/  8460 | loss: 0.0340 | ds_loss: 0.0000 | lr: 9.6551e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7714/  8460 | global iter:   7714/  8460 | loss: 0.0227 | ds_loss: 0.0000 | lr: 9.6297e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7715/  8460 | global iter:   7715/  8460 | loss: 0.0271 | ds_loss: 0.0000 | lr: 9.6044e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7716/  8460 | global iter:   7716/  8460 | loss: 0.0086 | ds_loss: 0.0000 | lr: 9.5790e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7716/  8460 | global iter:   7716/  8460 | loss: 0.0231 | ds_loss: 0.0000 | lr: 9.5790e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7717/  8460 | global iter:   7717/  8460 | loss: 0.0668 | ds_loss: 0.0000 | lr: 9.5537e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7718/  8460 | global iter:   7718/  8460 | loss: 0.0220 | ds_loss: 0.0000 | lr: 9.5285e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7719/  8460 | global iter:   7719/  8460 | loss: 0.0649 | ds_loss: 0.0000 | lr: 9.5032e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7720/  8460 | global iter:   7720/  8460 | loss: 0.0956 | ds_loss: 0.0000 | lr: 9.4780e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7720/  8460 | global iter:   7720/  8460 | loss: 0.0623 | ds_loss: 0.0000 | lr: 9.4780e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7721/  8460 | global iter:   7721/  8460 | loss: 0.0758 | ds_loss: 0.0000 | lr: 9.4528e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7722/  8460 | global iter:   7722/  8460 | loss: 0.0658 | ds_loss: 0.0000 | lr: 9.4277e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7723/  8460 | global iter:   7723/  8460 | loss: 0.0819 | ds_loss: 0.0000 | lr: 9.4026e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7724/  8460 | global iter:   7724/  8460 | loss: 0.0432 | ds_loss: 0.0000 | lr: 9.3775e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7724/  8460 | global iter:   7724/  8460 | loss: 0.0667 | ds_loss: 0.0000 | lr: 9.3775e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7725/  8460 | global iter:   7725/  8460 | loss: 0.1172 | ds_loss: 0.0000 | lr: 9.3525e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7726/  8460 | global iter:   7726/  8460 | loss: 0.0616 | ds_loss: 0.0000 | lr: 9.3275e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7727/  8460 | global iter:   7727/  8460 | loss: 0.0268 | ds_loss: 0.0000 | lr: 9.3025e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7728/  8460 | global iter:   7728/  8460 | loss: 0.0647 | ds_loss: 0.0000 | lr: 9.2776e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7728/  8460 | global iter:   7728/  8460 | loss: 0.0676 | ds_loss: 0.0000 | lr: 9.2776e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7729/  8460 | global iter:   7729/  8460 | loss: 0.0860 | ds_loss: 0.0000 | lr: 9.2527e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7730/  8460 | global iter:   7730/  8460 | loss: 0.0765 | ds_loss: 0.0000 | lr: 9.2278e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7731/  8460 | global iter:   7731/  8460 | loss: 0.0049 | ds_loss: 0.0000 | lr: 9.2030e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7732/  8460 | global iter:   7732/  8460 | loss: 0.0631 | ds_loss: 0.0000 | lr: 9.1782e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7732/  8460 | global iter:   7732/  8460 | loss: 0.0576 | ds_loss: 0.0000 | lr: 9.1782e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7733/  8460 | global iter:   7733/  8460 | loss: 0.0190 | ds_loss: 0.0000 | lr: 9.1534e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7734/  8460 | global iter:   7734/  8460 | loss: 0.0619 | ds_loss: 0.0000 | lr: 9.1287e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7735/  8460 | global iter:   7735/  8460 | loss: 0.0861 | ds_loss: 0.0000 | lr: 9.1040e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7736/  8460 | global iter:   7736/  8460 | loss: 0.0235 | ds_loss: 0.0000 | lr: 9.0793e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7736/  8460 | global iter:   7736/  8460 | loss: 0.0476 | ds_loss: 0.0000 | lr: 9.0793e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7737/  8460 | global iter:   7737/  8460 | loss: 0.0517 | ds_loss: 0.0000 | lr: 9.0546e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7738/  8460 | global iter:   7738/  8460 | loss: 0.0230 | ds_loss: 0.0000 | lr: 9.0300e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7739/  8460 | global iter:   7739/  8460 | loss: 0.0302 | ds_loss: 0.0000 | lr: 9.0055e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7740/  8460 | global iter:   7740/  8460 | loss: 0.0019 | ds_loss: 0.0000 | lr: 8.9809e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7740/  8460 | global iter:   7740/  8460 | loss: 0.0267 | ds_loss: 0.0000 | lr: 8.9809e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7741/  8460 | global iter:   7741/  8460 | loss: 0.0626 | ds_loss: 0.0000 | lr: 8.9564e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7742/  8460 | global iter:   7742/  8460 | loss: 0.0648 | ds_loss: 0.0000 | lr: 8.9320e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7743/  8460 | global iter:   7743/  8460 | loss: 0.0020 | ds_loss: 0.0000 | lr: 8.9075e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7744/  8460 | global iter:   7744/  8460 | loss: 0.0862 | ds_loss: 0.0000 | lr: 8.8831e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7744/  8460 | global iter:   7744/  8460 | loss: 0.0539 | ds_loss: 0.0000 | lr: 8.8831e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7745/  8460 | global iter:   7745/  8460 | loss: 0.0166 | ds_loss: 0.0000 | lr: 8.8587e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7746/  8460 | global iter:   7746/  8460 | loss: 0.0257 | ds_loss: 0.0000 | lr: 8.8344e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7747/  8460 | global iter:   7747/  8460 | loss: 0.1194 | ds_loss: 0.0000 | lr: 8.8101e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7748/  8460 | global iter:   7748/  8460 | loss: 0.0347 | ds_loss: 0.0000 | lr: 8.7858e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7748/  8460 | global iter:   7748/  8460 | loss: 0.0491 | ds_loss: 0.0000 | lr: 8.7858e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7749/  8460 | global iter:   7749/  8460 | loss: 0.0179 | ds_loss: 0.0000 | lr: 8.7616e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7750/  8460 | global iter:   7750/  8460 | loss: 0.1607 | ds_loss: 0.0000 | lr: 8.7374e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7751/  8460 | global iter:   7751/  8460 | loss: 0.0370 | ds_loss: 0.0000 | lr: 8.7132e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7752/  8460 | global iter:   7752/  8460 | loss: 0.1668 | ds_loss: 0.0000 | lr: 8.6891e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7752/  8460 | global iter:   7752/  8460 | loss: 0.0956 | ds_loss: 0.0000 | lr: 8.6891e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7753/  8460 | global iter:   7753/  8460 | loss: 0.0440 | ds_loss: 0.0000 | lr: 8.6650e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7754/  8460 | global iter:   7754/  8460 | loss: 0.0036 | ds_loss: 0.0000 | lr: 8.6409e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7755/  8460 | global iter:   7755/  8460 | loss: 0.0104 | ds_loss: 0.0000 | lr: 8.6168e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7756/  8460 | global iter:   7756/  8460 | loss: 0.0726 | ds_loss: 0.0000 | lr: 8.5928e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7756/  8460 | global iter:   7756/  8460 | loss: 0.0326 | ds_loss: 0.0000 | lr: 8.5928e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7757/  8460 | global iter:   7757/  8460 | loss: 0.0101 | ds_loss: 0.0000 | lr: 8.5689e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7758/  8460 | global iter:   7758/  8460 | loss: 0.0725 | ds_loss: 0.0000 | lr: 8.5449e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7759/  8460 | global iter:   7759/  8460 | loss: 0.0851 | ds_loss: 0.0000 | lr: 8.5210e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   7760/  8460 | global iter:   7760/  8460 | loss: 0.2628 | ds_loss: 0.0000 | lr: 8.4971e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7760/  8460 | global iter:   7760/  8460 | loss: 0.1076 | ds_loss: 0.0000 | lr: 8.4971e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7761/  8460 | global iter:   7761/  8460 | loss: 0.0043 | ds_loss: 0.0000 | lr: 8.4733e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   7762/  8460 | global iter:   7762/  8460 | loss: 0.0543 | ds_loss: 0.0000 | lr: 8.4495e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7763/  8460 | global iter:   7763/  8460 | loss: 0.0336 | ds_loss: 0.0000 | lr: 8.4257e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7764/  8460 | global iter:   7764/  8460 | loss: 0.0113 | ds_loss: 0.0000 | lr: 8.4020e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7764/  8460 | global iter:   7764/  8460 | loss: 0.0259 | ds_loss: 0.0000 | lr: 8.4020e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7765/  8460 | global iter:   7765/  8460 | loss: 0.0091 | ds_loss: 0.0000 | lr: 8.3783e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7766/  8460 | global iter:   7766/  8460 | loss: 0.0170 | ds_loss: 0.0000 | lr: 8.3546e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7767/  8460 | global iter:   7767/  8460 | loss: 0.0932 | ds_loss: 0.0000 | lr: 8.3310e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7768/  8460 | global iter:   7768/  8460 | loss: 0.0216 | ds_loss: 0.0000 | lr: 8.3074e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7768/  8460 | global iter:   7768/  8460 | loss: 0.0352 | ds_loss: 0.0000 | lr: 8.3074e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7769/  8460 | global iter:   7769/  8460 | loss: 0.0513 | ds_loss: 0.0000 | lr: 8.2838e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7770/  8460 | global iter:   7770/  8460 | loss: 0.0873 | ds_loss: 0.0000 | lr: 8.2602e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7771/  8460 | global iter:   7771/  8460 | loss: 0.0419 | ds_loss: 0.0000 | lr: 8.2367e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7772/  8460 | global iter:   7772/  8460 | loss: 0.0708 | ds_loss: 0.0000 | lr: 8.2133e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7772/  8460 | global iter:   7772/  8460 | loss: 0.0628 | ds_loss: 0.0000 | lr: 8.2133e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7773/  8460 | global iter:   7773/  8460 | loss: 0.0023 | ds_loss: 0.0000 | lr: 8.1898e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7774/  8460 | global iter:   7774/  8460 | loss: 0.0479 | ds_loss: 0.0000 | lr: 8.1664e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7775/  8460 | global iter:   7775/  8460 | loss: 0.0615 | ds_loss: 0.0000 | lr: 8.1430e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7776/  8460 | global iter:   7776/  8460 | loss: 0.0063 | ds_loss: 0.0000 | lr: 8.1197e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7776/  8460 | global iter:   7776/  8460 | loss: 0.0295 | ds_loss: 0.0000 | lr: 8.1197e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7777/  8460 | global iter:   7777/  8460 | loss: 0.0365 | ds_loss: 0.0000 | lr: 8.0964e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7778/  8460 | global iter:   7778/  8460 | loss: 0.2003 | ds_loss: 0.0000 | lr: 8.0731e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7779/  8460 | global iter:   7779/  8460 | loss: 0.0591 | ds_loss: 0.0000 | lr: 8.0499e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7780/  8460 | global iter:   7780/  8460 | loss: 0.0870 | ds_loss: 0.0000 | lr: 8.0267e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7780/  8460 | global iter:   7780/  8460 | loss: 0.0957 | ds_loss: 0.0000 | lr: 8.0267e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7781/  8460 | global iter:   7781/  8460 | loss: 0.0451 | ds_loss: 0.0000 | lr: 8.0035e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7782/  8460 | global iter:   7782/  8460 | loss: 0.0889 | ds_loss: 0.0000 | lr: 7.9804e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7783/  8460 | global iter:   7783/  8460 | loss: 0.0136 | ds_loss: 0.0000 | lr: 7.9573e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7784/  8460 | global iter:   7784/  8460 | loss: 0.0131 | ds_loss: 0.0000 | lr: 7.9342e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7784/  8460 | global iter:   7784/  8460 | loss: 0.0402 | ds_loss: 0.0000 | lr: 7.9342e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7785/  8460 | global iter:   7785/  8460 | loss: 0.0071 | ds_loss: 0.0000 | lr: 7.9111e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7786/  8460 | global iter:   7786/  8460 | loss: 0.0173 | ds_loss: 0.0000 | lr: 7.8881e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7787/  8460 | global iter:   7787/  8460 | loss: 0.1183 | ds_loss: 0.0000 | lr: 7.8652e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7788/  8460 | global iter:   7788/  8460 | loss: 0.0122 | ds_loss: 0.0000 | lr: 7.8422e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7788/  8460 | global iter:   7788/  8460 | loss: 0.0388 | ds_loss: 0.0000 | lr: 7.8422e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7789/  8460 | global iter:   7789/  8460 | loss: 0.0029 | ds_loss: 0.0000 | lr: 7.8193e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7790/  8460 | global iter:   7790/  8460 | loss: 0.0072 | ds_loss: 0.0000 | lr: 7.7964e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7791/  8460 | global iter:   7791/  8460 | loss: 0.0111 | ds_loss: 0.0000 | lr: 7.7736e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7792/  8460 | global iter:   7792/  8460 | loss: 0.0365 | ds_loss: 0.0000 | lr: 7.7508e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7792/  8460 | global iter:   7792/  8460 | loss: 0.0144 | ds_loss: 0.0000 | lr: 7.7508e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7793/  8460 | global iter:   7793/  8460 | loss: 0.0604 | ds_loss: 0.0000 | lr: 7.7280e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   7794/  8460 | global iter:   7794/  8460 | loss: 0.0691 | ds_loss: 0.0000 | lr: 7.7053e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7795/  8460 | global iter:   7795/  8460 | loss: 0.0364 | ds_loss: 0.0000 | lr: 7.6826e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7796/  8460 | global iter:   7796/  8460 | loss: 0.0330 | ds_loss: 0.0000 | lr: 7.6599e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7796/  8460 | global iter:   7796/  8460 | loss: 0.0497 | ds_loss: 0.0000 | lr: 7.6599e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7797/  8460 | global iter:   7797/  8460 | loss: 0.0250 | ds_loss: 0.0000 | lr: 7.6373e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7798/  8460 | global iter:   7798/  8460 | loss: 0.0559 | ds_loss: 0.0000 | lr: 7.6147e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7799/  8460 | global iter:   7799/  8460 | loss: 0.0135 | ds_loss: 0.0000 | lr: 7.5921e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7800/  8460 | global iter:   7800/  8460 | loss: 0.0409 | ds_loss: 0.0000 | lr: 7.5696e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7800/  8460 | global iter:   7800/  8460 | loss: 0.0338 | ds_loss: 0.0000 | lr: 7.5696e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7801/  8460 | global iter:   7801/  8460 | loss: 0.1433 | ds_loss: 0.0000 | lr: 7.5471e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7802/  8460 | global iter:   7802/  8460 | loss: 0.0078 | ds_loss: 0.0000 | lr: 7.5246e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7803/  8460 | global iter:   7803/  8460 | loss: 0.0490 | ds_loss: 0.0000 | lr: 7.5021e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7804/  8460 | global iter:   7804/  8460 | loss: 0.1002 | ds_loss: 0.0000 | lr: 7.4797e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7804/  8460 | global iter:   7804/  8460 | loss: 0.0751 | ds_loss: 0.0000 | lr: 7.4797e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7805/  8460 | global iter:   7805/  8460 | loss: 0.0372 | ds_loss: 0.0000 | lr: 7.4574e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7806/  8460 | global iter:   7806/  8460 | loss: 0.1303 | ds_loss: 0.0000 | lr: 7.4350e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7807/  8460 | global iter:   7807/  8460 | loss: 0.0382 | ds_loss: 0.0000 | lr: 7.4127e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7808/  8460 | global iter:   7808/  8460 | loss: 0.0108 | ds_loss: 0.0000 | lr: 7.3905e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7808/  8460 | global iter:   7808/  8460 | loss: 0.0541 | ds_loss: 0.0000 | lr: 7.3905e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7809/  8460 | global iter:   7809/  8460 | loss: 0.1287 | ds_loss: 0.0000 | lr: 7.3682e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7810/  8460 | global iter:   7810/  8460 | loss: 0.0455 | ds_loss: 0.0000 | lr: 7.3460e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7811/  8460 | global iter:   7811/  8460 | loss: 0.0171 | ds_loss: 0.0000 | lr: 7.3238e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7812/  8460 | global iter:   7812/  8460 | loss: 0.1144 | ds_loss: 0.0000 | lr: 7.3017e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7812/  8460 | global iter:   7812/  8460 | loss: 0.0764 | ds_loss: 0.0000 | lr: 7.3017e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7813/  8460 | global iter:   7813/  8460 | loss: 0.0248 | ds_loss: 0.0000 | lr: 7.2796e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7814/  8460 | global iter:   7814/  8460 | loss: 0.0427 | ds_loss: 0.0000 | lr: 7.2575e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7815/  8460 | global iter:   7815/  8460 | loss: 0.1255 | ds_loss: 0.0000 | lr: 7.2355e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7816/  8460 | global iter:   7816/  8460 | loss: 0.0680 | ds_loss: 0.0000 | lr: 7.2135e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7816/  8460 | global iter:   7816/  8460 | loss: 0.0652 | ds_loss: 0.0000 | lr: 7.2135e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7817/  8460 | global iter:   7817/  8460 | loss: 0.0221 | ds_loss: 0.0000 | lr: 7.1915e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7818/  8460 | global iter:   7818/  8460 | loss: 0.0520 | ds_loss: 0.0000 | lr: 7.1696e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7819/  8460 | global iter:   7819/  8460 | loss: 0.0372 | ds_loss: 0.0000 | lr: 7.1477e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7820/  8460 | global iter:   7820/  8460 | loss: 0.1116 | ds_loss: 0.0000 | lr: 7.1258e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7820/  8460 | global iter:   7820/  8460 | loss: 0.0557 | ds_loss: 0.0000 | lr: 7.1258e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7821/  8460 | global iter:   7821/  8460 | loss: 0.0389 | ds_loss: 0.0000 | lr: 7.1040e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7822/  8460 | global iter:   7822/  8460 | loss: 0.1176 | ds_loss: 0.0000 | lr: 7.0822e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7823/  8460 | global iter:   7823/  8460 | loss: 0.0330 | ds_loss: 0.0000 | lr: 7.0604e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7824/  8460 | global iter:   7824/  8460 | loss: 0.0182 | ds_loss: 0.0000 | lr: 7.0387e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7824/  8460 | global iter:   7824/  8460 | loss: 0.0519 | ds_loss: 0.0000 | lr: 7.0387e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7825/  8460 | global iter:   7825/  8460 | loss: 0.0025 | ds_loss: 0.0000 | lr: 7.0170e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7826/  8460 | global iter:   7826/  8460 | loss: 0.0265 | ds_loss: 0.0000 | lr: 6.9953e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7827/  8460 | global iter:   7827/  8460 | loss: 0.0380 | ds_loss: 0.0000 | lr: 6.9737e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7828/  8460 | global iter:   7828/  8460 | loss: 0.0873 | ds_loss: 0.0000 | lr: 6.9521e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7828/  8460 | global iter:   7828/  8460 | loss: 0.0386 | ds_loss: 0.0000 | lr: 6.9521e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7829/  8460 | global iter:   7829/  8460 | loss: 0.0316 | ds_loss: 0.0000 | lr: 6.9305e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7830/  8460 | global iter:   7830/  8460 | loss: 0.0122 | ds_loss: 0.0000 | lr: 6.9090e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7831/  8460 | global iter:   7831/  8460 | loss: 0.0658 | ds_loss: 0.0000 | lr: 6.8875e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7832/  8460 | global iter:   7832/  8460 | loss: 0.0041 | ds_loss: 0.0000 | lr: 6.8660e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7832/  8460 | global iter:   7832/  8460 | loss: 0.0284 | ds_loss: 0.0000 | lr: 6.8660e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7833/  8460 | global iter:   7833/  8460 | loss: 0.0227 | ds_loss: 0.0000 | lr: 6.8446e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7834/  8460 | global iter:   7834/  8460 | loss: 0.1422 | ds_loss: 0.0000 | lr: 6.8232e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7835/  8460 | global iter:   7835/  8460 | loss: 0.0030 | ds_loss: 0.0000 | lr: 6.8018e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7836/  8460 | global iter:   7836/  8460 | loss: 0.0026 | ds_loss: 0.0000 | lr: 6.7805e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7836/  8460 | global iter:   7836/  8460 | loss: 0.0426 | ds_loss: 0.0000 | lr: 6.7805e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7837/  8460 | global iter:   7837/  8460 | loss: 0.0206 | ds_loss: 0.0000 | lr: 6.7592e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   7838/  8460 | global iter:   7838/  8460 | loss: 0.0100 | ds_loss: 0.0000 | lr: 6.7379e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7839/  8460 | global iter:   7839/  8460 | loss: 0.0049 | ds_loss: 0.0000 | lr: 6.7167e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7840/  8460 | global iter:   7840/  8460 | loss: 0.0380 | ds_loss: 0.0000 | lr: 6.6955e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7840/  8460 | global iter:   7840/  8460 | loss: 0.0184 | ds_loss: 0.0000 | lr: 6.6955e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7841/  8460 | global iter:   7841/  8460 | loss: 0.0100 | ds_loss: 0.0000 | lr: 6.6743e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7842/  8460 | global iter:   7842/  8460 | loss: 0.0776 | ds_loss: 0.0000 | lr: 6.6532e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7843/  8460 | global iter:   7843/  8460 | loss: 0.0071 | ds_loss: 0.0000 | lr: 6.6321e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7844/  8460 | global iter:   7844/  8460 | loss: 0.0121 | ds_loss: 0.0000 | lr: 6.6110e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7844/  8460 | global iter:   7844/  8460 | loss: 0.0267 | ds_loss: 0.0000 | lr: 6.6110e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7845/  8460 | global iter:   7845/  8460 | loss: 0.0430 | ds_loss: 0.0000 | lr: 6.5900e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7846/  8460 | global iter:   7846/  8460 | loss: 0.0316 | ds_loss: 0.0000 | lr: 6.5690e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7847/  8460 | global iter:   7847/  8460 | loss: 0.0452 | ds_loss: 0.0000 | lr: 6.5480e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7848/  8460 | global iter:   7848/  8460 | loss: 0.0590 | ds_loss: 0.0000 | lr: 6.5271e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7848/  8460 | global iter:   7848/  8460 | loss: 0.0447 | ds_loss: 0.0000 | lr: 6.5271e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7849/  8460 | global iter:   7849/  8460 | loss: 0.1088 | ds_loss: 0.0000 | lr: 6.5062e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7850/  8460 | global iter:   7850/  8460 | loss: 0.0636 | ds_loss: 0.0000 | lr: 6.4853e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7851/  8460 | global iter:   7851/  8460 | loss: 0.0165 | ds_loss: 0.0000 | lr: 6.4645e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7852/  8460 | global iter:   7852/  8460 | loss: 0.0389 | ds_loss: 0.0000 | lr: 6.4437e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7852/  8460 | global iter:   7852/  8460 | loss: 0.0569 | ds_loss: 0.0000 | lr: 6.4437e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7853/  8460 | global iter:   7853/  8460 | loss: 0.0939 | ds_loss: 0.0000 | lr: 6.4230e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7854/  8460 | global iter:   7854/  8460 | loss: 0.0181 | ds_loss: 0.0000 | lr: 6.4022e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7855/  8460 | global iter:   7855/  8460 | loss: 0.0341 | ds_loss: 0.0000 | lr: 6.3815e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7856/  8460 | global iter:   7856/  8460 | loss: 0.0310 | ds_loss: 0.0000 | lr: 6.3609e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7856/  8460 | global iter:   7856/  8460 | loss: 0.0443 | ds_loss: 0.0000 | lr: 6.3609e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7857/  8460 | global iter:   7857/  8460 | loss: 0.0988 | ds_loss: 0.0000 | lr: 6.3402e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   7858/  8460 | global iter:   7858/  8460 | loss: 0.0048 | ds_loss: 0.0000 | lr: 6.3196e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   7859/  8460 | global iter:   7859/  8460 | loss: 0.0304 | ds_loss: 0.0000 | lr: 6.2991e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7860/  8460 | global iter:   7860/  8460 | loss: 0.0493 | ds_loss: 0.0000 | lr: 6.2786e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7860/  8460 | global iter:   7860/  8460 | loss: 0.0458 | ds_loss: 0.0000 | lr: 6.2786e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7861/  8460 | global iter:   7861/  8460 | loss: 0.0376 | ds_loss: 0.0000 | lr: 6.2581e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7862/  8460 | global iter:   7862/  8460 | loss: 0.0004 | ds_loss: 0.0000 | lr: 6.2376e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7863/  8460 | global iter:   7863/  8460 | loss: 0.0618 | ds_loss: 0.0000 | lr: 6.2172e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7864/  8460 | global iter:   7864/  8460 | loss: 0.0824 | ds_loss: 0.0000 | lr: 6.1968e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7864/  8460 | global iter:   7864/  8460 | loss: 0.0455 | ds_loss: 0.0000 | lr: 6.1968e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7865/  8460 | global iter:   7865/  8460 | loss: 0.0106 | ds_loss: 0.0000 | lr: 6.1764e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7866/  8460 | global iter:   7866/  8460 | loss: 0.0707 | ds_loss: 0.0000 | lr: 6.1561e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7867/  8460 | global iter:   7867/  8460 | loss: 0.0459 | ds_loss: 0.0000 | lr: 6.1358e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7868/  8460 | global iter:   7868/  8460 | loss: 0.0204 | ds_loss: 0.0000 | lr: 6.1156e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7868/  8460 | global iter:   7868/  8460 | loss: 0.0369 | ds_loss: 0.0000 | lr: 6.1156e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7869/  8460 | global iter:   7869/  8460 | loss: 0.1100 | ds_loss: 0.0000 | lr: 6.0953e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7870/  8460 | global iter:   7870/  8460 | loss: 0.0618 | ds_loss: 0.0000 | lr: 6.0751e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7871/  8460 | global iter:   7871/  8460 | loss: 0.0051 | ds_loss: 0.0000 | lr: 6.0550e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7872/  8460 | global iter:   7872/  8460 | loss: 0.0473 | ds_loss: 0.0000 | lr: 6.0349e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7872/  8460 | global iter:   7872/  8460 | loss: 0.0560 | ds_loss: 0.0000 | lr: 6.0349e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7873/  8460 | global iter:   7873/  8460 | loss: 0.0128 | ds_loss: 0.0000 | lr: 6.0148e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7874/  8460 | global iter:   7874/  8460 | loss: 0.1271 | ds_loss: 0.0000 | lr: 5.9947e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7875/  8460 | global iter:   7875/  8460 | loss: 0.0281 | ds_loss: 0.0000 | lr: 5.9747e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7876/  8460 | global iter:   7876/  8460 | loss: 0.0409 | ds_loss: 0.0000 | lr: 5.9547e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7876/  8460 | global iter:   7876/  8460 | loss: 0.0522 | ds_loss: 0.0000 | lr: 5.9547e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7877/  8460 | global iter:   7877/  8460 | loss: 0.0555 | ds_loss: 0.0000 | lr: 5.9348e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7878/  8460 | global iter:   7878/  8460 | loss: 0.0170 | ds_loss: 0.0000 | lr: 5.9148e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7879/  8460 | global iter:   7879/  8460 | loss: 0.0138 | ds_loss: 0.0000 | lr: 5.8949e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7880/  8460 | global iter:   7880/  8460 | loss: 0.0174 | ds_loss: 0.0000 | lr: 5.8751e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7880/  8460 | global iter:   7880/  8460 | loss: 0.0259 | ds_loss: 0.0000 | lr: 5.8751e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7881/  8460 | global iter:   7881/  8460 | loss: 0.0093 | ds_loss: 0.0000 | lr: 5.8553e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7882/  8460 | global iter:   7882/  8460 | loss: 0.1143 | ds_loss: 0.0000 | lr: 5.8355e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7883/  8460 | global iter:   7883/  8460 | loss: 0.0680 | ds_loss: 0.0000 | lr: 5.8157e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7884/  8460 | global iter:   7884/  8460 | loss: 0.0060 | ds_loss: 0.0000 | lr: 5.7960e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7884/  8460 | global iter:   7884/  8460 | loss: 0.0494 | ds_loss: 0.0000 | lr: 5.7960e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7885/  8460 | global iter:   7885/  8460 | loss: 0.0051 | ds_loss: 0.0000 | lr: 5.7763e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7886/  8460 | global iter:   7886/  8460 | loss: 0.0328 | ds_loss: 0.0000 | lr: 5.7567e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7887/  8460 | global iter:   7887/  8460 | loss: 0.0300 | ds_loss: 0.0000 | lr: 5.7371e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7888/  8460 | global iter:   7888/  8460 | loss: 0.0822 | ds_loss: 0.0000 | lr: 5.7175e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7888/  8460 | global iter:   7888/  8460 | loss: 0.0375 | ds_loss: 0.0000 | lr: 5.7175e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7889/  8460 | global iter:   7889/  8460 | loss: 0.0204 | ds_loss: 0.0000 | lr: 5.6979e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7890/  8460 | global iter:   7890/  8460 | loss: 0.1019 | ds_loss: 0.0000 | lr: 5.6784e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7891/  8460 | global iter:   7891/  8460 | loss: 0.0164 | ds_loss: 0.0000 | lr: 5.6589e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7892/  8460 | global iter:   7892/  8460 | loss: 0.0482 | ds_loss: 0.0000 | lr: 5.6395e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7892/  8460 | global iter:   7892/  8460 | loss: 0.0467 | ds_loss: 0.0000 | lr: 5.6395e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7893/  8460 | global iter:   7893/  8460 | loss: 0.0395 | ds_loss: 0.0000 | lr: 5.6201e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7894/  8460 | global iter:   7894/  8460 | loss: 0.0753 | ds_loss: 0.0000 | lr: 5.6007e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7895/  8460 | global iter:   7895/  8460 | loss: 0.0148 | ds_loss: 0.0000 | lr: 5.5813e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7896/  8460 | global iter:   7896/  8460 | loss: 0.0384 | ds_loss: 0.0000 | lr: 5.5620e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7896/  8460 | global iter:   7896/  8460 | loss: 0.0420 | ds_loss: 0.0000 | lr: 5.5620e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7897/  8460 | global iter:   7897/  8460 | loss: 0.0488 | ds_loss: 0.0000 | lr: 5.5427e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7898/  8460 | global iter:   7898/  8460 | loss: 0.1510 | ds_loss: 0.0000 | lr: 5.5235e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7899/  8460 | global iter:   7899/  8460 | loss: 0.0103 | ds_loss: 0.0000 | lr: 5.5043e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7900/  8460 | global iter:   7900/  8460 | loss: 0.0239 | ds_loss: 0.0000 | lr: 5.4851e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7900/  8460 | global iter:   7900/  8460 | loss: 0.0585 | ds_loss: 0.0000 | lr: 5.4851e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7901/  8460 | global iter:   7901/  8460 | loss: 0.0445 | ds_loss: 0.0000 | lr: 5.4659e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7902/  8460 | global iter:   7902/  8460 | loss: 0.0911 | ds_loss: 0.0000 | lr: 5.4468e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7903/  8460 | global iter:   7903/  8460 | loss: 0.0339 | ds_loss: 0.0000 | lr: 5.4277e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7904/  8460 | global iter:   7904/  8460 | loss: 0.0112 | ds_loss: 0.0000 | lr: 5.4087e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7904/  8460 | global iter:   7904/  8460 | loss: 0.0452 | ds_loss: 0.0000 | lr: 5.4087e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7905/  8460 | global iter:   7905/  8460 | loss: 0.0200 | ds_loss: 0.0000 | lr: 5.3897e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7906/  8460 | global iter:   7906/  8460 | loss: 0.0596 | ds_loss: 0.0000 | lr: 5.3707e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7907/  8460 | global iter:   7907/  8460 | loss: 0.0233 | ds_loss: 0.0000 | lr: 5.3518e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7908/  8460 | global iter:   7908/  8460 | loss: 0.1569 | ds_loss: 0.0000 | lr: 5.3329e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7908/  8460 | global iter:   7908/  8460 | loss: 0.0649 | ds_loss: 0.0000 | lr: 5.3329e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7909/  8460 | global iter:   7909/  8460 | loss: 0.1536 | ds_loss: 0.0000 | lr: 5.3140e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7910/  8460 | global iter:   7910/  8460 | loss: 0.0157 | ds_loss: 0.0000 | lr: 5.2951e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7911/  8460 | global iter:   7911/  8460 | loss: 0.0011 | ds_loss: 0.0000 | lr: 5.2763e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7912/  8460 | global iter:   7912/  8460 | loss: 0.0139 | ds_loss: 0.0000 | lr: 5.2576e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7912/  8460 | global iter:   7912/  8460 | loss: 0.0461 | ds_loss: 0.0000 | lr: 5.2576e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7913/  8460 | global iter:   7913/  8460 | loss: 0.0143 | ds_loss: 0.0000 | lr: 5.2388e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7914/  8460 | global iter:   7914/  8460 | loss: 0.0860 | ds_loss: 0.0000 | lr: 5.2201e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7915/  8460 | global iter:   7915/  8460 | loss: 0.0092 | ds_loss: 0.0000 | lr: 5.2014e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7916/  8460 | global iter:   7916/  8460 | loss: 0.0722 | ds_loss: 0.0000 | lr: 5.1828e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7916/  8460 | global iter:   7916/  8460 | loss: 0.0454 | ds_loss: 0.0000 | lr: 5.1828e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7917/  8460 | global iter:   7917/  8460 | loss: 0.0165 | ds_loss: 0.0000 | lr: 5.1642e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7918/  8460 | global iter:   7918/  8460 | loss: 0.0027 | ds_loss: 0.0000 | lr: 5.1456e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7919/  8460 | global iter:   7919/  8460 | loss: 0.0125 | ds_loss: 0.0000 | lr: 5.1271e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7920/  8460 | global iter:   7920/  8460 | loss: 0.0298 | ds_loss: 0.0000 | lr: 5.1086e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7920/  8460 | global iter:   7920/  8460 | loss: 0.0153 | ds_loss: 0.0000 | lr: 5.1086e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7921/  8460 | global iter:   7921/  8460 | loss: 0.0930 | ds_loss: 0.0000 | lr: 5.0901e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7922/  8460 | global iter:   7922/  8460 | loss: 0.0014 | ds_loss: 0.0000 | lr: 5.0717e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7923/  8460 | global iter:   7923/  8460 | loss: 0.0507 | ds_loss: 0.0000 | lr: 5.0533e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7924/  8460 | global iter:   7924/  8460 | loss: 0.0318 | ds_loss: 0.0000 | lr: 5.0349e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7924/  8460 | global iter:   7924/  8460 | loss: 0.0442 | ds_loss: 0.0000 | lr: 5.0349e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7925/  8460 | global iter:   7925/  8460 | loss: 0.0138 | ds_loss: 0.0000 | lr: 5.0166e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7926/  8460 | global iter:   7926/  8460 | loss: 0.0278 | ds_loss: 0.0000 | lr: 4.9983e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7927/  8460 | global iter:   7927/  8460 | loss: 0.0433 | ds_loss: 0.0000 | lr: 4.9800e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7928/  8460 | global iter:   7928/  8460 | loss: 0.0402 | ds_loss: 0.0000 | lr: 4.9617e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7928/  8460 | global iter:   7928/  8460 | loss: 0.0313 | ds_loss: 0.0000 | lr: 4.9617e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7929/  8460 | global iter:   7929/  8460 | loss: 0.0205 | ds_loss: 0.0000 | lr: 4.9435e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7930/  8460 | global iter:   7930/  8460 | loss: 0.0330 | ds_loss: 0.0000 | lr: 4.9254e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7931/  8460 | global iter:   7931/  8460 | loss: 0.0135 | ds_loss: 0.0000 | lr: 4.9072e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7932/  8460 | global iter:   7932/  8460 | loss: 0.0199 | ds_loss: 0.0000 | lr: 4.8891e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7932/  8460 | global iter:   7932/  8460 | loss: 0.0217 | ds_loss: 0.0000 | lr: 4.8891e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7933/  8460 | global iter:   7933/  8460 | loss: 0.1054 | ds_loss: 0.0000 | lr: 4.8711e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7934/  8460 | global iter:   7934/  8460 | loss: 0.0167 | ds_loss: 0.0000 | lr: 4.8531e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7935/  8460 | global iter:   7935/  8460 | loss: 0.0199 | ds_loss: 0.0000 | lr: 4.8351e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7936/  8460 | global iter:   7936/  8460 | loss: 0.0745 | ds_loss: 0.0000 | lr: 4.8171e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7936/  8460 | global iter:   7936/  8460 | loss: 0.0541 | ds_loss: 0.0000 | lr: 4.8171e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7937/  8460 | global iter:   7937/  8460 | loss: 0.0083 | ds_loss: 0.0000 | lr: 4.7992e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7938/  8460 | global iter:   7938/  8460 | loss: 0.0102 | ds_loss: 0.0000 | lr: 4.7813e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7939/  8460 | global iter:   7939/  8460 | loss: 0.0740 | ds_loss: 0.0000 | lr: 4.7634e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7940/  8460 | global iter:   7940/  8460 | loss: 0.0298 | ds_loss: 0.0000 | lr: 4.7456e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7940/  8460 | global iter:   7940/  8460 | loss: 0.0306 | ds_loss: 0.0000 | lr: 4.7456e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7941/  8460 | global iter:   7941/  8460 | loss: 0.0273 | ds_loss: 0.0000 | lr: 4.7278e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7942/  8460 | global iter:   7942/  8460 | loss: 0.1006 | ds_loss: 0.0000 | lr: 4.7100e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7943/  8460 | global iter:   7943/  8460 | loss: 0.0183 | ds_loss: 0.0000 | lr: 4.6923e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7944/  8460 | global iter:   7944/  8460 | loss: 0.0351 | ds_loss: 0.0000 | lr: 4.6746e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7944/  8460 | global iter:   7944/  8460 | loss: 0.0453 | ds_loss: 0.0000 | lr: 4.6746e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7945/  8460 | global iter:   7945/  8460 | loss: 0.0835 | ds_loss: 0.0000 | lr: 4.6569e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7946/  8460 | global iter:   7946/  8460 | loss: 0.0256 | ds_loss: 0.0000 | lr: 4.6393e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7947/  8460 | global iter:   7947/  8460 | loss: 0.0083 | ds_loss: 0.0000 | lr: 4.6217e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7948/  8460 | global iter:   7948/  8460 | loss: 0.1824 | ds_loss: 0.0000 | lr: 4.6042e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7948/  8460 | global iter:   7948/  8460 | loss: 0.0749 | ds_loss: 0.0000 | lr: 4.6042e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7949/  8460 | global iter:   7949/  8460 | loss: 0.0864 | ds_loss: 0.0000 | lr: 4.5866e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7950/  8460 | global iter:   7950/  8460 | loss: 0.0512 | ds_loss: 0.0000 | lr: 4.5691e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7951/  8460 | global iter:   7951/  8460 | loss: 0.0131 | ds_loss: 0.0000 | lr: 4.5517e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7952/  8460 | global iter:   7952/  8460 | loss: 0.0448 | ds_loss: 0.0000 | lr: 4.5343e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7952/  8460 | global iter:   7952/  8460 | loss: 0.0489 | ds_loss: 0.0000 | lr: 4.5343e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7953/  8460 | global iter:   7953/  8460 | loss: 0.0164 | ds_loss: 0.0000 | lr: 4.5169e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7954/  8460 | global iter:   7954/  8460 | loss: 0.0512 | ds_loss: 0.0000 | lr: 4.4995e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7955/  8460 | global iter:   7955/  8460 | loss: 0.0078 | ds_loss: 0.0000 | lr: 4.4822e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7956/  8460 | global iter:   7956/  8460 | loss: 0.0083 | ds_loss: 0.0000 | lr: 4.4649e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7956/  8460 | global iter:   7956/  8460 | loss: 0.0209 | ds_loss: 0.0000 | lr: 4.4649e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7957/  8460 | global iter:   7957/  8460 | loss: 0.0530 | ds_loss: 0.0000 | lr: 4.4477e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7958/  8460 | global iter:   7958/  8460 | loss: 0.0330 | ds_loss: 0.0000 | lr: 4.4304e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7959/  8460 | global iter:   7959/  8460 | loss: 0.0544 | ds_loss: 0.0000 | lr: 4.4132e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7960/  8460 | global iter:   7960/  8460 | loss: 0.0233 | ds_loss: 0.0000 | lr: 4.3961e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7960/  8460 | global iter:   7960/  8460 | loss: 0.0409 | ds_loss: 0.0000 | lr: 4.3961e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7961/  8460 | global iter:   7961/  8460 | loss: 0.0220 | ds_loss: 0.0000 | lr: 4.3790e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7962/  8460 | global iter:   7962/  8460 | loss: 0.0179 | ds_loss: 0.0000 | lr: 4.3619e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7963/  8460 | global iter:   7963/  8460 | loss: 0.0004 | ds_loss: 0.0000 | lr: 4.3448e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7964/  8460 | global iter:   7964/  8460 | loss: 0.0026 | ds_loss: 0.0000 | lr: 4.3278e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7964/  8460 | global iter:   7964/  8460 | loss: 0.0107 | ds_loss: 0.0000 | lr: 4.3278e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7965/  8460 | global iter:   7965/  8460 | loss: 0.0094 | ds_loss: 0.0000 | lr: 4.3108e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7966/  8460 | global iter:   7966/  8460 | loss: 0.0236 | ds_loss: 0.0000 | lr: 4.2939e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7967/  8460 | global iter:   7967/  8460 | loss: 0.0034 | ds_loss: 0.0000 | lr: 4.2770e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7968/  8460 | global iter:   7968/  8460 | loss: 0.0053 | ds_loss: 0.0000 | lr: 4.2601e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7968/  8460 | global iter:   7968/  8460 | loss: 0.0104 | ds_loss: 0.0000 | lr: 4.2601e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7969/  8460 | global iter:   7969/  8460 | loss: 0.0186 | ds_loss: 0.0000 | lr: 4.2433e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7970/  8460 | global iter:   7970/  8460 | loss: 0.0527 | ds_loss: 0.0000 | lr: 4.2264e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7971/  8460 | global iter:   7971/  8460 | loss: 0.2224 | ds_loss: 0.0000 | lr: 4.2097e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7972/  8460 | global iter:   7972/  8460 | loss: 0.0014 | ds_loss: 0.0000 | lr: 4.1929e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7972/  8460 | global iter:   7972/  8460 | loss: 0.0738 | ds_loss: 0.0000 | lr: 4.1929e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7973/  8460 | global iter:   7973/  8460 | loss: 0.1127 | ds_loss: 0.0000 | lr: 4.1762e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7974/  8460 | global iter:   7974/  8460 | loss: 0.0365 | ds_loss: 0.0000 | lr: 4.1595e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7975/  8460 | global iter:   7975/  8460 | loss: 0.0591 | ds_loss: 0.0000 | lr: 4.1429e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7976/  8460 | global iter:   7976/  8460 | loss: 0.0715 | ds_loss: 0.0000 | lr: 4.1263e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7976/  8460 | global iter:   7976/  8460 | loss: 0.0699 | ds_loss: 0.0000 | lr: 4.1263e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7977/  8460 | global iter:   7977/  8460 | loss: 0.0157 | ds_loss: 0.0000 | lr: 4.1097e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7978/  8460 | global iter:   7978/  8460 | loss: 0.0610 | ds_loss: 0.0000 | lr: 4.0932e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7979/  8460 | global iter:   7979/  8460 | loss: 0.0177 | ds_loss: 0.0000 | lr: 4.0766e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7980/  8460 | global iter:   7980/  8460 | loss: 0.0815 | ds_loss: 0.0000 | lr: 4.0602e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7980/  8460 | global iter:   7980/  8460 | loss: 0.0440 | ds_loss: 0.0000 | lr: 4.0602e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7981/  8460 | global iter:   7981/  8460 | loss: 0.0452 | ds_loss: 0.0000 | lr: 4.0437e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   7982/  8460 | global iter:   7982/  8460 | loss: 0.0037 | ds_loss: 0.0000 | lr: 4.0273e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7983/  8460 | global iter:   7983/  8460 | loss: 0.1289 | ds_loss: 0.0000 | lr: 4.0110e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7984/  8460 | global iter:   7984/  8460 | loss: 0.1324 | ds_loss: 0.0000 | lr: 3.9946e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7984/  8460 | global iter:   7984/  8460 | loss: 0.0775 | ds_loss: 0.0000 | lr: 3.9946e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7985/  8460 | global iter:   7985/  8460 | loss: 0.0537 | ds_loss: 0.0000 | lr: 3.9783e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7986/  8460 | global iter:   7986/  8460 | loss: 0.0902 | ds_loss: 0.0000 | lr: 3.9620e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7987/  8460 | global iter:   7987/  8460 | loss: 0.0459 | ds_loss: 0.0000 | lr: 3.9458e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   7988/  8460 | global iter:   7988/  8460 | loss: 0.1727 | ds_loss: 0.0000 | lr: 3.9296e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7988/  8460 | global iter:   7988/  8460 | loss: 0.0906 | ds_loss: 0.0000 | lr: 3.9296e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7989/  8460 | global iter:   7989/  8460 | loss: 0.0183 | ds_loss: 0.0000 | lr: 3.9134e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7990/  8460 | global iter:   7990/  8460 | loss: 0.0696 | ds_loss: 0.0000 | lr: 3.8973e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7991/  8460 | global iter:   7991/  8460 | loss: 0.0577 | ds_loss: 0.0000 | lr: 3.8812e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7992/  8460 | global iter:   7992/  8460 | loss: 0.0172 | ds_loss: 0.0000 | lr: 3.8651e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7992/  8460 | global iter:   7992/  8460 | loss: 0.0407 | ds_loss: 0.0000 | lr: 3.8651e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7993/  8460 | global iter:   7993/  8460 | loss: 0.0292 | ds_loss: 0.0000 | lr: 3.8491e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   7994/  8460 | global iter:   7994/  8460 | loss: 0.0368 | ds_loss: 0.0000 | lr: 3.8331e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7995/  8460 | global iter:   7995/  8460 | loss: 0.0307 | ds_loss: 0.0000 | lr: 3.8171e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7996/  8460 | global iter:   7996/  8460 | loss: 0.0373 | ds_loss: 0.0000 | lr: 3.8012e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   7996/  8460 | global iter:   7996/  8460 | loss: 0.0335 | ds_loss: 0.0000 | lr: 3.8012e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   7997/  8460 | global iter:   7997/  8460 | loss: 0.0024 | ds_loss: 0.0000 | lr: 3.7853e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7998/  8460 | global iter:   7998/  8460 | loss: 0.0754 | ds_loss: 0.0000 | lr: 3.7694e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   7999/  8460 | global iter:   7999/  8460 | loss: 0.0152 | ds_loss: 0.0000 | lr: 3.7536e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8000/  8460 | global iter:   8000/  8460 | loss: 0.0231 | ds_loss: 0.0000 | lr: 3.7378e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8000/  8460 | global iter:   8000/  8460 | loss: 0.0290 | ds_loss: 0.0000 | lr: 3.7378e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
Model save to ./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1/8000
dp size 1
0/125
1/125
2/125
3/125
4/125
5/125
6/125
7/125
8/125
9/125
10/125
11/125
12/125
13/125
14/125
15/125
Evaluating:   0%|          | 0/125 [00:00<?, ?it/s]Evaluating:   1%|          | 1/125 [00:01<03:54,  1.89s/it]Evaluating:   2%|▏         | 2/125 [00:03<03:49,  1.87s/it]Evaluating:   2%|▏         | 3/125 [00:05<03:32,  1.74s/it]Evaluating:   3%|▎         | 4/125 [00:07<03:35,  1.78s/it]Evaluating:   4%|▍         | 5/125 [00:09<04:08,  2.07s/it]Evaluating:   5%|▍         | 6/125 [00:12<04:15,  2.15s/it]Evaluating:   6%|▌         | 7/125 [00:12<03:25,  1.74s/it]Evaluating:   6%|▋         | 8/125 [00:14<03:25,  1.76s/it]Evaluating:   7%|▋         | 9/125 [00:16<03:27,  1.79s/it]Evaluating:   8%|▊         | 10/125 [00:18<03:42,  1.93s/it]Evaluating:   9%|▉         | 11/125 [00:20<03:42,  1.96s/it]Evaluating:  10%|▉         | 12/125 [00:23<04:02,  2.15s/it]Evaluating:  10%|█         | 13/125 [00:25<03:50,  2.05s/it]Evaluating:  11%|█         | 14/125 [00:26<03:12,  1.73s/it]Evaluating:  12%|█▏        | 15/125 [00:27<03:01,  1.65s/it]Evaluating:  13%|█▎        | 1616/125
17/125
18/125
19/125
20/125
21/125
22/125
23/125
24/125
25/125
26/125
27/125
28/125
29/125
30/125
31/125
/125 [00:30<03:27,  1.90s/it]Evaluating:  14%|█▎        | 17/125 [00:31<03:13,  1.79s/it]Evaluating:  14%|█▍        | 18/125 [00:32<02:48,  1.57s/it]Evaluating:  15%|█▌        | 19/125 [00:35<03:26,  1.94s/it]Evaluating:  16%|█▌        | 20/125 [00:38<03:51,  2.20s/it]Evaluating:  17%|█▋        | 21/125 [00:41<03:59,  2.31s/it]Evaluating:  18%|█▊        | 22/125 [00:43<03:51,  2.25s/it]Evaluating:  18%|█▊        | 23/125 [00:45<03:43,  2.20s/it]Evaluating:  19%|█▉        | 24/125 [00:47<03:47,  2.25s/it]Evaluating:  20%|██        | 25/125 [00:49<03:30,  2.10s/it]Evaluating:  21%|██        | 26/125 [00:51<03:41,  2.24s/it]Evaluating:  22%|██▏       | 27/125 [00:54<03:50,  2.35s/it]Evaluating:  22%|██▏       | 28/125 [00:57<04:01,  2.49s/it]Evaluating:  23%|██▎       | 29/125 [01:00<04:08,  2.59s/it]Evaluating:  24%|██▍       | 30/125 [01:02<04:12,  2.65s/it]Evaluating:  25%|██▍       | 31/125 [01:04<03:39,  2.34s/it]Evaluatin32/125
33/125
34/125
35/125
36/125
37/125
38/125
39/125
40/125
41/125
42/125
43/125
44/125
45/125
46/125
g:  26%|██▌       | 32/125 [01:06<03:15,  2.10s/it]Evaluating:  26%|██▋       | 33/125 [01:08<03:18,  2.16s/it]Evaluating:  27%|██▋       | 34/125 [01:10<03:15,  2.15s/it]Evaluating:  28%|██▊       | 35/125 [01:13<03:31,  2.35s/it]Evaluating:  29%|██▉       | 36/125 [01:16<03:38,  2.45s/it]Evaluating:  30%|██▉       | 37/125 [01:17<03:19,  2.27s/it]Evaluating:  30%|███       | 38/125 [01:19<03:01,  2.09s/it]Evaluating:  31%|███       | 39/125 [01:21<02:47,  1.95s/it]Evaluating:  32%|███▏      | 40/125 [01:22<02:32,  1.80s/it]Evaluating:  33%|███▎      | 41/125 [01:25<02:56,  2.10s/it]Evaluating:  34%|███▎      | 42/125 [01:28<03:13,  2.33s/it]Evaluating:  34%|███▍      | 43/125 [01:29<02:55,  2.14s/it]Evaluating:  35%|███▌      | 44/125 [01:31<02:46,  2.05s/it]Evaluating:  36%|███▌      | 45/125 [01:33<02:27,  1.85s/it]Evaluating:  37%|███▋      | 46/125 [01:35<02:35,  1.97s/it]Evaluating:  347/125
48/125
49/125
50/125
51/125
52/125
53/125
54/125
55/125
56/125
57/125
58/125
59/125
60/125
8%|███▊      | 47/125 [01:37<02:36,  2.00s/it]Evaluating:  38%|███▊      | 48/125 [01:39<02:41,  2.10s/it]Evaluating:  39%|███▉      | 49/125 [01:42<02:55,  2.31s/it]Evaluating:  40%|████      | 50/125 [01:44<02:38,  2.12s/it]Evaluating:  41%|████      | 51/125 [01:46<02:27,  1.99s/it]Evaluating:  42%|████▏     | 52/125 [01:47<02:18,  1.90s/it]Evaluating:  42%|████▏     | 53/125 [01:49<02:14,  1.87s/it]Evaluating:  43%|████▎     | 54/125 [01:51<02:15,  1.91s/it]Evaluating:  44%|████▍     | 55/125 [01:53<02:06,  1.80s/it]Evaluating:  45%|████▍     | 56/125 [01:55<02:18,  2.01s/it]Evaluating:  46%|████▌     | 57/125 [01:58<02:33,  2.25s/it]Evaluating:  46%|████▋     | 58/125 [02:00<02:24,  2.16s/it]Evaluating:  47%|████▋     | 59/125 [02:01<02:06,  1.91s/it]Evaluating:  48%|████▊     | 60/125 [02:03<02:05,  1.93s/it]Evaluating:  49%|████▉     | 61/125 [02:05<061/125
62/125
63/125
64/125
65/125
66/125
67/125
68/125
69/125
70/125
71/125
72/125
73/125
Distributed index stop interation. Idx: 596 Total_length: 596
2:07,  1.99s/it]Evaluating:  50%|████▉     | 62/125 [02:08<02:11,  2.09s/it]Evaluating:  50%|█████     | 63/125 [02:10<02:23,  2.31s/it]Evaluating:  51%|█████     | 64/125 [02:13<02:20,  2.30s/it]Evaluating:  52%|█████▏    | 65/125 [02:15<02:09,  2.16s/it]Evaluating:  53%|█████▎    | 66/125 [02:17<02:08,  2.17s/it]Evaluating:  54%|█████▎    | 67/125 [02:19<02:08,  2.21s/it]Evaluating:  54%|█████▍    | 68/125 [02:21<02:00,  2.11s/it]Evaluating:  55%|█████▌    | 69/125 [02:23<01:55,  2.07s/it]Evaluating:  56%|█████▌    | 70/125 [02:25<01:58,  2.16s/it]Evaluating:  57%|█████▋    | 71/125 [02:27<01:51,  2.06s/it]Evaluating:  58%|█████▊    | 72/125 [02:29<01:53,  2.14s/it]Evaluating:  58%|█████▊    | 73/125 [02:31<01:47,  2.07s/it]Evaluating:  59%|█████▉    | 74/125 [02:34<01:56,  2.29s/it]Evaluating:  59%|█████▉    | 74/125 [02:34<01:46,  2.09s/it]
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1/eval/9
dev | avg_loss: 1.1580768594065227 | {'exact_match': 0.0, 'rougeL': 57.5565}
train | epoch   9 | Iter:   8001/  8460 | global iter:   8001/  8460 | loss: 0.0031 | ds_loss: 0.0000 | lr: 3.7221e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8002/  8460 | global iter:   8002/  8460 | loss: 0.0523 | ds_loss: 0.0000 | lr: 3.7063e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8003/  8460 | global iter:   8003/  8460 | loss: 0.0118 | ds_loss: 0.0000 | lr: 3.6906e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8004/  8460 | global iter:   8004/  8460 | loss: 0.1121 | ds_loss: 0.0000 | lr: 3.6750e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8004/  8460 | global iter:   8004/  8460 | loss: 0.0448 | ds_loss: 0.0000 | lr: 3.6750e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8005/  8460 | global iter:   8005/  8460 | loss: 0.0437 | ds_loss: 0.0000 | lr: 3.6594e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8006/  8460 | global iter:   8006/  8460 | loss: 0.1229 | ds_loss: 0.0000 | lr: 3.6438e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8007/  8460 | global iter:   8007/  8460 | loss: 0.0262 | ds_loss: 0.0000 | lr: 3.6282e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8008/  8460 | global iter:   8008/  8460 | loss: 0.0218 | ds_loss: 0.0000 | lr: 3.6127e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8008/  8460 | global iter:   8008/  8460 | loss: 0.0537 | ds_loss: 0.0000 | lr: 3.6127e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8009/  8460 | global iter:   8009/  8460 | loss: 0.0230 | ds_loss: 0.0000 | lr: 3.5972e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8010/  8460 | global iter:   8010/  8460 | loss: 0.0059 | ds_loss: 0.0000 | lr: 3.5817e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8011/  8460 | global iter:   8011/  8460 | loss: 0.0378 | ds_loss: 0.0000 | lr: 3.5663e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8012/  8460 | global iter:   8012/  8460 | loss: 0.0410 | ds_loss: 0.0000 | lr: 3.5509e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8012/  8460 | global iter:   8012/  8460 | loss: 0.0269 | ds_loss: 0.0000 | lr: 3.5509e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8013/  8460 | global iter:   8013/  8460 | loss: 0.0155 | ds_loss: 0.0000 | lr: 3.5356e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8014/  8460 | global iter:   8014/  8460 | loss: 0.0586 | ds_loss: 0.0000 | lr: 3.5203e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8015/  8460 | global iter:   8015/  8460 | loss: 0.0723 | ds_loss: 0.0000 | lr: 3.5050e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8016/  8460 | global iter:   8016/  8460 | loss: 0.0199 | ds_loss: 0.0000 | lr: 3.4897e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8016/  8460 | global iter:   8016/  8460 | loss: 0.0416 | ds_loss: 0.0000 | lr: 3.4897e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8017/  8460 | global iter:   8017/  8460 | loss: 0.0148 | ds_loss: 0.0000 | lr: 3.4745e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8018/  8460 | global iter:   8018/  8460 | loss: 0.0638 | ds_loss: 0.0000 | lr: 3.4593e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8019/  8460 | global iter:   8019/  8460 | loss: 0.0025 | ds_loss: 0.0000 | lr: 3.4442e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8020/  8460 | global iter:   8020/  8460 | loss: 0.0499 | ds_loss: 0.0000 | lr: 3.4291e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8020/  8460 | global iter:   8020/  8460 | loss: 0.0327 | ds_loss: 0.0000 | lr: 3.4291e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8021/  8460 | global iter:   8021/  8460 | loss: 0.0092 | ds_loss: 0.0000 | lr: 3.4140e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8022/  8460 | global iter:   8022/  8460 | loss: 0.0483 | ds_loss: 0.0000 | lr: 3.3989e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8023/  8460 | global iter:   8023/  8460 | loss: 0.0650 | ds_loss: 0.0000 | lr: 3.3839e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8024/  8460 | global iter:   8024/  8460 | loss: 0.0154 | ds_loss: 0.0000 | lr: 3.3689e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8024/  8460 | global iter:   8024/  8460 | loss: 0.0345 | ds_loss: 0.0000 | lr: 3.3689e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8025/  8460 | global iter:   8025/  8460 | loss: 0.0687 | ds_loss: 0.0000 | lr: 3.3540e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8026/  8460 | global iter:   8026/  8460 | loss: 0.0186 | ds_loss: 0.0000 | lr: 3.3391e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8027/  8460 | global iter:   8027/  8460 | loss: 0.0374 | ds_loss: 0.0000 | lr: 3.3242e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8028/  8460 | global iter:   8028/  8460 | loss: 0.0264 | ds_loss: 0.0000 | lr: 3.3094e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8028/  8460 | global iter:   8028/  8460 | loss: 0.0378 | ds_loss: 0.0000 | lr: 3.3094e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8029/  8460 | global iter:   8029/  8460 | loss: 0.0048 | ds_loss: 0.0000 | lr: 3.2945e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8030/  8460 | global iter:   8030/  8460 | loss: 0.0220 | ds_loss: 0.0000 | lr: 3.2798e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8031/  8460 | global iter:   8031/  8460 | loss: 0.0150 | ds_loss: 0.0000 | lr: 3.2650e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8032/  8460 | global iter:   8032/  8460 | loss: 0.0108 | ds_loss: 0.0000 | lr: 3.2503e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8032/  8460 | global iter:   8032/  8460 | loss: 0.0132 | ds_loss: 0.0000 | lr: 3.2503e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8033/  8460 | global iter:   8033/  8460 | loss: 0.0405 | ds_loss: 0.0000 | lr: 3.2357e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8034/  8460 | global iter:   8034/  8460 | loss: 0.0300 | ds_loss: 0.0000 | lr: 3.2210e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8035/  8460 | global iter:   8035/  8460 | loss: 0.0239 | ds_loss: 0.0000 | lr: 3.2064e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8036/  8460 | global iter:   8036/  8460 | loss: 0.0136 | ds_loss: 0.0000 | lr: 3.1918e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8036/  8460 | global iter:   8036/  8460 | loss: 0.0270 | ds_loss: 0.0000 | lr: 3.1918e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8037/  8460 | global iter:   8037/  8460 | loss: 0.0171 | ds_loss: 0.0000 | lr: 3.1773e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   8038/  8460 | global iter:   8038/  8460 | loss: 0.0477 | ds_loss: 0.0000 | lr: 3.1628e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   8039/  8460 | global iter:   8039/  8460 | loss: 0.0346 | ds_loss: 0.0000 | lr: 3.1483e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8040/  8460 | global iter:   8040/  8460 | loss: 0.0151 | ds_loss: 0.0000 | lr: 3.1339e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8040/  8460 | global iter:   8040/  8460 | loss: 0.0286 | ds_loss: 0.0000 | lr: 3.1339e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8041/  8460 | global iter:   8041/  8460 | loss: 0.0170 | ds_loss: 0.0000 | lr: 3.1195e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8042/  8460 | global iter:   8042/  8460 | loss: 0.0442 | ds_loss: 0.0000 | lr: 3.1051e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8043/  8460 | global iter:   8043/  8460 | loss: 0.0482 | ds_loss: 0.0000 | lr: 3.0908e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8044/  8460 | global iter:   8044/  8460 | loss: 0.0047 | ds_loss: 0.0000 | lr: 3.0765e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8044/  8460 | global iter:   8044/  8460 | loss: 0.0285 | ds_loss: 0.0000 | lr: 3.0765e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8045/  8460 | global iter:   8045/  8460 | loss: 0.0550 | ds_loss: 0.0000 | lr: 3.0622e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8046/  8460 | global iter:   8046/  8460 | loss: 0.0328 | ds_loss: 0.0000 | lr: 3.0480e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8047/  8460 | global iter:   8047/  8460 | loss: 0.0265 | ds_loss: 0.0000 | lr: 3.0338e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8048/  8460 | global iter:   8048/  8460 | loss: 0.0400 | ds_loss: 0.0000 | lr: 3.0196e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8048/  8460 | global iter:   8048/  8460 | loss: 0.0386 | ds_loss: 0.0000 | lr: 3.0196e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8049/  8460 | global iter:   8049/  8460 | loss: 0.0413 | ds_loss: 0.0000 | lr: 3.0055e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   8050/  8460 | global iter:   8050/  8460 | loss: 0.0371 | ds_loss: 0.0000 | lr: 2.9914e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8051/  8460 | global iter:   8051/  8460 | loss: 0.0188 | ds_loss: 0.0000 | lr: 2.9774e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8052/  8460 | global iter:   8052/  8460 | loss: 0.0202 | ds_loss: 0.0000 | lr: 2.9633e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8052/  8460 | global iter:   8052/  8460 | loss: 0.0293 | ds_loss: 0.0000 | lr: 2.9633e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8053/  8460 | global iter:   8053/  8460 | loss: 0.0473 | ds_loss: 0.0000 | lr: 2.9493e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8054/  8460 | global iter:   8054/  8460 | loss: 0.0383 | ds_loss: 0.0000 | lr: 2.9354e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8055/  8460 | global iter:   8055/  8460 | loss: 0.0453 | ds_loss: 0.0000 | lr: 2.9215e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8056/  8460 | global iter:   8056/  8460 | loss: 0.0947 | ds_loss: 0.0000 | lr: 2.9076e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8056/  8460 | global iter:   8056/  8460 | loss: 0.0564 | ds_loss: 0.0000 | lr: 2.9076e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8057/  8460 | global iter:   8057/  8460 | loss: 0.0575 | ds_loss: 0.0000 | lr: 2.8937e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8058/  8460 | global iter:   8058/  8460 | loss: 0.1292 | ds_loss: 0.0000 | lr: 2.8799e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8059/  8460 | global iter:   8059/  8460 | loss: 0.0099 | ds_loss: 0.0000 | lr: 2.8661e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   8060/  8460 | global iter:   8060/  8460 | loss: 0.1480 | ds_loss: 0.0000 | lr: 2.8523e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8060/  8460 | global iter:   8060/  8460 | loss: 0.0861 | ds_loss: 0.0000 | lr: 2.8523e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8061/  8460 | global iter:   8061/  8460 | loss: 0.0011 | ds_loss: 0.0000 | lr: 2.8386e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8062/  8460 | global iter:   8062/  8460 | loss: 0.0187 | ds_loss: 0.0000 | lr: 2.8249e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8063/  8460 | global iter:   8063/  8460 | loss: 0.0323 | ds_loss: 0.0000 | lr: 2.8113e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8064/  8460 | global iter:   8064/  8460 | loss: 0.0139 | ds_loss: 0.0000 | lr: 2.7977e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8064/  8460 | global iter:   8064/  8460 | loss: 0.0165 | ds_loss: 0.0000 | lr: 2.7977e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8065/  8460 | global iter:   8065/  8460 | loss: 0.0037 | ds_loss: 0.0000 | lr: 2.7841e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8066/  8460 | global iter:   8066/  8460 | loss: 0.1808 | ds_loss: 0.0000 | lr: 2.7705e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8067/  8460 | global iter:   8067/  8460 | loss: 0.1391 | ds_loss: 0.0000 | lr: 2.7570e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8068/  8460 | global iter:   8068/  8460 | loss: 0.0392 | ds_loss: 0.0000 | lr: 2.7435e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8068/  8460 | global iter:   8068/  8460 | loss: 0.0907 | ds_loss: 0.0000 | lr: 2.7435e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8069/  8460 | global iter:   8069/  8460 | loss: 0.0501 | ds_loss: 0.0000 | lr: 2.7301e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8070/  8460 | global iter:   8070/  8460 | loss: 0.1450 | ds_loss: 0.0000 | lr: 2.7167e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8071/  8460 | global iter:   8071/  8460 | loss: 0.0329 | ds_loss: 0.0000 | lr: 2.7033e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8072/  8460 | global iter:   8072/  8460 | loss: 0.0028 | ds_loss: 0.0000 | lr: 2.6900e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8072/  8460 | global iter:   8072/  8460 | loss: 0.0577 | ds_loss: 0.0000 | lr: 2.6900e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8073/  8460 | global iter:   8073/  8460 | loss: 0.0254 | ds_loss: 0.0000 | lr: 2.6767e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8074/  8460 | global iter:   8074/  8460 | loss: 0.0260 | ds_loss: 0.0000 | lr: 2.6634e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8075/  8460 | global iter:   8075/  8460 | loss: 0.0153 | ds_loss: 0.0000 | lr: 2.6501e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8076/  8460 | global iter:   8076/  8460 | loss: 0.0242 | ds_loss: 0.0000 | lr: 2.6369e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8076/  8460 | global iter:   8076/  8460 | loss: 0.0228 | ds_loss: 0.0000 | lr: 2.6369e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8077/  8460 | global iter:   8077/  8460 | loss: 0.0804 | ds_loss: 0.0000 | lr: 2.6238e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8078/  8460 | global iter:   8078/  8460 | loss: 0.1556 | ds_loss: 0.0000 | lr: 2.6106e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8079/  8460 | global iter:   8079/  8460 | loss: 0.0536 | ds_loss: 0.0000 | lr: 2.5975e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8080/  8460 | global iter:   8080/  8460 | loss: 0.0597 | ds_loss: 0.0000 | lr: 2.5844e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8080/  8460 | global iter:   8080/  8460 | loss: 0.0873 | ds_loss: 0.0000 | lr: 2.5844e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8081/  8460 | global iter:   8081/  8460 | loss: 0.0684 | ds_loss: 0.0000 | lr: 2.5714e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8082/  8460 | global iter:   8082/  8460 | loss: 0.0183 | ds_loss: 0.0000 | lr: 2.5584e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8083/  8460 | global iter:   8083/  8460 | loss: 0.0094 | ds_loss: 0.0000 | lr: 2.5454e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8084/  8460 | global iter:   8084/  8460 | loss: 0.0164 | ds_loss: 0.0000 | lr: 2.5325e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8084/  8460 | global iter:   8084/  8460 | loss: 0.0281 | ds_loss: 0.0000 | lr: 2.5325e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8085/  8460 | global iter:   8085/  8460 | loss: 0.0272 | ds_loss: 0.0000 | lr: 2.5196e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8086/  8460 | global iter:   8086/  8460 | loss: 0.0095 | ds_loss: 0.0000 | lr: 2.5067e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8087/  8460 | global iter:   8087/  8460 | loss: 0.0924 | ds_loss: 0.0000 | lr: 2.4939e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   8088/  8460 | global iter:   8088/  8460 | loss: 0.0106 | ds_loss: 0.0000 | lr: 2.4811e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8088/  8460 | global iter:   8088/  8460 | loss: 0.0349 | ds_loss: 0.0000 | lr: 2.4811e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8089/  8460 | global iter:   8089/  8460 | loss: 0.1462 | ds_loss: 0.0000 | lr: 2.4683e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8090/  8460 | global iter:   8090/  8460 | loss: 0.1360 | ds_loss: 0.0000 | lr: 2.4556e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   8091/  8460 | global iter:   8091/  8460 | loss: 0.0379 | ds_loss: 0.0000 | lr: 2.4429e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   8092/  8460 | global iter:   8092/  8460 | loss: 0.0267 | ds_loss: 0.0000 | lr: 2.4302e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8092/  8460 | global iter:   8092/  8460 | loss: 0.0867 | ds_loss: 0.0000 | lr: 2.4302e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8093/  8460 | global iter:   8093/  8460 | loss: 0.0665 | ds_loss: 0.0000 | lr: 2.4176e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   8094/  8460 | global iter:   8094/  8460 | loss: 0.0409 | ds_loss: 0.0000 | lr: 2.4050e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8095/  8460 | global iter:   8095/  8460 | loss: 0.0087 | ds_loss: 0.0000 | lr: 2.3925e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8096/  8460 | global iter:   8096/  8460 | loss: 0.0204 | ds_loss: 0.0000 | lr: 2.3799e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8096/  8460 | global iter:   8096/  8460 | loss: 0.0341 | ds_loss: 0.0000 | lr: 2.3799e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8097/  8460 | global iter:   8097/  8460 | loss: 0.0017 | ds_loss: 0.0000 | lr: 2.3674e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8098/  8460 | global iter:   8098/  8460 | loss: 0.1122 | ds_loss: 0.0000 | lr: 2.3550e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8099/  8460 | global iter:   8099/  8460 | loss: 0.0142 | ds_loss: 0.0000 | lr: 2.3426e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8100/  8460 | global iter:   8100/  8460 | loss: 0.0136 | ds_loss: 0.0000 | lr: 2.3302e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8100/  8460 | global iter:   8100/  8460 | loss: 0.0354 | ds_loss: 0.0000 | lr: 2.3302e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8101/  8460 | global iter:   8101/  8460 | loss: 0.0144 | ds_loss: 0.0000 | lr: 2.3178e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8102/  8460 | global iter:   8102/  8460 | loss: 0.0084 | ds_loss: 0.0000 | lr: 2.3055e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8103/  8460 | global iter:   8103/  8460 | loss: 0.0116 | ds_loss: 0.0000 | lr: 2.2932e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8104/  8460 | global iter:   8104/  8460 | loss: 0.0078 | ds_loss: 0.0000 | lr: 2.2810e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8104/  8460 | global iter:   8104/  8460 | loss: 0.0105 | ds_loss: 0.0000 | lr: 2.2810e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8105/  8460 | global iter:   8105/  8460 | loss: 0.0070 | ds_loss: 0.0000 | lr: 2.2688e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8106/  8460 | global iter:   8106/  8460 | loss: 0.0150 | ds_loss: 0.0000 | lr: 2.2566e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   8107/  8460 | global iter:   8107/  8460 | loss: 0.0250 | ds_loss: 0.0000 | lr: 2.2444e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8108/  8460 | global iter:   8108/  8460 | loss: 0.0483 | ds_loss: 0.0000 | lr: 2.2323e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8108/  8460 | global iter:   8108/  8460 | loss: 0.0238 | ds_loss: 0.0000 | lr: 2.2323e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8109/  8460 | global iter:   8109/  8460 | loss: 0.0472 | ds_loss: 0.0000 | lr: 2.2202e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8110/  8460 | global iter:   8110/  8460 | loss: 0.0898 | ds_loss: 0.0000 | lr: 2.2082e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8111/  8460 | global iter:   8111/  8460 | loss: 0.0548 | ds_loss: 0.0000 | lr: 2.1962e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8112/  8460 | global iter:   8112/  8460 | loss: 0.1728 | ds_loss: 0.0000 | lr: 2.1842e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8112/  8460 | global iter:   8112/  8460 | loss: 0.0912 | ds_loss: 0.0000 | lr: 2.1842e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8113/  8460 | global iter:   8113/  8460 | loss: 0.0210 | ds_loss: 0.0000 | lr: 2.1722e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8114/  8460 | global iter:   8114/  8460 | loss: 0.0710 | ds_loss: 0.0000 | lr: 2.1603e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8115/  8460 | global iter:   8115/  8460 | loss: 0.0119 | ds_loss: 0.0000 | lr: 2.1485e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8116/  8460 | global iter:   8116/  8460 | loss: 0.0170 | ds_loss: 0.0000 | lr: 2.1366e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8116/  8460 | global iter:   8116/  8460 | loss: 0.0302 | ds_loss: 0.0000 | lr: 2.1366e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8117/  8460 | global iter:   8117/  8460 | loss: 0.0955 | ds_loss: 0.0000 | lr: 2.1248e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8118/  8460 | global iter:   8118/  8460 | loss: 0.0090 | ds_loss: 0.0000 | lr: 2.1130e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8119/  8460 | global iter:   8119/  8460 | loss: 0.0765 | ds_loss: 0.0000 | lr: 2.1013e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8120/  8460 | global iter:   8120/  8460 | loss: 0.0283 | ds_loss: 0.0000 | lr: 2.0896e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8120/  8460 | global iter:   8120/  8460 | loss: 0.0523 | ds_loss: 0.0000 | lr: 2.0896e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8121/  8460 | global iter:   8121/  8460 | loss: 0.1525 | ds_loss: 0.0000 | lr: 2.0779e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8122/  8460 | global iter:   8122/  8460 | loss: 0.0119 | ds_loss: 0.0000 | lr: 2.0663e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8123/  8460 | global iter:   8123/  8460 | loss: 0.1351 | ds_loss: 0.0000 | lr: 2.0547e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8124/  8460 | global iter:   8124/  8460 | loss: 0.0287 | ds_loss: 0.0000 | lr: 2.0431e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8124/  8460 | global iter:   8124/  8460 | loss: 0.0821 | ds_loss: 0.0000 | lr: 2.0431e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8125/  8460 | global iter:   8125/  8460 | loss: 0.0199 | ds_loss: 0.0000 | lr: 2.0316e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8126/  8460 | global iter:   8126/  8460 | loss: 0.0756 | ds_loss: 0.0000 | lr: 2.0201e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8127/  8460 | global iter:   8127/  8460 | loss: 0.0159 | ds_loss: 0.0000 | lr: 2.0086e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8128/  8460 | global iter:   8128/  8460 | loss: 0.0042 | ds_loss: 0.0000 | lr: 1.9972e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8128/  8460 | global iter:   8128/  8460 | loss: 0.0289 | ds_loss: 0.0000 | lr: 1.9972e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8129/  8460 | global iter:   8129/  8460 | loss: 0.0089 | ds_loss: 0.0000 | lr: 1.9858e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8130/  8460 | global iter:   8130/  8460 | loss: 0.0259 | ds_loss: 0.0000 | lr: 1.9744e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8131/  8460 | global iter:   8131/  8460 | loss: 0.0437 | ds_loss: 0.0000 | lr: 1.9631e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8132/  8460 | global iter:   8132/  8460 | loss: 0.0202 | ds_loss: 0.0000 | lr: 1.9518e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8132/  8460 | global iter:   8132/  8460 | loss: 0.0247 | ds_loss: 0.0000 | lr: 1.9518e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8133/  8460 | global iter:   8133/  8460 | loss: 0.0428 | ds_loss: 0.0000 | lr: 1.9405e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8134/  8460 | global iter:   8134/  8460 | loss: 0.0089 | ds_loss: 0.0000 | lr: 1.9293e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8135/  8460 | global iter:   8135/  8460 | loss: 0.0484 | ds_loss: 0.0000 | lr: 1.9181e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8136/  8460 | global iter:   8136/  8460 | loss: 0.0478 | ds_loss: 0.0000 | lr: 1.9070e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8136/  8460 | global iter:   8136/  8460 | loss: 0.0370 | ds_loss: 0.0000 | lr: 1.9070e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8137/  8460 | global iter:   8137/  8460 | loss: 0.0352 | ds_loss: 0.0000 | lr: 1.8958e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8138/  8460 | global iter:   8138/  8460 | loss: 0.0532 | ds_loss: 0.0000 | lr: 1.8847e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8139/  8460 | global iter:   8139/  8460 | loss: 0.0185 | ds_loss: 0.0000 | lr: 1.8737e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8140/  8460 | global iter:   8140/  8460 | loss: 0.0938 | ds_loss: 0.0000 | lr: 1.8627e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8140/  8460 | global iter:   8140/  8460 | loss: 0.0502 | ds_loss: 0.0000 | lr: 1.8627e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8141/  8460 | global iter:   8141/  8460 | loss: 0.0130 | ds_loss: 0.0000 | lr: 1.8517e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8142/  8460 | global iter:   8142/  8460 | loss: 0.0062 | ds_loss: 0.0000 | lr: 1.8407e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8143/  8460 | global iter:   8143/  8460 | loss: 0.0543 | ds_loss: 0.0000 | lr: 1.8298e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8144/  8460 | global iter:   8144/  8460 | loss: 0.0313 | ds_loss: 0.0000 | lr: 1.8189e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8144/  8460 | global iter:   8144/  8460 | loss: 0.0262 | ds_loss: 0.0000 | lr: 1.8189e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8145/  8460 | global iter:   8145/  8460 | loss: 0.0270 | ds_loss: 0.0000 | lr: 1.8081e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8146/  8460 | global iter:   8146/  8460 | loss: 0.0358 | ds_loss: 0.0000 | lr: 1.7973e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8147/  8460 | global iter:   8147/  8460 | loss: 0.0457 | ds_loss: 0.0000 | lr: 1.7865e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8148/  8460 | global iter:   8148/  8460 | loss: 0.0064 | ds_loss: 0.0000 | lr: 1.7757e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8148/  8460 | global iter:   8148/  8460 | loss: 0.0287 | ds_loss: 0.0000 | lr: 1.7757e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8149/  8460 | global iter:   8149/  8460 | loss: 0.0754 | ds_loss: 0.0000 | lr: 1.7650e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8150/  8460 | global iter:   8150/  8460 | loss: 0.0067 | ds_loss: 0.0000 | lr: 1.7543e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   8151/  8460 | global iter:   8151/  8460 | loss: 0.0023 | ds_loss: 0.0000 | lr: 1.7437e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   8152/  8460 | global iter:   8152/  8460 | loss: 0.0613 | ds_loss: 0.0000 | lr: 1.7331e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8152/  8460 | global iter:   8152/  8460 | loss: 0.0364 | ds_loss: 0.0000 | lr: 1.7331e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8153/  8460 | global iter:   8153/  8460 | loss: 0.0119 | ds_loss: 0.0000 | lr: 1.7225e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8154/  8460 | global iter:   8154/  8460 | loss: 0.0023 | ds_loss: 0.0000 | lr: 1.7120e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8155/  8460 | global iter:   8155/  8460 | loss: 0.0265 | ds_loss: 0.0000 | lr: 1.7015e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   8156/  8460 | global iter:   8156/  8460 | loss: 0.0167 | ds_loss: 0.0000 | lr: 1.6910e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8156/  8460 | global iter:   8156/  8460 | loss: 0.0144 | ds_loss: 0.0000 | lr: 1.6910e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8157/  8460 | global iter:   8157/  8460 | loss: 0.1198 | ds_loss: 0.0000 | lr: 1.6806e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8158/  8460 | global iter:   8158/  8460 | loss: 0.0278 | ds_loss: 0.0000 | lr: 1.6701e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8159/  8460 | global iter:   8159/  8460 | loss: 0.1205 | ds_loss: 0.0000 | lr: 1.6598e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8160/  8460 | global iter:   8160/  8460 | loss: 0.0115 | ds_loss: 0.0000 | lr: 1.6494e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8160/  8460 | global iter:   8160/  8460 | loss: 0.0699 | ds_loss: 0.0000 | lr: 1.6494e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8161/  8460 | global iter:   8161/  8460 | loss: 0.0233 | ds_loss: 0.0000 | lr: 1.6391e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8162/  8460 | global iter:   8162/  8460 | loss: 0.0383 | ds_loss: 0.0000 | lr: 1.6289e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8163/  8460 | global iter:   8163/  8460 | loss: 0.0090 | ds_loss: 0.0000 | lr: 1.6186e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8164/  8460 | global iter:   8164/  8460 | loss: 0.0491 | ds_loss: 0.0000 | lr: 1.6084e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8164/  8460 | global iter:   8164/  8460 | loss: 0.0299 | ds_loss: 0.0000 | lr: 1.6084e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8165/  8460 | global iter:   8165/  8460 | loss: 0.0504 | ds_loss: 0.0000 | lr: 1.5983e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8166/  8460 | global iter:   8166/  8460 | loss: 0.0016 | ds_loss: 0.0000 | lr: 1.5881e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8167/  8460 | global iter:   8167/  8460 | loss: 0.0029 | ds_loss: 0.0000 | lr: 1.5780e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8168/  8460 | global iter:   8168/  8460 | loss: 0.0082 | ds_loss: 0.0000 | lr: 1.5680e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8168/  8460 | global iter:   8168/  8460 | loss: 0.0158 | ds_loss: 0.0000 | lr: 1.5680e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8169/  8460 | global iter:   8169/  8460 | loss: 0.1990 | ds_loss: 0.0000 | lr: 1.5580e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8170/  8460 | global iter:   8170/  8460 | loss: 0.0611 | ds_loss: 0.0000 | lr: 1.5480e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8171/  8460 | global iter:   8171/  8460 | loss: 0.0102 | ds_loss: 0.0000 | lr: 1.5380e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8172/  8460 | global iter:   8172/  8460 | loss: 0.0160 | ds_loss: 0.0000 | lr: 1.5281e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8172/  8460 | global iter:   8172/  8460 | loss: 0.0716 | ds_loss: 0.0000 | lr: 1.5281e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8173/  8460 | global iter:   8173/  8460 | loss: 0.0471 | ds_loss: 0.0000 | lr: 1.5182e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8174/  8460 | global iter:   8174/  8460 | loss: 0.1430 | ds_loss: 0.0000 | lr: 1.5083e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8175/  8460 | global iter:   8175/  8460 | loss: 0.0373 | ds_loss: 0.0000 | lr: 1.4985e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8176/  8460 | global iter:   8176/  8460 | loss: 0.0039 | ds_loss: 0.0000 | lr: 1.4887e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8176/  8460 | global iter:   8176/  8460 | loss: 0.0578 | ds_loss: 0.0000 | lr: 1.4887e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8177/  8460 | global iter:   8177/  8460 | loss: 0.0500 | ds_loss: 0.0000 | lr: 1.4790e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8178/  8460 | global iter:   8178/  8460 | loss: 0.0188 | ds_loss: 0.0000 | lr: 1.4693e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8179/  8460 | global iter:   8179/  8460 | loss: 0.0240 | ds_loss: 0.0000 | lr: 1.4596e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8180/  8460 | global iter:   8180/  8460 | loss: 0.1046 | ds_loss: 0.0000 | lr: 1.4499e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8180/  8460 | global iter:   8180/  8460 | loss: 0.0493 | ds_loss: 0.0000 | lr: 1.4499e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8181/  8460 | global iter:   8181/  8460 | loss: 0.0152 | ds_loss: 0.0000 | lr: 1.4403e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8182/  8460 | global iter:   8182/  8460 | loss: 0.0402 | ds_loss: 0.0000 | lr: 1.4307e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8183/  8460 | global iter:   8183/  8460 | loss: 0.0593 | ds_loss: 0.0000 | lr: 1.4212e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8184/  8460 | global iter:   8184/  8460 | loss: 0.0400 | ds_loss: 0.0000 | lr: 1.4117e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8184/  8460 | global iter:   8184/  8460 | loss: 0.0387 | ds_loss: 0.0000 | lr: 1.4117e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8185/  8460 | global iter:   8185/  8460 | loss: 0.0229 | ds_loss: 0.0000 | lr: 1.4022e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8186/  8460 | global iter:   8186/  8460 | loss: 0.0209 | ds_loss: 0.0000 | lr: 1.3927e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8187/  8460 | global iter:   8187/  8460 | loss: 0.0226 | ds_loss: 0.0000 | lr: 1.3833e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8188/  8460 | global iter:   8188/  8460 | loss: 0.0565 | ds_loss: 0.0000 | lr: 1.3739e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8188/  8460 | global iter:   8188/  8460 | loss: 0.0307 | ds_loss: 0.0000 | lr: 1.3739e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8189/  8460 | global iter:   8189/  8460 | loss: 0.0128 | ds_loss: 0.0000 | lr: 1.3646e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8190/  8460 | global iter:   8190/  8460 | loss: 0.0387 | ds_loss: 0.0000 | lr: 1.3553e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8191/  8460 | global iter:   8191/  8460 | loss: 0.0578 | ds_loss: 0.0000 | lr: 1.3460e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8192/  8460 | global iter:   8192/  8460 | loss: 0.0506 | ds_loss: 0.0000 | lr: 1.3368e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8192/  8460 | global iter:   8192/  8460 | loss: 0.0400 | ds_loss: 0.0000 | lr: 1.3368e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8193/  8460 | global iter:   8193/  8460 | loss: 0.0213 | ds_loss: 0.0000 | lr: 1.3276e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8194/  8460 | global iter:   8194/  8460 | loss: 0.0022 | ds_loss: 0.0000 | lr: 1.3184e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8195/  8460 | global iter:   8195/  8460 | loss: 0.0157 | ds_loss: 0.0000 | lr: 1.3093e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8196/  8460 | global iter:   8196/  8460 | loss: 0.0582 | ds_loss: 0.0000 | lr: 1.3002e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8196/  8460 | global iter:   8196/  8460 | loss: 0.0243 | ds_loss: 0.0000 | lr: 1.3002e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8197/  8460 | global iter:   8197/  8460 | loss: 0.0147 | ds_loss: 0.0000 | lr: 1.2911e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8198/  8460 | global iter:   8198/  8460 | loss: 0.0524 | ds_loss: 0.0000 | lr: 1.2821e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8199/  8460 | global iter:   8199/  8460 | loss: 0.0192 | ds_loss: 0.0000 | lr: 1.2731e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8200/  8460 | global iter:   8200/  8460 | loss: 0.0221 | ds_loss: 0.0000 | lr: 1.2641e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8200/  8460 | global iter:   8200/  8460 | loss: 0.0271 | ds_loss: 0.0000 | lr: 1.2641e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8201/  8460 | global iter:   8201/  8460 | loss: 0.1063 | ds_loss: 0.0000 | lr: 1.2552e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   8202/  8460 | global iter:   8202/  8460 | loss: 0.0500 | ds_loss: 0.0000 | lr: 1.2463e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   8203/  8460 | global iter:   8203/  8460 | loss: 0.0130 | ds_loss: 0.0000 | lr: 1.2374e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8204/  8460 | global iter:   8204/  8460 | loss: 0.3151 | ds_loss: 0.0000 | lr: 1.2286e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8204/  8460 | global iter:   8204/  8460 | loss: 0.1211 | ds_loss: 0.0000 | lr: 1.2286e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8205/  8460 | global iter:   8205/  8460 | loss: 0.0531 | ds_loss: 0.0000 | lr: 1.2198e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8206/  8460 | global iter:   8206/  8460 | loss: 0.0500 | ds_loss: 0.0000 | lr: 1.2110e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8207/  8460 | global iter:   8207/  8460 | loss: 0.0486 | ds_loss: 0.0000 | lr: 1.2023e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8208/  8460 | global iter:   8208/  8460 | loss: 0.0180 | ds_loss: 0.0000 | lr: 1.1936e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8208/  8460 | global iter:   8208/  8460 | loss: 0.0424 | ds_loss: 0.0000 | lr: 1.1936e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8209/  8460 | global iter:   8209/  8460 | loss: 0.1241 | ds_loss: 0.0000 | lr: 1.1850e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8210/  8460 | global iter:   8210/  8460 | loss: 0.0041 | ds_loss: 0.0000 | lr: 1.1763e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8211/  8460 | global iter:   8211/  8460 | loss: 0.0642 | ds_loss: 0.0000 | lr: 1.1678e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8212/  8460 | global iter:   8212/  8460 | loss: 0.0056 | ds_loss: 0.0000 | lr: 1.1592e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8212/  8460 | global iter:   8212/  8460 | loss: 0.0495 | ds_loss: 0.0000 | lr: 1.1592e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8213/  8460 | global iter:   8213/  8460 | loss: 0.0116 | ds_loss: 0.0000 | lr: 1.1507e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8214/  8460 | global iter:   8214/  8460 | loss: 0.0215 | ds_loss: 0.0000 | lr: 1.1422e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8215/  8460 | global iter:   8215/  8460 | loss: 0.0053 | ds_loss: 0.0000 | lr: 1.1337e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8216/  8460 | global iter:   8216/  8460 | loss: 0.0193 | ds_loss: 0.0000 | lr: 1.1253e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8216/  8460 | global iter:   8216/  8460 | loss: 0.0144 | ds_loss: 0.0000 | lr: 1.1253e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8217/  8460 | global iter:   8217/  8460 | loss: 0.0496 | ds_loss: 0.0000 | lr: 1.1170e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8218/  8460 | global iter:   8218/  8460 | loss: 0.0216 | ds_loss: 0.0000 | lr: 1.1086e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8219/  8460 | global iter:   8219/  8460 | loss: 0.0499 | ds_loss: 0.0000 | lr: 1.1003e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8220/  8460 | global iter:   8220/  8460 | loss: 0.0502 | ds_loss: 0.0000 | lr: 1.0920e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8220/  8460 | global iter:   8220/  8460 | loss: 0.0428 | ds_loss: 0.0000 | lr: 1.0920e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8221/  8460 | global iter:   8221/  8460 | loss: 0.0556 | ds_loss: 0.0000 | lr: 1.0838e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8222/  8460 | global iter:   8222/  8460 | loss: 0.0555 | ds_loss: 0.0000 | lr: 1.0756e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8223/  8460 | global iter:   8223/  8460 | loss: 0.0549 | ds_loss: 0.0000 | lr: 1.0674e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8224/  8460 | global iter:   8224/  8460 | loss: 0.0451 | ds_loss: 0.0000 | lr: 1.0592e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8224/  8460 | global iter:   8224/  8460 | loss: 0.0528 | ds_loss: 0.0000 | lr: 1.0592e-06 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8225/  8460 | global iter:   8225/  8460 | loss: 0.0023 | ds_loss: 0.0000 | lr: 1.0511e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8226/  8460 | global iter:   8226/  8460 | loss: 0.0779 | ds_loss: 0.0000 | lr: 1.0431e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8227/  8460 | global iter:   8227/  8460 | loss: 0.0474 | ds_loss: 0.0000 | lr: 1.0350e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8228/  8460 | global iter:   8228/  8460 | loss: 0.0075 | ds_loss: 0.0000 | lr: 1.0270e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8228/  8460 | global iter:   8228/  8460 | loss: 0.0338 | ds_loss: 0.0000 | lr: 1.0270e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8229/  8460 | global iter:   8229/  8460 | loss: 0.0650 | ds_loss: 0.0000 | lr: 1.0191e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8230/  8460 | global iter:   8230/  8460 | loss: 0.0238 | ds_loss: 0.0000 | lr: 1.0111e-06 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8231/  8460 | global iter:   8231/  8460 | loss: 0.1374 | ds_loss: 0.0000 | lr: 1.0032e-06 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8232/  8460 | global iter:   8232/  8460 | loss: 0.0051 | ds_loss: 0.0000 | lr: 9.9535e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8232/  8460 | global iter:   8232/  8460 | loss: 0.0578 | ds_loss: 0.0000 | lr: 9.9535e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8233/  8460 | global iter:   8233/  8460 | loss: 0.0080 | ds_loss: 0.0000 | lr: 9.8752e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8234/  8460 | global iter:   8234/  8460 | loss: 0.1580 | ds_loss: 0.0000 | lr: 9.7972e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8235/  8460 | global iter:   8235/  8460 | loss: 0.0242 | ds_loss: 0.0000 | lr: 9.7196e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8236/  8460 | global iter:   8236/  8460 | loss: 0.0790 | ds_loss: 0.0000 | lr: 9.6423e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8236/  8460 | global iter:   8236/  8460 | loss: 0.0673 | ds_loss: 0.0000 | lr: 9.6423e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8237/  8460 | global iter:   8237/  8460 | loss: 0.0158 | ds_loss: 0.0000 | lr: 9.5653e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8238/  8460 | global iter:   8238/  8460 | loss: 0.0132 | ds_loss: 0.0000 | lr: 9.4887e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8239/  8460 | global iter:   8239/  8460 | loss: 0.0430 | ds_loss: 0.0000 | lr: 9.4125e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8240/  8460 | global iter:   8240/  8460 | loss: 0.1540 | ds_loss: 0.0000 | lr: 9.3365e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8240/  8460 | global iter:   8240/  8460 | loss: 0.0565 | ds_loss: 0.0000 | lr: 9.3365e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8241/  8460 | global iter:   8241/  8460 | loss: 0.0111 | ds_loss: 0.0000 | lr: 9.2610e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8242/  8460 | global iter:   8242/  8460 | loss: 0.0453 | ds_loss: 0.0000 | lr: 9.1857e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8243/  8460 | global iter:   8243/  8460 | loss: 0.1221 | ds_loss: 0.0000 | lr: 9.1109e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8244/  8460 | global iter:   8244/  8460 | loss: 0.0446 | ds_loss: 0.0000 | lr: 9.0363e-07 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8244/  8460 | global iter:   8244/  8460 | loss: 0.0558 | ds_loss: 0.0000 | lr: 9.0363e-07 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8245/  8460 | global iter:   8245/  8460 | loss: 0.0193 | ds_loss: 0.0000 | lr: 8.9621e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8246/  8460 | global iter:   8246/  8460 | loss: 0.0345 | ds_loss: 0.0000 | lr: 8.8883e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8247/  8460 | global iter:   8247/  8460 | loss: 0.0042 | ds_loss: 0.0000 | lr: 8.8147e-07 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   8248/  8460 | global iter:   8248/  8460 | loss: 0.0212 | ds_loss: 0.0000 | lr: 8.7416e-07 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8248/  8460 | global iter:   8248/  8460 | loss: 0.0198 | ds_loss: 0.0000 | lr: 8.7416e-07 | scale:     1.0000 | micro time: 0.429 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8249/  8460 | global iter:   8249/  8460 | loss: 0.1664 | ds_loss: 0.0000 | lr: 8.6688e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8250/  8460 | global iter:   8250/  8460 | loss: 0.0113 | ds_loss: 0.0000 | lr: 8.5963e-07 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   8251/  8460 | global iter:   8251/  8460 | loss: 0.0702 | ds_loss: 0.0000 | lr: 8.5241e-07 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   8252/  8460 | global iter:   8252/  8460 | loss: 0.0067 | ds_loss: 0.0000 | lr: 8.4523e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8252/  8460 | global iter:   8252/  8460 | loss: 0.0636 | ds_loss: 0.0000 | lr: 8.4523e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8253/  8460 | global iter:   8253/  8460 | loss: 0.0393 | ds_loss: 0.0000 | lr: 8.3809e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8254/  8460 | global iter:   8254/  8460 | loss: 0.1067 | ds_loss: 0.0000 | lr: 8.3098e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8255/  8460 | global iter:   8255/  8460 | loss: 0.0157 | ds_loss: 0.0000 | lr: 8.2390e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8256/  8460 | global iter:   8256/  8460 | loss: 0.0029 | ds_loss: 0.0000 | lr: 8.1686e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8256/  8460 | global iter:   8256/  8460 | loss: 0.0411 | ds_loss: 0.0000 | lr: 8.1686e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8257/  8460 | global iter:   8257/  8460 | loss: 0.0369 | ds_loss: 0.0000 | lr: 8.0985e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8258/  8460 | global iter:   8258/  8460 | loss: 0.0891 | ds_loss: 0.0000 | lr: 8.0288e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8259/  8460 | global iter:   8259/  8460 | loss: 0.0047 | ds_loss: 0.0000 | lr: 7.9594e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8260/  8460 | global iter:   8260/  8460 | loss: 0.0009 | ds_loss: 0.0000 | lr: 7.8904e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8260/  8460 | global iter:   8260/  8460 | loss: 0.0329 | ds_loss: 0.0000 | lr: 7.8904e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8261/  8460 | global iter:   8261/  8460 | loss: 0.0239 | ds_loss: 0.0000 | lr: 7.8217e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8262/  8460 | global iter:   8262/  8460 | loss: 0.0853 | ds_loss: 0.0000 | lr: 7.7533e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8263/  8460 | global iter:   8263/  8460 | loss: 0.0678 | ds_loss: 0.0000 | lr: 7.6853e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8264/  8460 | global iter:   8264/  8460 | loss: 0.0097 | ds_loss: 0.0000 | lr: 7.6176e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8264/  8460 | global iter:   8264/  8460 | loss: 0.0467 | ds_loss: 0.0000 | lr: 7.6176e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8265/  8460 | global iter:   8265/  8460 | loss: 0.0307 | ds_loss: 0.0000 | lr: 7.5503e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8266/  8460 | global iter:   8266/  8460 | loss: 0.1213 | ds_loss: 0.0000 | lr: 7.4833e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8267/  8460 | global iter:   8267/  8460 | loss: 0.0342 | ds_loss: 0.0000 | lr: 7.4167e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8268/  8460 | global iter:   8268/  8460 | loss: 0.0815 | ds_loss: 0.0000 | lr: 7.3504e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8268/  8460 | global iter:   8268/  8460 | loss: 0.0669 | ds_loss: 0.0000 | lr: 7.3504e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8269/  8460 | global iter:   8269/  8460 | loss: 0.0557 | ds_loss: 0.0000 | lr: 7.2844e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8270/  8460 | global iter:   8270/  8460 | loss: 0.0465 | ds_loss: 0.0000 | lr: 7.2188e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8271/  8460 | global iter:   8271/  8460 | loss: 0.1205 | ds_loss: 0.0000 | lr: 7.1536e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8272/  8460 | global iter:   8272/  8460 | loss: 0.0166 | ds_loss: 0.0000 | lr: 7.0887e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8272/  8460 | global iter:   8272/  8460 | loss: 0.0598 | ds_loss: 0.0000 | lr: 7.0887e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8273/  8460 | global iter:   8273/  8460 | loss: 0.0081 | ds_loss: 0.0000 | lr: 7.0241e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8274/  8460 | global iter:   8274/  8460 | loss: 0.0539 | ds_loss: 0.0000 | lr: 6.9599e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8275/  8460 | global iter:   8275/  8460 | loss: 0.1368 | ds_loss: 0.0000 | lr: 6.8960e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8276/  8460 | global iter:   8276/  8460 | loss: 0.0354 | ds_loss: 0.0000 | lr: 6.8324e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8276/  8460 | global iter:   8276/  8460 | loss: 0.0586 | ds_loss: 0.0000 | lr: 6.8324e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8277/  8460 | global iter:   8277/  8460 | loss: 0.1291 | ds_loss: 0.0000 | lr: 6.7692e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8278/  8460 | global iter:   8278/  8460 | loss: 0.0187 | ds_loss: 0.0000 | lr: 6.7064e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8279/  8460 | global iter:   8279/  8460 | loss: 0.0825 | ds_loss: 0.0000 | lr: 6.6439e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8280/  8460 | global iter:   8280/  8460 | loss: 0.0258 | ds_loss: 0.0000 | lr: 6.5817e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8280/  8460 | global iter:   8280/  8460 | loss: 0.0641 | ds_loss: 0.0000 | lr: 6.5817e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8281/  8460 | global iter:   8281/  8460 | loss: 0.1669 | ds_loss: 0.0000 | lr: 6.5199e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8282/  8460 | global iter:   8282/  8460 | loss: 0.0494 | ds_loss: 0.0000 | lr: 6.4584e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8283/  8460 | global iter:   8283/  8460 | loss: 0.0948 | ds_loss: 0.0000 | lr: 6.3972e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8284/  8460 | global iter:   8284/  8460 | loss: 0.0033 | ds_loss: 0.0000 | lr: 6.3365e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8284/  8460 | global iter:   8284/  8460 | loss: 0.0786 | ds_loss: 0.0000 | lr: 6.3365e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8285/  8460 | global iter:   8285/  8460 | loss: 0.0098 | ds_loss: 0.0000 | lr: 6.2760e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8286/  8460 | global iter:   8286/  8460 | loss: 0.0528 | ds_loss: 0.0000 | lr: 6.2159e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8287/  8460 | global iter:   8287/  8460 | loss: 0.0245 | ds_loss: 0.0000 | lr: 6.1561e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8288/  8460 | global iter:   8288/  8460 | loss: 0.0372 | ds_loss: 0.0000 | lr: 6.0967e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8288/  8460 | global iter:   8288/  8460 | loss: 0.0311 | ds_loss: 0.0000 | lr: 6.0967e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8289/  8460 | global iter:   8289/  8460 | loss: 0.0379 | ds_loss: 0.0000 | lr: 6.0377e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8290/  8460 | global iter:   8290/  8460 | loss: 0.0111 | ds_loss: 0.0000 | lr: 5.9789e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8291/  8460 | global iter:   8291/  8460 | loss: 0.0925 | ds_loss: 0.0000 | lr: 5.9205e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8292/  8460 | global iter:   8292/  8460 | loss: 0.0481 | ds_loss: 0.0000 | lr: 5.8625e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8292/  8460 | global iter:   8292/  8460 | loss: 0.0474 | ds_loss: 0.0000 | lr: 5.8625e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8293/  8460 | global iter:   8293/  8460 | loss: 0.0241 | ds_loss: 0.0000 | lr: 5.8048e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8294/  8460 | global iter:   8294/  8460 | loss: 0.0321 | ds_loss: 0.0000 | lr: 5.7475e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8295/  8460 | global iter:   8295/  8460 | loss: 0.0466 | ds_loss: 0.0000 | lr: 5.6904e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8296/  8460 | global iter:   8296/  8460 | loss: 0.0215 | ds_loss: 0.0000 | lr: 5.6338e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8296/  8460 | global iter:   8296/  8460 | loss: 0.0311 | ds_loss: 0.0000 | lr: 5.6338e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8297/  8460 | global iter:   8297/  8460 | loss: 0.0379 | ds_loss: 0.0000 | lr: 5.5775e-07 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   8298/  8460 | global iter:   8298/  8460 | loss: 0.0065 | ds_loss: 0.0000 | lr: 5.5215e-07 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   8299/  8460 | global iter:   8299/  8460 | loss: 0.0906 | ds_loss: 0.0000 | lr: 5.4659e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8300/  8460 | global iter:   8300/  8460 | loss: 0.0271 | ds_loss: 0.0000 | lr: 5.4106e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8300/  8460 | global iter:   8300/  8460 | loss: 0.0405 | ds_loss: 0.0000 | lr: 5.4106e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8301/  8460 | global iter:   8301/  8460 | loss: 0.0234 | ds_loss: 0.0000 | lr: 5.3556e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8302/  8460 | global iter:   8302/  8460 | loss: 0.0104 | ds_loss: 0.0000 | lr: 5.3010e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8303/  8460 | global iter:   8303/  8460 | loss: 0.0692 | ds_loss: 0.0000 | lr: 5.2468e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8304/  8460 | global iter:   8304/  8460 | loss: 0.0305 | ds_loss: 0.0000 | lr: 5.1929e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8304/  8460 | global iter:   8304/  8460 | loss: 0.0334 | ds_loss: 0.0000 | lr: 5.1929e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8305/  8460 | global iter:   8305/  8460 | loss: 0.0989 | ds_loss: 0.0000 | lr: 5.1393e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8306/  8460 | global iter:   8306/  8460 | loss: 0.0167 | ds_loss: 0.0000 | lr: 5.0861e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8307/  8460 | global iter:   8307/  8460 | loss: 0.0133 | ds_loss: 0.0000 | lr: 5.0332e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8308/  8460 | global iter:   8308/  8460 | loss: 0.0021 | ds_loss: 0.0000 | lr: 4.9807e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8308/  8460 | global iter:   8308/  8460 | loss: 0.0328 | ds_loss: 0.0000 | lr: 4.9807e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8309/  8460 | global iter:   8309/  8460 | loss: 0.0253 | ds_loss: 0.0000 | lr: 4.9285e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8310/  8460 | global iter:   8310/  8460 | loss: 0.0256 | ds_loss: 0.0000 | lr: 4.8766e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8311/  8460 | global iter:   8311/  8460 | loss: 0.1175 | ds_loss: 0.0000 | lr: 4.8251e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8312/  8460 | global iter:   8312/  8460 | loss: 0.0122 | ds_loss: 0.0000 | lr: 4.7740e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8312/  8460 | global iter:   8312/  8460 | loss: 0.0452 | ds_loss: 0.0000 | lr: 4.7740e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8313/  8460 | global iter:   8313/  8460 | loss: 0.0199 | ds_loss: 0.0000 | lr: 4.7231e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8314/  8460 | global iter:   8314/  8460 | loss: 0.1762 | ds_loss: 0.0000 | lr: 4.6727e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8315/  8460 | global iter:   8315/  8460 | loss: 0.0255 | ds_loss: 0.0000 | lr: 4.6225e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8316/  8460 | global iter:   8316/  8460 | loss: 0.0241 | ds_loss: 0.0000 | lr: 4.5728e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8316/  8460 | global iter:   8316/  8460 | loss: 0.0614 | ds_loss: 0.0000 | lr: 4.5728e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8317/  8460 | global iter:   8317/  8460 | loss: 0.0389 | ds_loss: 0.0000 | lr: 4.5233e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8318/  8460 | global iter:   8318/  8460 | loss: 0.0276 | ds_loss: 0.0000 | lr: 4.4742e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8319/  8460 | global iter:   8319/  8460 | loss: 0.0093 | ds_loss: 0.0000 | lr: 4.4255e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8320/  8460 | global iter:   8320/  8460 | loss: 0.0068 | ds_loss: 0.0000 | lr: 4.3771e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8320/  8460 | global iter:   8320/  8460 | loss: 0.0207 | ds_loss: 0.0000 | lr: 4.3771e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8321/  8460 | global iter:   8321/  8460 | loss: 0.0311 | ds_loss: 0.0000 | lr: 4.3290e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8322/  8460 | global iter:   8322/  8460 | loss: 0.0063 | ds_loss: 0.0000 | lr: 4.2813e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8323/  8460 | global iter:   8323/  8460 | loss: 0.2275 | ds_loss: 0.0000 | lr: 4.2339e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8324/  8460 | global iter:   8324/  8460 | loss: 0.0920 | ds_loss: 0.0000 | lr: 4.1869e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8324/  8460 | global iter:   8324/  8460 | loss: 0.0892 | ds_loss: 0.0000 | lr: 4.1869e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8325/  8460 | global iter:   8325/  8460 | loss: 0.0617 | ds_loss: 0.0000 | lr: 4.1402e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8326/  8460 | global iter:   8326/  8460 | loss: 0.0108 | ds_loss: 0.0000 | lr: 4.0939e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8327/  8460 | global iter:   8327/  8460 | loss: 0.0047 | ds_loss: 0.0000 | lr: 4.0479e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8328/  8460 | global iter:   8328/  8460 | loss: 0.0061 | ds_loss: 0.0000 | lr: 4.0022e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8328/  8460 | global iter:   8328/  8460 | loss: 0.0208 | ds_loss: 0.0000 | lr: 4.0022e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8329/  8460 | global iter:   8329/  8460 | loss: 0.0646 | ds_loss: 0.0000 | lr: 3.9569e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8330/  8460 | global iter:   8330/  8460 | loss: 0.0931 | ds_loss: 0.0000 | lr: 3.9120e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8331/  8460 | global iter:   8331/  8460 | loss: 0.0313 | ds_loss: 0.0000 | lr: 3.8673e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8332/  8460 | global iter:   8332/  8460 | loss: 0.1109 | ds_loss: 0.0000 | lr: 3.8231e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8332/  8460 | global iter:   8332/  8460 | loss: 0.0750 | ds_loss: 0.0000 | lr: 3.8231e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8333/  8460 | global iter:   8333/  8460 | loss: 0.0272 | ds_loss: 0.0000 | lr: 3.7791e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8334/  8460 | global iter:   8334/  8460 | loss: 0.0475 | ds_loss: 0.0000 | lr: 3.7355e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8335/  8460 | global iter:   8335/  8460 | loss: 0.0325 | ds_loss: 0.0000 | lr: 3.6923e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8336/  8460 | global iter:   8336/  8460 | loss: 0.0145 | ds_loss: 0.0000 | lr: 3.6494e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8336/  8460 | global iter:   8336/  8460 | loss: 0.0304 | ds_loss: 0.0000 | lr: 3.6494e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8337/  8460 | global iter:   8337/  8460 | loss: 0.0220 | ds_loss: 0.0000 | lr: 3.6069e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8338/  8460 | global iter:   8338/  8460 | loss: 0.0659 | ds_loss: 0.0000 | lr: 3.5646e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8339/  8460 | global iter:   8339/  8460 | loss: 0.0337 | ds_loss: 0.0000 | lr: 3.5228e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8340/  8460 | global iter:   8340/  8460 | loss: 0.0253 | ds_loss: 0.0000 | lr: 3.4813e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8340/  8460 | global iter:   8340/  8460 | loss: 0.0367 | ds_loss: 0.0000 | lr: 3.4813e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8341/  8460 | global iter:   8341/  8460 | loss: 0.0711 | ds_loss: 0.0000 | lr: 3.4401e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8342/  8460 | global iter:   8342/  8460 | loss: 0.0089 | ds_loss: 0.0000 | lr: 3.3993e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8343/  8460 | global iter:   8343/  8460 | loss: 0.0085 | ds_loss: 0.0000 | lr: 3.3588e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8344/  8460 | global iter:   8344/  8460 | loss: 0.0402 | ds_loss: 0.0000 | lr: 3.3186e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8344/  8460 | global iter:   8344/  8460 | loss: 0.0322 | ds_loss: 0.0000 | lr: 3.3186e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8345/  8460 | global iter:   8345/  8460 | loss: 0.0805 | ds_loss: 0.0000 | lr: 3.2788e-07 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   8346/  8460 | global iter:   8346/  8460 | loss: 0.0370 | ds_loss: 0.0000 | lr: 3.2394e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8347/  8460 | global iter:   8347/  8460 | loss: 0.0361 | ds_loss: 0.0000 | lr: 3.2003e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8348/  8460 | global iter:   8348/  8460 | loss: 0.0349 | ds_loss: 0.0000 | lr: 3.1615e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8348/  8460 | global iter:   8348/  8460 | loss: 0.0471 | ds_loss: 0.0000 | lr: 3.1615e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8349/  8460 | global iter:   8349/  8460 | loss: 0.0074 | ds_loss: 0.0000 | lr: 3.1231e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8350/  8460 | global iter:   8350/  8460 | loss: 0.0247 | ds_loss: 0.0000 | lr: 3.0850e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8351/  8460 | global iter:   8351/  8460 | loss: 0.0379 | ds_loss: 0.0000 | lr: 3.0473e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8352/  8460 | global iter:   8352/  8460 | loss: 0.0762 | ds_loss: 0.0000 | lr: 3.0099e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8352/  8460 | global iter:   8352/  8460 | loss: 0.0365 | ds_loss: 0.0000 | lr: 3.0099e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8353/  8460 | global iter:   8353/  8460 | loss: 0.0395 | ds_loss: 0.0000 | lr: 2.9728e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8354/  8460 | global iter:   8354/  8460 | loss: 0.0247 | ds_loss: 0.0000 | lr: 2.9361e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8355/  8460 | global iter:   8355/  8460 | loss: 0.0485 | ds_loss: 0.0000 | lr: 2.8998e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8356/  8460 | global iter:   8356/  8460 | loss: 0.0143 | ds_loss: 0.0000 | lr: 2.8638e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8356/  8460 | global iter:   8356/  8460 | loss: 0.0318 | ds_loss: 0.0000 | lr: 2.8638e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8357/  8460 | global iter:   8357/  8460 | loss: 0.0062 | ds_loss: 0.0000 | lr: 2.8281e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8358/  8460 | global iter:   8358/  8460 | loss: 0.0204 | ds_loss: 0.0000 | lr: 2.7928e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8359/  8460 | global iter:   8359/  8460 | loss: 0.0111 | ds_loss: 0.0000 | lr: 2.7578e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8360/  8460 | global iter:   8360/  8460 | loss: 0.0354 | ds_loss: 0.0000 | lr: 2.7232e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8360/  8460 | global iter:   8360/  8460 | loss: 0.0183 | ds_loss: 0.0000 | lr: 2.7232e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8361/  8460 | global iter:   8361/  8460 | loss: 0.0486 | ds_loss: 0.0000 | lr: 2.6889e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8362/  8460 | global iter:   8362/  8460 | loss: 0.0892 | ds_loss: 0.0000 | lr: 2.6550e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8363/  8460 | global iter:   8363/  8460 | loss: 0.0450 | ds_loss: 0.0000 | lr: 2.6214e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8364/  8460 | global iter:   8364/  8460 | loss: 0.0331 | ds_loss: 0.0000 | lr: 2.5881e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8364/  8460 | global iter:   8364/  8460 | loss: 0.0540 | ds_loss: 0.0000 | lr: 2.5881e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8365/  8460 | global iter:   8365/  8460 | loss: 0.0133 | ds_loss: 0.0000 | lr: 2.5552e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8366/  8460 | global iter:   8366/  8460 | loss: 0.0215 | ds_loss: 0.0000 | lr: 2.5226e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8367/  8460 | global iter:   8367/  8460 | loss: 0.0056 | ds_loss: 0.0000 | lr: 2.4904e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8368/  8460 | global iter:   8368/  8460 | loss: 0.0094 | ds_loss: 0.0000 | lr: 2.4585e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8368/  8460 | global iter:   8368/  8460 | loss: 0.0124 | ds_loss: 0.0000 | lr: 2.4585e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8369/  8460 | global iter:   8369/  8460 | loss: 0.0099 | ds_loss: 0.0000 | lr: 2.4270e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8370/  8460 | global iter:   8370/  8460 | loss: 0.0634 | ds_loss: 0.0000 | lr: 2.3958e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8371/  8460 | global iter:   8371/  8460 | loss: 0.0459 | ds_loss: 0.0000 | lr: 2.3650e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8372/  8460 | global iter:   8372/  8460 | loss: 0.0286 | ds_loss: 0.0000 | lr: 2.3345e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8372/  8460 | global iter:   8372/  8460 | loss: 0.0370 | ds_loss: 0.0000 | lr: 2.3345e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8373/  8460 | global iter:   8373/  8460 | loss: 0.0441 | ds_loss: 0.0000 | lr: 2.3043e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8374/  8460 | global iter:   8374/  8460 | loss: 0.0077 | ds_loss: 0.0000 | lr: 2.2745e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8375/  8460 | global iter:   8375/  8460 | loss: 0.0316 | ds_loss: 0.0000 | lr: 2.2450e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8376/  8460 | global iter:   8376/  8460 | loss: 0.0112 | ds_loss: 0.0000 | lr: 2.2159e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8376/  8460 | global iter:   8376/  8460 | loss: 0.0236 | ds_loss: 0.0000 | lr: 2.2159e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8377/  8460 | global iter:   8377/  8460 | loss: 0.0315 | ds_loss: 0.0000 | lr: 2.1871e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8378/  8460 | global iter:   8378/  8460 | loss: 0.0287 | ds_loss: 0.0000 | lr: 2.1587e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8379/  8460 | global iter:   8379/  8460 | loss: 0.0154 | ds_loss: 0.0000 | lr: 2.1306e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8380/  8460 | global iter:   8380/  8460 | loss: 0.0278 | ds_loss: 0.0000 | lr: 2.1029e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8380/  8460 | global iter:   8380/  8460 | loss: 0.0259 | ds_loss: 0.0000 | lr: 2.1029e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8381/  8460 | global iter:   8381/  8460 | loss: 0.0162 | ds_loss: 0.0000 | lr: 2.0755e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8382/  8460 | global iter:   8382/  8460 | loss: 0.0106 | ds_loss: 0.0000 | lr: 2.0484e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8383/  8460 | global iter:   8383/  8460 | loss: 0.1330 | ds_loss: 0.0000 | lr: 2.0217e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8384/  8460 | global iter:   8384/  8460 | loss: 0.0145 | ds_loss: 0.0000 | lr: 1.9954e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8384/  8460 | global iter:   8384/  8460 | loss: 0.0436 | ds_loss: 0.0000 | lr: 1.9954e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8385/  8460 | global iter:   8385/  8460 | loss: 0.0138 | ds_loss: 0.0000 | lr: 1.9693e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8386/  8460 | global iter:   8386/  8460 | loss: 0.0169 | ds_loss: 0.0000 | lr: 1.9437e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8387/  8460 | global iter:   8387/  8460 | loss: 0.0160 | ds_loss: 0.0000 | lr: 1.9183e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8388/  8460 | global iter:   8388/  8460 | loss: 0.0137 | ds_loss: 0.0000 | lr: 1.8933e-07 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8388/  8460 | global iter:   8388/  8460 | loss: 0.0151 | ds_loss: 0.0000 | lr: 1.8933e-07 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8389/  8460 | global iter:   8389/  8460 | loss: 0.0092 | ds_loss: 0.0000 | lr: 1.8687e-07 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   8390/  8460 | global iter:   8390/  8460 | loss: 0.0080 | ds_loss: 0.0000 | lr: 1.8444e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8391/  8460 | global iter:   8391/  8460 | loss: 0.0161 | ds_loss: 0.0000 | lr: 1.8205e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8392/  8460 | global iter:   8392/  8460 | loss: 0.0547 | ds_loss: 0.0000 | lr: 1.7969e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8392/  8460 | global iter:   8392/  8460 | loss: 0.0220 | ds_loss: 0.0000 | lr: 1.7969e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.429
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8393/  8460 | global iter:   8393/  8460 | loss: 0.0686 | ds_loss: 0.0000 | lr: 1.7736e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8394/  8460 | global iter:   8394/  8460 | loss: 0.0217 | ds_loss: 0.0000 | lr: 1.7507e-07 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   8395/  8460 | global iter:   8395/  8460 | loss: 0.0225 | ds_loss: 0.0000 | lr: 1.7281e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8396/  8460 | global iter:   8396/  8460 | loss: 0.0505 | ds_loss: 0.0000 | lr: 1.7059e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8396/  8460 | global iter:   8396/  8460 | loss: 0.0408 | ds_loss: 0.0000 | lr: 1.7059e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8397/  8460 | global iter:   8397/  8460 | loss: 0.0680 | ds_loss: 0.0000 | lr: 1.6840e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8398/  8460 | global iter:   8398/  8460 | loss: 0.0197 | ds_loss: 0.0000 | lr: 1.6624e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8399/  8460 | global iter:   8399/  8460 | loss: 0.0711 | ds_loss: 0.0000 | lr: 1.6412e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8400/  8460 | global iter:   8400/  8460 | loss: 0.0124 | ds_loss: 0.0000 | lr: 1.6204e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8400/  8460 | global iter:   8400/  8460 | loss: 0.0428 | ds_loss: 0.0000 | lr: 1.6204e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8401/  8460 | global iter:   8401/  8460 | loss: 0.0198 | ds_loss: 0.0000 | lr: 1.5999e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8402/  8460 | global iter:   8402/  8460 | loss: 0.0706 | ds_loss: 0.0000 | lr: 1.5797e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8403/  8460 | global iter:   8403/  8460 | loss: 0.0215 | ds_loss: 0.0000 | lr: 1.5599e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8404/  8460 | global iter:   8404/  8460 | loss: 0.0064 | ds_loss: 0.0000 | lr: 1.5404e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8404/  8460 | global iter:   8404/  8460 | loss: 0.0296 | ds_loss: 0.0000 | lr: 1.5404e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8405/  8460 | global iter:   8405/  8460 | loss: 0.0202 | ds_loss: 0.0000 | lr: 1.5213e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8406/  8460 | global iter:   8406/  8460 | loss: 0.0562 | ds_loss: 0.0000 | lr: 1.5025e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8407/  8460 | global iter:   8407/  8460 | loss: 0.0013 | ds_loss: 0.0000 | lr: 1.4841e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8408/  8460 | global iter:   8408/  8460 | loss: 0.0921 | ds_loss: 0.0000 | lr: 1.4660e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8408/  8460 | global iter:   8408/  8460 | loss: 0.0424 | ds_loss: 0.0000 | lr: 1.4660e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8409/  8460 | global iter:   8409/  8460 | loss: 0.0703 | ds_loss: 0.0000 | lr: 1.4482e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8410/  8460 | global iter:   8410/  8460 | loss: 0.0061 | ds_loss: 0.0000 | lr: 1.4308e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8411/  8460 | global iter:   8411/  8460 | loss: 0.0071 | ds_loss: 0.0000 | lr: 1.4138e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8412/  8460 | global iter:   8412/  8460 | loss: 0.0661 | ds_loss: 0.0000 | lr: 1.3971e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8412/  8460 | global iter:   8412/  8460 | loss: 0.0374 | ds_loss: 0.0000 | lr: 1.3971e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8413/  8460 | global iter:   8413/  8460 | loss: 0.0307 | ds_loss: 0.0000 | lr: 1.3807e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8414/  8460 | global iter:   8414/  8460 | loss: 0.0339 | ds_loss: 0.0000 | lr: 1.3647e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8415/  8460 | global iter:   8415/  8460 | loss: 0.0170 | ds_loss: 0.0000 | lr: 1.3490e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8416/  8460 | global iter:   8416/  8460 | loss: 0.0133 | ds_loss: 0.0000 | lr: 1.3336e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8416/  8460 | global iter:   8416/  8460 | loss: 0.0237 | ds_loss: 0.0000 | lr: 1.3336e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8417/  8460 | global iter:   8417/  8460 | loss: 0.1801 | ds_loss: 0.0000 | lr: 1.3186e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8418/  8460 | global iter:   8418/  8460 | loss: 0.0312 | ds_loss: 0.0000 | lr: 1.3040e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8419/  8460 | global iter:   8419/  8460 | loss: 0.0081 | ds_loss: 0.0000 | lr: 1.2897e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8420/  8460 | global iter:   8420/  8460 | loss: 0.0240 | ds_loss: 0.0000 | lr: 1.2757e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8420/  8460 | global iter:   8420/  8460 | loss: 0.0608 | ds_loss: 0.0000 | lr: 1.2757e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8421/  8460 | global iter:   8421/  8460 | loss: 0.0477 | ds_loss: 0.0000 | lr: 1.2621e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8422/  8460 | global iter:   8422/  8460 | loss: 0.0189 | ds_loss: 0.0000 | lr: 1.2489e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8423/  8460 | global iter:   8423/  8460 | loss: 0.0094 | ds_loss: 0.0000 | lr: 1.2359e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8424/  8460 | global iter:   8424/  8460 | loss: 0.0612 | ds_loss: 0.0000 | lr: 1.2233e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8424/  8460 | global iter:   8424/  8460 | loss: 0.0343 | ds_loss: 0.0000 | lr: 1.2233e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8425/  8460 | global iter:   8425/  8460 | loss: 0.0219 | ds_loss: 0.0000 | lr: 1.2111e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8426/  8460 | global iter:   8426/  8460 | loss: 0.0558 | ds_loss: 0.0000 | lr: 1.1992e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8427/  8460 | global iter:   8427/  8460 | loss: 0.0608 | ds_loss: 0.0000 | lr: 1.1877e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8428/  8460 | global iter:   8428/  8460 | loss: 0.0054 | ds_loss: 0.0000 | lr: 1.1765e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8428/  8460 | global iter:   8428/  8460 | loss: 0.0360 | ds_loss: 0.0000 | lr: 1.1765e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8429/  8460 | global iter:   8429/  8460 | loss: 0.0094 | ds_loss: 0.0000 | lr: 1.1656e-07 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
train | epoch   9 | Iter:   8430/  8460 | global iter:   8430/  8460 | loss: 0.0347 | ds_loss: 0.0000 | lr: 1.1551e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8431/  8460 | global iter:   8431/  8460 | loss: 0.1067 | ds_loss: 0.0000 | lr: 1.1449e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8432/  8460 | global iter:   8432/  8460 | loss: 0.0332 | ds_loss: 0.0000 | lr: 1.1351e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8432/  8460 | global iter:   8432/  8460 | loss: 0.0460 | ds_loss: 0.0000 | lr: 1.1351e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8433/  8460 | global iter:   8433/  8460 | loss: 0.0262 | ds_loss: 0.0000 | lr: 1.1256e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8434/  8460 | global iter:   8434/  8460 | loss: 0.0374 | ds_loss: 0.0000 | lr: 1.1165e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8435/  8460 | global iter:   8435/  8460 | loss: 0.0053 | ds_loss: 0.0000 | lr: 1.1077e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8436/  8460 | global iter:   8436/  8460 | loss: 0.1178 | ds_loss: 0.0000 | lr: 1.0993e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8436/  8460 | global iter:   8436/  8460 | loss: 0.0467 | ds_loss: 0.0000 | lr: 1.0993e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8437/  8460 | global iter:   8437/  8460 | loss: 0.0068 | ds_loss: 0.0000 | lr: 1.0912e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8438/  8460 | global iter:   8438/  8460 | loss: 0.0026 | ds_loss: 0.0000 | lr: 1.0834e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8439/  8460 | global iter:   8439/  8460 | loss: 0.0633 | ds_loss: 0.0000 | lr: 1.0760e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8440/  8460 | global iter:   8440/  8460 | loss: 0.0689 | ds_loss: 0.0000 | lr: 1.0689e-07 | scale:     1.0000 | micro time: 0.429 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8440/  8460 | global iter:   8440/  8460 | loss: 0.0354 | ds_loss: 0.0000 | lr: 1.0689e-07 | scale:     1.0000 | micro time: 0.429 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8441/  8460 | global iter:   8441/  8460 | loss: 0.0355 | ds_loss: 0.0000 | lr: 1.0622e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8442/  8460 | global iter:   8442/  8460 | loss: 0.0115 | ds_loss: 0.0000 | lr: 1.0558e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8443/  8460 | global iter:   8443/  8460 | loss: 0.0215 | ds_loss: 0.0000 | lr: 1.0498e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8444/  8460 | global iter:   8444/  8460 | loss: 0.0292 | ds_loss: 0.0000 | lr: 1.0441e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8444/  8460 | global iter:   8444/  8460 | loss: 0.0244 | ds_loss: 0.0000 | lr: 1.0441e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8445/  8460 | global iter:   8445/  8460 | loss: 0.0145 | ds_loss: 0.0000 | lr: 1.0388e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8446/  8460 | global iter:   8446/  8460 | loss: 0.0402 | ds_loss: 0.0000 | lr: 1.0338e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8447/  8460 | global iter:   8447/  8460 | loss: 0.1360 | ds_loss: 0.0000 | lr: 1.0291e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8448/  8460 | global iter:   8448/  8460 | loss: 0.0202 | ds_loss: 0.0000 | lr: 1.0248e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8448/  8460 | global iter:   8448/  8460 | loss: 0.0527 | ds_loss: 0.0000 | lr: 1.0248e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8449/  8460 | global iter:   8449/  8460 | loss: 0.2016 | ds_loss: 0.0000 | lr: 1.0209e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8450/  8460 | global iter:   8450/  8460 | loss: 0.2092 | ds_loss: 0.0000 | lr: 1.0172e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8451/  8460 | global iter:   8451/  8460 | loss: 0.0561 | ds_loss: 0.0000 | lr: 1.0140e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8452/  8460 | global iter:   8452/  8460 | loss: 0.0321 | ds_loss: 0.0000 | lr: 1.0110e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8452/  8460 | global iter:   8452/  8460 | loss: 0.1247 | ds_loss: 0.0000 | lr: 1.0110e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8453/  8460 | global iter:   8453/  8460 | loss: 0.0066 | ds_loss: 0.0000 | lr: 1.0084e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8454/  8460 | global iter:   8454/  8460 | loss: 0.0685 | ds_loss: 0.0000 | lr: 1.0062e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8455/  8460 | global iter:   8455/  8460 | loss: 0.0119 | ds_loss: 0.0000 | lr: 1.0043e-07 | scale:     1.0000 | micro time: 0.428 | step time: 0.000
train | epoch   9 | Iter:   8456/  8460 | global iter:   8456/  8460 | loss: 0.0318 | ds_loss: 0.0000 | lr: 1.0028e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8456/  8460 | global iter:   8456/  8460 | loss: 0.0297 | ds_loss: 0.0000 | lr: 1.0028e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.428
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
train | epoch   9 | Iter:   8457/  8460 | global iter:   8457/  8460 | loss: 0.0396 | ds_loss: 0.0000 | lr: 1.0016e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8458/  8460 | global iter:   8458/  8460 | loss: 0.0074 | ds_loss: 0.0000 | lr: 1.0007e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8459/  8460 | global iter:   8459/  8460 | loss: 0.0532 | ds_loss: 0.0000 | lr: 1.0002e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
train | epoch   9 | Iter:   8460/  8460 | global iter:   8460/  8460 | loss: 0.0068 | ds_loss: 0.0000 | lr: 1.0000e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.000
****************************************************************************************************
train | epoch   9 | Iter:   8460/  8460 | global iter:   8460/  8460 | loss: 0.0267 | ds_loss: 0.0000 | lr: 1.0000e-07 | scale:     1.0000 | micro time: 0.427 | step time: 0.427
./results/gpt2/train/sft/gpt2-base/e10-bs2-lr0.0005-G1-N1-NN1
****************************************************************************************************
[rank0]:[W406 21:55:50.116112613 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
