compsci-cluster-fitz-03
Sun Apr 20 03:56:20 PM EDT 2025
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
The token `llama3` has been saved to /dev/shm/hf-home/stored_tokens
Your token has been saved to /dev/shm/hf-home/token
Login successful.
The current active token is: `llama3`
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2012 ./finetune.py --base-path . --model-path Qwen/Qwen2.5-0.5B-Instruct --ckpt-name qwen2.5-0.5B-Instruct --n-gpu 2 --model-type qwen2 --gradient-checkpointing --data-dir ./processed_data/pytorrent/full/qwen2 --num-workers 0 --dev-num 1000 --lr 0.00001 --batch-size 1 --eval-batch-size 8 --gradient-accumulation-steps 2 --warmup-iters 0 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --epochs 10 --max-length 512 --max-prompt-length 256 --do-train --do-valid --eval-gen --save-interval 4000 --eval-interval 4000 --log-interval 4 --mid-log-num 1 --save ./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct --seed 10 --seed-order 10 --deepspeed --deepspeed_config ./configs/deepspeed/ds_config_zero2_bf16.json --type lm --do-sample --top-k 0 --top-p 1.0 --temperature 1.0
PYTHONPATH=.
W0420 15:56:23.193000 3955296 torch/distributed/run.py:792] 
W0420 15:56:23.193000 3955296 torch/distributed/run.py:792] *****************************************
W0420 15:56:23.193000 3955296 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0420 15:56:23.193000 3955296 torch/distributed/run.py:792] *****************************************
[2025-04-20 15:56:25,953] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-04-20 15:56:25,953] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /home/users/ap794/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.Warning: The cache directory for DeepSpeed Triton autotune, /home/users/ap794/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.

/home/users/ap794/final_project_distillLLM/venv/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/home/users/ap794/final_project_distillLLM/venv/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
using world size: 2
[2025-04-20 15:56:30,926] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-04-20 15:56:30,926] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_path ................... Qwen/Qwen2.5-0.5B-Instruct
  ckpt_name .................... qwen2.5-0.5B-Instruct
  model_type ................... qwen2
  teacher_model_type ........... None
  n_gpu ........................ 2
  n_nodes ...................... 1
  teacher_model_path ........... None
  teacher_ckpt_name ............ None
  teacher_model_fp16 ........... False
  model_parallel ............... False
  model_parallel_size .......... None
  no_value ..................... False
  dropout_path_rate ............ None
  dtype ........................ torch.float16
  type ......................... lm
  do_train ..................... True
  do_valid ..................... True
  do_eval ...................... False
  base_path .................... .
  load ......................... None
  save ......................... ./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
  log_interval ................. 4
  mid_log_num .................. 1
  save_interval ................ 4000
  eval_interval ................ 4000
  local_rank ................... 0
  save_additional_suffix ....... 
  save_rollout ................. False
  eb_sample_times .............. 3
  data_dir ..................... ./processed_data/pytorrent/full/qwen2
  processed_data_dir ........... None
  force_process ................ False
  force_process_demo ........... False
  data_process_workers ......... -1
  train_num .................... -1
  train_ratio .................. 1
  dev_num ...................... 1000
  dev_ratio .................... 1
  gen_num ...................... -1
  data_names ................... None
  prompt_type .................. None
  num_workers .................. 0
  max_prompt_length ............ 256
  min_prompt_length ............ 128
  json_data .................... False
  bin_data ..................... False
  txt_data ..................... False
  prompt_data_dir .............. None
  lm_data_dir .................. None
  eval_ppl ..................... False
  eval_rw ...................... False
  eval_gen ..................... True
  only_prompt .................. False
  batch_size ................... 1
  eval_batch_size .............. 8
  clip_grad .................... 1.0
  total_iters .................. None
  train_iters_per_epoch ........ -1
  max_length ................... 512
  seed ......................... 10
  seed_order ................... 10
  seed_data .................... 42
  seed_ppo ..................... 42
  seed_lm ...................... 7
  epochs ....................... 10
  training_epochs .............. 10000
  gradient_accumulation_steps .. 2
  gradient_checkpointing ....... True
  attn_dtype ................... None
  lr ........................... 1e-05
  lr_min ....................... 1e-07
  weight_decay ................. 0.01
  loss_scale ................... 65536
  kd_ratio ..................... None
  warmup_iters ................. 0
  lr_decay_iters ............... None
  lr_decay_style ............... cosine
  scheduler_name ............... constant_trm
  reward_scaling ............... None
  cliprange_reward ............. 1
  ppo_epochs ................... None
  num_rollouts ................. 256
  num_rollouts_per_device ...... None
  cliprange .................... 0.2
  chunk_size ................... None
  gamma ........................ 0.95
  length_norm .................. False
  single_step_reg .............. False
  teacher_mixed_alpha .......... None
  lm_coef ...................... 1
  top_k ........................ 0
  top_p ........................ 1.0
  do_sample .................... True
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  num_beams .................... 1
  temperature .................. 1.0
  peft ......................... None
  peft_lora_r .................. 8
  peft_lora_alpha .............. 32
  peft_lora_dropout ............ 0.1
  peft_name .................... None
  peft_path .................... None
  teacher_peft_name ............ None
  teacher_peft_path ............ None
  deepspeed .................... True
  deepspeed_config ............. ./configs/deepspeed/ds_config_zero2_bf16.json
  deepscale .................... False
  deepscale_config ............. None
  rank ......................... 0
  world_size ................... 2
[2025-04-20 15:56:31,016] [INFO] [comm.py:658:init_distributed] cdb=None
Sun Apr 20 15:56:30 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   26C    P8             16W /  230W |       4MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   25C    P2             18W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3955303      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

Sun Apr 20 15:56:31 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   27C    P8             17W /  230W |       4MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   25C    P2             25W /  230W |     209MiB /  24564MiB |      2%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3955303      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

Sun Apr 20 15:56:31 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   27C    P8             18W /  230W |       4MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   25C    P2             30W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3955303      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

Sun Apr 20 15:56:31 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   27C    P8             18W /  230W |       4MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   26C    P2             32W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3955303      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

Probing Dataset
Probing end. Max data state 1, total length 499991
499991
Num LM instances: 499991
train num 499991
Probing Dataset
Probing end. Max data state 1, total length 1000
1000
Num LM instances: 1000
Train iters per epoch 124997
total_iters 1249970
Sun Apr 20 15:56:38 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   26C    P8             16W /  230W |       4MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   27C    P2             60W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3955303      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

Sun Apr 20 15:56:38 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   26C    P8             16W /  230W |       4MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   27C    P2             60W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3955303      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

[2025-04-20 15:56:49,097] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 2
 > number of parameters: 494032768
Model load time: 10.696739435195923s
Optimizer = AdamW
[2025-04-20 15:56:49,114] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed info: version=0.16.4, git-hash=unknown, git-branch=unknown
[2025-04-20 15:56:49,114] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 2
[2025-04-20 15:56:49,538] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-04-20 15:56:49,540] [INFO] [logging.py:128:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2025-04-20 15:56:49,540] [INFO] [logging.py:128:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-04-20 15:56:49,560] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2025-04-20 15:56:49,560] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2025-04-20 15:56:49,561] [INFO] [logging.py:128:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2025-04-20 15:56:49,561] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2025-04-20 15:56:49,561] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2025-04-20 15:56:49,561] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2025-04-20 15:56:49,561] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
Sun Apr 20 15:56:50 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   29C    P2             59W /  230W |    2257MiB /  24564MiB |     17%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   29C    P2             62W /  230W |    3201MiB /  24564MiB |     17%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3955302      C   ...project_distillLLM/venv/bin/python3       2250MiB |
|    1   N/A  N/A   3955303      C   ...project_distillLLM/venv/bin/python3       3194MiB |
+-----------------------------------------------------------------------------------------+

[2025-04-20 15:56:51,023] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[2025-04-20 15:56:51,024] [INFO] [utils.py:782:see_memory_usage] MA 1.84 GB         Max_MA 1.84 GB         CA 1.85 GB         Max_CA 2 GB 
[2025-04-20 15:56:51,024] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 38.65 GB, percent = 5.1%
Sun Apr 20 15:56:51 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   29C    P2             60W /  230W |    3201MiB /  24564MiB |     11%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   29C    P2             62W /  230W |    3201MiB /  24564MiB |      8%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3955302      C   ...project_distillLLM/venv/bin/python3       3194MiB |
|    1   N/A  N/A   3955303      C   ...project_distillLLM/venv/bin/python3       3194MiB |
+-----------------------------------------------------------------------------------------+

[2025-04-20 15:56:51,252] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[2025-04-20 15:56:51,254] [INFO] [utils.py:782:see_memory_usage] MA 1.84 GB         Max_MA 2.76 GB         CA 2.78 GB         Max_CA 3 GB 
[2025-04-20 15:56:51,254] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 38.66 GB, percent = 5.1%
[2025-04-20 15:56:51,254] [INFO] [stage_1_and_2.py:550:__init__] optimizer state initialized
[2025-04-20 15:56:51,499] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[2025-04-20 15:56:51,500] [INFO] [utils.py:782:see_memory_usage] MA 1.84 GB         Max_MA 1.84 GB         CA 2.78 GB         Max_CA 3 GB 
[2025-04-20 15:56:51,500] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 38.69 GB, percent = 5.1%
[2025-04-20 15:56:51,504] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer
[2025-04-20 15:56:51,505] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2025-04-20 15:56:51,505] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f83f4c38130>
[2025-04-20 15:56:51,505] [INFO] [logging.py:128:log_dist] [Rank 0] step=0, skipped=0, lr=[1e-05, 1e-05], mom=[(0.9, 0.999), (0.9, 0.999)]
[2025-04-20 15:56:51,507] [INFO] [config.py:1001:print] DeepSpeedEngine configuration:
[2025-04-20 15:56:51,507] [INFO] [config.py:1005:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-04-20 15:56:51,507] [INFO] [config.py:1005:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-04-20 15:56:51,508] [INFO] [config.py:1005:print]   amp_enabled .................. False
[2025-04-20 15:56:51,508] [INFO] [config.py:1005:print]   amp_params ................... False
[2025-04-20 15:56:51,508] [INFO] [config.py:1005:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-04-20 15:56:51,508] [INFO] [config.py:1005:print]   bfloat16_enabled ............. False
[2025-04-20 15:56:51,508] [INFO] [config.py:1005:print]   bfloat16_immediate_grad_update  False
[2025-04-20 15:56:51,509] [INFO] [config.py:1005:print]   checkpoint_parallel_write_pipeline  False
[2025-04-20 15:56:51,509] [INFO] [config.py:1005:print]   checkpoint_tag_validation_enabled  True
[2025-04-20 15:56:51,509] [INFO] [config.py:1005:print]   checkpoint_tag_validation_fail  False
[2025-04-20 15:56:51,509] [INFO] [config.py:1005:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f839cb17160>
[2025-04-20 15:56:51,509] [INFO] [config.py:1005:print]   communication_data_type ...... None
[2025-04-20 15:56:51,509] [INFO] [config.py:1005:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-04-20 15:56:51,509] [INFO] [config.py:1005:print]   curriculum_enabled_legacy .... False
[2025-04-20 15:56:51,510] [INFO] [config.py:1005:print]   curriculum_params_legacy ..... False
[2025-04-20 15:56:51,510] [INFO] [config.py:1005:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-04-20 15:56:51,510] [INFO] [config.py:1005:print]   data_efficiency_enabled ...... False
[2025-04-20 15:56:51,510] [INFO] [config.py:1005:print]   dataloader_drop_last ......... False
[2025-04-20 15:56:51,510] [INFO] [config.py:1005:print]   disable_allgather ............ False
[2025-04-20 15:56:51,510] [INFO] [config.py:1005:print]   dump_state ................... False
[2025-04-20 15:56:51,510] [INFO] [config.py:1005:print]   dynamic_loss_scale_args ...... None
[2025-04-20 15:56:51,511] [INFO] [config.py:1005:print]   eigenvalue_enabled ........... False
[2025-04-20 15:56:51,511] [INFO] [config.py:1005:print]   eigenvalue_gas_boundary_resolution  1
[2025-04-20 15:56:51,511] [INFO] [config.py:1005:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-04-20 15:56:51,511] [INFO] [config.py:1005:print]   eigenvalue_layer_num ......... 0
[2025-04-20 15:56:51,511] [INFO] [config.py:1005:print]   eigenvalue_max_iter .......... 100
[2025-04-20 15:56:51,511] [INFO] [config.py:1005:print]   eigenvalue_stability ......... 1e-06
[2025-04-20 15:56:51,511] [INFO] [config.py:1005:print]   eigenvalue_tol ............... 0.01
[2025-04-20 15:56:51,511] [INFO] [config.py:1005:print]   eigenvalue_verbose ........... False
[2025-04-20 15:56:51,511] [INFO] [config.py:1005:print]   elasticity_enabled ........... False
[2025-04-20 15:56:51,512] [INFO] [config.py:1005:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-04-20 15:56:51,512] [INFO] [config.py:1005:print]   fp16_auto_cast ............... None
[2025-04-20 15:56:51,512] [INFO] [config.py:1005:print]   fp16_enabled ................. False
[2025-04-20 15:56:51,512] [INFO] [config.py:1005:print]   fp16_master_weights_and_gradients  False
[2025-04-20 15:56:51,512] [INFO] [config.py:1005:print]   global_rank .................. 0
[2025-04-20 15:56:51,512] [INFO] [config.py:1005:print]   grad_accum_dtype ............. None
[2025-04-20 15:56:51,512] [INFO] [config.py:1005:print]   gradient_accumulation_steps .. 2
[2025-04-20 15:56:51,512] [INFO] [config.py:1005:print]   gradient_clipping ............ 1.0
[2025-04-20 15:56:51,513] [INFO] [config.py:1005:print]   gradient_predivide_factor .... 1.0
[2025-04-20 15:56:51,513] [INFO] [config.py:1005:print]   graph_harvesting ............. False
[2025-04-20 15:56:51,513] [INFO] [config.py:1005:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-04-20 15:56:51,513] [INFO] [config.py:1005:print]   initial_dynamic_scale ........ 65536
[2025-04-20 15:56:51,513] [INFO] [config.py:1005:print]   load_universal_checkpoint .... False
[2025-04-20 15:56:51,513] [INFO] [config.py:1005:print]   loss_scale ................... 0
[2025-04-20 15:56:51,513] [INFO] [config.py:1005:print]   memory_breakdown ............. False
[2025-04-20 15:56:51,513] [INFO] [config.py:1005:print]   mics_hierarchial_params_gather  False
[2025-04-20 15:56:51,513] [INFO] [config.py:1005:print]   mics_shard_size .............. -1
[2025-04-20 15:56:51,514] [INFO] [config.py:1005:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2025-04-20 15:56:51,514] [INFO] [config.py:1005:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-04-20 15:56:51,514] [INFO] [config.py:1005:print]   optimizer_legacy_fusion ...... False
[2025-04-20 15:56:51,514] [INFO] [config.py:1005:print]   optimizer_name ............... None
[2025-04-20 15:56:51,514] [INFO] [config.py:1005:print]   optimizer_params ............. None
[2025-04-20 15:56:51,514] [INFO] [config.py:1005:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-04-20 15:56:51,515] [INFO] [config.py:1005:print]   pld_enabled .................. False
[2025-04-20 15:56:51,515] [INFO] [config.py:1005:print]   pld_params ................... False
[2025-04-20 15:56:51,515] [INFO] [config.py:1005:print]   prescale_gradients ........... False
[2025-04-20 15:56:51,515] [INFO] [config.py:1005:print]   scheduler_name ............... None
[2025-04-20 15:56:51,515] [INFO] [config.py:1005:print]   scheduler_params ............. None
[2025-04-20 15:56:51,515] [INFO] [config.py:1005:print]   seq_parallel_communication_data_type  torch.float32
[2025-04-20 15:56:51,515] [INFO] [config.py:1005:print]   sparse_attention ............. None
[2025-04-20 15:56:51,516] [INFO] [config.py:1005:print]   sparse_gradients_enabled ..... False
[2025-04-20 15:56:51,516] [INFO] [config.py:1005:print]   steps_per_print .............. 10000000
[2025-04-20 15:56:51,516] [INFO] [config.py:1005:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False
[2025-04-20 15:56:51,516] [INFO] [config.py:1005:print]   timers_config ................ enabled=True synchronized=True
[2025-04-20 15:56:51,516] [INFO] [config.py:1005:print]   train_batch_size ............. 4
[2025-04-20 15:56:51,516] [INFO] [config.py:1005:print]   train_micro_batch_size_per_gpu  1
[2025-04-20 15:56:51,516] [INFO] [config.py:1005:print]   use_data_before_expert_parallel_  False
[2025-04-20 15:56:51,516] [INFO] [config.py:1005:print]   use_node_local_storage ....... False
[2025-04-20 15:56:51,517] [INFO] [config.py:1005:print]   wall_clock_breakdown ......... False
[2025-04-20 15:56:51,517] [INFO] [config.py:1005:print]   weight_quantization_config ... None
[2025-04-20 15:56:51,517] [INFO] [config.py:1005:print]   world_size ................... 2
[2025-04-20 15:56:51,517] [INFO] [config.py:1005:print]   zero_allow_untested_optimizer  True
[2025-04-20 15:56:51,517] [INFO] [config.py:1005:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False
[2025-04-20 15:56:51,517] [INFO] [config.py:1005:print]   zero_enabled ................. True
[2025-04-20 15:56:51,517] [INFO] [config.py:1005:print]   zero_force_ds_cpu_optimizer .. True
[2025-04-20 15:56:51,517] [INFO] [config.py:1005:print]   zero_optimization_stage ...... 2
[2025-04-20 15:56:51,518] [INFO] [config.py:991:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 2, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "none"
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true
    }, 
    "zero_allow_untested_optimizer": true, 
    "bf16": {
        "enabled": false
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1.000000e+07
}
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   1884 MiB |   1884 MiB |   4249 MiB |   2364 MiB |
|       from large pool |   1884 MiB |   1884 MiB |   4238 MiB |   2353 MiB |
|       from small pool |      0 MiB |      0 MiB |     11 MiB |     10 MiB |
|---------------------------------------------------------------------------|
| Active memory         |   1884 MiB |   1884 MiB |   4249 MiB |   2364 MiB |
|       from large pool |   1884 MiB |   1884 MiB |   4238 MiB |   2353 MiB |
|       from small pool |      0 MiB |      0 MiB |     11 MiB |     10 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |   1884 MiB |   1884 MiB |   4240 MiB |   2355 MiB |
|       from large pool |   1884 MiB |   1884 MiB |   4229 MiB |   2345 MiB |
|       from small pool |      0 MiB |      0 MiB |     10 MiB |     10 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   2842 MiB |   2842 MiB |   4296 MiB |   1454 MiB |
|       from large pool |   2832 MiB |   2832 MiB |   4284 MiB |   1452 MiB |
|       from small pool |     10 MiB |     10 MiB |     12 MiB |      2 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   7579 KiB |   7579 KiB |    827 MiB |    820 MiB |
|       from large pool |   3604 KiB |   3604 KiB |    806 MiB |    802 MiB |
|       from small pool |   3975 KiB |   3975 KiB |     21 MiB |     17 MiB |
|---------------------------------------------------------------------------|
| Allocations           |      29    |      29    |     613    |     584    |
|       from large pool |       2    |       2    |     125    |     123    |
|       from small pool |      27    |      27    |     488    |     461    |
|---------------------------------------------------------------------------|
| Active allocs         |      29    |      29    |     613    |     584    |
|       from large pool |       2    |       2    |     125    |     123    |
|       from small pool |      27    |      27    |     488    |     461    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       8    |       8    |      47    |      39    |
|       from large pool |       3    |       3    |      41    |      38    |
|       from small pool |       5    |       5    |       6    |       1    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       7    |       7    |     170    |     163    |
|       from large pool |       2    |       2    |      86    |      84    |
|       from small pool |       5    |       5    |      84    |      79    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Start Fine-tuning
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
Sun Apr 20 15:56:51 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   29C    P2             60W /  230W |    3201MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   30C    P2             62W /  230W |    5637MiB /  24564MiB |      2%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3955302      C   ...project_distillLLM/venv/bin/python3       3194MiB |
|    1   N/A  N/A   3955303      C   ...project_distillLLM/venv/bin/python3       5630MiB |
+-----------------------------------------------------------------------------------------+

Start Fine-tuning
Sun Apr 20 15:56:51 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   29C    P2             61W /  230W |    3201MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   31C    P2             83W /  230W |    5637MiB /  24564MiB |     60%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3955302      C   ...project_distillLLM/venv/bin/python3       3194MiB |
|    1   N/A  N/A   3955303      C   ...project_distillLLM/venv/bin/python3       5630MiB |
+-----------------------------------------------------------------------------------------+

dp size 2
0/63
Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
1/63
Evaluating:   2%|▏         | 1/63 [00:08<08:37,  8.35s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2/63
Evaluating:   3%|▎         | 2/63 [00:15<07:55,  7.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
3/63
Evaluating:   5%|▍         | 3/63 [00:23<07:52,  7.88s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
4/63
Evaluating:   6%|▋         | 4/63 [00:31<07:48,  7.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
5/63
Evaluating:   8%|▊         | 5/63 [00:39<07:41,  7.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
6/63
Evaluating:  10%|▉         | 6/63 [00:47<07:34,  7.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
7/63
Evaluating:  11%|█         | 7/63 [00:55<07:27,  7.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
8/63
Evaluating:  13%|█▎        | 8/63 [01:03<07:20,  8.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
9/63
Evaluating:  14%|█▍        | 9/63 [01:11<07:03,  7.83s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
10/63
Evaluating:  16%|█▌        | 10/63 [01:19<06:58,  7.89s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
11/63
Evaluating:  17%|█▋        | 11/63 [01:27<06:52,  7.94s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
12/63
Evaluating:  19%|█▉        | 12/63 [01:35<06:46,  7.97s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
13/63
Evaluating:  21%|██        | 13/63 [01:43<06:39,  7.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
14/63
Evaluating:  22%|██▏       | 14/63 [01:51<06:32,  8.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
15/63
Evaluating:  24%|██▍       | 15/63 [01:59<06:24,  8.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
16/63
Evaluating:  25%|██▌       | 16/63 [02:07<06:16,  8.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
17/63
Evaluating:  27%|██▋       | 17/63 [02:14<06:00,  7.83s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
18/63
Evaluating:  29%|██▊       | 18/63 [02:22<05:55,  7.89s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
19/63
Evaluating:  30%|███       | 19/63 [02:30<05:48,  7.92s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
20/63
Evaluating:  32%|███▏      | 20/63 [02:38<05:41,  7.94s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
21/63
Evaluating:  33%|███▎      | 21/63 [02:46<05:34,  7.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
22/63
Evaluating:  35%|███▍      | 22/63 [02:54<05:26,  7.97s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
23/63
Evaluating:  37%|███▋      | 23/63 [03:02<05:19,  7.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
24/63
Evaluating:  38%|███▊      | 24/63 [03:10<05:11,  7.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
25/63
Evaluating:  40%|███▉      | 25/63 [03:18<05:00,  7.91s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
26/63
Evaluating:  41%|████▏     | 26/63 [03:26<04:53,  7.94s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
27/63
Evaluating:  43%|████▎     | 27/63 [03:34<04:46,  7.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
28/63
Evaluating:  44%|████▍     | 28/63 [03:42<04:39,  7.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
29/63
Evaluating:  46%|████▌     | 29/63 [03:50<04:31,  7.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
30/63
Evaluating:  48%|████▊     | 30/63 [03:58<04:24,  8.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
31/63
Evaluating:  49%|████▉     | 31/63 [04:06<04:16,  8.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
32/63
Evaluating:  51%|█████     | 32/63 [04:14<04:08,  8.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
33/63
Evaluating:  52%|█████▏    | 33/63 [04:22<04:00,  8.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
34/63
Evaluating:  54%|█████▍    | 34/63 [04:30<03:52,  8.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
35/63
Evaluating:  56%|█████▌    | 35/63 [04:38<03:44,  8.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
36/63
Evaluating:  57%|█████▋    | 36/63 [04:46<03:36,  8.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
37/63
Evaluating:  59%|█████▊    | 37/63 [04:54<03:28,  8.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
38/63
Evaluating:  60%|██████    | 38/63 [05:02<03:20,  8.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
39/63
Evaluating:  62%|██████▏   | 39/63 [05:10<03:12,  8.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
40/63
Evaluating:  63%|██████▎   | 40/63 [05:18<03:04,  8.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
41/63
Evaluating:  65%|██████▌   | 41/63 [05:26<02:56,  8.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
42/63
Evaluating:  67%|██████▋   | 42/63 [05:34<02:47,  7.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
43/63
Evaluating:  68%|██████▊   | 43/63 [05:42<02:39,  7.97s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
44/63
Evaluating:  70%|██████▉   | 44/63 [05:50<02:31,  7.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
45/63
Evaluating:  71%|███████▏  | 45/63 [05:58<02:23,  7.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
46/63
Evaluating:  73%|███████▎  | 46/63 [06:06<02:15,  8.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
47/63
Evaluating:  75%|███████▍  | 47/63 [06:14<02:07,  8.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
48/63
Evaluating:  76%|███████▌  | 48/63 [06:22<02:00,  8.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
49/63
Evaluating:  78%|███████▊  | 49/63 [06:29<01:48,  7.72s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
50/63
Evaluating:  79%|███████▉  | 50/63 [06:37<01:41,  7.80s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
51/63
Evaluating:  81%|████████  | 51/63 [06:45<01:34,  7.87s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
52/63
Evaluating:  83%|████████▎ | 52/63 [06:54<01:27,  7.92s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
53/63
Evaluating:  84%|████████▍ | 53/63 [07:02<01:19,  7.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
54/63
Evaluating:  86%|████████▌ | 54/63 [07:10<01:11,  7.97s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
55/63
Evaluating:  87%|████████▋ | 55/63 [07:18<01:03,  7.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
56/63
Evaluating:  89%|████████▉ | 56/63 [07:26<00:55,  7.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
57/63
Evaluating:  90%|█████████ | 57/63 [07:33<00:47,  7.89s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
58/63
Evaluating:  92%|█████████▏| 58/63 [07:41<00:39,  7.93s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
59/63
Evaluating:  94%|█████████▎| 59/63 [07:49<00:31,  7.97s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
60/63
Evaluating:  95%|█████████▌| 60/63 [07:57<00:23,  7.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
61/63
Evaluating:  97%|█████████▋| 61/63 [08:05<00:16,  8.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
62/63
Evaluating:  98%|█████████▊| 62/63 [08:13<00:08,  8.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
Evaluating: 100%|██████████| 63/63 [08:21<00:00,  8.01s/it]Evaluating: 100%|██████████| 63/63 [08:21<00:00,  7.97s/it]
Sun Apr 20 16:05:14 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   41C    P2             78W /  230W |    5717MiB /  24564MiB |     21%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   38C    P2             79W /  230W |    5719MiB /  24564MiB |     22%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3955302      C   ...project_distillLLM/venv/bin/python3       5710MiB |
|    1   N/A  N/A   3955303      C   ...project_distillLLM/venv/bin/python3       5712MiB |
+-----------------------------------------------------------------------------------------+

./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1/eval/0
dev | avg_loss: 2.0111142113095237 | {'exact_match': 0.0, 'rougeL': 8.6801}
Sun Apr 20 16:05:19 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   40C    P2             63W /  230W |    5717MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   40C    P2             99W /  230W |    7339MiB /  24564MiB |    100%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3955302      C   ...project_distillLLM/venv/bin/python3       5710MiB |
|    1   N/A  N/A   3955303      C   ...project_distillLLM/venv/bin/python3       7332MiB |
+-----------------------------------------------------------------------------------------+

[2025-04-20 16:05:20,766] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648
train | epoch   0 | Iter:      2/2499940 | global iter:      2/1249970 | loss: 2.2508 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 2147483648.0000 | micro time: 0.336 | step time: 0.000
[2025-04-20 16:05:21,375] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648, reducing to 1073741824
train | epoch   0 | Iter:      4/2499940 | global iter:      3/1249970 | loss: 1.7658 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 1073741824.0000 | micro time: 0.314 | step time: 0.000
[2025-04-20 16:05:21,978] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1073741824, reducing to 536870912
train | epoch   0 | Iter:      6/2499940 | global iter:      4/1249970 | loss: 2.2727 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 536870912.0000 | micro time: 0.309 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:      6/2499940 | global iter:      4/1249970 | loss: 1.4964 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 536870912.0000 | micro time: 0.309 | step time: 0.455
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
[2025-04-20 16:05:22,591] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 536870912, reducing to 268435456
train | epoch   0 | Iter:      8/2499940 | global iter:      5/1249970 | loss: 2.3722 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 268435456.0000 | micro time: 0.312 | step time: 0.000
[2025-04-20 16:05:23,193] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 268435456, reducing to 134217728
train | epoch   0 | Iter:     10/2499940 | global iter:      6/1249970 | loss: 1.9078 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 134217728.0000 | micro time: 0.309 | step time: 0.000
[2025-04-20 16:05:23,796] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 134217728, reducing to 67108864
train | epoch   0 | Iter:     12/2499940 | global iter:      7/1249970 | loss: 2.2729 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 67108864.0000 | micro time: 0.311 | step time: 0.000
[2025-04-20 16:05:24,395] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 67108864, reducing to 33554432
train | epoch   0 | Iter:     14/2499940 | global iter:      8/1249970 | loss: 1.7960 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 33554432.0000 | micro time: 0.310 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     14/2499940 | global iter:      8/1249970 | loss: 2.2815 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 33554432.0000 | micro time: 0.310 | step time: 0.603
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
[2025-04-20 16:05:25,003] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 33554432, reducing to 16777216
train | epoch   0 | Iter:     16/2499940 | global iter:      9/1249970 | loss: 2.2768 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16777216.0000 | micro time: 0.315 | step time: 0.000
[2025-04-20 16:05:25,598] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16777216, reducing to 8388608
train | epoch   0 | Iter:     18/2499940 | global iter:     10/1249970 | loss: 2.1695 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 8388608.0000 | micro time: 0.309 | step time: 0.000
[2025-04-20 16:05:26,204] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608, reducing to 4194304
train | epoch   0 | Iter:     20/2499940 | global iter:     11/1249970 | loss: 2.0581 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 4194304.0000 | micro time: 0.312 | step time: 0.000
[2025-04-20 16:05:26,804] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152
train | epoch   0 | Iter:     22/2499940 | global iter:     12/1249970 | loss: 2.9604 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 2097152.0000 | micro time: 0.309 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     22/2499940 | global iter:     12/1249970 | loss: 2.2412 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 2097152.0000 | micro time: 0.309 | step time: 0.600
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
[2025-04-20 16:05:27,409] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2097152, reducing to 1048576
train | epoch   0 | Iter:     24/2499940 | global iter:     13/1249970 | loss: 1.8674 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 1048576.0000 | micro time: 0.310 | step time: 0.000
[2025-04-20 16:05:28,010] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1048576, reducing to 524288
train | epoch   0 | Iter:     26/2499940 | global iter:     14/1249970 | loss: 2.2013 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 524288.0000 | micro time: 0.311 | step time: 0.000
[2025-04-20 16:05:28,616] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 524288, reducing to 262144
train | epoch   0 | Iter:     28/2499940 | global iter:     15/1249970 | loss: 1.9918 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 262144.0000 | micro time: 0.315 | step time: 0.000
[2025-04-20 16:05:29,214] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 262144, reducing to 131072
train | epoch   0 | Iter:     30/2499940 | global iter:     16/1249970 | loss: 2.3406 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 131072.0000 | micro time: 0.308 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     30/2499940 | global iter:     16/1249970 | loss: 2.4664 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 131072.0000 | micro time: 0.308 | step time: 0.601
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
[2025-04-20 16:05:29,816] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 131072, reducing to 65536
train | epoch   0 | Iter:     32/2499940 | global iter:     17/1249970 | loss: 2.0630 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 65536.0000 | micro time: 0.311 | step time: 0.000
[2025-04-20 16:05:30,418] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768
train | epoch   0 | Iter:     34/2499940 | global iter:     18/1249970 | loss: 2.1377 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 32768.0000 | micro time: 0.310 | step time: 0.000
[2025-04-20 16:05:31,018] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 32768, reducing to 16384
train | epoch   0 | Iter:     36/2499940 | global iter:     19/1249970 | loss: 1.7941 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.311 | step time: 0.000
train | epoch   0 | Iter:     38/2499940 | global iter:     20/1249970 | loss: 2.2390 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.440 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     38/2499940 | global iter:     20/1249970 | loss: 2.1956 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.440 | step time: 0.632
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:     40/2499940 | global iter:     21/1249970 | loss: 1.7357 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:     42/2499940 | global iter:     22/1249970 | loss: 1.7677 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:     44/2499940 | global iter:     23/1249970 | loss: 0.7145 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:     46/2499940 | global iter:     24/1249970 | loss: 1.1186 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     46/2499940 | global iter:     24/1249970 | loss: 1.4501 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:     48/2499940 | global iter:     25/1249970 | loss: 0.4290 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:     50/2499940 | global iter:     26/1249970 | loss: 1.8131 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:     52/2499940 | global iter:     27/1249970 | loss: 1.4060 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:     54/2499940 | global iter:     28/1249970 | loss: 1.4880 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     54/2499940 | global iter:     28/1249970 | loss: 1.2829 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:     56/2499940 | global iter:     29/1249970 | loss: 1.0900 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:     58/2499940 | global iter:     30/1249970 | loss: 1.5622 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:     60/2499940 | global iter:     31/1249970 | loss: 1.1049 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:     62/2499940 | global iter:     32/1249970 | loss: 1.1426 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     62/2499940 | global iter:     32/1249970 | loss: 1.2119 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:     64/2499940 | global iter:     33/1249970 | loss: 1.0171 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:     66/2499940 | global iter:     34/1249970 | loss: 1.2407 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:     68/2499940 | global iter:     35/1249970 | loss: 1.5833 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:     70/2499940 | global iter:     36/1249970 | loss: 1.5181 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     70/2499940 | global iter:     36/1249970 | loss: 1.4692 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:     72/2499940 | global iter:     37/1249970 | loss: 0.6648 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:     74/2499940 | global iter:     38/1249970 | loss: 1.2952 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:     76/2499940 | global iter:     39/1249970 | loss: 1.8508 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:     78/2499940 | global iter:     40/1249970 | loss: 1.0725 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     78/2499940 | global iter:     40/1249970 | loss: 1.3378 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.398 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:     80/2499940 | global iter:     41/1249970 | loss: 0.5559 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:     82/2499940 | global iter:     42/1249970 | loss: 1.1086 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:     84/2499940 | global iter:     43/1249970 | loss: 1.7788 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:     86/2499940 | global iter:     44/1249970 | loss: 1.7500 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     86/2499940 | global iter:     44/1249970 | loss: 1.2759 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.395 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:     88/2499940 | global iter:     45/1249970 | loss: 1.9028 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:     90/2499940 | global iter:     46/1249970 | loss: 1.2532 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:     92/2499940 | global iter:     47/1249970 | loss: 1.1784 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.416 | step time: 0.000
train | epoch   0 | Iter:     94/2499940 | global iter:     48/1249970 | loss: 1.8491 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     94/2499940 | global iter:     48/1249970 | loss: 1.4801 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.397 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:     96/2499940 | global iter:     49/1249970 | loss: 1.0453 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:     98/2499940 | global iter:     50/1249970 | loss: 1.3696 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    100/2499940 | global iter:     51/1249970 | loss: 1.2525 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    102/2499940 | global iter:     52/1249970 | loss: 2.1225 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    102/2499940 | global iter:     52/1249970 | loss: 1.3004 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    104/2499940 | global iter:     53/1249970 | loss: 1.4123 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    106/2499940 | global iter:     54/1249970 | loss: 1.5733 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:    108/2499940 | global iter:     55/1249970 | loss: 1.4321 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    110/2499940 | global iter:     56/1249970 | loss: 1.9112 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    110/2499940 | global iter:     56/1249970 | loss: 1.2741 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    112/2499940 | global iter:     57/1249970 | loss: 2.0290 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    114/2499940 | global iter:     58/1249970 | loss: 0.5570 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    116/2499940 | global iter:     59/1249970 | loss: 1.7158 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    118/2499940 | global iter:     60/1249970 | loss: 1.8205 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    118/2499940 | global iter:     60/1249970 | loss: 1.2960 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale: 16384.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
[2025-04-20 16:06:00,047] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16384, reducing to 8192
train | epoch   0 | Iter:    120/2499940 | global iter:     61/1249970 | loss: 1.5364 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.312 | step time: 0.000
train | epoch   0 | Iter:    122/2499940 | global iter:     62/1249970 | loss: 1.5769 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    124/2499940 | global iter:     63/1249970 | loss: 1.5155 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    126/2499940 | global iter:     64/1249970 | loss: 0.7513 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    126/2499940 | global iter:     64/1249970 | loss: 1.0516 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.669
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    128/2499940 | global iter:     65/1249970 | loss: 1.5042 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    130/2499940 | global iter:     66/1249970 | loss: 0.7085 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    132/2499940 | global iter:     67/1249970 | loss: 0.9697 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    134/2499940 | global iter:     68/1249970 | loss: 1.2083 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    134/2499940 | global iter:     68/1249970 | loss: 1.4331 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    136/2499940 | global iter:     69/1249970 | loss: 1.1613 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    138/2499940 | global iter:     70/1249970 | loss: 1.2479 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    140/2499940 | global iter:     71/1249970 | loss: 1.7375 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    142/2499940 | global iter:     72/1249970 | loss: 1.4262 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    142/2499940 | global iter:     72/1249970 | loss: 1.0797 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    144/2499940 | global iter:     73/1249970 | loss: 1.9320 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    146/2499940 | global iter:     74/1249970 | loss: 0.5898 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    148/2499940 | global iter:     75/1249970 | loss: 0.9986 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    150/2499940 | global iter:     76/1249970 | loss: 1.3272 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    150/2499940 | global iter:     76/1249970 | loss: 1.3333 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    152/2499940 | global iter:     77/1249970 | loss: 1.4757 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    154/2499940 | global iter:     78/1249970 | loss: 1.2841 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:    156/2499940 | global iter:     79/1249970 | loss: 1.3610 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    158/2499940 | global iter:     80/1249970 | loss: 1.2574 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    158/2499940 | global iter:     80/1249970 | loss: 1.2731 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    160/2499940 | global iter:     81/1249970 | loss: 1.7053 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    162/2499940 | global iter:     82/1249970 | loss: 1.3977 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    164/2499940 | global iter:     83/1249970 | loss: 1.1956 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    166/2499940 | global iter:     84/1249970 | loss: 1.6134 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    166/2499940 | global iter:     84/1249970 | loss: 1.5417 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    168/2499940 | global iter:     85/1249970 | loss: 1.4348 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    170/2499940 | global iter:     86/1249970 | loss: 0.6876 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:    172/2499940 | global iter:     87/1249970 | loss: 1.3587 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    174/2499940 | global iter:     88/1249970 | loss: 1.0446 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    174/2499940 | global iter:     88/1249970 | loss: 1.2334 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    176/2499940 | global iter:     89/1249970 | loss: 1.0964 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    178/2499940 | global iter:     90/1249970 | loss: 1.2525 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:    180/2499940 | global iter:     91/1249970 | loss: 1.3132 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    182/2499940 | global iter:     92/1249970 | loss: 1.6310 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    182/2499940 | global iter:     92/1249970 | loss: 1.4367 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    184/2499940 | global iter:     93/1249970 | loss: 1.1463 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    186/2499940 | global iter:     94/1249970 | loss: 2.0207 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    188/2499940 | global iter:     95/1249970 | loss: 0.4619 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    190/2499940 | global iter:     96/1249970 | loss: 0.7023 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    190/2499940 | global iter:     96/1249970 | loss: 0.9817 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.395 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    192/2499940 | global iter:     97/1249970 | loss: 1.3219 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    194/2499940 | global iter:     98/1249970 | loss: 1.2774 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    196/2499940 | global iter:     99/1249970 | loss: 1.6949 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    198/2499940 | global iter:    100/1249970 | loss: 1.0470 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.392 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    198/2499940 | global iter:    100/1249970 | loss: 1.2720 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.392 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    200/2499940 | global iter:    101/1249970 | loss: 0.9940 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    202/2499940 | global iter:    102/1249970 | loss: 1.7838 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    204/2499940 | global iter:    103/1249970 | loss: 1.7342 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    206/2499940 | global iter:    104/1249970 | loss: 1.2012 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    206/2499940 | global iter:    104/1249970 | loss: 1.2800 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    208/2499940 | global iter:    105/1249970 | loss: 1.9112 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    210/2499940 | global iter:    106/1249970 | loss: 1.2802 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    212/2499940 | global iter:    107/1249970 | loss: 1.1031 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    214/2499940 | global iter:    108/1249970 | loss: 1.3697 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    214/2499940 | global iter:    108/1249970 | loss: 1.3671 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    216/2499940 | global iter:    109/1249970 | loss: 0.4927 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    218/2499940 | global iter:    110/1249970 | loss: 0.6944 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    220/2499940 | global iter:    111/1249970 | loss: 1.1200 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    222/2499940 | global iter:    112/1249970 | loss: 0.7357 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    222/2499940 | global iter:    112/1249970 | loss: 0.9042 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    224/2499940 | global iter:    113/1249970 | loss: 1.3372 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    226/2499940 | global iter:    114/1249970 | loss: 1.6332 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    228/2499940 | global iter:    115/1249970 | loss: 1.1756 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    230/2499940 | global iter:    116/1249970 | loss: 1.4991 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    230/2499940 | global iter:    116/1249970 | loss: 1.2946 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    232/2499940 | global iter:    117/1249970 | loss: 1.0935 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    234/2499940 | global iter:    118/1249970 | loss: 1.4157 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    236/2499940 | global iter:    119/1249970 | loss: 1.1843 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    238/2499940 | global iter:    120/1249970 | loss: 1.3415 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    238/2499940 | global iter:    120/1249970 | loss: 1.2374 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.393 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    240/2499940 | global iter:    121/1249970 | loss: 1.7343 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    242/2499940 | global iter:    122/1249970 | loss: 1.2461 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    244/2499940 | global iter:    123/1249970 | loss: 0.7092 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    246/2499940 | global iter:    124/1249970 | loss: 1.6777 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    246/2499940 | global iter:    124/1249970 | loss: 1.3421 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    248/2499940 | global iter:    125/1249970 | loss: 1.0568 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    250/2499940 | global iter:    126/1249970 | loss: 1.0498 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    252/2499940 | global iter:    127/1249970 | loss: 1.3647 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    254/2499940 | global iter:    128/1249970 | loss: 0.8606 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    254/2499940 | global iter:    128/1249970 | loss: 1.1083 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    256/2499940 | global iter:    129/1249970 | loss: 1.2122 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    258/2499940 | global iter:    130/1249970 | loss: 0.5538 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:    260/2499940 | global iter:    131/1249970 | loss: 1.9158 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    262/2499940 | global iter:    132/1249970 | loss: 1.5503 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    262/2499940 | global iter:    132/1249970 | loss: 1.1533 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    264/2499940 | global iter:    133/1249970 | loss: 1.0107 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    266/2499940 | global iter:    134/1249970 | loss: 0.4907 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    268/2499940 | global iter:    135/1249970 | loss: 1.5003 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    270/2499940 | global iter:    136/1249970 | loss: 1.1423 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    270/2499940 | global iter:    136/1249970 | loss: 1.0865 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.695
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    272/2499940 | global iter:    137/1249970 | loss: 1.1672 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    274/2499940 | global iter:    138/1249970 | loss: 1.3441 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    276/2499940 | global iter:    139/1249970 | loss: 0.3429 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    278/2499940 | global iter:    140/1249970 | loss: 0.8830 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    278/2499940 | global iter:    140/1249970 | loss: 1.0542 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    280/2499940 | global iter:    141/1249970 | loss: 1.1740 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    282/2499940 | global iter:    142/1249970 | loss: 1.2342 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    284/2499940 | global iter:    143/1249970 | loss: 1.3890 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    286/2499940 | global iter:    144/1249970 | loss: 1.7035 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    286/2499940 | global iter:    144/1249970 | loss: 1.3340 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    288/2499940 | global iter:    145/1249970 | loss: 0.3449 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    290/2499940 | global iter:    146/1249970 | loss: 0.9495 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    292/2499940 | global iter:    147/1249970 | loss: 0.9230 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    294/2499940 | global iter:    148/1249970 | loss: 0.9218 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    294/2499940 | global iter:    148/1249970 | loss: 1.0061 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    296/2499940 | global iter:    149/1249970 | loss: 0.9327 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    298/2499940 | global iter:    150/1249970 | loss: 1.4167 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    300/2499940 | global iter:    151/1249970 | loss: 1.1925 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    302/2499940 | global iter:    152/1249970 | loss: 1.1870 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    302/2499940 | global iter:    152/1249970 | loss: 1.1052 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    304/2499940 | global iter:    153/1249970 | loss: 1.2475 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    306/2499940 | global iter:    154/1249970 | loss: 1.3655 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    308/2499940 | global iter:    155/1249970 | loss: 1.3454 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    310/2499940 | global iter:    156/1249970 | loss: 0.8331 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    310/2499940 | global iter:    156/1249970 | loss: 1.1160 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    312/2499940 | global iter:    157/1249970 | loss: 1.6530 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    314/2499940 | global iter:    158/1249970 | loss: 1.1918 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    316/2499940 | global iter:    159/1249970 | loss: 1.0316 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    318/2499940 | global iter:    160/1249970 | loss: 1.6297 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    318/2499940 | global iter:    160/1249970 | loss: 1.4042 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    320/2499940 | global iter:    161/1249970 | loss: 0.9638 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    322/2499940 | global iter:    162/1249970 | loss: 0.8018 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    324/2499940 | global iter:    163/1249970 | loss: 1.0368 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    326/2499940 | global iter:    164/1249970 | loss: 0.9729 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    326/2499940 | global iter:    164/1249970 | loss: 1.0554 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    328/2499940 | global iter:    165/1249970 | loss: 0.8435 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    330/2499940 | global iter:    166/1249970 | loss: 1.0390 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    332/2499940 | global iter:    167/1249970 | loss: 0.7843 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    334/2499940 | global iter:    168/1249970 | loss: 0.5497 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    334/2499940 | global iter:    168/1249970 | loss: 0.9120 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    336/2499940 | global iter:    169/1249970 | loss: 1.2350 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    338/2499940 | global iter:    170/1249970 | loss: 1.2317 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    340/2499940 | global iter:    171/1249970 | loss: 1.7480 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    342/2499940 | global iter:    172/1249970 | loss: 0.6620 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    342/2499940 | global iter:    172/1249970 | loss: 1.2949 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    344/2499940 | global iter:    173/1249970 | loss: 0.6588 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    346/2499940 | global iter:    174/1249970 | loss: 1.3914 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    348/2499940 | global iter:    175/1249970 | loss: 1.7238 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    350/2499940 | global iter:    176/1249970 | loss: 1.0870 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    350/2499940 | global iter:    176/1249970 | loss: 1.3004 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    352/2499940 | global iter:    177/1249970 | loss: 0.8303 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:    354/2499940 | global iter:    178/1249970 | loss: 2.0658 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    356/2499940 | global iter:    179/1249970 | loss: 1.1871 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    358/2499940 | global iter:    180/1249970 | loss: 1.2593 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    358/2499940 | global iter:    180/1249970 | loss: 1.1511 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    360/2499940 | global iter:    181/1249970 | loss: 0.8454 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    362/2499940 | global iter:    182/1249970 | loss: 1.0554 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:    364/2499940 | global iter:    183/1249970 | loss: 0.4589 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    366/2499940 | global iter:    184/1249970 | loss: 1.5180 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    366/2499940 | global iter:    184/1249970 | loss: 0.9579 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    368/2499940 | global iter:    185/1249970 | loss: 2.0989 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    370/2499940 | global iter:    186/1249970 | loss: 1.0822 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    372/2499940 | global iter:    187/1249970 | loss: 1.4051 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:    374/2499940 | global iter:    188/1249970 | loss: 0.7842 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    374/2499940 | global iter:    188/1249970 | loss: 1.2657 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    376/2499940 | global iter:    189/1249970 | loss: 1.4799 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    378/2499940 | global iter:    190/1249970 | loss: 0.5108 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    380/2499940 | global iter:    191/1249970 | loss: 1.7709 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    382/2499940 | global iter:    192/1249970 | loss: 1.2409 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    382/2499940 | global iter:    192/1249970 | loss: 1.1275 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    384/2499940 | global iter:    193/1249970 | loss: 1.1370 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    386/2499940 | global iter:    194/1249970 | loss: 1.3694 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    388/2499940 | global iter:    195/1249970 | loss: 0.9028 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    390/2499940 | global iter:    196/1249970 | loss: 1.9651 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    390/2499940 | global iter:    196/1249970 | loss: 1.3087 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    392/2499940 | global iter:    197/1249970 | loss: 0.7825 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:    394/2499940 | global iter:    198/1249970 | loss: 0.6194 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    396/2499940 | global iter:    199/1249970 | loss: 1.1477 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    398/2499940 | global iter:    200/1249970 | loss: 1.3094 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    398/2499940 | global iter:    200/1249970 | loss: 1.2209 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    400/2499940 | global iter:    201/1249970 | loss: 1.3225 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    402/2499940 | global iter:    202/1249970 | loss: 0.7298 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:    404/2499940 | global iter:    203/1249970 | loss: 1.1788 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    406/2499940 | global iter:    204/1249970 | loss: 0.6616 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    406/2499940 | global iter:    204/1249970 | loss: 0.9678 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    408/2499940 | global iter:    205/1249970 | loss: 1.4989 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    410/2499940 | global iter:    206/1249970 | loss: 0.6026 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    412/2499940 | global iter:    207/1249970 | loss: 0.9835 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    414/2499940 | global iter:    208/1249970 | loss: 0.6909 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    414/2499940 | global iter:    208/1249970 | loss: 0.9782 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    416/2499940 | global iter:    209/1249970 | loss: 0.5368 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    418/2499940 | global iter:    210/1249970 | loss: 1.2447 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    420/2499940 | global iter:    211/1249970 | loss: 0.6899 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    422/2499940 | global iter:    212/1249970 | loss: 1.1854 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    422/2499940 | global iter:    212/1249970 | loss: 0.9571 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    424/2499940 | global iter:    213/1249970 | loss: 1.3272 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    426/2499940 | global iter:    214/1249970 | loss: 1.4560 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    428/2499940 | global iter:    215/1249970 | loss: 1.9783 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    430/2499940 | global iter:    216/1249970 | loss: 1.0802 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    430/2499940 | global iter:    216/1249970 | loss: 1.4134 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    432/2499940 | global iter:    217/1249970 | loss: 0.7090 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    434/2499940 | global iter:    218/1249970 | loss: 0.7223 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    436/2499940 | global iter:    219/1249970 | loss: 1.5808 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    438/2499940 | global iter:    220/1249970 | loss: 0.5367 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    438/2499940 | global iter:    220/1249970 | loss: 1.0739 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    440/2499940 | global iter:    221/1249970 | loss: 1.2614 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    442/2499940 | global iter:    222/1249970 | loss: 0.6760 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    444/2499940 | global iter:    223/1249970 | loss: 1.1025 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    446/2499940 | global iter:    224/1249970 | loss: 1.2048 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    446/2499940 | global iter:    224/1249970 | loss: 1.1439 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    448/2499940 | global iter:    225/1249970 | loss: 1.3257 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    450/2499940 | global iter:    226/1249970 | loss: 1.1281 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    452/2499940 | global iter:    227/1249970 | loss: 0.9364 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    454/2499940 | global iter:    228/1249970 | loss: 1.2008 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    454/2499940 | global iter:    228/1249970 | loss: 1.1769 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    456/2499940 | global iter:    229/1249970 | loss: 1.3832 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    458/2499940 | global iter:    230/1249970 | loss: 1.3930 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    460/2499940 | global iter:    231/1249970 | loss: 0.9331 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    462/2499940 | global iter:    232/1249970 | loss: 0.3050 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    462/2499940 | global iter:    232/1249970 | loss: 1.1324 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    464/2499940 | global iter:    233/1249970 | loss: 1.5972 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    466/2499940 | global iter:    234/1249970 | loss: 0.5189 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    468/2499940 | global iter:    235/1249970 | loss: 1.3677 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    470/2499940 | global iter:    236/1249970 | loss: 0.9038 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    470/2499940 | global iter:    236/1249970 | loss: 1.1998 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    472/2499940 | global iter:    237/1249970 | loss: 1.6133 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    474/2499940 | global iter:    238/1249970 | loss: 0.9236 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    476/2499940 | global iter:    239/1249970 | loss: 0.7426 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    478/2499940 | global iter:    240/1249970 | loss: 1.3054 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    478/2499940 | global iter:    240/1249970 | loss: 1.1831 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    480/2499940 | global iter:    241/1249970 | loss: 1.4550 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    482/2499940 | global iter:    242/1249970 | loss: 0.5063 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    484/2499940 | global iter:    243/1249970 | loss: 1.0793 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    486/2499940 | global iter:    244/1249970 | loss: 1.1227 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    486/2499940 | global iter:    244/1249970 | loss: 1.0743 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    488/2499940 | global iter:    245/1249970 | loss: 0.9875 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    490/2499940 | global iter:    246/1249970 | loss: 0.7703 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    492/2499940 | global iter:    247/1249970 | loss: 1.0017 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    494/2499940 | global iter:    248/1249970 | loss: 1.6810 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    494/2499940 | global iter:    248/1249970 | loss: 1.3279 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    496/2499940 | global iter:    249/1249970 | loss: 1.5539 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    498/2499940 | global iter:    250/1249970 | loss: 0.5207 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:    500/2499940 | global iter:    251/1249970 | loss: 1.2634 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    502/2499940 | global iter:    252/1249970 | loss: 1.6807 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    502/2499940 | global iter:    252/1249970 | loss: 1.3121 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    504/2499940 | global iter:    253/1249970 | loss: 0.8823 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    506/2499940 | global iter:    254/1249970 | loss: 1.5301 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    508/2499940 | global iter:    255/1249970 | loss: 0.6598 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    510/2499940 | global iter:    256/1249970 | loss: 0.9731 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    510/2499940 | global iter:    256/1249970 | loss: 1.0419 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    512/2499940 | global iter:    257/1249970 | loss: 1.1737 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    514/2499940 | global iter:    258/1249970 | loss: 1.2122 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    516/2499940 | global iter:    259/1249970 | loss: 2.2157 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    518/2499940 | global iter:    260/1249970 | loss: 1.4014 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    518/2499940 | global iter:    260/1249970 | loss: 1.1178 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    520/2499940 | global iter:    261/1249970 | loss: 1.2653 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    522/2499940 | global iter:    262/1249970 | loss: 1.8074 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    524/2499940 | global iter:    263/1249970 | loss: 0.5468 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    526/2499940 | global iter:    264/1249970 | loss: 1.2398 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    526/2499940 | global iter:    264/1249970 | loss: 1.2270 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    528/2499940 | global iter:    265/1249970 | loss: 0.8198 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    530/2499940 | global iter:    266/1249970 | loss: 1.1186 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    532/2499940 | global iter:    267/1249970 | loss: 0.3039 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    534/2499940 | global iter:    268/1249970 | loss: 1.3080 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    534/2499940 | global iter:    268/1249970 | loss: 1.0414 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    536/2499940 | global iter:    269/1249970 | loss: 1.6148 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    538/2499940 | global iter:    270/1249970 | loss: 2.1156 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    540/2499940 | global iter:    271/1249970 | loss: 1.0978 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    542/2499940 | global iter:    272/1249970 | loss: 1.3086 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    542/2499940 | global iter:    272/1249970 | loss: 1.1557 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    544/2499940 | global iter:    273/1249970 | loss: 1.3601 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    546/2499940 | global iter:    274/1249970 | loss: 1.2009 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    548/2499940 | global iter:    275/1249970 | loss: 1.4592 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    550/2499940 | global iter:    276/1249970 | loss: 1.2180 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    550/2499940 | global iter:    276/1249970 | loss: 1.3047 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    552/2499940 | global iter:    277/1249970 | loss: 1.0184 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    554/2499940 | global iter:    278/1249970 | loss: 1.5741 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    556/2499940 | global iter:    279/1249970 | loss: 0.6218 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    558/2499940 | global iter:    280/1249970 | loss: 1.2181 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    558/2499940 | global iter:    280/1249970 | loss: 1.0615 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    560/2499940 | global iter:    281/1249970 | loss: 0.9354 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    562/2499940 | global iter:    282/1249970 | loss: 0.8262 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:    564/2499940 | global iter:    283/1249970 | loss: 0.6257 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    566/2499940 | global iter:    284/1249970 | loss: 0.9263 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    566/2499940 | global iter:    284/1249970 | loss: 0.9287 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    568/2499940 | global iter:    285/1249970 | loss: 0.9696 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    570/2499940 | global iter:    286/1249970 | loss: 1.6408 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:    572/2499940 | global iter:    287/1249970 | loss: 0.9478 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    574/2499940 | global iter:    288/1249970 | loss: 1.1950 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    574/2499940 | global iter:    288/1249970 | loss: 1.1510 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    576/2499940 | global iter:    289/1249970 | loss: 1.1330 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    578/2499940 | global iter:    290/1249970 | loss: 1.2561 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    580/2499940 | global iter:    291/1249970 | loss: 0.9119 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    582/2499940 | global iter:    292/1249970 | loss: 1.5491 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    582/2499940 | global iter:    292/1249970 | loss: 1.1514 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    584/2499940 | global iter:    293/1249970 | loss: 1.8215 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:    586/2499940 | global iter:    294/1249970 | loss: 0.5547 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:    588/2499940 | global iter:    295/1249970 | loss: 1.3173 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    590/2499940 | global iter:    296/1249970 | loss: 0.9226 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    590/2499940 | global iter:    296/1249970 | loss: 1.1815 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    592/2499940 | global iter:    297/1249970 | loss: 0.3972 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    594/2499940 | global iter:    298/1249970 | loss: 1.0907 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    596/2499940 | global iter:    299/1249970 | loss: 1.0031 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    598/2499940 | global iter:    300/1249970 | loss: 0.8951 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    598/2499940 | global iter:    300/1249970 | loss: 1.0454 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    600/2499940 | global iter:    301/1249970 | loss: 1.3894 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    602/2499940 | global iter:    302/1249970 | loss: 1.0463 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    604/2499940 | global iter:    303/1249970 | loss: 1.7799 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    606/2499940 | global iter:    304/1249970 | loss: 1.4582 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    606/2499940 | global iter:    304/1249970 | loss: 1.4481 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    608/2499940 | global iter:    305/1249970 | loss: 1.2445 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    610/2499940 | global iter:    306/1249970 | loss: 0.6411 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:    612/2499940 | global iter:    307/1249970 | loss: 1.4067 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    614/2499940 | global iter:    308/1249970 | loss: 1.6070 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.411 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    614/2499940 | global iter:    308/1249970 | loss: 1.1567 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.411 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    616/2499940 | global iter:    309/1249970 | loss: 1.4113 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    618/2499940 | global iter:    310/1249970 | loss: 1.0517 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    620/2499940 | global iter:    311/1249970 | loss: 0.6767 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    622/2499940 | global iter:    312/1249970 | loss: 1.2137 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    622/2499940 | global iter:    312/1249970 | loss: 1.2906 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    624/2499940 | global iter:    313/1249970 | loss: 0.8128 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    626/2499940 | global iter:    314/1249970 | loss: 1.1067 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:    628/2499940 | global iter:    315/1249970 | loss: 1.5169 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    630/2499940 | global iter:    316/1249970 | loss: 0.6997 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    630/2499940 | global iter:    316/1249970 | loss: 1.1569 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    632/2499940 | global iter:    317/1249970 | loss: 0.7797 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    634/2499940 | global iter:    318/1249970 | loss: 1.0392 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:    636/2499940 | global iter:    319/1249970 | loss: 1.0401 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    638/2499940 | global iter:    320/1249970 | loss: 0.4233 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    638/2499940 | global iter:    320/1249970 | loss: 1.0556 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    640/2499940 | global iter:    321/1249970 | loss: 1.1171 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    642/2499940 | global iter:    322/1249970 | loss: 0.3044 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:    644/2499940 | global iter:    323/1249970 | loss: 0.8151 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    646/2499940 | global iter:    324/1249970 | loss: 0.7352 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    646/2499940 | global iter:    324/1249970 | loss: 0.9069 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    648/2499940 | global iter:    325/1249970 | loss: 1.8679 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    650/2499940 | global iter:    326/1249970 | loss: 0.5264 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    652/2499940 | global iter:    327/1249970 | loss: 0.7806 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    654/2499940 | global iter:    328/1249970 | loss: 0.7519 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    654/2499940 | global iter:    328/1249970 | loss: 1.3033 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    656/2499940 | global iter:    329/1249970 | loss: 0.8325 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    658/2499940 | global iter:    330/1249970 | loss: 1.4394 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    660/2499940 | global iter:    331/1249970 | loss: 1.0075 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    662/2499940 | global iter:    332/1249970 | loss: 1.4717 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    662/2499940 | global iter:    332/1249970 | loss: 1.1529 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.394 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    664/2499940 | global iter:    333/1249970 | loss: 0.6075 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    666/2499940 | global iter:    334/1249970 | loss: 0.8493 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    668/2499940 | global iter:    335/1249970 | loss: 0.0897 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    670/2499940 | global iter:    336/1249970 | loss: 1.3669 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    670/2499940 | global iter:    336/1249970 | loss: 1.0205 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    672/2499940 | global iter:    337/1249970 | loss: 0.9736 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    674/2499940 | global iter:    338/1249970 | loss: 1.6684 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    676/2499940 | global iter:    339/1249970 | loss: 1.7489 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    678/2499940 | global iter:    340/1249970 | loss: 1.2019 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    678/2499940 | global iter:    340/1249970 | loss: 1.3355 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    680/2499940 | global iter:    341/1249970 | loss: 1.0892 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    682/2499940 | global iter:    342/1249970 | loss: 1.4456 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:    684/2499940 | global iter:    343/1249970 | loss: 1.5464 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    686/2499940 | global iter:    344/1249970 | loss: 1.0801 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    686/2499940 | global iter:    344/1249970 | loss: 1.2246 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    688/2499940 | global iter:    345/1249970 | loss: 1.7557 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    690/2499940 | global iter:    346/1249970 | loss: 1.1156 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    692/2499940 | global iter:    347/1249970 | loss: 1.5411 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    694/2499940 | global iter:    348/1249970 | loss: 1.7460 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    694/2499940 | global iter:    348/1249970 | loss: 1.4459 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    696/2499940 | global iter:    349/1249970 | loss: 0.5467 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:    698/2499940 | global iter:    350/1249970 | loss: 1.7219 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:    700/2499940 | global iter:    351/1249970 | loss: 0.9481 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    702/2499940 | global iter:    352/1249970 | loss: 1.6392 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    702/2499940 | global iter:    352/1249970 | loss: 1.1527 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    704/2499940 | global iter:    353/1249970 | loss: 1.7243 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    706/2499940 | global iter:    354/1249970 | loss: 0.7259 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    708/2499940 | global iter:    355/1249970 | loss: 0.9255 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    710/2499940 | global iter:    356/1249970 | loss: 1.0500 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    710/2499940 | global iter:    356/1249970 | loss: 0.9573 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    712/2499940 | global iter:    357/1249970 | loss: 1.5422 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    714/2499940 | global iter:    358/1249970 | loss: 0.8730 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    716/2499940 | global iter:    359/1249970 | loss: 1.1497 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    718/2499940 | global iter:    360/1249970 | loss: 1.7066 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    718/2499940 | global iter:    360/1249970 | loss: 1.2555 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    720/2499940 | global iter:    361/1249970 | loss: 1.5516 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    722/2499940 | global iter:    362/1249970 | loss: 1.0710 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
[2025-04-20 16:09:28,955] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8192, reducing to 4096
train | epoch   0 | Iter:    724/2499940 | global iter:    363/1249970 | loss: 1.3780 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.312 | step time: 0.000
train | epoch   0 | Iter:    726/2499940 | global iter:    364/1249970 | loss: 1.4314 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    726/2499940 | global iter:    364/1249970 | loss: 1.3723 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.668
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    728/2499940 | global iter:    365/1249970 | loss: 0.9843 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    730/2499940 | global iter:    366/1249970 | loss: 0.9318 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    732/2499940 | global iter:    367/1249970 | loss: 1.0937 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    734/2499940 | global iter:    368/1249970 | loss: 1.3775 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    734/2499940 | global iter:    368/1249970 | loss: 1.3309 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    736/2499940 | global iter:    369/1249970 | loss: 0.8305 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    738/2499940 | global iter:    370/1249970 | loss: 0.7087 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    740/2499940 | global iter:    371/1249970 | loss: 0.8004 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:    742/2499940 | global iter:    372/1249970 | loss: 1.0880 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    742/2499940 | global iter:    372/1249970 | loss: 1.0364 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    744/2499940 | global iter:    373/1249970 | loss: 1.7610 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    746/2499940 | global iter:    374/1249970 | loss: 1.2857 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    748/2499940 | global iter:    375/1249970 | loss: 1.5761 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:    750/2499940 | global iter:    376/1249970 | loss: 1.0098 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    750/2499940 | global iter:    376/1249970 | loss: 1.4694 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    752/2499940 | global iter:    377/1249970 | loss: 0.6316 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:    754/2499940 | global iter:    378/1249970 | loss: 1.1142 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:    756/2499940 | global iter:    379/1249970 | loss: 1.1574 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    758/2499940 | global iter:    380/1249970 | loss: 1.9515 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    758/2499940 | global iter:    380/1249970 | loss: 1.2461 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    760/2499940 | global iter:    381/1249970 | loss: 1.1363 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    762/2499940 | global iter:    382/1249970 | loss: 0.9048 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    764/2499940 | global iter:    383/1249970 | loss: 0.9753 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:    766/2499940 | global iter:    384/1249970 | loss: 1.8341 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    766/2499940 | global iter:    384/1249970 | loss: 1.1665 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    768/2499940 | global iter:    385/1249970 | loss: 1.2358 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    770/2499940 | global iter:    386/1249970 | loss: 1.4988 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:    772/2499940 | global iter:    387/1249970 | loss: 0.8526 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    774/2499940 | global iter:    388/1249970 | loss: 1.6087 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    774/2499940 | global iter:    388/1249970 | loss: 1.1578 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    776/2499940 | global iter:    389/1249970 | loss: 1.0940 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    778/2499940 | global iter:    390/1249970 | loss: 1.1696 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    780/2499940 | global iter:    391/1249970 | loss: 1.6979 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    782/2499940 | global iter:    392/1249970 | loss: 1.4858 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    782/2499940 | global iter:    392/1249970 | loss: 1.3429 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    784/2499940 | global iter:    393/1249970 | loss: 0.7296 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    786/2499940 | global iter:    394/1249970 | loss: 1.4873 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:    788/2499940 | global iter:    395/1249970 | loss: 1.1304 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:    790/2499940 | global iter:    396/1249970 | loss: 1.4343 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    790/2499940 | global iter:    396/1249970 | loss: 1.2732 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    792/2499940 | global iter:    397/1249970 | loss: 0.4410 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    794/2499940 | global iter:    398/1249970 | loss: 1.4662 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    796/2499940 | global iter:    399/1249970 | loss: 1.2515 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    798/2499940 | global iter:    400/1249970 | loss: 1.2144 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    798/2499940 | global iter:    400/1249970 | loss: 1.3180 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    800/2499940 | global iter:    401/1249970 | loss: 1.5206 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    802/2499940 | global iter:    402/1249970 | loss: 1.2094 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:    804/2499940 | global iter:    403/1249970 | loss: 1.2002 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    806/2499940 | global iter:    404/1249970 | loss: 1.8238 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    806/2499940 | global iter:    404/1249970 | loss: 1.1598 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    808/2499940 | global iter:    405/1249970 | loss: 0.5103 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    810/2499940 | global iter:    406/1249970 | loss: 0.5156 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    812/2499940 | global iter:    407/1249970 | loss: 1.4520 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:    814/2499940 | global iter:    408/1249970 | loss: 1.0298 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    814/2499940 | global iter:    408/1249970 | loss: 1.0663 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    816/2499940 | global iter:    409/1249970 | loss: 1.0257 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    818/2499940 | global iter:    410/1249970 | loss: 0.4230 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:    820/2499940 | global iter:    411/1249970 | loss: 0.8221 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    822/2499940 | global iter:    412/1249970 | loss: 1.3877 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    822/2499940 | global iter:    412/1249970 | loss: 1.2003 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    824/2499940 | global iter:    413/1249970 | loss: 1.4008 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:    826/2499940 | global iter:    414/1249970 | loss: 1.2137 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    828/2499940 | global iter:    415/1249970 | loss: 1.6558 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:    830/2499940 | global iter:    416/1249970 | loss: 1.0516 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    830/2499940 | global iter:    416/1249970 | loss: 1.2433 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    832/2499940 | global iter:    417/1249970 | loss: 0.7108 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    834/2499940 | global iter:    418/1249970 | loss: 1.7863 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    836/2499940 | global iter:    419/1249970 | loss: 1.0029 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    838/2499940 | global iter:    420/1249970 | loss: 1.2317 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    838/2499940 | global iter:    420/1249970 | loss: 1.2808 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    840/2499940 | global iter:    421/1249970 | loss: 1.3462 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    842/2499940 | global iter:    422/1249970 | loss: 1.6004 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    844/2499940 | global iter:    423/1249970 | loss: 0.3733 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    846/2499940 | global iter:    424/1249970 | loss: 2.0612 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    846/2499940 | global iter:    424/1249970 | loss: 1.4668 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    848/2499940 | global iter:    425/1249970 | loss: 0.8282 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    850/2499940 | global iter:    426/1249970 | loss: 0.6151 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:    852/2499940 | global iter:    427/1249970 | loss: 1.3814 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    854/2499940 | global iter:    428/1249970 | loss: 1.3069 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    854/2499940 | global iter:    428/1249970 | loss: 1.0699 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    856/2499940 | global iter:    429/1249970 | loss: 0.8907 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:    858/2499940 | global iter:    430/1249970 | loss: 1.6011 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    860/2499940 | global iter:    431/1249970 | loss: 1.3364 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    862/2499940 | global iter:    432/1249970 | loss: 0.9009 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    862/2499940 | global iter:    432/1249970 | loss: 1.2124 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    864/2499940 | global iter:    433/1249970 | loss: 0.7112 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    866/2499940 | global iter:    434/1249970 | loss: 1.4186 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:    868/2499940 | global iter:    435/1249970 | loss: 0.7315 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    870/2499940 | global iter:    436/1249970 | loss: 1.5245 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    870/2499940 | global iter:    436/1249970 | loss: 0.9821 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    872/2499940 | global iter:    437/1249970 | loss: 0.6920 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.405 | step time: 0.000
train | epoch   0 | Iter:    874/2499940 | global iter:    438/1249970 | loss: 1.8640 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    876/2499940 | global iter:    439/1249970 | loss: 1.1519 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    878/2499940 | global iter:    440/1249970 | loss: 0.8216 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    878/2499940 | global iter:    440/1249970 | loss: 1.1244 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    880/2499940 | global iter:    441/1249970 | loss: 0.7535 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    882/2499940 | global iter:    442/1249970 | loss: 0.8191 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    884/2499940 | global iter:    443/1249970 | loss: 1.3716 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:    886/2499940 | global iter:    444/1249970 | loss: 0.8592 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    886/2499940 | global iter:    444/1249970 | loss: 1.0477 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    888/2499940 | global iter:    445/1249970 | loss: 1.2495 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    890/2499940 | global iter:    446/1249970 | loss: 1.0005 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    892/2499940 | global iter:    447/1249970 | loss: 1.6472 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    894/2499940 | global iter:    448/1249970 | loss: 0.5988 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    894/2499940 | global iter:    448/1249970 | loss: 1.1994 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    896/2499940 | global iter:    449/1249970 | loss: 1.2749 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    898/2499940 | global iter:    450/1249970 | loss: 1.1242 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    900/2499940 | global iter:    451/1249970 | loss: 1.5586 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    902/2499940 | global iter:    452/1249970 | loss: 0.7630 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    902/2499940 | global iter:    452/1249970 | loss: 0.9500 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    904/2499940 | global iter:    453/1249970 | loss: 1.8546 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:    906/2499940 | global iter:    454/1249970 | loss: 0.5479 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    908/2499940 | global iter:    455/1249970 | loss: 0.7147 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    910/2499940 | global iter:    456/1249970 | loss: 1.8807 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    910/2499940 | global iter:    456/1249970 | loss: 1.3350 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    912/2499940 | global iter:    457/1249970 | loss: 0.8709 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    914/2499940 | global iter:    458/1249970 | loss: 0.1192 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    916/2499940 | global iter:    459/1249970 | loss: 0.5915 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    918/2499940 | global iter:    460/1249970 | loss: 0.7485 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    918/2499940 | global iter:    460/1249970 | loss: 0.9907 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    920/2499940 | global iter:    461/1249970 | loss: 1.2210 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    922/2499940 | global iter:    462/1249970 | loss: 1.9121 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:    924/2499940 | global iter:    463/1249970 | loss: 1.2903 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    926/2499940 | global iter:    464/1249970 | loss: 0.9839 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    926/2499940 | global iter:    464/1249970 | loss: 1.5383 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    928/2499940 | global iter:    465/1249970 | loss: 1.5819 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    930/2499940 | global iter:    466/1249970 | loss: 0.7554 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    932/2499940 | global iter:    467/1249970 | loss: 0.5445 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:    934/2499940 | global iter:    468/1249970 | loss: 1.6866 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    934/2499940 | global iter:    468/1249970 | loss: 1.1885 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    936/2499940 | global iter:    469/1249970 | loss: 1.3685 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:    938/2499940 | global iter:    470/1249970 | loss: 1.4325 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    940/2499940 | global iter:    471/1249970 | loss: 0.7196 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:    942/2499940 | global iter:    472/1249970 | loss: 1.5216 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    942/2499940 | global iter:    472/1249970 | loss: 1.3344 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    944/2499940 | global iter:    473/1249970 | loss: 2.3160 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:    946/2499940 | global iter:    474/1249970 | loss: 1.0130 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    948/2499940 | global iter:    475/1249970 | loss: 1.0809 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:    950/2499940 | global iter:    476/1249970 | loss: 1.8299 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    950/2499940 | global iter:    476/1249970 | loss: 1.3687 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    952/2499940 | global iter:    477/1249970 | loss: 0.8169 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    954/2499940 | global iter:    478/1249970 | loss: 0.5856 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    956/2499940 | global iter:    479/1249970 | loss: 1.7230 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:    958/2499940 | global iter:    480/1249970 | loss: 1.3880 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    958/2499940 | global iter:    480/1249970 | loss: 1.1837 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    960/2499940 | global iter:    481/1249970 | loss: 1.2964 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    962/2499940 | global iter:    482/1249970 | loss: 1.3180 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    964/2499940 | global iter:    483/1249970 | loss: 1.4265 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    966/2499940 | global iter:    484/1249970 | loss: 1.3586 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    966/2499940 | global iter:    484/1249970 | loss: 1.3541 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    968/2499940 | global iter:    485/1249970 | loss: 1.1104 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    970/2499940 | global iter:    486/1249970 | loss: 1.8320 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:    972/2499940 | global iter:    487/1249970 | loss: 1.6317 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:    974/2499940 | global iter:    488/1249970 | loss: 0.9748 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    974/2499940 | global iter:    488/1249970 | loss: 1.0798 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    976/2499940 | global iter:    489/1249970 | loss: 1.0417 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:    978/2499940 | global iter:    490/1249970 | loss: 1.1345 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:    980/2499940 | global iter:    491/1249970 | loss: 1.4876 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:    982/2499940 | global iter:    492/1249970 | loss: 1.2980 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    982/2499940 | global iter:    492/1249970 | loss: 1.3448 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    984/2499940 | global iter:    493/1249970 | loss: 1.4834 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:    986/2499940 | global iter:    494/1249970 | loss: 1.4790 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:    988/2499940 | global iter:    495/1249970 | loss: 0.2431 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    990/2499940 | global iter:    496/1249970 | loss: 0.8648 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    990/2499940 | global iter:    496/1249970 | loss: 1.0607 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:    992/2499940 | global iter:    497/1249970 | loss: 1.8474 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    994/2499940 | global iter:    498/1249970 | loss: 0.9004 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:    996/2499940 | global iter:    499/1249970 | loss: 0.7516 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:    998/2499940 | global iter:    500/1249970 | loss: 0.7368 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    998/2499940 | global iter:    500/1249970 | loss: 1.1428 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1000/2499940 | global iter:    501/1249970 | loss: 1.1748 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1002/2499940 | global iter:    502/1249970 | loss: 0.6111 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1004/2499940 | global iter:    503/1249970 | loss: 2.0603 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   1006/2499940 | global iter:    504/1249970 | loss: 1.0983 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1006/2499940 | global iter:    504/1249970 | loss: 1.1897 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1008/2499940 | global iter:    505/1249970 | loss: 0.5528 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   1010/2499940 | global iter:    506/1249970 | loss: 0.8189 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1012/2499940 | global iter:    507/1249970 | loss: 1.3391 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   1014/2499940 | global iter:    508/1249970 | loss: 1.6632 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1014/2499940 | global iter:    508/1249970 | loss: 1.0995 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1016/2499940 | global iter:    509/1249970 | loss: 0.4958 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1018/2499940 | global iter:    510/1249970 | loss: 1.3073 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1020/2499940 | global iter:    511/1249970 | loss: 1.6407 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1022/2499940 | global iter:    512/1249970 | loss: 0.5971 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1022/2499940 | global iter:    512/1249970 | loss: 1.1486 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1024/2499940 | global iter:    513/1249970 | loss: 0.7516 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   1026/2499940 | global iter:    514/1249970 | loss: 1.1450 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1028/2499940 | global iter:    515/1249970 | loss: 1.4971 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1030/2499940 | global iter:    516/1249970 | loss: 1.5581 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1030/2499940 | global iter:    516/1249970 | loss: 1.0712 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1032/2499940 | global iter:    517/1249970 | loss: 1.0754 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1034/2499940 | global iter:    518/1249970 | loss: 1.4371 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1036/2499940 | global iter:    519/1249970 | loss: 1.1398 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1038/2499940 | global iter:    520/1249970 | loss: 0.5084 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1038/2499940 | global iter:    520/1249970 | loss: 1.0328 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1040/2499940 | global iter:    521/1249970 | loss: 1.0854 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1042/2499940 | global iter:    522/1249970 | loss: 1.2185 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1044/2499940 | global iter:    523/1249970 | loss: 0.7825 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1046/2499940 | global iter:    524/1249970 | loss: 1.2115 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.408 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1046/2499940 | global iter:    524/1249970 | loss: 1.2757 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.408 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1048/2499940 | global iter:    525/1249970 | loss: 1.0062 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1050/2499940 | global iter:    526/1249970 | loss: 0.4613 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   1052/2499940 | global iter:    527/1249970 | loss: 0.8526 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1054/2499940 | global iter:    528/1249970 | loss: 1.3698 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1054/2499940 | global iter:    528/1249970 | loss: 0.8606 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1056/2499940 | global iter:    529/1249970 | loss: 1.4260 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1058/2499940 | global iter:    530/1249970 | loss: 1.0711 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1060/2499940 | global iter:    531/1249970 | loss: 2.0117 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1062/2499940 | global iter:    532/1249970 | loss: 1.2885 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1062/2499940 | global iter:    532/1249970 | loss: 1.5028 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1064/2499940 | global iter:    533/1249970 | loss: 1.1725 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1066/2499940 | global iter:    534/1249970 | loss: 1.1687 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1068/2499940 | global iter:    535/1249970 | loss: 1.5425 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1070/2499940 | global iter:    536/1249970 | loss: 0.9131 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1070/2499940 | global iter:    536/1249970 | loss: 1.2082 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1072/2499940 | global iter:    537/1249970 | loss: 1.4147 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1074/2499940 | global iter:    538/1249970 | loss: 0.9670 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1076/2499940 | global iter:    539/1249970 | loss: 0.7720 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1078/2499940 | global iter:    540/1249970 | loss: 1.1947 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1078/2499940 | global iter:    540/1249970 | loss: 1.1858 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1080/2499940 | global iter:    541/1249970 | loss: 0.9823 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1082/2499940 | global iter:    542/1249970 | loss: 1.3372 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   1084/2499940 | global iter:    543/1249970 | loss: 0.5701 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1086/2499940 | global iter:    544/1249970 | loss: 1.2503 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1086/2499940 | global iter:    544/1249970 | loss: 1.2145 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.393 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1088/2499940 | global iter:    545/1249970 | loss: 1.0418 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1090/2499940 | global iter:    546/1249970 | loss: 1.9710 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1092/2499940 | global iter:    547/1249970 | loss: 1.7237 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1094/2499940 | global iter:    548/1249970 | loss: 0.6131 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1094/2499940 | global iter:    548/1249970 | loss: 1.1201 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1096/2499940 | global iter:    549/1249970 | loss: 1.4269 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1098/2499940 | global iter:    550/1249970 | loss: 0.8801 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1100/2499940 | global iter:    551/1249970 | loss: 1.3257 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1102/2499940 | global iter:    552/1249970 | loss: 0.7478 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1102/2499940 | global iter:    552/1249970 | loss: 1.1435 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1104/2499940 | global iter:    553/1249970 | loss: 0.8422 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1106/2499940 | global iter:    554/1249970 | loss: 0.8377 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1108/2499940 | global iter:    555/1249970 | loss: 1.3153 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1110/2499940 | global iter:    556/1249970 | loss: 1.4841 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1110/2499940 | global iter:    556/1249970 | loss: 1.2496 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1112/2499940 | global iter:    557/1249970 | loss: 1.4898 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1114/2499940 | global iter:    558/1249970 | loss: 1.1254 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1116/2499940 | global iter:    559/1249970 | loss: 0.8574 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1118/2499940 | global iter:    560/1249970 | loss: 1.1256 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1118/2499940 | global iter:    560/1249970 | loss: 1.0676 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1120/2499940 | global iter:    561/1249970 | loss: 0.5604 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   1122/2499940 | global iter:    562/1249970 | loss: 0.2468 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1124/2499940 | global iter:    563/1249970 | loss: 0.9053 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1126/2499940 | global iter:    564/1249970 | loss: 1.3067 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1126/2499940 | global iter:    564/1249970 | loss: 0.9242 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1128/2499940 | global iter:    565/1249970 | loss: 0.5138 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1130/2499940 | global iter:    566/1249970 | loss: 1.8464 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1132/2499940 | global iter:    567/1249970 | loss: 1.4298 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1134/2499940 | global iter:    568/1249970 | loss: 1.3281 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1134/2499940 | global iter:    568/1249970 | loss: 1.2486 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1136/2499940 | global iter:    569/1249970 | loss: 2.1666 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1138/2499940 | global iter:    570/1249970 | loss: 1.5241 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1140/2499940 | global iter:    571/1249970 | loss: 0.9360 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1142/2499940 | global iter:    572/1249970 | loss: 1.0739 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1142/2499940 | global iter:    572/1249970 | loss: 1.3467 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1144/2499940 | global iter:    573/1249970 | loss: 1.5752 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1146/2499940 | global iter:    574/1249970 | loss: 1.0775 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1148/2499940 | global iter:    575/1249970 | loss: 1.1420 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1150/2499940 | global iter:    576/1249970 | loss: 1.0860 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1150/2499940 | global iter:    576/1249970 | loss: 1.3631 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1152/2499940 | global iter:    577/1249970 | loss: 1.7712 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1154/2499940 | global iter:    578/1249970 | loss: 1.0781 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1156/2499940 | global iter:    579/1249970 | loss: 1.4141 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1158/2499940 | global iter:    580/1249970 | loss: 2.1445 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1158/2499940 | global iter:    580/1249970 | loss: 1.2558 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1160/2499940 | global iter:    581/1249970 | loss: 0.9409 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1162/2499940 | global iter:    582/1249970 | loss: 1.4792 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1164/2499940 | global iter:    583/1249970 | loss: 1.0001 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1166/2499940 | global iter:    584/1249970 | loss: 1.9353 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1166/2499940 | global iter:    584/1249970 | loss: 1.4865 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1168/2499940 | global iter:    585/1249970 | loss: 1.1695 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1170/2499940 | global iter:    586/1249970 | loss: 1.0133 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1172/2499940 | global iter:    587/1249970 | loss: 0.2182 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1174/2499940 | global iter:    588/1249970 | loss: 1.8354 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1174/2499940 | global iter:    588/1249970 | loss: 1.1336 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1176/2499940 | global iter:    589/1249970 | loss: 0.9389 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1178/2499940 | global iter:    590/1249970 | loss: 0.7823 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1180/2499940 | global iter:    591/1249970 | loss: 0.9548 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1182/2499940 | global iter:    592/1249970 | loss: 1.5389 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1182/2499940 | global iter:    592/1249970 | loss: 1.1560 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1184/2499940 | global iter:    593/1249970 | loss: 1.7100 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1186/2499940 | global iter:    594/1249970 | loss: 0.9150 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1188/2499940 | global iter:    595/1249970 | loss: 1.9287 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1190/2499940 | global iter:    596/1249970 | loss: 0.7414 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1190/2499940 | global iter:    596/1249970 | loss: 1.2879 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1192/2499940 | global iter:    597/1249970 | loss: 1.4123 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1194/2499940 | global iter:    598/1249970 | loss: 1.0419 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1196/2499940 | global iter:    599/1249970 | loss: 1.6282 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   1198/2499940 | global iter:    600/1249970 | loss: 1.2906 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1198/2499940 | global iter:    600/1249970 | loss: 1.1052 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1200/2499940 | global iter:    601/1249970 | loss: 1.9275 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1202/2499940 | global iter:    602/1249970 | loss: 1.2954 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1204/2499940 | global iter:    603/1249970 | loss: 0.5982 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1206/2499940 | global iter:    604/1249970 | loss: 0.8665 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1206/2499940 | global iter:    604/1249970 | loss: 1.1798 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1208/2499940 | global iter:    605/1249970 | loss: 1.6494 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1210/2499940 | global iter:    606/1249970 | loss: 0.9066 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1212/2499940 | global iter:    607/1249970 | loss: 0.9303 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1214/2499940 | global iter:    608/1249970 | loss: 1.5796 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1214/2499940 | global iter:    608/1249970 | loss: 1.3562 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1216/2499940 | global iter:    609/1249970 | loss: 0.5349 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1218/2499940 | global iter:    610/1249970 | loss: 1.2140 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1220/2499940 | global iter:    611/1249970 | loss: 1.4700 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1222/2499940 | global iter:    612/1249970 | loss: 1.7499 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1222/2499940 | global iter:    612/1249970 | loss: 1.2110 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1224/2499940 | global iter:    613/1249970 | loss: 0.7373 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1226/2499940 | global iter:    614/1249970 | loss: 0.5898 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1228/2499940 | global iter:    615/1249970 | loss: 0.6162 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1230/2499940 | global iter:    616/1249970 | loss: 1.3860 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1230/2499940 | global iter:    616/1249970 | loss: 0.9340 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1232/2499940 | global iter:    617/1249970 | loss: 1.3496 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1234/2499940 | global iter:    618/1249970 | loss: 1.3743 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1236/2499940 | global iter:    619/1249970 | loss: 1.4997 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1238/2499940 | global iter:    620/1249970 | loss: 1.1432 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1238/2499940 | global iter:    620/1249970 | loss: 1.1370 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1240/2499940 | global iter:    621/1249970 | loss: 1.1875 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1242/2499940 | global iter:    622/1249970 | loss: 0.6369 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1244/2499940 | global iter:    623/1249970 | loss: 1.8255 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1246/2499940 | global iter:    624/1249970 | loss: 1.2623 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1246/2499940 | global iter:    624/1249970 | loss: 1.2259 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1248/2499940 | global iter:    625/1249970 | loss: 0.9879 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1250/2499940 | global iter:    626/1249970 | loss: 1.5586 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1252/2499940 | global iter:    627/1249970 | loss: 1.1300 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1254/2499940 | global iter:    628/1249970 | loss: 1.0272 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1254/2499940 | global iter:    628/1249970 | loss: 1.2578 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1256/2499940 | global iter:    629/1249970 | loss: 0.8165 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   1258/2499940 | global iter:    630/1249970 | loss: 1.3444 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1260/2499940 | global iter:    631/1249970 | loss: 1.4754 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1262/2499940 | global iter:    632/1249970 | loss: 0.8431 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1262/2499940 | global iter:    632/1249970 | loss: 0.9642 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1264/2499940 | global iter:    633/1249970 | loss: 1.1893 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1266/2499940 | global iter:    634/1249970 | loss: 1.1854 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1268/2499940 | global iter:    635/1249970 | loss: 0.6060 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1270/2499940 | global iter:    636/1249970 | loss: 1.0282 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1270/2499940 | global iter:    636/1249970 | loss: 1.0378 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1272/2499940 | global iter:    637/1249970 | loss: 0.6708 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1274/2499940 | global iter:    638/1249970 | loss: 1.7477 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1276/2499940 | global iter:    639/1249970 | loss: 0.3224 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1278/2499940 | global iter:    640/1249970 | loss: 1.5987 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1278/2499940 | global iter:    640/1249970 | loss: 1.3018 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1280/2499940 | global iter:    641/1249970 | loss: 0.9817 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1282/2499940 | global iter:    642/1249970 | loss: 1.1380 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1284/2499940 | global iter:    643/1249970 | loss: 1.3403 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1286/2499940 | global iter:    644/1249970 | loss: 0.4630 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1286/2499940 | global iter:    644/1249970 | loss: 1.2738 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1288/2499940 | global iter:    645/1249970 | loss: 0.9482 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1290/2499940 | global iter:    646/1249970 | loss: 1.3765 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1292/2499940 | global iter:    647/1249970 | loss: 1.7467 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   1294/2499940 | global iter:    648/1249970 | loss: 1.2344 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1294/2499940 | global iter:    648/1249970 | loss: 1.1440 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.394 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1296/2499940 | global iter:    649/1249970 | loss: 1.4104 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1298/2499940 | global iter:    650/1249970 | loss: 0.8016 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   1300/2499940 | global iter:    651/1249970 | loss: 1.0306 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   1302/2499940 | global iter:    652/1249970 | loss: 1.4862 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1302/2499940 | global iter:    652/1249970 | loss: 1.2663 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1304/2499940 | global iter:    653/1249970 | loss: 0.1639 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.407 | step time: 0.000
train | epoch   0 | Iter:   1306/2499940 | global iter:    654/1249970 | loss: 0.4827 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.404 | step time: 0.000
train | epoch   0 | Iter:   1308/2499940 | global iter:    655/1249970 | loss: 0.7918 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1310/2499940 | global iter:    656/1249970 | loss: 1.1176 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1310/2499940 | global iter:    656/1249970 | loss: 0.8479 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.695
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1312/2499940 | global iter:    657/1249970 | loss: 1.5783 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1314/2499940 | global iter:    658/1249970 | loss: 0.9793 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   1316/2499940 | global iter:    659/1249970 | loss: 0.4940 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1318/2499940 | global iter:    660/1249970 | loss: 1.4604 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1318/2499940 | global iter:    660/1249970 | loss: 1.0601 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1320/2499940 | global iter:    661/1249970 | loss: 1.7583 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1322/2499940 | global iter:    662/1249970 | loss: 0.5437 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1324/2499940 | global iter:    663/1249970 | loss: 0.0278 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1326/2499940 | global iter:    664/1249970 | loss: 1.0089 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1326/2499940 | global iter:    664/1249970 | loss: 1.0976 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1328/2499940 | global iter:    665/1249970 | loss: 1.4922 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1330/2499940 | global iter:    666/1249970 | loss: 1.0678 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1332/2499940 | global iter:    667/1249970 | loss: 0.8360 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1334/2499940 | global iter:    668/1249970 | loss: 0.9763 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1334/2499940 | global iter:    668/1249970 | loss: 1.0784 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1336/2499940 | global iter:    669/1249970 | loss: 1.5083 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1338/2499940 | global iter:    670/1249970 | loss: 1.9045 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1340/2499940 | global iter:    671/1249970 | loss: 1.3232 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1342/2499940 | global iter:    672/1249970 | loss: 1.4908 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1342/2499940 | global iter:    672/1249970 | loss: 1.4816 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1344/2499940 | global iter:    673/1249970 | loss: 1.5117 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1346/2499940 | global iter:    674/1249970 | loss: 0.8232 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   1348/2499940 | global iter:    675/1249970 | loss: 1.5194 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1350/2499940 | global iter:    676/1249970 | loss: 1.5395 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1350/2499940 | global iter:    676/1249970 | loss: 1.1464 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1352/2499940 | global iter:    677/1249970 | loss: 1.4516 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1354/2499940 | global iter:    678/1249970 | loss: 1.0869 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1356/2499940 | global iter:    679/1249970 | loss: 0.3053 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1358/2499940 | global iter:    680/1249970 | loss: 1.2840 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1358/2499940 | global iter:    680/1249970 | loss: 1.1220 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1360/2499940 | global iter:    681/1249970 | loss: 0.6370 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1362/2499940 | global iter:    682/1249970 | loss: 1.4738 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1364/2499940 | global iter:    683/1249970 | loss: 0.8899 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1366/2499940 | global iter:    684/1249970 | loss: 0.8982 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1366/2499940 | global iter:    684/1249970 | loss: 1.1224 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1368/2499940 | global iter:    685/1249970 | loss: 1.7018 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1370/2499940 | global iter:    686/1249970 | loss: 1.4093 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1372/2499940 | global iter:    687/1249970 | loss: 1.0569 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1374/2499940 | global iter:    688/1249970 | loss: 1.1386 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1374/2499940 | global iter:    688/1249970 | loss: 1.2436 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.394 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1376/2499940 | global iter:    689/1249970 | loss: 0.5102 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1378/2499940 | global iter:    690/1249970 | loss: 0.2475 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1380/2499940 | global iter:    691/1249970 | loss: 0.9302 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1382/2499940 | global iter:    692/1249970 | loss: 1.0673 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1382/2499940 | global iter:    692/1249970 | loss: 0.9102 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1384/2499940 | global iter:    693/1249970 | loss: 1.0455 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   1386/2499940 | global iter:    694/1249970 | loss: 0.8988 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   1388/2499940 | global iter:    695/1249970 | loss: 0.6206 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1390/2499940 | global iter:    696/1249970 | loss: 1.7180 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1390/2499940 | global iter:    696/1249970 | loss: 1.0748 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1392/2499940 | global iter:    697/1249970 | loss: 1.1781 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1394/2499940 | global iter:    698/1249970 | loss: 0.9503 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   1396/2499940 | global iter:    699/1249970 | loss: 0.7744 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1398/2499940 | global iter:    700/1249970 | loss: 1.3351 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1398/2499940 | global iter:    700/1249970 | loss: 1.0723 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1400/2499940 | global iter:    701/1249970 | loss: 0.5876 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   1402/2499940 | global iter:    702/1249970 | loss: 1.0627 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1404/2499940 | global iter:    703/1249970 | loss: 0.5745 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   1406/2499940 | global iter:    704/1249970 | loss: 1.2125 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1406/2499940 | global iter:    704/1249970 | loss: 1.0596 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1408/2499940 | global iter:    705/1249970 | loss: 1.1550 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1410/2499940 | global iter:    706/1249970 | loss: 0.9047 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1412/2499940 | global iter:    707/1249970 | loss: 0.7866 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1414/2499940 | global iter:    708/1249970 | loss: 1.5956 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1414/2499940 | global iter:    708/1249970 | loss: 1.0784 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1416/2499940 | global iter:    709/1249970 | loss: 1.8340 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1418/2499940 | global iter:    710/1249970 | loss: 1.6065 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1420/2499940 | global iter:    711/1249970 | loss: 1.5540 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1422/2499940 | global iter:    712/1249970 | loss: 0.8036 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1422/2499940 | global iter:    712/1249970 | loss: 1.0806 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1424/2499940 | global iter:    713/1249970 | loss: 1.8313 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   1426/2499940 | global iter:    714/1249970 | loss: 1.4630 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1428/2499940 | global iter:    715/1249970 | loss: 1.6055 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1430/2499940 | global iter:    716/1249970 | loss: 1.7313 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1430/2499940 | global iter:    716/1249970 | loss: 1.4680 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1432/2499940 | global iter:    717/1249970 | loss: 1.4011 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1434/2499940 | global iter:    718/1249970 | loss: 1.0415 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1436/2499940 | global iter:    719/1249970 | loss: 0.3308 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1438/2499940 | global iter:    720/1249970 | loss: 1.5340 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1438/2499940 | global iter:    720/1249970 | loss: 0.9904 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1440/2499940 | global iter:    721/1249970 | loss: 0.9770 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1442/2499940 | global iter:    722/1249970 | loss: 0.6218 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1444/2499940 | global iter:    723/1249970 | loss: 0.9813 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1446/2499940 | global iter:    724/1249970 | loss: 1.1488 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1446/2499940 | global iter:    724/1249970 | loss: 1.2815 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1448/2499940 | global iter:    725/1249970 | loss: 1.6683 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1450/2499940 | global iter:    726/1249970 | loss: 1.6479 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1452/2499940 | global iter:    727/1249970 | loss: 1.0503 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1454/2499940 | global iter:    728/1249970 | loss: 1.4605 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1454/2499940 | global iter:    728/1249970 | loss: 1.2390 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1456/2499940 | global iter:    729/1249970 | loss: 0.6016 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1458/2499940 | global iter:    730/1249970 | loss: 1.4287 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1460/2499940 | global iter:    731/1249970 | loss: 1.0902 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1462/2499940 | global iter:    732/1249970 | loss: 1.2299 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1462/2499940 | global iter:    732/1249970 | loss: 1.0595 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1464/2499940 | global iter:    733/1249970 | loss: 1.1964 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1466/2499940 | global iter:    734/1249970 | loss: 1.9097 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1468/2499940 | global iter:    735/1249970 | loss: 1.7059 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1470/2499940 | global iter:    736/1249970 | loss: 1.4010 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1470/2499940 | global iter:    736/1249970 | loss: 1.4269 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1472/2499940 | global iter:    737/1249970 | loss: 1.5093 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1474/2499940 | global iter:    738/1249970 | loss: 1.8066 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   1476/2499940 | global iter:    739/1249970 | loss: 1.1317 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1478/2499940 | global iter:    740/1249970 | loss: 0.7440 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1478/2499940 | global iter:    740/1249970 | loss: 1.1389 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1480/2499940 | global iter:    741/1249970 | loss: 1.5734 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1482/2499940 | global iter:    742/1249970 | loss: 1.5006 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1484/2499940 | global iter:    743/1249970 | loss: 1.7017 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1486/2499940 | global iter:    744/1249970 | loss: 1.0190 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1486/2499940 | global iter:    744/1249970 | loss: 1.4222 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1488/2499940 | global iter:    745/1249970 | loss: 1.9184 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   1490/2499940 | global iter:    746/1249970 | loss: 1.2615 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1492/2499940 | global iter:    747/1249970 | loss: 0.3620 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1494/2499940 | global iter:    748/1249970 | loss: 0.8969 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1494/2499940 | global iter:    748/1249970 | loss: 1.2597 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1496/2499940 | global iter:    749/1249970 | loss: 1.4557 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1498/2499940 | global iter:    750/1249970 | loss: 1.7746 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1500/2499940 | global iter:    751/1249970 | loss: 0.6537 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1502/2499940 | global iter:    752/1249970 | loss: 1.1242 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1502/2499940 | global iter:    752/1249970 | loss: 1.2634 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1504/2499940 | global iter:    753/1249970 | loss: 1.1035 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1506/2499940 | global iter:    754/1249970 | loss: 1.8692 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1508/2499940 | global iter:    755/1249970 | loss: 1.4936 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1510/2499940 | global iter:    756/1249970 | loss: 1.2930 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1510/2499940 | global iter:    756/1249970 | loss: 1.3560 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1512/2499940 | global iter:    757/1249970 | loss: 0.4943 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1514/2499940 | global iter:    758/1249970 | loss: 1.2222 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1516/2499940 | global iter:    759/1249970 | loss: 1.1056 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1518/2499940 | global iter:    760/1249970 | loss: 1.3253 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1518/2499940 | global iter:    760/1249970 | loss: 1.2756 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1520/2499940 | global iter:    761/1249970 | loss: 0.6771 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1522/2499940 | global iter:    762/1249970 | loss: 1.2772 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1524/2499940 | global iter:    763/1249970 | loss: 1.3508 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1526/2499940 | global iter:    764/1249970 | loss: 0.9720 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1526/2499940 | global iter:    764/1249970 | loss: 1.0900 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1528/2499940 | global iter:    765/1249970 | loss: 0.9741 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1530/2499940 | global iter:    766/1249970 | loss: 1.2484 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1532/2499940 | global iter:    767/1249970 | loss: 1.8907 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1534/2499940 | global iter:    768/1249970 | loss: 1.2418 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1534/2499940 | global iter:    768/1249970 | loss: 1.2024 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1536/2499940 | global iter:    769/1249970 | loss: 1.4132 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1538/2499940 | global iter:    770/1249970 | loss: 0.1261 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1540/2499940 | global iter:    771/1249970 | loss: 0.7365 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1542/2499940 | global iter:    772/1249970 | loss: 0.9530 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1542/2499940 | global iter:    772/1249970 | loss: 0.9709 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1544/2499940 | global iter:    773/1249970 | loss: 1.0562 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1546/2499940 | global iter:    774/1249970 | loss: 1.6830 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1548/2499940 | global iter:    775/1249970 | loss: 1.4982 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   1550/2499940 | global iter:    776/1249970 | loss: 0.2986 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1550/2499940 | global iter:    776/1249970 | loss: 1.2558 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1552/2499940 | global iter:    777/1249970 | loss: 1.2573 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1554/2499940 | global iter:    778/1249970 | loss: 0.8327 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1556/2499940 | global iter:    779/1249970 | loss: 1.2574 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1558/2499940 | global iter:    780/1249970 | loss: 1.1327 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1558/2499940 | global iter:    780/1249970 | loss: 1.2823 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1560/2499940 | global iter:    781/1249970 | loss: 1.5237 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1562/2499940 | global iter:    782/1249970 | loss: 1.3487 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1564/2499940 | global iter:    783/1249970 | loss: 1.6484 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1566/2499940 | global iter:    784/1249970 | loss: 0.6839 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1566/2499940 | global iter:    784/1249970 | loss: 1.2755 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1568/2499940 | global iter:    785/1249970 | loss: 1.4185 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1570/2499940 | global iter:    786/1249970 | loss: 0.3735 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1572/2499940 | global iter:    787/1249970 | loss: 0.4381 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1574/2499940 | global iter:    788/1249970 | loss: 0.9185 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1574/2499940 | global iter:    788/1249970 | loss: 0.9820 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1576/2499940 | global iter:    789/1249970 | loss: 1.4576 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1578/2499940 | global iter:    790/1249970 | loss: 1.1154 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1580/2499940 | global iter:    791/1249970 | loss: 1.5477 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1582/2499940 | global iter:    792/1249970 | loss: 1.2479 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1582/2499940 | global iter:    792/1249970 | loss: 1.1900 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1584/2499940 | global iter:    793/1249970 | loss: 1.4650 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1586/2499940 | global iter:    794/1249970 | loss: 1.6522 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1588/2499940 | global iter:    795/1249970 | loss: 1.0277 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1590/2499940 | global iter:    796/1249970 | loss: 1.2608 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1590/2499940 | global iter:    796/1249970 | loss: 1.2307 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1592/2499940 | global iter:    797/1249970 | loss: 1.4778 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1594/2499940 | global iter:    798/1249970 | loss: 1.1673 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1596/2499940 | global iter:    799/1249970 | loss: 1.0963 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1598/2499940 | global iter:    800/1249970 | loss: 0.6506 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1598/2499940 | global iter:    800/1249970 | loss: 1.1940 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1600/2499940 | global iter:    801/1249970 | loss: 1.2570 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1602/2499940 | global iter:    802/1249970 | loss: 0.5180 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1604/2499940 | global iter:    803/1249970 | loss: 1.3088 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   1606/2499940 | global iter:    804/1249970 | loss: 0.9608 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1606/2499940 | global iter:    804/1249970 | loss: 1.2381 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1608/2499940 | global iter:    805/1249970 | loss: 1.2874 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1610/2499940 | global iter:    806/1249970 | loss: 1.0288 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1612/2499940 | global iter:    807/1249970 | loss: 0.8413 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1614/2499940 | global iter:    808/1249970 | loss: 1.4960 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1614/2499940 | global iter:    808/1249970 | loss: 1.2132 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1616/2499940 | global iter:    809/1249970 | loss: 1.9349 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1618/2499940 | global iter:    810/1249970 | loss: 1.6762 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1620/2499940 | global iter:    811/1249970 | loss: 1.1317 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1622/2499940 | global iter:    812/1249970 | loss: 1.3488 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1622/2499940 | global iter:    812/1249970 | loss: 1.3324 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1624/2499940 | global iter:    813/1249970 | loss: 1.0479 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1626/2499940 | global iter:    814/1249970 | loss: 1.3846 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1628/2499940 | global iter:    815/1249970 | loss: 1.5644 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1630/2499940 | global iter:    816/1249970 | loss: 1.4420 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1630/2499940 | global iter:    816/1249970 | loss: 1.1188 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1632/2499940 | global iter:    817/1249970 | loss: 1.7873 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1634/2499940 | global iter:    818/1249970 | loss: 0.5720 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1636/2499940 | global iter:    819/1249970 | loss: 1.2888 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1638/2499940 | global iter:    820/1249970 | loss: 1.1768 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1638/2499940 | global iter:    820/1249970 | loss: 1.1823 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1640/2499940 | global iter:    821/1249970 | loss: 1.7502 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1642/2499940 | global iter:    822/1249970 | loss: 1.3347 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1644/2499940 | global iter:    823/1249970 | loss: 1.2963 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1646/2499940 | global iter:    824/1249970 | loss: 1.9371 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1646/2499940 | global iter:    824/1249970 | loss: 1.3945 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1648/2499940 | global iter:    825/1249970 | loss: 1.3404 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1650/2499940 | global iter:    826/1249970 | loss: 1.1055 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1652/2499940 | global iter:    827/1249970 | loss: 1.5549 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1654/2499940 | global iter:    828/1249970 | loss: 1.0077 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1654/2499940 | global iter:    828/1249970 | loss: 1.4040 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1656/2499940 | global iter:    829/1249970 | loss: 1.5522 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1658/2499940 | global iter:    830/1249970 | loss: 1.3034 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1660/2499940 | global iter:    831/1249970 | loss: 0.6122 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1662/2499940 | global iter:    832/1249970 | loss: 1.0656 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1662/2499940 | global iter:    832/1249970 | loss: 1.2254 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1664/2499940 | global iter:    833/1249970 | loss: 0.7078 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1666/2499940 | global iter:    834/1249970 | loss: 1.1726 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1668/2499940 | global iter:    835/1249970 | loss: 1.1253 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1670/2499940 | global iter:    836/1249970 | loss: 1.8280 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1670/2499940 | global iter:    836/1249970 | loss: 1.2297 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1672/2499940 | global iter:    837/1249970 | loss: 2.0143 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1674/2499940 | global iter:    838/1249970 | loss: 1.1827 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1676/2499940 | global iter:    839/1249970 | loss: 0.8643 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1678/2499940 | global iter:    840/1249970 | loss: 0.9470 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1678/2499940 | global iter:    840/1249970 | loss: 1.3899 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.393 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1680/2499940 | global iter:    841/1249970 | loss: 0.2253 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1682/2499940 | global iter:    842/1249970 | loss: 0.3941 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1684/2499940 | global iter:    843/1249970 | loss: 1.5524 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1686/2499940 | global iter:    844/1249970 | loss: 0.9876 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1686/2499940 | global iter:    844/1249970 | loss: 0.9425 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.393 | step time: 0.686
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1688/2499940 | global iter:    845/1249970 | loss: 0.9143 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1690/2499940 | global iter:    846/1249970 | loss: 0.9093 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1692/2499940 | global iter:    847/1249970 | loss: 1.0403 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1694/2499940 | global iter:    848/1249970 | loss: 0.9407 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1694/2499940 | global iter:    848/1249970 | loss: 0.9942 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1696/2499940 | global iter:    849/1249970 | loss: 1.1614 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1698/2499940 | global iter:    850/1249970 | loss: 1.7078 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   1700/2499940 | global iter:    851/1249970 | loss: 1.2203 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1702/2499940 | global iter:    852/1249970 | loss: 2.1907 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1702/2499940 | global iter:    852/1249970 | loss: 1.1370 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1704/2499940 | global iter:    853/1249970 | loss: 0.9532 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1706/2499940 | global iter:    854/1249970 | loss: 1.3307 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1708/2499940 | global iter:    855/1249970 | loss: 0.7431 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1710/2499940 | global iter:    856/1249970 | loss: 1.4700 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1710/2499940 | global iter:    856/1249970 | loss: 1.2562 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1712/2499940 | global iter:    857/1249970 | loss: 1.9474 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   1714/2499940 | global iter:    858/1249970 | loss: 1.4986 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1716/2499940 | global iter:    859/1249970 | loss: 1.1752 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1718/2499940 | global iter:    860/1249970 | loss: 0.5710 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1718/2499940 | global iter:    860/1249970 | loss: 1.2419 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1720/2499940 | global iter:    861/1249970 | loss: 1.4015 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1722/2499940 | global iter:    862/1249970 | loss: 1.2261 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1724/2499940 | global iter:    863/1249970 | loss: 1.5611 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1726/2499940 | global iter:    864/1249970 | loss: 1.1938 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1726/2499940 | global iter:    864/1249970 | loss: 1.2618 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1728/2499940 | global iter:    865/1249970 | loss: 0.5516 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1730/2499940 | global iter:    866/1249970 | loss: 0.1035 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1732/2499940 | global iter:    867/1249970 | loss: 0.8154 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1734/2499940 | global iter:    868/1249970 | loss: 1.2168 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1734/2499940 | global iter:    868/1249970 | loss: 0.9192 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1736/2499940 | global iter:    869/1249970 | loss: 1.5629 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1738/2499940 | global iter:    870/1249970 | loss: 0.4605 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1740/2499940 | global iter:    871/1249970 | loss: 0.7874 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1742/2499940 | global iter:    872/1249970 | loss: 1.7433 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1742/2499940 | global iter:    872/1249970 | loss: 1.2056 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1744/2499940 | global iter:    873/1249970 | loss: 1.0220 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1746/2499940 | global iter:    874/1249970 | loss: 0.6696 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1748/2499940 | global iter:    875/1249970 | loss: 1.4201 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1750/2499940 | global iter:    876/1249970 | loss: 1.0992 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1750/2499940 | global iter:    876/1249970 | loss: 1.3217 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1752/2499940 | global iter:    877/1249970 | loss: 1.5593 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1754/2499940 | global iter:    878/1249970 | loss: 1.3409 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1756/2499940 | global iter:    879/1249970 | loss: 1.4553 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1758/2499940 | global iter:    880/1249970 | loss: 0.5331 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1758/2499940 | global iter:    880/1249970 | loss: 1.3339 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1760/2499940 | global iter:    881/1249970 | loss: 1.2903 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1762/2499940 | global iter:    882/1249970 | loss: 1.1954 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1764/2499940 | global iter:    883/1249970 | loss: 1.4565 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1766/2499940 | global iter:    884/1249970 | loss: 1.5003 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1766/2499940 | global iter:    884/1249970 | loss: 1.2872 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1768/2499940 | global iter:    885/1249970 | loss: 1.0347 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1770/2499940 | global iter:    886/1249970 | loss: 1.6107 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1772/2499940 | global iter:    887/1249970 | loss: 0.9106 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1774/2499940 | global iter:    888/1249970 | loss: 1.4191 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1774/2499940 | global iter:    888/1249970 | loss: 1.1524 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1776/2499940 | global iter:    889/1249970 | loss: 2.0631 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1778/2499940 | global iter:    890/1249970 | loss: 0.9241 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1780/2499940 | global iter:    891/1249970 | loss: 0.6034 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1782/2499940 | global iter:    892/1249970 | loss: 1.5913 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1782/2499940 | global iter:    892/1249970 | loss: 1.2292 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1784/2499940 | global iter:    893/1249970 | loss: 1.0909 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1786/2499940 | global iter:    894/1249970 | loss: 1.2122 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1788/2499940 | global iter:    895/1249970 | loss: 1.2225 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1790/2499940 | global iter:    896/1249970 | loss: 1.5109 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1790/2499940 | global iter:    896/1249970 | loss: 1.1962 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1792/2499940 | global iter:    897/1249970 | loss: 0.7830 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1794/2499940 | global iter:    898/1249970 | loss: 0.3080 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1796/2499940 | global iter:    899/1249970 | loss: 1.2154 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1798/2499940 | global iter:    900/1249970 | loss: 1.8511 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1798/2499940 | global iter:    900/1249970 | loss: 1.0691 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1800/2499940 | global iter:    901/1249970 | loss: 1.4552 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1802/2499940 | global iter:    902/1249970 | loss: 1.2239 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1804/2499940 | global iter:    903/1249970 | loss: 1.5330 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1806/2499940 | global iter:    904/1249970 | loss: 1.5844 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1806/2499940 | global iter:    904/1249970 | loss: 1.3120 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1808/2499940 | global iter:    905/1249970 | loss: 0.9550 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   1810/2499940 | global iter:    906/1249970 | loss: 1.2716 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1812/2499940 | global iter:    907/1249970 | loss: 0.0523 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   1814/2499940 | global iter:    908/1249970 | loss: 0.8878 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1814/2499940 | global iter:    908/1249970 | loss: 1.0625 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1816/2499940 | global iter:    909/1249970 | loss: 1.5727 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1818/2499940 | global iter:    910/1249970 | loss: 0.7964 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1820/2499940 | global iter:    911/1249970 | loss: 1.0984 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1822/2499940 | global iter:    912/1249970 | loss: 0.8849 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1822/2499940 | global iter:    912/1249970 | loss: 1.1686 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1824/2499940 | global iter:    913/1249970 | loss: 0.6171 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   1826/2499940 | global iter:    914/1249970 | loss: 1.4996 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   1828/2499940 | global iter:    915/1249970 | loss: 1.8419 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.413 | step time: 0.000
train | epoch   0 | Iter:   1830/2499940 | global iter:    916/1249970 | loss: 0.9801 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1830/2499940 | global iter:    916/1249970 | loss: 1.1323 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1832/2499940 | global iter:    917/1249970 | loss: 1.3146 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1834/2499940 | global iter:    918/1249970 | loss: 0.8190 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1836/2499940 | global iter:    919/1249970 | loss: 0.6511 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1838/2499940 | global iter:    920/1249970 | loss: 1.2792 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1838/2499940 | global iter:    920/1249970 | loss: 1.1287 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1840/2499940 | global iter:    921/1249970 | loss: 1.3937 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1842/2499940 | global iter:    922/1249970 | loss: 0.9355 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1844/2499940 | global iter:    923/1249970 | loss: 0.9031 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1846/2499940 | global iter:    924/1249970 | loss: 1.3674 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1846/2499940 | global iter:    924/1249970 | loss: 1.4803 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1848/2499940 | global iter:    925/1249970 | loss: 0.4885 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   1850/2499940 | global iter:    926/1249970 | loss: 1.1067 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1852/2499940 | global iter:    927/1249970 | loss: 0.8826 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1854/2499940 | global iter:    928/1249970 | loss: 1.0760 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1854/2499940 | global iter:    928/1249970 | loss: 1.0532 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.393 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1856/2499940 | global iter:    929/1249970 | loss: 1.3269 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1858/2499940 | global iter:    930/1249970 | loss: 1.4223 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1860/2499940 | global iter:    931/1249970 | loss: 1.1530 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1862/2499940 | global iter:    932/1249970 | loss: 1.7532 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1862/2499940 | global iter:    932/1249970 | loss: 1.3771 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1864/2499940 | global iter:    933/1249970 | loss: 0.7049 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1866/2499940 | global iter:    934/1249970 | loss: 1.4482 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1868/2499940 | global iter:    935/1249970 | loss: 1.6976 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   1870/2499940 | global iter:    936/1249970 | loss: 0.8473 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1870/2499940 | global iter:    936/1249970 | loss: 1.0038 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1872/2499940 | global iter:    937/1249970 | loss: 1.3911 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1874/2499940 | global iter:    938/1249970 | loss: 0.8707 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   1876/2499940 | global iter:    939/1249970 | loss: 0.9804 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1878/2499940 | global iter:    940/1249970 | loss: 1.7283 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1878/2499940 | global iter:    940/1249970 | loss: 1.0869 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1880/2499940 | global iter:    941/1249970 | loss: 1.2443 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   1882/2499940 | global iter:    942/1249970 | loss: 1.3974 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1884/2499940 | global iter:    943/1249970 | loss: 1.2091 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1886/2499940 | global iter:    944/1249970 | loss: 0.9746 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1886/2499940 | global iter:    944/1249970 | loss: 1.2880 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1888/2499940 | global iter:    945/1249970 | loss: 1.4883 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1890/2499940 | global iter:    946/1249970 | loss: 0.1334 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1892/2499940 | global iter:    947/1249970 | loss: 1.1483 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1894/2499940 | global iter:    948/1249970 | loss: 1.9948 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1894/2499940 | global iter:    948/1249970 | loss: 1.2943 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1896/2499940 | global iter:    949/1249970 | loss: 1.2980 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1898/2499940 | global iter:    950/1249970 | loss: 0.6682 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   1900/2499940 | global iter:    951/1249970 | loss: 1.0862 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1902/2499940 | global iter:    952/1249970 | loss: 0.7033 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1902/2499940 | global iter:    952/1249970 | loss: 1.1109 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.394 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1904/2499940 | global iter:    953/1249970 | loss: 1.8200 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1906/2499940 | global iter:    954/1249970 | loss: 1.1596 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1908/2499940 | global iter:    955/1249970 | loss: 1.5772 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1910/2499940 | global iter:    956/1249970 | loss: 0.7163 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1910/2499940 | global iter:    956/1249970 | loss: 1.2955 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1912/2499940 | global iter:    957/1249970 | loss: 1.6982 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1914/2499940 | global iter:    958/1249970 | loss: 1.3501 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1916/2499940 | global iter:    959/1249970 | loss: 1.3358 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1918/2499940 | global iter:    960/1249970 | loss: 1.2737 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1918/2499940 | global iter:    960/1249970 | loss: 1.3711 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1920/2499940 | global iter:    961/1249970 | loss: 1.1044 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1922/2499940 | global iter:    962/1249970 | loss: 1.1741 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1924/2499940 | global iter:    963/1249970 | loss: 0.3572 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   1926/2499940 | global iter:    964/1249970 | loss: 1.6646 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1926/2499940 | global iter:    964/1249970 | loss: 0.9876 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1928/2499940 | global iter:    965/1249970 | loss: 0.4967 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1930/2499940 | global iter:    966/1249970 | loss: 0.9353 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1932/2499940 | global iter:    967/1249970 | loss: 1.3019 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1934/2499940 | global iter:    968/1249970 | loss: 1.2022 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1934/2499940 | global iter:    968/1249970 | loss: 1.1349 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1936/2499940 | global iter:    969/1249970 | loss: 1.7196 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1938/2499940 | global iter:    970/1249970 | loss: 0.8334 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1940/2499940 | global iter:    971/1249970 | loss: 0.9141 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1942/2499940 | global iter:    972/1249970 | loss: 1.1548 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1942/2499940 | global iter:    972/1249970 | loss: 1.2411 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1944/2499940 | global iter:    973/1249970 | loss: 1.2079 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1946/2499940 | global iter:    974/1249970 | loss: 0.8471 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1948/2499940 | global iter:    975/1249970 | loss: 1.8946 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1950/2499940 | global iter:    976/1249970 | loss: 2.0103 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1950/2499940 | global iter:    976/1249970 | loss: 1.4875 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1952/2499940 | global iter:    977/1249970 | loss: 0.9254 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1954/2499940 | global iter:    978/1249970 | loss: 0.9487 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.392 | step time: 0.000
train | epoch   0 | Iter:   1956/2499940 | global iter:    979/1249970 | loss: 0.5875 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1958/2499940 | global iter:    980/1249970 | loss: 1.4131 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1958/2499940 | global iter:    980/1249970 | loss: 0.9963 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1960/2499940 | global iter:    981/1249970 | loss: 0.8701 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1962/2499940 | global iter:    982/1249970 | loss: 1.5429 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1964/2499940 | global iter:    983/1249970 | loss: 1.2389 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   1966/2499940 | global iter:    984/1249970 | loss: 1.5917 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1966/2499940 | global iter:    984/1249970 | loss: 1.1573 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1968/2499940 | global iter:    985/1249970 | loss: 0.7277 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1970/2499940 | global iter:    986/1249970 | loss: 0.3889 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1972/2499940 | global iter:    987/1249970 | loss: 1.4802 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1974/2499940 | global iter:    988/1249970 | loss: 1.3648 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1974/2499940 | global iter:    988/1249970 | loss: 0.9172 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1976/2499940 | global iter:    989/1249970 | loss: 1.6098 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1978/2499940 | global iter:    990/1249970 | loss: 1.6040 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1980/2499940 | global iter:    991/1249970 | loss: 1.0194 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1982/2499940 | global iter:    992/1249970 | loss: 1.5020 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1982/2499940 | global iter:    992/1249970 | loss: 1.3183 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1984/2499940 | global iter:    993/1249970 | loss: 1.0532 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1986/2499940 | global iter:    994/1249970 | loss: 1.3163 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   1988/2499940 | global iter:    995/1249970 | loss: 1.2899 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1990/2499940 | global iter:    996/1249970 | loss: 1.1696 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1990/2499940 | global iter:    996/1249970 | loss: 1.2818 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   1992/2499940 | global iter:    997/1249970 | loss: 0.8991 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   1994/2499940 | global iter:    998/1249970 | loss: 1.5073 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   1996/2499940 | global iter:    999/1249970 | loss: 1.6611 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   1998/2499940 | global iter:   1000/1249970 | loss: 0.9041 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1998/2499940 | global iter:   1000/1249970 | loss: 1.1396 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2000/2499940 | global iter:   1001/1249970 | loss: 0.9051 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.407 | step time: 0.000
train | epoch   0 | Iter:   2002/2499940 | global iter:   1002/1249970 | loss: 1.2396 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2004/2499940 | global iter:   1003/1249970 | loss: 1.2550 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2006/2499940 | global iter:   1004/1249970 | loss: 2.0768 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2006/2499940 | global iter:   1004/1249970 | loss: 1.1975 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2008/2499940 | global iter:   1005/1249970 | loss: 1.0343 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2010/2499940 | global iter:   1006/1249970 | loss: 0.8655 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2012/2499940 | global iter:   1007/1249970 | loss: 0.5846 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2014/2499940 | global iter:   1008/1249970 | loss: 1.1895 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2014/2499940 | global iter:   1008/1249970 | loss: 1.3343 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2016/2499940 | global iter:   1009/1249970 | loss: 0.7320 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2018/2499940 | global iter:   1010/1249970 | loss: 0.9564 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   2020/2499940 | global iter:   1011/1249970 | loss: 1.1782 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2022/2499940 | global iter:   1012/1249970 | loss: 1.3711 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2022/2499940 | global iter:   1012/1249970 | loss: 1.0992 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2024/2499940 | global iter:   1013/1249970 | loss: 1.3997 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2026/2499940 | global iter:   1014/1249970 | loss: 0.9120 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2028/2499940 | global iter:   1015/1249970 | loss: 0.4999 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2030/2499940 | global iter:   1016/1249970 | loss: 1.1468 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2030/2499940 | global iter:   1016/1249970 | loss: 0.8922 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2032/2499940 | global iter:   1017/1249970 | loss: 1.6203 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2034/2499940 | global iter:   1018/1249970 | loss: 1.4408 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2036/2499940 | global iter:   1019/1249970 | loss: 1.6079 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2038/2499940 | global iter:   1020/1249970 | loss: 0.9186 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2038/2499940 | global iter:   1020/1249970 | loss: 1.0719 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2040/2499940 | global iter:   1021/1249970 | loss: 1.6241 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2042/2499940 | global iter:   1022/1249970 | loss: 1.2976 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2044/2499940 | global iter:   1023/1249970 | loss: 1.3048 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2046/2499940 | global iter:   1024/1249970 | loss: 1.1568 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2046/2499940 | global iter:   1024/1249970 | loss: 1.4256 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2048/2499940 | global iter:   1025/1249970 | loss: 0.9473 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2050/2499940 | global iter:   1026/1249970 | loss: 1.1915 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:   2052/2499940 | global iter:   1027/1249970 | loss: 1.3209 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2054/2499940 | global iter:   1028/1249970 | loss: 1.3348 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2054/2499940 | global iter:   1028/1249970 | loss: 1.2699 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2056/2499940 | global iter:   1029/1249970 | loss: 0.5681 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2058/2499940 | global iter:   1030/1249970 | loss: 1.1450 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2060/2499940 | global iter:   1031/1249970 | loss: 1.0172 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2062/2499940 | global iter:   1032/1249970 | loss: 1.1312 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2062/2499940 | global iter:   1032/1249970 | loss: 1.1442 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2064/2499940 | global iter:   1033/1249970 | loss: 0.7073 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2066/2499940 | global iter:   1034/1249970 | loss: 0.7847 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2068/2499940 | global iter:   1035/1249970 | loss: 1.4077 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2070/2499940 | global iter:   1036/1249970 | loss: 0.7242 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2070/2499940 | global iter:   1036/1249970 | loss: 0.9968 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2072/2499940 | global iter:   1037/1249970 | loss: 1.7160 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2074/2499940 | global iter:   1038/1249970 | loss: 0.8760 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   2076/2499940 | global iter:   1039/1249970 | loss: 0.8000 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2078/2499940 | global iter:   1040/1249970 | loss: 1.7770 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2078/2499940 | global iter:   1040/1249970 | loss: 1.2064 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2080/2499940 | global iter:   1041/1249970 | loss: 0.9247 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2082/2499940 | global iter:   1042/1249970 | loss: 1.5239 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2084/2499940 | global iter:   1043/1249970 | loss: 1.4185 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2086/2499940 | global iter:   1044/1249970 | loss: 1.7819 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2086/2499940 | global iter:   1044/1249970 | loss: 1.2271 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2088/2499940 | global iter:   1045/1249970 | loss: 0.9464 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.411 | step time: 0.000
train | epoch   0 | Iter:   2090/2499940 | global iter:   1046/1249970 | loss: 1.2349 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   2092/2499940 | global iter:   1047/1249970 | loss: 1.7513 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2094/2499940 | global iter:   1048/1249970 | loss: 0.5955 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2094/2499940 | global iter:   1048/1249970 | loss: 1.0664 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2096/2499940 | global iter:   1049/1249970 | loss: 1.6474 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2098/2499940 | global iter:   1050/1249970 | loss: 1.1664 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2100/2499940 | global iter:   1051/1249970 | loss: 0.7627 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2102/2499940 | global iter:   1052/1249970 | loss: 1.1610 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2102/2499940 | global iter:   1052/1249970 | loss: 1.1049 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2104/2499940 | global iter:   1053/1249970 | loss: 0.4254 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2106/2499940 | global iter:   1054/1249970 | loss: 1.6880 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2108/2499940 | global iter:   1055/1249970 | loss: 1.3035 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2110/2499940 | global iter:   1056/1249970 | loss: 1.5627 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2110/2499940 | global iter:   1056/1249970 | loss: 1.2932 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2112/2499940 | global iter:   1057/1249970 | loss: 1.1769 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2114/2499940 | global iter:   1058/1249970 | loss: 1.5355 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2116/2499940 | global iter:   1059/1249970 | loss: 1.6851 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2118/2499940 | global iter:   1060/1249970 | loss: 1.7213 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2118/2499940 | global iter:   1060/1249970 | loss: 1.2017 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2120/2499940 | global iter:   1061/1249970 | loss: 1.9723 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2122/2499940 | global iter:   1062/1249970 | loss: 0.6364 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   2124/2499940 | global iter:   1063/1249970 | loss: 1.7944 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2126/2499940 | global iter:   1064/1249970 | loss: 0.9406 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2126/2499940 | global iter:   1064/1249970 | loss: 1.1977 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2128/2499940 | global iter:   1065/1249970 | loss: 1.2886 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2130/2499940 | global iter:   1066/1249970 | loss: 1.0788 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2132/2499940 | global iter:   1067/1249970 | loss: 1.1798 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2134/2499940 | global iter:   1068/1249970 | loss: 1.3466 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2134/2499940 | global iter:   1068/1249970 | loss: 1.1194 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2136/2499940 | global iter:   1069/1249970 | loss: 1.1308 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2138/2499940 | global iter:   1070/1249970 | loss: 0.9910 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2140/2499940 | global iter:   1071/1249970 | loss: 1.5899 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2142/2499940 | global iter:   1072/1249970 | loss: 1.3813 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2142/2499940 | global iter:   1072/1249970 | loss: 1.0913 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2144/2499940 | global iter:   1073/1249970 | loss: 1.1855 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2146/2499940 | global iter:   1074/1249970 | loss: 0.9781 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2148/2499940 | global iter:   1075/1249970 | loss: 1.4727 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2150/2499940 | global iter:   1076/1249970 | loss: 0.6058 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2150/2499940 | global iter:   1076/1249970 | loss: 1.2431 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.394 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2152/2499940 | global iter:   1077/1249970 | loss: 1.6137 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2154/2499940 | global iter:   1078/1249970 | loss: 0.9799 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2156/2499940 | global iter:   1079/1249970 | loss: 0.9716 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2158/2499940 | global iter:   1080/1249970 | loss: 1.0167 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2158/2499940 | global iter:   1080/1249970 | loss: 1.2150 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2160/2499940 | global iter:   1081/1249970 | loss: 1.3165 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2162/2499940 | global iter:   1082/1249970 | loss: 1.7334 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2164/2499940 | global iter:   1083/1249970 | loss: 0.6854 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2166/2499940 | global iter:   1084/1249970 | loss: 0.5777 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2166/2499940 | global iter:   1084/1249970 | loss: 0.9876 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2168/2499940 | global iter:   1085/1249970 | loss: 1.2871 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2170/2499940 | global iter:   1086/1249970 | loss: 1.9501 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2172/2499940 | global iter:   1087/1249970 | loss: 0.4349 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2174/2499940 | global iter:   1088/1249970 | loss: 0.9653 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.406 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2174/2499940 | global iter:   1088/1249970 | loss: 0.9946 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.406 | step time: 0.697
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2176/2499940 | global iter:   1089/1249970 | loss: 0.8400 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2178/2499940 | global iter:   1090/1249970 | loss: 0.5774 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2180/2499940 | global iter:   1091/1249970 | loss: 1.0194 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2182/2499940 | global iter:   1092/1249970 | loss: 1.6624 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2182/2499940 | global iter:   1092/1249970 | loss: 1.0698 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2184/2499940 | global iter:   1093/1249970 | loss: 1.7185 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2186/2499940 | global iter:   1094/1249970 | loss: 1.2583 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2188/2499940 | global iter:   1095/1249970 | loss: 0.6577 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2190/2499940 | global iter:   1096/1249970 | loss: 0.6807 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2190/2499940 | global iter:   1096/1249970 | loss: 1.0631 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2192/2499940 | global iter:   1097/1249970 | loss: 0.8057 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2194/2499940 | global iter:   1098/1249970 | loss: 1.0400 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   2196/2499940 | global iter:   1099/1249970 | loss: 0.4587 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2198/2499940 | global iter:   1100/1249970 | loss: 0.7684 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2198/2499940 | global iter:   1100/1249970 | loss: 0.9564 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2200/2499940 | global iter:   1101/1249970 | loss: 1.3868 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2202/2499940 | global iter:   1102/1249970 | loss: 0.5549 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2204/2499940 | global iter:   1103/1249970 | loss: 1.6021 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2206/2499940 | global iter:   1104/1249970 | loss: 1.0968 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2206/2499940 | global iter:   1104/1249970 | loss: 1.1709 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2208/2499940 | global iter:   1105/1249970 | loss: 0.9817 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2210/2499940 | global iter:   1106/1249970 | loss: 1.1369 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2212/2499940 | global iter:   1107/1249970 | loss: 1.7764 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2214/2499940 | global iter:   1108/1249970 | loss: 1.4486 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2214/2499940 | global iter:   1108/1249970 | loss: 1.2466 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2216/2499940 | global iter:   1109/1249970 | loss: 1.5506 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2218/2499940 | global iter:   1110/1249970 | loss: 0.4168 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   2220/2499940 | global iter:   1111/1249970 | loss: 0.5972 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2222/2499940 | global iter:   1112/1249970 | loss: 1.1520 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2222/2499940 | global iter:   1112/1249970 | loss: 1.0691 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2224/2499940 | global iter:   1113/1249970 | loss: 1.1606 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   2226/2499940 | global iter:   1114/1249970 | loss: 0.9517 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2228/2499940 | global iter:   1115/1249970 | loss: 1.3147 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2230/2499940 | global iter:   1116/1249970 | loss: 0.5841 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2230/2499940 | global iter:   1116/1249970 | loss: 1.0545 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2232/2499940 | global iter:   1117/1249970 | loss: 1.7624 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2234/2499940 | global iter:   1118/1249970 | loss: 1.6172 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2236/2499940 | global iter:   1119/1249970 | loss: 2.0534 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2238/2499940 | global iter:   1120/1249970 | loss: 1.1325 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2238/2499940 | global iter:   1120/1249970 | loss: 1.4460 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2240/2499940 | global iter:   1121/1249970 | loss: 0.5702 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2242/2499940 | global iter:   1122/1249970 | loss: 1.6058 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   2244/2499940 | global iter:   1123/1249970 | loss: 0.8361 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2246/2499940 | global iter:   1124/1249970 | loss: 1.7038 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2246/2499940 | global iter:   1124/1249970 | loss: 1.2346 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2248/2499940 | global iter:   1125/1249970 | loss: 1.7880 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2250/2499940 | global iter:   1126/1249970 | loss: 1.3071 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2252/2499940 | global iter:   1127/1249970 | loss: 0.9778 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2254/2499940 | global iter:   1128/1249970 | loss: 1.1792 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2254/2499940 | global iter:   1128/1249970 | loss: 1.2655 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2256/2499940 | global iter:   1129/1249970 | loss: 0.6288 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2258/2499940 | global iter:   1130/1249970 | loss: 0.9518 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   2260/2499940 | global iter:   1131/1249970 | loss: 1.0103 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.407 | step time: 0.000
train | epoch   0 | Iter:   2262/2499940 | global iter:   1132/1249970 | loss: 1.2348 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2262/2499940 | global iter:   1132/1249970 | loss: 1.1801 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2264/2499940 | global iter:   1133/1249970 | loss: 1.7966 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2266/2499940 | global iter:   1134/1249970 | loss: 1.2254 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2268/2499940 | global iter:   1135/1249970 | loss: 1.0461 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2270/2499940 | global iter:   1136/1249970 | loss: 1.8297 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2270/2499940 | global iter:   1136/1249970 | loss: 1.3202 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2272/2499940 | global iter:   1137/1249970 | loss: 1.5019 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2274/2499940 | global iter:   1138/1249970 | loss: 0.5201 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2276/2499940 | global iter:   1139/1249970 | loss: 0.8907 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2278/2499940 | global iter:   1140/1249970 | loss: 1.3920 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2278/2499940 | global iter:   1140/1249970 | loss: 1.0359 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2280/2499940 | global iter:   1141/1249970 | loss: 1.0661 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2282/2499940 | global iter:   1142/1249970 | loss: 1.8178 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   2284/2499940 | global iter:   1143/1249970 | loss: 0.8600 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2286/2499940 | global iter:   1144/1249970 | loss: 0.3127 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2286/2499940 | global iter:   1144/1249970 | loss: 1.1552 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2288/2499940 | global iter:   1145/1249970 | loss: 0.9466 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2290/2499940 | global iter:   1146/1249970 | loss: 1.3701 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2292/2499940 | global iter:   1147/1249970 | loss: 1.4297 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2294/2499940 | global iter:   1148/1249970 | loss: 1.0716 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2294/2499940 | global iter:   1148/1249970 | loss: 1.2966 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2296/2499940 | global iter:   1149/1249970 | loss: 0.5508 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2298/2499940 | global iter:   1150/1249970 | loss: 1.1570 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2300/2499940 | global iter:   1151/1249970 | loss: 0.3870 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2302/2499940 | global iter:   1152/1249970 | loss: 1.5032 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2302/2499940 | global iter:   1152/1249970 | loss: 0.9469 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2304/2499940 | global iter:   1153/1249970 | loss: 1.1669 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2306/2499940 | global iter:   1154/1249970 | loss: 1.0824 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2308/2499940 | global iter:   1155/1249970 | loss: 1.3718 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2310/2499940 | global iter:   1156/1249970 | loss: 1.6051 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2310/2499940 | global iter:   1156/1249970 | loss: 1.1612 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2312/2499940 | global iter:   1157/1249970 | loss: 1.3400 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2314/2499940 | global iter:   1158/1249970 | loss: 1.3673 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2316/2499940 | global iter:   1159/1249970 | loss: 0.7856 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2318/2499940 | global iter:   1160/1249970 | loss: 1.5423 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2318/2499940 | global iter:   1160/1249970 | loss: 1.2681 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2320/2499940 | global iter:   1161/1249970 | loss: 0.1119 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2322/2499940 | global iter:   1162/1249970 | loss: 1.6468 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   2324/2499940 | global iter:   1163/1249970 | loss: 1.2400 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2326/2499940 | global iter:   1164/1249970 | loss: 1.3086 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2326/2499940 | global iter:   1164/1249970 | loss: 1.0179 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2328/2499940 | global iter:   1165/1249970 | loss: 1.3160 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2330/2499940 | global iter:   1166/1249970 | loss: 0.7867 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2332/2499940 | global iter:   1167/1249970 | loss: 1.1242 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2334/2499940 | global iter:   1168/1249970 | loss: 0.6757 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2334/2499940 | global iter:   1168/1249970 | loss: 1.1052 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2336/2499940 | global iter:   1169/1249970 | loss: 1.8492 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2338/2499940 | global iter:   1170/1249970 | loss: 0.8352 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2340/2499940 | global iter:   1171/1249970 | loss: 0.5283 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2342/2499940 | global iter:   1172/1249970 | loss: 1.8847 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2342/2499940 | global iter:   1172/1249970 | loss: 1.3548 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2344/2499940 | global iter:   1173/1249970 | loss: 1.3058 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2346/2499940 | global iter:   1174/1249970 | loss: 0.2954 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2348/2499940 | global iter:   1175/1249970 | loss: 1.2623 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.414 | step time: 0.000
train | epoch   0 | Iter:   2350/2499940 | global iter:   1176/1249970 | loss: 1.5296 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2350/2499940 | global iter:   1176/1249970 | loss: 1.1496 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.696
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2352/2499940 | global iter:   1177/1249970 | loss: 0.9750 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2354/2499940 | global iter:   1178/1249970 | loss: 1.3492 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2356/2499940 | global iter:   1179/1249970 | loss: 0.8747 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2358/2499940 | global iter:   1180/1249970 | loss: 0.6660 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2358/2499940 | global iter:   1180/1249970 | loss: 0.9502 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2360/2499940 | global iter:   1181/1249970 | loss: 1.0218 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2362/2499940 | global iter:   1182/1249970 | loss: 0.9513 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   2364/2499940 | global iter:   1183/1249970 | loss: 0.7104 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2366/2499940 | global iter:   1184/1249970 | loss: 1.2324 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2366/2499940 | global iter:   1184/1249970 | loss: 1.0130 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2368/2499940 | global iter:   1185/1249970 | loss: 1.1375 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2370/2499940 | global iter:   1186/1249970 | loss: 0.7917 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2372/2499940 | global iter:   1187/1249970 | loss: 1.3788 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2374/2499940 | global iter:   1188/1249970 | loss: 1.0293 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2374/2499940 | global iter:   1188/1249970 | loss: 1.1041 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2376/2499940 | global iter:   1189/1249970 | loss: 1.3332 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2378/2499940 | global iter:   1190/1249970 | loss: 1.7424 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2380/2499940 | global iter:   1191/1249970 | loss: 0.9021 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2382/2499940 | global iter:   1192/1249970 | loss: 1.5509 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2382/2499940 | global iter:   1192/1249970 | loss: 1.0445 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2384/2499940 | global iter:   1193/1249970 | loss: 1.4181 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2386/2499940 | global iter:   1194/1249970 | loss: 1.3667 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2388/2499940 | global iter:   1195/1249970 | loss: 1.5771 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2390/2499940 | global iter:   1196/1249970 | loss: 1.4593 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2390/2499940 | global iter:   1196/1249970 | loss: 1.4092 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2392/2499940 | global iter:   1197/1249970 | loss: 1.9698 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2394/2499940 | global iter:   1198/1249970 | loss: 1.3921 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2396/2499940 | global iter:   1199/1249970 | loss: 1.8707 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2398/2499940 | global iter:   1200/1249970 | loss: 1.4253 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2398/2499940 | global iter:   1200/1249970 | loss: 1.3977 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2400/2499940 | global iter:   1201/1249970 | loss: 0.3500 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2402/2499940 | global iter:   1202/1249970 | loss: 1.3221 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2404/2499940 | global iter:   1203/1249970 | loss: 1.3300 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2406/2499940 | global iter:   1204/1249970 | loss: 1.5126 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2406/2499940 | global iter:   1204/1249970 | loss: 1.1392 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2408/2499940 | global iter:   1205/1249970 | loss: 0.6904 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:   2410/2499940 | global iter:   1206/1249970 | loss: 0.0105 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2412/2499940 | global iter:   1207/1249970 | loss: 1.1259 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2414/2499940 | global iter:   1208/1249970 | loss: 1.7384 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2414/2499940 | global iter:   1208/1249970 | loss: 0.9234 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2416/2499940 | global iter:   1209/1249970 | loss: 1.4742 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2418/2499940 | global iter:   1210/1249970 | loss: 0.9727 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   2420/2499940 | global iter:   1211/1249970 | loss: 2.0842 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2422/2499940 | global iter:   1212/1249970 | loss: 0.7504 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2422/2499940 | global iter:   1212/1249970 | loss: 1.2673 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2424/2499940 | global iter:   1213/1249970 | loss: 0.6869 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2426/2499940 | global iter:   1214/1249970 | loss: 0.7415 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2428/2499940 | global iter:   1215/1249970 | loss: 0.8121 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2430/2499940 | global iter:   1216/1249970 | loss: 0.8970 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2430/2499940 | global iter:   1216/1249970 | loss: 1.0080 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2432/2499940 | global iter:   1217/1249970 | loss: 1.3488 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2434/2499940 | global iter:   1218/1249970 | loss: 0.9610 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2436/2499940 | global iter:   1219/1249970 | loss: 1.9960 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2438/2499940 | global iter:   1220/1249970 | loss: 1.4549 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2438/2499940 | global iter:   1220/1249970 | loss: 1.2926 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2440/2499940 | global iter:   1221/1249970 | loss: 1.2650 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2442/2499940 | global iter:   1222/1249970 | loss: 1.0693 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   2444/2499940 | global iter:   1223/1249970 | loss: 1.3404 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2446/2499940 | global iter:   1224/1249970 | loss: 0.3407 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2446/2499940 | global iter:   1224/1249970 | loss: 1.0850 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2448/2499940 | global iter:   1225/1249970 | loss: 1.0315 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2450/2499940 | global iter:   1226/1249970 | loss: 1.2428 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2452/2499940 | global iter:   1227/1249970 | loss: 1.4253 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2454/2499940 | global iter:   1228/1249970 | loss: 1.1030 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2454/2499940 | global iter:   1228/1249970 | loss: 1.2333 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2456/2499940 | global iter:   1229/1249970 | loss: 1.4881 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2458/2499940 | global iter:   1230/1249970 | loss: 1.3807 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   2460/2499940 | global iter:   1231/1249970 | loss: 0.8138 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2462/2499940 | global iter:   1232/1249970 | loss: 0.9698 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2462/2499940 | global iter:   1232/1249970 | loss: 1.0047 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2464/2499940 | global iter:   1233/1249970 | loss: 2.0703 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2466/2499940 | global iter:   1234/1249970 | loss: 0.4274 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   2468/2499940 | global iter:   1235/1249970 | loss: 1.5768 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2470/2499940 | global iter:   1236/1249970 | loss: 1.4231 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2470/2499940 | global iter:   1236/1249970 | loss: 1.2623 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2472/2499940 | global iter:   1237/1249970 | loss: 0.8716 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2474/2499940 | global iter:   1238/1249970 | loss: 1.5554 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2476/2499940 | global iter:   1239/1249970 | loss: 1.0655 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2478/2499940 | global iter:   1240/1249970 | loss: 0.4443 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2478/2499940 | global iter:   1240/1249970 | loss: 1.1133 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2480/2499940 | global iter:   1241/1249970 | loss: 2.3464 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2482/2499940 | global iter:   1242/1249970 | loss: 1.3039 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2484/2499940 | global iter:   1243/1249970 | loss: 1.0992 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2486/2499940 | global iter:   1244/1249970 | loss: 1.0987 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2486/2499940 | global iter:   1244/1249970 | loss: 1.4281 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2488/2499940 | global iter:   1245/1249970 | loss: 1.1373 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2490/2499940 | global iter:   1246/1249970 | loss: 1.5650 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   2492/2499940 | global iter:   1247/1249970 | loss: 1.2073 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2494/2499940 | global iter:   1248/1249970 | loss: 1.0967 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2494/2499940 | global iter:   1248/1249970 | loss: 1.2031 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2496/2499940 | global iter:   1249/1249970 | loss: 1.5439 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2498/2499940 | global iter:   1250/1249970 | loss: 0.7799 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2500/2499940 | global iter:   1251/1249970 | loss: 1.1853 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2502/2499940 | global iter:   1252/1249970 | loss: 1.6265 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2502/2499940 | global iter:   1252/1249970 | loss: 1.3539 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2504/2499940 | global iter:   1253/1249970 | loss: 0.9665 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2506/2499940 | global iter:   1254/1249970 | loss: 1.7509 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2508/2499940 | global iter:   1255/1249970 | loss: 1.2904 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2510/2499940 | global iter:   1256/1249970 | loss: 1.2875 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2510/2499940 | global iter:   1256/1249970 | loss: 1.3450 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2512/2499940 | global iter:   1257/1249970 | loss: 1.5626 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2514/2499940 | global iter:   1258/1249970 | loss: 0.7262 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2516/2499940 | global iter:   1259/1249970 | loss: 1.3306 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2518/2499940 | global iter:   1260/1249970 | loss: 1.0264 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2518/2499940 | global iter:   1260/1249970 | loss: 1.1746 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2520/2499940 | global iter:   1261/1249970 | loss: 0.6636 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2522/2499940 | global iter:   1262/1249970 | loss: 0.4835 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   2524/2499940 | global iter:   1263/1249970 | loss: 1.1906 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2526/2499940 | global iter:   1264/1249970 | loss: 1.6197 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2526/2499940 | global iter:   1264/1249970 | loss: 1.1173 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2528/2499940 | global iter:   1265/1249970 | loss: 1.1599 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2530/2499940 | global iter:   1266/1249970 | loss: 1.7647 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2532/2499940 | global iter:   1267/1249970 | loss: 1.1008 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2534/2499940 | global iter:   1268/1249970 | loss: 1.1825 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2534/2499940 | global iter:   1268/1249970 | loss: 1.2528 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2536/2499940 | global iter:   1269/1249970 | loss: 0.6372 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2538/2499940 | global iter:   1270/1249970 | loss: 1.2175 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2540/2499940 | global iter:   1271/1249970 | loss: 1.0884 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2542/2499940 | global iter:   1272/1249970 | loss: 1.2101 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2542/2499940 | global iter:   1272/1249970 | loss: 1.1031 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.395 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2544/2499940 | global iter:   1273/1249970 | loss: 0.4267 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2546/2499940 | global iter:   1274/1249970 | loss: 1.4416 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2548/2499940 | global iter:   1275/1249970 | loss: 0.9488 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2550/2499940 | global iter:   1276/1249970 | loss: 1.1498 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2550/2499940 | global iter:   1276/1249970 | loss: 1.1330 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2552/2499940 | global iter:   1277/1249970 | loss: 1.3128 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2554/2499940 | global iter:   1278/1249970 | loss: 1.7084 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2556/2499940 | global iter:   1279/1249970 | loss: 1.2922 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2558/2499940 | global iter:   1280/1249970 | loss: 1.1116 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2558/2499940 | global iter:   1280/1249970 | loss: 1.0312 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2560/2499940 | global iter:   1281/1249970 | loss: 1.3096 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2562/2499940 | global iter:   1282/1249970 | loss: 0.9766 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2564/2499940 | global iter:   1283/1249970 | loss: 0.7916 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2566/2499940 | global iter:   1284/1249970 | loss: 1.4408 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2566/2499940 | global iter:   1284/1249970 | loss: 1.3386 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2568/2499940 | global iter:   1285/1249970 | loss: 0.7152 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2570/2499940 | global iter:   1286/1249970 | loss: 1.1039 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2572/2499940 | global iter:   1287/1249970 | loss: 0.9558 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2574/2499940 | global iter:   1288/1249970 | loss: 0.8226 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2574/2499940 | global iter:   1288/1249970 | loss: 0.9849 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2576/2499940 | global iter:   1289/1249970 | loss: 0.6036 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2578/2499940 | global iter:   1290/1249970 | loss: 1.4144 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2580/2499940 | global iter:   1291/1249970 | loss: 1.1979 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2582/2499940 | global iter:   1292/1249970 | loss: 0.7717 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2582/2499940 | global iter:   1292/1249970 | loss: 1.0788 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2584/2499940 | global iter:   1293/1249970 | loss: 0.7600 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2586/2499940 | global iter:   1294/1249970 | loss: 1.1353 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2588/2499940 | global iter:   1295/1249970 | loss: 0.6849 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2590/2499940 | global iter:   1296/1249970 | loss: 1.8185 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2590/2499940 | global iter:   1296/1249970 | loss: 1.1048 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2592/2499940 | global iter:   1297/1249970 | loss: 1.4332 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2594/2499940 | global iter:   1298/1249970 | loss: 1.2498 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   2596/2499940 | global iter:   1299/1249970 | loss: 1.5242 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2598/2499940 | global iter:   1300/1249970 | loss: 0.0990 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2598/2499940 | global iter:   1300/1249970 | loss: 0.8731 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2600/2499940 | global iter:   1301/1249970 | loss: 1.1369 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2602/2499940 | global iter:   1302/1249970 | loss: 1.0835 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2604/2499940 | global iter:   1303/1249970 | loss: 0.9711 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2606/2499940 | global iter:   1304/1249970 | loss: 1.2457 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2606/2499940 | global iter:   1304/1249970 | loss: 1.0497 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2608/2499940 | global iter:   1305/1249970 | loss: 0.6425 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   2610/2499940 | global iter:   1306/1249970 | loss: 1.2550 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2612/2499940 | global iter:   1307/1249970 | loss: 1.2564 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2614/2499940 | global iter:   1308/1249970 | loss: 1.5703 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2614/2499940 | global iter:   1308/1249970 | loss: 1.3067 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2616/2499940 | global iter:   1309/1249970 | loss: 1.1369 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2618/2499940 | global iter:   1310/1249970 | loss: 1.2284 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2620/2499940 | global iter:   1311/1249970 | loss: 1.4999 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2622/2499940 | global iter:   1312/1249970 | loss: 1.6229 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2622/2499940 | global iter:   1312/1249970 | loss: 1.3333 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.394 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2624/2499940 | global iter:   1313/1249970 | loss: 1.2983 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2626/2499940 | global iter:   1314/1249970 | loss: 1.2678 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2628/2499940 | global iter:   1315/1249970 | loss: 1.8469 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2630/2499940 | global iter:   1316/1249970 | loss: 1.1602 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2630/2499940 | global iter:   1316/1249970 | loss: 1.2766 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.695
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2632/2499940 | global iter:   1317/1249970 | loss: 0.9896 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2634/2499940 | global iter:   1318/1249970 | loss: 1.6544 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2636/2499940 | global iter:   1319/1249970 | loss: 1.3974 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2638/2499940 | global iter:   1320/1249970 | loss: 1.7794 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2638/2499940 | global iter:   1320/1249970 | loss: 1.5795 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2640/2499940 | global iter:   1321/1249970 | loss: 0.5163 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2642/2499940 | global iter:   1322/1249970 | loss: 0.7794 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2644/2499940 | global iter:   1323/1249970 | loss: 1.4127 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2646/2499940 | global iter:   1324/1249970 | loss: 1.0129 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2646/2499940 | global iter:   1324/1249970 | loss: 1.0958 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2648/2499940 | global iter:   1325/1249970 | loss: 0.7399 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2650/2499940 | global iter:   1326/1249970 | loss: 1.6501 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2652/2499940 | global iter:   1327/1249970 | loss: 1.3669 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2654/2499940 | global iter:   1328/1249970 | loss: 0.6513 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2654/2499940 | global iter:   1328/1249970 | loss: 1.1564 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2656/2499940 | global iter:   1329/1249970 | loss: 1.3742 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2658/2499940 | global iter:   1330/1249970 | loss: 0.7230 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2660/2499940 | global iter:   1331/1249970 | loss: 0.5467 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2662/2499940 | global iter:   1332/1249970 | loss: 1.2705 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2662/2499940 | global iter:   1332/1249970 | loss: 1.3057 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2664/2499940 | global iter:   1333/1249970 | loss: 1.4436 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2666/2499940 | global iter:   1334/1249970 | loss: 1.6114 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2668/2499940 | global iter:   1335/1249970 | loss: 0.5391 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2670/2499940 | global iter:   1336/1249970 | loss: 1.2802 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2670/2499940 | global iter:   1336/1249970 | loss: 1.2938 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2672/2499940 | global iter:   1337/1249970 | loss: 0.8574 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:   2674/2499940 | global iter:   1338/1249970 | loss: 0.8570 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   2676/2499940 | global iter:   1339/1249970 | loss: 1.0150 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2678/2499940 | global iter:   1340/1249970 | loss: 1.0124 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2678/2499940 | global iter:   1340/1249970 | loss: 1.0134 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2680/2499940 | global iter:   1341/1249970 | loss: 0.4313 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2682/2499940 | global iter:   1342/1249970 | loss: 0.8571 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2684/2499940 | global iter:   1343/1249970 | loss: 0.5764 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2686/2499940 | global iter:   1344/1249970 | loss: 0.6661 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2686/2499940 | global iter:   1344/1249970 | loss: 0.8256 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2688/2499940 | global iter:   1345/1249970 | loss: 1.7704 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2690/2499940 | global iter:   1346/1249970 | loss: 1.5886 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2692/2499940 | global iter:   1347/1249970 | loss: 1.2602 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2694/2499940 | global iter:   1348/1249970 | loss: 1.2649 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2694/2499940 | global iter:   1348/1249970 | loss: 1.2152 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2696/2499940 | global iter:   1349/1249970 | loss: 0.7377 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2698/2499940 | global iter:   1350/1249970 | loss: 1.1059 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2700/2499940 | global iter:   1351/1249970 | loss: 0.7805 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2702/2499940 | global iter:   1352/1249970 | loss: 1.2022 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2702/2499940 | global iter:   1352/1249970 | loss: 0.9088 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2704/2499940 | global iter:   1353/1249970 | loss: 1.4533 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2706/2499940 | global iter:   1354/1249970 | loss: 0.4185 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2708/2499940 | global iter:   1355/1249970 | loss: 0.4345 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2710/2499940 | global iter:   1356/1249970 | loss: 1.4801 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2710/2499940 | global iter:   1356/1249970 | loss: 1.1083 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2712/2499940 | global iter:   1357/1249970 | loss: 0.5023 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2714/2499940 | global iter:   1358/1249970 | loss: 0.9624 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2716/2499940 | global iter:   1359/1249970 | loss: 0.6837 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2718/2499940 | global iter:   1360/1249970 | loss: 1.2748 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2718/2499940 | global iter:   1360/1249970 | loss: 0.9860 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2720/2499940 | global iter:   1361/1249970 | loss: 1.0471 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2722/2499940 | global iter:   1362/1249970 | loss: 1.3550 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2724/2499940 | global iter:   1363/1249970 | loss: 1.2857 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2726/2499940 | global iter:   1364/1249970 | loss: 0.9769 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2726/2499940 | global iter:   1364/1249970 | loss: 1.0866 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2728/2499940 | global iter:   1365/1249970 | loss: 0.6439 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2730/2499940 | global iter:   1366/1249970 | loss: 0.8371 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2732/2499940 | global iter:   1367/1249970 | loss: 0.1771 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2734/2499940 | global iter:   1368/1249970 | loss: 0.5697 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2734/2499940 | global iter:   1368/1249970 | loss: 0.8879 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2736/2499940 | global iter:   1369/1249970 | loss: 1.4632 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2738/2499940 | global iter:   1370/1249970 | loss: 1.0354 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2740/2499940 | global iter:   1371/1249970 | loss: 1.7890 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   2742/2499940 | global iter:   1372/1249970 | loss: 1.9320 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2742/2499940 | global iter:   1372/1249970 | loss: 1.3018 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2744/2499940 | global iter:   1373/1249970 | loss: 1.4302 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2746/2499940 | global iter:   1374/1249970 | loss: 1.7065 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   2748/2499940 | global iter:   1375/1249970 | loss: 1.3049 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2750/2499940 | global iter:   1376/1249970 | loss: 1.5477 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2750/2499940 | global iter:   1376/1249970 | loss: 1.2371 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2752/2499940 | global iter:   1377/1249970 | loss: 0.8448 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2754/2499940 | global iter:   1378/1249970 | loss: 0.4119 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2756/2499940 | global iter:   1379/1249970 | loss: 0.8657 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2758/2499940 | global iter:   1380/1249970 | loss: 0.6557 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2758/2499940 | global iter:   1380/1249970 | loss: 0.9956 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2760/2499940 | global iter:   1381/1249970 | loss: 1.6125 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2762/2499940 | global iter:   1382/1249970 | loss: 1.6290 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2764/2499940 | global iter:   1383/1249970 | loss: 0.9511 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2766/2499940 | global iter:   1384/1249970 | loss: 0.6811 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2766/2499940 | global iter:   1384/1249970 | loss: 1.2606 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.394 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2768/2499940 | global iter:   1385/1249970 | loss: 1.1502 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2770/2499940 | global iter:   1386/1249970 | loss: 1.1989 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2772/2499940 | global iter:   1387/1249970 | loss: 1.3981 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2774/2499940 | global iter:   1388/1249970 | loss: 1.7005 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2774/2499940 | global iter:   1388/1249970 | loss: 1.2661 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2776/2499940 | global iter:   1389/1249970 | loss: 1.1986 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2778/2499940 | global iter:   1390/1249970 | loss: 0.3833 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2780/2499940 | global iter:   1391/1249970 | loss: 1.5856 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.407 | step time: 0.000
train | epoch   0 | Iter:   2782/2499940 | global iter:   1392/1249970 | loss: 1.2759 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2782/2499940 | global iter:   1392/1249970 | loss: 1.1882 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2784/2499940 | global iter:   1393/1249970 | loss: 1.6220 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2786/2499940 | global iter:   1394/1249970 | loss: 2.0389 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2788/2499940 | global iter:   1395/1249970 | loss: 1.6581 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2790/2499940 | global iter:   1396/1249970 | loss: 1.4471 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2790/2499940 | global iter:   1396/1249970 | loss: 1.4775 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2792/2499940 | global iter:   1397/1249970 | loss: 1.4019 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2794/2499940 | global iter:   1398/1249970 | loss: 0.6988 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2796/2499940 | global iter:   1399/1249970 | loss: 0.9079 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2798/2499940 | global iter:   1400/1249970 | loss: 1.4106 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2798/2499940 | global iter:   1400/1249970 | loss: 1.4005 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2800/2499940 | global iter:   1401/1249970 | loss: 1.1345 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2802/2499940 | global iter:   1402/1249970 | loss: 1.1708 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2804/2499940 | global iter:   1403/1249970 | loss: 1.1774 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2806/2499940 | global iter:   1404/1249970 | loss: 1.3957 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2806/2499940 | global iter:   1404/1249970 | loss: 1.2517 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2808/2499940 | global iter:   1405/1249970 | loss: 1.3567 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2810/2499940 | global iter:   1406/1249970 | loss: 1.2518 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2812/2499940 | global iter:   1407/1249970 | loss: 1.7210 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2814/2499940 | global iter:   1408/1249970 | loss: 1.5159 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2814/2499940 | global iter:   1408/1249970 | loss: 1.4633 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2816/2499940 | global iter:   1409/1249970 | loss: 0.2286 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2818/2499940 | global iter:   1410/1249970 | loss: 0.6495 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   2820/2499940 | global iter:   1411/1249970 | loss: 0.6230 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2822/2499940 | global iter:   1412/1249970 | loss: 0.0858 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2822/2499940 | global iter:   1412/1249970 | loss: 0.7178 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2824/2499940 | global iter:   1413/1249970 | loss: 1.3046 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2826/2499940 | global iter:   1414/1249970 | loss: 0.6996 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   2828/2499940 | global iter:   1415/1249970 | loss: 0.9696 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2830/2499940 | global iter:   1416/1249970 | loss: 1.1023 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2830/2499940 | global iter:   1416/1249970 | loss: 1.0218 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2832/2499940 | global iter:   1417/1249970 | loss: 1.0542 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2834/2499940 | global iter:   1418/1249970 | loss: 0.4099 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   2836/2499940 | global iter:   1419/1249970 | loss: 1.2452 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2838/2499940 | global iter:   1420/1249970 | loss: 0.9257 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2838/2499940 | global iter:   1420/1249970 | loss: 1.2211 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2840/2499940 | global iter:   1421/1249970 | loss: 1.1568 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2842/2499940 | global iter:   1422/1249970 | loss: 0.9183 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2844/2499940 | global iter:   1423/1249970 | loss: 1.5310 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2846/2499940 | global iter:   1424/1249970 | loss: 1.4232 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2846/2499940 | global iter:   1424/1249970 | loss: 1.2461 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2848/2499940 | global iter:   1425/1249970 | loss: 1.7252 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2850/2499940 | global iter:   1426/1249970 | loss: 0.3628 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   2852/2499940 | global iter:   1427/1249970 | loss: 1.0615 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2854/2499940 | global iter:   1428/1249970 | loss: 1.0318 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2854/2499940 | global iter:   1428/1249970 | loss: 0.9367 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2856/2499940 | global iter:   1429/1249970 | loss: 1.2170 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2858/2499940 | global iter:   1430/1249970 | loss: 1.0849 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   2860/2499940 | global iter:   1431/1249970 | loss: 1.0828 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2862/2499940 | global iter:   1432/1249970 | loss: 1.0776 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2862/2499940 | global iter:   1432/1249970 | loss: 0.9992 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2864/2499940 | global iter:   1433/1249970 | loss: 1.8510 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2866/2499940 | global iter:   1434/1249970 | loss: 1.4340 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.407 | step time: 0.000
train | epoch   0 | Iter:   2868/2499940 | global iter:   1435/1249970 | loss: 1.1549 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2870/2499940 | global iter:   1436/1249970 | loss: 1.4468 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2870/2499940 | global iter:   1436/1249970 | loss: 1.2206 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2872/2499940 | global iter:   1437/1249970 | loss: 1.1093 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2874/2499940 | global iter:   1438/1249970 | loss: 0.8629 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2876/2499940 | global iter:   1439/1249970 | loss: 1.0344 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2878/2499940 | global iter:   1440/1249970 | loss: 1.2553 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2878/2499940 | global iter:   1440/1249970 | loss: 1.3547 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2880/2499940 | global iter:   1441/1249970 | loss: 1.0320 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2882/2499940 | global iter:   1442/1249970 | loss: 0.8564 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2884/2499940 | global iter:   1443/1249970 | loss: 0.6396 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2886/2499940 | global iter:   1444/1249970 | loss: 1.1559 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2886/2499940 | global iter:   1444/1249970 | loss: 0.9436 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2888/2499940 | global iter:   1445/1249970 | loss: 1.1593 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2890/2499940 | global iter:   1446/1249970 | loss: 0.9533 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   2892/2499940 | global iter:   1447/1249970 | loss: 1.6540 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2894/2499940 | global iter:   1448/1249970 | loss: 1.2910 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2894/2499940 | global iter:   1448/1249970 | loss: 1.1093 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2896/2499940 | global iter:   1449/1249970 | loss: 1.5831 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2898/2499940 | global iter:   1450/1249970 | loss: 1.2473 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2900/2499940 | global iter:   1451/1249970 | loss: 0.7985 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2902/2499940 | global iter:   1452/1249970 | loss: 1.4638 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2902/2499940 | global iter:   1452/1249970 | loss: 1.2546 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2904/2499940 | global iter:   1453/1249970 | loss: 1.1028 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2906/2499940 | global iter:   1454/1249970 | loss: 1.2497 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2908/2499940 | global iter:   1455/1249970 | loss: 1.4522 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2910/2499940 | global iter:   1456/1249970 | loss: 1.7267 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2910/2499940 | global iter:   1456/1249970 | loss: 1.4129 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2912/2499940 | global iter:   1457/1249970 | loss: 1.7785 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2914/2499940 | global iter:   1458/1249970 | loss: 0.9157 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2916/2499940 | global iter:   1459/1249970 | loss: 1.5306 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2918/2499940 | global iter:   1460/1249970 | loss: 1.5598 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2918/2499940 | global iter:   1460/1249970 | loss: 1.2944 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2920/2499940 | global iter:   1461/1249970 | loss: 1.3759 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2922/2499940 | global iter:   1462/1249970 | loss: 0.8975 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2924/2499940 | global iter:   1463/1249970 | loss: 1.4660 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2926/2499940 | global iter:   1464/1249970 | loss: 0.1730 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2926/2499940 | global iter:   1464/1249970 | loss: 1.1031 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2928/2499940 | global iter:   1465/1249970 | loss: 1.0070 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2930/2499940 | global iter:   1466/1249970 | loss: 1.1931 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2932/2499940 | global iter:   1467/1249970 | loss: 0.9660 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2934/2499940 | global iter:   1468/1249970 | loss: 1.1510 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2934/2499940 | global iter:   1468/1249970 | loss: 0.9482 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2936/2499940 | global iter:   1469/1249970 | loss: 1.2562 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2938/2499940 | global iter:   1470/1249970 | loss: 1.3389 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2940/2499940 | global iter:   1471/1249970 | loss: 1.0388 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2942/2499940 | global iter:   1472/1249970 | loss: 0.8169 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2942/2499940 | global iter:   1472/1249970 | loss: 1.1123 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2944/2499940 | global iter:   1473/1249970 | loss: 1.0389 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:   2946/2499940 | global iter:   1474/1249970 | loss: 0.1082 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2948/2499940 | global iter:   1475/1249970 | loss: 1.4923 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2950/2499940 | global iter:   1476/1249970 | loss: 1.6508 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2950/2499940 | global iter:   1476/1249970 | loss: 1.1163 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2952/2499940 | global iter:   1477/1249970 | loss: 1.5675 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2954/2499940 | global iter:   1478/1249970 | loss: 0.4647 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.410 | step time: 0.000
train | epoch   0 | Iter:   2956/2499940 | global iter:   1479/1249970 | loss: 1.8749 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2958/2499940 | global iter:   1480/1249970 | loss: 0.9046 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2958/2499940 | global iter:   1480/1249970 | loss: 1.1364 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.695
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2960/2499940 | global iter:   1481/1249970 | loss: 1.7602 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2962/2499940 | global iter:   1482/1249970 | loss: 0.3742 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   2964/2499940 | global iter:   1483/1249970 | loss: 1.1442 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2966/2499940 | global iter:   1484/1249970 | loss: 1.5085 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2966/2499940 | global iter:   1484/1249970 | loss: 1.1550 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2968/2499940 | global iter:   1485/1249970 | loss: 1.1743 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2970/2499940 | global iter:   1486/1249970 | loss: 1.7728 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   2972/2499940 | global iter:   1487/1249970 | loss: 1.3917 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   2974/2499940 | global iter:   1488/1249970 | loss: 1.6147 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2974/2499940 | global iter:   1488/1249970 | loss: 1.3875 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2976/2499940 | global iter:   1489/1249970 | loss: 1.5097 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2978/2499940 | global iter:   1490/1249970 | loss: 1.2216 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2980/2499940 | global iter:   1491/1249970 | loss: 1.2060 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2982/2499940 | global iter:   1492/1249970 | loss: 1.0629 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2982/2499940 | global iter:   1492/1249970 | loss: 1.3658 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2984/2499940 | global iter:   1493/1249970 | loss: 1.2474 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   2986/2499940 | global iter:   1494/1249970 | loss: 1.7108 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   2988/2499940 | global iter:   1495/1249970 | loss: 1.2303 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   2990/2499940 | global iter:   1496/1249970 | loss: 1.1404 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2990/2499940 | global iter:   1496/1249970 | loss: 1.2212 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   2992/2499940 | global iter:   1497/1249970 | loss: 1.4562 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:   2994/2499940 | global iter:   1498/1249970 | loss: 1.7668 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   2996/2499940 | global iter:   1499/1249970 | loss: 1.7216 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   2998/2499940 | global iter:   1500/1249970 | loss: 1.4301 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2998/2499940 | global iter:   1500/1249970 | loss: 1.5185 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3000/2499940 | global iter:   1501/1249970 | loss: 0.6391 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3002/2499940 | global iter:   1502/1249970 | loss: 1.3537 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3004/2499940 | global iter:   1503/1249970 | loss: 1.4925 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3006/2499940 | global iter:   1504/1249970 | loss: 1.5971 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3006/2499940 | global iter:   1504/1249970 | loss: 1.0540 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3008/2499940 | global iter:   1505/1249970 | loss: 1.4509 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3010/2499940 | global iter:   1506/1249970 | loss: 1.4908 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   3012/2499940 | global iter:   1507/1249970 | loss: 1.7255 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3014/2499940 | global iter:   1508/1249970 | loss: 0.8748 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3014/2499940 | global iter:   1508/1249970 | loss: 1.4458 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3016/2499940 | global iter:   1509/1249970 | loss: 0.9369 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3018/2499940 | global iter:   1510/1249970 | loss: 1.4513 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3020/2499940 | global iter:   1511/1249970 | loss: 1.1591 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3022/2499940 | global iter:   1512/1249970 | loss: 1.0088 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3022/2499940 | global iter:   1512/1249970 | loss: 1.0946 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3024/2499940 | global iter:   1513/1249970 | loss: 1.3676 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3026/2499940 | global iter:   1514/1249970 | loss: 1.3990 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3028/2499940 | global iter:   1515/1249970 | loss: 1.2497 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3030/2499940 | global iter:   1516/1249970 | loss: 1.0275 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3030/2499940 | global iter:   1516/1249970 | loss: 1.2668 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3032/2499940 | global iter:   1517/1249970 | loss: 1.8004 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3034/2499940 | global iter:   1518/1249970 | loss: 1.7162 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3036/2499940 | global iter:   1519/1249970 | loss: 1.2660 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3038/2499940 | global iter:   1520/1249970 | loss: 0.0238 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3038/2499940 | global iter:   1520/1249970 | loss: 1.0464 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3040/2499940 | global iter:   1521/1249970 | loss: 1.1032 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3042/2499940 | global iter:   1522/1249970 | loss: 1.1729 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3044/2499940 | global iter:   1523/1249970 | loss: 1.0767 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3046/2499940 | global iter:   1524/1249970 | loss: 2.2318 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3046/2499940 | global iter:   1524/1249970 | loss: 1.2751 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3048/2499940 | global iter:   1525/1249970 | loss: 1.4013 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3050/2499940 | global iter:   1526/1249970 | loss: 0.5509 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3052/2499940 | global iter:   1527/1249970 | loss: 1.1349 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3054/2499940 | global iter:   1528/1249970 | loss: 0.9876 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3054/2499940 | global iter:   1528/1249970 | loss: 1.1386 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3056/2499940 | global iter:   1529/1249970 | loss: 1.1194 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3058/2499940 | global iter:   1530/1249970 | loss: 0.9987 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3060/2499940 | global iter:   1531/1249970 | loss: 1.5479 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3062/2499940 | global iter:   1532/1249970 | loss: 0.9933 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3062/2499940 | global iter:   1532/1249970 | loss: 1.2120 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3064/2499940 | global iter:   1533/1249970 | loss: 0.5517 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3066/2499940 | global iter:   1534/1249970 | loss: 1.1649 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3068/2499940 | global iter:   1535/1249970 | loss: 1.6171 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3070/2499940 | global iter:   1536/1249970 | loss: 0.6727 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3070/2499940 | global iter:   1536/1249970 | loss: 1.0949 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3072/2499940 | global iter:   1537/1249970 | loss: 1.6023 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3074/2499940 | global iter:   1538/1249970 | loss: 0.8433 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3076/2499940 | global iter:   1539/1249970 | loss: 1.6145 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3078/2499940 | global iter:   1540/1249970 | loss: 1.1657 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3078/2499940 | global iter:   1540/1249970 | loss: 1.3267 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3080/2499940 | global iter:   1541/1249970 | loss: 1.2470 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3082/2499940 | global iter:   1542/1249970 | loss: 0.8856 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3084/2499940 | global iter:   1543/1249970 | loss: 0.9929 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3086/2499940 | global iter:   1544/1249970 | loss: 0.5397 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3086/2499940 | global iter:   1544/1249970 | loss: 1.0472 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3088/2499940 | global iter:   1545/1249970 | loss: 1.9338 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3090/2499940 | global iter:   1546/1249970 | loss: 1.3252 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   3092/2499940 | global iter:   1547/1249970 | loss: 1.0711 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3094/2499940 | global iter:   1548/1249970 | loss: 0.7707 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3094/2499940 | global iter:   1548/1249970 | loss: 1.2038 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3096/2499940 | global iter:   1549/1249970 | loss: 0.7693 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3098/2499940 | global iter:   1550/1249970 | loss: 0.8776 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3100/2499940 | global iter:   1551/1249970 | loss: 1.0201 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3102/2499940 | global iter:   1552/1249970 | loss: 1.2549 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3102/2499940 | global iter:   1552/1249970 | loss: 1.0195 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3104/2499940 | global iter:   1553/1249970 | loss: 0.7680 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3106/2499940 | global iter:   1554/1249970 | loss: 0.5126 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3108/2499940 | global iter:   1555/1249970 | loss: 1.4099 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3110/2499940 | global iter:   1556/1249970 | loss: 1.5748 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3110/2499940 | global iter:   1556/1249970 | loss: 1.2868 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3112/2499940 | global iter:   1557/1249970 | loss: 0.6869 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3114/2499940 | global iter:   1558/1249970 | loss: 1.3494 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3116/2499940 | global iter:   1559/1249970 | loss: 0.2804 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3118/2499940 | global iter:   1560/1249970 | loss: 1.2987 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3118/2499940 | global iter:   1560/1249970 | loss: 0.9988 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3120/2499940 | global iter:   1561/1249970 | loss: 0.7857 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3122/2499940 | global iter:   1562/1249970 | loss: 1.4019 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3124/2499940 | global iter:   1563/1249970 | loss: 1.2201 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3126/2499940 | global iter:   1564/1249970 | loss: 0.7020 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3126/2499940 | global iter:   1564/1249970 | loss: 0.7957 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3128/2499940 | global iter:   1565/1249970 | loss: 0.7984 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3130/2499940 | global iter:   1566/1249970 | loss: 0.9621 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3132/2499940 | global iter:   1567/1249970 | loss: 1.3340 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3134/2499940 | global iter:   1568/1249970 | loss: 1.2895 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3134/2499940 | global iter:   1568/1249970 | loss: 1.2462 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3136/2499940 | global iter:   1569/1249970 | loss: 1.0615 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3138/2499940 | global iter:   1570/1249970 | loss: 1.0640 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3140/2499940 | global iter:   1571/1249970 | loss: 1.4335 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3142/2499940 | global iter:   1572/1249970 | loss: 2.0080 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3142/2499940 | global iter:   1572/1249970 | loss: 1.3496 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3144/2499940 | global iter:   1573/1249970 | loss: 1.2958 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3146/2499940 | global iter:   1574/1249970 | loss: 1.9017 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3148/2499940 | global iter:   1575/1249970 | loss: 1.1262 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3150/2499940 | global iter:   1576/1249970 | loss: 1.6646 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3150/2499940 | global iter:   1576/1249970 | loss: 1.3040 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3152/2499940 | global iter:   1577/1249970 | loss: 0.8498 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3154/2499940 | global iter:   1578/1249970 | loss: 1.2217 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3156/2499940 | global iter:   1579/1249970 | loss: 0.9452 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3158/2499940 | global iter:   1580/1249970 | loss: 1.5726 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3158/2499940 | global iter:   1580/1249970 | loss: 1.0681 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3160/2499940 | global iter:   1581/1249970 | loss: 0.6256 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3162/2499940 | global iter:   1582/1249970 | loss: 1.6487 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3164/2499940 | global iter:   1583/1249970 | loss: 1.6998 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3166/2499940 | global iter:   1584/1249970 | loss: 1.2652 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3166/2499940 | global iter:   1584/1249970 | loss: 1.2512 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3168/2499940 | global iter:   1585/1249970 | loss: 1.8060 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3170/2499940 | global iter:   1586/1249970 | loss: 1.1997 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   3172/2499940 | global iter:   1587/1249970 | loss: 1.8983 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3174/2499940 | global iter:   1588/1249970 | loss: 0.5334 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3174/2499940 | global iter:   1588/1249970 | loss: 1.3111 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3176/2499940 | global iter:   1589/1249970 | loss: 1.0105 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3178/2499940 | global iter:   1590/1249970 | loss: 1.6322 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3180/2499940 | global iter:   1591/1249970 | loss: 0.8259 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3182/2499940 | global iter:   1592/1249970 | loss: 0.9104 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3182/2499940 | global iter:   1592/1249970 | loss: 0.9299 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3184/2499940 | global iter:   1593/1249970 | loss: 1.6456 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3186/2499940 | global iter:   1594/1249970 | loss: 1.4641 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3188/2499940 | global iter:   1595/1249970 | loss: 1.2872 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3190/2499940 | global iter:   1596/1249970 | loss: 2.0342 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3190/2499940 | global iter:   1596/1249970 | loss: 1.2707 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3192/2499940 | global iter:   1597/1249970 | loss: 1.2179 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3194/2499940 | global iter:   1598/1249970 | loss: 1.7210 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3196/2499940 | global iter:   1599/1249970 | loss: 1.5247 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:   3198/2499940 | global iter:   1600/1249970 | loss: 1.4998 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3198/2499940 | global iter:   1600/1249970 | loss: 1.4727 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3200/2499940 | global iter:   1601/1249970 | loss: 1.3312 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3202/2499940 | global iter:   1602/1249970 | loss: 0.7513 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3204/2499940 | global iter:   1603/1249970 | loss: 1.1358 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3206/2499940 | global iter:   1604/1249970 | loss: 0.3037 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3206/2499940 | global iter:   1604/1249970 | loss: 1.0504 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3208/2499940 | global iter:   1605/1249970 | loss: 1.4679 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3210/2499940 | global iter:   1606/1249970 | loss: 1.6362 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3212/2499940 | global iter:   1607/1249970 | loss: 1.2320 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.407 | step time: 0.000
train | epoch   0 | Iter:   3214/2499940 | global iter:   1608/1249970 | loss: 0.6192 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3214/2499940 | global iter:   1608/1249970 | loss: 1.3168 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.695
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3216/2499940 | global iter:   1609/1249970 | loss: 2.1886 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3218/2499940 | global iter:   1610/1249970 | loss: 1.5963 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3220/2499940 | global iter:   1611/1249970 | loss: 1.3771 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3222/2499940 | global iter:   1612/1249970 | loss: 0.8534 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3222/2499940 | global iter:   1612/1249970 | loss: 1.3120 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3224/2499940 | global iter:   1613/1249970 | loss: 0.3388 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3226/2499940 | global iter:   1614/1249970 | loss: 0.5436 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3228/2499940 | global iter:   1615/1249970 | loss: 1.2466 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3230/2499940 | global iter:   1616/1249970 | loss: 1.2063 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3230/2499940 | global iter:   1616/1249970 | loss: 0.9972 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3232/2499940 | global iter:   1617/1249970 | loss: 1.1964 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3234/2499940 | global iter:   1618/1249970 | loss: 0.8236 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3236/2499940 | global iter:   1619/1249970 | loss: 2.1371 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3238/2499940 | global iter:   1620/1249970 | loss: 1.2276 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3238/2499940 | global iter:   1620/1249970 | loss: 1.2439 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3240/2499940 | global iter:   1621/1249970 | loss: 0.6788 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3242/2499940 | global iter:   1622/1249970 | loss: 1.5025 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3244/2499940 | global iter:   1623/1249970 | loss: 1.6475 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3246/2499940 | global iter:   1624/1249970 | loss: 1.0361 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3246/2499940 | global iter:   1624/1249970 | loss: 1.2539 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3248/2499940 | global iter:   1625/1249970 | loss: 1.4072 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3250/2499940 | global iter:   1626/1249970 | loss: 1.4244 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3252/2499940 | global iter:   1627/1249970 | loss: 1.4690 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3254/2499940 | global iter:   1628/1249970 | loss: 1.3089 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3254/2499940 | global iter:   1628/1249970 | loss: 1.3723 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3256/2499940 | global iter:   1629/1249970 | loss: 1.3661 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3258/2499940 | global iter:   1630/1249970 | loss: 1.2685 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3260/2499940 | global iter:   1631/1249970 | loss: 0.7343 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3262/2499940 | global iter:   1632/1249970 | loss: 1.1716 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3262/2499940 | global iter:   1632/1249970 | loss: 1.2512 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3264/2499940 | global iter:   1633/1249970 | loss: 1.2143 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3266/2499940 | global iter:   1634/1249970 | loss: 1.3796 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3268/2499940 | global iter:   1635/1249970 | loss: 0.6815 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3270/2499940 | global iter:   1636/1249970 | loss: 1.0277 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3270/2499940 | global iter:   1636/1249970 | loss: 1.1541 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.393 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3272/2499940 | global iter:   1637/1249970 | loss: 1.0093 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3274/2499940 | global iter:   1638/1249970 | loss: 1.0438 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3276/2499940 | global iter:   1639/1249970 | loss: 0.8780 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3278/2499940 | global iter:   1640/1249970 | loss: 1.3333 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3278/2499940 | global iter:   1640/1249970 | loss: 1.0804 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3280/2499940 | global iter:   1641/1249970 | loss: 0.6860 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3282/2499940 | global iter:   1642/1249970 | loss: 1.4670 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3284/2499940 | global iter:   1643/1249970 | loss: 1.0048 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3286/2499940 | global iter:   1644/1249970 | loss: 1.6668 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3286/2499940 | global iter:   1644/1249970 | loss: 1.0468 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3288/2499940 | global iter:   1645/1249970 | loss: 1.5753 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3290/2499940 | global iter:   1646/1249970 | loss: 1.9031 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3292/2499940 | global iter:   1647/1249970 | loss: 0.4529 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3294/2499940 | global iter:   1648/1249970 | loss: 1.2586 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3294/2499940 | global iter:   1648/1249970 | loss: 1.3693 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3296/2499940 | global iter:   1649/1249970 | loss: 1.5293 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3298/2499940 | global iter:   1650/1249970 | loss: 0.2720 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3300/2499940 | global iter:   1651/1249970 | loss: 1.2029 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3302/2499940 | global iter:   1652/1249970 | loss: 1.5907 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3302/2499940 | global iter:   1652/1249970 | loss: 1.1949 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3304/2499940 | global iter:   1653/1249970 | loss: 0.7918 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3306/2499940 | global iter:   1654/1249970 | loss: 2.1343 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   3308/2499940 | global iter:   1655/1249970 | loss: 1.1683 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3310/2499940 | global iter:   1656/1249970 | loss: 1.8950 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3310/2499940 | global iter:   1656/1249970 | loss: 1.4894 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3312/2499940 | global iter:   1657/1249970 | loss: 1.6833 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3314/2499940 | global iter:   1658/1249970 | loss: 1.4142 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3316/2499940 | global iter:   1659/1249970 | loss: 1.4784 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3318/2499940 | global iter:   1660/1249970 | loss: 0.9009 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3318/2499940 | global iter:   1660/1249970 | loss: 1.4246 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3320/2499940 | global iter:   1661/1249970 | loss: 1.0593 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   3322/2499940 | global iter:   1662/1249970 | loss: 1.0682 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3324/2499940 | global iter:   1663/1249970 | loss: 1.1752 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3326/2499940 | global iter:   1664/1249970 | loss: 1.5431 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3326/2499940 | global iter:   1664/1249970 | loss: 1.2861 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3328/2499940 | global iter:   1665/1249970 | loss: 1.0922 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3330/2499940 | global iter:   1666/1249970 | loss: 1.9786 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3332/2499940 | global iter:   1667/1249970 | loss: 1.9333 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3334/2499940 | global iter:   1668/1249970 | loss: 1.7017 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3334/2499940 | global iter:   1668/1249970 | loss: 1.3230 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3336/2499940 | global iter:   1669/1249970 | loss: 1.0933 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3338/2499940 | global iter:   1670/1249970 | loss: 0.9103 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3340/2499940 | global iter:   1671/1249970 | loss: 1.5391 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3342/2499940 | global iter:   1672/1249970 | loss: 1.7146 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3342/2499940 | global iter:   1672/1249970 | loss: 1.1207 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3344/2499940 | global iter:   1673/1249970 | loss: 1.7932 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3346/2499940 | global iter:   1674/1249970 | loss: 0.3232 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3348/2499940 | global iter:   1675/1249970 | loss: 1.0099 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3350/2499940 | global iter:   1676/1249970 | loss: 1.7764 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3350/2499940 | global iter:   1676/1249970 | loss: 1.0037 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3352/2499940 | global iter:   1677/1249970 | loss: 1.3368 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3354/2499940 | global iter:   1678/1249970 | loss: 1.2646 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3356/2499940 | global iter:   1679/1249970 | loss: 1.7610 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3358/2499940 | global iter:   1680/1249970 | loss: 0.8425 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3358/2499940 | global iter:   1680/1249970 | loss: 1.2414 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3360/2499940 | global iter:   1681/1249970 | loss: 1.4570 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3362/2499940 | global iter:   1682/1249970 | loss: 1.1289 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3364/2499940 | global iter:   1683/1249970 | loss: 1.4173 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3366/2499940 | global iter:   1684/1249970 | loss: 1.4820 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3366/2499940 | global iter:   1684/1249970 | loss: 1.2678 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3368/2499940 | global iter:   1685/1249970 | loss: 1.0071 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3370/2499940 | global iter:   1686/1249970 | loss: 0.7070 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3372/2499940 | global iter:   1687/1249970 | loss: 1.3435 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3374/2499940 | global iter:   1688/1249970 | loss: 0.9902 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3374/2499940 | global iter:   1688/1249970 | loss: 0.9484 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3376/2499940 | global iter:   1689/1249970 | loss: 1.3182 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3378/2499940 | global iter:   1690/1249970 | loss: 1.0661 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   3380/2499940 | global iter:   1691/1249970 | loss: 0.8760 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3382/2499940 | global iter:   1692/1249970 | loss: 0.9960 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3382/2499940 | global iter:   1692/1249970 | loss: 1.1861 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3384/2499940 | global iter:   1693/1249970 | loss: 1.3467 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3386/2499940 | global iter:   1694/1249970 | loss: 0.5655 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3388/2499940 | global iter:   1695/1249970 | loss: 0.8718 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3390/2499940 | global iter:   1696/1249970 | loss: 1.3517 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3390/2499940 | global iter:   1696/1249970 | loss: 1.1542 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3392/2499940 | global iter:   1697/1249970 | loss: 1.1396 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3394/2499940 | global iter:   1698/1249970 | loss: 1.1590 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   3396/2499940 | global iter:   1699/1249970 | loss: 0.5462 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3398/2499940 | global iter:   1700/1249970 | loss: 1.8586 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3398/2499940 | global iter:   1700/1249970 | loss: 1.2899 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3400/2499940 | global iter:   1701/1249970 | loss: 1.4401 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3402/2499940 | global iter:   1702/1249970 | loss: 0.0219 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3404/2499940 | global iter:   1703/1249970 | loss: 0.9379 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3406/2499940 | global iter:   1704/1249970 | loss: 1.0411 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3406/2499940 | global iter:   1704/1249970 | loss: 0.8755 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3408/2499940 | global iter:   1705/1249970 | loss: 0.6320 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3410/2499940 | global iter:   1706/1249970 | loss: 0.9063 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3412/2499940 | global iter:   1707/1249970 | loss: 0.5374 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3414/2499940 | global iter:   1708/1249970 | loss: 1.7809 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3414/2499940 | global iter:   1708/1249970 | loss: 1.0041 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3416/2499940 | global iter:   1709/1249970 | loss: 1.4723 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3418/2499940 | global iter:   1710/1249970 | loss: 2.2069 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3420/2499940 | global iter:   1711/1249970 | loss: 1.2937 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3422/2499940 | global iter:   1712/1249970 | loss: 1.2871 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3422/2499940 | global iter:   1712/1249970 | loss: 1.2570 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3424/2499940 | global iter:   1713/1249970 | loss: 1.5110 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3426/2499940 | global iter:   1714/1249970 | loss: 1.3729 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3428/2499940 | global iter:   1715/1249970 | loss: 1.7144 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3430/2499940 | global iter:   1716/1249970 | loss: 1.3764 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3430/2499940 | global iter:   1716/1249970 | loss: 1.3070 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3432/2499940 | global iter:   1717/1249970 | loss: 0.6859 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3434/2499940 | global iter:   1718/1249970 | loss: 0.4963 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3436/2499940 | global iter:   1719/1249970 | loss: 0.4517 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3438/2499940 | global iter:   1720/1249970 | loss: 1.3659 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3438/2499940 | global iter:   1720/1249970 | loss: 0.9463 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3440/2499940 | global iter:   1721/1249970 | loss: 1.5709 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3442/2499940 | global iter:   1722/1249970 | loss: 1.2060 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3444/2499940 | global iter:   1723/1249970 | loss: 0.7849 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3446/2499940 | global iter:   1724/1249970 | loss: 0.7181 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3446/2499940 | global iter:   1724/1249970 | loss: 1.3034 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3448/2499940 | global iter:   1725/1249970 | loss: 0.7317 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3450/2499940 | global iter:   1726/1249970 | loss: 1.1204 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   3452/2499940 | global iter:   1727/1249970 | loss: 0.8530 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3454/2499940 | global iter:   1728/1249970 | loss: 1.6313 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3454/2499940 | global iter:   1728/1249970 | loss: 1.4107 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3456/2499940 | global iter:   1729/1249970 | loss: 0.8767 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3458/2499940 | global iter:   1730/1249970 | loss: 1.5652 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3460/2499940 | global iter:   1731/1249970 | loss: 0.9411 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3462/2499940 | global iter:   1732/1249970 | loss: 1.1697 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3462/2499940 | global iter:   1732/1249970 | loss: 1.1619 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3464/2499940 | global iter:   1733/1249970 | loss: 0.6299 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3466/2499940 | global iter:   1734/1249970 | loss: 1.1409 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3468/2499940 | global iter:   1735/1249970 | loss: 0.8817 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3470/2499940 | global iter:   1736/1249970 | loss: 0.7442 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3470/2499940 | global iter:   1736/1249970 | loss: 1.1318 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3472/2499940 | global iter:   1737/1249970 | loss: 0.0458 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.409 | step time: 0.000
train | epoch   0 | Iter:   3474/2499940 | global iter:   1738/1249970 | loss: 2.1045 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3476/2499940 | global iter:   1739/1249970 | loss: 0.8305 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3478/2499940 | global iter:   1740/1249970 | loss: 1.3792 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3478/2499940 | global iter:   1740/1249970 | loss: 1.1669 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3480/2499940 | global iter:   1741/1249970 | loss: 1.3025 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3482/2499940 | global iter:   1742/1249970 | loss: 0.4442 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3484/2499940 | global iter:   1743/1249970 | loss: 1.7264 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3486/2499940 | global iter:   1744/1249970 | loss: 1.0322 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3486/2499940 | global iter:   1744/1249970 | loss: 1.3020 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3488/2499940 | global iter:   1745/1249970 | loss: 0.5590 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3490/2499940 | global iter:   1746/1249970 | loss: 0.9944 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3492/2499940 | global iter:   1747/1249970 | loss: 0.6617 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3494/2499940 | global iter:   1748/1249970 | loss: 1.4250 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3494/2499940 | global iter:   1748/1249970 | loss: 0.9302 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3496/2499940 | global iter:   1749/1249970 | loss: 1.6208 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3498/2499940 | global iter:   1750/1249970 | loss: 1.5211 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3500/2499940 | global iter:   1751/1249970 | loss: 1.2626 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3502/2499940 | global iter:   1752/1249970 | loss: 1.0467 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3502/2499940 | global iter:   1752/1249970 | loss: 1.4473 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3504/2499940 | global iter:   1753/1249970 | loss: 1.1212 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3506/2499940 | global iter:   1754/1249970 | loss: 1.3592 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3508/2499940 | global iter:   1755/1249970 | loss: 0.4977 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3510/2499940 | global iter:   1756/1249970 | loss: 0.9030 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3510/2499940 | global iter:   1756/1249970 | loss: 1.0491 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3512/2499940 | global iter:   1757/1249970 | loss: 1.3342 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3514/2499940 | global iter:   1758/1249970 | loss: 0.5632 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3516/2499940 | global iter:   1759/1249970 | loss: 0.6048 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3518/2499940 | global iter:   1760/1249970 | loss: 0.8709 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3518/2499940 | global iter:   1760/1249970 | loss: 1.0305 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3520/2499940 | global iter:   1761/1249970 | loss: 0.8777 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   3522/2499940 | global iter:   1762/1249970 | loss: 1.5002 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3524/2499940 | global iter:   1763/1249970 | loss: 1.2169 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3526/2499940 | global iter:   1764/1249970 | loss: 1.0862 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3526/2499940 | global iter:   1764/1249970 | loss: 1.0708 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3528/2499940 | global iter:   1765/1249970 | loss: 1.0967 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
[2025-04-20 16:25:40,450] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8192, reducing to 4096
train | epoch   0 | Iter:   3530/2499940 | global iter:   1766/1249970 | loss: 0.9494 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.307 | step time: 0.000
train | epoch   0 | Iter:   3532/2499940 | global iter:   1767/1249970 | loss: 1.0649 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   3534/2499940 | global iter:   1768/1249970 | loss: 0.3776 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3534/2499940 | global iter:   1768/1249970 | loss: 0.8106 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.667
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3536/2499940 | global iter:   1769/1249970 | loss: 1.1111 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3538/2499940 | global iter:   1770/1249970 | loss: 0.9954 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3540/2499940 | global iter:   1771/1249970 | loss: 0.6088 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3542/2499940 | global iter:   1772/1249970 | loss: 0.8200 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3542/2499940 | global iter:   1772/1249970 | loss: 0.9313 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3544/2499940 | global iter:   1773/1249970 | loss: 0.9042 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3546/2499940 | global iter:   1774/1249970 | loss: 0.8558 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3548/2499940 | global iter:   1775/1249970 | loss: 0.9081 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3550/2499940 | global iter:   1776/1249970 | loss: 1.0547 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3550/2499940 | global iter:   1776/1249970 | loss: 0.9947 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3552/2499940 | global iter:   1777/1249970 | loss: 1.4405 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3554/2499940 | global iter:   1778/1249970 | loss: 1.2393 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3556/2499940 | global iter:   1779/1249970 | loss: 1.5277 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3558/2499940 | global iter:   1780/1249970 | loss: 1.1697 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3558/2499940 | global iter:   1780/1249970 | loss: 1.1203 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3560/2499940 | global iter:   1781/1249970 | loss: 1.6395 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3562/2499940 | global iter:   1782/1249970 | loss: 1.1701 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3564/2499940 | global iter:   1783/1249970 | loss: 1.2004 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3566/2499940 | global iter:   1784/1249970 | loss: 0.4898 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3566/2499940 | global iter:   1784/1249970 | loss: 1.0627 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3568/2499940 | global iter:   1785/1249970 | loss: 0.8087 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3570/2499940 | global iter:   1786/1249970 | loss: 1.6186 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3572/2499940 | global iter:   1787/1249970 | loss: 1.5308 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3574/2499940 | global iter:   1788/1249970 | loss: 1.4912 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3574/2499940 | global iter:   1788/1249970 | loss: 0.9391 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3576/2499940 | global iter:   1789/1249970 | loss: 1.1993 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3578/2499940 | global iter:   1790/1249970 | loss: 0.7523 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3580/2499940 | global iter:   1791/1249970 | loss: 1.4442 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3582/2499940 | global iter:   1792/1249970 | loss: 1.3924 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3582/2499940 | global iter:   1792/1249970 | loss: 1.0640 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3584/2499940 | global iter:   1793/1249970 | loss: 1.0151 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3586/2499940 | global iter:   1794/1249970 | loss: 0.8303 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   3588/2499940 | global iter:   1795/1249970 | loss: 1.8971 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3590/2499940 | global iter:   1796/1249970 | loss: 0.8386 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3590/2499940 | global iter:   1796/1249970 | loss: 1.1249 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3592/2499940 | global iter:   1797/1249970 | loss: 0.9701 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3594/2499940 | global iter:   1798/1249970 | loss: 0.1417 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3596/2499940 | global iter:   1799/1249970 | loss: 1.0275 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3598/2499940 | global iter:   1800/1249970 | loss: 1.7194 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3598/2499940 | global iter:   1800/1249970 | loss: 1.0525 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3600/2499940 | global iter:   1801/1249970 | loss: 1.0914 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3602/2499940 | global iter:   1802/1249970 | loss: 1.8415 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   3604/2499940 | global iter:   1803/1249970 | loss: 1.7073 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3606/2499940 | global iter:   1804/1249970 | loss: 1.6309 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3606/2499940 | global iter:   1804/1249970 | loss: 1.2926 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3608/2499940 | global iter:   1805/1249970 | loss: 1.2035 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3610/2499940 | global iter:   1806/1249970 | loss: 1.4998 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3612/2499940 | global iter:   1807/1249970 | loss: 0.8788 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3614/2499940 | global iter:   1808/1249970 | loss: 1.0144 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3614/2499940 | global iter:   1808/1249970 | loss: 1.2007 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3616/2499940 | global iter:   1809/1249970 | loss: 1.5149 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3618/2499940 | global iter:   1810/1249970 | loss: 1.2647 | ds_loss: 0.0000 | lr: 1.0000e-05 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   3620/2499940 | global iter:   1811/1249970 | loss: 1.2325 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3622/2499940 | global iter:   1812/1249970 | loss: 0.7116 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3622/2499940 | global iter:   1812/1249970 | loss: 1.1321 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3624/2499940 | global iter:   1813/1249970 | loss: 0.9460 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3626/2499940 | global iter:   1814/1249970 | loss: 0.9006 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3628/2499940 | global iter:   1815/1249970 | loss: 1.8135 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3630/2499940 | global iter:   1816/1249970 | loss: 1.5733 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3630/2499940 | global iter:   1816/1249970 | loss: 1.1685 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3632/2499940 | global iter:   1817/1249970 | loss: 0.6694 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3634/2499940 | global iter:   1818/1249970 | loss: 1.0524 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3636/2499940 | global iter:   1819/1249970 | loss: 0.8718 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3638/2499940 | global iter:   1820/1249970 | loss: 0.4534 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3638/2499940 | global iter:   1820/1249970 | loss: 0.9958 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3640/2499940 | global iter:   1821/1249970 | loss: 1.3825 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3642/2499940 | global iter:   1822/1249970 | loss: 0.8729 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3644/2499940 | global iter:   1823/1249970 | loss: 1.7314 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3646/2499940 | global iter:   1824/1249970 | loss: 0.6860 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3646/2499940 | global iter:   1824/1249970 | loss: 1.0672 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3648/2499940 | global iter:   1825/1249970 | loss: 0.4042 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3650/2499940 | global iter:   1826/1249970 | loss: 0.9964 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3652/2499940 | global iter:   1827/1249970 | loss: 1.0879 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3654/2499940 | global iter:   1828/1249970 | loss: 1.0092 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3654/2499940 | global iter:   1828/1249970 | loss: 0.7618 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3656/2499940 | global iter:   1829/1249970 | loss: 1.1613 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3658/2499940 | global iter:   1830/1249970 | loss: 0.8429 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   3660/2499940 | global iter:   1831/1249970 | loss: 1.2763 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3662/2499940 | global iter:   1832/1249970 | loss: 1.0095 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3662/2499940 | global iter:   1832/1249970 | loss: 1.3194 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3664/2499940 | global iter:   1833/1249970 | loss: 1.5402 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3666/2499940 | global iter:   1834/1249970 | loss: 0.8639 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3668/2499940 | global iter:   1835/1249970 | loss: 0.9666 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3670/2499940 | global iter:   1836/1249970 | loss: 1.2646 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3670/2499940 | global iter:   1836/1249970 | loss: 1.3205 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3672/2499940 | global iter:   1837/1249970 | loss: 1.8583 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3674/2499940 | global iter:   1838/1249970 | loss: 1.1872 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3676/2499940 | global iter:   1839/1249970 | loss: 1.4590 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3678/2499940 | global iter:   1840/1249970 | loss: 0.9406 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3678/2499940 | global iter:   1840/1249970 | loss: 1.2794 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3680/2499940 | global iter:   1841/1249970 | loss: 1.7248 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3682/2499940 | global iter:   1842/1249970 | loss: 1.2272 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3684/2499940 | global iter:   1843/1249970 | loss: 1.8576 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3686/2499940 | global iter:   1844/1249970 | loss: 1.2615 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3686/2499940 | global iter:   1844/1249970 | loss: 1.1487 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3688/2499940 | global iter:   1845/1249970 | loss: 0.7013 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3690/2499940 | global iter:   1846/1249970 | loss: 1.4920 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3692/2499940 | global iter:   1847/1249970 | loss: 1.6494 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3694/2499940 | global iter:   1848/1249970 | loss: 1.0828 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3694/2499940 | global iter:   1848/1249970 | loss: 1.1102 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3696/2499940 | global iter:   1849/1249970 | loss: 1.6997 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3698/2499940 | global iter:   1850/1249970 | loss: 1.2016 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   3700/2499940 | global iter:   1851/1249970 | loss: 1.2609 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3702/2499940 | global iter:   1852/1249970 | loss: 1.2224 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3702/2499940 | global iter:   1852/1249970 | loss: 1.0326 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3704/2499940 | global iter:   1853/1249970 | loss: 1.5702 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3706/2499940 | global iter:   1854/1249970 | loss: 1.4103 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3708/2499940 | global iter:   1855/1249970 | loss: 0.6768 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3710/2499940 | global iter:   1856/1249970 | loss: 1.4895 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3710/2499940 | global iter:   1856/1249970 | loss: 1.2816 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3712/2499940 | global iter:   1857/1249970 | loss: 1.3549 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3714/2499940 | global iter:   1858/1249970 | loss: 0.4835 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3716/2499940 | global iter:   1859/1249970 | loss: 1.6555 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   3718/2499940 | global iter:   1860/1249970 | loss: 1.4352 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3718/2499940 | global iter:   1860/1249970 | loss: 1.1528 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3720/2499940 | global iter:   1861/1249970 | loss: 1.2159 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3722/2499940 | global iter:   1862/1249970 | loss: 0.8992 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   3724/2499940 | global iter:   1863/1249970 | loss: 0.8977 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3726/2499940 | global iter:   1864/1249970 | loss: 1.0859 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3726/2499940 | global iter:   1864/1249970 | loss: 1.0768 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3728/2499940 | global iter:   1865/1249970 | loss: 0.6414 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3730/2499940 | global iter:   1866/1249970 | loss: 1.2749 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3732/2499940 | global iter:   1867/1249970 | loss: 0.7273 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3734/2499940 | global iter:   1868/1249970 | loss: 0.8105 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.413 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3734/2499940 | global iter:   1868/1249970 | loss: 1.1078 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.413 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3736/2499940 | global iter:   1869/1249970 | loss: 0.8068 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3738/2499940 | global iter:   1870/1249970 | loss: 0.8122 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3740/2499940 | global iter:   1871/1249970 | loss: 0.8061 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3742/2499940 | global iter:   1872/1249970 | loss: 0.8013 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3742/2499940 | global iter:   1872/1249970 | loss: 0.7408 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3744/2499940 | global iter:   1873/1249970 | loss: 1.0676 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   3746/2499940 | global iter:   1874/1249970 | loss: 1.4561 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   3748/2499940 | global iter:   1875/1249970 | loss: 1.7268 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3750/2499940 | global iter:   1876/1249970 | loss: 1.5287 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3750/2499940 | global iter:   1876/1249970 | loss: 1.3155 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3752/2499940 | global iter:   1877/1249970 | loss: 0.9432 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3754/2499940 | global iter:   1878/1249970 | loss: 0.3081 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3756/2499940 | global iter:   1879/1249970 | loss: 1.1177 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3758/2499940 | global iter:   1880/1249970 | loss: 0.9639 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3758/2499940 | global iter:   1880/1249970 | loss: 1.0753 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3760/2499940 | global iter:   1881/1249970 | loss: 1.6948 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3762/2499940 | global iter:   1882/1249970 | loss: 1.0190 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3764/2499940 | global iter:   1883/1249970 | loss: 0.7150 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3766/2499940 | global iter:   1884/1249970 | loss: 0.8483 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3766/2499940 | global iter:   1884/1249970 | loss: 1.1741 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3768/2499940 | global iter:   1885/1249970 | loss: 0.7300 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3770/2499940 | global iter:   1886/1249970 | loss: 1.3135 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:   3772/2499940 | global iter:   1887/1249970 | loss: 1.5207 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3774/2499940 | global iter:   1888/1249970 | loss: 1.2556 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3774/2499940 | global iter:   1888/1249970 | loss: 1.2687 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3776/2499940 | global iter:   1889/1249970 | loss: 0.8517 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3778/2499940 | global iter:   1890/1249970 | loss: 1.4062 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3780/2499940 | global iter:   1891/1249970 | loss: 1.8425 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3782/2499940 | global iter:   1892/1249970 | loss: 1.2085 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3782/2499940 | global iter:   1892/1249970 | loss: 1.2137 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3784/2499940 | global iter:   1893/1249970 | loss: 0.7135 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3786/2499940 | global iter:   1894/1249970 | loss: 1.0627 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3788/2499940 | global iter:   1895/1249970 | loss: 1.2961 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3790/2499940 | global iter:   1896/1249970 | loss: 1.3766 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3790/2499940 | global iter:   1896/1249970 | loss: 1.0990 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3792/2499940 | global iter:   1897/1249970 | loss: 1.3036 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3794/2499940 | global iter:   1898/1249970 | loss: 1.2371 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3796/2499940 | global iter:   1899/1249970 | loss: 1.1289 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3798/2499940 | global iter:   1900/1249970 | loss: 0.8969 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3798/2499940 | global iter:   1900/1249970 | loss: 1.1529 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3800/2499940 | global iter:   1901/1249970 | loss: 0.8610 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3802/2499940 | global iter:   1902/1249970 | loss: 0.8393 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3804/2499940 | global iter:   1903/1249970 | loss: 1.1030 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3806/2499940 | global iter:   1904/1249970 | loss: 1.0222 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3806/2499940 | global iter:   1904/1249970 | loss: 1.1311 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3808/2499940 | global iter:   1905/1249970 | loss: 0.5331 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3810/2499940 | global iter:   1906/1249970 | loss: 1.0104 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3812/2499940 | global iter:   1907/1249970 | loss: 1.4574 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3814/2499940 | global iter:   1908/1249970 | loss: 1.5531 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3814/2499940 | global iter:   1908/1249970 | loss: 1.1101 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3816/2499940 | global iter:   1909/1249970 | loss: 1.3602 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3818/2499940 | global iter:   1910/1249970 | loss: 0.9723 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3820/2499940 | global iter:   1911/1249970 | loss: 1.7744 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3822/2499940 | global iter:   1912/1249970 | loss: 0.1962 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3822/2499940 | global iter:   1912/1249970 | loss: 1.2701 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3824/2499940 | global iter:   1913/1249970 | loss: 1.1461 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3826/2499940 | global iter:   1914/1249970 | loss: 1.9065 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3828/2499940 | global iter:   1915/1249970 | loss: 1.7267 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3830/2499940 | global iter:   1916/1249970 | loss: 0.7794 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3830/2499940 | global iter:   1916/1249970 | loss: 1.3821 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3832/2499940 | global iter:   1917/1249970 | loss: 1.7199 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3834/2499940 | global iter:   1918/1249970 | loss: 1.3890 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3836/2499940 | global iter:   1919/1249970 | loss: 1.7244 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3838/2499940 | global iter:   1920/1249970 | loss: 1.9365 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3838/2499940 | global iter:   1920/1249970 | loss: 1.5380 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3840/2499940 | global iter:   1921/1249970 | loss: 1.2857 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3842/2499940 | global iter:   1922/1249970 | loss: 0.8013 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3844/2499940 | global iter:   1923/1249970 | loss: 0.7310 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3846/2499940 | global iter:   1924/1249970 | loss: 1.5155 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3846/2499940 | global iter:   1924/1249970 | loss: 1.0375 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3848/2499940 | global iter:   1925/1249970 | loss: 0.5322 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3850/2499940 | global iter:   1926/1249970 | loss: 0.9332 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3852/2499940 | global iter:   1927/1249970 | loss: 1.7457 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3854/2499940 | global iter:   1928/1249970 | loss: 1.3785 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3854/2499940 | global iter:   1928/1249970 | loss: 1.2453 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3856/2499940 | global iter:   1929/1249970 | loss: 1.2899 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3858/2499940 | global iter:   1930/1249970 | loss: 0.8053 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3860/2499940 | global iter:   1931/1249970 | loss: 1.0261 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3862/2499940 | global iter:   1932/1249970 | loss: 1.6474 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3862/2499940 | global iter:   1932/1249970 | loss: 1.2267 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3864/2499940 | global iter:   1933/1249970 | loss: 0.3047 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3866/2499940 | global iter:   1934/1249970 | loss: 0.6497 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   3868/2499940 | global iter:   1935/1249970 | loss: 1.3437 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3870/2499940 | global iter:   1936/1249970 | loss: 0.9820 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3870/2499940 | global iter:   1936/1249970 | loss: 0.8110 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3872/2499940 | global iter:   1937/1249970 | loss: 0.9468 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3874/2499940 | global iter:   1938/1249970 | loss: 1.6015 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   3876/2499940 | global iter:   1939/1249970 | loss: 0.1860 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3878/2499940 | global iter:   1940/1249970 | loss: 1.4575 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3878/2499940 | global iter:   1940/1249970 | loss: 1.1206 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3880/2499940 | global iter:   1941/1249970 | loss: 1.0091 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3882/2499940 | global iter:   1942/1249970 | loss: 1.0029 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:   3884/2499940 | global iter:   1943/1249970 | loss: 0.4964 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3886/2499940 | global iter:   1944/1249970 | loss: 1.2544 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3886/2499940 | global iter:   1944/1249970 | loss: 0.9141 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3888/2499940 | global iter:   1945/1249970 | loss: 1.6660 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3890/2499940 | global iter:   1946/1249970 | loss: 0.9719 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3892/2499940 | global iter:   1947/1249970 | loss: 1.0091 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3894/2499940 | global iter:   1948/1249970 | loss: 1.5902 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3894/2499940 | global iter:   1948/1249970 | loss: 1.3172 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3896/2499940 | global iter:   1949/1249970 | loss: 1.4527 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3898/2499940 | global iter:   1950/1249970 | loss: 1.2744 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3900/2499940 | global iter:   1951/1249970 | loss: 1.7748 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3902/2499940 | global iter:   1952/1249970 | loss: 1.5299 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3902/2499940 | global iter:   1952/1249970 | loss: 1.2070 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3904/2499940 | global iter:   1953/1249970 | loss: 1.2412 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3906/2499940 | global iter:   1954/1249970 | loss: 1.6835 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3908/2499940 | global iter:   1955/1249970 | loss: 1.1614 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3910/2499940 | global iter:   1956/1249970 | loss: 0.4308 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3910/2499940 | global iter:   1956/1249970 | loss: 1.0540 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3912/2499940 | global iter:   1957/1249970 | loss: 0.4678 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   3914/2499940 | global iter:   1958/1249970 | loss: 0.9570 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3916/2499940 | global iter:   1959/1249970 | loss: 1.0347 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3918/2499940 | global iter:   1960/1249970 | loss: 1.7590 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3918/2499940 | global iter:   1960/1249970 | loss: 1.0748 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3920/2499940 | global iter:   1961/1249970 | loss: 1.7628 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3922/2499940 | global iter:   1962/1249970 | loss: 1.7287 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3924/2499940 | global iter:   1963/1249970 | loss: 1.0133 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3926/2499940 | global iter:   1964/1249970 | loss: 1.4447 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3926/2499940 | global iter:   1964/1249970 | loss: 1.2984 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3928/2499940 | global iter:   1965/1249970 | loss: 1.8567 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3930/2499940 | global iter:   1966/1249970 | loss: 1.7480 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   3932/2499940 | global iter:   1967/1249970 | loss: 1.6985 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3934/2499940 | global iter:   1968/1249970 | loss: 0.7924 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3934/2499940 | global iter:   1968/1249970 | loss: 1.3026 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3936/2499940 | global iter:   1969/1249970 | loss: 1.2456 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3938/2499940 | global iter:   1970/1249970 | loss: 1.0964 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3940/2499940 | global iter:   1971/1249970 | loss: 0.7436 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3942/2499940 | global iter:   1972/1249970 | loss: 0.5684 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3942/2499940 | global iter:   1972/1249970 | loss: 0.8649 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3944/2499940 | global iter:   1973/1249970 | loss: 1.4119 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3946/2499940 | global iter:   1974/1249970 | loss: 0.4381 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   3948/2499940 | global iter:   1975/1249970 | loss: 0.7196 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3950/2499940 | global iter:   1976/1249970 | loss: 1.2813 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3950/2499940 | global iter:   1976/1249970 | loss: 1.0368 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3952/2499940 | global iter:   1977/1249970 | loss: 0.5360 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3954/2499940 | global iter:   1978/1249970 | loss: 0.4221 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3956/2499940 | global iter:   1979/1249970 | loss: 0.9030 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3958/2499940 | global iter:   1980/1249970 | loss: 1.5335 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3958/2499940 | global iter:   1980/1249970 | loss: 1.1785 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3960/2499940 | global iter:   1981/1249970 | loss: 1.1560 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3962/2499940 | global iter:   1982/1249970 | loss: 1.0391 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3964/2499940 | global iter:   1983/1249970 | loss: 1.0415 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3966/2499940 | global iter:   1984/1249970 | loss: 1.2825 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3966/2499940 | global iter:   1984/1249970 | loss: 1.1048 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3968/2499940 | global iter:   1985/1249970 | loss: 1.0695 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   3970/2499940 | global iter:   1986/1249970 | loss: 0.6775 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3972/2499940 | global iter:   1987/1249970 | loss: 1.1729 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3974/2499940 | global iter:   1988/1249970 | loss: 0.8514 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3974/2499940 | global iter:   1988/1249970 | loss: 1.2498 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3976/2499940 | global iter:   1989/1249970 | loss: 0.7231 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3978/2499940 | global iter:   1990/1249970 | loss: 1.4838 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3980/2499940 | global iter:   1991/1249970 | loss: 0.6575 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   3982/2499940 | global iter:   1992/1249970 | loss: 1.3333 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3982/2499940 | global iter:   1992/1249970 | loss: 1.1825 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3984/2499940 | global iter:   1993/1249970 | loss: 0.9840 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3986/2499940 | global iter:   1994/1249970 | loss: 1.4756 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   3988/2499940 | global iter:   1995/1249970 | loss: 1.0721 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   3990/2499940 | global iter:   1996/1249970 | loss: 0.8253 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3990/2499940 | global iter:   1996/1249970 | loss: 1.2633 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   3992/2499940 | global iter:   1997/1249970 | loss: 1.4421 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.406 | step time: 0.000
train | epoch   0 | Iter:   3994/2499940 | global iter:   1998/1249970 | loss: 1.2544 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3996/2499940 | global iter:   1999/1249970 | loss: 1.1232 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   3998/2499940 | global iter:   2000/1249970 | loss: 1.5237 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3998/2499940 | global iter:   2000/1249970 | loss: 1.1471 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.695
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4000/2499940 | global iter:   2001/1249970 | loss: 1.5427 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4002/2499940 | global iter:   2002/1249970 | loss: 0.1640 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4004/2499940 | global iter:   2003/1249970 | loss: 1.5697 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   4006/2499940 | global iter:   2004/1249970 | loss: 1.4247 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4006/2499940 | global iter:   2004/1249970 | loss: 1.0995 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4008/2499940 | global iter:   2005/1249970 | loss: 1.4345 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4010/2499940 | global iter:   2006/1249970 | loss: 1.3558 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   4012/2499940 | global iter:   2007/1249970 | loss: 1.1318 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   4014/2499940 | global iter:   2008/1249970 | loss: 1.1512 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4014/2499940 | global iter:   2008/1249970 | loss: 1.3187 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4016/2499940 | global iter:   2009/1249970 | loss: 1.0295 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4018/2499940 | global iter:   2010/1249970 | loss: 0.8030 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4020/2499940 | global iter:   2011/1249970 | loss: 1.2628 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4022/2499940 | global iter:   2012/1249970 | loss: 0.9770 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4022/2499940 | global iter:   2012/1249970 | loss: 0.9449 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4024/2499940 | global iter:   2013/1249970 | loss: 1.1638 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4026/2499940 | global iter:   2014/1249970 | loss: 0.8699 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4028/2499940 | global iter:   2015/1249970 | loss: 1.7832 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4030/2499940 | global iter:   2016/1249970 | loss: 0.6276 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4030/2499940 | global iter:   2016/1249970 | loss: 1.1374 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4032/2499940 | global iter:   2017/1249970 | loss: 0.9881 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4034/2499940 | global iter:   2018/1249970 | loss: 0.8116 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   4036/2499940 | global iter:   2019/1249970 | loss: 0.9448 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4038/2499940 | global iter:   2020/1249970 | loss: 1.1854 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4038/2499940 | global iter:   2020/1249970 | loss: 1.0944 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4040/2499940 | global iter:   2021/1249970 | loss: 0.9488 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4042/2499940 | global iter:   2022/1249970 | loss: 1.5152 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   4044/2499940 | global iter:   2023/1249970 | loss: 0.9036 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4046/2499940 | global iter:   2024/1249970 | loss: 1.7871 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4046/2499940 | global iter:   2024/1249970 | loss: 1.1453 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4048/2499940 | global iter:   2025/1249970 | loss: 0.9345 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4050/2499940 | global iter:   2026/1249970 | loss: 1.3122 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4052/2499940 | global iter:   2027/1249970 | loss: 1.2123 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4054/2499940 | global iter:   2028/1249970 | loss: 1.0807 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4054/2499940 | global iter:   2028/1249970 | loss: 1.2786 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4056/2499940 | global iter:   2029/1249970 | loss: 1.4182 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4058/2499940 | global iter:   2030/1249970 | loss: 0.8210 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   4060/2499940 | global iter:   2031/1249970 | loss: 1.4650 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4062/2499940 | global iter:   2032/1249970 | loss: 1.0566 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4062/2499940 | global iter:   2032/1249970 | loss: 1.1247 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4064/2499940 | global iter:   2033/1249970 | loss: 0.5864 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4066/2499940 | global iter:   2034/1249970 | loss: 1.0828 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   4068/2499940 | global iter:   2035/1249970 | loss: 0.6351 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4070/2499940 | global iter:   2036/1249970 | loss: 0.9778 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4070/2499940 | global iter:   2036/1249970 | loss: 1.2363 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4072/2499940 | global iter:   2037/1249970 | loss: 1.0963 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   4074/2499940 | global iter:   2038/1249970 | loss: 1.0590 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   4076/2499940 | global iter:   2039/1249970 | loss: 0.9938 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4078/2499940 | global iter:   2040/1249970 | loss: 1.3443 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4078/2499940 | global iter:   2040/1249970 | loss: 0.9573 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4080/2499940 | global iter:   2041/1249970 | loss: 1.0866 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4082/2499940 | global iter:   2042/1249970 | loss: 1.1709 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4084/2499940 | global iter:   2043/1249970 | loss: 1.8100 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4086/2499940 | global iter:   2044/1249970 | loss: 0.7269 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4086/2499940 | global iter:   2044/1249970 | loss: 1.2197 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4088/2499940 | global iter:   2045/1249970 | loss: 1.4759 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4090/2499940 | global iter:   2046/1249970 | loss: 1.9811 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4092/2499940 | global iter:   2047/1249970 | loss: 1.4024 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4094/2499940 | global iter:   2048/1249970 | loss: 1.2317 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4094/2499940 | global iter:   2048/1249970 | loss: 1.5044 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4096/2499940 | global iter:   2049/1249970 | loss: 1.5676 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   4098/2499940 | global iter:   2050/1249970 | loss: 1.2734 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4100/2499940 | global iter:   2051/1249970 | loss: 0.7747 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4102/2499940 | global iter:   2052/1249970 | loss: 1.1592 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4102/2499940 | global iter:   2052/1249970 | loss: 1.0018 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4104/2499940 | global iter:   2053/1249970 | loss: 1.6209 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4106/2499940 | global iter:   2054/1249970 | loss: 1.0238 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   4108/2499940 | global iter:   2055/1249970 | loss: 0.9975 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4110/2499940 | global iter:   2056/1249970 | loss: 1.9332 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4110/2499940 | global iter:   2056/1249970 | loss: 1.2297 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4112/2499940 | global iter:   2057/1249970 | loss: 0.8430 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   4114/2499940 | global iter:   2058/1249970 | loss: 1.2743 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   4116/2499940 | global iter:   2059/1249970 | loss: 0.7245 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4118/2499940 | global iter:   2060/1249970 | loss: 0.8961 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4118/2499940 | global iter:   2060/1249970 | loss: 1.0685 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4120/2499940 | global iter:   2061/1249970 | loss: 1.6314 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   4122/2499940 | global iter:   2062/1249970 | loss: 1.4956 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4124/2499940 | global iter:   2063/1249970 | loss: 1.2889 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4126/2499940 | global iter:   2064/1249970 | loss: 1.7181 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4126/2499940 | global iter:   2064/1249970 | loss: 1.2791 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4128/2499940 | global iter:   2065/1249970 | loss: 1.2376 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4130/2499940 | global iter:   2066/1249970 | loss: 0.7735 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   4132/2499940 | global iter:   2067/1249970 | loss: 1.1343 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4134/2499940 | global iter:   2068/1249970 | loss: 0.9791 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4134/2499940 | global iter:   2068/1249970 | loss: 1.1356 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4136/2499940 | global iter:   2069/1249970 | loss: 0.6755 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4138/2499940 | global iter:   2070/1249970 | loss: 0.8422 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4140/2499940 | global iter:   2071/1249970 | loss: 1.5058 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4142/2499940 | global iter:   2072/1249970 | loss: 1.8024 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4142/2499940 | global iter:   2072/1249970 | loss: 1.4142 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4144/2499940 | global iter:   2073/1249970 | loss: 1.7960 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   4146/2499940 | global iter:   2074/1249970 | loss: 1.3052 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   4148/2499940 | global iter:   2075/1249970 | loss: 2.1651 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4150/2499940 | global iter:   2076/1249970 | loss: 1.1745 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4150/2499940 | global iter:   2076/1249970 | loss: 1.3486 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4152/2499940 | global iter:   2077/1249970 | loss: 1.2220 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4154/2499940 | global iter:   2078/1249970 | loss: 1.4951 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4156/2499940 | global iter:   2079/1249970 | loss: 0.8624 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4158/2499940 | global iter:   2080/1249970 | loss: 0.8908 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4158/2499940 | global iter:   2080/1249970 | loss: 0.9901 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4160/2499940 | global iter:   2081/1249970 | loss: 1.4975 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4162/2499940 | global iter:   2082/1249970 | loss: 0.9616 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4164/2499940 | global iter:   2083/1249970 | loss: 0.5962 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   4166/2499940 | global iter:   2084/1249970 | loss: 1.3935 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4166/2499940 | global iter:   2084/1249970 | loss: 1.1013 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4168/2499940 | global iter:   2085/1249970 | loss: 0.9640 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4170/2499940 | global iter:   2086/1249970 | loss: 1.1253 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4172/2499940 | global iter:   2087/1249970 | loss: 1.1516 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4174/2499940 | global iter:   2088/1249970 | loss: 1.5753 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4174/2499940 | global iter:   2088/1249970 | loss: 1.2013 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4176/2499940 | global iter:   2089/1249970 | loss: 1.3516 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4178/2499940 | global iter:   2090/1249970 | loss: 0.2072 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4180/2499940 | global iter:   2091/1249970 | loss: 0.1022 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4182/2499940 | global iter:   2092/1249970 | loss: 1.0946 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4182/2499940 | global iter:   2092/1249970 | loss: 1.0089 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4184/2499940 | global iter:   2093/1249970 | loss: 1.8027 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4186/2499940 | global iter:   2094/1249970 | loss: 1.5231 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4188/2499940 | global iter:   2095/1249970 | loss: 1.6969 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4190/2499940 | global iter:   2096/1249970 | loss: 0.9634 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4190/2499940 | global iter:   2096/1249970 | loss: 1.2550 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4192/2499940 | global iter:   2097/1249970 | loss: 0.4509 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4194/2499940 | global iter:   2098/1249970 | loss: 0.6428 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4196/2499940 | global iter:   2099/1249970 | loss: 0.8556 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   4198/2499940 | global iter:   2100/1249970 | loss: 0.3294 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4198/2499940 | global iter:   2100/1249970 | loss: 0.8344 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4200/2499940 | global iter:   2101/1249970 | loss: 1.5971 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4202/2499940 | global iter:   2102/1249970 | loss: 0.9399 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4204/2499940 | global iter:   2103/1249970 | loss: 1.2821 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4206/2499940 | global iter:   2104/1249970 | loss: 1.2606 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4206/2499940 | global iter:   2104/1249970 | loss: 1.2750 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4208/2499940 | global iter:   2105/1249970 | loss: 1.2806 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   4210/2499940 | global iter:   2106/1249970 | loss: 0.8655 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.392 | step time: 0.000
train | epoch   0 | Iter:   4212/2499940 | global iter:   2107/1249970 | loss: 1.6101 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4214/2499940 | global iter:   2108/1249970 | loss: 1.1886 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4214/2499940 | global iter:   2108/1249970 | loss: 1.1747 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4216/2499940 | global iter:   2109/1249970 | loss: 1.3122 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4218/2499940 | global iter:   2110/1249970 | loss: 1.7773 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4220/2499940 | global iter:   2111/1249970 | loss: 1.3836 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4222/2499940 | global iter:   2112/1249970 | loss: 0.8127 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4222/2499940 | global iter:   2112/1249970 | loss: 1.2835 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4224/2499940 | global iter:   2113/1249970 | loss: 1.6230 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4226/2499940 | global iter:   2114/1249970 | loss: 1.5665 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4228/2499940 | global iter:   2115/1249970 | loss: 1.6276 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4230/2499940 | global iter:   2116/1249970 | loss: 0.6959 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4230/2499940 | global iter:   2116/1249970 | loss: 1.1734 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4232/2499940 | global iter:   2117/1249970 | loss: 1.5598 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4234/2499940 | global iter:   2118/1249970 | loss: 0.9915 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4236/2499940 | global iter:   2119/1249970 | loss: 1.2869 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4238/2499940 | global iter:   2120/1249970 | loss: 1.1342 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4238/2499940 | global iter:   2120/1249970 | loss: 1.2720 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4240/2499940 | global iter:   2121/1249970 | loss: 0.8619 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4242/2499940 | global iter:   2122/1249970 | loss: 1.1085 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4244/2499940 | global iter:   2123/1249970 | loss: 0.4024 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   4246/2499940 | global iter:   2124/1249970 | loss: 1.6196 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4246/2499940 | global iter:   2124/1249970 | loss: 1.1892 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4248/2499940 | global iter:   2125/1249970 | loss: 1.7370 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4250/2499940 | global iter:   2126/1249970 | loss: 0.8734 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4252/2499940 | global iter:   2127/1249970 | loss: 0.7952 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   4254/2499940 | global iter:   2128/1249970 | loss: 1.3626 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.409 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4254/2499940 | global iter:   2128/1249970 | loss: 1.1640 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.409 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4256/2499940 | global iter:   2129/1249970 | loss: 1.3050 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4258/2499940 | global iter:   2130/1249970 | loss: 1.3438 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4260/2499940 | global iter:   2131/1249970 | loss: 0.7055 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4262/2499940 | global iter:   2132/1249970 | loss: 1.1232 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4262/2499940 | global iter:   2132/1249970 | loss: 1.1411 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4264/2499940 | global iter:   2133/1249970 | loss: 1.2267 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4266/2499940 | global iter:   2134/1249970 | loss: 0.7971 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4268/2499940 | global iter:   2135/1249970 | loss: 1.7594 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4270/2499940 | global iter:   2136/1249970 | loss: 0.7523 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4270/2499940 | global iter:   2136/1249970 | loss: 1.0307 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4272/2499940 | global iter:   2137/1249970 | loss: 1.5093 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4274/2499940 | global iter:   2138/1249970 | loss: 1.3127 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4276/2499940 | global iter:   2139/1249970 | loss: 0.5902 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4278/2499940 | global iter:   2140/1249970 | loss: 0.7729 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4278/2499940 | global iter:   2140/1249970 | loss: 1.1163 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4280/2499940 | global iter:   2141/1249970 | loss: 1.1457 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4282/2499940 | global iter:   2142/1249970 | loss: 1.2791 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   4284/2499940 | global iter:   2143/1249970 | loss: 0.9096 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4286/2499940 | global iter:   2144/1249970 | loss: 0.7475 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4286/2499940 | global iter:   2144/1249970 | loss: 1.0940 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4288/2499940 | global iter:   2145/1249970 | loss: 1.4834 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4290/2499940 | global iter:   2146/1249970 | loss: 1.1227 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4292/2499940 | global iter:   2147/1249970 | loss: 1.4043 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4294/2499940 | global iter:   2148/1249970 | loss: 1.2896 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4294/2499940 | global iter:   2148/1249970 | loss: 1.2962 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4296/2499940 | global iter:   2149/1249970 | loss: 1.4726 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4298/2499940 | global iter:   2150/1249970 | loss: 0.8793 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   4300/2499940 | global iter:   2151/1249970 | loss: 1.4573 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4302/2499940 | global iter:   2152/1249970 | loss: 0.9223 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4302/2499940 | global iter:   2152/1249970 | loss: 1.2680 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4304/2499940 | global iter:   2153/1249970 | loss: 0.8107 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4306/2499940 | global iter:   2154/1249970 | loss: 1.4051 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4308/2499940 | global iter:   2155/1249970 | loss: 0.7766 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4310/2499940 | global iter:   2156/1249970 | loss: 1.6799 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4310/2499940 | global iter:   2156/1249970 | loss: 1.2147 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4312/2499940 | global iter:   2157/1249970 | loss: 1.4256 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:   4314/2499940 | global iter:   2158/1249970 | loss: 1.8782 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   4316/2499940 | global iter:   2159/1249970 | loss: 0.9849 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4318/2499940 | global iter:   2160/1249970 | loss: 0.4783 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4318/2499940 | global iter:   2160/1249970 | loss: 0.9672 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4320/2499940 | global iter:   2161/1249970 | loss: 1.3215 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4322/2499940 | global iter:   2162/1249970 | loss: 1.3391 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:   4324/2499940 | global iter:   2163/1249970 | loss: 1.6333 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4326/2499940 | global iter:   2164/1249970 | loss: 1.4789 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4326/2499940 | global iter:   2164/1249970 | loss: 1.3837 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4328/2499940 | global iter:   2165/1249970 | loss: 0.6871 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4330/2499940 | global iter:   2166/1249970 | loss: 0.9436 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4332/2499940 | global iter:   2167/1249970 | loss: 0.9695 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4334/2499940 | global iter:   2168/1249970 | loss: 1.3373 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4334/2499940 | global iter:   2168/1249970 | loss: 0.9472 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4336/2499940 | global iter:   2169/1249970 | loss: 1.0939 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4338/2499940 | global iter:   2170/1249970 | loss: 0.8884 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4340/2499940 | global iter:   2171/1249970 | loss: 1.3127 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.409 | step time: 0.000
train | epoch   0 | Iter:   4342/2499940 | global iter:   2172/1249970 | loss: 1.0770 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4342/2499940 | global iter:   2172/1249970 | loss: 1.0771 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.696
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4344/2499940 | global iter:   2173/1249970 | loss: 1.3422 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4346/2499940 | global iter:   2174/1249970 | loss: 0.8927 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   4348/2499940 | global iter:   2175/1249970 | loss: 1.6346 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4350/2499940 | global iter:   2176/1249970 | loss: 1.0290 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4350/2499940 | global iter:   2176/1249970 | loss: 1.2140 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4352/2499940 | global iter:   2177/1249970 | loss: 1.7736 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   4354/2499940 | global iter:   2178/1249970 | loss: 1.7946 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4356/2499940 | global iter:   2179/1249970 | loss: 1.3616 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4358/2499940 | global iter:   2180/1249970 | loss: 0.2897 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4358/2499940 | global iter:   2180/1249970 | loss: 1.3646 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4360/2499940 | global iter:   2181/1249970 | loss: 1.4134 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4362/2499940 | global iter:   2182/1249970 | loss: 0.7767 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4364/2499940 | global iter:   2183/1249970 | loss: 1.2423 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   4366/2499940 | global iter:   2184/1249970 | loss: 1.7318 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4366/2499940 | global iter:   2184/1249970 | loss: 1.2276 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4368/2499940 | global iter:   2185/1249970 | loss: 0.7849 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   4370/2499940 | global iter:   2186/1249970 | loss: 1.0129 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   4372/2499940 | global iter:   2187/1249970 | loss: 1.4073 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4374/2499940 | global iter:   2188/1249970 | loss: 0.5273 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4374/2499940 | global iter:   2188/1249970 | loss: 1.0744 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4376/2499940 | global iter:   2189/1249970 | loss: 0.8081 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4378/2499940 | global iter:   2190/1249970 | loss: 1.1778 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4380/2499940 | global iter:   2191/1249970 | loss: 1.2725 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4382/2499940 | global iter:   2192/1249970 | loss: 1.4927 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4382/2499940 | global iter:   2192/1249970 | loss: 1.1259 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4384/2499940 | global iter:   2193/1249970 | loss: 1.5552 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4386/2499940 | global iter:   2194/1249970 | loss: 1.4988 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4388/2499940 | global iter:   2195/1249970 | loss: 1.3589 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:   4390/2499940 | global iter:   2196/1249970 | loss: 0.9027 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4390/2499940 | global iter:   2196/1249970 | loss: 1.2677 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4392/2499940 | global iter:   2197/1249970 | loss: 0.8338 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4394/2499940 | global iter:   2198/1249970 | loss: 0.5567 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4396/2499940 | global iter:   2199/1249970 | loss: 2.1310 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4398/2499940 | global iter:   2200/1249970 | loss: 1.2067 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4398/2499940 | global iter:   2200/1249970 | loss: 1.1012 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4400/2499940 | global iter:   2201/1249970 | loss: 1.1261 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4402/2499940 | global iter:   2202/1249970 | loss: 1.7116 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   4404/2499940 | global iter:   2203/1249970 | loss: 1.0273 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4406/2499940 | global iter:   2204/1249970 | loss: 1.0375 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4406/2499940 | global iter:   2204/1249970 | loss: 1.2609 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4408/2499940 | global iter:   2205/1249970 | loss: 1.4862 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4410/2499940 | global iter:   2206/1249970 | loss: 1.5837 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4412/2499940 | global iter:   2207/1249970 | loss: 0.0694 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4414/2499940 | global iter:   2208/1249970 | loss: 0.9826 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4414/2499940 | global iter:   2208/1249970 | loss: 0.9797 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4416/2499940 | global iter:   2209/1249970 | loss: 1.7023 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4418/2499940 | global iter:   2210/1249970 | loss: 1.2828 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4420/2499940 | global iter:   2211/1249970 | loss: 0.5562 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4422/2499940 | global iter:   2212/1249970 | loss: 0.0908 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4422/2499940 | global iter:   2212/1249970 | loss: 0.9758 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4424/2499940 | global iter:   2213/1249970 | loss: 1.5190 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   4426/2499940 | global iter:   2214/1249970 | loss: 2.0472 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.406 | step time: 0.000
train | epoch   0 | Iter:   4428/2499940 | global iter:   2215/1249970 | loss: 1.4803 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4430/2499940 | global iter:   2216/1249970 | loss: 1.4759 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4430/2499940 | global iter:   2216/1249970 | loss: 1.4481 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.695
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4432/2499940 | global iter:   2217/1249970 | loss: 1.7712 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4434/2499940 | global iter:   2218/1249970 | loss: 1.5154 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   4436/2499940 | global iter:   2219/1249970 | loss: 1.3271 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4438/2499940 | global iter:   2220/1249970 | loss: 0.6273 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4438/2499940 | global iter:   2220/1249970 | loss: 1.1989 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4440/2499940 | global iter:   2221/1249970 | loss: 1.5907 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4442/2499940 | global iter:   2222/1249970 | loss: 1.5173 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4444/2499940 | global iter:   2223/1249970 | loss: 1.3207 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4446/2499940 | global iter:   2224/1249970 | loss: 0.7489 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4446/2499940 | global iter:   2224/1249970 | loss: 1.2475 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4448/2499940 | global iter:   2225/1249970 | loss: 1.1911 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4450/2499940 | global iter:   2226/1249970 | loss: 1.6871 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   4452/2499940 | global iter:   2227/1249970 | loss: 0.8048 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4454/2499940 | global iter:   2228/1249970 | loss: 2.1467 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4454/2499940 | global iter:   2228/1249970 | loss: 1.5246 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4456/2499940 | global iter:   2229/1249970 | loss: 1.3814 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4458/2499940 | global iter:   2230/1249970 | loss: 1.7201 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4460/2499940 | global iter:   2231/1249970 | loss: 0.5400 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4462/2499940 | global iter:   2232/1249970 | loss: 0.8456 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.390 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4462/2499940 | global iter:   2232/1249970 | loss: 1.1171 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.390 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4464/2499940 | global iter:   2233/1249970 | loss: 0.9647 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4466/2499940 | global iter:   2234/1249970 | loss: 1.1333 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   4468/2499940 | global iter:   2235/1249970 | loss: 0.3526 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4470/2499940 | global iter:   2236/1249970 | loss: 0.8765 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4470/2499940 | global iter:   2236/1249970 | loss: 0.9154 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4472/2499940 | global iter:   2237/1249970 | loss: 1.1346 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4474/2499940 | global iter:   2238/1249970 | loss: 1.3667 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4476/2499940 | global iter:   2239/1249970 | loss: 0.9839 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4478/2499940 | global iter:   2240/1249970 | loss: 1.2257 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4478/2499940 | global iter:   2240/1249970 | loss: 1.3241 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4480/2499940 | global iter:   2241/1249970 | loss: 1.5155 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4482/2499940 | global iter:   2242/1249970 | loss: 0.7546 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4484/2499940 | global iter:   2243/1249970 | loss: 1.0673 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4486/2499940 | global iter:   2244/1249970 | loss: 1.5255 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4486/2499940 | global iter:   2244/1249970 | loss: 1.2115 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4488/2499940 | global iter:   2245/1249970 | loss: 1.2103 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4490/2499940 | global iter:   2246/1249970 | loss: 1.2565 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4492/2499940 | global iter:   2247/1249970 | loss: 1.4635 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4494/2499940 | global iter:   2248/1249970 | loss: 0.5640 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4494/2499940 | global iter:   2248/1249970 | loss: 1.1353 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4496/2499940 | global iter:   2249/1249970 | loss: 1.2063 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4498/2499940 | global iter:   2250/1249970 | loss: 0.9193 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4500/2499940 | global iter:   2251/1249970 | loss: 1.3633 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4502/2499940 | global iter:   2252/1249970 | loss: 0.0297 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4502/2499940 | global iter:   2252/1249970 | loss: 1.1099 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4504/2499940 | global iter:   2253/1249970 | loss: 0.9750 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4506/2499940 | global iter:   2254/1249970 | loss: 1.0231 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   4508/2499940 | global iter:   2255/1249970 | loss: 0.7921 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4510/2499940 | global iter:   2256/1249970 | loss: 1.4348 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4510/2499940 | global iter:   2256/1249970 | loss: 0.9010 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4512/2499940 | global iter:   2257/1249970 | loss: 1.4174 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   4514/2499940 | global iter:   2258/1249970 | loss: 0.2288 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.407 | step time: 0.000
train | epoch   0 | Iter:   4516/2499940 | global iter:   2259/1249970 | loss: 0.9151 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4518/2499940 | global iter:   2260/1249970 | loss: 1.6013 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4518/2499940 | global iter:   2260/1249970 | loss: 1.2172 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4520/2499940 | global iter:   2261/1249970 | loss: 2.0393 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4522/2499940 | global iter:   2262/1249970 | loss: 0.8683 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4524/2499940 | global iter:   2263/1249970 | loss: 1.2807 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4526/2499940 | global iter:   2264/1249970 | loss: 0.9792 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4526/2499940 | global iter:   2264/1249970 | loss: 1.1936 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4528/2499940 | global iter:   2265/1249970 | loss: 0.9650 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4530/2499940 | global iter:   2266/1249970 | loss: 1.2497 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4532/2499940 | global iter:   2267/1249970 | loss: 1.2085 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4534/2499940 | global iter:   2268/1249970 | loss: 1.6385 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4534/2499940 | global iter:   2268/1249970 | loss: 1.3111 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4536/2499940 | global iter:   2269/1249970 | loss: 1.0541 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4538/2499940 | global iter:   2270/1249970 | loss: 1.3582 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   4540/2499940 | global iter:   2271/1249970 | loss: 1.1833 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   4542/2499940 | global iter:   2272/1249970 | loss: 1.1542 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4542/2499940 | global iter:   2272/1249970 | loss: 1.0348 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4544/2499940 | global iter:   2273/1249970 | loss: 0.0978 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4546/2499940 | global iter:   2274/1249970 | loss: 0.3044 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4548/2499940 | global iter:   2275/1249970 | loss: 1.0388 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4550/2499940 | global iter:   2276/1249970 | loss: 0.8323 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4550/2499940 | global iter:   2276/1249970 | loss: 0.7314 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4552/2499940 | global iter:   2277/1249970 | loss: 1.8002 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4554/2499940 | global iter:   2278/1249970 | loss: 0.8464 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   4556/2499940 | global iter:   2279/1249970 | loss: 1.0211 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4558/2499940 | global iter:   2280/1249970 | loss: 1.3328 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4558/2499940 | global iter:   2280/1249970 | loss: 1.2391 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4560/2499940 | global iter:   2281/1249970 | loss: 1.0633 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   4562/2499940 | global iter:   2282/1249970 | loss: 2.6042 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   4564/2499940 | global iter:   2283/1249970 | loss: 1.5280 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4566/2499940 | global iter:   2284/1249970 | loss: 0.2405 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4566/2499940 | global iter:   2284/1249970 | loss: 1.0817 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4568/2499940 | global iter:   2285/1249970 | loss: 1.5375 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4570/2499940 | global iter:   2286/1249970 | loss: 1.4938 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   4572/2499940 | global iter:   2287/1249970 | loss: 1.0523 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4574/2499940 | global iter:   2288/1249970 | loss: 0.9670 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4574/2499940 | global iter:   2288/1249970 | loss: 1.0102 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4576/2499940 | global iter:   2289/1249970 | loss: 0.7956 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4578/2499940 | global iter:   2290/1249970 | loss: 1.0908 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4580/2499940 | global iter:   2291/1249970 | loss: 1.7302 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4582/2499940 | global iter:   2292/1249970 | loss: 1.3936 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4582/2499940 | global iter:   2292/1249970 | loss: 1.1994 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4584/2499940 | global iter:   2293/1249970 | loss: 1.3153 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4586/2499940 | global iter:   2294/1249970 | loss: 1.6522 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4588/2499940 | global iter:   2295/1249970 | loss: 1.2599 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4590/2499940 | global iter:   2296/1249970 | loss: 0.6231 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4590/2499940 | global iter:   2296/1249970 | loss: 1.1354 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4592/2499940 | global iter:   2297/1249970 | loss: 0.9015 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4594/2499940 | global iter:   2298/1249970 | loss: 0.8169 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   4596/2499940 | global iter:   2299/1249970 | loss: 0.6632 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4598/2499940 | global iter:   2300/1249970 | loss: 1.4377 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4598/2499940 | global iter:   2300/1249970 | loss: 1.0650 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4600/2499940 | global iter:   2301/1249970 | loss: 1.3230 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4602/2499940 | global iter:   2302/1249970 | loss: 1.8343 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4604/2499940 | global iter:   2303/1249970 | loss: 1.0712 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4606/2499940 | global iter:   2304/1249970 | loss: 0.7939 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4606/2499940 | global iter:   2304/1249970 | loss: 1.2465 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4608/2499940 | global iter:   2305/1249970 | loss: 1.4565 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4610/2499940 | global iter:   2306/1249970 | loss: 0.8110 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4612/2499940 | global iter:   2307/1249970 | loss: 0.0763 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4614/2499940 | global iter:   2308/1249970 | loss: 0.8383 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4614/2499940 | global iter:   2308/1249970 | loss: 0.8991 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4616/2499940 | global iter:   2309/1249970 | loss: 0.9658 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4618/2499940 | global iter:   2310/1249970 | loss: 0.4374 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4620/2499940 | global iter:   2311/1249970 | loss: 1.6657 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4622/2499940 | global iter:   2312/1249970 | loss: 0.9888 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4622/2499940 | global iter:   2312/1249970 | loss: 1.0071 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4624/2499940 | global iter:   2313/1249970 | loss: 1.4451 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4626/2499940 | global iter:   2314/1249970 | loss: 1.3140 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4628/2499940 | global iter:   2315/1249970 | loss: 1.2286 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4630/2499940 | global iter:   2316/1249970 | loss: 1.9583 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4630/2499940 | global iter:   2316/1249970 | loss: 1.1663 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4632/2499940 | global iter:   2317/1249970 | loss: 1.9696 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4634/2499940 | global iter:   2318/1249970 | loss: 1.5580 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   4636/2499940 | global iter:   2319/1249970 | loss: 1.0770 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4638/2499940 | global iter:   2320/1249970 | loss: 1.1558 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4638/2499940 | global iter:   2320/1249970 | loss: 1.2242 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4640/2499940 | global iter:   2321/1249970 | loss: 0.8806 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   4642/2499940 | global iter:   2322/1249970 | loss: 0.5793 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4644/2499940 | global iter:   2323/1249970 | loss: 0.5669 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4646/2499940 | global iter:   2324/1249970 | loss: 1.6373 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4646/2499940 | global iter:   2324/1249970 | loss: 0.8443 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4648/2499940 | global iter:   2325/1249970 | loss: 0.4924 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4650/2499940 | global iter:   2326/1249970 | loss: 1.3767 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4652/2499940 | global iter:   2327/1249970 | loss: 1.2629 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4654/2499940 | global iter:   2328/1249970 | loss: 1.5524 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4654/2499940 | global iter:   2328/1249970 | loss: 1.1938 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4656/2499940 | global iter:   2329/1249970 | loss: 1.3298 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   4658/2499940 | global iter:   2330/1249970 | loss: 0.8118 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   4660/2499940 | global iter:   2331/1249970 | loss: 0.7856 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4662/2499940 | global iter:   2332/1249970 | loss: 1.5957 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4662/2499940 | global iter:   2332/1249970 | loss: 1.1977 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4664/2499940 | global iter:   2333/1249970 | loss: 1.3105 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   4666/2499940 | global iter:   2334/1249970 | loss: 1.0211 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4668/2499940 | global iter:   2335/1249970 | loss: 0.8163 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4670/2499940 | global iter:   2336/1249970 | loss: 0.6422 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4670/2499940 | global iter:   2336/1249970 | loss: 1.1344 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4672/2499940 | global iter:   2337/1249970 | loss: 1.7665 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4674/2499940 | global iter:   2338/1249970 | loss: 0.6054 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   4676/2499940 | global iter:   2339/1249970 | loss: 1.1089 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4678/2499940 | global iter:   2340/1249970 | loss: 1.5216 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4678/2499940 | global iter:   2340/1249970 | loss: 1.2024 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4680/2499940 | global iter:   2341/1249970 | loss: 1.2677 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4682/2499940 | global iter:   2342/1249970 | loss: 1.5011 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4684/2499940 | global iter:   2343/1249970 | loss: 0.5514 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4686/2499940 | global iter:   2344/1249970 | loss: 1.4341 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4686/2499940 | global iter:   2344/1249970 | loss: 1.2068 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4688/2499940 | global iter:   2345/1249970 | loss: 1.7612 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4690/2499940 | global iter:   2346/1249970 | loss: 1.9625 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4692/2499940 | global iter:   2347/1249970 | loss: 0.6250 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.433 | step time: 0.000
train | epoch   0 | Iter:   4694/2499940 | global iter:   2348/1249970 | loss: 0.8352 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.403 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4694/2499940 | global iter:   2348/1249970 | loss: 1.4064 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.403 | step time: 0.701
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4696/2499940 | global iter:   2349/1249970 | loss: 0.9810 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   4698/2499940 | global iter:   2350/1249970 | loss: 1.8482 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4700/2499940 | global iter:   2351/1249970 | loss: 1.6928 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4702/2499940 | global iter:   2352/1249970 | loss: 1.0050 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4702/2499940 | global iter:   2352/1249970 | loss: 1.2282 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4704/2499940 | global iter:   2353/1249970 | loss: 0.2202 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4706/2499940 | global iter:   2354/1249970 | loss: 1.1120 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   4708/2499940 | global iter:   2355/1249970 | loss: 1.3375 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:   4710/2499940 | global iter:   2356/1249970 | loss: 0.8846 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4710/2499940 | global iter:   2356/1249970 | loss: 1.3638 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4712/2499940 | global iter:   2357/1249970 | loss: 0.5188 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4714/2499940 | global iter:   2358/1249970 | loss: 0.8740 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   4716/2499940 | global iter:   2359/1249970 | loss: 1.2348 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   4718/2499940 | global iter:   2360/1249970 | loss: 1.1819 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4718/2499940 | global iter:   2360/1249970 | loss: 0.9795 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4720/2499940 | global iter:   2361/1249970 | loss: 1.0119 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   4722/2499940 | global iter:   2362/1249970 | loss: 0.6049 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4724/2499940 | global iter:   2363/1249970 | loss: 0.9780 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   4726/2499940 | global iter:   2364/1249970 | loss: 1.0961 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4726/2499940 | global iter:   2364/1249970 | loss: 1.0267 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4728/2499940 | global iter:   2365/1249970 | loss: 1.2648 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4730/2499940 | global iter:   2366/1249970 | loss: 0.1054 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4732/2499940 | global iter:   2367/1249970 | loss: 0.6408 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4734/2499940 | global iter:   2368/1249970 | loss: 1.3367 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4734/2499940 | global iter:   2368/1249970 | loss: 0.9814 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4736/2499940 | global iter:   2369/1249970 | loss: 1.6081 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4738/2499940 | global iter:   2370/1249970 | loss: 0.7849 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4740/2499940 | global iter:   2371/1249970 | loss: 1.5537 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4742/2499940 | global iter:   2372/1249970 | loss: 1.3991 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4742/2499940 | global iter:   2372/1249970 | loss: 1.2974 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4744/2499940 | global iter:   2373/1249970 | loss: 1.3936 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4746/2499940 | global iter:   2374/1249970 | loss: 1.3744 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4748/2499940 | global iter:   2375/1249970 | loss: 1.1480 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4750/2499940 | global iter:   2376/1249970 | loss: 1.6650 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4750/2499940 | global iter:   2376/1249970 | loss: 1.3610 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4752/2499940 | global iter:   2377/1249970 | loss: 1.0560 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4754/2499940 | global iter:   2378/1249970 | loss: 0.5795 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4756/2499940 | global iter:   2379/1249970 | loss: 0.7064 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4758/2499940 | global iter:   2380/1249970 | loss: 1.2788 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4758/2499940 | global iter:   2380/1249970 | loss: 1.0679 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4760/2499940 | global iter:   2381/1249970 | loss: 1.4160 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   4762/2499940 | global iter:   2382/1249970 | loss: 0.8017 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:   4764/2499940 | global iter:   2383/1249970 | loss: 1.9373 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.405 | step time: 0.000
train | epoch   0 | Iter:   4766/2499940 | global iter:   2384/1249970 | loss: 1.7151 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.404 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4766/2499940 | global iter:   2384/1249970 | loss: 1.3368 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.404 | step time: 0.698
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4768/2499940 | global iter:   2385/1249970 | loss: 1.5137 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4770/2499940 | global iter:   2386/1249970 | loss: 1.0623 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4772/2499940 | global iter:   2387/1249970 | loss: 1.5812 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4774/2499940 | global iter:   2388/1249970 | loss: 1.3557 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.412 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4774/2499940 | global iter:   2388/1249970 | loss: 1.1353 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.412 | step time: 0.695
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4776/2499940 | global iter:   2389/1249970 | loss: 1.3213 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4778/2499940 | global iter:   2390/1249970 | loss: 1.2426 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4780/2499940 | global iter:   2391/1249970 | loss: 1.6373 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4782/2499940 | global iter:   2392/1249970 | loss: 1.1852 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4782/2499940 | global iter:   2392/1249970 | loss: 1.1833 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4784/2499940 | global iter:   2393/1249970 | loss: 0.3103 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4786/2499940 | global iter:   2394/1249970 | loss: 1.4269 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   4788/2499940 | global iter:   2395/1249970 | loss: 1.7714 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4790/2499940 | global iter:   2396/1249970 | loss: 1.0911 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4790/2499940 | global iter:   2396/1249970 | loss: 1.1619 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4792/2499940 | global iter:   2397/1249970 | loss: 0.9058 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4794/2499940 | global iter:   2398/1249970 | loss: 0.6822 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   4796/2499940 | global iter:   2399/1249970 | loss: 1.3957 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4798/2499940 | global iter:   2400/1249970 | loss: 1.1473 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4798/2499940 | global iter:   2400/1249970 | loss: 1.1795 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4800/2499940 | global iter:   2401/1249970 | loss: 1.0277 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4802/2499940 | global iter:   2402/1249970 | loss: 1.3208 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4804/2499940 | global iter:   2403/1249970 | loss: 0.9627 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4806/2499940 | global iter:   2404/1249970 | loss: 1.8615 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4806/2499940 | global iter:   2404/1249970 | loss: 1.1254 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4808/2499940 | global iter:   2405/1249970 | loss: 0.6754 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   4810/2499940 | global iter:   2406/1249970 | loss: 0.9546 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4812/2499940 | global iter:   2407/1249970 | loss: 0.9263 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4814/2499940 | global iter:   2408/1249970 | loss: 0.9166 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4814/2499940 | global iter:   2408/1249970 | loss: 0.8505 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4816/2499940 | global iter:   2409/1249970 | loss: 1.3584 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4818/2499940 | global iter:   2410/1249970 | loss: 0.8205 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4820/2499940 | global iter:   2411/1249970 | loss: 1.0781 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4822/2499940 | global iter:   2412/1249970 | loss: 0.7953 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4822/2499940 | global iter:   2412/1249970 | loss: 1.0534 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4824/2499940 | global iter:   2413/1249970 | loss: 0.6949 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4826/2499940 | global iter:   2414/1249970 | loss: 1.6882 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   4828/2499940 | global iter:   2415/1249970 | loss: 0.8194 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4830/2499940 | global iter:   2416/1249970 | loss: 0.5779 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4830/2499940 | global iter:   2416/1249970 | loss: 0.9401 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4832/2499940 | global iter:   2417/1249970 | loss: 1.2774 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   4834/2499940 | global iter:   2418/1249970 | loss: 1.7902 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4836/2499940 | global iter:   2419/1249970 | loss: 1.2523 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   4838/2499940 | global iter:   2420/1249970 | loss: 0.5528 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4838/2499940 | global iter:   2420/1249970 | loss: 1.2879 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4840/2499940 | global iter:   2421/1249970 | loss: 1.3542 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4842/2499940 | global iter:   2422/1249970 | loss: 1.5119 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4844/2499940 | global iter:   2423/1249970 | loss: 0.8848 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4846/2499940 | global iter:   2424/1249970 | loss: 1.6483 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4846/2499940 | global iter:   2424/1249970 | loss: 1.2573 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4848/2499940 | global iter:   2425/1249970 | loss: 1.6028 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4850/2499940 | global iter:   2426/1249970 | loss: 1.0767 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:   4852/2499940 | global iter:   2427/1249970 | loss: 1.2420 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4854/2499940 | global iter:   2428/1249970 | loss: 0.7668 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4854/2499940 | global iter:   2428/1249970 | loss: 1.0181 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4856/2499940 | global iter:   2429/1249970 | loss: 0.3787 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4858/2499940 | global iter:   2430/1249970 | loss: 1.6011 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   4860/2499940 | global iter:   2431/1249970 | loss: 0.8933 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4862/2499940 | global iter:   2432/1249970 | loss: 1.3215 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4862/2499940 | global iter:   2432/1249970 | loss: 1.0661 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4864/2499940 | global iter:   2433/1249970 | loss: 1.4179 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4866/2499940 | global iter:   2434/1249970 | loss: 0.9574 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4868/2499940 | global iter:   2435/1249970 | loss: 1.6986 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4870/2499940 | global iter:   2436/1249970 | loss: 1.0763 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4870/2499940 | global iter:   2436/1249970 | loss: 1.1613 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4872/2499940 | global iter:   2437/1249970 | loss: 1.3644 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4874/2499940 | global iter:   2438/1249970 | loss: 0.7625 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4876/2499940 | global iter:   2439/1249970 | loss: 1.3307 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4878/2499940 | global iter:   2440/1249970 | loss: 1.2924 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4878/2499940 | global iter:   2440/1249970 | loss: 1.0905 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4880/2499940 | global iter:   2441/1249970 | loss: 0.8969 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4882/2499940 | global iter:   2442/1249970 | loss: 1.9134 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4884/2499940 | global iter:   2443/1249970 | loss: 0.6826 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4886/2499940 | global iter:   2444/1249970 | loss: 0.7585 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4886/2499940 | global iter:   2444/1249970 | loss: 1.2213 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4888/2499940 | global iter:   2445/1249970 | loss: 0.8575 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4890/2499940 | global iter:   2446/1249970 | loss: 1.6204 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4892/2499940 | global iter:   2447/1249970 | loss: 0.8728 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4894/2499940 | global iter:   2448/1249970 | loss: 0.9889 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4894/2499940 | global iter:   2448/1249970 | loss: 1.1553 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4896/2499940 | global iter:   2449/1249970 | loss: 1.3570 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4898/2499940 | global iter:   2450/1249970 | loss: 1.8011 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4900/2499940 | global iter:   2451/1249970 | loss: 1.6083 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4902/2499940 | global iter:   2452/1249970 | loss: 1.1674 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4902/2499940 | global iter:   2452/1249970 | loss: 1.2882 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4904/2499940 | global iter:   2453/1249970 | loss: 1.7084 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4906/2499940 | global iter:   2454/1249970 | loss: 1.0518 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4908/2499940 | global iter:   2455/1249970 | loss: 1.4204 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4910/2499940 | global iter:   2456/1249970 | loss: 0.5791 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4910/2499940 | global iter:   2456/1249970 | loss: 0.9927 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4912/2499940 | global iter:   2457/1249970 | loss: 0.6056 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4914/2499940 | global iter:   2458/1249970 | loss: 1.8383 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4916/2499940 | global iter:   2459/1249970 | loss: 1.0600 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4918/2499940 | global iter:   2460/1249970 | loss: 1.4622 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4918/2499940 | global iter:   2460/1249970 | loss: 0.9631 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4920/2499940 | global iter:   2461/1249970 | loss: 0.2065 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4922/2499940 | global iter:   2462/1249970 | loss: 1.1691 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   4924/2499940 | global iter:   2463/1249970 | loss: 0.5142 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4926/2499940 | global iter:   2464/1249970 | loss: 1.2918 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4926/2499940 | global iter:   2464/1249970 | loss: 0.9103 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4928/2499940 | global iter:   2465/1249970 | loss: 1.8893 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   4930/2499940 | global iter:   2466/1249970 | loss: 0.4283 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4932/2499940 | global iter:   2467/1249970 | loss: 1.0636 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4934/2499940 | global iter:   2468/1249970 | loss: 0.8344 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4934/2499940 | global iter:   2468/1249970 | loss: 0.9128 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4936/2499940 | global iter:   2469/1249970 | loss: 0.6455 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   4938/2499940 | global iter:   2470/1249970 | loss: 1.3676 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4940/2499940 | global iter:   2471/1249970 | loss: 0.7372 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4942/2499940 | global iter:   2472/1249970 | loss: 1.5022 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4942/2499940 | global iter:   2472/1249970 | loss: 1.0235 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4944/2499940 | global iter:   2473/1249970 | loss: 0.6727 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4946/2499940 | global iter:   2474/1249970 | loss: 0.6682 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.405 | step time: 0.000
train | epoch   0 | Iter:   4948/2499940 | global iter:   2475/1249970 | loss: 1.7389 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4950/2499940 | global iter:   2476/1249970 | loss: 1.2343 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4950/2499940 | global iter:   2476/1249970 | loss: 1.1584 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.695
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4952/2499940 | global iter:   2477/1249970 | loss: 0.6372 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4954/2499940 | global iter:   2478/1249970 | loss: 1.2706 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   4956/2499940 | global iter:   2479/1249970 | loss: 0.8559 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   4958/2499940 | global iter:   2480/1249970 | loss: 1.1249 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4958/2499940 | global iter:   2480/1249970 | loss: 0.9351 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4960/2499940 | global iter:   2481/1249970 | loss: 1.6534 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   4962/2499940 | global iter:   2482/1249970 | loss: 1.4230 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4964/2499940 | global iter:   2483/1249970 | loss: 1.0434 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4966/2499940 | global iter:   2484/1249970 | loss: 0.9258 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4966/2499940 | global iter:   2484/1249970 | loss: 1.1162 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4968/2499940 | global iter:   2485/1249970 | loss: 1.8652 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4970/2499940 | global iter:   2486/1249970 | loss: 1.6515 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:   4972/2499940 | global iter:   2487/1249970 | loss: 1.4812 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4974/2499940 | global iter:   2488/1249970 | loss: 0.4263 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4974/2499940 | global iter:   2488/1249970 | loss: 1.1521 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4976/2499940 | global iter:   2489/1249970 | loss: 0.7871 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4978/2499940 | global iter:   2490/1249970 | loss: 1.2441 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   4980/2499940 | global iter:   2491/1249970 | loss: 1.3762 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   4982/2499940 | global iter:   2492/1249970 | loss: 1.5643 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4982/2499940 | global iter:   2492/1249970 | loss: 1.1059 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4984/2499940 | global iter:   2493/1249970 | loss: 0.6193 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4986/2499940 | global iter:   2494/1249970 | loss: 1.2950 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   4988/2499940 | global iter:   2495/1249970 | loss: 1.4508 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4990/2499940 | global iter:   2496/1249970 | loss: 1.1656 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4990/2499940 | global iter:   2496/1249970 | loss: 1.3127 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   4992/2499940 | global iter:   2497/1249970 | loss: 1.0311 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   4994/2499940 | global iter:   2498/1249970 | loss: 1.1497 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4996/2499940 | global iter:   2499/1249970 | loss: 1.7038 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   4998/2499940 | global iter:   2500/1249970 | loss: 0.7606 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4998/2499940 | global iter:   2500/1249970 | loss: 1.1552 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5000/2499940 | global iter:   2501/1249970 | loss: 1.6907 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5002/2499940 | global iter:   2502/1249970 | loss: 1.1459 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5004/2499940 | global iter:   2503/1249970 | loss: 0.7694 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5006/2499940 | global iter:   2504/1249970 | loss: 0.9323 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5006/2499940 | global iter:   2504/1249970 | loss: 1.1365 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5008/2499940 | global iter:   2505/1249970 | loss: 1.2367 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5010/2499940 | global iter:   2506/1249970 | loss: 0.8216 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5012/2499940 | global iter:   2507/1249970 | loss: 0.6392 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5014/2499940 | global iter:   2508/1249970 | loss: 1.2934 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5014/2499940 | global iter:   2508/1249970 | loss: 0.9927 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5016/2499940 | global iter:   2509/1249970 | loss: 0.7115 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5018/2499940 | global iter:   2510/1249970 | loss: 0.9713 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5020/2499940 | global iter:   2511/1249970 | loss: 1.0229 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5022/2499940 | global iter:   2512/1249970 | loss: 1.4568 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5022/2499940 | global iter:   2512/1249970 | loss: 0.9652 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.686
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5024/2499940 | global iter:   2513/1249970 | loss: 1.5971 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5026/2499940 | global iter:   2514/1249970 | loss: 0.5902 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5028/2499940 | global iter:   2515/1249970 | loss: 0.9575 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5030/2499940 | global iter:   2516/1249970 | loss: 1.1670 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5030/2499940 | global iter:   2516/1249970 | loss: 1.1118 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5032/2499940 | global iter:   2517/1249970 | loss: 0.7600 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   5034/2499940 | global iter:   2518/1249970 | loss: 1.4277 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.410 | step time: 0.000
train | epoch   0 | Iter:   5036/2499940 | global iter:   2519/1249970 | loss: 0.7619 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5038/2499940 | global iter:   2520/1249970 | loss: 1.1433 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5038/2499940 | global iter:   2520/1249970 | loss: 1.2093 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.695
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5040/2499940 | global iter:   2521/1249970 | loss: 1.2664 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5042/2499940 | global iter:   2522/1249970 | loss: 1.3715 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5044/2499940 | global iter:   2523/1249970 | loss: 1.2495 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5046/2499940 | global iter:   2524/1249970 | loss: 1.4101 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5046/2499940 | global iter:   2524/1249970 | loss: 1.2289 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5048/2499940 | global iter:   2525/1249970 | loss: 0.8522 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5050/2499940 | global iter:   2526/1249970 | loss: 2.3344 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5052/2499940 | global iter:   2527/1249970 | loss: 1.2243 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5054/2499940 | global iter:   2528/1249970 | loss: 1.3287 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5054/2499940 | global iter:   2528/1249970 | loss: 1.3484 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5056/2499940 | global iter:   2529/1249970 | loss: 0.9841 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5058/2499940 | global iter:   2530/1249970 | loss: 1.3144 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   5060/2499940 | global iter:   2531/1249970 | loss: 1.6846 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5062/2499940 | global iter:   2532/1249970 | loss: 0.8465 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5062/2499940 | global iter:   2532/1249970 | loss: 1.2517 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5064/2499940 | global iter:   2533/1249970 | loss: 0.6228 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5066/2499940 | global iter:   2534/1249970 | loss: 1.2120 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5068/2499940 | global iter:   2535/1249970 | loss: 1.5467 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   5070/2499940 | global iter:   2536/1249970 | loss: 1.2870 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5070/2499940 | global iter:   2536/1249970 | loss: 1.0379 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5072/2499940 | global iter:   2537/1249970 | loss: 0.8045 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5074/2499940 | global iter:   2538/1249970 | loss: 1.1566 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   5076/2499940 | global iter:   2539/1249970 | loss: 1.5416 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5078/2499940 | global iter:   2540/1249970 | loss: 1.1686 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5078/2499940 | global iter:   2540/1249970 | loss: 1.3170 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5080/2499940 | global iter:   2541/1249970 | loss: 0.8628 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5082/2499940 | global iter:   2542/1249970 | loss: 1.4809 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5084/2499940 | global iter:   2543/1249970 | loss: 1.0917 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5086/2499940 | global iter:   2544/1249970 | loss: 1.3003 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5086/2499940 | global iter:   2544/1249970 | loss: 1.2921 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5088/2499940 | global iter:   2545/1249970 | loss: 1.1981 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5090/2499940 | global iter:   2546/1249970 | loss: 1.3045 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:   5092/2499940 | global iter:   2547/1249970 | loss: 0.3295 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5094/2499940 | global iter:   2548/1249970 | loss: 1.3040 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5094/2499940 | global iter:   2548/1249970 | loss: 1.1330 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5096/2499940 | global iter:   2549/1249970 | loss: 1.6999 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5098/2499940 | global iter:   2550/1249970 | loss: 1.0299 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5100/2499940 | global iter:   2551/1249970 | loss: 0.8390 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5102/2499940 | global iter:   2552/1249970 | loss: 0.9440 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.391 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5102/2499940 | global iter:   2552/1249970 | loss: 1.2967 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.391 | step time: 0.686
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5104/2499940 | global iter:   2553/1249970 | loss: 0.4715 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5106/2499940 | global iter:   2554/1249970 | loss: 1.4808 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   5108/2499940 | global iter:   2555/1249970 | loss: 1.4680 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5110/2499940 | global iter:   2556/1249970 | loss: 1.5636 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5110/2499940 | global iter:   2556/1249970 | loss: 1.0704 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5112/2499940 | global iter:   2557/1249970 | loss: 1.6345 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5114/2499940 | global iter:   2558/1249970 | loss: 1.0564 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5116/2499940 | global iter:   2559/1249970 | loss: 1.0965 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5118/2499940 | global iter:   2560/1249970 | loss: 1.1868 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5118/2499940 | global iter:   2560/1249970 | loss: 1.3218 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5120/2499940 | global iter:   2561/1249970 | loss: 1.0926 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.405 | step time: 0.000
train | epoch   0 | Iter:   5122/2499940 | global iter:   2562/1249970 | loss: 0.0711 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   5124/2499940 | global iter:   2563/1249970 | loss: 0.7491 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5126/2499940 | global iter:   2564/1249970 | loss: 1.6731 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5126/2499940 | global iter:   2564/1249970 | loss: 0.9542 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5128/2499940 | global iter:   2565/1249970 | loss: 0.6811 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5130/2499940 | global iter:   2566/1249970 | loss: 0.9958 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5132/2499940 | global iter:   2567/1249970 | loss: 1.2181 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5134/2499940 | global iter:   2568/1249970 | loss: 1.4983 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5134/2499940 | global iter:   2568/1249970 | loss: 1.2315 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5136/2499940 | global iter:   2569/1249970 | loss: 0.9810 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5138/2499940 | global iter:   2570/1249970 | loss: 1.3858 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5140/2499940 | global iter:   2571/1249970 | loss: 0.8754 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5142/2499940 | global iter:   2572/1249970 | loss: 1.3502 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5142/2499940 | global iter:   2572/1249970 | loss: 1.1642 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5144/2499940 | global iter:   2573/1249970 | loss: 0.7992 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   5146/2499940 | global iter:   2574/1249970 | loss: 1.3294 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.392 | step time: 0.000
train | epoch   0 | Iter:   5148/2499940 | global iter:   2575/1249970 | loss: 1.5334 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5150/2499940 | global iter:   2576/1249970 | loss: 1.5643 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5150/2499940 | global iter:   2576/1249970 | loss: 1.0945 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.686
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5152/2499940 | global iter:   2577/1249970 | loss: 0.8428 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5154/2499940 | global iter:   2578/1249970 | loss: 1.1995 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:   5156/2499940 | global iter:   2579/1249970 | loss: 1.9088 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5158/2499940 | global iter:   2580/1249970 | loss: 1.0742 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5158/2499940 | global iter:   2580/1249970 | loss: 0.9860 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5160/2499940 | global iter:   2581/1249970 | loss: 0.8263 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5162/2499940 | global iter:   2582/1249970 | loss: 0.9856 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5164/2499940 | global iter:   2583/1249970 | loss: 1.5206 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5166/2499940 | global iter:   2584/1249970 | loss: 1.3172 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5166/2499940 | global iter:   2584/1249970 | loss: 1.2099 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5168/2499940 | global iter:   2585/1249970 | loss: 0.9480 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5170/2499940 | global iter:   2586/1249970 | loss: 1.0207 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5172/2499940 | global iter:   2587/1249970 | loss: 1.6998 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5174/2499940 | global iter:   2588/1249970 | loss: 1.3863 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5174/2499940 | global iter:   2588/1249970 | loss: 1.3248 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5176/2499940 | global iter:   2589/1249970 | loss: 1.3199 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5178/2499940 | global iter:   2590/1249970 | loss: 0.7417 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5180/2499940 | global iter:   2591/1249970 | loss: 1.0105 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5182/2499940 | global iter:   2592/1249970 | loss: 1.0699 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5182/2499940 | global iter:   2592/1249970 | loss: 1.1333 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5184/2499940 | global iter:   2593/1249970 | loss: 0.1900 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5186/2499940 | global iter:   2594/1249970 | loss: 0.7149 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5188/2499940 | global iter:   2595/1249970 | loss: 1.3179 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5190/2499940 | global iter:   2596/1249970 | loss: 1.0513 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5190/2499940 | global iter:   2596/1249970 | loss: 0.9073 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5192/2499940 | global iter:   2597/1249970 | loss: 0.3298 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5194/2499940 | global iter:   2598/1249970 | loss: 1.0357 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   5196/2499940 | global iter:   2599/1249970 | loss: 1.0275 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   5198/2499940 | global iter:   2600/1249970 | loss: 1.3037 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5198/2499940 | global iter:   2600/1249970 | loss: 1.2453 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5200/2499940 | global iter:   2601/1249970 | loss: 0.8273 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5202/2499940 | global iter:   2602/1249970 | loss: 0.8022 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   5204/2499940 | global iter:   2603/1249970 | loss: 0.8127 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5206/2499940 | global iter:   2604/1249970 | loss: 1.1249 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5206/2499940 | global iter:   2604/1249970 | loss: 0.8784 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5208/2499940 | global iter:   2605/1249970 | loss: 1.1319 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5210/2499940 | global iter:   2606/1249970 | loss: 0.6170 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   5212/2499940 | global iter:   2607/1249970 | loss: 1.0337 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5214/2499940 | global iter:   2608/1249970 | loss: 1.4203 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5214/2499940 | global iter:   2608/1249970 | loss: 0.9657 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5216/2499940 | global iter:   2609/1249970 | loss: 0.7799 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5218/2499940 | global iter:   2610/1249970 | loss: 1.3068 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5220/2499940 | global iter:   2611/1249970 | loss: 0.9253 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5222/2499940 | global iter:   2612/1249970 | loss: 1.2339 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5222/2499940 | global iter:   2612/1249970 | loss: 1.2396 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5224/2499940 | global iter:   2613/1249970 | loss: 0.8878 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   5226/2499940 | global iter:   2614/1249970 | loss: 1.8773 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   5228/2499940 | global iter:   2615/1249970 | loss: 0.8517 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5230/2499940 | global iter:   2616/1249970 | loss: 0.8407 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5230/2499940 | global iter:   2616/1249970 | loss: 1.1666 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.686
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5232/2499940 | global iter:   2617/1249970 | loss: 1.4855 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5234/2499940 | global iter:   2618/1249970 | loss: 1.5874 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5236/2499940 | global iter:   2619/1249970 | loss: 1.2334 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5238/2499940 | global iter:   2620/1249970 | loss: 0.9535 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5238/2499940 | global iter:   2620/1249970 | loss: 1.1247 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5240/2499940 | global iter:   2621/1249970 | loss: 1.0153 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5242/2499940 | global iter:   2622/1249970 | loss: 1.0421 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5244/2499940 | global iter:   2623/1249970 | loss: 0.8388 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5246/2499940 | global iter:   2624/1249970 | loss: 0.9319 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5246/2499940 | global iter:   2624/1249970 | loss: 0.9696 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5248/2499940 | global iter:   2625/1249970 | loss: 1.3044 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5250/2499940 | global iter:   2626/1249970 | loss: 1.6224 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5252/2499940 | global iter:   2627/1249970 | loss: 1.1900 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   5254/2499940 | global iter:   2628/1249970 | loss: 1.6502 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5254/2499940 | global iter:   2628/1249970 | loss: 1.1677 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5256/2499940 | global iter:   2629/1249970 | loss: 1.3398 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5258/2499940 | global iter:   2630/1249970 | loss: 0.7825 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5260/2499940 | global iter:   2631/1249970 | loss: 1.1648 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   5262/2499940 | global iter:   2632/1249970 | loss: 0.5992 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5262/2499940 | global iter:   2632/1249970 | loss: 0.9972 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5264/2499940 | global iter:   2633/1249970 | loss: 1.5448 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   5266/2499940 | global iter:   2634/1249970 | loss: 0.3896 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5268/2499940 | global iter:   2635/1249970 | loss: 1.2331 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5270/2499940 | global iter:   2636/1249970 | loss: 0.8457 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5270/2499940 | global iter:   2636/1249970 | loss: 1.0956 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5272/2499940 | global iter:   2637/1249970 | loss: 1.1545 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5274/2499940 | global iter:   2638/1249970 | loss: 1.4412 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5276/2499940 | global iter:   2639/1249970 | loss: 1.3083 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   5278/2499940 | global iter:   2640/1249970 | loss: 0.9637 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5278/2499940 | global iter:   2640/1249970 | loss: 1.3390 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5280/2499940 | global iter:   2641/1249970 | loss: 1.7260 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5282/2499940 | global iter:   2642/1249970 | loss: 0.7594 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   5284/2499940 | global iter:   2643/1249970 | loss: 1.0181 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5286/2499940 | global iter:   2644/1249970 | loss: 0.5127 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5286/2499940 | global iter:   2644/1249970 | loss: 0.9181 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5288/2499940 | global iter:   2645/1249970 | loss: 1.4166 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5290/2499940 | global iter:   2646/1249970 | loss: 1.5117 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5292/2499940 | global iter:   2647/1249970 | loss: 1.3171 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5294/2499940 | global iter:   2648/1249970 | loss: 1.3403 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5294/2499940 | global iter:   2648/1249970 | loss: 1.0389 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5296/2499940 | global iter:   2649/1249970 | loss: 0.4572 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5298/2499940 | global iter:   2650/1249970 | loss: 1.0057 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5300/2499940 | global iter:   2651/1249970 | loss: 1.3588 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5302/2499940 | global iter:   2652/1249970 | loss: 1.0914 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5302/2499940 | global iter:   2652/1249970 | loss: 1.1997 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5304/2499940 | global iter:   2653/1249970 | loss: 1.0461 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5306/2499940 | global iter:   2654/1249970 | loss: 1.0519 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5308/2499940 | global iter:   2655/1249970 | loss: 0.9817 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5310/2499940 | global iter:   2656/1249970 | loss: 1.2741 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5310/2499940 | global iter:   2656/1249970 | loss: 1.2799 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5312/2499940 | global iter:   2657/1249970 | loss: 1.1756 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5314/2499940 | global iter:   2658/1249970 | loss: 1.8258 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   5316/2499940 | global iter:   2659/1249970 | loss: 0.2750 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5318/2499940 | global iter:   2660/1249970 | loss: 1.2548 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5318/2499940 | global iter:   2660/1249970 | loss: 1.2549 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5320/2499940 | global iter:   2661/1249970 | loss: 0.7919 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5322/2499940 | global iter:   2662/1249970 | loss: 0.8503 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   5324/2499940 | global iter:   2663/1249970 | loss: 0.7076 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5326/2499940 | global iter:   2664/1249970 | loss: 0.6429 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5326/2499940 | global iter:   2664/1249970 | loss: 0.7444 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5328/2499940 | global iter:   2665/1249970 | loss: 2.0049 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5330/2499940 | global iter:   2666/1249970 | loss: 0.9011 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5332/2499940 | global iter:   2667/1249970 | loss: 0.4110 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5334/2499940 | global iter:   2668/1249970 | loss: 1.3030 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5334/2499940 | global iter:   2668/1249970 | loss: 1.1636 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5336/2499940 | global iter:   2669/1249970 | loss: 0.1283 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5338/2499940 | global iter:   2670/1249970 | loss: 0.6197 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5340/2499940 | global iter:   2671/1249970 | loss: 0.3944 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5342/2499940 | global iter:   2672/1249970 | loss: 0.8793 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5342/2499940 | global iter:   2672/1249970 | loss: 0.7962 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5344/2499940 | global iter:   2673/1249970 | loss: 1.5046 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5346/2499940 | global iter:   2674/1249970 | loss: 1.4009 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5348/2499940 | global iter:   2675/1249970 | loss: 1.4773 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5350/2499940 | global iter:   2676/1249970 | loss: 1.4037 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5350/2499940 | global iter:   2676/1249970 | loss: 1.3454 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5352/2499940 | global iter:   2677/1249970 | loss: 0.9311 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5354/2499940 | global iter:   2678/1249970 | loss: 0.8999 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5356/2499940 | global iter:   2679/1249970 | loss: 1.2205 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   5358/2499940 | global iter:   2680/1249970 | loss: 0.2814 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5358/2499940 | global iter:   2680/1249970 | loss: 0.8990 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5360/2499940 | global iter:   2681/1249970 | loss: 1.7528 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5362/2499940 | global iter:   2682/1249970 | loss: 0.5816 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5364/2499940 | global iter:   2683/1249970 | loss: 0.8722 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5366/2499940 | global iter:   2684/1249970 | loss: 0.7656 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5366/2499940 | global iter:   2684/1249970 | loss: 1.0388 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5368/2499940 | global iter:   2685/1249970 | loss: 1.6380 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5370/2499940 | global iter:   2686/1249970 | loss: 1.5637 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5372/2499940 | global iter:   2687/1249970 | loss: 0.8199 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5374/2499940 | global iter:   2688/1249970 | loss: 1.6952 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5374/2499940 | global iter:   2688/1249970 | loss: 1.1571 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5376/2499940 | global iter:   2689/1249970 | loss: 0.9911 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5378/2499940 | global iter:   2690/1249970 | loss: 1.7579 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5380/2499940 | global iter:   2691/1249970 | loss: 1.6713 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.408 | step time: 0.000
train | epoch   0 | Iter:   5382/2499940 | global iter:   2692/1249970 | loss: 0.1894 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5382/2499940 | global iter:   2692/1249970 | loss: 1.0311 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5384/2499940 | global iter:   2693/1249970 | loss: 1.1805 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5386/2499940 | global iter:   2694/1249970 | loss: 0.9749 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5388/2499940 | global iter:   2695/1249970 | loss: 1.1705 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5390/2499940 | global iter:   2696/1249970 | loss: 1.2051 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5390/2499940 | global iter:   2696/1249970 | loss: 0.9984 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5392/2499940 | global iter:   2697/1249970 | loss: 0.8118 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5394/2499940 | global iter:   2698/1249970 | loss: 0.2772 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5396/2499940 | global iter:   2699/1249970 | loss: 1.0826 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5398/2499940 | global iter:   2700/1249970 | loss: 0.6485 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5398/2499940 | global iter:   2700/1249970 | loss: 0.7602 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5400/2499940 | global iter:   2701/1249970 | loss: 0.7974 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5402/2499940 | global iter:   2702/1249970 | loss: 0.8959 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5404/2499940 | global iter:   2703/1249970 | loss: 1.3188 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5406/2499940 | global iter:   2704/1249970 | loss: 0.8309 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5406/2499940 | global iter:   2704/1249970 | loss: 1.1044 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5408/2499940 | global iter:   2705/1249970 | loss: 1.4725 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5410/2499940 | global iter:   2706/1249970 | loss: 1.6214 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   5412/2499940 | global iter:   2707/1249970 | loss: 1.4187 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5414/2499940 | global iter:   2708/1249970 | loss: 1.5033 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5414/2499940 | global iter:   2708/1249970 | loss: 1.4223 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5416/2499940 | global iter:   2709/1249970 | loss: 0.9062 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5418/2499940 | global iter:   2710/1249970 | loss: 1.1808 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5420/2499940 | global iter:   2711/1249970 | loss: 0.9069 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5422/2499940 | global iter:   2712/1249970 | loss: 1.3329 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5422/2499940 | global iter:   2712/1249970 | loss: 1.2670 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5424/2499940 | global iter:   2713/1249970 | loss: 0.3348 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   5426/2499940 | global iter:   2714/1249970 | loss: 1.8302 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5428/2499940 | global iter:   2715/1249970 | loss: 1.6161 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5430/2499940 | global iter:   2716/1249970 | loss: 1.4415 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5430/2499940 | global iter:   2716/1249970 | loss: 1.2968 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5432/2499940 | global iter:   2717/1249970 | loss: 0.8501 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5434/2499940 | global iter:   2718/1249970 | loss: 1.8477 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5436/2499940 | global iter:   2719/1249970 | loss: 1.4312 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5438/2499940 | global iter:   2720/1249970 | loss: 0.7345 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5438/2499940 | global iter:   2720/1249970 | loss: 0.8882 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5440/2499940 | global iter:   2721/1249970 | loss: 1.3061 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5442/2499940 | global iter:   2722/1249970 | loss: 0.9848 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5444/2499940 | global iter:   2723/1249970 | loss: 0.8960 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5446/2499940 | global iter:   2724/1249970 | loss: 0.2811 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5446/2499940 | global iter:   2724/1249970 | loss: 0.9758 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5448/2499940 | global iter:   2725/1249970 | loss: 0.6335 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   5450/2499940 | global iter:   2726/1249970 | loss: 1.5746 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5452/2499940 | global iter:   2727/1249970 | loss: 1.4043 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5454/2499940 | global iter:   2728/1249970 | loss: 1.0047 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5454/2499940 | global iter:   2728/1249970 | loss: 1.3028 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5456/2499940 | global iter:   2729/1249970 | loss: 1.0927 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5458/2499940 | global iter:   2730/1249970 | loss: 0.4589 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5460/2499940 | global iter:   2731/1249970 | loss: 1.7621 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5462/2499940 | global iter:   2732/1249970 | loss: 1.1780 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5462/2499940 | global iter:   2732/1249970 | loss: 1.1819 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5464/2499940 | global iter:   2733/1249970 | loss: 0.6500 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5466/2499940 | global iter:   2734/1249970 | loss: 0.6872 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.405 | step time: 0.000
train | epoch   0 | Iter:   5468/2499940 | global iter:   2735/1249970 | loss: 1.0835 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5470/2499940 | global iter:   2736/1249970 | loss: 1.0039 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5470/2499940 | global iter:   2736/1249970 | loss: 1.1007 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5472/2499940 | global iter:   2737/1249970 | loss: 1.6508 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5474/2499940 | global iter:   2738/1249970 | loss: 2.1649 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   5476/2499940 | global iter:   2739/1249970 | loss: 2.0190 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5478/2499940 | global iter:   2740/1249970 | loss: 0.8758 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5478/2499940 | global iter:   2740/1249970 | loss: 1.4567 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5480/2499940 | global iter:   2741/1249970 | loss: 0.9775 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5482/2499940 | global iter:   2742/1249970 | loss: 0.7090 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5484/2499940 | global iter:   2743/1249970 | loss: 1.4154 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   5486/2499940 | global iter:   2744/1249970 | loss: 1.0605 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5486/2499940 | global iter:   2744/1249970 | loss: 1.0642 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5488/2499940 | global iter:   2745/1249970 | loss: 2.0716 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5490/2499940 | global iter:   2746/1249970 | loss: 0.6941 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5492/2499940 | global iter:   2747/1249970 | loss: 0.8400 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5494/2499940 | global iter:   2748/1249970 | loss: 1.2873 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5494/2499940 | global iter:   2748/1249970 | loss: 1.0649 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5496/2499940 | global iter:   2749/1249970 | loss: 0.6661 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5498/2499940 | global iter:   2750/1249970 | loss: 1.1481 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5500/2499940 | global iter:   2751/1249970 | loss: 0.8980 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5502/2499940 | global iter:   2752/1249970 | loss: 0.6640 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5502/2499940 | global iter:   2752/1249970 | loss: 0.9984 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5504/2499940 | global iter:   2753/1249970 | loss: 0.5382 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5506/2499940 | global iter:   2754/1249970 | loss: 0.5460 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5508/2499940 | global iter:   2755/1249970 | loss: 1.1533 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5510/2499940 | global iter:   2756/1249970 | loss: 1.4435 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5510/2499940 | global iter:   2756/1249970 | loss: 0.9276 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5512/2499940 | global iter:   2757/1249970 | loss: 1.3397 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   5514/2499940 | global iter:   2758/1249970 | loss: 1.8168 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5516/2499940 | global iter:   2759/1249970 | loss: 0.8598 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5518/2499940 | global iter:   2760/1249970 | loss: 0.9510 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5518/2499940 | global iter:   2760/1249970 | loss: 1.3032 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5520/2499940 | global iter:   2761/1249970 | loss: 0.7266 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5522/2499940 | global iter:   2762/1249970 | loss: 1.5023 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5524/2499940 | global iter:   2763/1249970 | loss: 1.3470 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5526/2499940 | global iter:   2764/1249970 | loss: 1.5485 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5526/2499940 | global iter:   2764/1249970 | loss: 1.4645 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5528/2499940 | global iter:   2765/1249970 | loss: 0.3153 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5530/2499940 | global iter:   2766/1249970 | loss: 1.5501 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5532/2499940 | global iter:   2767/1249970 | loss: 0.6251 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5534/2499940 | global iter:   2768/1249970 | loss: 0.9853 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5534/2499940 | global iter:   2768/1249970 | loss: 1.2162 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5536/2499940 | global iter:   2769/1249970 | loss: 1.7500 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5538/2499940 | global iter:   2770/1249970 | loss: 1.1584 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5540/2499940 | global iter:   2771/1249970 | loss: 1.0455 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5542/2499940 | global iter:   2772/1249970 | loss: 1.0650 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5542/2499940 | global iter:   2772/1249970 | loss: 1.1281 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5544/2499940 | global iter:   2773/1249970 | loss: 1.6885 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   5546/2499940 | global iter:   2774/1249970 | loss: 1.3668 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5548/2499940 | global iter:   2775/1249970 | loss: 1.5555 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5550/2499940 | global iter:   2776/1249970 | loss: 1.2871 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.392 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5550/2499940 | global iter:   2776/1249970 | loss: 1.2261 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.392 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5552/2499940 | global iter:   2777/1249970 | loss: 1.8000 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.407 | step time: 0.000
train | epoch   0 | Iter:   5554/2499940 | global iter:   2778/1249970 | loss: 0.8238 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   5556/2499940 | global iter:   2779/1249970 | loss: 0.4646 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5558/2499940 | global iter:   2780/1249970 | loss: 1.3149 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5558/2499940 | global iter:   2780/1249970 | loss: 1.0402 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5560/2499940 | global iter:   2781/1249970 | loss: 0.8826 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5562/2499940 | global iter:   2782/1249970 | loss: 1.2476 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5564/2499940 | global iter:   2783/1249970 | loss: 1.2120 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5566/2499940 | global iter:   2784/1249970 | loss: 0.5648 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5566/2499940 | global iter:   2784/1249970 | loss: 0.9568 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5568/2499940 | global iter:   2785/1249970 | loss: 0.8505 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5570/2499940 | global iter:   2786/1249970 | loss: 1.0726 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5572/2499940 | global iter:   2787/1249970 | loss: 1.2797 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5574/2499940 | global iter:   2788/1249970 | loss: 1.4689 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5574/2499940 | global iter:   2788/1249970 | loss: 0.9389 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5576/2499940 | global iter:   2789/1249970 | loss: 1.3300 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5578/2499940 | global iter:   2790/1249970 | loss: 1.1576 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5580/2499940 | global iter:   2791/1249970 | loss: 0.4025 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5582/2499940 | global iter:   2792/1249970 | loss: 1.1514 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5582/2499940 | global iter:   2792/1249970 | loss: 0.8270 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5584/2499940 | global iter:   2793/1249970 | loss: 0.9664 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5586/2499940 | global iter:   2794/1249970 | loss: 1.0745 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.392 | step time: 0.000
train | epoch   0 | Iter:   5588/2499940 | global iter:   2795/1249970 | loss: 0.8841 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5590/2499940 | global iter:   2796/1249970 | loss: 0.9787 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5590/2499940 | global iter:   2796/1249970 | loss: 1.0750 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5592/2499940 | global iter:   2797/1249970 | loss: 1.0014 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5594/2499940 | global iter:   2798/1249970 | loss: 1.0013 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   5596/2499940 | global iter:   2799/1249970 | loss: 1.1758 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5598/2499940 | global iter:   2800/1249970 | loss: 0.4685 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5598/2499940 | global iter:   2800/1249970 | loss: 0.9107 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5600/2499940 | global iter:   2801/1249970 | loss: 0.3910 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5602/2499940 | global iter:   2802/1249970 | loss: 0.8870 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5604/2499940 | global iter:   2803/1249970 | loss: 1.0120 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5606/2499940 | global iter:   2804/1249970 | loss: 1.7054 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5606/2499940 | global iter:   2804/1249970 | loss: 1.1768 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5608/2499940 | global iter:   2805/1249970 | loss: 0.7219 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5610/2499940 | global iter:   2806/1249970 | loss: 1.0502 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5612/2499940 | global iter:   2807/1249970 | loss: 0.5602 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5614/2499940 | global iter:   2808/1249970 | loss: 0.7234 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5614/2499940 | global iter:   2808/1249970 | loss: 0.8756 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5616/2499940 | global iter:   2809/1249970 | loss: 0.9388 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5618/2499940 | global iter:   2810/1249970 | loss: 0.5514 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.392 | step time: 0.000
train | epoch   0 | Iter:   5620/2499940 | global iter:   2811/1249970 | loss: 0.8534 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5622/2499940 | global iter:   2812/1249970 | loss: 1.5302 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5622/2499940 | global iter:   2812/1249970 | loss: 0.9522 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5624/2499940 | global iter:   2813/1249970 | loss: 0.9073 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5626/2499940 | global iter:   2814/1249970 | loss: 1.3781 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5628/2499940 | global iter:   2815/1249970 | loss: 0.4692 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5630/2499940 | global iter:   2816/1249970 | loss: 1.4809 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5630/2499940 | global iter:   2816/1249970 | loss: 0.9893 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5632/2499940 | global iter:   2817/1249970 | loss: 1.8156 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5634/2499940 | global iter:   2818/1249970 | loss: 1.5642 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5636/2499940 | global iter:   2819/1249970 | loss: 0.7234 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5638/2499940 | global iter:   2820/1249970 | loss: 0.9688 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5638/2499940 | global iter:   2820/1249970 | loss: 1.0523 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5640/2499940 | global iter:   2821/1249970 | loss: 1.1115 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5642/2499940 | global iter:   2822/1249970 | loss: 1.1495 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5644/2499940 | global iter:   2823/1249970 | loss: 1.7536 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5646/2499940 | global iter:   2824/1249970 | loss: 1.7306 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5646/2499940 | global iter:   2824/1249970 | loss: 1.1882 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5648/2499940 | global iter:   2825/1249970 | loss: 0.9515 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   5650/2499940 | global iter:   2826/1249970 | loss: 0.5719 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5652/2499940 | global iter:   2827/1249970 | loss: 0.8911 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5654/2499940 | global iter:   2828/1249970 | loss: 1.1939 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5654/2499940 | global iter:   2828/1249970 | loss: 1.0047 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5656/2499940 | global iter:   2829/1249970 | loss: 1.0212 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5658/2499940 | global iter:   2830/1249970 | loss: 0.8150 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5660/2499940 | global iter:   2831/1249970 | loss: 1.4018 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5662/2499940 | global iter:   2832/1249970 | loss: 1.1688 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5662/2499940 | global iter:   2832/1249970 | loss: 1.1188 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5664/2499940 | global iter:   2833/1249970 | loss: 1.1426 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5666/2499940 | global iter:   2834/1249970 | loss: 1.3229 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5668/2499940 | global iter:   2835/1249970 | loss: 0.3706 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5670/2499940 | global iter:   2836/1249970 | loss: 1.1515 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5670/2499940 | global iter:   2836/1249970 | loss: 1.0226 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5672/2499940 | global iter:   2837/1249970 | loss: 0.6374 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5674/2499940 | global iter:   2838/1249970 | loss: 1.4232 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5676/2499940 | global iter:   2839/1249970 | loss: 1.3637 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5678/2499940 | global iter:   2840/1249970 | loss: 1.0455 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5678/2499940 | global iter:   2840/1249970 | loss: 1.2862 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5680/2499940 | global iter:   2841/1249970 | loss: 1.8664 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5682/2499940 | global iter:   2842/1249970 | loss: 0.7631 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5684/2499940 | global iter:   2843/1249970 | loss: 0.8948 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5686/2499940 | global iter:   2844/1249970 | loss: 0.9688 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5686/2499940 | global iter:   2844/1249970 | loss: 1.0944 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5688/2499940 | global iter:   2845/1249970 | loss: 1.0193 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5690/2499940 | global iter:   2846/1249970 | loss: 1.9017 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   5692/2499940 | global iter:   2847/1249970 | loss: 1.6000 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5694/2499940 | global iter:   2848/1249970 | loss: 1.4655 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5694/2499940 | global iter:   2848/1249970 | loss: 1.4401 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5696/2499940 | global iter:   2849/1249970 | loss: 0.4240 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5698/2499940 | global iter:   2850/1249970 | loss: 1.7752 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5700/2499940 | global iter:   2851/1249970 | loss: 1.3469 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   5702/2499940 | global iter:   2852/1249970 | loss: 1.3792 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5702/2499940 | global iter:   2852/1249970 | loss: 1.1922 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5704/2499940 | global iter:   2853/1249970 | loss: 1.6785 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5706/2499940 | global iter:   2854/1249970 | loss: 0.8731 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5708/2499940 | global iter:   2855/1249970 | loss: 1.6067 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:   5710/2499940 | global iter:   2856/1249970 | loss: 1.2581 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5710/2499940 | global iter:   2856/1249970 | loss: 1.2586 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5712/2499940 | global iter:   2857/1249970 | loss: 1.5025 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5714/2499940 | global iter:   2858/1249970 | loss: 1.9588 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5716/2499940 | global iter:   2859/1249970 | loss: 1.4330 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5718/2499940 | global iter:   2860/1249970 | loss: 0.8001 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5718/2499940 | global iter:   2860/1249970 | loss: 1.1954 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5720/2499940 | global iter:   2861/1249970 | loss: 1.6365 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5722/2499940 | global iter:   2862/1249970 | loss: 0.9063 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5724/2499940 | global iter:   2863/1249970 | loss: 1.3235 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5726/2499940 | global iter:   2864/1249970 | loss: 1.5945 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5726/2499940 | global iter:   2864/1249970 | loss: 1.2612 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5728/2499940 | global iter:   2865/1249970 | loss: 0.4506 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.411 | step time: 0.000
train | epoch   0 | Iter:   5730/2499940 | global iter:   2866/1249970 | loss: 0.4665 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5732/2499940 | global iter:   2867/1249970 | loss: 1.6855 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5734/2499940 | global iter:   2868/1249970 | loss: 1.7004 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5734/2499940 | global iter:   2868/1249970 | loss: 1.0020 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5736/2499940 | global iter:   2869/1249970 | loss: 0.7435 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   5738/2499940 | global iter:   2870/1249970 | loss: 1.4064 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5740/2499940 | global iter:   2871/1249970 | loss: 1.3125 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5742/2499940 | global iter:   2872/1249970 | loss: 0.7114 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5742/2499940 | global iter:   2872/1249970 | loss: 0.8162 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5744/2499940 | global iter:   2873/1249970 | loss: 1.5352 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5746/2499940 | global iter:   2874/1249970 | loss: 0.5470 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5748/2499940 | global iter:   2875/1249970 | loss: 1.2887 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5750/2499940 | global iter:   2876/1249970 | loss: 1.7079 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5750/2499940 | global iter:   2876/1249970 | loss: 1.3031 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5752/2499940 | global iter:   2877/1249970 | loss: 0.5715 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   5754/2499940 | global iter:   2878/1249970 | loss: 1.0219 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5756/2499940 | global iter:   2879/1249970 | loss: 0.5839 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5758/2499940 | global iter:   2880/1249970 | loss: 1.5365 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5758/2499940 | global iter:   2880/1249970 | loss: 0.9276 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5760/2499940 | global iter:   2881/1249970 | loss: 0.0123 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5762/2499940 | global iter:   2882/1249970 | loss: 1.3812 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5764/2499940 | global iter:   2883/1249970 | loss: 0.3821 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5766/2499940 | global iter:   2884/1249970 | loss: 1.8416 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5766/2499940 | global iter:   2884/1249970 | loss: 0.9137 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5768/2499940 | global iter:   2885/1249970 | loss: 0.6902 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5770/2499940 | global iter:   2886/1249970 | loss: 0.9564 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   5772/2499940 | global iter:   2887/1249970 | loss: 0.7752 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5774/2499940 | global iter:   2888/1249970 | loss: 1.5682 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5774/2499940 | global iter:   2888/1249970 | loss: 1.0583 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5776/2499940 | global iter:   2889/1249970 | loss: 1.4783 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5778/2499940 | global iter:   2890/1249970 | loss: 1.3861 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   5780/2499940 | global iter:   2891/1249970 | loss: 1.2053 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   5782/2499940 | global iter:   2892/1249970 | loss: 0.6217 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5782/2499940 | global iter:   2892/1249970 | loss: 1.0404 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5784/2499940 | global iter:   2893/1249970 | loss: 1.2604 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5786/2499940 | global iter:   2894/1249970 | loss: 0.5055 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5788/2499940 | global iter:   2895/1249970 | loss: 1.1228 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5790/2499940 | global iter:   2896/1249970 | loss: 1.8709 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5790/2499940 | global iter:   2896/1249970 | loss: 1.0715 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5792/2499940 | global iter:   2897/1249970 | loss: 1.2639 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5794/2499940 | global iter:   2898/1249970 | loss: 1.1060 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5796/2499940 | global iter:   2899/1249970 | loss: 0.3399 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5798/2499940 | global iter:   2900/1249970 | loss: 1.5403 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5798/2499940 | global iter:   2900/1249970 | loss: 1.2017 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5800/2499940 | global iter:   2901/1249970 | loss: 0.5325 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   5802/2499940 | global iter:   2902/1249970 | loss: 2.1856 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5804/2499940 | global iter:   2903/1249970 | loss: 0.9098 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   5806/2499940 | global iter:   2904/1249970 | loss: 1.4836 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5806/2499940 | global iter:   2904/1249970 | loss: 1.1312 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5808/2499940 | global iter:   2905/1249970 | loss: 1.4691 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5810/2499940 | global iter:   2906/1249970 | loss: 1.4034 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:   5812/2499940 | global iter:   2907/1249970 | loss: 1.0542 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5814/2499940 | global iter:   2908/1249970 | loss: 1.1754 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5814/2499940 | global iter:   2908/1249970 | loss: 1.3074 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5816/2499940 | global iter:   2909/1249970 | loss: 1.7025 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5818/2499940 | global iter:   2910/1249970 | loss: 1.1791 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:   5820/2499940 | global iter:   2911/1249970 | loss: 0.6333 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5822/2499940 | global iter:   2912/1249970 | loss: 1.2645 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5822/2499940 | global iter:   2912/1249970 | loss: 1.1839 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5824/2499940 | global iter:   2913/1249970 | loss: 1.2458 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5826/2499940 | global iter:   2914/1249970 | loss: 0.7916 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   5828/2499940 | global iter:   2915/1249970 | loss: 1.9997 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   5830/2499940 | global iter:   2916/1249970 | loss: 0.9044 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5830/2499940 | global iter:   2916/1249970 | loss: 1.1663 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5832/2499940 | global iter:   2917/1249970 | loss: 0.7506 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5834/2499940 | global iter:   2918/1249970 | loss: 1.5179 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5836/2499940 | global iter:   2919/1249970 | loss: 1.0010 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   5838/2499940 | global iter:   2920/1249970 | loss: 2.2663 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5838/2499940 | global iter:   2920/1249970 | loss: 1.5519 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5840/2499940 | global iter:   2921/1249970 | loss: 1.3652 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5842/2499940 | global iter:   2922/1249970 | loss: 0.7574 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5844/2499940 | global iter:   2923/1249970 | loss: 1.5519 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5846/2499940 | global iter:   2924/1249970 | loss: 0.9633 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5846/2499940 | global iter:   2924/1249970 | loss: 1.2404 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5848/2499940 | global iter:   2925/1249970 | loss: 1.0016 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5850/2499940 | global iter:   2926/1249970 | loss: 0.5354 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   5852/2499940 | global iter:   2927/1249970 | loss: 1.5595 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5854/2499940 | global iter:   2928/1249970 | loss: 1.3659 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5854/2499940 | global iter:   2928/1249970 | loss: 1.0116 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5856/2499940 | global iter:   2929/1249970 | loss: 1.1523 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5858/2499940 | global iter:   2930/1249970 | loss: 0.7742 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5860/2499940 | global iter:   2931/1249970 | loss: 0.6041 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5862/2499940 | global iter:   2932/1249970 | loss: 0.6671 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5862/2499940 | global iter:   2932/1249970 | loss: 0.8860 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5864/2499940 | global iter:   2933/1249970 | loss: 0.8633 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5866/2499940 | global iter:   2934/1249970 | loss: 1.9454 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5868/2499940 | global iter:   2935/1249970 | loss: 1.5400 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5870/2499940 | global iter:   2936/1249970 | loss: 1.3866 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5870/2499940 | global iter:   2936/1249970 | loss: 1.2271 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5872/2499940 | global iter:   2937/1249970 | loss: 1.1385 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5874/2499940 | global iter:   2938/1249970 | loss: 1.0969 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5876/2499940 | global iter:   2939/1249970 | loss: 0.8542 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5878/2499940 | global iter:   2940/1249970 | loss: 1.4768 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5878/2499940 | global iter:   2940/1249970 | loss: 1.1601 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5880/2499940 | global iter:   2941/1249970 | loss: 0.9011 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5882/2499940 | global iter:   2942/1249970 | loss: 0.0556 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5884/2499940 | global iter:   2943/1249970 | loss: 1.4431 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5886/2499940 | global iter:   2944/1249970 | loss: 1.2964 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5886/2499940 | global iter:   2944/1249970 | loss: 0.9892 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5888/2499940 | global iter:   2945/1249970 | loss: 1.1755 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   5890/2499940 | global iter:   2946/1249970 | loss: 1.2661 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5892/2499940 | global iter:   2947/1249970 | loss: 1.4670 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5894/2499940 | global iter:   2948/1249970 | loss: 1.5671 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5894/2499940 | global iter:   2948/1249970 | loss: 1.3055 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5896/2499940 | global iter:   2949/1249970 | loss: 1.6343 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   5898/2499940 | global iter:   2950/1249970 | loss: 1.5530 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5900/2499940 | global iter:   2951/1249970 | loss: 0.8170 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.410 | step time: 0.000
train | epoch   0 | Iter:   5902/2499940 | global iter:   2952/1249970 | loss: 1.2648 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5902/2499940 | global iter:   2952/1249970 | loss: 1.2014 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.697
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5904/2499940 | global iter:   2953/1249970 | loss: 0.5323 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5906/2499940 | global iter:   2954/1249970 | loss: 0.4933 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   5908/2499940 | global iter:   2955/1249970 | loss: 1.4376 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   5910/2499940 | global iter:   2956/1249970 | loss: 1.3560 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5910/2499940 | global iter:   2956/1249970 | loss: 1.0773 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5912/2499940 | global iter:   2957/1249970 | loss: 0.3303 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5914/2499940 | global iter:   2958/1249970 | loss: 0.5268 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5916/2499940 | global iter:   2959/1249970 | loss: 1.3341 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5918/2499940 | global iter:   2960/1249970 | loss: 1.3589 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5918/2499940 | global iter:   2960/1249970 | loss: 0.9866 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5920/2499940 | global iter:   2961/1249970 | loss: 1.2372 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5922/2499940 | global iter:   2962/1249970 | loss: 1.4938 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5924/2499940 | global iter:   2963/1249970 | loss: 1.0374 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5926/2499940 | global iter:   2964/1249970 | loss: 2.1637 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5926/2499940 | global iter:   2964/1249970 | loss: 1.3675 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5928/2499940 | global iter:   2965/1249970 | loss: 1.1699 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5930/2499940 | global iter:   2966/1249970 | loss: 1.1808 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5932/2499940 | global iter:   2967/1249970 | loss: 1.4728 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5934/2499940 | global iter:   2968/1249970 | loss: 0.6172 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5934/2499940 | global iter:   2968/1249970 | loss: 1.1055 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5936/2499940 | global iter:   2969/1249970 | loss: 1.3515 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5938/2499940 | global iter:   2970/1249970 | loss: 1.0530 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5940/2499940 | global iter:   2971/1249970 | loss: 1.0127 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5942/2499940 | global iter:   2972/1249970 | loss: 1.4567 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5942/2499940 | global iter:   2972/1249970 | loss: 1.0948 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5944/2499940 | global iter:   2973/1249970 | loss: 0.2782 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5946/2499940 | global iter:   2974/1249970 | loss: 0.9852 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5948/2499940 | global iter:   2975/1249970 | loss: 1.1685 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5950/2499940 | global iter:   2976/1249970 | loss: 1.0287 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5950/2499940 | global iter:   2976/1249970 | loss: 0.8568 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5952/2499940 | global iter:   2977/1249970 | loss: 0.2029 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   5954/2499940 | global iter:   2978/1249970 | loss: 1.1088 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5956/2499940 | global iter:   2979/1249970 | loss: 1.0176 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5958/2499940 | global iter:   2980/1249970 | loss: 1.0021 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.404 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5958/2499940 | global iter:   2980/1249970 | loss: 1.0416 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.404 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5960/2499940 | global iter:   2981/1249970 | loss: 1.4048 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5962/2499940 | global iter:   2982/1249970 | loss: 1.0395 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   5964/2499940 | global iter:   2983/1249970 | loss: 1.4995 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5966/2499940 | global iter:   2984/1249970 | loss: 1.7786 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5966/2499940 | global iter:   2984/1249970 | loss: 1.1914 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.393 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5968/2499940 | global iter:   2985/1249970 | loss: 1.1535 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5970/2499940 | global iter:   2986/1249970 | loss: 0.8074 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5972/2499940 | global iter:   2987/1249970 | loss: 0.1864 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5974/2499940 | global iter:   2988/1249970 | loss: 1.7690 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5974/2499940 | global iter:   2988/1249970 | loss: 1.0354 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5976/2499940 | global iter:   2989/1249970 | loss: 0.7006 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5978/2499940 | global iter:   2990/1249970 | loss: 0.9912 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:   5980/2499940 | global iter:   2991/1249970 | loss: 0.5404 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5982/2499940 | global iter:   2992/1249970 | loss: 0.9225 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5982/2499940 | global iter:   2992/1249970 | loss: 1.0103 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5984/2499940 | global iter:   2993/1249970 | loss: 1.2202 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5986/2499940 | global iter:   2994/1249970 | loss: 0.7527 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   5988/2499940 | global iter:   2995/1249970 | loss: 0.8915 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.411 | step time: 0.000
train | epoch   0 | Iter:   5990/2499940 | global iter:   2996/1249970 | loss: 0.6715 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5990/2499940 | global iter:   2996/1249970 | loss: 1.1295 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   5992/2499940 | global iter:   2997/1249970 | loss: 1.4662 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   5994/2499940 | global iter:   2998/1249970 | loss: 1.7146 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   5996/2499940 | global iter:   2999/1249970 | loss: 1.1872 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   5998/2499940 | global iter:   3000/1249970 | loss: 0.6824 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5998/2499940 | global iter:   3000/1249970 | loss: 1.2972 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6000/2499940 | global iter:   3001/1249970 | loss: 1.3089 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6002/2499940 | global iter:   3002/1249970 | loss: 0.6478 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6004/2499940 | global iter:   3003/1249970 | loss: 1.3632 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6006/2499940 | global iter:   3004/1249970 | loss: 0.7944 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6006/2499940 | global iter:   3004/1249970 | loss: 1.1477 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6008/2499940 | global iter:   3005/1249970 | loss: 1.0688 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6010/2499940 | global iter:   3006/1249970 | loss: 1.2408 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6012/2499940 | global iter:   3007/1249970 | loss: 1.3244 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6014/2499940 | global iter:   3008/1249970 | loss: 0.3209 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6014/2499940 | global iter:   3008/1249970 | loss: 0.9495 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6016/2499940 | global iter:   3009/1249970 | loss: 0.2274 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6018/2499940 | global iter:   3010/1249970 | loss: 1.6113 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6020/2499940 | global iter:   3011/1249970 | loss: 1.0513 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6022/2499940 | global iter:   3012/1249970 | loss: 0.5560 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6022/2499940 | global iter:   3012/1249970 | loss: 1.0448 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6024/2499940 | global iter:   3013/1249970 | loss: 1.6560 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6026/2499940 | global iter:   3014/1249970 | loss: 2.3464 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   6028/2499940 | global iter:   3015/1249970 | loss: 1.1513 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6030/2499940 | global iter:   3016/1249970 | loss: 1.3935 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6030/2499940 | global iter:   3016/1249970 | loss: 1.3188 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6032/2499940 | global iter:   3017/1249970 | loss: 0.4792 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6034/2499940 | global iter:   3018/1249970 | loss: 1.4744 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6036/2499940 | global iter:   3019/1249970 | loss: 1.4792 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6038/2499940 | global iter:   3020/1249970 | loss: 0.7356 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6038/2499940 | global iter:   3020/1249970 | loss: 1.0124 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6040/2499940 | global iter:   3021/1249970 | loss: 0.6494 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6042/2499940 | global iter:   3022/1249970 | loss: 1.8630 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   6044/2499940 | global iter:   3023/1249970 | loss: 1.6776 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6046/2499940 | global iter:   3024/1249970 | loss: 0.8033 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6046/2499940 | global iter:   3024/1249970 | loss: 1.1636 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6048/2499940 | global iter:   3025/1249970 | loss: 0.7612 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6050/2499940 | global iter:   3026/1249970 | loss: 0.5232 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6052/2499940 | global iter:   3027/1249970 | loss: 0.8740 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6054/2499940 | global iter:   3028/1249970 | loss: 1.2380 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6054/2499940 | global iter:   3028/1249970 | loss: 1.1765 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.393 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6056/2499940 | global iter:   3029/1249970 | loss: 0.8922 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6058/2499940 | global iter:   3030/1249970 | loss: 1.4267 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6060/2499940 | global iter:   3031/1249970 | loss: 0.9283 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6062/2499940 | global iter:   3032/1249970 | loss: 0.9194 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6062/2499940 | global iter:   3032/1249970 | loss: 1.1437 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6064/2499940 | global iter:   3033/1249970 | loss: 1.5385 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6066/2499940 | global iter:   3034/1249970 | loss: 1.2337 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   6068/2499940 | global iter:   3035/1249970 | loss: 1.5923 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6070/2499940 | global iter:   3036/1249970 | loss: 1.4310 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6070/2499940 | global iter:   3036/1249970 | loss: 1.3380 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6072/2499940 | global iter:   3037/1249970 | loss: 1.0544 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6074/2499940 | global iter:   3038/1249970 | loss: 0.5528 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   6076/2499940 | global iter:   3039/1249970 | loss: 1.6677 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6078/2499940 | global iter:   3040/1249970 | loss: 0.7535 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6078/2499940 | global iter:   3040/1249970 | loss: 1.0619 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6080/2499940 | global iter:   3041/1249970 | loss: 1.2734 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6082/2499940 | global iter:   3042/1249970 | loss: 0.8384 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6084/2499940 | global iter:   3043/1249970 | loss: 0.8207 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6086/2499940 | global iter:   3044/1249970 | loss: 0.4274 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6086/2499940 | global iter:   3044/1249970 | loss: 0.9134 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6088/2499940 | global iter:   3045/1249970 | loss: 1.2831 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6090/2499940 | global iter:   3046/1249970 | loss: 1.6704 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6092/2499940 | global iter:   3047/1249970 | loss: 0.8287 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6094/2499940 | global iter:   3048/1249970 | loss: 0.6219 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6094/2499940 | global iter:   3048/1249970 | loss: 1.2390 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6096/2499940 | global iter:   3049/1249970 | loss: 1.3070 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6098/2499940 | global iter:   3050/1249970 | loss: 1.6190 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6100/2499940 | global iter:   3051/1249970 | loss: 0.6606 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6102/2499940 | global iter:   3052/1249970 | loss: 0.8766 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6102/2499940 | global iter:   3052/1249970 | loss: 1.1108 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6104/2499940 | global iter:   3053/1249970 | loss: 1.1074 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6106/2499940 | global iter:   3054/1249970 | loss: 1.4796 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6108/2499940 | global iter:   3055/1249970 | loss: 1.2294 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6110/2499940 | global iter:   3056/1249970 | loss: 1.5355 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6110/2499940 | global iter:   3056/1249970 | loss: 1.3776 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6112/2499940 | global iter:   3057/1249970 | loss: 0.8868 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6114/2499940 | global iter:   3058/1249970 | loss: 0.7091 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6116/2499940 | global iter:   3059/1249970 | loss: 1.4187 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6118/2499940 | global iter:   3060/1249970 | loss: 0.8250 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6118/2499940 | global iter:   3060/1249970 | loss: 1.0754 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6120/2499940 | global iter:   3061/1249970 | loss: 0.9710 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6122/2499940 | global iter:   3062/1249970 | loss: 1.0112 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6124/2499940 | global iter:   3063/1249970 | loss: 0.1256 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6126/2499940 | global iter:   3064/1249970 | loss: 0.4535 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6126/2499940 | global iter:   3064/1249970 | loss: 0.7171 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6128/2499940 | global iter:   3065/1249970 | loss: 0.6289 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6130/2499940 | global iter:   3066/1249970 | loss: 1.5017 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6132/2499940 | global iter:   3067/1249970 | loss: 0.7585 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6134/2499940 | global iter:   3068/1249970 | loss: 0.9317 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6134/2499940 | global iter:   3068/1249970 | loss: 1.1517 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6136/2499940 | global iter:   3069/1249970 | loss: 0.9494 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   6138/2499940 | global iter:   3070/1249970 | loss: 1.9838 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6140/2499940 | global iter:   3071/1249970 | loss: 1.9232 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6142/2499940 | global iter:   3072/1249970 | loss: 1.2437 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6142/2499940 | global iter:   3072/1249970 | loss: 1.3253 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6144/2499940 | global iter:   3073/1249970 | loss: 0.6640 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6146/2499940 | global iter:   3074/1249970 | loss: 0.7681 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   6148/2499940 | global iter:   3075/1249970 | loss: 2.0306 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6150/2499940 | global iter:   3076/1249970 | loss: 1.6796 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6150/2499940 | global iter:   3076/1249970 | loss: 1.2279 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6152/2499940 | global iter:   3077/1249970 | loss: 1.0814 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6154/2499940 | global iter:   3078/1249970 | loss: 1.3022 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6156/2499940 | global iter:   3079/1249970 | loss: 1.7640 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6158/2499940 | global iter:   3080/1249970 | loss: 0.0256 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6158/2499940 | global iter:   3080/1249970 | loss: 1.0988 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6160/2499940 | global iter:   3081/1249970 | loss: 1.1344 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.409 | step time: 0.000
train | epoch   0 | Iter:   6162/2499940 | global iter:   3082/1249970 | loss: 1.1394 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6164/2499940 | global iter:   3083/1249970 | loss: 0.6929 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6166/2499940 | global iter:   3084/1249970 | loss: 1.1541 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6166/2499940 | global iter:   3084/1249970 | loss: 1.2790 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6168/2499940 | global iter:   3085/1249970 | loss: 0.7402 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6170/2499940 | global iter:   3086/1249970 | loss: 1.0381 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6172/2499940 | global iter:   3087/1249970 | loss: 1.2041 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6174/2499940 | global iter:   3088/1249970 | loss: 1.9064 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6174/2499940 | global iter:   3088/1249970 | loss: 1.1666 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6176/2499940 | global iter:   3089/1249970 | loss: 0.4505 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6178/2499940 | global iter:   3090/1249970 | loss: 1.0058 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   6180/2499940 | global iter:   3091/1249970 | loss: 0.2765 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6182/2499940 | global iter:   3092/1249970 | loss: 1.0721 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6182/2499940 | global iter:   3092/1249970 | loss: 0.9930 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6184/2499940 | global iter:   3093/1249970 | loss: 0.7149 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6186/2499940 | global iter:   3094/1249970 | loss: 1.8577 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6188/2499940 | global iter:   3095/1249970 | loss: 0.7604 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6190/2499940 | global iter:   3096/1249970 | loss: 0.4908 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6190/2499940 | global iter:   3096/1249970 | loss: 0.8460 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6192/2499940 | global iter:   3097/1249970 | loss: 0.7056 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6194/2499940 | global iter:   3098/1249970 | loss: 1.0800 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6196/2499940 | global iter:   3099/1249970 | loss: 0.6219 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6198/2499940 | global iter:   3100/1249970 | loss: 0.2612 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6198/2499940 | global iter:   3100/1249970 | loss: 0.8123 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6200/2499940 | global iter:   3101/1249970 | loss: 0.7148 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6202/2499940 | global iter:   3102/1249970 | loss: 0.9178 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6204/2499940 | global iter:   3103/1249970 | loss: 0.8021 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6206/2499940 | global iter:   3104/1249970 | loss: 1.4824 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6206/2499940 | global iter:   3104/1249970 | loss: 1.0977 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6208/2499940 | global iter:   3105/1249970 | loss: 1.3130 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6210/2499940 | global iter:   3106/1249970 | loss: 1.6738 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6212/2499940 | global iter:   3107/1249970 | loss: 1.4313 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   6214/2499940 | global iter:   3108/1249970 | loss: 0.2951 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6214/2499940 | global iter:   3108/1249970 | loss: 1.0792 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6216/2499940 | global iter:   3109/1249970 | loss: 1.2749 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6218/2499940 | global iter:   3110/1249970 | loss: 0.8170 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6220/2499940 | global iter:   3111/1249970 | loss: 0.9956 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6222/2499940 | global iter:   3112/1249970 | loss: 1.5083 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6222/2499940 | global iter:   3112/1249970 | loss: 1.1511 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6224/2499940 | global iter:   3113/1249970 | loss: 0.8716 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6226/2499940 | global iter:   3114/1249970 | loss: 1.3048 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   6228/2499940 | global iter:   3115/1249970 | loss: 1.5529 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6230/2499940 | global iter:   3116/1249970 | loss: 1.7388 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6230/2499940 | global iter:   3116/1249970 | loss: 1.3448 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6232/2499940 | global iter:   3117/1249970 | loss: 1.2897 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6234/2499940 | global iter:   3118/1249970 | loss: 0.6656 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6236/2499940 | global iter:   3119/1249970 | loss: 0.0192 | ds_loss: 0.0000 | lr: 9.9999e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6238/2499940 | global iter:   3120/1249970 | loss: 0.1338 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6238/2499940 | global iter:   3120/1249970 | loss: 0.9910 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6240/2499940 | global iter:   3121/1249970 | loss: 0.9865 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6242/2499940 | global iter:   3122/1249970 | loss: 1.0358 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   6244/2499940 | global iter:   3123/1249970 | loss: 1.7113 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6246/2499940 | global iter:   3124/1249970 | loss: 1.6912 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6246/2499940 | global iter:   3124/1249970 | loss: 1.3782 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6248/2499940 | global iter:   3125/1249970 | loss: 1.6778 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6250/2499940 | global iter:   3126/1249970 | loss: 1.5188 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   6252/2499940 | global iter:   3127/1249970 | loss: 0.6056 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6254/2499940 | global iter:   3128/1249970 | loss: 0.4689 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6254/2499940 | global iter:   3128/1249970 | loss: 1.1508 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6256/2499940 | global iter:   3129/1249970 | loss: 1.5351 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   6258/2499940 | global iter:   3130/1249970 | loss: 1.4112 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6260/2499940 | global iter:   3131/1249970 | loss: 1.8679 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6262/2499940 | global iter:   3132/1249970 | loss: 1.4861 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6262/2499940 | global iter:   3132/1249970 | loss: 1.2938 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.686
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6264/2499940 | global iter:   3133/1249970 | loss: 0.5886 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6266/2499940 | global iter:   3134/1249970 | loss: 1.5971 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6268/2499940 | global iter:   3135/1249970 | loss: 1.0803 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6270/2499940 | global iter:   3136/1249970 | loss: 0.9307 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6270/2499940 | global iter:   3136/1249970 | loss: 1.0417 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6272/2499940 | global iter:   3137/1249970 | loss: 1.0984 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6274/2499940 | global iter:   3138/1249970 | loss: 0.2668 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6276/2499940 | global iter:   3139/1249970 | loss: 1.1701 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6278/2499940 | global iter:   3140/1249970 | loss: 0.7614 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6278/2499940 | global iter:   3140/1249970 | loss: 1.0551 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6280/2499940 | global iter:   3141/1249970 | loss: 0.3022 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   6282/2499940 | global iter:   3142/1249970 | loss: 1.0716 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6284/2499940 | global iter:   3143/1249970 | loss: 0.6230 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   6286/2499940 | global iter:   3144/1249970 | loss: 1.3803 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6286/2499940 | global iter:   3144/1249970 | loss: 0.8160 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6288/2499940 | global iter:   3145/1249970 | loss: 1.4913 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6290/2499940 | global iter:   3146/1249970 | loss: 1.1842 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.391 | step time: 0.000
train | epoch   0 | Iter:   6292/2499940 | global iter:   3147/1249970 | loss: 1.0366 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6294/2499940 | global iter:   3148/1249970 | loss: 1.6633 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6294/2499940 | global iter:   3148/1249970 | loss: 1.0152 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6296/2499940 | global iter:   3149/1249970 | loss: 1.3565 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6298/2499940 | global iter:   3150/1249970 | loss: 1.7443 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6300/2499940 | global iter:   3151/1249970 | loss: 1.2637 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6302/2499940 | global iter:   3152/1249970 | loss: 0.7751 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6302/2499940 | global iter:   3152/1249970 | loss: 1.2093 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6304/2499940 | global iter:   3153/1249970 | loss: 1.1509 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6306/2499940 | global iter:   3154/1249970 | loss: 0.6856 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6308/2499940 | global iter:   3155/1249970 | loss: 1.1574 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6310/2499940 | global iter:   3156/1249970 | loss: 0.9010 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6310/2499940 | global iter:   3156/1249970 | loss: 1.1601 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6312/2499940 | global iter:   3157/1249970 | loss: 1.1794 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6314/2499940 | global iter:   3158/1249970 | loss: 0.8266 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6316/2499940 | global iter:   3159/1249970 | loss: 0.9994 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6318/2499940 | global iter:   3160/1249970 | loss: 1.0852 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6318/2499940 | global iter:   3160/1249970 | loss: 1.2160 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6320/2499940 | global iter:   3161/1249970 | loss: 0.8204 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6322/2499940 | global iter:   3162/1249970 | loss: 1.3801 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6324/2499940 | global iter:   3163/1249970 | loss: 0.8501 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6326/2499940 | global iter:   3164/1249970 | loss: 1.3174 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6326/2499940 | global iter:   3164/1249970 | loss: 1.2173 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6328/2499940 | global iter:   3165/1249970 | loss: 0.6851 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6330/2499940 | global iter:   3166/1249970 | loss: 1.3943 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6332/2499940 | global iter:   3167/1249970 | loss: 1.2430 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6334/2499940 | global iter:   3168/1249970 | loss: 1.4361 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6334/2499940 | global iter:   3168/1249970 | loss: 1.0069 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6336/2499940 | global iter:   3169/1249970 | loss: 0.4113 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6338/2499940 | global iter:   3170/1249970 | loss: 1.3872 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6340/2499940 | global iter:   3171/1249970 | loss: 2.3838 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6342/2499940 | global iter:   3172/1249970 | loss: 1.0652 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6342/2499940 | global iter:   3172/1249970 | loss: 1.2050 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6344/2499940 | global iter:   3173/1249970 | loss: 1.7633 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6346/2499940 | global iter:   3174/1249970 | loss: 0.9855 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6348/2499940 | global iter:   3175/1249970 | loss: 2.0811 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6350/2499940 | global iter:   3176/1249970 | loss: 0.9699 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6350/2499940 | global iter:   3176/1249970 | loss: 1.0935 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6352/2499940 | global iter:   3177/1249970 | loss: 0.8004 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6354/2499940 | global iter:   3178/1249970 | loss: 1.0373 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6356/2499940 | global iter:   3179/1249970 | loss: 0.5341 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6358/2499940 | global iter:   3180/1249970 | loss: 1.4371 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6358/2499940 | global iter:   3180/1249970 | loss: 1.0151 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6360/2499940 | global iter:   3181/1249970 | loss: 0.8178 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6362/2499940 | global iter:   3182/1249970 | loss: 0.9112 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6364/2499940 | global iter:   3183/1249970 | loss: 0.4638 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6366/2499940 | global iter:   3184/1249970 | loss: 0.7949 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6366/2499940 | global iter:   3184/1249970 | loss: 0.9692 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6368/2499940 | global iter:   3185/1249970 | loss: 1.0514 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   6370/2499940 | global iter:   3186/1249970 | loss: 0.5453 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6372/2499940 | global iter:   3187/1249970 | loss: 1.0453 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6374/2499940 | global iter:   3188/1249970 | loss: 1.3002 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6374/2499940 | global iter:   3188/1249970 | loss: 0.9808 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6376/2499940 | global iter:   3189/1249970 | loss: 0.9921 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6378/2499940 | global iter:   3190/1249970 | loss: 0.9047 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   6380/2499940 | global iter:   3191/1249970 | loss: 0.8016 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6382/2499940 | global iter:   3192/1249970 | loss: 1.2056 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6382/2499940 | global iter:   3192/1249970 | loss: 1.1704 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6384/2499940 | global iter:   3193/1249970 | loss: 1.3319 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6386/2499940 | global iter:   3194/1249970 | loss: 0.9109 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6388/2499940 | global iter:   3195/1249970 | loss: 0.7369 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6390/2499940 | global iter:   3196/1249970 | loss: 2.0280 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6390/2499940 | global iter:   3196/1249970 | loss: 1.1695 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6392/2499940 | global iter:   3197/1249970 | loss: 1.1682 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6394/2499940 | global iter:   3198/1249970 | loss: 0.8910 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   6396/2499940 | global iter:   3199/1249970 | loss: 1.8272 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6398/2499940 | global iter:   3200/1249970 | loss: 0.7253 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6398/2499940 | global iter:   3200/1249970 | loss: 1.1600 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6400/2499940 | global iter:   3201/1249970 | loss: 1.4461 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6402/2499940 | global iter:   3202/1249970 | loss: 1.7036 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   6404/2499940 | global iter:   3203/1249970 | loss: 0.8953 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6406/2499940 | global iter:   3204/1249970 | loss: 1.8325 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6406/2499940 | global iter:   3204/1249970 | loss: 0.9808 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6408/2499940 | global iter:   3205/1249970 | loss: 0.6336 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6410/2499940 | global iter:   3206/1249970 | loss: 1.2768 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6412/2499940 | global iter:   3207/1249970 | loss: 1.5411 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   6414/2499940 | global iter:   3208/1249970 | loss: 0.9823 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6414/2499940 | global iter:   3208/1249970 | loss: 0.9897 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6416/2499940 | global iter:   3209/1249970 | loss: 1.3362 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6418/2499940 | global iter:   3210/1249970 | loss: 1.1440 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6420/2499940 | global iter:   3211/1249970 | loss: 1.2024 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6422/2499940 | global iter:   3212/1249970 | loss: 1.4383 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.408 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6422/2499940 | global iter:   3212/1249970 | loss: 1.3222 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.408 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6424/2499940 | global iter:   3213/1249970 | loss: 0.9541 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6426/2499940 | global iter:   3214/1249970 | loss: 1.3620 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6428/2499940 | global iter:   3215/1249970 | loss: 1.0851 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6430/2499940 | global iter:   3216/1249970 | loss: 2.3864 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6430/2499940 | global iter:   3216/1249970 | loss: 1.2812 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6432/2499940 | global iter:   3217/1249970 | loss: 1.3079 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6434/2499940 | global iter:   3218/1249970 | loss: 1.5029 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   6436/2499940 | global iter:   3219/1249970 | loss: 1.7401 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6438/2499940 | global iter:   3220/1249970 | loss: 0.5409 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6438/2499940 | global iter:   3220/1249970 | loss: 1.2564 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6440/2499940 | global iter:   3221/1249970 | loss: 0.7297 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6442/2499940 | global iter:   3222/1249970 | loss: 0.7152 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6444/2499940 | global iter:   3223/1249970 | loss: 1.1311 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6446/2499940 | global iter:   3224/1249970 | loss: 0.6359 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6446/2499940 | global iter:   3224/1249970 | loss: 1.1316 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6448/2499940 | global iter:   3225/1249970 | loss: 0.5928 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6450/2499940 | global iter:   3226/1249970 | loss: 0.2076 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6452/2499940 | global iter:   3227/1249970 | loss: 0.9169 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6454/2499940 | global iter:   3228/1249970 | loss: 1.7226 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6454/2499940 | global iter:   3228/1249970 | loss: 0.9778 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6456/2499940 | global iter:   3229/1249970 | loss: 0.6482 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6458/2499940 | global iter:   3230/1249970 | loss: 0.6703 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6460/2499940 | global iter:   3231/1249970 | loss: 1.4626 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6462/2499940 | global iter:   3232/1249970 | loss: 0.9310 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6462/2499940 | global iter:   3232/1249970 | loss: 0.9805 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6464/2499940 | global iter:   3233/1249970 | loss: 0.6226 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6466/2499940 | global iter:   3234/1249970 | loss: 1.2671 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   6468/2499940 | global iter:   3235/1249970 | loss: 0.4038 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6470/2499940 | global iter:   3236/1249970 | loss: 1.1053 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6470/2499940 | global iter:   3236/1249970 | loss: 1.0505 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6472/2499940 | global iter:   3237/1249970 | loss: 0.9232 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6474/2499940 | global iter:   3238/1249970 | loss: 0.7650 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   6476/2499940 | global iter:   3239/1249970 | loss: 1.7897 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6478/2499940 | global iter:   3240/1249970 | loss: 1.2403 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6478/2499940 | global iter:   3240/1249970 | loss: 1.1692 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6480/2499940 | global iter:   3241/1249970 | loss: 1.4635 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6482/2499940 | global iter:   3242/1249970 | loss: 0.6720 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6484/2499940 | global iter:   3243/1249970 | loss: 0.5712 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6486/2499940 | global iter:   3244/1249970 | loss: 1.2935 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6486/2499940 | global iter:   3244/1249970 | loss: 0.8799 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6488/2499940 | global iter:   3245/1249970 | loss: 1.4320 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6490/2499940 | global iter:   3246/1249970 | loss: 1.2633 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6492/2499940 | global iter:   3247/1249970 | loss: 1.9526 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6494/2499940 | global iter:   3248/1249970 | loss: 0.7227 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6494/2499940 | global iter:   3248/1249970 | loss: 1.3076 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6496/2499940 | global iter:   3249/1249970 | loss: 1.2110 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6498/2499940 | global iter:   3250/1249970 | loss: 0.7119 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6500/2499940 | global iter:   3251/1249970 | loss: 0.5479 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6502/2499940 | global iter:   3252/1249970 | loss: 0.3674 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6502/2499940 | global iter:   3252/1249970 | loss: 1.0914 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6504/2499940 | global iter:   3253/1249970 | loss: 0.7424 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6506/2499940 | global iter:   3254/1249970 | loss: 1.6468 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   6508/2499940 | global iter:   3255/1249970 | loss: 0.6301 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.411 | step time: 0.000
train | epoch   0 | Iter:   6510/2499940 | global iter:   3256/1249970 | loss: 0.5270 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6510/2499940 | global iter:   3256/1249970 | loss: 1.0812 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.695
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6512/2499940 | global iter:   3257/1249970 | loss: 1.8437 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6514/2499940 | global iter:   3258/1249970 | loss: 0.9389 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6516/2499940 | global iter:   3259/1249970 | loss: 0.8604 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6518/2499940 | global iter:   3260/1249970 | loss: 0.6709 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6518/2499940 | global iter:   3260/1249970 | loss: 1.1035 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6520/2499940 | global iter:   3261/1249970 | loss: 0.4696 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6522/2499940 | global iter:   3262/1249970 | loss: 1.1344 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6524/2499940 | global iter:   3263/1249970 | loss: 0.9492 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6526/2499940 | global iter:   3264/1249970 | loss: 1.3291 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6526/2499940 | global iter:   3264/1249970 | loss: 1.1822 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6528/2499940 | global iter:   3265/1249970 | loss: 1.2671 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6530/2499940 | global iter:   3266/1249970 | loss: 0.9759 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6532/2499940 | global iter:   3267/1249970 | loss: 0.5348 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6534/2499940 | global iter:   3268/1249970 | loss: 1.2708 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6534/2499940 | global iter:   3268/1249970 | loss: 0.9094 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6536/2499940 | global iter:   3269/1249970 | loss: 0.9605 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6538/2499940 | global iter:   3270/1249970 | loss: 0.7298 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6540/2499940 | global iter:   3271/1249970 | loss: 1.2678 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6542/2499940 | global iter:   3272/1249970 | loss: 1.2869 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6542/2499940 | global iter:   3272/1249970 | loss: 1.0386 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6544/2499940 | global iter:   3273/1249970 | loss: 0.9348 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6546/2499940 | global iter:   3274/1249970 | loss: 1.2157 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6548/2499940 | global iter:   3275/1249970 | loss: 0.8482 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6550/2499940 | global iter:   3276/1249970 | loss: 1.2003 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6550/2499940 | global iter:   3276/1249970 | loss: 1.0848 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6552/2499940 | global iter:   3277/1249970 | loss: 0.3806 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6554/2499940 | global iter:   3278/1249970 | loss: 0.1935 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   6556/2499940 | global iter:   3279/1249970 | loss: 0.9472 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6558/2499940 | global iter:   3280/1249970 | loss: 1.6905 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6558/2499940 | global iter:   3280/1249970 | loss: 0.7105 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6560/2499940 | global iter:   3281/1249970 | loss: 1.6900 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6562/2499940 | global iter:   3282/1249970 | loss: 1.1084 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6564/2499940 | global iter:   3283/1249970 | loss: 1.2235 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6566/2499940 | global iter:   3284/1249970 | loss: 1.1991 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6566/2499940 | global iter:   3284/1249970 | loss: 1.2608 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6568/2499940 | global iter:   3285/1249970 | loss: 1.2799 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6570/2499940 | global iter:   3286/1249970 | loss: 1.2285 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6572/2499940 | global iter:   3287/1249970 | loss: 1.3726 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6574/2499940 | global iter:   3288/1249970 | loss: 1.3183 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6574/2499940 | global iter:   3288/1249970 | loss: 1.3334 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6576/2499940 | global iter:   3289/1249970 | loss: 1.3784 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6578/2499940 | global iter:   3290/1249970 | loss: 1.6656 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6580/2499940 | global iter:   3291/1249970 | loss: 1.5981 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6582/2499940 | global iter:   3292/1249970 | loss: 0.7513 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6582/2499940 | global iter:   3292/1249970 | loss: 1.3474 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6584/2499940 | global iter:   3293/1249970 | loss: 1.1288 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6586/2499940 | global iter:   3294/1249970 | loss: 1.2924 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6588/2499940 | global iter:   3295/1249970 | loss: 1.8379 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6590/2499940 | global iter:   3296/1249970 | loss: 0.7106 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6590/2499940 | global iter:   3296/1249970 | loss: 1.4136 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6592/2499940 | global iter:   3297/1249970 | loss: 1.4982 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6594/2499940 | global iter:   3298/1249970 | loss: 1.2612 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6596/2499940 | global iter:   3299/1249970 | loss: 1.5879 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6598/2499940 | global iter:   3300/1249970 | loss: 1.0850 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6598/2499940 | global iter:   3300/1249970 | loss: 1.3136 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6600/2499940 | global iter:   3301/1249970 | loss: 1.2359 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6602/2499940 | global iter:   3302/1249970 | loss: 0.9568 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6604/2499940 | global iter:   3303/1249970 | loss: 1.3382 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   6606/2499940 | global iter:   3304/1249970 | loss: 0.9390 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6606/2499940 | global iter:   3304/1249970 | loss: 1.1291 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6608/2499940 | global iter:   3305/1249970 | loss: 0.6599 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6610/2499940 | global iter:   3306/1249970 | loss: 1.5472 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6612/2499940 | global iter:   3307/1249970 | loss: 0.8345 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6614/2499940 | global iter:   3308/1249970 | loss: 0.7791 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6614/2499940 | global iter:   3308/1249970 | loss: 1.1318 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6616/2499940 | global iter:   3309/1249970 | loss: 0.6883 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   6618/2499940 | global iter:   3310/1249970 | loss: 1.1468 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6620/2499940 | global iter:   3311/1249970 | loss: 1.1860 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6622/2499940 | global iter:   3312/1249970 | loss: 1.1492 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6622/2499940 | global iter:   3312/1249970 | loss: 1.0668 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6624/2499940 | global iter:   3313/1249970 | loss: 1.6603 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6626/2499940 | global iter:   3314/1249970 | loss: 1.6984 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6628/2499940 | global iter:   3315/1249970 | loss: 1.0339 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6630/2499940 | global iter:   3316/1249970 | loss: 1.3432 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6630/2499940 | global iter:   3316/1249970 | loss: 1.4852 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6632/2499940 | global iter:   3317/1249970 | loss: 1.1102 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6634/2499940 | global iter:   3318/1249970 | loss: 1.3584 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6636/2499940 | global iter:   3319/1249970 | loss: 1.3079 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6638/2499940 | global iter:   3320/1249970 | loss: 0.6235 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6638/2499940 | global iter:   3320/1249970 | loss: 1.3599 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6640/2499940 | global iter:   3321/1249970 | loss: 0.6671 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6642/2499940 | global iter:   3322/1249970 | loss: 2.2466 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6644/2499940 | global iter:   3323/1249970 | loss: 1.2893 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6646/2499940 | global iter:   3324/1249970 | loss: 1.4729 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6646/2499940 | global iter:   3324/1249970 | loss: 1.3003 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6648/2499940 | global iter:   3325/1249970 | loss: 1.1908 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6650/2499940 | global iter:   3326/1249970 | loss: 1.0767 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6652/2499940 | global iter:   3327/1249970 | loss: 1.7511 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6654/2499940 | global iter:   3328/1249970 | loss: 1.2127 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6654/2499940 | global iter:   3328/1249970 | loss: 1.3417 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6656/2499940 | global iter:   3329/1249970 | loss: 0.9366 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6658/2499940 | global iter:   3330/1249970 | loss: 1.0787 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6660/2499940 | global iter:   3331/1249970 | loss: 1.6545 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6662/2499940 | global iter:   3332/1249970 | loss: 0.8810 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6662/2499940 | global iter:   3332/1249970 | loss: 1.0370 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6664/2499940 | global iter:   3333/1249970 | loss: 0.6073 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6666/2499940 | global iter:   3334/1249970 | loss: 0.5369 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6668/2499940 | global iter:   3335/1249970 | loss: 1.6713 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6670/2499940 | global iter:   3336/1249970 | loss: 0.4177 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6670/2499940 | global iter:   3336/1249970 | loss: 1.0083 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6672/2499940 | global iter:   3337/1249970 | loss: 0.8179 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6674/2499940 | global iter:   3338/1249970 | loss: 1.4195 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6676/2499940 | global iter:   3339/1249970 | loss: 0.9533 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6678/2499940 | global iter:   3340/1249970 | loss: 0.9672 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6678/2499940 | global iter:   3340/1249970 | loss: 0.8826 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6680/2499940 | global iter:   3341/1249970 | loss: 1.5204 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6682/2499940 | global iter:   3342/1249970 | loss: 1.2650 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6684/2499940 | global iter:   3343/1249970 | loss: 0.7032 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6686/2499940 | global iter:   3344/1249970 | loss: 0.8016 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6686/2499940 | global iter:   3344/1249970 | loss: 1.0102 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6688/2499940 | global iter:   3345/1249970 | loss: 0.5866 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6690/2499940 | global iter:   3346/1249970 | loss: 1.1222 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6692/2499940 | global iter:   3347/1249970 | loss: 1.2153 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6694/2499940 | global iter:   3348/1249970 | loss: 1.0605 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6694/2499940 | global iter:   3348/1249970 | loss: 0.8993 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6696/2499940 | global iter:   3349/1249970 | loss: 1.7295 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6698/2499940 | global iter:   3350/1249970 | loss: 1.2913 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6700/2499940 | global iter:   3351/1249970 | loss: 0.8345 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6702/2499940 | global iter:   3352/1249970 | loss: 2.0644 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6702/2499940 | global iter:   3352/1249970 | loss: 1.3492 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6704/2499940 | global iter:   3353/1249970 | loss: 0.9191 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   6706/2499940 | global iter:   3354/1249970 | loss: 1.4032 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6708/2499940 | global iter:   3355/1249970 | loss: 0.7534 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6710/2499940 | global iter:   3356/1249970 | loss: 2.1991 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6710/2499940 | global iter:   3356/1249970 | loss: 1.3412 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6712/2499940 | global iter:   3357/1249970 | loss: 1.2784 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6714/2499940 | global iter:   3358/1249970 | loss: 1.3222 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   6716/2499940 | global iter:   3359/1249970 | loss: 0.9666 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6718/2499940 | global iter:   3360/1249970 | loss: 1.3967 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6718/2499940 | global iter:   3360/1249970 | loss: 1.0844 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6720/2499940 | global iter:   3361/1249970 | loss: 1.7582 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6722/2499940 | global iter:   3362/1249970 | loss: 1.1685 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   6724/2499940 | global iter:   3363/1249970 | loss: 0.9712 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6726/2499940 | global iter:   3364/1249970 | loss: 1.3087 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6726/2499940 | global iter:   3364/1249970 | loss: 1.0719 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6728/2499940 | global iter:   3365/1249970 | loss: 1.1205 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6730/2499940 | global iter:   3366/1249970 | loss: 0.7579 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6732/2499940 | global iter:   3367/1249970 | loss: 1.3013 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6734/2499940 | global iter:   3368/1249970 | loss: 0.8636 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6734/2499940 | global iter:   3368/1249970 | loss: 0.9320 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6736/2499940 | global iter:   3369/1249970 | loss: 0.8361 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6738/2499940 | global iter:   3370/1249970 | loss: 1.4783 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6740/2499940 | global iter:   3371/1249970 | loss: 1.7150 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6742/2499940 | global iter:   3372/1249970 | loss: 1.1534 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6742/2499940 | global iter:   3372/1249970 | loss: 1.3772 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6744/2499940 | global iter:   3373/1249970 | loss: 1.0288 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6746/2499940 | global iter:   3374/1249970 | loss: 1.7919 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6748/2499940 | global iter:   3375/1249970 | loss: 1.8022 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6750/2499940 | global iter:   3376/1249970 | loss: 1.2039 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6750/2499940 | global iter:   3376/1249970 | loss: 1.2924 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6752/2499940 | global iter:   3377/1249970 | loss: 1.1755 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6754/2499940 | global iter:   3378/1249970 | loss: 0.9201 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6756/2499940 | global iter:   3379/1249970 | loss: 1.1692 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6758/2499940 | global iter:   3380/1249970 | loss: 0.8167 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6758/2499940 | global iter:   3380/1249970 | loss: 1.2053 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6760/2499940 | global iter:   3381/1249970 | loss: 1.2800 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6762/2499940 | global iter:   3382/1249970 | loss: 1.9601 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6764/2499940 | global iter:   3383/1249970 | loss: 1.4960 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6766/2499940 | global iter:   3384/1249970 | loss: 1.6832 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6766/2499940 | global iter:   3384/1249970 | loss: 1.3455 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6768/2499940 | global iter:   3385/1249970 | loss: 0.6170 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6770/2499940 | global iter:   3386/1249970 | loss: 1.0259 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6772/2499940 | global iter:   3387/1249970 | loss: 0.8474 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6774/2499940 | global iter:   3388/1249970 | loss: 0.8056 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6774/2499940 | global iter:   3388/1249970 | loss: 0.9575 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6776/2499940 | global iter:   3389/1249970 | loss: 1.5409 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6778/2499940 | global iter:   3390/1249970 | loss: 1.3762 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6780/2499940 | global iter:   3391/1249970 | loss: 1.9485 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6782/2499940 | global iter:   3392/1249970 | loss: 0.5510 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6782/2499940 | global iter:   3392/1249970 | loss: 1.2664 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6784/2499940 | global iter:   3393/1249970 | loss: 0.8402 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6786/2499940 | global iter:   3394/1249970 | loss: 0.5980 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6788/2499940 | global iter:   3395/1249970 | loss: 0.9536 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6790/2499940 | global iter:   3396/1249970 | loss: 1.7218 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6790/2499940 | global iter:   3396/1249970 | loss: 1.0728 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6792/2499940 | global iter:   3397/1249970 | loss: 1.2074 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6794/2499940 | global iter:   3398/1249970 | loss: 0.8752 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6796/2499940 | global iter:   3399/1249970 | loss: 1.3234 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6798/2499940 | global iter:   3400/1249970 | loss: 1.5341 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6798/2499940 | global iter:   3400/1249970 | loss: 1.2876 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6800/2499940 | global iter:   3401/1249970 | loss: 0.5610 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6802/2499940 | global iter:   3402/1249970 | loss: 1.0860 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   6804/2499940 | global iter:   3403/1249970 | loss: 1.7032 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6806/2499940 | global iter:   3404/1249970 | loss: 0.8226 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6806/2499940 | global iter:   3404/1249970 | loss: 1.2125 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6808/2499940 | global iter:   3405/1249970 | loss: 0.7835 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6810/2499940 | global iter:   3406/1249970 | loss: 1.5608 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.390 | step time: 0.000
train | epoch   0 | Iter:   6812/2499940 | global iter:   3407/1249970 | loss: 1.0278 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6814/2499940 | global iter:   3408/1249970 | loss: 1.0907 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6814/2499940 | global iter:   3408/1249970 | loss: 1.0048 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.686
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6816/2499940 | global iter:   3409/1249970 | loss: 1.5897 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6818/2499940 | global iter:   3410/1249970 | loss: 0.5526 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   6820/2499940 | global iter:   3411/1249970 | loss: 1.4498 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6822/2499940 | global iter:   3412/1249970 | loss: 0.7293 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6822/2499940 | global iter:   3412/1249970 | loss: 0.9212 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6824/2499940 | global iter:   3413/1249970 | loss: 0.4934 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6826/2499940 | global iter:   3414/1249970 | loss: 1.0647 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6828/2499940 | global iter:   3415/1249970 | loss: 1.3167 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6830/2499940 | global iter:   3416/1249970 | loss: 0.8458 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6830/2499940 | global iter:   3416/1249970 | loss: 1.1614 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6832/2499940 | global iter:   3417/1249970 | loss: 0.6329 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6834/2499940 | global iter:   3418/1249970 | loss: 1.4967 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6836/2499940 | global iter:   3419/1249970 | loss: 0.7492 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6838/2499940 | global iter:   3420/1249970 | loss: 1.2190 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6838/2499940 | global iter:   3420/1249970 | loss: 1.1388 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6840/2499940 | global iter:   3421/1249970 | loss: 2.1042 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6842/2499940 | global iter:   3422/1249970 | loss: 0.7246 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
[2025-04-20 16:44:46,736] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8192, reducing to 4096
train | epoch   0 | Iter:   6844/2499940 | global iter:   3423/1249970 | loss: 0.5058 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.311 | step time: 0.000
train | epoch   0 | Iter:   6846/2499940 | global iter:   3424/1249970 | loss: 0.2772 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6846/2499940 | global iter:   3424/1249970 | loss: 0.8681 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.668
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6848/2499940 | global iter:   3425/1249970 | loss: 0.7971 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6850/2499940 | global iter:   3426/1249970 | loss: 1.5574 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6852/2499940 | global iter:   3427/1249970 | loss: 1.3688 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6854/2499940 | global iter:   3428/1249970 | loss: 1.4682 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6854/2499940 | global iter:   3428/1249970 | loss: 1.2249 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6856/2499940 | global iter:   3429/1249970 | loss: 1.8493 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   6858/2499940 | global iter:   3430/1249970 | loss: 0.5369 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6860/2499940 | global iter:   3431/1249970 | loss: 1.1725 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6862/2499940 | global iter:   3432/1249970 | loss: 0.4903 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6862/2499940 | global iter:   3432/1249970 | loss: 1.0127 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6864/2499940 | global iter:   3433/1249970 | loss: 0.5652 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   6866/2499940 | global iter:   3434/1249970 | loss: 0.5890 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   6868/2499940 | global iter:   3435/1249970 | loss: 0.7592 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6870/2499940 | global iter:   3436/1249970 | loss: 0.8402 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6870/2499940 | global iter:   3436/1249970 | loss: 0.9121 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6872/2499940 | global iter:   3437/1249970 | loss: 0.6613 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6874/2499940 | global iter:   3438/1249970 | loss: 1.9197 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   6876/2499940 | global iter:   3439/1249970 | loss: 1.4624 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6878/2499940 | global iter:   3440/1249970 | loss: 1.3090 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6878/2499940 | global iter:   3440/1249970 | loss: 1.1971 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6880/2499940 | global iter:   3441/1249970 | loss: 0.7553 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6882/2499940 | global iter:   3442/1249970 | loss: 1.0052 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   6884/2499940 | global iter:   3443/1249970 | loss: 1.4586 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6886/2499940 | global iter:   3444/1249970 | loss: 1.4743 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6886/2499940 | global iter:   3444/1249970 | loss: 1.1346 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6888/2499940 | global iter:   3445/1249970 | loss: 0.3501 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6890/2499940 | global iter:   3446/1249970 | loss: 0.7938 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   6892/2499940 | global iter:   3447/1249970 | loss: 1.1595 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6894/2499940 | global iter:   3448/1249970 | loss: 1.3360 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6894/2499940 | global iter:   3448/1249970 | loss: 0.9477 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6896/2499940 | global iter:   3449/1249970 | loss: 0.2962 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6898/2499940 | global iter:   3450/1249970 | loss: 1.5056 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6900/2499940 | global iter:   3451/1249970 | loss: 0.6412 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6902/2499940 | global iter:   3452/1249970 | loss: 1.0333 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6902/2499940 | global iter:   3452/1249970 | loss: 1.1199 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6904/2499940 | global iter:   3453/1249970 | loss: 1.6555 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6906/2499940 | global iter:   3454/1249970 | loss: 0.0542 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6908/2499940 | global iter:   3455/1249970 | loss: 1.7153 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6910/2499940 | global iter:   3456/1249970 | loss: 1.0968 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6910/2499940 | global iter:   3456/1249970 | loss: 0.9092 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6912/2499940 | global iter:   3457/1249970 | loss: 1.6403 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   6914/2499940 | global iter:   3458/1249970 | loss: 1.6874 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6916/2499940 | global iter:   3459/1249970 | loss: 1.1013 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6918/2499940 | global iter:   3460/1249970 | loss: 0.6528 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6918/2499940 | global iter:   3460/1249970 | loss: 1.2456 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6920/2499940 | global iter:   3461/1249970 | loss: 0.0530 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6922/2499940 | global iter:   3462/1249970 | loss: 1.4589 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6924/2499940 | global iter:   3463/1249970 | loss: 0.1272 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6926/2499940 | global iter:   3464/1249970 | loss: 0.8074 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6926/2499940 | global iter:   3464/1249970 | loss: 0.9109 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6928/2499940 | global iter:   3465/1249970 | loss: 0.8360 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6930/2499940 | global iter:   3466/1249970 | loss: 0.8133 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   6932/2499940 | global iter:   3467/1249970 | loss: 0.9663 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6934/2499940 | global iter:   3468/1249970 | loss: 2.0256 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6934/2499940 | global iter:   3468/1249970 | loss: 1.0625 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6936/2499940 | global iter:   3469/1249970 | loss: 1.2480 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6938/2499940 | global iter:   3470/1249970 | loss: 0.6914 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   6940/2499940 | global iter:   3471/1249970 | loss: 1.3371 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6942/2499940 | global iter:   3472/1249970 | loss: 1.9325 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6942/2499940 | global iter:   3472/1249970 | loss: 1.2711 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6944/2499940 | global iter:   3473/1249970 | loss: 1.8511 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6946/2499940 | global iter:   3474/1249970 | loss: 0.4774 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6948/2499940 | global iter:   3475/1249970 | loss: 1.5229 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6950/2499940 | global iter:   3476/1249970 | loss: 1.2111 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6950/2499940 | global iter:   3476/1249970 | loss: 1.2051 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6952/2499940 | global iter:   3477/1249970 | loss: 1.2577 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6954/2499940 | global iter:   3478/1249970 | loss: 2.2065 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   6956/2499940 | global iter:   3479/1249970 | loss: 1.1513 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6958/2499940 | global iter:   3480/1249970 | loss: 1.4968 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6958/2499940 | global iter:   3480/1249970 | loss: 1.3312 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6960/2499940 | global iter:   3481/1249970 | loss: 0.8515 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6962/2499940 | global iter:   3482/1249970 | loss: 0.6890 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6964/2499940 | global iter:   3483/1249970 | loss: 0.1032 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   6966/2499940 | global iter:   3484/1249970 | loss: 0.5861 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6966/2499940 | global iter:   3484/1249970 | loss: 1.0547 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6968/2499940 | global iter:   3485/1249970 | loss: 1.1149 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6970/2499940 | global iter:   3486/1249970 | loss: 1.1556 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   6972/2499940 | global iter:   3487/1249970 | loss: 1.1035 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6974/2499940 | global iter:   3488/1249970 | loss: 1.0447 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6974/2499940 | global iter:   3488/1249970 | loss: 0.8841 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6976/2499940 | global iter:   3489/1249970 | loss: 1.9498 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   6978/2499940 | global iter:   3490/1249970 | loss: 1.4770 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   6980/2499940 | global iter:   3491/1249970 | loss: 0.2957 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6982/2499940 | global iter:   3492/1249970 | loss: 0.8599 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6982/2499940 | global iter:   3492/1249970 | loss: 1.1240 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6984/2499940 | global iter:   3493/1249970 | loss: 0.5435 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6986/2499940 | global iter:   3494/1249970 | loss: 1.4674 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   6988/2499940 | global iter:   3495/1249970 | loss: 0.7208 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6990/2499940 | global iter:   3496/1249970 | loss: 1.9787 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6990/2499940 | global iter:   3496/1249970 | loss: 1.1983 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   6992/2499940 | global iter:   3497/1249970 | loss: 1.1573 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   6994/2499940 | global iter:   3498/1249970 | loss: 1.0649 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   6996/2499940 | global iter:   3499/1249970 | loss: 0.7144 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   6998/2499940 | global iter:   3500/1249970 | loss: 1.1611 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6998/2499940 | global iter:   3500/1249970 | loss: 0.9340 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7000/2499940 | global iter:   3501/1249970 | loss: 0.9989 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7002/2499940 | global iter:   3502/1249970 | loss: 1.8384 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7004/2499940 | global iter:   3503/1249970 | loss: 0.3788 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7006/2499940 | global iter:   3504/1249970 | loss: 1.6969 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7006/2499940 | global iter:   3504/1249970 | loss: 1.1804 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7008/2499940 | global iter:   3505/1249970 | loss: 1.1404 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7010/2499940 | global iter:   3506/1249970 | loss: 1.4636 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7012/2499940 | global iter:   3507/1249970 | loss: 0.8017 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7014/2499940 | global iter:   3508/1249970 | loss: 1.4888 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7014/2499940 | global iter:   3508/1249970 | loss: 1.3744 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7016/2499940 | global iter:   3509/1249970 | loss: 1.1972 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7018/2499940 | global iter:   3510/1249970 | loss: 1.2475 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   7020/2499940 | global iter:   3511/1249970 | loss: 0.8898 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7022/2499940 | global iter:   3512/1249970 | loss: 0.9746 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7022/2499940 | global iter:   3512/1249970 | loss: 0.9071 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7024/2499940 | global iter:   3513/1249970 | loss: 1.6844 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7026/2499940 | global iter:   3514/1249970 | loss: 0.2993 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   7028/2499940 | global iter:   3515/1249970 | loss: 0.7189 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.405 | step time: 0.000
train | epoch   0 | Iter:   7030/2499940 | global iter:   3516/1249970 | loss: 0.6388 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7030/2499940 | global iter:   3516/1249970 | loss: 0.9896 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7032/2499940 | global iter:   3517/1249970 | loss: 0.7636 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7034/2499940 | global iter:   3518/1249970 | loss: 0.9942 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7036/2499940 | global iter:   3519/1249970 | loss: 1.3221 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7038/2499940 | global iter:   3520/1249970 | loss: 1.2946 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7038/2499940 | global iter:   3520/1249970 | loss: 1.0828 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7040/2499940 | global iter:   3521/1249970 | loss: 1.0509 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7042/2499940 | global iter:   3522/1249970 | loss: 1.6609 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7044/2499940 | global iter:   3523/1249970 | loss: 1.5230 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7046/2499940 | global iter:   3524/1249970 | loss: 0.9555 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7046/2499940 | global iter:   3524/1249970 | loss: 1.0309 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7048/2499940 | global iter:   3525/1249970 | loss: 1.1011 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7050/2499940 | global iter:   3526/1249970 | loss: 1.3619 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   7052/2499940 | global iter:   3527/1249970 | loss: 1.7453 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7054/2499940 | global iter:   3528/1249970 | loss: 1.2807 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7054/2499940 | global iter:   3528/1249970 | loss: 1.2521 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7056/2499940 | global iter:   3529/1249970 | loss: 0.2834 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7058/2499940 | global iter:   3530/1249970 | loss: 1.1094 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   7060/2499940 | global iter:   3531/1249970 | loss: 0.1049 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7062/2499940 | global iter:   3532/1249970 | loss: 0.8714 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7062/2499940 | global iter:   3532/1249970 | loss: 1.0461 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7064/2499940 | global iter:   3533/1249970 | loss: 0.6715 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7066/2499940 | global iter:   3534/1249970 | loss: 1.0284 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7068/2499940 | global iter:   3535/1249970 | loss: 0.7149 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   7070/2499940 | global iter:   3536/1249970 | loss: 1.4069 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7070/2499940 | global iter:   3536/1249970 | loss: 1.0407 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7072/2499940 | global iter:   3537/1249970 | loss: 1.6211 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7074/2499940 | global iter:   3538/1249970 | loss: 1.1810 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   7076/2499940 | global iter:   3539/1249970 | loss: 1.7524 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7078/2499940 | global iter:   3540/1249970 | loss: 0.6604 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7078/2499940 | global iter:   3540/1249970 | loss: 1.1793 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7080/2499940 | global iter:   3541/1249970 | loss: 0.6959 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7082/2499940 | global iter:   3542/1249970 | loss: 1.1318 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7084/2499940 | global iter:   3543/1249970 | loss: 1.8592 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7086/2499940 | global iter:   3544/1249970 | loss: 1.2724 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7086/2499940 | global iter:   3544/1249970 | loss: 1.2642 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7088/2499940 | global iter:   3545/1249970 | loss: 1.4392 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7090/2499940 | global iter:   3546/1249970 | loss: 1.0471 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   7092/2499940 | global iter:   3547/1249970 | loss: 1.3092 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7094/2499940 | global iter:   3548/1249970 | loss: 1.0008 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7094/2499940 | global iter:   3548/1249970 | loss: 1.1595 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7096/2499940 | global iter:   3549/1249970 | loss: 1.0708 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7098/2499940 | global iter:   3550/1249970 | loss: 0.2689 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7100/2499940 | global iter:   3551/1249970 | loss: 1.8099 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7102/2499940 | global iter:   3552/1249970 | loss: 1.4706 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7102/2499940 | global iter:   3552/1249970 | loss: 1.1577 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7104/2499940 | global iter:   3553/1249970 | loss: 1.5639 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7106/2499940 | global iter:   3554/1249970 | loss: 0.3904 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7108/2499940 | global iter:   3555/1249970 | loss: 1.3332 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7110/2499940 | global iter:   3556/1249970 | loss: 1.0030 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7110/2499940 | global iter:   3556/1249970 | loss: 1.0440 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7112/2499940 | global iter:   3557/1249970 | loss: 0.4210 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7114/2499940 | global iter:   3558/1249970 | loss: 0.8549 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7116/2499940 | global iter:   3559/1249970 | loss: 0.7094 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   7118/2499940 | global iter:   3560/1249970 | loss: 0.3137 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7118/2499940 | global iter:   3560/1249970 | loss: 0.9559 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7120/2499940 | global iter:   3561/1249970 | loss: 1.3749 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7122/2499940 | global iter:   3562/1249970 | loss: 0.7062 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7124/2499940 | global iter:   3563/1249970 | loss: 0.6950 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7126/2499940 | global iter:   3564/1249970 | loss: 1.4827 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7126/2499940 | global iter:   3564/1249970 | loss: 1.1366 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7128/2499940 | global iter:   3565/1249970 | loss: 0.1146 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7130/2499940 | global iter:   3566/1249970 | loss: 1.5907 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7132/2499940 | global iter:   3567/1249970 | loss: 1.5369 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7134/2499940 | global iter:   3568/1249970 | loss: 1.6455 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7134/2499940 | global iter:   3568/1249970 | loss: 1.0832 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7136/2499940 | global iter:   3569/1249970 | loss: 0.2022 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7138/2499940 | global iter:   3570/1249970 | loss: 1.2950 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7140/2499940 | global iter:   3571/1249970 | loss: 1.2502 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7142/2499940 | global iter:   3572/1249970 | loss: 1.6332 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7142/2499940 | global iter:   3572/1249970 | loss: 0.9910 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7144/2499940 | global iter:   3573/1249970 | loss: 1.6517 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7146/2499940 | global iter:   3574/1249970 | loss: 0.1251 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   7148/2499940 | global iter:   3575/1249970 | loss: 0.2987 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7150/2499940 | global iter:   3576/1249970 | loss: 0.7287 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7150/2499940 | global iter:   3576/1249970 | loss: 1.0017 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7152/2499940 | global iter:   3577/1249970 | loss: 1.5512 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7154/2499940 | global iter:   3578/1249970 | loss: 0.6250 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7156/2499940 | global iter:   3579/1249970 | loss: 1.3334 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7158/2499940 | global iter:   3580/1249970 | loss: 1.0489 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7158/2499940 | global iter:   3580/1249970 | loss: 1.1839 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7160/2499940 | global iter:   3581/1249970 | loss: 1.3733 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7162/2499940 | global iter:   3582/1249970 | loss: 0.6311 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7164/2499940 | global iter:   3583/1249970 | loss: 1.7225 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7166/2499940 | global iter:   3584/1249970 | loss: 1.6753 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7166/2499940 | global iter:   3584/1249970 | loss: 1.3599 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7168/2499940 | global iter:   3585/1249970 | loss: 0.6485 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7170/2499940 | global iter:   3586/1249970 | loss: 1.4793 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7172/2499940 | global iter:   3587/1249970 | loss: 0.8048 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7174/2499940 | global iter:   3588/1249970 | loss: 0.1791 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7174/2499940 | global iter:   3588/1249970 | loss: 0.8906 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7176/2499940 | global iter:   3589/1249970 | loss: 0.8655 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7178/2499940 | global iter:   3590/1249970 | loss: 0.9242 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7180/2499940 | global iter:   3591/1249970 | loss: 0.7434 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7182/2499940 | global iter:   3592/1249970 | loss: 1.1033 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7182/2499940 | global iter:   3592/1249970 | loss: 0.9599 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7184/2499940 | global iter:   3593/1249970 | loss: 0.7509 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7186/2499940 | global iter:   3594/1249970 | loss: 0.1889 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7188/2499940 | global iter:   3595/1249970 | loss: 1.1663 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7190/2499940 | global iter:   3596/1249970 | loss: 0.7765 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7190/2499940 | global iter:   3596/1249970 | loss: 0.7999 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7192/2499940 | global iter:   3597/1249970 | loss: 0.7542 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7194/2499940 | global iter:   3598/1249970 | loss: 0.6501 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   7196/2499940 | global iter:   3599/1249970 | loss: 1.0392 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7198/2499940 | global iter:   3600/1249970 | loss: 1.4640 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7198/2499940 | global iter:   3600/1249970 | loss: 0.9551 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7200/2499940 | global iter:   3601/1249970 | loss: 0.8109 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7202/2499940 | global iter:   3602/1249970 | loss: 0.8863 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7204/2499940 | global iter:   3603/1249970 | loss: 1.2191 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7206/2499940 | global iter:   3604/1249970 | loss: 1.3459 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7206/2499940 | global iter:   3604/1249970 | loss: 0.9311 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7208/2499940 | global iter:   3605/1249970 | loss: 0.8132 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7210/2499940 | global iter:   3606/1249970 | loss: 2.1164 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   7212/2499940 | global iter:   3607/1249970 | loss: 1.6446 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7214/2499940 | global iter:   3608/1249970 | loss: 1.6208 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7214/2499940 | global iter:   3608/1249970 | loss: 1.1600 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7216/2499940 | global iter:   3609/1249970 | loss: 0.9832 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7218/2499940 | global iter:   3610/1249970 | loss: 1.0756 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7220/2499940 | global iter:   3611/1249970 | loss: 1.3925 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7222/2499940 | global iter:   3612/1249970 | loss: 0.9491 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7222/2499940 | global iter:   3612/1249970 | loss: 1.0635 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7224/2499940 | global iter:   3613/1249970 | loss: 1.2311 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7226/2499940 | global iter:   3614/1249970 | loss: 1.4056 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:   7228/2499940 | global iter:   3615/1249970 | loss: 1.1140 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7230/2499940 | global iter:   3616/1249970 | loss: 1.2533 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7230/2499940 | global iter:   3616/1249970 | loss: 1.2997 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7232/2499940 | global iter:   3617/1249970 | loss: 0.8049 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7234/2499940 | global iter:   3618/1249970 | loss: 0.7062 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   7236/2499940 | global iter:   3619/1249970 | loss: 1.2963 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7238/2499940 | global iter:   3620/1249970 | loss: 0.8089 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7238/2499940 | global iter:   3620/1249970 | loss: 1.0008 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7240/2499940 | global iter:   3621/1249970 | loss: 0.8881 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7242/2499940 | global iter:   3622/1249970 | loss: 0.8832 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   7244/2499940 | global iter:   3623/1249970 | loss: 1.3370 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7246/2499940 | global iter:   3624/1249970 | loss: 1.1356 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7246/2499940 | global iter:   3624/1249970 | loss: 1.0456 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7248/2499940 | global iter:   3625/1249970 | loss: 0.8201 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7250/2499940 | global iter:   3626/1249970 | loss: 1.0109 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7252/2499940 | global iter:   3627/1249970 | loss: 1.1744 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7254/2499940 | global iter:   3628/1249970 | loss: 0.8235 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7254/2499940 | global iter:   3628/1249970 | loss: 0.9752 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7256/2499940 | global iter:   3629/1249970 | loss: 0.6620 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7258/2499940 | global iter:   3630/1249970 | loss: 1.1937 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7260/2499940 | global iter:   3631/1249970 | loss: 1.1648 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7262/2499940 | global iter:   3632/1249970 | loss: 1.6102 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7262/2499940 | global iter:   3632/1249970 | loss: 0.9531 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7264/2499940 | global iter:   3633/1249970 | loss: 2.1188 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7266/2499940 | global iter:   3634/1249970 | loss: 0.5930 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7268/2499940 | global iter:   3635/1249970 | loss: 1.3868 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7270/2499940 | global iter:   3636/1249970 | loss: 1.1292 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7270/2499940 | global iter:   3636/1249970 | loss: 1.2943 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7272/2499940 | global iter:   3637/1249970 | loss: 1.4408 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7274/2499940 | global iter:   3638/1249970 | loss: 0.6301 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7276/2499940 | global iter:   3639/1249970 | loss: 0.9659 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7278/2499940 | global iter:   3640/1249970 | loss: 0.6837 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7278/2499940 | global iter:   3640/1249970 | loss: 0.9652 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7280/2499940 | global iter:   3641/1249970 | loss: 1.0293 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7282/2499940 | global iter:   3642/1249970 | loss: 1.8592 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7284/2499940 | global iter:   3643/1249970 | loss: 1.2009 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7286/2499940 | global iter:   3644/1249970 | loss: 1.4305 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7286/2499940 | global iter:   3644/1249970 | loss: 1.3975 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7288/2499940 | global iter:   3645/1249970 | loss: 0.2457 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.407 | step time: 0.000
train | epoch   0 | Iter:   7290/2499940 | global iter:   3646/1249970 | loss: 1.8577 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7292/2499940 | global iter:   3647/1249970 | loss: 1.0404 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7294/2499940 | global iter:   3648/1249970 | loss: 1.0116 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7294/2499940 | global iter:   3648/1249970 | loss: 0.9742 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7296/2499940 | global iter:   3649/1249970 | loss: 0.4768 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7298/2499940 | global iter:   3650/1249970 | loss: 1.2450 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7300/2499940 | global iter:   3651/1249970 | loss: 0.7968 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:   7302/2499940 | global iter:   3652/1249970 | loss: 1.3135 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7302/2499940 | global iter:   3652/1249970 | loss: 1.0830 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7304/2499940 | global iter:   3653/1249970 | loss: 1.3638 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7306/2499940 | global iter:   3654/1249970 | loss: 1.2202 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   7308/2499940 | global iter:   3655/1249970 | loss: 1.3756 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7310/2499940 | global iter:   3656/1249970 | loss: 0.9533 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7310/2499940 | global iter:   3656/1249970 | loss: 1.0536 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7312/2499940 | global iter:   3657/1249970 | loss: 1.4518 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7314/2499940 | global iter:   3658/1249970 | loss: 1.7645 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7316/2499940 | global iter:   3659/1249970 | loss: 0.7347 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7318/2499940 | global iter:   3660/1249970 | loss: 0.3810 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7318/2499940 | global iter:   3660/1249970 | loss: 1.0992 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7320/2499940 | global iter:   3661/1249970 | loss: 0.8569 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7322/2499940 | global iter:   3662/1249970 | loss: 0.8675 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7324/2499940 | global iter:   3663/1249970 | loss: 1.0463 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7326/2499940 | global iter:   3664/1249970 | loss: 1.5430 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7326/2499940 | global iter:   3664/1249970 | loss: 1.3328 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7328/2499940 | global iter:   3665/1249970 | loss: 1.0047 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7330/2499940 | global iter:   3666/1249970 | loss: 1.0811 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   7332/2499940 | global iter:   3667/1249970 | loss: 1.0478 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7334/2499940 | global iter:   3668/1249970 | loss: 1.5817 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7334/2499940 | global iter:   3668/1249970 | loss: 1.3117 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7336/2499940 | global iter:   3669/1249970 | loss: 0.7085 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7338/2499940 | global iter:   3670/1249970 | loss: 1.6663 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   7340/2499940 | global iter:   3671/1249970 | loss: 0.7020 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7342/2499940 | global iter:   3672/1249970 | loss: 1.2258 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7342/2499940 | global iter:   3672/1249970 | loss: 1.1050 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7344/2499940 | global iter:   3673/1249970 | loss: 1.2266 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7346/2499940 | global iter:   3674/1249970 | loss: 1.1932 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   7348/2499940 | global iter:   3675/1249970 | loss: 0.9121 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7350/2499940 | global iter:   3676/1249970 | loss: 1.6937 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7350/2499940 | global iter:   3676/1249970 | loss: 1.0152 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7352/2499940 | global iter:   3677/1249970 | loss: 1.7482 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7354/2499940 | global iter:   3678/1249970 | loss: 1.5738 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7356/2499940 | global iter:   3679/1249970 | loss: 1.2775 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7358/2499940 | global iter:   3680/1249970 | loss: 0.8387 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7358/2499940 | global iter:   3680/1249970 | loss: 1.3169 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7360/2499940 | global iter:   3681/1249970 | loss: 1.0442 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7362/2499940 | global iter:   3682/1249970 | loss: 1.5347 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7364/2499940 | global iter:   3683/1249970 | loss: 1.9610 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7366/2499940 | global iter:   3684/1249970 | loss: 0.4508 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7366/2499940 | global iter:   3684/1249970 | loss: 1.1939 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7368/2499940 | global iter:   3685/1249970 | loss: 1.4368 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7370/2499940 | global iter:   3686/1249970 | loss: 1.5796 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   7372/2499940 | global iter:   3687/1249970 | loss: 1.0569 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7374/2499940 | global iter:   3688/1249970 | loss: 1.1981 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7374/2499940 | global iter:   3688/1249970 | loss: 1.2407 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7376/2499940 | global iter:   3689/1249970 | loss: 0.5239 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.404 | step time: 0.000
train | epoch   0 | Iter:   7378/2499940 | global iter:   3690/1249970 | loss: 1.7923 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7380/2499940 | global iter:   3691/1249970 | loss: 1.5434 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7382/2499940 | global iter:   3692/1249970 | loss: 1.2265 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7382/2499940 | global iter:   3692/1249970 | loss: 1.2489 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7384/2499940 | global iter:   3693/1249970 | loss: 1.0926 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7386/2499940 | global iter:   3694/1249970 | loss: 0.2643 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   7388/2499940 | global iter:   3695/1249970 | loss: 0.8662 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7390/2499940 | global iter:   3696/1249970 | loss: 1.3225 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7390/2499940 | global iter:   3696/1249970 | loss: 1.0933 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7392/2499940 | global iter:   3697/1249970 | loss: 1.2039 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7394/2499940 | global iter:   3698/1249970 | loss: 1.6073 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7396/2499940 | global iter:   3699/1249970 | loss: 0.9841 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7398/2499940 | global iter:   3700/1249970 | loss: 0.9709 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7398/2499940 | global iter:   3700/1249970 | loss: 1.1937 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7400/2499940 | global iter:   3701/1249970 | loss: 1.0130 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7402/2499940 | global iter:   3702/1249970 | loss: 1.5634 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7404/2499940 | global iter:   3703/1249970 | loss: 0.2476 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7406/2499940 | global iter:   3704/1249970 | loss: 0.8401 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7406/2499940 | global iter:   3704/1249970 | loss: 1.1695 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7408/2499940 | global iter:   3705/1249970 | loss: 1.1013 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7410/2499940 | global iter:   3706/1249970 | loss: 1.3133 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   7412/2499940 | global iter:   3707/1249970 | loss: 1.1285 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7414/2499940 | global iter:   3708/1249970 | loss: 1.4231 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7414/2499940 | global iter:   3708/1249970 | loss: 1.1861 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7416/2499940 | global iter:   3709/1249970 | loss: 1.6133 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7418/2499940 | global iter:   3710/1249970 | loss: 0.8559 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7420/2499940 | global iter:   3711/1249970 | loss: 1.4280 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7422/2499940 | global iter:   3712/1249970 | loss: 0.8643 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7422/2499940 | global iter:   3712/1249970 | loss: 0.9475 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7424/2499940 | global iter:   3713/1249970 | loss: 0.7744 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7426/2499940 | global iter:   3714/1249970 | loss: 1.3549 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7428/2499940 | global iter:   3715/1249970 | loss: 1.5844 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7430/2499940 | global iter:   3716/1249970 | loss: 1.0064 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7430/2499940 | global iter:   3716/1249970 | loss: 1.2740 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7432/2499940 | global iter:   3717/1249970 | loss: 1.5420 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7434/2499940 | global iter:   3718/1249970 | loss: 0.7918 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7436/2499940 | global iter:   3719/1249970 | loss: 1.1145 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7438/2499940 | global iter:   3720/1249970 | loss: 1.0434 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7438/2499940 | global iter:   3720/1249970 | loss: 1.0362 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7440/2499940 | global iter:   3721/1249970 | loss: 1.3390 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7442/2499940 | global iter:   3722/1249970 | loss: 0.7491 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7444/2499940 | global iter:   3723/1249970 | loss: 1.6738 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7446/2499940 | global iter:   3724/1249970 | loss: 1.2528 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7446/2499940 | global iter:   3724/1249970 | loss: 1.1782 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7448/2499940 | global iter:   3725/1249970 | loss: 2.2265 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7450/2499940 | global iter:   3726/1249970 | loss: 1.1185 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7452/2499940 | global iter:   3727/1249970 | loss: 2.2367 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7454/2499940 | global iter:   3728/1249970 | loss: 0.7767 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7454/2499940 | global iter:   3728/1249970 | loss: 1.6090 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7456/2499940 | global iter:   3729/1249970 | loss: 0.3761 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7458/2499940 | global iter:   3730/1249970 | loss: 1.2731 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7460/2499940 | global iter:   3731/1249970 | loss: 1.0346 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7462/2499940 | global iter:   3732/1249970 | loss: 0.7966 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7462/2499940 | global iter:   3732/1249970 | loss: 1.0622 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7464/2499940 | global iter:   3733/1249970 | loss: 0.9389 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7466/2499940 | global iter:   3734/1249970 | loss: 1.5924 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7468/2499940 | global iter:   3735/1249970 | loss: 1.1963 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7470/2499940 | global iter:   3736/1249970 | loss: 0.4804 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7470/2499940 | global iter:   3736/1249970 | loss: 1.1481 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7472/2499940 | global iter:   3737/1249970 | loss: 1.4783 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7474/2499940 | global iter:   3738/1249970 | loss: 1.4649 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7476/2499940 | global iter:   3739/1249970 | loss: 1.4750 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7478/2499940 | global iter:   3740/1249970 | loss: 0.5165 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7478/2499940 | global iter:   3740/1249970 | loss: 1.1519 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7480/2499940 | global iter:   3741/1249970 | loss: 1.6706 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7482/2499940 | global iter:   3742/1249970 | loss: 0.9761 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7484/2499940 | global iter:   3743/1249970 | loss: 0.9811 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7486/2499940 | global iter:   3744/1249970 | loss: 0.9599 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7486/2499940 | global iter:   3744/1249970 | loss: 0.9348 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7488/2499940 | global iter:   3745/1249970 | loss: 0.7095 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7490/2499940 | global iter:   3746/1249970 | loss: 0.9810 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7492/2499940 | global iter:   3747/1249970 | loss: 0.9822 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7494/2499940 | global iter:   3748/1249970 | loss: 0.5179 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7494/2499940 | global iter:   3748/1249970 | loss: 1.1125 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7496/2499940 | global iter:   3749/1249970 | loss: 1.8010 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7498/2499940 | global iter:   3750/1249970 | loss: 1.0357 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7500/2499940 | global iter:   3751/1249970 | loss: 1.1680 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7502/2499940 | global iter:   3752/1249970 | loss: 1.5482 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7502/2499940 | global iter:   3752/1249970 | loss: 1.3466 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7504/2499940 | global iter:   3753/1249970 | loss: 1.0413 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7506/2499940 | global iter:   3754/1249970 | loss: 1.1150 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7508/2499940 | global iter:   3755/1249970 | loss: 1.0362 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7510/2499940 | global iter:   3756/1249970 | loss: 1.0375 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7510/2499940 | global iter:   3756/1249970 | loss: 1.0949 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7512/2499940 | global iter:   3757/1249970 | loss: 1.4932 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7514/2499940 | global iter:   3758/1249970 | loss: 1.2046 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7516/2499940 | global iter:   3759/1249970 | loss: 0.8461 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7518/2499940 | global iter:   3760/1249970 | loss: 1.7156 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7518/2499940 | global iter:   3760/1249970 | loss: 1.1474 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7520/2499940 | global iter:   3761/1249970 | loss: 0.9058 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7522/2499940 | global iter:   3762/1249970 | loss: 1.0461 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7524/2499940 | global iter:   3763/1249970 | loss: 0.6538 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7526/2499940 | global iter:   3764/1249970 | loss: 0.5875 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7526/2499940 | global iter:   3764/1249970 | loss: 0.9745 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7528/2499940 | global iter:   3765/1249970 | loss: 0.5300 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7530/2499940 | global iter:   3766/1249970 | loss: 0.9384 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7532/2499940 | global iter:   3767/1249970 | loss: 0.7093 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7534/2499940 | global iter:   3768/1249970 | loss: 0.7377 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7534/2499940 | global iter:   3768/1249970 | loss: 0.8783 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7536/2499940 | global iter:   3769/1249970 | loss: 1.5171 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7538/2499940 | global iter:   3770/1249970 | loss: 1.6699 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7540/2499940 | global iter:   3771/1249970 | loss: 1.5313 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7542/2499940 | global iter:   3772/1249970 | loss: 1.4379 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.392 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7542/2499940 | global iter:   3772/1249970 | loss: 1.3646 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.392 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7544/2499940 | global iter:   3773/1249970 | loss: 1.0271 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7546/2499940 | global iter:   3774/1249970 | loss: 1.3450 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7548/2499940 | global iter:   3775/1249970 | loss: 1.2978 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.407 | step time: 0.000
train | epoch   0 | Iter:   7550/2499940 | global iter:   3776/1249970 | loss: 0.5534 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7550/2499940 | global iter:   3776/1249970 | loss: 0.9025 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7552/2499940 | global iter:   3777/1249970 | loss: 1.5592 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7554/2499940 | global iter:   3778/1249970 | loss: 1.5356 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   7556/2499940 | global iter:   3779/1249970 | loss: 1.3293 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7558/2499940 | global iter:   3780/1249970 | loss: 1.2429 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7558/2499940 | global iter:   3780/1249970 | loss: 1.4741 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7560/2499940 | global iter:   3781/1249970 | loss: 1.0549 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7562/2499940 | global iter:   3782/1249970 | loss: 1.7198 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7564/2499940 | global iter:   3783/1249970 | loss: 0.8190 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7566/2499940 | global iter:   3784/1249970 | loss: 0.9688 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7566/2499940 | global iter:   3784/1249970 | loss: 1.1871 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7568/2499940 | global iter:   3785/1249970 | loss: 1.1476 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7570/2499940 | global iter:   3786/1249970 | loss: 0.9507 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7572/2499940 | global iter:   3787/1249970 | loss: 0.6759 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7574/2499940 | global iter:   3788/1249970 | loss: 1.0420 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7574/2499940 | global iter:   3788/1249970 | loss: 1.0533 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7576/2499940 | global iter:   3789/1249970 | loss: 1.2897 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7578/2499940 | global iter:   3790/1249970 | loss: 1.0889 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7580/2499940 | global iter:   3791/1249970 | loss: 1.4204 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7582/2499940 | global iter:   3792/1249970 | loss: 1.6777 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7582/2499940 | global iter:   3792/1249970 | loss: 1.1853 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7584/2499940 | global iter:   3793/1249970 | loss: 1.0311 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7586/2499940 | global iter:   3794/1249970 | loss: 0.6763 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7588/2499940 | global iter:   3795/1249970 | loss: 0.5693 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7590/2499940 | global iter:   3796/1249970 | loss: 1.3522 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7590/2499940 | global iter:   3796/1249970 | loss: 1.0216 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7592/2499940 | global iter:   3797/1249970 | loss: 0.9329 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7594/2499940 | global iter:   3798/1249970 | loss: 0.8632 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7596/2499940 | global iter:   3799/1249970 | loss: 0.7075 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7598/2499940 | global iter:   3800/1249970 | loss: 0.6957 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7598/2499940 | global iter:   3800/1249970 | loss: 0.8609 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7600/2499940 | global iter:   3801/1249970 | loss: 1.1922 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7602/2499940 | global iter:   3802/1249970 | loss: 0.8480 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7604/2499940 | global iter:   3803/1249970 | loss: 1.5991 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7606/2499940 | global iter:   3804/1249970 | loss: 0.8027 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7606/2499940 | global iter:   3804/1249970 | loss: 1.3919 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7608/2499940 | global iter:   3805/1249970 | loss: 0.9384 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7610/2499940 | global iter:   3806/1249970 | loss: 0.1215 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7612/2499940 | global iter:   3807/1249970 | loss: 0.7663 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7614/2499940 | global iter:   3808/1249970 | loss: 1.4777 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7614/2499940 | global iter:   3808/1249970 | loss: 1.0294 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7616/2499940 | global iter:   3809/1249970 | loss: 1.1300 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7618/2499940 | global iter:   3810/1249970 | loss: 1.1576 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7620/2499940 | global iter:   3811/1249970 | loss: 1.0597 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7622/2499940 | global iter:   3812/1249970 | loss: 1.4567 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7622/2499940 | global iter:   3812/1249970 | loss: 1.2449 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7624/2499940 | global iter:   3813/1249970 | loss: 0.9912 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7626/2499940 | global iter:   3814/1249970 | loss: 1.0365 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7628/2499940 | global iter:   3815/1249970 | loss: 0.7494 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7630/2499940 | global iter:   3816/1249970 | loss: 1.5979 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7630/2499940 | global iter:   3816/1249970 | loss: 1.1061 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7632/2499940 | global iter:   3817/1249970 | loss: 0.5799 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7634/2499940 | global iter:   3818/1249970 | loss: 0.8550 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7636/2499940 | global iter:   3819/1249970 | loss: 1.2662 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7638/2499940 | global iter:   3820/1249970 | loss: 1.3830 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7638/2499940 | global iter:   3820/1249970 | loss: 0.9100 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7640/2499940 | global iter:   3821/1249970 | loss: 1.2924 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7642/2499940 | global iter:   3822/1249970 | loss: 1.5957 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7644/2499940 | global iter:   3823/1249970 | loss: 0.9913 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7646/2499940 | global iter:   3824/1249970 | loss: 1.5745 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7646/2499940 | global iter:   3824/1249970 | loss: 1.3418 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7648/2499940 | global iter:   3825/1249970 | loss: 1.5199 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7650/2499940 | global iter:   3826/1249970 | loss: 1.5028 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   7652/2499940 | global iter:   3827/1249970 | loss: 1.5970 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7654/2499940 | global iter:   3828/1249970 | loss: 1.2591 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7654/2499940 | global iter:   3828/1249970 | loss: 1.4710 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7656/2499940 | global iter:   3829/1249970 | loss: 1.1297 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7658/2499940 | global iter:   3830/1249970 | loss: 1.8095 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7660/2499940 | global iter:   3831/1249970 | loss: 1.0250 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7662/2499940 | global iter:   3832/1249970 | loss: 1.3475 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7662/2499940 | global iter:   3832/1249970 | loss: 1.2461 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7664/2499940 | global iter:   3833/1249970 | loss: 1.0559 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7666/2499940 | global iter:   3834/1249970 | loss: 1.4366 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7668/2499940 | global iter:   3835/1249970 | loss: 0.9020 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7670/2499940 | global iter:   3836/1249970 | loss: 1.1682 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7670/2499940 | global iter:   3836/1249970 | loss: 1.0177 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7672/2499940 | global iter:   3837/1249970 | loss: 1.6527 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7674/2499940 | global iter:   3838/1249970 | loss: 1.4064 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7676/2499940 | global iter:   3839/1249970 | loss: 0.9253 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7678/2499940 | global iter:   3840/1249970 | loss: 1.1246 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7678/2499940 | global iter:   3840/1249970 | loss: 1.2535 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7680/2499940 | global iter:   3841/1249970 | loss: 0.8765 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7682/2499940 | global iter:   3842/1249970 | loss: 1.6213 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7684/2499940 | global iter:   3843/1249970 | loss: 1.9463 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7686/2499940 | global iter:   3844/1249970 | loss: 0.9206 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7686/2499940 | global iter:   3844/1249970 | loss: 1.3398 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7688/2499940 | global iter:   3845/1249970 | loss: 0.8717 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7690/2499940 | global iter:   3846/1249970 | loss: 0.4911 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   7692/2499940 | global iter:   3847/1249970 | loss: 0.6988 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7694/2499940 | global iter:   3848/1249970 | loss: 0.9259 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7694/2499940 | global iter:   3848/1249970 | loss: 0.8334 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7696/2499940 | global iter:   3849/1249970 | loss: 0.6909 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7698/2499940 | global iter:   3850/1249970 | loss: 1.7182 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7700/2499940 | global iter:   3851/1249970 | loss: 1.1286 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7702/2499940 | global iter:   3852/1249970 | loss: 0.6466 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7702/2499940 | global iter:   3852/1249970 | loss: 0.9177 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7704/2499940 | global iter:   3853/1249970 | loss: 1.5353 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7706/2499940 | global iter:   3854/1249970 | loss: 1.2952 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7708/2499940 | global iter:   3855/1249970 | loss: 0.9673 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   7710/2499940 | global iter:   3856/1249970 | loss: 0.7497 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7710/2499940 | global iter:   3856/1249970 | loss: 0.9576 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7712/2499940 | global iter:   3857/1249970 | loss: 1.1150 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7714/2499940 | global iter:   3858/1249970 | loss: 1.5195 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.392 | step time: 0.000
train | epoch   0 | Iter:   7716/2499940 | global iter:   3859/1249970 | loss: 0.7364 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7718/2499940 | global iter:   3860/1249970 | loss: 1.5028 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7718/2499940 | global iter:   3860/1249970 | loss: 1.1544 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7720/2499940 | global iter:   3861/1249970 | loss: 0.9527 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7722/2499940 | global iter:   3862/1249970 | loss: 0.9476 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7724/2499940 | global iter:   3863/1249970 | loss: 1.0921 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7726/2499940 | global iter:   3864/1249970 | loss: 1.5779 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7726/2499940 | global iter:   3864/1249970 | loss: 1.1416 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7728/2499940 | global iter:   3865/1249970 | loss: 1.6771 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7730/2499940 | global iter:   3866/1249970 | loss: 1.6096 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7732/2499940 | global iter:   3867/1249970 | loss: 0.7230 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7734/2499940 | global iter:   3868/1249970 | loss: 1.8824 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7734/2499940 | global iter:   3868/1249970 | loss: 1.3066 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7736/2499940 | global iter:   3869/1249970 | loss: 1.0506 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   7738/2499940 | global iter:   3870/1249970 | loss: 0.3293 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7740/2499940 | global iter:   3871/1249970 | loss: 1.1280 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7742/2499940 | global iter:   3872/1249970 | loss: 0.6843 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7742/2499940 | global iter:   3872/1249970 | loss: 0.9973 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7744/2499940 | global iter:   3873/1249970 | loss: 0.7930 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7746/2499940 | global iter:   3874/1249970 | loss: 1.5726 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   7748/2499940 | global iter:   3875/1249970 | loss: 0.9150 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7750/2499940 | global iter:   3876/1249970 | loss: 1.7047 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7750/2499940 | global iter:   3876/1249970 | loss: 1.3964 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7752/2499940 | global iter:   3877/1249970 | loss: 0.8558 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7754/2499940 | global iter:   3878/1249970 | loss: 1.0123 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7756/2499940 | global iter:   3879/1249970 | loss: 0.9235 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7758/2499940 | global iter:   3880/1249970 | loss: 1.1753 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7758/2499940 | global iter:   3880/1249970 | loss: 1.0178 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7760/2499940 | global iter:   3881/1249970 | loss: 1.3405 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7762/2499940 | global iter:   3882/1249970 | loss: 1.1049 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7764/2499940 | global iter:   3883/1249970 | loss: 0.9064 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7766/2499940 | global iter:   3884/1249970 | loss: 1.1121 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7766/2499940 | global iter:   3884/1249970 | loss: 1.0789 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7768/2499940 | global iter:   3885/1249970 | loss: 0.1559 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7770/2499940 | global iter:   3886/1249970 | loss: 0.6894 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7772/2499940 | global iter:   3887/1249970 | loss: 0.4715 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7774/2499940 | global iter:   3888/1249970 | loss: 1.0733 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7774/2499940 | global iter:   3888/1249970 | loss: 0.7588 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7776/2499940 | global iter:   3889/1249970 | loss: 1.0309 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7778/2499940 | global iter:   3890/1249970 | loss: 0.9174 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   7780/2499940 | global iter:   3891/1249970 | loss: 1.4293 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7782/2499940 | global iter:   3892/1249970 | loss: 1.1590 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7782/2499940 | global iter:   3892/1249970 | loss: 1.0770 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7784/2499940 | global iter:   3893/1249970 | loss: 1.0897 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7786/2499940 | global iter:   3894/1249970 | loss: 1.2401 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7788/2499940 | global iter:   3895/1249970 | loss: 1.3768 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7790/2499940 | global iter:   3896/1249970 | loss: 1.1797 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7790/2499940 | global iter:   3896/1249970 | loss: 1.2510 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7792/2499940 | global iter:   3897/1249970 | loss: 0.6369 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7794/2499940 | global iter:   3898/1249970 | loss: 1.1286 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7796/2499940 | global iter:   3899/1249970 | loss: 1.0345 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7798/2499940 | global iter:   3900/1249970 | loss: 1.0660 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7798/2499940 | global iter:   3900/1249970 | loss: 0.7823 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7800/2499940 | global iter:   3901/1249970 | loss: 1.5432 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   7802/2499940 | global iter:   3902/1249970 | loss: 1.0809 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7804/2499940 | global iter:   3903/1249970 | loss: 1.5233 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7806/2499940 | global iter:   3904/1249970 | loss: 1.3178 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7806/2499940 | global iter:   3904/1249970 | loss: 1.4370 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7808/2499940 | global iter:   3905/1249970 | loss: 1.2462 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.406 | step time: 0.000
train | epoch   0 | Iter:   7810/2499940 | global iter:   3906/1249970 | loss: 0.5601 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   7812/2499940 | global iter:   3907/1249970 | loss: 1.6883 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7814/2499940 | global iter:   3908/1249970 | loss: 0.8299 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7814/2499940 | global iter:   3908/1249970 | loss: 0.9627 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7816/2499940 | global iter:   3909/1249970 | loss: 0.4849 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7818/2499940 | global iter:   3910/1249970 | loss: 0.4125 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7820/2499940 | global iter:   3911/1249970 | loss: 0.7122 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7822/2499940 | global iter:   3912/1249970 | loss: 1.3826 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7822/2499940 | global iter:   3912/1249970 | loss: 1.0434 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7824/2499940 | global iter:   3913/1249970 | loss: 1.9186 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7826/2499940 | global iter:   3914/1249970 | loss: 1.6684 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:   7828/2499940 | global iter:   3915/1249970 | loss: 1.6904 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7830/2499940 | global iter:   3916/1249970 | loss: 0.8358 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7830/2499940 | global iter:   3916/1249970 | loss: 1.4745 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7832/2499940 | global iter:   3917/1249970 | loss: 0.8363 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7834/2499940 | global iter:   3918/1249970 | loss: 1.3459 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7836/2499940 | global iter:   3919/1249970 | loss: 1.1916 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7838/2499940 | global iter:   3920/1249970 | loss: 1.5442 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7838/2499940 | global iter:   3920/1249970 | loss: 1.1023 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7840/2499940 | global iter:   3921/1249970 | loss: 2.0000 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7842/2499940 | global iter:   3922/1249970 | loss: 0.4753 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   7844/2499940 | global iter:   3923/1249970 | loss: 0.8770 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7846/2499940 | global iter:   3924/1249970 | loss: 0.5191 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7846/2499940 | global iter:   3924/1249970 | loss: 0.8654 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7848/2499940 | global iter:   3925/1249970 | loss: 1.0109 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7850/2499940 | global iter:   3926/1249970 | loss: 0.9651 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7852/2499940 | global iter:   3927/1249970 | loss: 1.5885 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7854/2499940 | global iter:   3928/1249970 | loss: 1.4934 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7854/2499940 | global iter:   3928/1249970 | loss: 1.1787 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7856/2499940 | global iter:   3929/1249970 | loss: 1.8359 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7858/2499940 | global iter:   3930/1249970 | loss: 1.2526 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   7860/2499940 | global iter:   3931/1249970 | loss: 0.4992 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7862/2499940 | global iter:   3932/1249970 | loss: 1.8588 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7862/2499940 | global iter:   3932/1249970 | loss: 1.2195 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7864/2499940 | global iter:   3933/1249970 | loss: 0.8284 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7866/2499940 | global iter:   3934/1249970 | loss: 1.6218 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7868/2499940 | global iter:   3935/1249970 | loss: 1.2302 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7870/2499940 | global iter:   3936/1249970 | loss: 0.7484 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7870/2499940 | global iter:   3936/1249970 | loss: 1.1092 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7872/2499940 | global iter:   3937/1249970 | loss: 1.1701 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7874/2499940 | global iter:   3938/1249970 | loss: 0.7864 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7876/2499940 | global iter:   3939/1249970 | loss: 1.0365 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7878/2499940 | global iter:   3940/1249970 | loss: 1.7145 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7878/2499940 | global iter:   3940/1249970 | loss: 1.2599 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7880/2499940 | global iter:   3941/1249970 | loss: 1.1755 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7882/2499940 | global iter:   3942/1249970 | loss: 1.1046 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7884/2499940 | global iter:   3943/1249970 | loss: 1.3846 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7886/2499940 | global iter:   3944/1249970 | loss: 0.8361 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7886/2499940 | global iter:   3944/1249970 | loss: 1.1956 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7888/2499940 | global iter:   3945/1249970 | loss: 1.9426 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7890/2499940 | global iter:   3946/1249970 | loss: 1.1873 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7892/2499940 | global iter:   3947/1249970 | loss: 1.6146 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7894/2499940 | global iter:   3948/1249970 | loss: 1.1124 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7894/2499940 | global iter:   3948/1249970 | loss: 1.2023 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7896/2499940 | global iter:   3949/1249970 | loss: 0.9026 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7898/2499940 | global iter:   3950/1249970 | loss: 0.7188 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   7900/2499940 | global iter:   3951/1249970 | loss: 1.2822 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7902/2499940 | global iter:   3952/1249970 | loss: 1.3261 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7902/2499940 | global iter:   3952/1249970 | loss: 1.1204 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7904/2499940 | global iter:   3953/1249970 | loss: 1.1294 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7906/2499940 | global iter:   3954/1249970 | loss: 1.8727 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7908/2499940 | global iter:   3955/1249970 | loss: 1.1414 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7910/2499940 | global iter:   3956/1249970 | loss: 0.9627 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7910/2499940 | global iter:   3956/1249970 | loss: 1.0325 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7912/2499940 | global iter:   3957/1249970 | loss: 1.1429 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7914/2499940 | global iter:   3958/1249970 | loss: 0.8017 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   7916/2499940 | global iter:   3959/1249970 | loss: 1.6162 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7918/2499940 | global iter:   3960/1249970 | loss: 0.6170 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7918/2499940 | global iter:   3960/1249970 | loss: 1.1792 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7920/2499940 | global iter:   3961/1249970 | loss: 0.8197 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7922/2499940 | global iter:   3962/1249970 | loss: 1.6425 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7924/2499940 | global iter:   3963/1249970 | loss: 1.5724 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7926/2499940 | global iter:   3964/1249970 | loss: 1.6082 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7926/2499940 | global iter:   3964/1249970 | loss: 1.2797 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7928/2499940 | global iter:   3965/1249970 | loss: 1.4778 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7930/2499940 | global iter:   3966/1249970 | loss: 0.5719 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7932/2499940 | global iter:   3967/1249970 | loss: 0.7312 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7934/2499940 | global iter:   3968/1249970 | loss: 1.4513 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7934/2499940 | global iter:   3968/1249970 | loss: 1.1395 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7936/2499940 | global iter:   3969/1249970 | loss: 1.5911 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7938/2499940 | global iter:   3970/1249970 | loss: 1.3027 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7940/2499940 | global iter:   3971/1249970 | loss: 0.8314 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7942/2499940 | global iter:   3972/1249970 | loss: 0.6782 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7942/2499940 | global iter:   3972/1249970 | loss: 1.1042 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7944/2499940 | global iter:   3973/1249970 | loss: 1.1872 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7946/2499940 | global iter:   3974/1249970 | loss: 1.6062 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7948/2499940 | global iter:   3975/1249970 | loss: 0.4710 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7950/2499940 | global iter:   3976/1249970 | loss: 2.0755 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7950/2499940 | global iter:   3976/1249970 | loss: 1.1246 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7952/2499940 | global iter:   3977/1249970 | loss: 1.3331 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7954/2499940 | global iter:   3978/1249970 | loss: 1.1932 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7956/2499940 | global iter:   3979/1249970 | loss: 1.4783 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7958/2499940 | global iter:   3980/1249970 | loss: 0.2320 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7958/2499940 | global iter:   3980/1249970 | loss: 1.0847 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7960/2499940 | global iter:   3981/1249970 | loss: 0.6404 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7962/2499940 | global iter:   3982/1249970 | loss: 1.3990 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   7964/2499940 | global iter:   3983/1249970 | loss: 0.3997 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7966/2499940 | global iter:   3984/1249970 | loss: 2.0257 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7966/2499940 | global iter:   3984/1249970 | loss: 0.9384 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7968/2499940 | global iter:   3985/1249970 | loss: 0.7714 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7970/2499940 | global iter:   3986/1249970 | loss: 1.0350 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   7972/2499940 | global iter:   3987/1249970 | loss: 1.0317 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7974/2499940 | global iter:   3988/1249970 | loss: 1.0160 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7974/2499940 | global iter:   3988/1249970 | loss: 1.1099 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7976/2499940 | global iter:   3989/1249970 | loss: 1.1554 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7978/2499940 | global iter:   3990/1249970 | loss: 0.7404 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7980/2499940 | global iter:   3991/1249970 | loss: 0.5710 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7982/2499940 | global iter:   3992/1249970 | loss: 1.3699 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.414 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7982/2499940 | global iter:   3992/1249970 | loss: 1.0592 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.414 | step time: 0.697
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7984/2499940 | global iter:   3993/1249970 | loss: 1.1051 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.404 | step time: 0.000
train | epoch   0 | Iter:   7986/2499940 | global iter:   3994/1249970 | loss: 1.4844 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   7988/2499940 | global iter:   3995/1249970 | loss: 0.6359 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   7990/2499940 | global iter:   3996/1249970 | loss: 1.6159 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7990/2499940 | global iter:   3996/1249970 | loss: 1.0572 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.697
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   7992/2499940 | global iter:   3997/1249970 | loss: 1.9685 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7994/2499940 | global iter:   3998/1249970 | loss: 0.7976 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   7996/2499940 | global iter:   3999/1249970 | loss: 1.2923 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   7998/2499940 | global iter:   4000/1249970 | loss: 1.1558 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7998/2499940 | global iter:   4000/1249970 | loss: 1.2838 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
Model save to ./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1/4000
dp size 2
0/63
Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
1/63
Evaluating:   2%|▏         | 1/63 [00:07<08:13,  7.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2/63
Evaluating:   3%|▎         | 2/63 [00:13<06:50,  6.72s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
3/63
Evaluating:   5%|▍         | 3/63 [00:21<07:16,  7.27s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
4/63
Evaluating:   6%|▋         | 4/63 [00:29<07:24,  7.54s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
5/63
Evaluating:   8%|▊         | 5/63 [00:36<07:08,  7.39s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
6/63
Evaluating:  10%|▉         | 6/63 [00:44<07:09,  7.53s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
7/63
Evaluating:  11%|█         | 7/63 [00:51<06:44,  7.22s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
8/63
Evaluating:  13%|█▎        | 8/63 [00:58<06:40,  7.29s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
9/63
Evaluating:  14%|█▍        | 9/63 [01:06<06:45,  7.51s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
10/63
Evaluating:  16%|█▌        | 10/63 [01:14<06:45,  7.65s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
11/63
Evaluating:  17%|█▋        | 11/63 [01:22<06:43,  7.76s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
12/63
Evaluating:  19%|█▉        | 12/63 [01:30<06:39,  7.84s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
13/63
Evaluating:  21%|██        | 13/63 [01:38<06:33,  7.88s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
14/63
Evaluating:  22%|██▏       | 14/63 [01:46<06:27,  7.91s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
15/63
Evaluating:  24%|██▍       | 15/63 [01:54<06:17,  7.85s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
16/63
Evaluating:  25%|██▌       | 16/63 [02:02<06:10,  7.89s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
17/63
Evaluating:  27%|██▋       | 17/63 [02:09<05:50,  7.62s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
18/63
Evaluating:  29%|██▊       | 18/63 [02:17<05:48,  7.74s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
19/63
Evaluating:  30%|███       | 19/63 [02:25<05:44,  7.82s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
20/63
Evaluating:  32%|███▏      | 20/63 [02:33<05:38,  7.87s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
21/63
Evaluating:  33%|███▎      | 21/63 [02:38<04:59,  7.12s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
22/63
Evaluating:  35%|███▍      | 22/63 [02:46<05:02,  7.39s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
23/63
Evaluating:  37%|███▋      | 23/63 [02:54<05:02,  7.57s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
24/63
Evaluating:  38%|███▊      | 24/63 [03:02<05:00,  7.70s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
25/63
Evaluating:  40%|███▉      | 25/63 [03:09<04:45,  7.52s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
26/63
Evaluating:  41%|████▏     | 26/63 [03:17<04:35,  7.44s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
27/63
Evaluating:  43%|████▎     | 27/63 [03:25<04:34,  7.63s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
28/63
Evaluating:  44%|████▍     | 28/63 [03:32<04:29,  7.69s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
29/63
Evaluating:  46%|████▌     | 29/63 [03:40<04:24,  7.78s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
30/63
Evaluating:  48%|████▊     | 30/63 [03:48<04:18,  7.85s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
31/63
Evaluating:  49%|████▉     | 31/63 [03:56<04:12,  7.90s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
32/63
Evaluating:  51%|█████     | 32/63 [04:04<04:01,  7.80s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
33/63
Evaluating:  52%|█████▏    | 33/63 [04:12<03:52,  7.76s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
34/63
Evaluating:  54%|█████▍    | 34/63 [04:20<03:47,  7.83s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
35/63
Evaluating:  56%|█████▌    | 35/63 [04:27<03:35,  7.69s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
36/63
Evaluating:  57%|█████▋    | 36/63 [04:35<03:30,  7.78s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
37/63
Evaluating:  59%|█████▊    | 37/63 [04:43<03:24,  7.85s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
38/63
Evaluating:  60%|██████    | 38/63 [04:51<03:16,  7.88s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
39/63
Evaluating:  62%|██████▏   | 39/63 [04:59<03:08,  7.86s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
40/63
Evaluating:  63%|██████▎   | 40/63 [05:07<03:01,  7.89s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
41/63
Evaluating:  65%|██████▌   | 41/63 [05:15<02:54,  7.93s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
42/63
Evaluating:  67%|██████▋   | 42/63 [05:23<02:47,  7.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
43/63
Evaluating:  68%|██████▊   | 43/63 [05:31<02:39,  7.97s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
44/63
Evaluating:  70%|██████▉   | 44/63 [05:39<02:31,  7.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
45/63
Evaluating:  71%|███████▏  | 45/63 [05:47<02:23,  7.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
46/63
Evaluating:  73%|███████▎  | 46/63 [05:55<02:16,  8.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
47/63
Evaluating:  75%|███████▍  | 47/63 [06:02<02:05,  7.86s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
48/63
Evaluating:  76%|███████▌  | 48/63 [06:09<01:51,  7.41s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
49/63
Evaluating:  78%|███████▊  | 49/63 [06:17<01:46,  7.59s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
50/63
Evaluating:  79%|███████▉  | 50/63 [06:25<01:40,  7.73s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
51/63
Evaluating:  81%|████████  | 51/63 [06:33<01:33,  7.81s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
52/63
Evaluating:  83%|████████▎ | 52/63 [06:39<01:22,  7.46s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
53/63
Evaluating:  84%|████████▍ | 53/63 [06:47<01:16,  7.63s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
54/63
Evaluating:  86%|████████▌ | 54/63 [06:55<01:09,  7.70s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
55/63
Evaluating:  87%|████████▋ | 55/63 [07:03<01:02,  7.80s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
56/63
Evaluating:  89%|████████▉ | 56/63 [07:11<00:55,  7.86s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
57/63
Evaluating:  90%|█████████ | 57/63 [07:19<00:47,  7.90s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
58/63
Evaluating:  92%|█████████▏| 58/63 [07:25<00:35,  7.18s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
59/63
Evaluating:  94%|█████████▎| 59/63 [07:33<00:29,  7.43s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
60/63
Evaluating:  95%|█████████▌| 60/63 [07:41<00:22,  7.60s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
61/63
Evaluating:  97%|█████████▋| 61/63 [07:48<00:14,  7.42s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
62/63
Evaluating:  98%|█████████▊| 62/63 [07:56<00:07,  7.60s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
Evaluating: 100%|██████████| 63/63 [08:01<00:00,  6.92s/it]Evaluating: 100%|██████████| 63/63 [08:01<00:00,  7.65s/it]
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1/eval/0
dev | avg_loss: 1.271360367063492 | {'exact_match': 0.0, 'rougeL': 34.3027}
train | epoch   0 | Iter:   8000/2499940 | global iter:   4001/1249970 | loss: 1.2169 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:   8002/2499940 | global iter:   4002/1249970 | loss: 1.6022 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8004/2499940 | global iter:   4003/1249970 | loss: 1.1453 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8006/2499940 | global iter:   4004/1249970 | loss: 2.0473 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8006/2499940 | global iter:   4004/1249970 | loss: 1.4003 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.684
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8008/2499940 | global iter:   4005/1249970 | loss: 1.4186 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8010/2499940 | global iter:   4006/1249970 | loss: 1.2922 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8012/2499940 | global iter:   4007/1249970 | loss: 1.0649 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:   8014/2499940 | global iter:   4008/1249970 | loss: 0.8274 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8014/2499940 | global iter:   4008/1249970 | loss: 1.3111 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8016/2499940 | global iter:   4009/1249970 | loss: 1.0067 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8018/2499940 | global iter:   4010/1249970 | loss: 0.7341 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8020/2499940 | global iter:   4011/1249970 | loss: 0.6626 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8022/2499940 | global iter:   4012/1249970 | loss: 1.0772 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8022/2499940 | global iter:   4012/1249970 | loss: 0.8990 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8024/2499940 | global iter:   4013/1249970 | loss: 0.7962 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8026/2499940 | global iter:   4014/1249970 | loss: 1.5165 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   8028/2499940 | global iter:   4015/1249970 | loss: 0.7792 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8030/2499940 | global iter:   4016/1249970 | loss: 1.0838 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8030/2499940 | global iter:   4016/1249970 | loss: 1.1510 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8032/2499940 | global iter:   4017/1249970 | loss: 1.3597 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8034/2499940 | global iter:   4018/1249970 | loss: 1.6630 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8036/2499940 | global iter:   4019/1249970 | loss: 1.3835 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8038/2499940 | global iter:   4020/1249970 | loss: 1.3687 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8038/2499940 | global iter:   4020/1249970 | loss: 1.3591 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8040/2499940 | global iter:   4021/1249970 | loss: 1.7038 | ds_loss: 0.0000 | lr: 9.9998e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8042/2499940 | global iter:   4022/1249970 | loss: 0.8659 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   8044/2499940 | global iter:   4023/1249970 | loss: 0.6197 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8046/2499940 | global iter:   4024/1249970 | loss: 1.1036 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8046/2499940 | global iter:   4024/1249970 | loss: 0.9997 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8048/2499940 | global iter:   4025/1249970 | loss: 1.4938 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:   8050/2499940 | global iter:   4026/1249970 | loss: 0.7231 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8052/2499940 | global iter:   4027/1249970 | loss: 0.9607 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8054/2499940 | global iter:   4028/1249970 | loss: 0.8392 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8054/2499940 | global iter:   4028/1249970 | loss: 1.1747 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8056/2499940 | global iter:   4029/1249970 | loss: 0.8594 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8058/2499940 | global iter:   4030/1249970 | loss: 1.1366 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8060/2499940 | global iter:   4031/1249970 | loss: 0.7364 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8062/2499940 | global iter:   4032/1249970 | loss: 1.0678 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8062/2499940 | global iter:   4032/1249970 | loss: 1.0955 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8064/2499940 | global iter:   4033/1249970 | loss: 0.5873 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8066/2499940 | global iter:   4034/1249970 | loss: 0.6007 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8068/2499940 | global iter:   4035/1249970 | loss: 1.0858 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8070/2499940 | global iter:   4036/1249970 | loss: 1.3426 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8070/2499940 | global iter:   4036/1249970 | loss: 1.0073 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8072/2499940 | global iter:   4037/1249970 | loss: 1.8906 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8074/2499940 | global iter:   4038/1249970 | loss: 1.3240 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   8076/2499940 | global iter:   4039/1249970 | loss: 1.6669 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8078/2499940 | global iter:   4040/1249970 | loss: 1.0535 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8078/2499940 | global iter:   4040/1249970 | loss: 1.2386 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8080/2499940 | global iter:   4041/1249970 | loss: 1.0277 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8082/2499940 | global iter:   4042/1249970 | loss: 1.1471 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   8084/2499940 | global iter:   4043/1249970 | loss: 0.3002 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8086/2499940 | global iter:   4044/1249970 | loss: 1.4204 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8086/2499940 | global iter:   4044/1249970 | loss: 0.9240 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8088/2499940 | global iter:   4045/1249970 | loss: 0.7564 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8090/2499940 | global iter:   4046/1249970 | loss: 0.4037 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8092/2499940 | global iter:   4047/1249970 | loss: 0.1551 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   8094/2499940 | global iter:   4048/1249970 | loss: 1.4234 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8094/2499940 | global iter:   4048/1249970 | loss: 1.0758 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8096/2499940 | global iter:   4049/1249970 | loss: 0.2302 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8098/2499940 | global iter:   4050/1249970 | loss: 0.6350 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8100/2499940 | global iter:   4051/1249970 | loss: 1.0551 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8102/2499940 | global iter:   4052/1249970 | loss: 0.8093 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8102/2499940 | global iter:   4052/1249970 | loss: 0.7491 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8104/2499940 | global iter:   4053/1249970 | loss: 1.0518 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8106/2499940 | global iter:   4054/1249970 | loss: 0.9095 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8108/2499940 | global iter:   4055/1249970 | loss: 1.3917 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8110/2499940 | global iter:   4056/1249970 | loss: 0.4775 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8110/2499940 | global iter:   4056/1249970 | loss: 1.0385 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8112/2499940 | global iter:   4057/1249970 | loss: 0.8802 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8114/2499940 | global iter:   4058/1249970 | loss: 1.4262 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8116/2499940 | global iter:   4059/1249970 | loss: 1.7232 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8118/2499940 | global iter:   4060/1249970 | loss: 1.0162 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8118/2499940 | global iter:   4060/1249970 | loss: 1.2497 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8120/2499940 | global iter:   4061/1249970 | loss: 0.6551 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8122/2499940 | global iter:   4062/1249970 | loss: 0.9655 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8124/2499940 | global iter:   4063/1249970 | loss: 0.9545 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8126/2499940 | global iter:   4064/1249970 | loss: 1.2605 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.405 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8126/2499940 | global iter:   4064/1249970 | loss: 1.1432 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.405 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8128/2499940 | global iter:   4065/1249970 | loss: 1.2687 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   8130/2499940 | global iter:   4066/1249970 | loss: 1.2534 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   8132/2499940 | global iter:   4067/1249970 | loss: 0.6972 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8134/2499940 | global iter:   4068/1249970 | loss: 1.0377 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8134/2499940 | global iter:   4068/1249970 | loss: 1.2542 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8136/2499940 | global iter:   4069/1249970 | loss: 1.3004 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8138/2499940 | global iter:   4070/1249970 | loss: 0.6920 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8140/2499940 | global iter:   4071/1249970 | loss: 1.2445 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8142/2499940 | global iter:   4072/1249970 | loss: 1.8863 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8142/2499940 | global iter:   4072/1249970 | loss: 1.1345 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8144/2499940 | global iter:   4073/1249970 | loss: 1.2465 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8146/2499940 | global iter:   4074/1249970 | loss: 1.5149 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8148/2499940 | global iter:   4075/1249970 | loss: 1.2157 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8150/2499940 | global iter:   4076/1249970 | loss: 0.3432 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8150/2499940 | global iter:   4076/1249970 | loss: 1.0683 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8152/2499940 | global iter:   4077/1249970 | loss: 0.5142 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8154/2499940 | global iter:   4078/1249970 | loss: 0.8380 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8156/2499940 | global iter:   4079/1249970 | loss: 1.6250 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8158/2499940 | global iter:   4080/1249970 | loss: 1.7999 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8158/2499940 | global iter:   4080/1249970 | loss: 1.1362 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8160/2499940 | global iter:   4081/1249970 | loss: 0.9937 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8162/2499940 | global iter:   4082/1249970 | loss: 1.0997 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8164/2499940 | global iter:   4083/1249970 | loss: 1.5478 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8166/2499940 | global iter:   4084/1249970 | loss: 0.9668 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8166/2499940 | global iter:   4084/1249970 | loss: 1.2145 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8168/2499940 | global iter:   4085/1249970 | loss: 0.5542 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8170/2499940 | global iter:   4086/1249970 | loss: 1.0236 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   8172/2499940 | global iter:   4087/1249970 | loss: 0.6882 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8174/2499940 | global iter:   4088/1249970 | loss: 0.2002 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8174/2499940 | global iter:   4088/1249970 | loss: 0.9722 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8176/2499940 | global iter:   4089/1249970 | loss: 0.5594 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8178/2499940 | global iter:   4090/1249970 | loss: 0.8943 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8180/2499940 | global iter:   4091/1249970 | loss: 0.8190 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8182/2499940 | global iter:   4092/1249970 | loss: 0.9886 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8182/2499940 | global iter:   4092/1249970 | loss: 0.8424 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8184/2499940 | global iter:   4093/1249970 | loss: 0.9944 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8186/2499940 | global iter:   4094/1249970 | loss: 0.9823 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8188/2499940 | global iter:   4095/1249970 | loss: 0.9063 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8190/2499940 | global iter:   4096/1249970 | loss: 0.8319 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8190/2499940 | global iter:   4096/1249970 | loss: 1.0025 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8192/2499940 | global iter:   4097/1249970 | loss: 1.1576 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8194/2499940 | global iter:   4098/1249970 | loss: 0.7712 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8196/2499940 | global iter:   4099/1249970 | loss: 1.6615 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8198/2499940 | global iter:   4100/1249970 | loss: 1.4287 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8198/2499940 | global iter:   4100/1249970 | loss: 1.2937 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8200/2499940 | global iter:   4101/1249970 | loss: 1.3954 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8202/2499940 | global iter:   4102/1249970 | loss: 0.9327 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8204/2499940 | global iter:   4103/1249970 | loss: 1.5533 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8206/2499940 | global iter:   4104/1249970 | loss: 1.4386 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8206/2499940 | global iter:   4104/1249970 | loss: 1.0867 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8208/2499940 | global iter:   4105/1249970 | loss: 1.3925 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8210/2499940 | global iter:   4106/1249970 | loss: 1.0586 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8212/2499940 | global iter:   4107/1249970 | loss: 0.6287 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   8214/2499940 | global iter:   4108/1249970 | loss: 1.4401 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8214/2499940 | global iter:   4108/1249970 | loss: 0.9551 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8216/2499940 | global iter:   4109/1249970 | loss: 1.0855 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8218/2499940 | global iter:   4110/1249970 | loss: 0.5931 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   8220/2499940 | global iter:   4111/1249970 | loss: 0.8128 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8222/2499940 | global iter:   4112/1249970 | loss: 1.1864 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8222/2499940 | global iter:   4112/1249970 | loss: 0.9522 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8224/2499940 | global iter:   4113/1249970 | loss: 0.9673 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8226/2499940 | global iter:   4114/1249970 | loss: 1.0153 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8228/2499940 | global iter:   4115/1249970 | loss: 1.0365 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8230/2499940 | global iter:   4116/1249970 | loss: 1.0496 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8230/2499940 | global iter:   4116/1249970 | loss: 1.2760 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8232/2499940 | global iter:   4117/1249970 | loss: 0.7994 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8234/2499940 | global iter:   4118/1249970 | loss: 0.8631 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8236/2499940 | global iter:   4119/1249970 | loss: 1.1803 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:   8238/2499940 | global iter:   4120/1249970 | loss: 1.4590 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8238/2499940 | global iter:   4120/1249970 | loss: 0.9437 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8240/2499940 | global iter:   4121/1249970 | loss: 1.0656 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   8242/2499940 | global iter:   4122/1249970 | loss: 1.4909 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   8244/2499940 | global iter:   4123/1249970 | loss: 0.8167 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8246/2499940 | global iter:   4124/1249970 | loss: 1.4628 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8246/2499940 | global iter:   4124/1249970 | loss: 1.2112 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8248/2499940 | global iter:   4125/1249970 | loss: 0.8048 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8250/2499940 | global iter:   4126/1249970 | loss: 0.0582 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8252/2499940 | global iter:   4127/1249970 | loss: 0.9835 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8254/2499940 | global iter:   4128/1249970 | loss: 0.6131 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8254/2499940 | global iter:   4128/1249970 | loss: 1.1262 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8256/2499940 | global iter:   4129/1249970 | loss: 1.3326 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   8258/2499940 | global iter:   4130/1249970 | loss: 0.2600 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8260/2499940 | global iter:   4131/1249970 | loss: 0.9929 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8262/2499940 | global iter:   4132/1249970 | loss: 1.4677 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8262/2499940 | global iter:   4132/1249970 | loss: 1.2616 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8264/2499940 | global iter:   4133/1249970 | loss: 0.7292 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8266/2499940 | global iter:   4134/1249970 | loss: 1.3076 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   8268/2499940 | global iter:   4135/1249970 | loss: 0.8007 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   8270/2499940 | global iter:   4136/1249970 | loss: 1.9142 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8270/2499940 | global iter:   4136/1249970 | loss: 1.2522 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8272/2499940 | global iter:   4137/1249970 | loss: 1.4994 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8274/2499940 | global iter:   4138/1249970 | loss: 1.4904 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8276/2499940 | global iter:   4139/1249970 | loss: 0.6768 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   8278/2499940 | global iter:   4140/1249970 | loss: 1.1048 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8278/2499940 | global iter:   4140/1249970 | loss: 1.1431 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8280/2499940 | global iter:   4141/1249970 | loss: 0.7742 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8282/2499940 | global iter:   4142/1249970 | loss: 0.6459 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   8284/2499940 | global iter:   4143/1249970 | loss: 1.0308 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8286/2499940 | global iter:   4144/1249970 | loss: 1.1066 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8286/2499940 | global iter:   4144/1249970 | loss: 1.1198 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8288/2499940 | global iter:   4145/1249970 | loss: 0.9763 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8290/2499940 | global iter:   4146/1249970 | loss: 0.0388 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8292/2499940 | global iter:   4147/1249970 | loss: 0.5739 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8294/2499940 | global iter:   4148/1249970 | loss: 1.0520 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8294/2499940 | global iter:   4148/1249970 | loss: 0.8575 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8296/2499940 | global iter:   4149/1249970 | loss: 0.6286 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   8298/2499940 | global iter:   4150/1249970 | loss: 1.1408 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8300/2499940 | global iter:   4151/1249970 | loss: 1.1330 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.406 | step time: 0.000
train | epoch   0 | Iter:   8302/2499940 | global iter:   4152/1249970 | loss: 1.0089 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8302/2499940 | global iter:   4152/1249970 | loss: 1.0019 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.695
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8304/2499940 | global iter:   4153/1249970 | loss: 0.9162 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8306/2499940 | global iter:   4154/1249970 | loss: 0.3368 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   8308/2499940 | global iter:   4155/1249970 | loss: 0.0638 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8310/2499940 | global iter:   4156/1249970 | loss: 1.4698 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8310/2499940 | global iter:   4156/1249970 | loss: 0.8864 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8312/2499940 | global iter:   4157/1249970 | loss: 1.0535 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8314/2499940 | global iter:   4158/1249970 | loss: 0.8353 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8316/2499940 | global iter:   4159/1249970 | loss: 1.0779 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8318/2499940 | global iter:   4160/1249970 | loss: 1.5648 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8318/2499940 | global iter:   4160/1249970 | loss: 1.0283 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8320/2499940 | global iter:   4161/1249970 | loss: 1.1470 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8322/2499940 | global iter:   4162/1249970 | loss: 0.0186 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8324/2499940 | global iter:   4163/1249970 | loss: 0.3579 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8326/2499940 | global iter:   4164/1249970 | loss: 0.7568 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8326/2499940 | global iter:   4164/1249970 | loss: 0.7423 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8328/2499940 | global iter:   4165/1249970 | loss: 0.4661 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   8330/2499940 | global iter:   4166/1249970 | loss: 1.0952 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8332/2499940 | global iter:   4167/1249970 | loss: 1.1860 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8334/2499940 | global iter:   4168/1249970 | loss: 1.2120 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8334/2499940 | global iter:   4168/1249970 | loss: 0.8908 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8336/2499940 | global iter:   4169/1249970 | loss: 0.9383 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8338/2499940 | global iter:   4170/1249970 | loss: 1.1671 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   8340/2499940 | global iter:   4171/1249970 | loss: 1.7753 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8342/2499940 | global iter:   4172/1249970 | loss: 1.6862 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8342/2499940 | global iter:   4172/1249970 | loss: 1.2742 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8344/2499940 | global iter:   4173/1249970 | loss: 1.3222 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8346/2499940 | global iter:   4174/1249970 | loss: 1.6461 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8348/2499940 | global iter:   4175/1249970 | loss: 1.1217 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8350/2499940 | global iter:   4176/1249970 | loss: 0.6025 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8350/2499940 | global iter:   4176/1249970 | loss: 1.1039 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8352/2499940 | global iter:   4177/1249970 | loss: 0.8590 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8354/2499940 | global iter:   4178/1249970 | loss: 1.6992 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8356/2499940 | global iter:   4179/1249970 | loss: 0.9198 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   8358/2499940 | global iter:   4180/1249970 | loss: 1.4720 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8358/2499940 | global iter:   4180/1249970 | loss: 1.1110 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8360/2499940 | global iter:   4181/1249970 | loss: 0.3345 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8362/2499940 | global iter:   4182/1249970 | loss: 1.3651 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8364/2499940 | global iter:   4183/1249970 | loss: 1.4658 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8366/2499940 | global iter:   4184/1249970 | loss: 0.9500 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8366/2499940 | global iter:   4184/1249970 | loss: 1.1025 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8368/2499940 | global iter:   4185/1249970 | loss: 1.1745 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8370/2499940 | global iter:   4186/1249970 | loss: 0.8162 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8372/2499940 | global iter:   4187/1249970 | loss: 1.0743 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8374/2499940 | global iter:   4188/1249970 | loss: 1.1446 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8374/2499940 | global iter:   4188/1249970 | loss: 1.2692 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8376/2499940 | global iter:   4189/1249970 | loss: 1.4188 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8378/2499940 | global iter:   4190/1249970 | loss: 0.4681 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8380/2499940 | global iter:   4191/1249970 | loss: 0.8249 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   8382/2499940 | global iter:   4192/1249970 | loss: 0.7313 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8382/2499940 | global iter:   4192/1249970 | loss: 0.9795 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8384/2499940 | global iter:   4193/1249970 | loss: 1.6409 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8386/2499940 | global iter:   4194/1249970 | loss: 0.8887 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.404 | step time: 0.000
train | epoch   0 | Iter:   8388/2499940 | global iter:   4195/1249970 | loss: 0.7299 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8390/2499940 | global iter:   4196/1249970 | loss: 1.7326 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8390/2499940 | global iter:   4196/1249970 | loss: 1.1393 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8392/2499940 | global iter:   4197/1249970 | loss: 1.3955 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   8394/2499940 | global iter:   4198/1249970 | loss: 1.1575 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8396/2499940 | global iter:   4199/1249970 | loss: 1.0163 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8398/2499940 | global iter:   4200/1249970 | loss: 1.3880 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8398/2499940 | global iter:   4200/1249970 | loss: 1.2047 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8400/2499940 | global iter:   4201/1249970 | loss: 0.6923 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   8402/2499940 | global iter:   4202/1249970 | loss: 1.3767 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   8404/2499940 | global iter:   4203/1249970 | loss: 0.5774 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8406/2499940 | global iter:   4204/1249970 | loss: 0.9553 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8406/2499940 | global iter:   4204/1249970 | loss: 1.0515 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8408/2499940 | global iter:   4205/1249970 | loss: 1.2519 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8410/2499940 | global iter:   4206/1249970 | loss: 1.8062 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8412/2499940 | global iter:   4207/1249970 | loss: 0.9846 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8414/2499940 | global iter:   4208/1249970 | loss: 1.6673 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8414/2499940 | global iter:   4208/1249970 | loss: 1.4229 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8416/2499940 | global iter:   4209/1249970 | loss: 1.6367 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8418/2499940 | global iter:   4210/1249970 | loss: 0.8404 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   8420/2499940 | global iter:   4211/1249970 | loss: 0.9745 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8422/2499940 | global iter:   4212/1249970 | loss: 1.3729 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8422/2499940 | global iter:   4212/1249970 | loss: 1.2360 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8424/2499940 | global iter:   4213/1249970 | loss: 1.3235 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8426/2499940 | global iter:   4214/1249970 | loss: 1.3205 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8428/2499940 | global iter:   4215/1249970 | loss: 0.8977 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8430/2499940 | global iter:   4216/1249970 | loss: 1.9620 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8430/2499940 | global iter:   4216/1249970 | loss: 1.1671 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8432/2499940 | global iter:   4217/1249970 | loss: 1.3897 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8434/2499940 | global iter:   4218/1249970 | loss: 0.9218 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8436/2499940 | global iter:   4219/1249970 | loss: 0.9617 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8438/2499940 | global iter:   4220/1249970 | loss: 0.4996 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8438/2499940 | global iter:   4220/1249970 | loss: 1.0634 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8440/2499940 | global iter:   4221/1249970 | loss: 0.9651 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8442/2499940 | global iter:   4222/1249970 | loss: 0.7048 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8444/2499940 | global iter:   4223/1249970 | loss: 1.0045 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8446/2499940 | global iter:   4224/1249970 | loss: 0.9564 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8446/2499940 | global iter:   4224/1249970 | loss: 1.0805 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8448/2499940 | global iter:   4225/1249970 | loss: 0.7479 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8450/2499940 | global iter:   4226/1249970 | loss: 1.5933 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8452/2499940 | global iter:   4227/1249970 | loss: 0.6933 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8454/2499940 | global iter:   4228/1249970 | loss: 0.7549 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8454/2499940 | global iter:   4228/1249970 | loss: 0.9797 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8456/2499940 | global iter:   4229/1249970 | loss: 1.0657 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8458/2499940 | global iter:   4230/1249970 | loss: 1.2819 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   8460/2499940 | global iter:   4231/1249970 | loss: 1.7332 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8462/2499940 | global iter:   4232/1249970 | loss: 1.4098 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8462/2499940 | global iter:   4232/1249970 | loss: 1.1049 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8464/2499940 | global iter:   4233/1249970 | loss: 0.8089 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8466/2499940 | global iter:   4234/1249970 | loss: 0.9057 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   8468/2499940 | global iter:   4235/1249970 | loss: 1.1361 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8470/2499940 | global iter:   4236/1249970 | loss: 1.1261 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8470/2499940 | global iter:   4236/1249970 | loss: 0.8651 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8472/2499940 | global iter:   4237/1249970 | loss: 0.2853 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8474/2499940 | global iter:   4238/1249970 | loss: 2.0113 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   8476/2499940 | global iter:   4239/1249970 | loss: 0.9051 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8478/2499940 | global iter:   4240/1249970 | loss: 1.5344 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8478/2499940 | global iter:   4240/1249970 | loss: 1.1010 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8480/2499940 | global iter:   4241/1249970 | loss: 0.8647 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8482/2499940 | global iter:   4242/1249970 | loss: 0.8792 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8484/2499940 | global iter:   4243/1249970 | loss: 0.9745 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8486/2499940 | global iter:   4244/1249970 | loss: 0.9157 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8486/2499940 | global iter:   4244/1249970 | loss: 0.9169 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8488/2499940 | global iter:   4245/1249970 | loss: 1.2263 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8490/2499940 | global iter:   4246/1249970 | loss: 1.8792 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   8492/2499940 | global iter:   4247/1249970 | loss: 1.8870 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8494/2499940 | global iter:   4248/1249970 | loss: 1.0462 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8494/2499940 | global iter:   4248/1249970 | loss: 1.2829 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8496/2499940 | global iter:   4249/1249970 | loss: 1.4680 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8498/2499940 | global iter:   4250/1249970 | loss: 1.0661 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   8500/2499940 | global iter:   4251/1249970 | loss: 1.3275 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8502/2499940 | global iter:   4252/1249970 | loss: 1.4073 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8502/2499940 | global iter:   4252/1249970 | loss: 1.0596 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8504/2499940 | global iter:   4253/1249970 | loss: 0.7997 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8506/2499940 | global iter:   4254/1249970 | loss: 0.5784 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   8508/2499940 | global iter:   4255/1249970 | loss: 0.9820 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8510/2499940 | global iter:   4256/1249970 | loss: 1.3373 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8510/2499940 | global iter:   4256/1249970 | loss: 0.9068 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8512/2499940 | global iter:   4257/1249970 | loss: 1.4403 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8514/2499940 | global iter:   4258/1249970 | loss: 0.8725 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8516/2499940 | global iter:   4259/1249970 | loss: 0.6434 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8518/2499940 | global iter:   4260/1249970 | loss: 1.0419 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8518/2499940 | global iter:   4260/1249970 | loss: 1.0132 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8520/2499940 | global iter:   4261/1249970 | loss: 1.9052 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8522/2499940 | global iter:   4262/1249970 | loss: 0.9538 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8524/2499940 | global iter:   4263/1249970 | loss: 1.3447 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8526/2499940 | global iter:   4264/1249970 | loss: 1.3344 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8526/2499940 | global iter:   4264/1249970 | loss: 1.2143 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8528/2499940 | global iter:   4265/1249970 | loss: 0.8575 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   8530/2499940 | global iter:   4266/1249970 | loss: 1.9598 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8532/2499940 | global iter:   4267/1249970 | loss: 1.7047 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8534/2499940 | global iter:   4268/1249970 | loss: 0.8108 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8534/2499940 | global iter:   4268/1249970 | loss: 1.2720 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8536/2499940 | global iter:   4269/1249970 | loss: 1.2320 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8538/2499940 | global iter:   4270/1249970 | loss: 1.1016 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8540/2499940 | global iter:   4271/1249970 | loss: 0.1850 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8542/2499940 | global iter:   4272/1249970 | loss: 0.9424 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8542/2499940 | global iter:   4272/1249970 | loss: 1.1308 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8544/2499940 | global iter:   4273/1249970 | loss: 0.7430 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   8546/2499940 | global iter:   4274/1249970 | loss: 0.7764 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   8548/2499940 | global iter:   4275/1249970 | loss: 0.6613 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8550/2499940 | global iter:   4276/1249970 | loss: 2.3310 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8550/2499940 | global iter:   4276/1249970 | loss: 1.1932 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8552/2499940 | global iter:   4277/1249970 | loss: 0.6915 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8554/2499940 | global iter:   4278/1249970 | loss: 0.5981 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8556/2499940 | global iter:   4279/1249970 | loss: 1.2463 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8558/2499940 | global iter:   4280/1249970 | loss: 1.0293 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8558/2499940 | global iter:   4280/1249970 | loss: 1.0927 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8560/2499940 | global iter:   4281/1249970 | loss: 0.5651 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8562/2499940 | global iter:   4282/1249970 | loss: 0.4299 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8564/2499940 | global iter:   4283/1249970 | loss: 0.6747 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8566/2499940 | global iter:   4284/1249970 | loss: 0.7032 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8566/2499940 | global iter:   4284/1249970 | loss: 0.7473 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8568/2499940 | global iter:   4285/1249970 | loss: 1.8943 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8570/2499940 | global iter:   4286/1249970 | loss: 0.4388 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8572/2499940 | global iter:   4287/1249970 | loss: 0.7468 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8574/2499940 | global iter:   4288/1249970 | loss: 0.7347 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8574/2499940 | global iter:   4288/1249970 | loss: 1.0876 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8576/2499940 | global iter:   4289/1249970 | loss: 0.9012 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8578/2499940 | global iter:   4290/1249970 | loss: 0.7942 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8580/2499940 | global iter:   4291/1249970 | loss: 0.7183 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8582/2499940 | global iter:   4292/1249970 | loss: 0.8764 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8582/2499940 | global iter:   4292/1249970 | loss: 1.0161 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8584/2499940 | global iter:   4293/1249970 | loss: 1.8888 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8586/2499940 | global iter:   4294/1249970 | loss: 0.5557 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   8588/2499940 | global iter:   4295/1249970 | loss: 1.2378 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   8590/2499940 | global iter:   4296/1249970 | loss: 0.8753 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8590/2499940 | global iter:   4296/1249970 | loss: 1.2038 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8592/2499940 | global iter:   4297/1249970 | loss: 1.3990 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8594/2499940 | global iter:   4298/1249970 | loss: 0.4888 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8596/2499940 | global iter:   4299/1249970 | loss: 0.9740 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8598/2499940 | global iter:   4300/1249970 | loss: 0.7860 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8598/2499940 | global iter:   4300/1249970 | loss: 0.9576 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8600/2499940 | global iter:   4301/1249970 | loss: 1.1513 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8602/2499940 | global iter:   4302/1249970 | loss: 1.2199 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:   8604/2499940 | global iter:   4303/1249970 | loss: 1.3989 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8606/2499940 | global iter:   4304/1249970 | loss: 1.2448 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8606/2499940 | global iter:   4304/1249970 | loss: 1.3533 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8608/2499940 | global iter:   4305/1249970 | loss: 0.6763 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8610/2499940 | global iter:   4306/1249970 | loss: 1.1654 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8612/2499940 | global iter:   4307/1249970 | loss: 1.2584 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8614/2499940 | global iter:   4308/1249970 | loss: 1.1601 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8614/2499940 | global iter:   4308/1249970 | loss: 1.0689 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8616/2499940 | global iter:   4309/1249970 | loss: 0.4018 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8618/2499940 | global iter:   4310/1249970 | loss: 0.9634 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   8620/2499940 | global iter:   4311/1249970 | loss: 1.1070 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8622/2499940 | global iter:   4312/1249970 | loss: 0.8200 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8622/2499940 | global iter:   4312/1249970 | loss: 0.7530 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8624/2499940 | global iter:   4313/1249970 | loss: 0.7659 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8626/2499940 | global iter:   4314/1249970 | loss: 1.4143 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8628/2499940 | global iter:   4315/1249970 | loss: 0.9301 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8630/2499940 | global iter:   4316/1249970 | loss: 1.1396 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8630/2499940 | global iter:   4316/1249970 | loss: 1.0271 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8632/2499940 | global iter:   4317/1249970 | loss: 1.5851 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8634/2499940 | global iter:   4318/1249970 | loss: 1.5012 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8636/2499940 | global iter:   4319/1249970 | loss: 1.3105 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8638/2499940 | global iter:   4320/1249970 | loss: 1.1043 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8638/2499940 | global iter:   4320/1249970 | loss: 1.1145 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8640/2499940 | global iter:   4321/1249970 | loss: 1.0652 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8642/2499940 | global iter:   4322/1249970 | loss: 0.7278 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   8644/2499940 | global iter:   4323/1249970 | loss: 1.6158 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8646/2499940 | global iter:   4324/1249970 | loss: 0.2364 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.404 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8646/2499940 | global iter:   4324/1249970 | loss: 0.8504 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.404 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8648/2499940 | global iter:   4325/1249970 | loss: 1.2992 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8650/2499940 | global iter:   4326/1249970 | loss: 1.8443 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8652/2499940 | global iter:   4327/1249970 | loss: 1.1799 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8654/2499940 | global iter:   4328/1249970 | loss: 0.6915 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8654/2499940 | global iter:   4328/1249970 | loss: 1.0738 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8656/2499940 | global iter:   4329/1249970 | loss: 1.2558 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8658/2499940 | global iter:   4330/1249970 | loss: 0.8181 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8660/2499940 | global iter:   4331/1249970 | loss: 1.7973 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8662/2499940 | global iter:   4332/1249970 | loss: 1.1715 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8662/2499940 | global iter:   4332/1249970 | loss: 1.2701 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8664/2499940 | global iter:   4333/1249970 | loss: 1.6418 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8666/2499940 | global iter:   4334/1249970 | loss: 1.2445 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8668/2499940 | global iter:   4335/1249970 | loss: 1.8833 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8670/2499940 | global iter:   4336/1249970 | loss: 1.1964 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8670/2499940 | global iter:   4336/1249970 | loss: 1.4166 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8672/2499940 | global iter:   4337/1249970 | loss: 0.7440 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8674/2499940 | global iter:   4338/1249970 | loss: 0.7441 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   8676/2499940 | global iter:   4339/1249970 | loss: 1.2734 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8678/2499940 | global iter:   4340/1249970 | loss: 1.5734 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8678/2499940 | global iter:   4340/1249970 | loss: 0.9099 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8680/2499940 | global iter:   4341/1249970 | loss: 0.4176 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8682/2499940 | global iter:   4342/1249970 | loss: 1.2280 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8684/2499940 | global iter:   4343/1249970 | loss: 1.6047 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8686/2499940 | global iter:   4344/1249970 | loss: 1.1598 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8686/2499940 | global iter:   4344/1249970 | loss: 1.2396 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8688/2499940 | global iter:   4345/1249970 | loss: 0.5115 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:   8690/2499940 | global iter:   4346/1249970 | loss: 0.8260 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8692/2499940 | global iter:   4347/1249970 | loss: 1.7443 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8694/2499940 | global iter:   4348/1249970 | loss: 0.4350 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8694/2499940 | global iter:   4348/1249970 | loss: 1.0216 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8696/2499940 | global iter:   4349/1249970 | loss: 1.1797 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8698/2499940 | global iter:   4350/1249970 | loss: 0.9408 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   8700/2499940 | global iter:   4351/1249970 | loss: 0.9244 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8702/2499940 | global iter:   4352/1249970 | loss: 0.9699 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8702/2499940 | global iter:   4352/1249970 | loss: 1.0212 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8704/2499940 | global iter:   4353/1249970 | loss: 0.8685 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8706/2499940 | global iter:   4354/1249970 | loss: 0.9409 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   8708/2499940 | global iter:   4355/1249970 | loss: 1.4467 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8710/2499940 | global iter:   4356/1249970 | loss: 1.2688 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8710/2499940 | global iter:   4356/1249970 | loss: 1.1541 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8712/2499940 | global iter:   4357/1249970 | loss: 0.8077 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8714/2499940 | global iter:   4358/1249970 | loss: 1.2741 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8716/2499940 | global iter:   4359/1249970 | loss: 1.8194 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8718/2499940 | global iter:   4360/1249970 | loss: 0.0428 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8718/2499940 | global iter:   4360/1249970 | loss: 1.0302 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8720/2499940 | global iter:   4361/1249970 | loss: 0.6449 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8722/2499940 | global iter:   4362/1249970 | loss: 1.7245 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8724/2499940 | global iter:   4363/1249970 | loss: 1.4158 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8726/2499940 | global iter:   4364/1249970 | loss: 1.2381 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8726/2499940 | global iter:   4364/1249970 | loss: 1.2163 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8728/2499940 | global iter:   4365/1249970 | loss: 1.4958 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   8730/2499940 | global iter:   4366/1249970 | loss: 1.6655 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   8732/2499940 | global iter:   4367/1249970 | loss: 0.5884 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.406 | step time: 0.000
train | epoch   0 | Iter:   8734/2499940 | global iter:   4368/1249970 | loss: 1.1664 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8734/2499940 | global iter:   4368/1249970 | loss: 1.2957 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8736/2499940 | global iter:   4369/1249970 | loss: 0.5152 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8738/2499940 | global iter:   4370/1249970 | loss: 0.6996 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   8740/2499940 | global iter:   4371/1249970 | loss: 1.0773 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8742/2499940 | global iter:   4372/1249970 | loss: 1.0414 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8742/2499940 | global iter:   4372/1249970 | loss: 0.9409 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8744/2499940 | global iter:   4373/1249970 | loss: 1.4484 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8746/2499940 | global iter:   4374/1249970 | loss: 1.5523 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8748/2499940 | global iter:   4375/1249970 | loss: 0.8703 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8750/2499940 | global iter:   4376/1249970 | loss: 0.9357 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8750/2499940 | global iter:   4376/1249970 | loss: 1.1555 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8752/2499940 | global iter:   4377/1249970 | loss: 1.6158 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8754/2499940 | global iter:   4378/1249970 | loss: 1.1999 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8756/2499940 | global iter:   4379/1249970 | loss: 1.4214 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8758/2499940 | global iter:   4380/1249970 | loss: 0.8716 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8758/2499940 | global iter:   4380/1249970 | loss: 1.2565 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8760/2499940 | global iter:   4381/1249970 | loss: 1.2203 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8762/2499940 | global iter:   4382/1249970 | loss: 1.1037 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8764/2499940 | global iter:   4383/1249970 | loss: 0.9840 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8766/2499940 | global iter:   4384/1249970 | loss: 1.7484 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8766/2499940 | global iter:   4384/1249970 | loss: 1.3734 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8768/2499940 | global iter:   4385/1249970 | loss: 1.2726 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8770/2499940 | global iter:   4386/1249970 | loss: 0.8750 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   8772/2499940 | global iter:   4387/1249970 | loss: 0.7380 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8774/2499940 | global iter:   4388/1249970 | loss: 2.1993 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8774/2499940 | global iter:   4388/1249970 | loss: 1.3144 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8776/2499940 | global iter:   4389/1249970 | loss: 1.3022 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8778/2499940 | global iter:   4390/1249970 | loss: 1.0283 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8780/2499940 | global iter:   4391/1249970 | loss: 0.6891 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8782/2499940 | global iter:   4392/1249970 | loss: 1.2830 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8782/2499940 | global iter:   4392/1249970 | loss: 1.0327 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8784/2499940 | global iter:   4393/1249970 | loss: 1.9639 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8786/2499940 | global iter:   4394/1249970 | loss: 0.8053 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   8788/2499940 | global iter:   4395/1249970 | loss: 1.6132 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8790/2499940 | global iter:   4396/1249970 | loss: 1.4491 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8790/2499940 | global iter:   4396/1249970 | loss: 1.2869 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8792/2499940 | global iter:   4397/1249970 | loss: 1.4638 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8794/2499940 | global iter:   4398/1249970 | loss: 1.2349 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   8796/2499940 | global iter:   4399/1249970 | loss: 0.5797 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8798/2499940 | global iter:   4400/1249970 | loss: 0.6347 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8798/2499940 | global iter:   4400/1249970 | loss: 1.2429 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8800/2499940 | global iter:   4401/1249970 | loss: 1.4466 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8802/2499940 | global iter:   4402/1249970 | loss: 1.5277 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8804/2499940 | global iter:   4403/1249970 | loss: 0.2144 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   8806/2499940 | global iter:   4404/1249970 | loss: 0.5448 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8806/2499940 | global iter:   4404/1249970 | loss: 1.0391 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8808/2499940 | global iter:   4405/1249970 | loss: 1.5700 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8810/2499940 | global iter:   4406/1249970 | loss: 1.9852 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   8812/2499940 | global iter:   4407/1249970 | loss: 1.7246 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8814/2499940 | global iter:   4408/1249970 | loss: 1.6772 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8814/2499940 | global iter:   4408/1249970 | loss: 1.3119 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8816/2499940 | global iter:   4409/1249970 | loss: 1.4831 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8818/2499940 | global iter:   4410/1249970 | loss: 1.2334 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8820/2499940 | global iter:   4411/1249970 | loss: 1.0202 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8822/2499940 | global iter:   4412/1249970 | loss: 1.6080 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8822/2499940 | global iter:   4412/1249970 | loss: 1.1373 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.695
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8824/2499940 | global iter:   4413/1249970 | loss: 0.9374 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8826/2499940 | global iter:   4414/1249970 | loss: 0.3164 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8828/2499940 | global iter:   4415/1249970 | loss: 0.6559 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8830/2499940 | global iter:   4416/1249970 | loss: 1.3594 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.403 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8830/2499940 | global iter:   4416/1249970 | loss: 1.1596 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.403 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8832/2499940 | global iter:   4417/1249970 | loss: 1.1106 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   8834/2499940 | global iter:   4418/1249970 | loss: 0.6211 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8836/2499940 | global iter:   4419/1249970 | loss: 0.6520 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8838/2499940 | global iter:   4420/1249970 | loss: 0.8137 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8838/2499940 | global iter:   4420/1249970 | loss: 0.9584 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8840/2499940 | global iter:   4421/1249970 | loss: 0.6817 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8842/2499940 | global iter:   4422/1249970 | loss: 1.0665 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8844/2499940 | global iter:   4423/1249970 | loss: 0.6839 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8846/2499940 | global iter:   4424/1249970 | loss: 0.7042 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8846/2499940 | global iter:   4424/1249970 | loss: 1.0072 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8848/2499940 | global iter:   4425/1249970 | loss: 1.5651 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8850/2499940 | global iter:   4426/1249970 | loss: 0.7521 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8852/2499940 | global iter:   4427/1249970 | loss: 1.5795 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8854/2499940 | global iter:   4428/1249970 | loss: 1.3976 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8854/2499940 | global iter:   4428/1249970 | loss: 1.1764 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8856/2499940 | global iter:   4429/1249970 | loss: 1.4574 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8858/2499940 | global iter:   4430/1249970 | loss: 0.6655 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8860/2499940 | global iter:   4431/1249970 | loss: 0.8719 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8862/2499940 | global iter:   4432/1249970 | loss: 1.1143 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8862/2499940 | global iter:   4432/1249970 | loss: 1.0911 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8864/2499940 | global iter:   4433/1249970 | loss: 0.9692 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8866/2499940 | global iter:   4434/1249970 | loss: 0.6833 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8868/2499940 | global iter:   4435/1249970 | loss: 1.9268 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8870/2499940 | global iter:   4436/1249970 | loss: 1.2319 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8870/2499940 | global iter:   4436/1249970 | loss: 1.1409 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8872/2499940 | global iter:   4437/1249970 | loss: 1.4739 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8874/2499940 | global iter:   4438/1249970 | loss: 1.4623 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   8876/2499940 | global iter:   4439/1249970 | loss: 0.8681 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8878/2499940 | global iter:   4440/1249970 | loss: 1.0845 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8878/2499940 | global iter:   4440/1249970 | loss: 1.3074 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8880/2499940 | global iter:   4441/1249970 | loss: 0.6372 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8882/2499940 | global iter:   4442/1249970 | loss: 1.8351 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8884/2499940 | global iter:   4443/1249970 | loss: 1.0541 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8886/2499940 | global iter:   4444/1249970 | loss: 0.9750 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8886/2499940 | global iter:   4444/1249970 | loss: 1.0296 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8888/2499940 | global iter:   4445/1249970 | loss: 1.3588 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8890/2499940 | global iter:   4446/1249970 | loss: 1.2139 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8892/2499940 | global iter:   4447/1249970 | loss: 0.2864 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8894/2499940 | global iter:   4448/1249970 | loss: 1.3286 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8894/2499940 | global iter:   4448/1249970 | loss: 1.0391 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8896/2499940 | global iter:   4449/1249970 | loss: 1.3627 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8898/2499940 | global iter:   4450/1249970 | loss: 1.4858 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   8900/2499940 | global iter:   4451/1249970 | loss: 1.6207 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8902/2499940 | global iter:   4452/1249970 | loss: 0.4104 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8902/2499940 | global iter:   4452/1249970 | loss: 1.0712 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8904/2499940 | global iter:   4453/1249970 | loss: 0.5393 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8906/2499940 | global iter:   4454/1249970 | loss: 0.0253 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.405 | step time: 0.000
train | epoch   0 | Iter:   8908/2499940 | global iter:   4455/1249970 | loss: 1.3364 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8910/2499940 | global iter:   4456/1249970 | loss: 1.3027 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8910/2499940 | global iter:   4456/1249970 | loss: 0.7927 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8912/2499940 | global iter:   4457/1249970 | loss: 0.7780 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8914/2499940 | global iter:   4458/1249970 | loss: 0.7167 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8916/2499940 | global iter:   4459/1249970 | loss: 1.2201 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8918/2499940 | global iter:   4460/1249970 | loss: 1.2717 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8918/2499940 | global iter:   4460/1249970 | loss: 1.1631 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8920/2499940 | global iter:   4461/1249970 | loss: 0.4123 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8922/2499940 | global iter:   4462/1249970 | loss: 1.5139 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8924/2499940 | global iter:   4463/1249970 | loss: 0.7412 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   8926/2499940 | global iter:   4464/1249970 | loss: 1.2119 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8926/2499940 | global iter:   4464/1249970 | loss: 1.1063 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8928/2499940 | global iter:   4465/1249970 | loss: 1.8115 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   8930/2499940 | global iter:   4466/1249970 | loss: 1.1449 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   8932/2499940 | global iter:   4467/1249970 | loss: 1.3110 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8934/2499940 | global iter:   4468/1249970 | loss: 0.8838 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8934/2499940 | global iter:   4468/1249970 | loss: 1.2124 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8936/2499940 | global iter:   4469/1249970 | loss: 0.6607 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8938/2499940 | global iter:   4470/1249970 | loss: 0.6839 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8940/2499940 | global iter:   4471/1249970 | loss: 0.8132 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8942/2499940 | global iter:   4472/1249970 | loss: 0.5239 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8942/2499940 | global iter:   4472/1249970 | loss: 1.0005 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8944/2499940 | global iter:   4473/1249970 | loss: 0.7447 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8946/2499940 | global iter:   4474/1249970 | loss: 1.5113 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   8948/2499940 | global iter:   4475/1249970 | loss: 0.2473 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8950/2499940 | global iter:   4476/1249970 | loss: 2.0848 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8950/2499940 | global iter:   4476/1249970 | loss: 1.0526 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8952/2499940 | global iter:   4477/1249970 | loss: 1.8421 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8954/2499940 | global iter:   4478/1249970 | loss: 1.0130 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   8956/2499940 | global iter:   4479/1249970 | loss: 0.7820 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8958/2499940 | global iter:   4480/1249970 | loss: 0.8075 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8958/2499940 | global iter:   4480/1249970 | loss: 1.0422 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8960/2499940 | global iter:   4481/1249970 | loss: 0.6441 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8962/2499940 | global iter:   4482/1249970 | loss: 1.9663 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8964/2499940 | global iter:   4483/1249970 | loss: 1.5780 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8966/2499940 | global iter:   4484/1249970 | loss: 1.5749 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8966/2499940 | global iter:   4484/1249970 | loss: 1.3041 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8968/2499940 | global iter:   4485/1249970 | loss: 1.4561 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8970/2499940 | global iter:   4486/1249970 | loss: 1.0824 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8972/2499940 | global iter:   4487/1249970 | loss: 1.4103 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8974/2499940 | global iter:   4488/1249970 | loss: 1.2977 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8974/2499940 | global iter:   4488/1249970 | loss: 1.0432 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8976/2499940 | global iter:   4489/1249970 | loss: 0.5578 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8978/2499940 | global iter:   4490/1249970 | loss: 1.1921 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   8980/2499940 | global iter:   4491/1249970 | loss: 1.6143 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8982/2499940 | global iter:   4492/1249970 | loss: 0.7356 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8982/2499940 | global iter:   4492/1249970 | loss: 1.1745 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8984/2499940 | global iter:   4493/1249970 | loss: 0.8084 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8986/2499940 | global iter:   4494/1249970 | loss: 0.8092 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   8988/2499940 | global iter:   4495/1249970 | loss: 0.9953 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   8990/2499940 | global iter:   4496/1249970 | loss: 1.6996 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8990/2499940 | global iter:   4496/1249970 | loss: 1.0981 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   8992/2499940 | global iter:   4497/1249970 | loss: 1.1502 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.406 | step time: 0.000
train | epoch   0 | Iter:   8994/2499940 | global iter:   4498/1249970 | loss: 1.2498 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   8996/2499940 | global iter:   4499/1249970 | loss: 1.1220 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   8998/2499940 | global iter:   4500/1249970 | loss: 1.6068 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8998/2499940 | global iter:   4500/1249970 | loss: 0.9457 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9000/2499940 | global iter:   4501/1249970 | loss: 1.4141 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9002/2499940 | global iter:   4502/1249970 | loss: 1.4412 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9004/2499940 | global iter:   4503/1249970 | loss: 0.9980 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   9006/2499940 | global iter:   4504/1249970 | loss: 0.5568 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9006/2499940 | global iter:   4504/1249970 | loss: 1.2205 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9008/2499940 | global iter:   4505/1249970 | loss: 1.1346 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9010/2499940 | global iter:   4506/1249970 | loss: 0.8306 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9012/2499940 | global iter:   4507/1249970 | loss: 1.4460 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9014/2499940 | global iter:   4508/1249970 | loss: 0.7631 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9014/2499940 | global iter:   4508/1249970 | loss: 1.1043 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9016/2499940 | global iter:   4509/1249970 | loss: 1.4339 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9018/2499940 | global iter:   4510/1249970 | loss: 0.9633 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   9020/2499940 | global iter:   4511/1249970 | loss: 0.3879 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   9022/2499940 | global iter:   4512/1249970 | loss: 0.2875 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9022/2499940 | global iter:   4512/1249970 | loss: 0.9721 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9024/2499940 | global iter:   4513/1249970 | loss: 1.3956 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   9026/2499940 | global iter:   4514/1249970 | loss: 0.7877 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9028/2499940 | global iter:   4515/1249970 | loss: 0.9362 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   9030/2499940 | global iter:   4516/1249970 | loss: 0.4588 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9030/2499940 | global iter:   4516/1249970 | loss: 0.8281 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9032/2499940 | global iter:   4517/1249970 | loss: 0.4697 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9034/2499940 | global iter:   4518/1249970 | loss: 1.2918 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9036/2499940 | global iter:   4519/1249970 | loss: 0.2264 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9038/2499940 | global iter:   4520/1249970 | loss: 1.1302 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9038/2499940 | global iter:   4520/1249970 | loss: 0.9714 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9040/2499940 | global iter:   4521/1249970 | loss: 0.0519 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9042/2499940 | global iter:   4522/1249970 | loss: 1.8365 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9044/2499940 | global iter:   4523/1249970 | loss: 0.7991 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9046/2499940 | global iter:   4524/1249970 | loss: 1.7452 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9046/2499940 | global iter:   4524/1249970 | loss: 1.0172 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9048/2499940 | global iter:   4525/1249970 | loss: 0.9581 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9050/2499940 | global iter:   4526/1249970 | loss: 0.6265 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   9052/2499940 | global iter:   4527/1249970 | loss: 1.7109 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9054/2499940 | global iter:   4528/1249970 | loss: 0.3459 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9054/2499940 | global iter:   4528/1249970 | loss: 1.0458 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9056/2499940 | global iter:   4529/1249970 | loss: 0.6931 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9058/2499940 | global iter:   4530/1249970 | loss: 0.5480 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9060/2499940 | global iter:   4531/1249970 | loss: 0.1614 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9062/2499940 | global iter:   4532/1249970 | loss: 0.8444 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9062/2499940 | global iter:   4532/1249970 | loss: 0.7839 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9064/2499940 | global iter:   4533/1249970 | loss: 0.8053 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9066/2499940 | global iter:   4534/1249970 | loss: 1.3469 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9068/2499940 | global iter:   4535/1249970 | loss: 1.1331 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   9070/2499940 | global iter:   4536/1249970 | loss: 0.4133 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9070/2499940 | global iter:   4536/1249970 | loss: 1.0066 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9072/2499940 | global iter:   4537/1249970 | loss: 1.1421 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9074/2499940 | global iter:   4538/1249970 | loss: 1.6791 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9076/2499940 | global iter:   4539/1249970 | loss: 1.0213 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9078/2499940 | global iter:   4540/1249970 | loss: 1.0913 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9078/2499940 | global iter:   4540/1249970 | loss: 1.0465 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9080/2499940 | global iter:   4541/1249970 | loss: 1.6505 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9082/2499940 | global iter:   4542/1249970 | loss: 1.1055 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9084/2499940 | global iter:   4543/1249970 | loss: 1.1775 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9086/2499940 | global iter:   4544/1249970 | loss: 0.8784 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9086/2499940 | global iter:   4544/1249970 | loss: 1.1937 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9088/2499940 | global iter:   4545/1249970 | loss: 1.3744 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9090/2499940 | global iter:   4546/1249970 | loss: 1.8013 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9092/2499940 | global iter:   4547/1249970 | loss: 0.5416 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9094/2499940 | global iter:   4548/1249970 | loss: 1.5638 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9094/2499940 | global iter:   4548/1249970 | loss: 1.2240 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9096/2499940 | global iter:   4549/1249970 | loss: 1.6298 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9098/2499940 | global iter:   4550/1249970 | loss: 1.5013 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9100/2499940 | global iter:   4551/1249970 | loss: 0.6048 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9102/2499940 | global iter:   4552/1249970 | loss: 0.9679 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9102/2499940 | global iter:   4552/1249970 | loss: 1.0246 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9104/2499940 | global iter:   4553/1249970 | loss: 0.5519 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9106/2499940 | global iter:   4554/1249970 | loss: 0.6488 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9108/2499940 | global iter:   4555/1249970 | loss: 1.7097 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9110/2499940 | global iter:   4556/1249970 | loss: 0.4279 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9110/2499940 | global iter:   4556/1249970 | loss: 0.9110 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9112/2499940 | global iter:   4557/1249970 | loss: 1.8526 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9114/2499940 | global iter:   4558/1249970 | loss: 1.5396 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9116/2499940 | global iter:   4559/1249970 | loss: 1.2430 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9118/2499940 | global iter:   4560/1249970 | loss: 0.6187 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9118/2499940 | global iter:   4560/1249970 | loss: 1.2024 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9120/2499940 | global iter:   4561/1249970 | loss: 1.5969 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9122/2499940 | global iter:   4562/1249970 | loss: 1.3572 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9124/2499940 | global iter:   4563/1249970 | loss: 0.4084 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9126/2499940 | global iter:   4564/1249970 | loss: 1.9905 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9126/2499940 | global iter:   4564/1249970 | loss: 1.3026 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9128/2499940 | global iter:   4565/1249970 | loss: 1.0321 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9130/2499940 | global iter:   4566/1249970 | loss: 1.2542 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   9132/2499940 | global iter:   4567/1249970 | loss: 1.5252 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9134/2499940 | global iter:   4568/1249970 | loss: 0.4808 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9134/2499940 | global iter:   4568/1249970 | loss: 1.2232 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9136/2499940 | global iter:   4569/1249970 | loss: 1.6121 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   9138/2499940 | global iter:   4570/1249970 | loss: 1.3534 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9140/2499940 | global iter:   4571/1249970 | loss: 0.9179 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9142/2499940 | global iter:   4572/1249970 | loss: 1.3356 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9142/2499940 | global iter:   4572/1249970 | loss: 1.4380 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9144/2499940 | global iter:   4573/1249970 | loss: 0.7313 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9146/2499940 | global iter:   4574/1249970 | loss: 1.0753 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   9148/2499940 | global iter:   4575/1249970 | loss: 1.6679 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9150/2499940 | global iter:   4576/1249970 | loss: 0.4615 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9150/2499940 | global iter:   4576/1249970 | loss: 0.8922 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9152/2499940 | global iter:   4577/1249970 | loss: 1.0265 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9154/2499940 | global iter:   4578/1249970 | loss: 0.5000 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   9156/2499940 | global iter:   4579/1249970 | loss: 0.8778 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9158/2499940 | global iter:   4580/1249970 | loss: 0.8733 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9158/2499940 | global iter:   4580/1249970 | loss: 1.0461 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9160/2499940 | global iter:   4581/1249970 | loss: 1.0486 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9162/2499940 | global iter:   4582/1249970 | loss: 0.6966 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9164/2499940 | global iter:   4583/1249970 | loss: 1.2811 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9166/2499940 | global iter:   4584/1249970 | loss: 0.9478 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9166/2499940 | global iter:   4584/1249970 | loss: 1.0288 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9168/2499940 | global iter:   4585/1249970 | loss: 0.9648 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.413 | step time: 0.000
train | epoch   0 | Iter:   9170/2499940 | global iter:   4586/1249970 | loss: 1.3704 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   9172/2499940 | global iter:   4587/1249970 | loss: 1.3353 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   9174/2499940 | global iter:   4588/1249970 | loss: 1.1156 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9174/2499940 | global iter:   4588/1249970 | loss: 1.2583 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9176/2499940 | global iter:   4589/1249970 | loss: 1.5544 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9178/2499940 | global iter:   4590/1249970 | loss: 1.2355 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9180/2499940 | global iter:   4591/1249970 | loss: 1.7754 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   9182/2499940 | global iter:   4592/1249970 | loss: 0.7348 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9182/2499940 | global iter:   4592/1249970 | loss: 1.2813 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9184/2499940 | global iter:   4593/1249970 | loss: 1.3435 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9186/2499940 | global iter:   4594/1249970 | loss: 1.6140 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9188/2499940 | global iter:   4595/1249970 | loss: 1.1453 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9190/2499940 | global iter:   4596/1249970 | loss: 0.2139 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9190/2499940 | global iter:   4596/1249970 | loss: 1.0967 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9192/2499940 | global iter:   4597/1249970 | loss: 1.2761 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9194/2499940 | global iter:   4598/1249970 | loss: 1.7641 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   9196/2499940 | global iter:   4599/1249970 | loss: 1.5920 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9198/2499940 | global iter:   4600/1249970 | loss: 1.0985 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9198/2499940 | global iter:   4600/1249970 | loss: 1.2298 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9200/2499940 | global iter:   4601/1249970 | loss: 1.2124 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9202/2499940 | global iter:   4602/1249970 | loss: 1.0093 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9204/2499940 | global iter:   4603/1249970 | loss: 0.3476 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9206/2499940 | global iter:   4604/1249970 | loss: 1.3400 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9206/2499940 | global iter:   4604/1249970 | loss: 1.1216 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9208/2499940 | global iter:   4605/1249970 | loss: 1.5357 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9210/2499940 | global iter:   4606/1249970 | loss: 1.1505 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9212/2499940 | global iter:   4607/1249970 | loss: 0.4567 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9214/2499940 | global iter:   4608/1249970 | loss: 1.0078 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9214/2499940 | global iter:   4608/1249970 | loss: 1.2782 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9216/2499940 | global iter:   4609/1249970 | loss: 1.3172 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   9218/2499940 | global iter:   4610/1249970 | loss: 1.0559 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9220/2499940 | global iter:   4611/1249970 | loss: 1.4180 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9222/2499940 | global iter:   4612/1249970 | loss: 1.5475 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9222/2499940 | global iter:   4612/1249970 | loss: 1.2481 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9224/2499940 | global iter:   4613/1249970 | loss: 0.5958 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9226/2499940 | global iter:   4614/1249970 | loss: 1.6485 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   9228/2499940 | global iter:   4615/1249970 | loss: 0.5336 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9230/2499940 | global iter:   4616/1249970 | loss: 0.9955 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9230/2499940 | global iter:   4616/1249970 | loss: 0.8244 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9232/2499940 | global iter:   4617/1249970 | loss: 1.6921 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   9234/2499940 | global iter:   4618/1249970 | loss: 0.9476 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   9236/2499940 | global iter:   4619/1249970 | loss: 1.8562 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9238/2499940 | global iter:   4620/1249970 | loss: 1.3687 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9238/2499940 | global iter:   4620/1249970 | loss: 1.3909 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9240/2499940 | global iter:   4621/1249970 | loss: 1.4256 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9242/2499940 | global iter:   4622/1249970 | loss: 1.8744 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9244/2499940 | global iter:   4623/1249970 | loss: 1.3957 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   9246/2499940 | global iter:   4624/1249970 | loss: 1.6683 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9246/2499940 | global iter:   4624/1249970 | loss: 1.3894 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9248/2499940 | global iter:   4625/1249970 | loss: 1.5341 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9250/2499940 | global iter:   4626/1249970 | loss: 0.7653 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9252/2499940 | global iter:   4627/1249970 | loss: 0.6962 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9254/2499940 | global iter:   4628/1249970 | loss: 1.4923 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9254/2499940 | global iter:   4628/1249970 | loss: 0.9607 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9256/2499940 | global iter:   4629/1249970 | loss: 1.2580 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9258/2499940 | global iter:   4630/1249970 | loss: 0.8922 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9260/2499940 | global iter:   4631/1249970 | loss: 1.1900 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9262/2499940 | global iter:   4632/1249970 | loss: 0.0296 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9262/2499940 | global iter:   4632/1249970 | loss: 1.1428 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9264/2499940 | global iter:   4633/1249970 | loss: 1.3264 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9266/2499940 | global iter:   4634/1249970 | loss: 1.2750 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   9268/2499940 | global iter:   4635/1249970 | loss: 1.3913 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9270/2499940 | global iter:   4636/1249970 | loss: 0.4863 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9270/2499940 | global iter:   4636/1249970 | loss: 1.2296 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9272/2499940 | global iter:   4637/1249970 | loss: 1.0238 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   9274/2499940 | global iter:   4638/1249970 | loss: 1.5536 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   9276/2499940 | global iter:   4639/1249970 | loss: 1.3827 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9278/2499940 | global iter:   4640/1249970 | loss: 1.6273 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9278/2499940 | global iter:   4640/1249970 | loss: 1.2541 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9280/2499940 | global iter:   4641/1249970 | loss: 1.2696 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9282/2499940 | global iter:   4642/1249970 | loss: 0.7844 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9284/2499940 | global iter:   4643/1249970 | loss: 0.9544 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9286/2499940 | global iter:   4644/1249970 | loss: 1.2008 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9286/2499940 | global iter:   4644/1249970 | loss: 1.0108 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9288/2499940 | global iter:   4645/1249970 | loss: 0.9091 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9290/2499940 | global iter:   4646/1249970 | loss: 1.1894 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9292/2499940 | global iter:   4647/1249970 | loss: 1.1097 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9294/2499940 | global iter:   4648/1249970 | loss: 1.1869 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9294/2499940 | global iter:   4648/1249970 | loss: 1.1858 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9296/2499940 | global iter:   4649/1249970 | loss: 1.1693 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9298/2499940 | global iter:   4650/1249970 | loss: 2.0669 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9300/2499940 | global iter:   4651/1249970 | loss: 1.2987 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9302/2499940 | global iter:   4652/1249970 | loss: 1.0983 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9302/2499940 | global iter:   4652/1249970 | loss: 1.1914 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9304/2499940 | global iter:   4653/1249970 | loss: 1.7253 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9306/2499940 | global iter:   4654/1249970 | loss: 1.6232 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9308/2499940 | global iter:   4655/1249970 | loss: 0.8040 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9310/2499940 | global iter:   4656/1249970 | loss: 0.6738 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9310/2499940 | global iter:   4656/1249970 | loss: 1.0374 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9312/2499940 | global iter:   4657/1249970 | loss: 0.6006 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   9314/2499940 | global iter:   4658/1249970 | loss: 1.5019 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9316/2499940 | global iter:   4659/1249970 | loss: 1.4676 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9318/2499940 | global iter:   4660/1249970 | loss: 1.9290 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9318/2499940 | global iter:   4660/1249970 | loss: 1.1969 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9320/2499940 | global iter:   4661/1249970 | loss: 1.1369 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9322/2499940 | global iter:   4662/1249970 | loss: 1.2982 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   9324/2499940 | global iter:   4663/1249970 | loss: 1.0673 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9326/2499940 | global iter:   4664/1249970 | loss: 1.4277 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9326/2499940 | global iter:   4664/1249970 | loss: 1.2187 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9328/2499940 | global iter:   4665/1249970 | loss: 1.1876 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9330/2499940 | global iter:   4666/1249970 | loss: 1.1554 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9332/2499940 | global iter:   4667/1249970 | loss: 1.0598 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9334/2499940 | global iter:   4668/1249970 | loss: 1.3552 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9334/2499940 | global iter:   4668/1249970 | loss: 1.2081 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9336/2499940 | global iter:   4669/1249970 | loss: 0.8401 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   9338/2499940 | global iter:   4670/1249970 | loss: 1.3634 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   9340/2499940 | global iter:   4671/1249970 | loss: 0.4108 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   9342/2499940 | global iter:   4672/1249970 | loss: 1.3997 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9342/2499940 | global iter:   4672/1249970 | loss: 1.1821 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9344/2499940 | global iter:   4673/1249970 | loss: 1.0599 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9346/2499940 | global iter:   4674/1249970 | loss: 0.4314 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9348/2499940 | global iter:   4675/1249970 | loss: 0.9272 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   9350/2499940 | global iter:   4676/1249970 | loss: 0.4101 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9350/2499940 | global iter:   4676/1249970 | loss: 0.9145 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9352/2499940 | global iter:   4677/1249970 | loss: 1.4885 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9354/2499940 | global iter:   4678/1249970 | loss: 1.5801 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9356/2499940 | global iter:   4679/1249970 | loss: 1.3712 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   9358/2499940 | global iter:   4680/1249970 | loss: 0.9026 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9358/2499940 | global iter:   4680/1249970 | loss: 1.1654 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9360/2499940 | global iter:   4681/1249970 | loss: 1.4893 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   9362/2499940 | global iter:   4682/1249970 | loss: 1.2019 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9364/2499940 | global iter:   4683/1249970 | loss: 1.4489 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9366/2499940 | global iter:   4684/1249970 | loss: 2.0325 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9366/2499940 | global iter:   4684/1249970 | loss: 1.4993 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9368/2499940 | global iter:   4685/1249970 | loss: 1.6629 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9370/2499940 | global iter:   4686/1249970 | loss: 1.8674 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   9372/2499940 | global iter:   4687/1249970 | loss: 1.2435 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   9374/2499940 | global iter:   4688/1249970 | loss: 1.4049 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9374/2499940 | global iter:   4688/1249970 | loss: 1.4998 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9376/2499940 | global iter:   4689/1249970 | loss: 1.4471 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
[2025-04-20 17:07:33,630] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8192, reducing to 4096
train | epoch   0 | Iter:   9378/2499940 | global iter:   4690/1249970 | loss: 1.2604 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.311 | step time: 0.000
train | epoch   0 | Iter:   9380/2499940 | global iter:   4691/1249970 | loss: 1.1790 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9382/2499940 | global iter:   4692/1249970 | loss: 1.5064 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9382/2499940 | global iter:   4692/1249970 | loss: 1.5549 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.669
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9384/2499940 | global iter:   4693/1249970 | loss: 1.5371 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9386/2499940 | global iter:   4694/1249970 | loss: 1.4146 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9388/2499940 | global iter:   4695/1249970 | loss: 1.4496 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9390/2499940 | global iter:   4696/1249970 | loss: 0.6758 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9390/2499940 | global iter:   4696/1249970 | loss: 1.2278 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9392/2499940 | global iter:   4697/1249970 | loss: 1.2908 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   9394/2499940 | global iter:   4698/1249970 | loss: 0.2568 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   9396/2499940 | global iter:   4699/1249970 | loss: 1.3509 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9398/2499940 | global iter:   4700/1249970 | loss: 1.5085 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9398/2499940 | global iter:   4700/1249970 | loss: 0.9694 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9400/2499940 | global iter:   4701/1249970 | loss: 0.5440 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9402/2499940 | global iter:   4702/1249970 | loss: 0.6696 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9404/2499940 | global iter:   4703/1249970 | loss: 0.1513 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9406/2499940 | global iter:   4704/1249970 | loss: 1.0142 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9406/2499940 | global iter:   4704/1249970 | loss: 0.8524 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9408/2499940 | global iter:   4705/1249970 | loss: 1.3042 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9410/2499940 | global iter:   4706/1249970 | loss: 1.0724 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9412/2499940 | global iter:   4707/1249970 | loss: 0.9255 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9414/2499940 | global iter:   4708/1249970 | loss: 1.4540 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9414/2499940 | global iter:   4708/1249970 | loss: 1.1802 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9416/2499940 | global iter:   4709/1249970 | loss: 0.8496 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9418/2499940 | global iter:   4710/1249970 | loss: 1.4633 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9420/2499940 | global iter:   4711/1249970 | loss: 0.8361 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9422/2499940 | global iter:   4712/1249970 | loss: 1.1322 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9422/2499940 | global iter:   4712/1249970 | loss: 1.0433 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9424/2499940 | global iter:   4713/1249970 | loss: 1.8257 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9426/2499940 | global iter:   4714/1249970 | loss: 1.3221 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.404 | step time: 0.000
train | epoch   0 | Iter:   9428/2499940 | global iter:   4715/1249970 | loss: 1.6322 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.411 | step time: 0.000
train | epoch   0 | Iter:   9430/2499940 | global iter:   4716/1249970 | loss: 0.8627 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9430/2499940 | global iter:   4716/1249970 | loss: 1.2847 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9432/2499940 | global iter:   4717/1249970 | loss: 1.7769 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9434/2499940 | global iter:   4718/1249970 | loss: 0.4569 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9436/2499940 | global iter:   4719/1249970 | loss: 1.8315 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9438/2499940 | global iter:   4720/1249970 | loss: 1.0633 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9438/2499940 | global iter:   4720/1249970 | loss: 1.1704 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9440/2499940 | global iter:   4721/1249970 | loss: 1.7575 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9442/2499940 | global iter:   4722/1249970 | loss: 0.9692 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9444/2499940 | global iter:   4723/1249970 | loss: 0.7527 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9446/2499940 | global iter:   4724/1249970 | loss: 1.4637 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9446/2499940 | global iter:   4724/1249970 | loss: 1.1670 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9448/2499940 | global iter:   4725/1249970 | loss: 1.8323 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9450/2499940 | global iter:   4726/1249970 | loss: 1.1045 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   9452/2499940 | global iter:   4727/1249970 | loss: 1.1763 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9454/2499940 | global iter:   4728/1249970 | loss: 1.4414 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9454/2499940 | global iter:   4728/1249970 | loss: 1.2581 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9456/2499940 | global iter:   4729/1249970 | loss: 0.7432 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9458/2499940 | global iter:   4730/1249970 | loss: 1.0007 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9460/2499940 | global iter:   4731/1249970 | loss: 1.8158 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9462/2499940 | global iter:   4732/1249970 | loss: 0.4084 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9462/2499940 | global iter:   4732/1249970 | loss: 0.9028 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9464/2499940 | global iter:   4733/1249970 | loss: 0.8940 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9466/2499940 | global iter:   4734/1249970 | loss: 0.4221 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9468/2499940 | global iter:   4735/1249970 | loss: 1.3643 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9470/2499940 | global iter:   4736/1249970 | loss: 0.0903 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9470/2499940 | global iter:   4736/1249970 | loss: 0.8305 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9472/2499940 | global iter:   4737/1249970 | loss: 0.9659 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9474/2499940 | global iter:   4738/1249970 | loss: 0.9990 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9476/2499940 | global iter:   4739/1249970 | loss: 0.5371 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9478/2499940 | global iter:   4740/1249970 | loss: 1.0684 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9478/2499940 | global iter:   4740/1249970 | loss: 1.0660 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9480/2499940 | global iter:   4741/1249970 | loss: 0.9646 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9482/2499940 | global iter:   4742/1249970 | loss: 0.6451 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9484/2499940 | global iter:   4743/1249970 | loss: 0.9030 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9486/2499940 | global iter:   4744/1249970 | loss: 1.0852 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9486/2499940 | global iter:   4744/1249970 | loss: 0.7864 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9488/2499940 | global iter:   4745/1249970 | loss: 1.7580 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9490/2499940 | global iter:   4746/1249970 | loss: 1.1023 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9492/2499940 | global iter:   4747/1249970 | loss: 0.7075 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9494/2499940 | global iter:   4748/1249970 | loss: 0.8847 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9494/2499940 | global iter:   4748/1249970 | loss: 0.9956 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9496/2499940 | global iter:   4749/1249970 | loss: 0.7615 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9498/2499940 | global iter:   4750/1249970 | loss: 0.8492 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9500/2499940 | global iter:   4751/1249970 | loss: 1.3442 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9502/2499940 | global iter:   4752/1249970 | loss: 1.6170 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9502/2499940 | global iter:   4752/1249970 | loss: 1.1881 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9504/2499940 | global iter:   4753/1249970 | loss: 0.5728 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9506/2499940 | global iter:   4754/1249970 | loss: 1.1859 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9508/2499940 | global iter:   4755/1249970 | loss: 1.5485 | ds_loss: 0.0000 | lr: 9.9997e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9510/2499940 | global iter:   4756/1249970 | loss: 1.0995 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9510/2499940 | global iter:   4756/1249970 | loss: 0.9398 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9512/2499940 | global iter:   4757/1249970 | loss: 1.9123 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9514/2499940 | global iter:   4758/1249970 | loss: 1.5951 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9516/2499940 | global iter:   4759/1249970 | loss: 0.8315 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9518/2499940 | global iter:   4760/1249970 | loss: 1.0116 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9518/2499940 | global iter:   4760/1249970 | loss: 1.2056 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9520/2499940 | global iter:   4761/1249970 | loss: 1.3046 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9522/2499940 | global iter:   4762/1249970 | loss: 1.3594 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9524/2499940 | global iter:   4763/1249970 | loss: 0.7494 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9526/2499940 | global iter:   4764/1249970 | loss: 1.2871 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9526/2499940 | global iter:   4764/1249970 | loss: 1.2981 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9528/2499940 | global iter:   4765/1249970 | loss: 1.3130 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9530/2499940 | global iter:   4766/1249970 | loss: 0.9932 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9532/2499940 | global iter:   4767/1249970 | loss: 0.9576 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9534/2499940 | global iter:   4768/1249970 | loss: 0.4199 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9534/2499940 | global iter:   4768/1249970 | loss: 0.8539 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9536/2499940 | global iter:   4769/1249970 | loss: 0.5210 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9538/2499940 | global iter:   4770/1249970 | loss: 0.7222 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   9540/2499940 | global iter:   4771/1249970 | loss: 0.6476 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9542/2499940 | global iter:   4772/1249970 | loss: 1.1257 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9542/2499940 | global iter:   4772/1249970 | loss: 0.9607 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9544/2499940 | global iter:   4773/1249970 | loss: 0.9719 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9546/2499940 | global iter:   4774/1249970 | loss: 1.0211 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9548/2499940 | global iter:   4775/1249970 | loss: 0.8209 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9550/2499940 | global iter:   4776/1249970 | loss: 0.4090 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9550/2499940 | global iter:   4776/1249970 | loss: 0.7828 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9552/2499940 | global iter:   4777/1249970 | loss: 0.9498 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9554/2499940 | global iter:   4778/1249970 | loss: 0.8075 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9556/2499940 | global iter:   4779/1249970 | loss: 1.1101 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9558/2499940 | global iter:   4780/1249970 | loss: 1.6416 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9558/2499940 | global iter:   4780/1249970 | loss: 1.0672 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9560/2499940 | global iter:   4781/1249970 | loss: 1.2443 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9562/2499940 | global iter:   4782/1249970 | loss: 1.9621 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9564/2499940 | global iter:   4783/1249970 | loss: 1.5356 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9566/2499940 | global iter:   4784/1249970 | loss: 1.2350 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9566/2499940 | global iter:   4784/1249970 | loss: 1.3589 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9568/2499940 | global iter:   4785/1249970 | loss: 0.7431 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9570/2499940 | global iter:   4786/1249970 | loss: 1.3129 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   9572/2499940 | global iter:   4787/1249970 | loss: 1.0481 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9574/2499940 | global iter:   4788/1249970 | loss: 1.2492 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9574/2499940 | global iter:   4788/1249970 | loss: 1.0221 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9576/2499940 | global iter:   4789/1249970 | loss: 1.5154 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9578/2499940 | global iter:   4790/1249970 | loss: 0.9782 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9580/2499940 | global iter:   4791/1249970 | loss: 0.1398 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9582/2499940 | global iter:   4792/1249970 | loss: 0.2638 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9582/2499940 | global iter:   4792/1249970 | loss: 0.8870 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9584/2499940 | global iter:   4793/1249970 | loss: 1.0178 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9586/2499940 | global iter:   4794/1249970 | loss: 0.5572 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9588/2499940 | global iter:   4795/1249970 | loss: 1.4496 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9590/2499940 | global iter:   4796/1249970 | loss: 1.3777 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9590/2499940 | global iter:   4796/1249970 | loss: 0.8605 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9592/2499940 | global iter:   4797/1249970 | loss: 1.3383 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9594/2499940 | global iter:   4798/1249970 | loss: 0.3974 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9596/2499940 | global iter:   4799/1249970 | loss: 0.6611 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9598/2499940 | global iter:   4800/1249970 | loss: 1.0368 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9598/2499940 | global iter:   4800/1249970 | loss: 0.7835 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9600/2499940 | global iter:   4801/1249970 | loss: 1.0294 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9602/2499940 | global iter:   4802/1249970 | loss: 0.6167 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.410 | step time: 0.000
train | epoch   0 | Iter:   9604/2499940 | global iter:   4803/1249970 | loss: 1.0052 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9606/2499940 | global iter:   4804/1249970 | loss: 1.2792 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9606/2499940 | global iter:   4804/1249970 | loss: 1.0968 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9608/2499940 | global iter:   4805/1249970 | loss: 1.2594 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9610/2499940 | global iter:   4806/1249970 | loss: 0.9868 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9612/2499940 | global iter:   4807/1249970 | loss: 0.3569 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9614/2499940 | global iter:   4808/1249970 | loss: 0.7190 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9614/2499940 | global iter:   4808/1249970 | loss: 0.9748 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9616/2499940 | global iter:   4809/1249970 | loss: 1.2610 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9618/2499940 | global iter:   4810/1249970 | loss: 1.0558 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9620/2499940 | global iter:   4811/1249970 | loss: 1.4727 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9622/2499940 | global iter:   4812/1249970 | loss: 1.4887 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9622/2499940 | global iter:   4812/1249970 | loss: 1.1854 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9624/2499940 | global iter:   4813/1249970 | loss: 0.6018 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9626/2499940 | global iter:   4814/1249970 | loss: 0.6954 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9628/2499940 | global iter:   4815/1249970 | loss: 1.3098 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9630/2499940 | global iter:   4816/1249970 | loss: 0.8027 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9630/2499940 | global iter:   4816/1249970 | loss: 1.0514 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9632/2499940 | global iter:   4817/1249970 | loss: 0.1304 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9634/2499940 | global iter:   4818/1249970 | loss: 1.3041 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9636/2499940 | global iter:   4819/1249970 | loss: 1.3393 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9638/2499940 | global iter:   4820/1249970 | loss: 0.7202 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9638/2499940 | global iter:   4820/1249970 | loss: 1.0474 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9640/2499940 | global iter:   4821/1249970 | loss: 1.5012 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9642/2499940 | global iter:   4822/1249970 | loss: 0.7148 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9644/2499940 | global iter:   4823/1249970 | loss: 1.3447 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9646/2499940 | global iter:   4824/1249970 | loss: 0.9286 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9646/2499940 | global iter:   4824/1249970 | loss: 1.1518 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9648/2499940 | global iter:   4825/1249970 | loss: 1.3857 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9650/2499940 | global iter:   4826/1249970 | loss: 1.3259 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9652/2499940 | global iter:   4827/1249970 | loss: 0.6340 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9654/2499940 | global iter:   4828/1249970 | loss: 1.5086 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9654/2499940 | global iter:   4828/1249970 | loss: 1.1557 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9656/2499940 | global iter:   4829/1249970 | loss: 1.1790 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9658/2499940 | global iter:   4830/1249970 | loss: 1.6029 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9660/2499940 | global iter:   4831/1249970 | loss: 0.4127 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9662/2499940 | global iter:   4832/1249970 | loss: 0.8429 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9662/2499940 | global iter:   4832/1249970 | loss: 1.0142 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9664/2499940 | global iter:   4833/1249970 | loss: 1.1200 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9666/2499940 | global iter:   4834/1249970 | loss: 1.3491 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9668/2499940 | global iter:   4835/1249970 | loss: 0.9512 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9670/2499940 | global iter:   4836/1249970 | loss: 1.9634 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9670/2499940 | global iter:   4836/1249970 | loss: 1.1314 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9672/2499940 | global iter:   4837/1249970 | loss: 1.3984 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9674/2499940 | global iter:   4838/1249970 | loss: 0.7495 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   9676/2499940 | global iter:   4839/1249970 | loss: 0.4181 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9678/2499940 | global iter:   4840/1249970 | loss: 1.5253 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9678/2499940 | global iter:   4840/1249970 | loss: 1.1912 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9680/2499940 | global iter:   4841/1249970 | loss: 0.1706 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9682/2499940 | global iter:   4842/1249970 | loss: 1.4693 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   9684/2499940 | global iter:   4843/1249970 | loss: 0.6061 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9686/2499940 | global iter:   4844/1249970 | loss: 1.1891 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9686/2499940 | global iter:   4844/1249970 | loss: 1.0912 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9688/2499940 | global iter:   4845/1249970 | loss: 1.7638 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9690/2499940 | global iter:   4846/1249970 | loss: 1.7150 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9692/2499940 | global iter:   4847/1249970 | loss: 0.2369 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9694/2499940 | global iter:   4848/1249970 | loss: 2.1202 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9694/2499940 | global iter:   4848/1249970 | loss: 1.1532 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9696/2499940 | global iter:   4849/1249970 | loss: 0.8470 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9698/2499940 | global iter:   4850/1249970 | loss: 1.6245 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:   9700/2499940 | global iter:   4851/1249970 | loss: 1.5688 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9702/2499940 | global iter:   4852/1249970 | loss: 1.0535 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9702/2499940 | global iter:   4852/1249970 | loss: 1.3565 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9704/2499940 | global iter:   4853/1249970 | loss: 1.2642 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9706/2499940 | global iter:   4854/1249970 | loss: 0.9473 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9708/2499940 | global iter:   4855/1249970 | loss: 0.7631 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9710/2499940 | global iter:   4856/1249970 | loss: 0.9700 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9710/2499940 | global iter:   4856/1249970 | loss: 1.0592 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9712/2499940 | global iter:   4857/1249970 | loss: 0.7978 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9714/2499940 | global iter:   4858/1249970 | loss: 1.7523 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   9716/2499940 | global iter:   4859/1249970 | loss: 0.4378 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9718/2499940 | global iter:   4860/1249970 | loss: 1.0483 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9718/2499940 | global iter:   4860/1249970 | loss: 1.0367 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9720/2499940 | global iter:   4861/1249970 | loss: 0.6523 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9722/2499940 | global iter:   4862/1249970 | loss: 0.3376 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9724/2499940 | global iter:   4863/1249970 | loss: 0.9525 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9726/2499940 | global iter:   4864/1249970 | loss: 0.7489 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9726/2499940 | global iter:   4864/1249970 | loss: 0.8812 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9728/2499940 | global iter:   4865/1249970 | loss: 0.7544 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9730/2499940 | global iter:   4866/1249970 | loss: 1.0893 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9732/2499940 | global iter:   4867/1249970 | loss: 1.1591 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9734/2499940 | global iter:   4868/1249970 | loss: 1.3856 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9734/2499940 | global iter:   4868/1249970 | loss: 1.2082 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9736/2499940 | global iter:   4869/1249970 | loss: 0.8115 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9738/2499940 | global iter:   4870/1249970 | loss: 1.6224 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9740/2499940 | global iter:   4871/1249970 | loss: 0.9165 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9742/2499940 | global iter:   4872/1249970 | loss: 1.0791 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9742/2499940 | global iter:   4872/1249970 | loss: 1.2360 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9744/2499940 | global iter:   4873/1249970 | loss: 0.2483 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9746/2499940 | global iter:   4874/1249970 | loss: 1.0062 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9748/2499940 | global iter:   4875/1249970 | loss: 1.9997 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9750/2499940 | global iter:   4876/1249970 | loss: 1.4234 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9750/2499940 | global iter:   4876/1249970 | loss: 1.0989 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9752/2499940 | global iter:   4877/1249970 | loss: 1.2166 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9754/2499940 | global iter:   4878/1249970 | loss: 0.3310 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.391 | step time: 0.000
train | epoch   0 | Iter:   9756/2499940 | global iter:   4879/1249970 | loss: 0.7594 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9758/2499940 | global iter:   4880/1249970 | loss: 1.4416 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9758/2499940 | global iter:   4880/1249970 | loss: 0.9498 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9760/2499940 | global iter:   4881/1249970 | loss: 1.2917 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9762/2499940 | global iter:   4882/1249970 | loss: 0.6975 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9764/2499940 | global iter:   4883/1249970 | loss: 1.6218 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9766/2499940 | global iter:   4884/1249970 | loss: 0.8463 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9766/2499940 | global iter:   4884/1249970 | loss: 0.8059 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9768/2499940 | global iter:   4885/1249970 | loss: 1.4185 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9770/2499940 | global iter:   4886/1249970 | loss: 0.7425 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.392 | step time: 0.000
train | epoch   0 | Iter:   9772/2499940 | global iter:   4887/1249970 | loss: 1.6609 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9774/2499940 | global iter:   4888/1249970 | loss: 0.7521 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.408 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9774/2499940 | global iter:   4888/1249970 | loss: 1.1496 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.408 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9776/2499940 | global iter:   4889/1249970 | loss: 1.5189 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9778/2499940 | global iter:   4890/1249970 | loss: 0.9498 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9780/2499940 | global iter:   4891/1249970 | loss: 0.3259 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9782/2499940 | global iter:   4892/1249970 | loss: 0.8401 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9782/2499940 | global iter:   4892/1249970 | loss: 0.8510 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9784/2499940 | global iter:   4893/1249970 | loss: 0.0228 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9786/2499940 | global iter:   4894/1249970 | loss: 0.2330 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   9788/2499940 | global iter:   4895/1249970 | loss: 0.9675 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9790/2499940 | global iter:   4896/1249970 | loss: 0.6552 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9790/2499940 | global iter:   4896/1249970 | loss: 0.6117 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9792/2499940 | global iter:   4897/1249970 | loss: 1.1404 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9794/2499940 | global iter:   4898/1249970 | loss: 0.9699 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   9796/2499940 | global iter:   4899/1249970 | loss: 1.2477 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9798/2499940 | global iter:   4900/1249970 | loss: 0.8897 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9798/2499940 | global iter:   4900/1249970 | loss: 1.3109 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9800/2499940 | global iter:   4901/1249970 | loss: 1.1479 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9802/2499940 | global iter:   4902/1249970 | loss: 1.3624 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   9804/2499940 | global iter:   4903/1249970 | loss: 1.2215 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9806/2499940 | global iter:   4904/1249970 | loss: 0.6472 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9806/2499940 | global iter:   4904/1249970 | loss: 1.2546 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9808/2499940 | global iter:   4905/1249970 | loss: 1.8270 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9810/2499940 | global iter:   4906/1249970 | loss: 1.1074 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.392 | step time: 0.000
train | epoch   0 | Iter:   9812/2499940 | global iter:   4907/1249970 | loss: 0.7334 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9814/2499940 | global iter:   4908/1249970 | loss: 0.7728 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9814/2499940 | global iter:   4908/1249970 | loss: 0.9961 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9816/2499940 | global iter:   4909/1249970 | loss: 0.1141 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9818/2499940 | global iter:   4910/1249970 | loss: 1.3218 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:   9820/2499940 | global iter:   4911/1249970 | loss: 2.2260 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9822/2499940 | global iter:   4912/1249970 | loss: 1.1648 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9822/2499940 | global iter:   4912/1249970 | loss: 1.2257 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9824/2499940 | global iter:   4913/1249970 | loss: 1.7642 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9826/2499940 | global iter:   4914/1249970 | loss: 1.2871 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9828/2499940 | global iter:   4915/1249970 | loss: 1.9906 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9830/2499940 | global iter:   4916/1249970 | loss: 1.0856 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9830/2499940 | global iter:   4916/1249970 | loss: 1.2556 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9832/2499940 | global iter:   4917/1249970 | loss: 1.6108 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9834/2499940 | global iter:   4918/1249970 | loss: 2.1314 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:   9836/2499940 | global iter:   4919/1249970 | loss: 0.3018 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9838/2499940 | global iter:   4920/1249970 | loss: 1.1344 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9838/2499940 | global iter:   4920/1249970 | loss: 1.1504 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9840/2499940 | global iter:   4921/1249970 | loss: 1.5709 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:   9842/2499940 | global iter:   4922/1249970 | loss: 1.4077 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9844/2499940 | global iter:   4923/1249970 | loss: 0.6651 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   9846/2499940 | global iter:   4924/1249970 | loss: 0.8417 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9846/2499940 | global iter:   4924/1249970 | loss: 1.1266 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9848/2499940 | global iter:   4925/1249970 | loss: 1.5189 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9850/2499940 | global iter:   4926/1249970 | loss: 1.3423 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9852/2499940 | global iter:   4927/1249970 | loss: 0.6936 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9854/2499940 | global iter:   4928/1249970 | loss: 0.0796 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9854/2499940 | global iter:   4928/1249970 | loss: 1.0272 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9856/2499940 | global iter:   4929/1249970 | loss: 1.0230 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9858/2499940 | global iter:   4930/1249970 | loss: 1.1084 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   9860/2499940 | global iter:   4931/1249970 | loss: 0.8245 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9862/2499940 | global iter:   4932/1249970 | loss: 1.2566 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.406 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9862/2499940 | global iter:   4932/1249970 | loss: 1.0271 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.406 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9864/2499940 | global iter:   4933/1249970 | loss: 1.4675 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9866/2499940 | global iter:   4934/1249970 | loss: 1.3383 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   9868/2499940 | global iter:   4935/1249970 | loss: 1.0924 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9870/2499940 | global iter:   4936/1249970 | loss: 1.1628 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9870/2499940 | global iter:   4936/1249970 | loss: 1.3084 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9872/2499940 | global iter:   4937/1249970 | loss: 1.0943 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   9874/2499940 | global iter:   4938/1249970 | loss: 1.2126 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9876/2499940 | global iter:   4939/1249970 | loss: 0.7568 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9878/2499940 | global iter:   4940/1249970 | loss: 0.9014 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9878/2499940 | global iter:   4940/1249970 | loss: 0.9724 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9880/2499940 | global iter:   4941/1249970 | loss: 0.6667 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9882/2499940 | global iter:   4942/1249970 | loss: 0.7824 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   9884/2499940 | global iter:   4943/1249970 | loss: 1.4791 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9886/2499940 | global iter:   4944/1249970 | loss: 1.0421 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9886/2499940 | global iter:   4944/1249970 | loss: 0.9202 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9888/2499940 | global iter:   4945/1249970 | loss: 1.3738 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9890/2499940 | global iter:   4946/1249970 | loss: 1.4335 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9892/2499940 | global iter:   4947/1249970 | loss: 1.8079 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9894/2499940 | global iter:   4948/1249970 | loss: 0.5757 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9894/2499940 | global iter:   4948/1249970 | loss: 1.1441 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9896/2499940 | global iter:   4949/1249970 | loss: 1.1325 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9898/2499940 | global iter:   4950/1249970 | loss: 1.5605 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9900/2499940 | global iter:   4951/1249970 | loss: 0.6599 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9902/2499940 | global iter:   4952/1249970 | loss: 0.8820 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9902/2499940 | global iter:   4952/1249970 | loss: 0.9488 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9904/2499940 | global iter:   4953/1249970 | loss: 1.0548 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9906/2499940 | global iter:   4954/1249970 | loss: 0.5707 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:   9908/2499940 | global iter:   4955/1249970 | loss: 0.9880 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9910/2499940 | global iter:   4956/1249970 | loss: 1.6781 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9910/2499940 | global iter:   4956/1249970 | loss: 1.1049 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9912/2499940 | global iter:   4957/1249970 | loss: 1.0922 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9914/2499940 | global iter:   4958/1249970 | loss: 1.4043 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9916/2499940 | global iter:   4959/1249970 | loss: 1.4691 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9918/2499940 | global iter:   4960/1249970 | loss: 1.2488 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9918/2499940 | global iter:   4960/1249970 | loss: 1.2876 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9920/2499940 | global iter:   4961/1249970 | loss: 1.5919 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9922/2499940 | global iter:   4962/1249970 | loss: 0.8278 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9924/2499940 | global iter:   4963/1249970 | loss: 1.2452 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9926/2499940 | global iter:   4964/1249970 | loss: 0.8311 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9926/2499940 | global iter:   4964/1249970 | loss: 0.9896 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9928/2499940 | global iter:   4965/1249970 | loss: 1.3889 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9930/2499940 | global iter:   4966/1249970 | loss: 1.1032 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   9932/2499940 | global iter:   4967/1249970 | loss: 0.7387 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9934/2499940 | global iter:   4968/1249970 | loss: 1.4646 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9934/2499940 | global iter:   4968/1249970 | loss: 1.2805 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9936/2499940 | global iter:   4969/1249970 | loss: 1.1850 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9938/2499940 | global iter:   4970/1249970 | loss: 0.7708 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9940/2499940 | global iter:   4971/1249970 | loss: 1.7969 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9942/2499940 | global iter:   4972/1249970 | loss: 0.9232 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9942/2499940 | global iter:   4972/1249970 | loss: 1.1722 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9944/2499940 | global iter:   4973/1249970 | loss: 1.6036 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9946/2499940 | global iter:   4974/1249970 | loss: 1.2469 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9948/2499940 | global iter:   4975/1249970 | loss: 1.1799 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:   9950/2499940 | global iter:   4976/1249970 | loss: 0.7756 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9950/2499940 | global iter:   4976/1249970 | loss: 1.0149 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9952/2499940 | global iter:   4977/1249970 | loss: 0.6041 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9954/2499940 | global iter:   4978/1249970 | loss: 1.1767 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9956/2499940 | global iter:   4979/1249970 | loss: 1.4547 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9958/2499940 | global iter:   4980/1249970 | loss: 1.2109 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9958/2499940 | global iter:   4980/1249970 | loss: 1.0827 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9960/2499940 | global iter:   4981/1249970 | loss: 1.5359 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9962/2499940 | global iter:   4982/1249970 | loss: 1.5246 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9964/2499940 | global iter:   4983/1249970 | loss: 1.6674 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9966/2499940 | global iter:   4984/1249970 | loss: 1.0932 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9966/2499940 | global iter:   4984/1249970 | loss: 1.3494 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9968/2499940 | global iter:   4985/1249970 | loss: 1.3423 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9970/2499940 | global iter:   4986/1249970 | loss: 0.6193 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9972/2499940 | global iter:   4987/1249970 | loss: 1.3844 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:   9974/2499940 | global iter:   4988/1249970 | loss: 0.9744 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9974/2499940 | global iter:   4988/1249970 | loss: 1.0181 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9976/2499940 | global iter:   4989/1249970 | loss: 0.8416 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9978/2499940 | global iter:   4990/1249970 | loss: 0.1530 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:   9980/2499940 | global iter:   4991/1249970 | loss: 1.1234 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9982/2499940 | global iter:   4992/1249970 | loss: 1.2229 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9982/2499940 | global iter:   4992/1249970 | loss: 1.1873 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9984/2499940 | global iter:   4993/1249970 | loss: 0.9242 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9986/2499940 | global iter:   4994/1249970 | loss: 0.9489 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:   9988/2499940 | global iter:   4995/1249970 | loss: 1.4372 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9990/2499940 | global iter:   4996/1249970 | loss: 1.5165 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9990/2499940 | global iter:   4996/1249970 | loss: 1.2576 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:   9992/2499940 | global iter:   4997/1249970 | loss: 0.7601 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9994/2499940 | global iter:   4998/1249970 | loss: 1.2868 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:   9996/2499940 | global iter:   4999/1249970 | loss: 1.3933 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:   9998/2499940 | global iter:   5000/1249970 | loss: 1.6526 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   9998/2499940 | global iter:   5000/1249970 | loss: 1.0128 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10000/2499940 | global iter:   5001/1249970 | loss: 1.2878 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10002/2499940 | global iter:   5002/1249970 | loss: 1.5565 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10004/2499940 | global iter:   5003/1249970 | loss: 0.9969 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10006/2499940 | global iter:   5004/1249970 | loss: 1.6384 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10006/2499940 | global iter:   5004/1249970 | loss: 1.1293 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10008/2499940 | global iter:   5005/1249970 | loss: 1.4309 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10010/2499940 | global iter:   5006/1249970 | loss: 0.3424 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10012/2499940 | global iter:   5007/1249970 | loss: 1.3774 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10014/2499940 | global iter:   5008/1249970 | loss: 1.0531 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10014/2499940 | global iter:   5008/1249970 | loss: 0.9931 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10016/2499940 | global iter:   5009/1249970 | loss: 1.3549 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10018/2499940 | global iter:   5010/1249970 | loss: 1.1865 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10020/2499940 | global iter:   5011/1249970 | loss: 1.4298 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  10022/2499940 | global iter:   5012/1249970 | loss: 0.9946 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10022/2499940 | global iter:   5012/1249970 | loss: 1.1171 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10024/2499940 | global iter:   5013/1249970 | loss: 1.0674 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  10026/2499940 | global iter:   5014/1249970 | loss: 1.8409 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10028/2499940 | global iter:   5015/1249970 | loss: 0.8595 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10030/2499940 | global iter:   5016/1249970 | loss: 1.5581 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10030/2499940 | global iter:   5016/1249970 | loss: 1.2031 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10032/2499940 | global iter:   5017/1249970 | loss: 0.0120 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10034/2499940 | global iter:   5018/1249970 | loss: 1.3141 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10036/2499940 | global iter:   5019/1249970 | loss: 1.9107 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10038/2499940 | global iter:   5020/1249970 | loss: 0.8597 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10038/2499940 | global iter:   5020/1249970 | loss: 0.8680 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10040/2499940 | global iter:   5021/1249970 | loss: 0.9691 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10042/2499940 | global iter:   5022/1249970 | loss: 1.0159 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  10044/2499940 | global iter:   5023/1249970 | loss: 0.9788 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10046/2499940 | global iter:   5024/1249970 | loss: 1.3462 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10046/2499940 | global iter:   5024/1249970 | loss: 1.0007 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10048/2499940 | global iter:   5025/1249970 | loss: 0.8915 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10050/2499940 | global iter:   5026/1249970 | loss: 0.8557 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10052/2499940 | global iter:   5027/1249970 | loss: 1.1812 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10054/2499940 | global iter:   5028/1249970 | loss: 0.8138 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10054/2499940 | global iter:   5028/1249970 | loss: 0.9855 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10056/2499940 | global iter:   5029/1249970 | loss: 0.8637 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10058/2499940 | global iter:   5030/1249970 | loss: 1.0447 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  10060/2499940 | global iter:   5031/1249970 | loss: 0.8483 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10062/2499940 | global iter:   5032/1249970 | loss: 0.8315 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10062/2499940 | global iter:   5032/1249970 | loss: 1.0171 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10064/2499940 | global iter:   5033/1249970 | loss: 1.4327 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10066/2499940 | global iter:   5034/1249970 | loss: 1.0313 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10068/2499940 | global iter:   5035/1249970 | loss: 0.9363 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10070/2499940 | global iter:   5036/1249970 | loss: 1.0895 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10070/2499940 | global iter:   5036/1249970 | loss: 1.2131 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10072/2499940 | global iter:   5037/1249970 | loss: 1.7245 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10074/2499940 | global iter:   5038/1249970 | loss: 1.1904 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  10076/2499940 | global iter:   5039/1249970 | loss: 1.0353 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10078/2499940 | global iter:   5040/1249970 | loss: 0.8795 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10078/2499940 | global iter:   5040/1249970 | loss: 1.2294 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10080/2499940 | global iter:   5041/1249970 | loss: 0.7512 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  10082/2499940 | global iter:   5042/1249970 | loss: 1.2254 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:  10084/2499940 | global iter:   5043/1249970 | loss: 1.1103 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10086/2499940 | global iter:   5044/1249970 | loss: 0.7214 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10086/2499940 | global iter:   5044/1249970 | loss: 0.7464 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10088/2499940 | global iter:   5045/1249970 | loss: 0.8951 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  10090/2499940 | global iter:   5046/1249970 | loss: 1.4582 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10092/2499940 | global iter:   5047/1249970 | loss: 0.6400 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10094/2499940 | global iter:   5048/1249970 | loss: 0.4696 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10094/2499940 | global iter:   5048/1249970 | loss: 1.0312 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10096/2499940 | global iter:   5049/1249970 | loss: 1.7127 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10098/2499940 | global iter:   5050/1249970 | loss: 1.0796 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10100/2499940 | global iter:   5051/1249970 | loss: 1.2993 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10102/2499940 | global iter:   5052/1249970 | loss: 1.3241 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10102/2499940 | global iter:   5052/1249970 | loss: 1.3828 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10104/2499940 | global iter:   5053/1249970 | loss: 1.2570 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10106/2499940 | global iter:   5054/1249970 | loss: 1.2752 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10108/2499940 | global iter:   5055/1249970 | loss: 1.3628 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10110/2499940 | global iter:   5056/1249970 | loss: 1.2585 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10110/2499940 | global iter:   5056/1249970 | loss: 1.1617 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10112/2499940 | global iter:   5057/1249970 | loss: 1.1258 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10114/2499940 | global iter:   5058/1249970 | loss: 1.2559 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10116/2499940 | global iter:   5059/1249970 | loss: 1.1312 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10118/2499940 | global iter:   5060/1249970 | loss: 1.3005 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10118/2499940 | global iter:   5060/1249970 | loss: 1.0360 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10120/2499940 | global iter:   5061/1249970 | loss: 2.0779 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  10122/2499940 | global iter:   5062/1249970 | loss: 0.4061 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10124/2499940 | global iter:   5063/1249970 | loss: 0.9765 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10126/2499940 | global iter:   5064/1249970 | loss: 1.3828 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10126/2499940 | global iter:   5064/1249970 | loss: 1.2889 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10128/2499940 | global iter:   5065/1249970 | loss: 1.2361 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10130/2499940 | global iter:   5066/1249970 | loss: 1.2391 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10132/2499940 | global iter:   5067/1249970 | loss: 1.7846 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10134/2499940 | global iter:   5068/1249970 | loss: 0.6539 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10134/2499940 | global iter:   5068/1249970 | loss: 1.2097 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10136/2499940 | global iter:   5069/1249970 | loss: 1.1718 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  10138/2499940 | global iter:   5070/1249970 | loss: 0.6362 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  10140/2499940 | global iter:   5071/1249970 | loss: 0.7841 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10142/2499940 | global iter:   5072/1249970 | loss: 0.5233 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10142/2499940 | global iter:   5072/1249970 | loss: 1.0495 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10144/2499940 | global iter:   5073/1249970 | loss: 1.5738 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10146/2499940 | global iter:   5074/1249970 | loss: 1.2856 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10148/2499940 | global iter:   5075/1249970 | loss: 1.7897 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  10150/2499940 | global iter:   5076/1249970 | loss: 1.1126 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10150/2499940 | global iter:   5076/1249970 | loss: 1.1301 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10152/2499940 | global iter:   5077/1249970 | loss: 0.2847 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10154/2499940 | global iter:   5078/1249970 | loss: 0.5675 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  10156/2499940 | global iter:   5079/1249970 | loss: 0.9656 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10158/2499940 | global iter:   5080/1249970 | loss: 1.0772 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10158/2499940 | global iter:   5080/1249970 | loss: 0.8660 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10160/2499940 | global iter:   5081/1249970 | loss: 0.8342 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10162/2499940 | global iter:   5082/1249970 | loss: 1.6306 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10164/2499940 | global iter:   5083/1249970 | loss: 0.7328 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10166/2499940 | global iter:   5084/1249970 | loss: 0.8435 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10166/2499940 | global iter:   5084/1249970 | loss: 1.2009 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10168/2499940 | global iter:   5085/1249970 | loss: 1.4243 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10170/2499940 | global iter:   5086/1249970 | loss: 0.6620 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  10172/2499940 | global iter:   5087/1249970 | loss: 1.9590 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10174/2499940 | global iter:   5088/1249970 | loss: 1.2573 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10174/2499940 | global iter:   5088/1249970 | loss: 1.2204 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10176/2499940 | global iter:   5089/1249970 | loss: 1.5218 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10178/2499940 | global iter:   5090/1249970 | loss: 0.9225 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10180/2499940 | global iter:   5091/1249970 | loss: 0.8595 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10182/2499940 | global iter:   5092/1249970 | loss: 2.2069 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10182/2499940 | global iter:   5092/1249970 | loss: 1.2651 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10184/2499940 | global iter:   5093/1249970 | loss: 1.3366 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  10186/2499940 | global iter:   5094/1249970 | loss: 1.0678 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10188/2499940 | global iter:   5095/1249970 | loss: 0.7648 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  10190/2499940 | global iter:   5096/1249970 | loss: 1.7618 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10190/2499940 | global iter:   5096/1249970 | loss: 1.0379 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10192/2499940 | global iter:   5097/1249970 | loss: 1.3750 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10194/2499940 | global iter:   5098/1249970 | loss: 1.2009 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10196/2499940 | global iter:   5099/1249970 | loss: 1.4133 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10198/2499940 | global iter:   5100/1249970 | loss: 1.3762 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10198/2499940 | global iter:   5100/1249970 | loss: 1.0737 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10200/2499940 | global iter:   5101/1249970 | loss: 2.1751 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  10202/2499940 | global iter:   5102/1249970 | loss: 1.3308 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10204/2499940 | global iter:   5103/1249970 | loss: 0.4622 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  10206/2499940 | global iter:   5104/1249970 | loss: 0.8271 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10206/2499940 | global iter:   5104/1249970 | loss: 1.0803 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10208/2499940 | global iter:   5105/1249970 | loss: 0.9205 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10210/2499940 | global iter:   5106/1249970 | loss: 0.9961 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10212/2499940 | global iter:   5107/1249970 | loss: 0.9353 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  10214/2499940 | global iter:   5108/1249970 | loss: 0.7977 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10214/2499940 | global iter:   5108/1249970 | loss: 0.9834 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10216/2499940 | global iter:   5109/1249970 | loss: 1.1688 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10218/2499940 | global iter:   5110/1249970 | loss: 1.3639 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10220/2499940 | global iter:   5111/1249970 | loss: 1.1737 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  10222/2499940 | global iter:   5112/1249970 | loss: 1.0084 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10222/2499940 | global iter:   5112/1249970 | loss: 1.1537 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10224/2499940 | global iter:   5113/1249970 | loss: 0.9699 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  10226/2499940 | global iter:   5114/1249970 | loss: 1.3359 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  10228/2499940 | global iter:   5115/1249970 | loss: 1.2752 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10230/2499940 | global iter:   5116/1249970 | loss: 1.2032 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10230/2499940 | global iter:   5116/1249970 | loss: 1.2484 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10232/2499940 | global iter:   5117/1249970 | loss: 0.5820 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  10234/2499940 | global iter:   5118/1249970 | loss: 0.8994 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  10236/2499940 | global iter:   5119/1249970 | loss: 1.0188 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10238/2499940 | global iter:   5120/1249970 | loss: 1.3754 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10238/2499940 | global iter:   5120/1249970 | loss: 0.9183 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10240/2499940 | global iter:   5121/1249970 | loss: 1.1912 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10242/2499940 | global iter:   5122/1249970 | loss: 1.6057 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10244/2499940 | global iter:   5123/1249970 | loss: 1.0895 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10246/2499940 | global iter:   5124/1249970 | loss: 0.6513 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10246/2499940 | global iter:   5124/1249970 | loss: 1.2615 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10248/2499940 | global iter:   5125/1249970 | loss: 0.8582 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10250/2499940 | global iter:   5126/1249970 | loss: 0.8107 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10252/2499940 | global iter:   5127/1249970 | loss: 1.3812 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10254/2499940 | global iter:   5128/1249970 | loss: 0.9798 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10254/2499940 | global iter:   5128/1249970 | loss: 0.7454 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10256/2499940 | global iter:   5129/1249970 | loss: 1.5851 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10258/2499940 | global iter:   5130/1249970 | loss: 0.7665 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  10260/2499940 | global iter:   5131/1249970 | loss: 0.4453 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10262/2499940 | global iter:   5132/1249970 | loss: 0.8162 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10262/2499940 | global iter:   5132/1249970 | loss: 0.9312 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10264/2499940 | global iter:   5133/1249970 | loss: 0.3940 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10266/2499940 | global iter:   5134/1249970 | loss: 1.7575 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10268/2499940 | global iter:   5135/1249970 | loss: 1.6169 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10270/2499940 | global iter:   5136/1249970 | loss: 1.0344 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10270/2499940 | global iter:   5136/1249970 | loss: 1.1043 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10272/2499940 | global iter:   5137/1249970 | loss: 0.5841 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  10274/2499940 | global iter:   5138/1249970 | loss: 1.1446 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  10276/2499940 | global iter:   5139/1249970 | loss: 0.8138 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10278/2499940 | global iter:   5140/1249970 | loss: 0.7626 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10278/2499940 | global iter:   5140/1249970 | loss: 1.0146 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10280/2499940 | global iter:   5141/1249970 | loss: 0.1746 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10282/2499940 | global iter:   5142/1249970 | loss: 2.1112 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  10284/2499940 | global iter:   5143/1249970 | loss: 1.0564 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10286/2499940 | global iter:   5144/1249970 | loss: 1.2891 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10286/2499940 | global iter:   5144/1249970 | loss: 1.3052 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.686
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10288/2499940 | global iter:   5145/1249970 | loss: 1.1438 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10290/2499940 | global iter:   5146/1249970 | loss: 1.0531 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  10292/2499940 | global iter:   5147/1249970 | loss: 1.1778 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10294/2499940 | global iter:   5148/1249970 | loss: 0.6552 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10294/2499940 | global iter:   5148/1249970 | loss: 0.8049 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10296/2499940 | global iter:   5149/1249970 | loss: 1.2070 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.411 | step time: 0.000
train | epoch   0 | Iter:  10298/2499940 | global iter:   5150/1249970 | loss: 1.7943 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10300/2499940 | global iter:   5151/1249970 | loss: 1.0520 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10302/2499940 | global iter:   5152/1249970 | loss: 1.2456 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10302/2499940 | global iter:   5152/1249970 | loss: 1.3213 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10304/2499940 | global iter:   5153/1249970 | loss: 0.9324 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10306/2499940 | global iter:   5154/1249970 | loss: 1.1340 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10308/2499940 | global iter:   5155/1249970 | loss: 1.2617 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10310/2499940 | global iter:   5156/1249970 | loss: 1.0716 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10310/2499940 | global iter:   5156/1249970 | loss: 1.0310 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10312/2499940 | global iter:   5157/1249970 | loss: 1.0733 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10314/2499940 | global iter:   5158/1249970 | loss: 1.2844 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10316/2499940 | global iter:   5159/1249970 | loss: 1.7155 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10318/2499940 | global iter:   5160/1249970 | loss: 0.9597 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10318/2499940 | global iter:   5160/1249970 | loss: 1.3168 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10320/2499940 | global iter:   5161/1249970 | loss: 1.1760 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10322/2499940 | global iter:   5162/1249970 | loss: 1.2327 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  10324/2499940 | global iter:   5163/1249970 | loss: 1.3871 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10326/2499940 | global iter:   5164/1249970 | loss: 0.9852 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10326/2499940 | global iter:   5164/1249970 | loss: 1.2193 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10328/2499940 | global iter:   5165/1249970 | loss: 1.2403 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10330/2499940 | global iter:   5166/1249970 | loss: 1.0877 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10332/2499940 | global iter:   5167/1249970 | loss: 0.9161 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10334/2499940 | global iter:   5168/1249970 | loss: 2.3969 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10334/2499940 | global iter:   5168/1249970 | loss: 1.1091 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10336/2499940 | global iter:   5169/1249970 | loss: 1.1921 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10338/2499940 | global iter:   5170/1249970 | loss: 1.0490 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10340/2499940 | global iter:   5171/1249970 | loss: 0.9603 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10342/2499940 | global iter:   5172/1249970 | loss: 1.1675 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10342/2499940 | global iter:   5172/1249970 | loss: 1.1859 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10344/2499940 | global iter:   5173/1249970 | loss: 0.9021 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  10346/2499940 | global iter:   5174/1249970 | loss: 1.0276 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10348/2499940 | global iter:   5175/1249970 | loss: 0.5303 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10350/2499940 | global iter:   5176/1249970 | loss: 0.2621 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10350/2499940 | global iter:   5176/1249970 | loss: 1.0597 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10352/2499940 | global iter:   5177/1249970 | loss: 1.1793 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10354/2499940 | global iter:   5178/1249970 | loss: 1.0441 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10356/2499940 | global iter:   5179/1249970 | loss: 0.8353 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10358/2499940 | global iter:   5180/1249970 | loss: 0.7757 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10358/2499940 | global iter:   5180/1249970 | loss: 0.8018 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10360/2499940 | global iter:   5181/1249970 | loss: 0.6328 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  10362/2499940 | global iter:   5182/1249970 | loss: 0.6289 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  10364/2499940 | global iter:   5183/1249970 | loss: 1.1389 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10366/2499940 | global iter:   5184/1249970 | loss: 1.3420 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10366/2499940 | global iter:   5184/1249970 | loss: 1.1272 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10368/2499940 | global iter:   5185/1249970 | loss: 0.7736 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  10370/2499940 | global iter:   5186/1249970 | loss: 1.8468 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10372/2499940 | global iter:   5187/1249970 | loss: 0.5931 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10374/2499940 | global iter:   5188/1249970 | loss: 1.6740 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10374/2499940 | global iter:   5188/1249970 | loss: 1.1424 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10376/2499940 | global iter:   5189/1249970 | loss: 1.1826 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10378/2499940 | global iter:   5190/1249970 | loss: 0.4888 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10380/2499940 | global iter:   5191/1249970 | loss: 1.2267 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  10382/2499940 | global iter:   5192/1249970 | loss: 1.4396 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10382/2499940 | global iter:   5192/1249970 | loss: 1.3028 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10384/2499940 | global iter:   5193/1249970 | loss: 1.6519 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10386/2499940 | global iter:   5194/1249970 | loss: 1.3568 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10388/2499940 | global iter:   5195/1249970 | loss: 1.2596 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10390/2499940 | global iter:   5196/1249970 | loss: 1.0330 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10390/2499940 | global iter:   5196/1249970 | loss: 1.1378 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10392/2499940 | global iter:   5197/1249970 | loss: 0.5410 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10394/2499940 | global iter:   5198/1249970 | loss: 0.7101 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10396/2499940 | global iter:   5199/1249970 | loss: 1.4023 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10398/2499940 | global iter:   5200/1249970 | loss: 1.1647 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10398/2499940 | global iter:   5200/1249970 | loss: 1.2276 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10400/2499940 | global iter:   5201/1249970 | loss: 0.9376 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10402/2499940 | global iter:   5202/1249970 | loss: 0.8458 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10404/2499940 | global iter:   5203/1249970 | loss: 1.0485 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  10406/2499940 | global iter:   5204/1249970 | loss: 0.2595 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10406/2499940 | global iter:   5204/1249970 | loss: 0.9947 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10408/2499940 | global iter:   5205/1249970 | loss: 1.6029 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10410/2499940 | global iter:   5206/1249970 | loss: 0.5307 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  10412/2499940 | global iter:   5207/1249970 | loss: 1.1810 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10414/2499940 | global iter:   5208/1249970 | loss: 0.9248 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10414/2499940 | global iter:   5208/1249970 | loss: 1.0507 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10416/2499940 | global iter:   5209/1249970 | loss: 1.8524 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10418/2499940 | global iter:   5210/1249970 | loss: 0.6805 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10420/2499940 | global iter:   5211/1249970 | loss: 1.3415 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10422/2499940 | global iter:   5212/1249970 | loss: 1.2741 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10422/2499940 | global iter:   5212/1249970 | loss: 1.3586 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10424/2499940 | global iter:   5213/1249970 | loss: 1.7169 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10426/2499940 | global iter:   5214/1249970 | loss: 1.3079 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10428/2499940 | global iter:   5215/1249970 | loss: 1.4406 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10430/2499940 | global iter:   5216/1249970 | loss: 1.4817 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10430/2499940 | global iter:   5216/1249970 | loss: 1.1500 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10432/2499940 | global iter:   5217/1249970 | loss: 1.1697 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10434/2499940 | global iter:   5218/1249970 | loss: 0.9954 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  10436/2499940 | global iter:   5219/1249970 | loss: 0.6419 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  10438/2499940 | global iter:   5220/1249970 | loss: 1.1180 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10438/2499940 | global iter:   5220/1249970 | loss: 1.0667 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10440/2499940 | global iter:   5221/1249970 | loss: 1.3254 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10442/2499940 | global iter:   5222/1249970 | loss: 1.2762 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10444/2499940 | global iter:   5223/1249970 | loss: 1.8117 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10446/2499940 | global iter:   5224/1249970 | loss: 0.9374 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10446/2499940 | global iter:   5224/1249970 | loss: 1.1590 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10448/2499940 | global iter:   5225/1249970 | loss: 0.8218 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10450/2499940 | global iter:   5226/1249970 | loss: 1.5806 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10452/2499940 | global iter:   5227/1249970 | loss: 1.0536 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10454/2499940 | global iter:   5228/1249970 | loss: 0.6380 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10454/2499940 | global iter:   5228/1249970 | loss: 1.2295 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10456/2499940 | global iter:   5229/1249970 | loss: 1.4300 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10458/2499940 | global iter:   5230/1249970 | loss: 1.4219 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  10460/2499940 | global iter:   5231/1249970 | loss: 0.1846 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10462/2499940 | global iter:   5232/1249970 | loss: 0.3324 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10462/2499940 | global iter:   5232/1249970 | loss: 1.1149 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10464/2499940 | global iter:   5233/1249970 | loss: 0.5590 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10466/2499940 | global iter:   5234/1249970 | loss: 0.9140 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10468/2499940 | global iter:   5235/1249970 | loss: 1.3776 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.409 | step time: 0.000
train | epoch   0 | Iter:  10470/2499940 | global iter:   5236/1249970 | loss: 1.2374 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10470/2499940 | global iter:   5236/1249970 | loss: 1.0949 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10472/2499940 | global iter:   5237/1249970 | loss: 0.6036 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  10474/2499940 | global iter:   5238/1249970 | loss: 1.5489 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10476/2499940 | global iter:   5239/1249970 | loss: 0.0897 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  10478/2499940 | global iter:   5240/1249970 | loss: 0.7786 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10478/2499940 | global iter:   5240/1249970 | loss: 0.9650 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10480/2499940 | global iter:   5241/1249970 | loss: 0.8740 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10482/2499940 | global iter:   5242/1249970 | loss: 0.8266 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10484/2499940 | global iter:   5243/1249970 | loss: 0.7918 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  10486/2499940 | global iter:   5244/1249970 | loss: 1.4899 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10486/2499940 | global iter:   5244/1249970 | loss: 1.2847 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10488/2499940 | global iter:   5245/1249970 | loss: 0.6677 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  10490/2499940 | global iter:   5246/1249970 | loss: 1.3934 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  10492/2499940 | global iter:   5247/1249970 | loss: 1.8549 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10494/2499940 | global iter:   5248/1249970 | loss: 1.6597 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10494/2499940 | global iter:   5248/1249970 | loss: 1.2577 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10496/2499940 | global iter:   5249/1249970 | loss: 1.1028 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  10498/2499940 | global iter:   5250/1249970 | loss: 1.9130 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10500/2499940 | global iter:   5251/1249970 | loss: 1.2029 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10502/2499940 | global iter:   5252/1249970 | loss: 1.6669 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10502/2499940 | global iter:   5252/1249970 | loss: 1.0252 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10504/2499940 | global iter:   5253/1249970 | loss: 1.2507 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10506/2499940 | global iter:   5254/1249970 | loss: 0.8182 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10508/2499940 | global iter:   5255/1249970 | loss: 1.3390 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  10510/2499940 | global iter:   5256/1249970 | loss: 1.5963 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10510/2499940 | global iter:   5256/1249970 | loss: 1.2356 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10512/2499940 | global iter:   5257/1249970 | loss: 1.2690 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10514/2499940 | global iter:   5258/1249970 | loss: 0.3476 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  10516/2499940 | global iter:   5259/1249970 | loss: 1.0132 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10518/2499940 | global iter:   5260/1249970 | loss: 0.8628 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10518/2499940 | global iter:   5260/1249970 | loss: 1.0370 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10520/2499940 | global iter:   5261/1249970 | loss: 0.8404 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  10522/2499940 | global iter:   5262/1249970 | loss: 1.6018 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10524/2499940 | global iter:   5263/1249970 | loss: 0.9937 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  10526/2499940 | global iter:   5264/1249970 | loss: 0.8478 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10526/2499940 | global iter:   5264/1249970 | loss: 1.0241 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10528/2499940 | global iter:   5265/1249970 | loss: 0.5682 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10530/2499940 | global iter:   5266/1249970 | loss: 0.2857 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  10532/2499940 | global iter:   5267/1249970 | loss: 1.4763 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10534/2499940 | global iter:   5268/1249970 | loss: 1.3576 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.392 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10534/2499940 | global iter:   5268/1249970 | loss: 1.2067 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.392 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10536/2499940 | global iter:   5269/1249970 | loss: 0.8635 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10538/2499940 | global iter:   5270/1249970 | loss: 0.5515 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10540/2499940 | global iter:   5271/1249970 | loss: 1.1956 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10542/2499940 | global iter:   5272/1249970 | loss: 0.9100 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10542/2499940 | global iter:   5272/1249970 | loss: 1.2083 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10544/2499940 | global iter:   5273/1249970 | loss: 0.6454 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  10546/2499940 | global iter:   5274/1249970 | loss: 1.0625 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  10548/2499940 | global iter:   5275/1249970 | loss: 0.6556 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10550/2499940 | global iter:   5276/1249970 | loss: 1.2065 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10550/2499940 | global iter:   5276/1249970 | loss: 1.0663 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10552/2499940 | global iter:   5277/1249970 | loss: 1.3387 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  10554/2499940 | global iter:   5278/1249970 | loss: 0.9395 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.406 | step time: 0.000
train | epoch   0 | Iter:  10556/2499940 | global iter:   5279/1249970 | loss: 1.5465 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.410 | step time: 0.000
train | epoch   0 | Iter:  10558/2499940 | global iter:   5280/1249970 | loss: 0.5280 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10558/2499940 | global iter:   5280/1249970 | loss: 1.1305 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10560/2499940 | global iter:   5281/1249970 | loss: 0.8678 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10562/2499940 | global iter:   5282/1249970 | loss: 1.8438 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10564/2499940 | global iter:   5283/1249970 | loss: 0.3845 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10566/2499940 | global iter:   5284/1249970 | loss: 1.5503 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10566/2499940 | global iter:   5284/1249970 | loss: 1.2669 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10568/2499940 | global iter:   5285/1249970 | loss: 1.3464 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10570/2499940 | global iter:   5286/1249970 | loss: 1.3091 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10572/2499940 | global iter:   5287/1249970 | loss: 1.3518 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10574/2499940 | global iter:   5288/1249970 | loss: 1.6427 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10574/2499940 | global iter:   5288/1249970 | loss: 1.2427 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10576/2499940 | global iter:   5289/1249970 | loss: 1.3646 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10578/2499940 | global iter:   5290/1249970 | loss: 1.5431 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10580/2499940 | global iter:   5291/1249970 | loss: 1.0560 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10582/2499940 | global iter:   5292/1249970 | loss: 1.4678 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10582/2499940 | global iter:   5292/1249970 | loss: 1.2283 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10584/2499940 | global iter:   5293/1249970 | loss: 1.5386 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10586/2499940 | global iter:   5294/1249970 | loss: 1.4210 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10588/2499940 | global iter:   5295/1249970 | loss: 1.7928 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10590/2499940 | global iter:   5296/1249970 | loss: 0.6091 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10590/2499940 | global iter:   5296/1249970 | loss: 1.4460 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10592/2499940 | global iter:   5297/1249970 | loss: 0.6741 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10594/2499940 | global iter:   5298/1249970 | loss: 1.0825 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10596/2499940 | global iter:   5299/1249970 | loss: 1.6649 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10598/2499940 | global iter:   5300/1249970 | loss: 0.0143 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10598/2499940 | global iter:   5300/1249970 | loss: 1.0689 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10600/2499940 | global iter:   5301/1249970 | loss: 0.5429 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10602/2499940 | global iter:   5302/1249970 | loss: 1.1904 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10604/2499940 | global iter:   5303/1249970 | loss: 1.2351 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10606/2499940 | global iter:   5304/1249970 | loss: 1.8542 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10606/2499940 | global iter:   5304/1249970 | loss: 1.2579 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10608/2499940 | global iter:   5305/1249970 | loss: 0.9495 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10610/2499940 | global iter:   5306/1249970 | loss: 1.8813 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10612/2499940 | global iter:   5307/1249970 | loss: 0.7305 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10614/2499940 | global iter:   5308/1249970 | loss: 0.9031 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10614/2499940 | global iter:   5308/1249970 | loss: 1.0046 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10616/2499940 | global iter:   5309/1249970 | loss: 0.7615 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10618/2499940 | global iter:   5310/1249970 | loss: 0.7154 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10620/2499940 | global iter:   5311/1249970 | loss: 1.3827 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10622/2499940 | global iter:   5312/1249970 | loss: 1.0090 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10622/2499940 | global iter:   5312/1249970 | loss: 0.9200 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10624/2499940 | global iter:   5313/1249970 | loss: 1.3716 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10626/2499940 | global iter:   5314/1249970 | loss: 1.5662 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:  10628/2499940 | global iter:   5315/1249970 | loss: 0.7890 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10630/2499940 | global iter:   5316/1249970 | loss: 0.6271 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10630/2499940 | global iter:   5316/1249970 | loss: 1.1541 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10632/2499940 | global iter:   5317/1249970 | loss: 1.3391 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10634/2499940 | global iter:   5318/1249970 | loss: 1.9203 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10636/2499940 | global iter:   5319/1249970 | loss: 1.0014 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10638/2499940 | global iter:   5320/1249970 | loss: 0.8369 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10638/2499940 | global iter:   5320/1249970 | loss: 1.0114 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10640/2499940 | global iter:   5321/1249970 | loss: 0.7288 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10642/2499940 | global iter:   5322/1249970 | loss: 1.3869 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  10644/2499940 | global iter:   5323/1249970 | loss: 0.9584 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10646/2499940 | global iter:   5324/1249970 | loss: 1.5262 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10646/2499940 | global iter:   5324/1249970 | loss: 1.3986 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10648/2499940 | global iter:   5325/1249970 | loss: 0.1874 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10650/2499940 | global iter:   5326/1249970 | loss: 1.4947 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10652/2499940 | global iter:   5327/1249970 | loss: 0.5321 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10654/2499940 | global iter:   5328/1249970 | loss: 0.6994 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10654/2499940 | global iter:   5328/1249970 | loss: 0.9061 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10656/2499940 | global iter:   5329/1249970 | loss: 0.4982 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10658/2499940 | global iter:   5330/1249970 | loss: 1.0379 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  10660/2499940 | global iter:   5331/1249970 | loss: 0.1696 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10662/2499940 | global iter:   5332/1249970 | loss: 1.1745 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10662/2499940 | global iter:   5332/1249970 | loss: 0.9622 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10664/2499940 | global iter:   5333/1249970 | loss: 1.3254 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10666/2499940 | global iter:   5334/1249970 | loss: 0.5846 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10668/2499940 | global iter:   5335/1249970 | loss: 1.1448 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10670/2499940 | global iter:   5336/1249970 | loss: 0.8617 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10670/2499940 | global iter:   5336/1249970 | loss: 1.1176 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10672/2499940 | global iter:   5337/1249970 | loss: 0.2101 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10674/2499940 | global iter:   5338/1249970 | loss: 1.2548 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10676/2499940 | global iter:   5339/1249970 | loss: 1.5778 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10678/2499940 | global iter:   5340/1249970 | loss: 0.1688 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10678/2499940 | global iter:   5340/1249970 | loss: 0.9618 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10680/2499940 | global iter:   5341/1249970 | loss: 0.8311 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10682/2499940 | global iter:   5342/1249970 | loss: 1.0241 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  10684/2499940 | global iter:   5343/1249970 | loss: 1.4453 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10686/2499940 | global iter:   5344/1249970 | loss: 1.1242 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10686/2499940 | global iter:   5344/1249970 | loss: 1.4282 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10688/2499940 | global iter:   5345/1249970 | loss: 1.6197 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10690/2499940 | global iter:   5346/1249970 | loss: 1.0904 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10692/2499940 | global iter:   5347/1249970 | loss: 1.8603 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10694/2499940 | global iter:   5348/1249970 | loss: 1.3496 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10694/2499940 | global iter:   5348/1249970 | loss: 1.3438 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10696/2499940 | global iter:   5349/1249970 | loss: 1.8058 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10698/2499940 | global iter:   5350/1249970 | loss: 1.8403 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10700/2499940 | global iter:   5351/1249970 | loss: 1.7721 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10702/2499940 | global iter:   5352/1249970 | loss: 0.7197 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10702/2499940 | global iter:   5352/1249970 | loss: 1.2573 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10704/2499940 | global iter:   5353/1249970 | loss: 0.8750 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10706/2499940 | global iter:   5354/1249970 | loss: 1.7420 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10708/2499940 | global iter:   5355/1249970 | loss: 0.9347 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10710/2499940 | global iter:   5356/1249970 | loss: 0.8429 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10710/2499940 | global iter:   5356/1249970 | loss: 1.0809 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10712/2499940 | global iter:   5357/1249970 | loss: 1.5793 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10714/2499940 | global iter:   5358/1249970 | loss: 1.4898 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10716/2499940 | global iter:   5359/1249970 | loss: 1.2231 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10718/2499940 | global iter:   5360/1249970 | loss: 1.0199 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10718/2499940 | global iter:   5360/1249970 | loss: 1.0944 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10720/2499940 | global iter:   5361/1249970 | loss: 1.3853 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10722/2499940 | global iter:   5362/1249970 | loss: 0.2010 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10724/2499940 | global iter:   5363/1249970 | loss: 0.9215 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10726/2499940 | global iter:   5364/1249970 | loss: 1.7295 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10726/2499940 | global iter:   5364/1249970 | loss: 0.9528 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10728/2499940 | global iter:   5365/1249970 | loss: 0.9348 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.406 | step time: 0.000
train | epoch   0 | Iter:  10730/2499940 | global iter:   5366/1249970 | loss: 1.2817 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10732/2499940 | global iter:   5367/1249970 | loss: 0.9215 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10734/2499940 | global iter:   5368/1249970 | loss: 0.1666 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10734/2499940 | global iter:   5368/1249970 | loss: 0.9222 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10736/2499940 | global iter:   5369/1249970 | loss: 0.9818 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  10738/2499940 | global iter:   5370/1249970 | loss: 0.9132 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10740/2499940 | global iter:   5371/1249970 | loss: 1.5362 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10742/2499940 | global iter:   5372/1249970 | loss: 0.9183 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10742/2499940 | global iter:   5372/1249970 | loss: 1.0774 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10744/2499940 | global iter:   5373/1249970 | loss: 0.9787 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10746/2499940 | global iter:   5374/1249970 | loss: 0.6567 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  10748/2499940 | global iter:   5375/1249970 | loss: 0.9507 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10750/2499940 | global iter:   5376/1249970 | loss: 0.6860 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10750/2499940 | global iter:   5376/1249970 | loss: 0.8643 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10752/2499940 | global iter:   5377/1249970 | loss: 1.4513 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10754/2499940 | global iter:   5378/1249970 | loss: 1.0917 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.392 | step time: 0.000
train | epoch   0 | Iter:  10756/2499940 | global iter:   5379/1249970 | loss: 0.7347 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10758/2499940 | global iter:   5380/1249970 | loss: 1.6246 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10758/2499940 | global iter:   5380/1249970 | loss: 1.2665 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10760/2499940 | global iter:   5381/1249970 | loss: 0.5335 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10762/2499940 | global iter:   5382/1249970 | loss: 1.7532 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10764/2499940 | global iter:   5383/1249970 | loss: 1.2572 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10766/2499940 | global iter:   5384/1249970 | loss: 0.7692 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10766/2499940 | global iter:   5384/1249970 | loss: 0.9499 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10768/2499940 | global iter:   5385/1249970 | loss: 1.3586 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10770/2499940 | global iter:   5386/1249970 | loss: 0.9101 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:  10772/2499940 | global iter:   5387/1249970 | loss: 0.7421 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10774/2499940 | global iter:   5388/1249970 | loss: 0.4986 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10774/2499940 | global iter:   5388/1249970 | loss: 0.9157 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10776/2499940 | global iter:   5389/1249970 | loss: 0.7205 | ds_loss: 0.0000 | lr: 9.9996e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10778/2499940 | global iter:   5390/1249970 | loss: 0.5766 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10780/2499940 | global iter:   5391/1249970 | loss: 0.7400 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10782/2499940 | global iter:   5392/1249970 | loss: 1.4554 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10782/2499940 | global iter:   5392/1249970 | loss: 1.0395 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10784/2499940 | global iter:   5393/1249970 | loss: 0.7445 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10786/2499940 | global iter:   5394/1249970 | loss: 1.3805 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10788/2499940 | global iter:   5395/1249970 | loss: 0.1342 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10790/2499940 | global iter:   5396/1249970 | loss: 1.2079 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10790/2499940 | global iter:   5396/1249970 | loss: 1.0420 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10792/2499940 | global iter:   5397/1249970 | loss: 0.9185 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  10794/2499940 | global iter:   5398/1249970 | loss: 1.2747 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10796/2499940 | global iter:   5399/1249970 | loss: 1.2074 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10798/2499940 | global iter:   5400/1249970 | loss: 0.8475 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10798/2499940 | global iter:   5400/1249970 | loss: 1.1426 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10800/2499940 | global iter:   5401/1249970 | loss: 0.5361 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10802/2499940 | global iter:   5402/1249970 | loss: 1.3962 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10804/2499940 | global iter:   5403/1249970 | loss: 1.7146 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10806/2499940 | global iter:   5404/1249970 | loss: 0.4807 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10806/2499940 | global iter:   5404/1249970 | loss: 1.0172 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10808/2499940 | global iter:   5405/1249970 | loss: 1.7447 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  10810/2499940 | global iter:   5406/1249970 | loss: 0.7856 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10812/2499940 | global iter:   5407/1249970 | loss: 0.9376 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10814/2499940 | global iter:   5408/1249970 | loss: 0.6909 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10814/2499940 | global iter:   5408/1249970 | loss: 0.9464 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10816/2499940 | global iter:   5409/1249970 | loss: 2.3402 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10818/2499940 | global iter:   5410/1249970 | loss: 1.8602 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10820/2499940 | global iter:   5411/1249970 | loss: 1.1657 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10822/2499940 | global iter:   5412/1249970 | loss: 1.3682 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10822/2499940 | global iter:   5412/1249970 | loss: 1.4288 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10824/2499940 | global iter:   5413/1249970 | loss: 0.6977 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10826/2499940 | global iter:   5414/1249970 | loss: 1.2966 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  10828/2499940 | global iter:   5415/1249970 | loss: 1.1521 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10830/2499940 | global iter:   5416/1249970 | loss: 0.5697 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10830/2499940 | global iter:   5416/1249970 | loss: 0.7070 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10832/2499940 | global iter:   5417/1249970 | loss: 1.5562 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10834/2499940 | global iter:   5418/1249970 | loss: 1.5916 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10836/2499940 | global iter:   5419/1249970 | loss: 0.8308 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10838/2499940 | global iter:   5420/1249970 | loss: 0.8691 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10838/2499940 | global iter:   5420/1249970 | loss: 1.1099 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10840/2499940 | global iter:   5421/1249970 | loss: 0.8294 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10842/2499940 | global iter:   5422/1249970 | loss: 1.7297 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10844/2499940 | global iter:   5423/1249970 | loss: 1.5762 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10846/2499940 | global iter:   5424/1249970 | loss: 1.7278 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10846/2499940 | global iter:   5424/1249970 | loss: 1.4998 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10848/2499940 | global iter:   5425/1249970 | loss: 0.6823 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10850/2499940 | global iter:   5426/1249970 | loss: 0.8620 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10852/2499940 | global iter:   5427/1249970 | loss: 1.6340 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10854/2499940 | global iter:   5428/1249970 | loss: 1.0619 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10854/2499940 | global iter:   5428/1249970 | loss: 1.2797 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10856/2499940 | global iter:   5429/1249970 | loss: 1.2683 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10858/2499940 | global iter:   5430/1249970 | loss: 1.1811 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10860/2499940 | global iter:   5431/1249970 | loss: 1.2127 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10862/2499940 | global iter:   5432/1249970 | loss: 0.8192 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10862/2499940 | global iter:   5432/1249970 | loss: 1.1170 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10864/2499940 | global iter:   5433/1249970 | loss: 1.3497 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10866/2499940 | global iter:   5434/1249970 | loss: 0.8906 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10868/2499940 | global iter:   5435/1249970 | loss: 0.1220 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10870/2499940 | global iter:   5436/1249970 | loss: 0.1208 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10870/2499940 | global iter:   5436/1249970 | loss: 0.9010 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10872/2499940 | global iter:   5437/1249970 | loss: 0.7119 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10874/2499940 | global iter:   5438/1249970 | loss: 1.3007 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10876/2499940 | global iter:   5439/1249970 | loss: 1.4338 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10878/2499940 | global iter:   5440/1249970 | loss: 0.9730 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10878/2499940 | global iter:   5440/1249970 | loss: 0.9783 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10880/2499940 | global iter:   5441/1249970 | loss: 1.1303 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10882/2499940 | global iter:   5442/1249970 | loss: 0.9460 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10884/2499940 | global iter:   5443/1249970 | loss: 0.7140 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10886/2499940 | global iter:   5444/1249970 | loss: 0.7729 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10886/2499940 | global iter:   5444/1249970 | loss: 0.9924 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10888/2499940 | global iter:   5445/1249970 | loss: 1.4231 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10890/2499940 | global iter:   5446/1249970 | loss: 1.0879 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10892/2499940 | global iter:   5447/1249970 | loss: 1.3749 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10894/2499940 | global iter:   5448/1249970 | loss: 0.8028 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10894/2499940 | global iter:   5448/1249970 | loss: 1.0180 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10896/2499940 | global iter:   5449/1249970 | loss: 1.1628 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  10898/2499940 | global iter:   5450/1249970 | loss: 0.6289 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10900/2499940 | global iter:   5451/1249970 | loss: 1.9100 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  10902/2499940 | global iter:   5452/1249970 | loss: 1.1683 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10902/2499940 | global iter:   5452/1249970 | loss: 1.0740 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10904/2499940 | global iter:   5453/1249970 | loss: 1.3864 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10906/2499940 | global iter:   5454/1249970 | loss: 2.0067 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10908/2499940 | global iter:   5455/1249970 | loss: 0.1566 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10910/2499940 | global iter:   5456/1249970 | loss: 0.8400 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10910/2499940 | global iter:   5456/1249970 | loss: 1.0168 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10912/2499940 | global iter:   5457/1249970 | loss: 0.6923 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10914/2499940 | global iter:   5458/1249970 | loss: 0.6532 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  10916/2499940 | global iter:   5459/1249970 | loss: 1.3171 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10918/2499940 | global iter:   5460/1249970 | loss: 1.1952 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10918/2499940 | global iter:   5460/1249970 | loss: 0.9800 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10920/2499940 | global iter:   5461/1249970 | loss: 1.6203 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  10922/2499940 | global iter:   5462/1249970 | loss: 1.2092 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10924/2499940 | global iter:   5463/1249970 | loss: 1.4975 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10926/2499940 | global iter:   5464/1249970 | loss: 1.1122 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10926/2499940 | global iter:   5464/1249970 | loss: 1.1741 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10928/2499940 | global iter:   5465/1249970 | loss: 0.7357 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  10930/2499940 | global iter:   5466/1249970 | loss: 1.2920 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10932/2499940 | global iter:   5467/1249970 | loss: 1.1733 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10934/2499940 | global iter:   5468/1249970 | loss: 1.1714 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10934/2499940 | global iter:   5468/1249970 | loss: 1.0150 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10936/2499940 | global iter:   5469/1249970 | loss: 0.9479 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  10938/2499940 | global iter:   5470/1249970 | loss: 2.0098 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10940/2499940 | global iter:   5471/1249970 | loss: 0.9060 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  10942/2499940 | global iter:   5472/1249970 | loss: 1.2532 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10942/2499940 | global iter:   5472/1249970 | loss: 1.1453 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10944/2499940 | global iter:   5473/1249970 | loss: 1.5855 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10946/2499940 | global iter:   5474/1249970 | loss: 0.5821 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:  10948/2499940 | global iter:   5475/1249970 | loss: 1.7465 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10950/2499940 | global iter:   5476/1249970 | loss: 1.0817 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10950/2499940 | global iter:   5476/1249970 | loss: 1.0692 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10952/2499940 | global iter:   5477/1249970 | loss: 0.4127 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10954/2499940 | global iter:   5478/1249970 | loss: 0.6562 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  10956/2499940 | global iter:   5479/1249970 | loss: 0.6517 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10958/2499940 | global iter:   5480/1249970 | loss: 1.0776 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10958/2499940 | global iter:   5480/1249970 | loss: 0.7529 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10960/2499940 | global iter:   5481/1249970 | loss: 1.1167 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10962/2499940 | global iter:   5482/1249970 | loss: 0.5923 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  10964/2499940 | global iter:   5483/1249970 | loss: 1.1110 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  10966/2499940 | global iter:   5484/1249970 | loss: 0.8858 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10966/2499940 | global iter:   5484/1249970 | loss: 1.1649 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10968/2499940 | global iter:   5485/1249970 | loss: 1.1310 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10970/2499940 | global iter:   5486/1249970 | loss: 0.9857 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  10972/2499940 | global iter:   5487/1249970 | loss: 1.6298 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10974/2499940 | global iter:   5488/1249970 | loss: 0.2821 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10974/2499940 | global iter:   5488/1249970 | loss: 0.9625 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10976/2499940 | global iter:   5489/1249970 | loss: 0.4312 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10978/2499940 | global iter:   5490/1249970 | loss: 0.8514 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  10980/2499940 | global iter:   5491/1249970 | loss: 0.3966 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10982/2499940 | global iter:   5492/1249970 | loss: 0.8067 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10982/2499940 | global iter:   5492/1249970 | loss: 0.9123 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10984/2499940 | global iter:   5493/1249970 | loss: 1.2116 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10986/2499940 | global iter:   5494/1249970 | loss: 0.7361 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10988/2499940 | global iter:   5495/1249970 | loss: 1.0890 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10990/2499940 | global iter:   5496/1249970 | loss: 0.8163 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.411 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10990/2499940 | global iter:   5496/1249970 | loss: 0.9820 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.411 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  10992/2499940 | global iter:   5497/1249970 | loss: 1.2300 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  10994/2499940 | global iter:   5498/1249970 | loss: 1.1706 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  10996/2499940 | global iter:   5499/1249970 | loss: 0.4352 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  10998/2499940 | global iter:   5500/1249970 | loss: 1.7050 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  10998/2499940 | global iter:   5500/1249970 | loss: 1.2734 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11000/2499940 | global iter:   5501/1249970 | loss: 0.6444 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11002/2499940 | global iter:   5502/1249970 | loss: 0.7820 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11004/2499940 | global iter:   5503/1249970 | loss: 1.0880 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  11006/2499940 | global iter:   5504/1249970 | loss: 1.5291 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11006/2499940 | global iter:   5504/1249970 | loss: 1.0744 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11008/2499940 | global iter:   5505/1249970 | loss: 1.5490 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11010/2499940 | global iter:   5506/1249970 | loss: 1.1118 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  11012/2499940 | global iter:   5507/1249970 | loss: 1.8579 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11014/2499940 | global iter:   5508/1249970 | loss: 1.2338 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11014/2499940 | global iter:   5508/1249970 | loss: 1.3829 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11016/2499940 | global iter:   5509/1249970 | loss: 0.1092 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11018/2499940 | global iter:   5510/1249970 | loss: 1.7030 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  11020/2499940 | global iter:   5511/1249970 | loss: 1.2577 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11022/2499940 | global iter:   5512/1249970 | loss: 1.1989 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11022/2499940 | global iter:   5512/1249970 | loss: 0.9345 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11024/2499940 | global iter:   5513/1249970 | loss: 1.2445 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11026/2499940 | global iter:   5514/1249970 | loss: 1.5125 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  11028/2499940 | global iter:   5515/1249970 | loss: 1.4622 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11030/2499940 | global iter:   5516/1249970 | loss: 1.4821 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11030/2499940 | global iter:   5516/1249970 | loss: 1.3882 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11032/2499940 | global iter:   5517/1249970 | loss: 1.4225 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11034/2499940 | global iter:   5518/1249970 | loss: 1.0629 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11036/2499940 | global iter:   5519/1249970 | loss: 1.5513 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11038/2499940 | global iter:   5520/1249970 | loss: 1.1364 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11038/2499940 | global iter:   5520/1249970 | loss: 1.1842 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11040/2499940 | global iter:   5521/1249970 | loss: 2.0887 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11042/2499940 | global iter:   5522/1249970 | loss: 0.1610 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11044/2499940 | global iter:   5523/1249970 | loss: 1.2810 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11046/2499940 | global iter:   5524/1249970 | loss: 0.6602 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11046/2499940 | global iter:   5524/1249970 | loss: 0.9191 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11048/2499940 | global iter:   5525/1249970 | loss: 1.6309 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11050/2499940 | global iter:   5526/1249970 | loss: 1.0933 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11052/2499940 | global iter:   5527/1249970 | loss: 1.2365 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  11054/2499940 | global iter:   5528/1249970 | loss: 1.0903 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.392 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11054/2499940 | global iter:   5528/1249970 | loss: 1.1772 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.392 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11056/2499940 | global iter:   5529/1249970 | loss: 1.1489 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11058/2499940 | global iter:   5530/1249970 | loss: 0.8932 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11060/2499940 | global iter:   5531/1249970 | loss: 1.7888 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11062/2499940 | global iter:   5532/1249970 | loss: 1.3948 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11062/2499940 | global iter:   5532/1249970 | loss: 1.2262 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11064/2499940 | global iter:   5533/1249970 | loss: 1.5249 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11066/2499940 | global iter:   5534/1249970 | loss: 0.8362 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  11068/2499940 | global iter:   5535/1249970 | loss: 1.6312 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11070/2499940 | global iter:   5536/1249970 | loss: 1.3564 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11070/2499940 | global iter:   5536/1249970 | loss: 1.1487 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11072/2499940 | global iter:   5537/1249970 | loss: 0.8181 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11074/2499940 | global iter:   5538/1249970 | loss: 1.5971 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  11076/2499940 | global iter:   5539/1249970 | loss: 0.2069 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.407 | step time: 0.000
train | epoch   0 | Iter:  11078/2499940 | global iter:   5540/1249970 | loss: 1.4428 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11078/2499940 | global iter:   5540/1249970 | loss: 1.1859 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11080/2499940 | global iter:   5541/1249970 | loss: 1.3295 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11082/2499940 | global iter:   5542/1249970 | loss: 1.2047 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11084/2499940 | global iter:   5543/1249970 | loss: 0.9603 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11086/2499940 | global iter:   5544/1249970 | loss: 1.0784 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11086/2499940 | global iter:   5544/1249970 | loss: 1.0177 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11088/2499940 | global iter:   5545/1249970 | loss: 1.4267 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11090/2499940 | global iter:   5546/1249970 | loss: 0.9082 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  11092/2499940 | global iter:   5547/1249970 | loss: 1.6126 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11094/2499940 | global iter:   5548/1249970 | loss: 0.9478 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11094/2499940 | global iter:   5548/1249970 | loss: 1.1196 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11096/2499940 | global iter:   5549/1249970 | loss: 1.4891 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11098/2499940 | global iter:   5550/1249970 | loss: 0.3514 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11100/2499940 | global iter:   5551/1249970 | loss: 1.2323 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11102/2499940 | global iter:   5552/1249970 | loss: 1.0222 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11102/2499940 | global iter:   5552/1249970 | loss: 1.1126 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11104/2499940 | global iter:   5553/1249970 | loss: 0.5048 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11106/2499940 | global iter:   5554/1249970 | loss: 1.1548 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11108/2499940 | global iter:   5555/1249970 | loss: 0.8369 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11110/2499940 | global iter:   5556/1249970 | loss: 1.6027 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11110/2499940 | global iter:   5556/1249970 | loss: 1.2630 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11112/2499940 | global iter:   5557/1249970 | loss: 1.5817 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11114/2499940 | global iter:   5558/1249970 | loss: 1.0303 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  11116/2499940 | global iter:   5559/1249970 | loss: 0.6047 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11118/2499940 | global iter:   5560/1249970 | loss: 1.6787 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11118/2499940 | global iter:   5560/1249970 | loss: 1.2070 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11120/2499940 | global iter:   5561/1249970 | loss: 1.6809 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11122/2499940 | global iter:   5562/1249970 | loss: 1.6973 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11124/2499940 | global iter:   5563/1249970 | loss: 1.0882 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11126/2499940 | global iter:   5564/1249970 | loss: 1.1853 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11126/2499940 | global iter:   5564/1249970 | loss: 1.3982 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11128/2499940 | global iter:   5565/1249970 | loss: 1.1780 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11130/2499940 | global iter:   5566/1249970 | loss: 1.2503 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11132/2499940 | global iter:   5567/1249970 | loss: 0.8660 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11134/2499940 | global iter:   5568/1249970 | loss: 2.2521 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11134/2499940 | global iter:   5568/1249970 | loss: 1.1122 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11136/2499940 | global iter:   5569/1249970 | loss: 1.5625 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11138/2499940 | global iter:   5570/1249970 | loss: 1.4952 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  11140/2499940 | global iter:   5571/1249970 | loss: 1.0755 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11142/2499940 | global iter:   5572/1249970 | loss: 0.6558 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11142/2499940 | global iter:   5572/1249970 | loss: 1.1800 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11144/2499940 | global iter:   5573/1249970 | loss: 1.1737 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11146/2499940 | global iter:   5574/1249970 | loss: 1.0140 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11148/2499940 | global iter:   5575/1249970 | loss: 1.2074 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11150/2499940 | global iter:   5576/1249970 | loss: 0.8743 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11150/2499940 | global iter:   5576/1249970 | loss: 1.1144 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11152/2499940 | global iter:   5577/1249970 | loss: 1.2845 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11154/2499940 | global iter:   5578/1249970 | loss: 1.7696 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11156/2499940 | global iter:   5579/1249970 | loss: 0.0616 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11158/2499940 | global iter:   5580/1249970 | loss: 1.1140 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11158/2499940 | global iter:   5580/1249970 | loss: 1.0816 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11160/2499940 | global iter:   5581/1249970 | loss: 1.5545 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11162/2499940 | global iter:   5582/1249970 | loss: 1.1029 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.405 | step time: 0.000
train | epoch   0 | Iter:  11164/2499940 | global iter:   5583/1249970 | loss: 1.0609 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11166/2499940 | global iter:   5584/1249970 | loss: 1.2401 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11166/2499940 | global iter:   5584/1249970 | loss: 1.1629 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11168/2499940 | global iter:   5585/1249970 | loss: 0.6087 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11170/2499940 | global iter:   5586/1249970 | loss: 0.9022 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11172/2499940 | global iter:   5587/1249970 | loss: 1.2152 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11174/2499940 | global iter:   5588/1249970 | loss: 0.9273 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11174/2499940 | global iter:   5588/1249970 | loss: 0.9152 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11176/2499940 | global iter:   5589/1249970 | loss: 1.2305 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  11178/2499940 | global iter:   5590/1249970 | loss: 0.6452 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11180/2499940 | global iter:   5591/1249970 | loss: 1.4250 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11182/2499940 | global iter:   5592/1249970 | loss: 1.3825 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11182/2499940 | global iter:   5592/1249970 | loss: 1.0981 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11184/2499940 | global iter:   5593/1249970 | loss: 1.7584 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11186/2499940 | global iter:   5594/1249970 | loss: 0.1756 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11188/2499940 | global iter:   5595/1249970 | loss: 1.1410 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11190/2499940 | global iter:   5596/1249970 | loss: 0.5448 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11190/2499940 | global iter:   5596/1249970 | loss: 0.9125 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11192/2499940 | global iter:   5597/1249970 | loss: 1.8246 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11194/2499940 | global iter:   5598/1249970 | loss: 0.4633 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  11196/2499940 | global iter:   5599/1249970 | loss: 0.5805 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11198/2499940 | global iter:   5600/1249970 | loss: 1.2445 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11198/2499940 | global iter:   5600/1249970 | loss: 1.0214 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11200/2499940 | global iter:   5601/1249970 | loss: 1.6792 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11202/2499940 | global iter:   5602/1249970 | loss: 1.0041 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11204/2499940 | global iter:   5603/1249970 | loss: 1.8196 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11206/2499940 | global iter:   5604/1249970 | loss: 1.3695 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11206/2499940 | global iter:   5604/1249970 | loss: 1.2706 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11208/2499940 | global iter:   5605/1249970 | loss: 1.8087 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11210/2499940 | global iter:   5606/1249970 | loss: 1.1392 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  11212/2499940 | global iter:   5607/1249970 | loss: 1.0206 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11214/2499940 | global iter:   5608/1249970 | loss: 0.8230 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11214/2499940 | global iter:   5608/1249970 | loss: 1.2114 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11216/2499940 | global iter:   5609/1249970 | loss: 1.1107 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11218/2499940 | global iter:   5610/1249970 | loss: 1.3446 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  11220/2499940 | global iter:   5611/1249970 | loss: 1.4268 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11222/2499940 | global iter:   5612/1249970 | loss: 1.2743 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11222/2499940 | global iter:   5612/1249970 | loss: 1.1660 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11224/2499940 | global iter:   5613/1249970 | loss: 0.8490 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11226/2499940 | global iter:   5614/1249970 | loss: 1.5002 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11228/2499940 | global iter:   5615/1249970 | loss: 0.1313 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11230/2499940 | global iter:   5616/1249970 | loss: 0.6776 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11230/2499940 | global iter:   5616/1249970 | loss: 0.7085 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11232/2499940 | global iter:   5617/1249970 | loss: 0.9034 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11234/2499940 | global iter:   5618/1249970 | loss: 0.7191 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11236/2499940 | global iter:   5619/1249970 | loss: 0.5105 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11238/2499940 | global iter:   5620/1249970 | loss: 1.0629 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11238/2499940 | global iter:   5620/1249970 | loss: 0.8362 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11240/2499940 | global iter:   5621/1249970 | loss: 1.7974 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11242/2499940 | global iter:   5622/1249970 | loss: 1.5607 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11244/2499940 | global iter:   5623/1249970 | loss: 1.0545 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11246/2499940 | global iter:   5624/1249970 | loss: 0.7038 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11246/2499940 | global iter:   5624/1249970 | loss: 1.1943 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11248/2499940 | global iter:   5625/1249970 | loss: 0.4612 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11250/2499940 | global iter:   5626/1249970 | loss: 0.9171 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11252/2499940 | global iter:   5627/1249970 | loss: 1.5428 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11254/2499940 | global iter:   5628/1249970 | loss: 0.5926 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11254/2499940 | global iter:   5628/1249970 | loss: 0.9460 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11256/2499940 | global iter:   5629/1249970 | loss: 0.7322 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11258/2499940 | global iter:   5630/1249970 | loss: 1.1634 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11260/2499940 | global iter:   5631/1249970 | loss: 1.3946 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11262/2499940 | global iter:   5632/1249970 | loss: 1.3370 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11262/2499940 | global iter:   5632/1249970 | loss: 1.0955 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11264/2499940 | global iter:   5633/1249970 | loss: 1.5150 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11266/2499940 | global iter:   5634/1249970 | loss: 1.4268 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:  11268/2499940 | global iter:   5635/1249970 | loss: 1.3100 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11270/2499940 | global iter:   5636/1249970 | loss: 1.4760 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11270/2499940 | global iter:   5636/1249970 | loss: 1.3038 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11272/2499940 | global iter:   5637/1249970 | loss: 0.9731 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11274/2499940 | global iter:   5638/1249970 | loss: 1.8009 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11276/2499940 | global iter:   5639/1249970 | loss: 0.5659 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11278/2499940 | global iter:   5640/1249970 | loss: 1.0742 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11278/2499940 | global iter:   5640/1249970 | loss: 0.9857 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11280/2499940 | global iter:   5641/1249970 | loss: 1.0371 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11282/2499940 | global iter:   5642/1249970 | loss: 1.7719 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11284/2499940 | global iter:   5643/1249970 | loss: 0.0165 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11286/2499940 | global iter:   5644/1249970 | loss: 1.7288 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11286/2499940 | global iter:   5644/1249970 | loss: 1.1738 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11288/2499940 | global iter:   5645/1249970 | loss: 1.1260 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11290/2499940 | global iter:   5646/1249970 | loss: 0.7278 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11292/2499940 | global iter:   5647/1249970 | loss: 1.7108 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11294/2499940 | global iter:   5648/1249970 | loss: 1.1120 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11294/2499940 | global iter:   5648/1249970 | loss: 1.2162 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11296/2499940 | global iter:   5649/1249970 | loss: 1.3209 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11298/2499940 | global iter:   5650/1249970 | loss: 0.4507 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  11300/2499940 | global iter:   5651/1249970 | loss: 1.1616 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11302/2499940 | global iter:   5652/1249970 | loss: 0.6316 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11302/2499940 | global iter:   5652/1249970 | loss: 1.2390 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11304/2499940 | global iter:   5653/1249970 | loss: 0.7510 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11306/2499940 | global iter:   5654/1249970 | loss: 1.0981 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  11308/2499940 | global iter:   5655/1249970 | loss: 1.2694 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11310/2499940 | global iter:   5656/1249970 | loss: 1.8420 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11310/2499940 | global iter:   5656/1249970 | loss: 1.0617 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11312/2499940 | global iter:   5657/1249970 | loss: 0.5637 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11314/2499940 | global iter:   5658/1249970 | loss: 1.1448 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11316/2499940 | global iter:   5659/1249970 | loss: 0.9802 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11318/2499940 | global iter:   5660/1249970 | loss: 0.8572 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11318/2499940 | global iter:   5660/1249970 | loss: 1.0926 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11320/2499940 | global iter:   5661/1249970 | loss: 0.5681 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11322/2499940 | global iter:   5662/1249970 | loss: 1.3716 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11324/2499940 | global iter:   5663/1249970 | loss: 1.9941 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11326/2499940 | global iter:   5664/1249970 | loss: 0.5913 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11326/2499940 | global iter:   5664/1249970 | loss: 1.1436 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11328/2499940 | global iter:   5665/1249970 | loss: 0.7583 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11330/2499940 | global iter:   5666/1249970 | loss: 0.8988 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11332/2499940 | global iter:   5667/1249970 | loss: 0.8854 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11334/2499940 | global iter:   5668/1249970 | loss: 1.0729 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11334/2499940 | global iter:   5668/1249970 | loss: 1.2448 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11336/2499940 | global iter:   5669/1249970 | loss: 0.9555 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11338/2499940 | global iter:   5670/1249970 | loss: 1.3301 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  11340/2499940 | global iter:   5671/1249970 | loss: 1.1893 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11342/2499940 | global iter:   5672/1249970 | loss: 0.6363 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11342/2499940 | global iter:   5672/1249970 | loss: 0.9019 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11344/2499940 | global iter:   5673/1249970 | loss: 1.9149 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11346/2499940 | global iter:   5674/1249970 | loss: 1.2647 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11348/2499940 | global iter:   5675/1249970 | loss: 1.7968 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11350/2499940 | global iter:   5676/1249970 | loss: 0.7703 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11350/2499940 | global iter:   5676/1249970 | loss: 1.3855 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11352/2499940 | global iter:   5677/1249970 | loss: 0.2866 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11354/2499940 | global iter:   5678/1249970 | loss: 1.0544 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11356/2499940 | global iter:   5679/1249970 | loss: 0.6656 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11358/2499940 | global iter:   5680/1249970 | loss: 1.0748 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11358/2499940 | global iter:   5680/1249970 | loss: 0.9630 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11360/2499940 | global iter:   5681/1249970 | loss: 1.9621 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11362/2499940 | global iter:   5682/1249970 | loss: 1.1431 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  11364/2499940 | global iter:   5683/1249970 | loss: 1.2367 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11366/2499940 | global iter:   5684/1249970 | loss: 1.5805 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11366/2499940 | global iter:   5684/1249970 | loss: 1.3525 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11368/2499940 | global iter:   5685/1249970 | loss: 1.0519 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11370/2499940 | global iter:   5686/1249970 | loss: 0.9687 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11372/2499940 | global iter:   5687/1249970 | loss: 0.0991 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11374/2499940 | global iter:   5688/1249970 | loss: 1.1013 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11374/2499940 | global iter:   5688/1249970 | loss: 0.8940 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11376/2499940 | global iter:   5689/1249970 | loss: 0.6844 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11378/2499940 | global iter:   5690/1249970 | loss: 1.4200 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11380/2499940 | global iter:   5691/1249970 | loss: 1.6226 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11382/2499940 | global iter:   5692/1249970 | loss: 1.1132 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11382/2499940 | global iter:   5692/1249970 | loss: 1.0877 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11384/2499940 | global iter:   5693/1249970 | loss: 1.9812 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11386/2499940 | global iter:   5694/1249970 | loss: 0.6367 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11388/2499940 | global iter:   5695/1249970 | loss: 0.5858 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11390/2499940 | global iter:   5696/1249970 | loss: 1.0592 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11390/2499940 | global iter:   5696/1249970 | loss: 1.0429 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11392/2499940 | global iter:   5697/1249970 | loss: 0.6409 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11394/2499940 | global iter:   5698/1249970 | loss: 0.8538 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11396/2499940 | global iter:   5699/1249970 | loss: 1.4792 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11398/2499940 | global iter:   5700/1249970 | loss: 1.2364 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11398/2499940 | global iter:   5700/1249970 | loss: 0.8983 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11400/2499940 | global iter:   5701/1249970 | loss: 1.4321 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11402/2499940 | global iter:   5702/1249970 | loss: 1.5527 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11404/2499940 | global iter:   5703/1249970 | loss: 0.8052 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11406/2499940 | global iter:   5704/1249970 | loss: 0.8282 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11406/2499940 | global iter:   5704/1249970 | loss: 1.1084 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11408/2499940 | global iter:   5705/1249970 | loss: 1.3929 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11410/2499940 | global iter:   5706/1249970 | loss: 1.7476 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  11412/2499940 | global iter:   5707/1249970 | loss: 0.5491 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11414/2499940 | global iter:   5708/1249970 | loss: 1.3175 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11414/2499940 | global iter:   5708/1249970 | loss: 1.2313 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11416/2499940 | global iter:   5709/1249970 | loss: 0.8745 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11418/2499940 | global iter:   5710/1249970 | loss: 1.4134 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11420/2499940 | global iter:   5711/1249970 | loss: 1.5973 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  11422/2499940 | global iter:   5712/1249970 | loss: 1.3808 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.405 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11422/2499940 | global iter:   5712/1249970 | loss: 1.1117 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.405 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11424/2499940 | global iter:   5713/1249970 | loss: 1.6171 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11426/2499940 | global iter:   5714/1249970 | loss: 1.5609 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11428/2499940 | global iter:   5715/1249970 | loss: 2.0040 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11430/2499940 | global iter:   5716/1249970 | loss: 1.3154 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11430/2499940 | global iter:   5716/1249970 | loss: 1.2643 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11432/2499940 | global iter:   5717/1249970 | loss: 0.8802 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11434/2499940 | global iter:   5718/1249970 | loss: 1.1837 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11436/2499940 | global iter:   5719/1249970 | loss: 0.5664 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11438/2499940 | global iter:   5720/1249970 | loss: 0.4211 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11438/2499940 | global iter:   5720/1249970 | loss: 1.1103 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11440/2499940 | global iter:   5721/1249970 | loss: 1.1507 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11442/2499940 | global iter:   5722/1249970 | loss: 1.5253 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11444/2499940 | global iter:   5723/1249970 | loss: 1.1964 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11446/2499940 | global iter:   5724/1249970 | loss: 1.6044 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11446/2499940 | global iter:   5724/1249970 | loss: 1.1362 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11448/2499940 | global iter:   5725/1249970 | loss: 1.1180 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11450/2499940 | global iter:   5726/1249970 | loss: 1.4150 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11452/2499940 | global iter:   5727/1249970 | loss: 1.0017 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11454/2499940 | global iter:   5728/1249970 | loss: 1.2340 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11454/2499940 | global iter:   5728/1249970 | loss: 1.2613 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11456/2499940 | global iter:   5729/1249970 | loss: 0.9866 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11458/2499940 | global iter:   5730/1249970 | loss: 1.3795 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11460/2499940 | global iter:   5731/1249970 | loss: 1.2058 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11462/2499940 | global iter:   5732/1249970 | loss: 1.0850 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11462/2499940 | global iter:   5732/1249970 | loss: 1.1609 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11464/2499940 | global iter:   5733/1249970 | loss: 1.0548 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11466/2499940 | global iter:   5734/1249970 | loss: 0.9947 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11468/2499940 | global iter:   5735/1249970 | loss: 1.3449 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11470/2499940 | global iter:   5736/1249970 | loss: 1.3198 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11470/2499940 | global iter:   5736/1249970 | loss: 1.2687 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11472/2499940 | global iter:   5737/1249970 | loss: 1.4506 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11474/2499940 | global iter:   5738/1249970 | loss: 1.0717 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  11476/2499940 | global iter:   5739/1249970 | loss: 1.2160 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11478/2499940 | global iter:   5740/1249970 | loss: 0.1894 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11478/2499940 | global iter:   5740/1249970 | loss: 0.9667 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11480/2499940 | global iter:   5741/1249970 | loss: 0.8297 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11482/2499940 | global iter:   5742/1249970 | loss: 1.2839 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11484/2499940 | global iter:   5743/1249970 | loss: 0.5042 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11486/2499940 | global iter:   5744/1249970 | loss: 1.2794 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11486/2499940 | global iter:   5744/1249970 | loss: 0.8917 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
[2025-04-20 17:19:43,117] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8192, reducing to 4096
train | epoch   0 | Iter:  11488/2499940 | global iter:   5745/1249970 | loss: 1.5057 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.310 | step time: 0.000
train | epoch   0 | Iter:  11490/2499940 | global iter:   5746/1249970 | loss: 1.3256 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11492/2499940 | global iter:   5747/1249970 | loss: 1.1433 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11494/2499940 | global iter:   5748/1249970 | loss: 1.5154 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11494/2499940 | global iter:   5748/1249970 | loss: 1.2621 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.668
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11496/2499940 | global iter:   5749/1249970 | loss: 1.3957 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11498/2499940 | global iter:   5750/1249970 | loss: 0.8763 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:  11500/2499940 | global iter:   5751/1249970 | loss: 0.7818 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11502/2499940 | global iter:   5752/1249970 | loss: 1.3114 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11502/2499940 | global iter:   5752/1249970 | loss: 1.0564 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11504/2499940 | global iter:   5753/1249970 | loss: 1.3628 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11506/2499940 | global iter:   5754/1249970 | loss: 1.1496 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11508/2499940 | global iter:   5755/1249970 | loss: 1.1839 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11510/2499940 | global iter:   5756/1249970 | loss: 1.3537 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11510/2499940 | global iter:   5756/1249970 | loss: 1.2907 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11512/2499940 | global iter:   5757/1249970 | loss: 1.5430 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11514/2499940 | global iter:   5758/1249970 | loss: 1.2015 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11516/2499940 | global iter:   5759/1249970 | loss: 1.8263 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11518/2499940 | global iter:   5760/1249970 | loss: 0.8775 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11518/2499940 | global iter:   5760/1249970 | loss: 1.2932 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11520/2499940 | global iter:   5761/1249970 | loss: 1.1712 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11522/2499940 | global iter:   5762/1249970 | loss: 0.0937 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11524/2499940 | global iter:   5763/1249970 | loss: 0.7672 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11526/2499940 | global iter:   5764/1249970 | loss: 0.5203 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11526/2499940 | global iter:   5764/1249970 | loss: 0.8681 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11528/2499940 | global iter:   5765/1249970 | loss: 0.7901 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11530/2499940 | global iter:   5766/1249970 | loss: 1.2548 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11532/2499940 | global iter:   5767/1249970 | loss: 1.9067 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11534/2499940 | global iter:   5768/1249970 | loss: 0.8046 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11534/2499940 | global iter:   5768/1249970 | loss: 1.0631 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11536/2499940 | global iter:   5769/1249970 | loss: 1.9599 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11538/2499940 | global iter:   5770/1249970 | loss: 0.8359 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11540/2499940 | global iter:   5771/1249970 | loss: 1.6904 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11542/2499940 | global iter:   5772/1249970 | loss: 0.6841 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11542/2499940 | global iter:   5772/1249970 | loss: 0.9377 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11544/2499940 | global iter:   5773/1249970 | loss: 1.4705 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11546/2499940 | global iter:   5774/1249970 | loss: 0.3661 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11548/2499940 | global iter:   5775/1249970 | loss: 1.1022 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11550/2499940 | global iter:   5776/1249970 | loss: 0.4904 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11550/2499940 | global iter:   5776/1249970 | loss: 1.1401 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11552/2499940 | global iter:   5777/1249970 | loss: 0.6352 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11554/2499940 | global iter:   5778/1249970 | loss: 0.7055 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  11556/2499940 | global iter:   5779/1249970 | loss: 1.1588 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  11558/2499940 | global iter:   5780/1249970 | loss: 1.2149 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11558/2499940 | global iter:   5780/1249970 | loss: 1.0559 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11560/2499940 | global iter:   5781/1249970 | loss: 1.8991 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11562/2499940 | global iter:   5782/1249970 | loss: 1.3697 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  11564/2499940 | global iter:   5783/1249970 | loss: 0.6947 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11566/2499940 | global iter:   5784/1249970 | loss: 1.2371 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11566/2499940 | global iter:   5784/1249970 | loss: 1.1698 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11568/2499940 | global iter:   5785/1249970 | loss: 1.4377 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11570/2499940 | global iter:   5786/1249970 | loss: 0.5094 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  11572/2499940 | global iter:   5787/1249970 | loss: 1.0652 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11574/2499940 | global iter:   5788/1249970 | loss: 1.3187 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11574/2499940 | global iter:   5788/1249970 | loss: 0.9259 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11576/2499940 | global iter:   5789/1249970 | loss: 1.3585 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11578/2499940 | global iter:   5790/1249970 | loss: 1.3813 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11580/2499940 | global iter:   5791/1249970 | loss: 0.4768 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11582/2499940 | global iter:   5792/1249970 | loss: 0.7842 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11582/2499940 | global iter:   5792/1249970 | loss: 1.1092 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11584/2499940 | global iter:   5793/1249970 | loss: 1.0279 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  11586/2499940 | global iter:   5794/1249970 | loss: 1.6683 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11588/2499940 | global iter:   5795/1249970 | loss: 0.8714 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11590/2499940 | global iter:   5796/1249970 | loss: 1.7963 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11590/2499940 | global iter:   5796/1249970 | loss: 1.2769 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11592/2499940 | global iter:   5797/1249970 | loss: 0.2889 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11594/2499940 | global iter:   5798/1249970 | loss: 0.1678 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11596/2499940 | global iter:   5799/1249970 | loss: 1.0852 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.410 | step time: 0.000
train | epoch   0 | Iter:  11598/2499940 | global iter:   5800/1249970 | loss: 1.1578 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11598/2499940 | global iter:   5800/1249970 | loss: 0.7830 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.695
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11600/2499940 | global iter:   5801/1249970 | loss: 1.5544 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11602/2499940 | global iter:   5802/1249970 | loss: 1.1791 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11604/2499940 | global iter:   5803/1249970 | loss: 1.0251 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11606/2499940 | global iter:   5804/1249970 | loss: 0.9307 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11606/2499940 | global iter:   5804/1249970 | loss: 1.0940 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11608/2499940 | global iter:   5805/1249970 | loss: 1.2468 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11610/2499940 | global iter:   5806/1249970 | loss: 2.0814 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  11612/2499940 | global iter:   5807/1249970 | loss: 1.4866 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11614/2499940 | global iter:   5808/1249970 | loss: 1.4606 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11614/2499940 | global iter:   5808/1249970 | loss: 1.3353 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11616/2499940 | global iter:   5809/1249970 | loss: 1.4378 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11618/2499940 | global iter:   5810/1249970 | loss: 1.2372 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  11620/2499940 | global iter:   5811/1249970 | loss: 1.5528 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  11622/2499940 | global iter:   5812/1249970 | loss: 1.7487 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11622/2499940 | global iter:   5812/1249970 | loss: 1.6486 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11624/2499940 | global iter:   5813/1249970 | loss: 1.1896 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11626/2499940 | global iter:   5814/1249970 | loss: 1.1778 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11628/2499940 | global iter:   5815/1249970 | loss: 1.2812 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11630/2499940 | global iter:   5816/1249970 | loss: 0.9581 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11630/2499940 | global iter:   5816/1249970 | loss: 0.9551 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11632/2499940 | global iter:   5817/1249970 | loss: 0.5682 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11634/2499940 | global iter:   5818/1249970 | loss: 1.0505 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11636/2499940 | global iter:   5819/1249970 | loss: 1.1997 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11638/2499940 | global iter:   5820/1249970 | loss: 1.0668 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11638/2499940 | global iter:   5820/1249970 | loss: 0.9104 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11640/2499940 | global iter:   5821/1249970 | loss: 0.8304 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11642/2499940 | global iter:   5822/1249970 | loss: 1.6475 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  11644/2499940 | global iter:   5823/1249970 | loss: 0.9469 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11646/2499940 | global iter:   5824/1249970 | loss: 0.9842 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11646/2499940 | global iter:   5824/1249970 | loss: 1.1486 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11648/2499940 | global iter:   5825/1249970 | loss: 0.9877 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11650/2499940 | global iter:   5826/1249970 | loss: 1.6521 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11652/2499940 | global iter:   5827/1249970 | loss: 1.2714 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11654/2499940 | global iter:   5828/1249970 | loss: 0.0878 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11654/2499940 | global iter:   5828/1249970 | loss: 1.0260 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11656/2499940 | global iter:   5829/1249970 | loss: 0.6974 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11658/2499940 | global iter:   5830/1249970 | loss: 0.7133 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11660/2499940 | global iter:   5831/1249970 | loss: 1.2811 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11662/2499940 | global iter:   5832/1249970 | loss: 0.8495 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11662/2499940 | global iter:   5832/1249970 | loss: 1.0676 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11664/2499940 | global iter:   5833/1249970 | loss: 1.0294 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11666/2499940 | global iter:   5834/1249970 | loss: 1.1611 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11668/2499940 | global iter:   5835/1249970 | loss: 0.1925 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11670/2499940 | global iter:   5836/1249970 | loss: 1.5921 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11670/2499940 | global iter:   5836/1249970 | loss: 1.1988 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11672/2499940 | global iter:   5837/1249970 | loss: 1.2942 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11674/2499940 | global iter:   5838/1249970 | loss: 0.3114 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11676/2499940 | global iter:   5839/1249970 | loss: 1.4812 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11678/2499940 | global iter:   5840/1249970 | loss: 0.6519 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11678/2499940 | global iter:   5840/1249970 | loss: 1.0220 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11680/2499940 | global iter:   5841/1249970 | loss: 0.3225 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11682/2499940 | global iter:   5842/1249970 | loss: 1.4143 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11684/2499940 | global iter:   5843/1249970 | loss: 0.6263 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.412 | step time: 0.000
train | epoch   0 | Iter:  11686/2499940 | global iter:   5844/1249970 | loss: 0.7465 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11686/2499940 | global iter:   5844/1249970 | loss: 1.0291 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.695
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11688/2499940 | global iter:   5845/1249970 | loss: 0.7310 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11690/2499940 | global iter:   5846/1249970 | loss: 0.4681 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11692/2499940 | global iter:   5847/1249970 | loss: 1.0236 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11694/2499940 | global iter:   5848/1249970 | loss: 0.1698 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11694/2499940 | global iter:   5848/1249970 | loss: 0.7585 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11696/2499940 | global iter:   5849/1249970 | loss: 1.4240 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11698/2499940 | global iter:   5850/1249970 | loss: 1.3763 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11700/2499940 | global iter:   5851/1249970 | loss: 0.9764 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  11702/2499940 | global iter:   5852/1249970 | loss: 1.4612 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11702/2499940 | global iter:   5852/1249970 | loss: 1.2874 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11704/2499940 | global iter:   5853/1249970 | loss: 1.5106 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11706/2499940 | global iter:   5854/1249970 | loss: 1.3842 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  11708/2499940 | global iter:   5855/1249970 | loss: 0.3654 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11710/2499940 | global iter:   5856/1249970 | loss: 1.1691 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11710/2499940 | global iter:   5856/1249970 | loss: 1.2198 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11712/2499940 | global iter:   5857/1249970 | loss: 0.2742 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11714/2499940 | global iter:   5858/1249970 | loss: 1.1978 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11716/2499940 | global iter:   5859/1249970 | loss: 0.9496 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11718/2499940 | global iter:   5860/1249970 | loss: 0.8417 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11718/2499940 | global iter:   5860/1249970 | loss: 0.6992 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11720/2499940 | global iter:   5861/1249970 | loss: 0.1936 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11722/2499940 | global iter:   5862/1249970 | loss: 1.1064 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11724/2499940 | global iter:   5863/1249970 | loss: 0.9278 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11726/2499940 | global iter:   5864/1249970 | loss: 1.8237 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11726/2499940 | global iter:   5864/1249970 | loss: 1.1597 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11728/2499940 | global iter:   5865/1249970 | loss: 0.5746 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11730/2499940 | global iter:   5866/1249970 | loss: 1.6716 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11732/2499940 | global iter:   5867/1249970 | loss: 1.6512 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11734/2499940 | global iter:   5868/1249970 | loss: 0.9570 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11734/2499940 | global iter:   5868/1249970 | loss: 1.2780 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11736/2499940 | global iter:   5869/1249970 | loss: 0.8339 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11738/2499940 | global iter:   5870/1249970 | loss: 1.6194 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11740/2499940 | global iter:   5871/1249970 | loss: 0.4025 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11742/2499940 | global iter:   5872/1249970 | loss: 1.4481 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11742/2499940 | global iter:   5872/1249970 | loss: 1.0124 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11744/2499940 | global iter:   5873/1249970 | loss: 1.3078 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11746/2499940 | global iter:   5874/1249970 | loss: 1.8965 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11748/2499940 | global iter:   5875/1249970 | loss: 1.8638 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11750/2499940 | global iter:   5876/1249970 | loss: 0.6200 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11750/2499940 | global iter:   5876/1249970 | loss: 1.4058 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11752/2499940 | global iter:   5877/1249970 | loss: 0.6470 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11754/2499940 | global iter:   5878/1249970 | loss: 1.0260 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11756/2499940 | global iter:   5879/1249970 | loss: 1.3984 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11758/2499940 | global iter:   5880/1249970 | loss: 0.8108 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11758/2499940 | global iter:   5880/1249970 | loss: 1.0701 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11760/2499940 | global iter:   5881/1249970 | loss: 1.0979 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11762/2499940 | global iter:   5882/1249970 | loss: 0.9079 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11764/2499940 | global iter:   5883/1249970 | loss: 0.8160 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11766/2499940 | global iter:   5884/1249970 | loss: 1.2308 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11766/2499940 | global iter:   5884/1249970 | loss: 1.1357 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11768/2499940 | global iter:   5885/1249970 | loss: 1.0878 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11770/2499940 | global iter:   5886/1249970 | loss: 1.4755 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  11772/2499940 | global iter:   5887/1249970 | loss: 0.9691 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11774/2499940 | global iter:   5888/1249970 | loss: 0.7130 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11774/2499940 | global iter:   5888/1249970 | loss: 0.8217 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11776/2499940 | global iter:   5889/1249970 | loss: 1.7327 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11778/2499940 | global iter:   5890/1249970 | loss: 1.3355 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11780/2499940 | global iter:   5891/1249970 | loss: 1.5264 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  11782/2499940 | global iter:   5892/1249970 | loss: 1.4590 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11782/2499940 | global iter:   5892/1249970 | loss: 1.5001 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11784/2499940 | global iter:   5893/1249970 | loss: 1.2027 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11786/2499940 | global iter:   5894/1249970 | loss: 1.4512 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11788/2499940 | global iter:   5895/1249970 | loss: 0.6605 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11790/2499940 | global iter:   5896/1249970 | loss: 1.2780 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11790/2499940 | global iter:   5896/1249970 | loss: 1.4049 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11792/2499940 | global iter:   5897/1249970 | loss: 1.0866 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11794/2499940 | global iter:   5898/1249970 | loss: 1.4438 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11796/2499940 | global iter:   5899/1249970 | loss: 0.9183 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11798/2499940 | global iter:   5900/1249970 | loss: 1.6512 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11798/2499940 | global iter:   5900/1249970 | loss: 1.3037 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11800/2499940 | global iter:   5901/1249970 | loss: 0.0792 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11802/2499940 | global iter:   5902/1249970 | loss: 0.8694 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11804/2499940 | global iter:   5903/1249970 | loss: 1.3478 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11806/2499940 | global iter:   5904/1249970 | loss: 0.7955 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11806/2499940 | global iter:   5904/1249970 | loss: 1.1255 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11808/2499940 | global iter:   5905/1249970 | loss: 1.5996 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11810/2499940 | global iter:   5906/1249970 | loss: 1.9858 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  11812/2499940 | global iter:   5907/1249970 | loss: 1.3234 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11814/2499940 | global iter:   5908/1249970 | loss: 2.3395 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11814/2499940 | global iter:   5908/1249970 | loss: 1.4103 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11816/2499940 | global iter:   5909/1249970 | loss: 1.4578 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11818/2499940 | global iter:   5910/1249970 | loss: 1.2547 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11820/2499940 | global iter:   5911/1249970 | loss: 0.8781 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11822/2499940 | global iter:   5912/1249970 | loss: 1.1401 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11822/2499940 | global iter:   5912/1249970 | loss: 1.0856 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11824/2499940 | global iter:   5913/1249970 | loss: 1.8129 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11826/2499940 | global iter:   5914/1249970 | loss: 0.5853 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11828/2499940 | global iter:   5915/1249970 | loss: 0.8225 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11830/2499940 | global iter:   5916/1249970 | loss: 0.1482 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11830/2499940 | global iter:   5916/1249970 | loss: 0.9081 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11832/2499940 | global iter:   5917/1249970 | loss: 0.3783 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11834/2499940 | global iter:   5918/1249970 | loss: 0.0501 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11836/2499940 | global iter:   5919/1249970 | loss: 0.9276 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11838/2499940 | global iter:   5920/1249970 | loss: 0.5974 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11838/2499940 | global iter:   5920/1249970 | loss: 0.7111 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11840/2499940 | global iter:   5921/1249970 | loss: 1.0539 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11842/2499940 | global iter:   5922/1249970 | loss: 1.3631 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11844/2499940 | global iter:   5923/1249970 | loss: 2.3898 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11846/2499940 | global iter:   5924/1249970 | loss: 0.2189 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11846/2499940 | global iter:   5924/1249970 | loss: 1.1344 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11848/2499940 | global iter:   5925/1249970 | loss: 0.9287 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11850/2499940 | global iter:   5926/1249970 | loss: 0.2807 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11852/2499940 | global iter:   5927/1249970 | loss: 0.6236 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11854/2499940 | global iter:   5928/1249970 | loss: 1.0567 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11854/2499940 | global iter:   5928/1249970 | loss: 0.8234 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11856/2499940 | global iter:   5929/1249970 | loss: 1.2813 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11858/2499940 | global iter:   5930/1249970 | loss: 0.7954 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11860/2499940 | global iter:   5931/1249970 | loss: 0.9442 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11862/2499940 | global iter:   5932/1249970 | loss: 0.0880 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11862/2499940 | global iter:   5932/1249970 | loss: 0.7829 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11864/2499940 | global iter:   5933/1249970 | loss: 1.2321 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11866/2499940 | global iter:   5934/1249970 | loss: 1.7124 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11868/2499940 | global iter:   5935/1249970 | loss: 1.3022 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11870/2499940 | global iter:   5936/1249970 | loss: 0.6660 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11870/2499940 | global iter:   5936/1249970 | loss: 1.0829 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11872/2499940 | global iter:   5937/1249970 | loss: 1.4189 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11874/2499940 | global iter:   5938/1249970 | loss: 0.9858 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11876/2499940 | global iter:   5939/1249970 | loss: 0.2878 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11878/2499940 | global iter:   5940/1249970 | loss: 0.7027 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11878/2499940 | global iter:   5940/1249970 | loss: 0.9254 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11880/2499940 | global iter:   5941/1249970 | loss: 1.5376 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11882/2499940 | global iter:   5942/1249970 | loss: 0.2976 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11884/2499940 | global iter:   5943/1249970 | loss: 0.9241 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11886/2499940 | global iter:   5944/1249970 | loss: 1.2637 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11886/2499940 | global iter:   5944/1249970 | loss: 1.2287 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11888/2499940 | global iter:   5945/1249970 | loss: 1.4561 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11890/2499940 | global iter:   5946/1249970 | loss: 0.7435 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11892/2499940 | global iter:   5947/1249970 | loss: 2.0095 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11894/2499940 | global iter:   5948/1249970 | loss: 0.6794 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11894/2499940 | global iter:   5948/1249970 | loss: 1.2168 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11896/2499940 | global iter:   5949/1249970 | loss: 0.8731 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11898/2499940 | global iter:   5950/1249970 | loss: 0.7982 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11900/2499940 | global iter:   5951/1249970 | loss: 0.6470 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11902/2499940 | global iter:   5952/1249970 | loss: 0.2817 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11902/2499940 | global iter:   5952/1249970 | loss: 0.9993 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11904/2499940 | global iter:   5953/1249970 | loss: 0.7388 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  11906/2499940 | global iter:   5954/1249970 | loss: 1.8647 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  11908/2499940 | global iter:   5955/1249970 | loss: 0.9463 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  11910/2499940 | global iter:   5956/1249970 | loss: 1.6861 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11910/2499940 | global iter:   5956/1249970 | loss: 1.2298 | ds_loss: 0.0000 | lr: 9.9995e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11912/2499940 | global iter:   5957/1249970 | loss: 0.9442 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11914/2499940 | global iter:   5958/1249970 | loss: 0.8464 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11916/2499940 | global iter:   5959/1249970 | loss: 0.9083 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11918/2499940 | global iter:   5960/1249970 | loss: 1.1117 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11918/2499940 | global iter:   5960/1249970 | loss: 1.2117 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11920/2499940 | global iter:   5961/1249970 | loss: 1.4690 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11922/2499940 | global iter:   5962/1249970 | loss: 1.4424 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11924/2499940 | global iter:   5963/1249970 | loss: 1.5783 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  11926/2499940 | global iter:   5964/1249970 | loss: 0.2084 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11926/2499940 | global iter:   5964/1249970 | loss: 1.3394 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11928/2499940 | global iter:   5965/1249970 | loss: 0.3798 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11930/2499940 | global iter:   5966/1249970 | loss: 1.1935 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11932/2499940 | global iter:   5967/1249970 | loss: 0.7251 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11934/2499940 | global iter:   5968/1249970 | loss: 0.5201 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11934/2499940 | global iter:   5968/1249970 | loss: 1.1040 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11936/2499940 | global iter:   5969/1249970 | loss: 0.4948 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11938/2499940 | global iter:   5970/1249970 | loss: 2.1117 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11940/2499940 | global iter:   5971/1249970 | loss: 0.7689 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11942/2499940 | global iter:   5972/1249970 | loss: 0.8793 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.404 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11942/2499940 | global iter:   5972/1249970 | loss: 1.1457 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.404 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11944/2499940 | global iter:   5973/1249970 | loss: 1.6908 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11946/2499940 | global iter:   5974/1249970 | loss: 0.8363 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11948/2499940 | global iter:   5975/1249970 | loss: 1.4725 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11950/2499940 | global iter:   5976/1249970 | loss: 0.9494 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11950/2499940 | global iter:   5976/1249970 | loss: 1.0170 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11952/2499940 | global iter:   5977/1249970 | loss: 1.0773 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11954/2499940 | global iter:   5978/1249970 | loss: 1.3003 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  11956/2499940 | global iter:   5979/1249970 | loss: 0.8780 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11958/2499940 | global iter:   5980/1249970 | loss: 1.4795 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11958/2499940 | global iter:   5980/1249970 | loss: 1.1945 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11960/2499940 | global iter:   5981/1249970 | loss: 1.0467 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11962/2499940 | global iter:   5982/1249970 | loss: 1.4010 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11964/2499940 | global iter:   5983/1249970 | loss: 1.4483 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11966/2499940 | global iter:   5984/1249970 | loss: 1.2802 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11966/2499940 | global iter:   5984/1249970 | loss: 1.3114 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11968/2499940 | global iter:   5985/1249970 | loss: 1.1809 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11970/2499940 | global iter:   5986/1249970 | loss: 1.7453 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  11972/2499940 | global iter:   5987/1249970 | loss: 0.4685 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  11974/2499940 | global iter:   5988/1249970 | loss: 0.6945 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11974/2499940 | global iter:   5988/1249970 | loss: 1.1972 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11976/2499940 | global iter:   5989/1249970 | loss: 1.1792 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11978/2499940 | global iter:   5990/1249970 | loss: 1.5194 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  11980/2499940 | global iter:   5991/1249970 | loss: 0.9858 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11982/2499940 | global iter:   5992/1249970 | loss: 0.7950 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11982/2499940 | global iter:   5992/1249970 | loss: 1.1272 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11984/2499940 | global iter:   5993/1249970 | loss: 1.2025 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11986/2499940 | global iter:   5994/1249970 | loss: 0.6728 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  11988/2499940 | global iter:   5995/1249970 | loss: 1.4984 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  11990/2499940 | global iter:   5996/1249970 | loss: 1.6778 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11990/2499940 | global iter:   5996/1249970 | loss: 1.1701 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.393 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  11992/2499940 | global iter:   5997/1249970 | loss: 1.4576 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  11994/2499940 | global iter:   5998/1249970 | loss: 0.5514 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  11996/2499940 | global iter:   5999/1249970 | loss: 1.7663 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  11998/2499940 | global iter:   6000/1249970 | loss: 0.6899 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  11998/2499940 | global iter:   6000/1249970 | loss: 0.9540 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.686
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12000/2499940 | global iter:   6001/1249970 | loss: 1.9242 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  12002/2499940 | global iter:   6002/1249970 | loss: 1.4549 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12004/2499940 | global iter:   6003/1249970 | loss: 0.7353 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12006/2499940 | global iter:   6004/1249970 | loss: 1.6796 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12006/2499940 | global iter:   6004/1249970 | loss: 1.3313 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12008/2499940 | global iter:   6005/1249970 | loss: 1.0065 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12010/2499940 | global iter:   6006/1249970 | loss: 0.9777 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12012/2499940 | global iter:   6007/1249970 | loss: 2.3077 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12014/2499940 | global iter:   6008/1249970 | loss: 1.2096 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12014/2499940 | global iter:   6008/1249970 | loss: 1.1730 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12016/2499940 | global iter:   6009/1249970 | loss: 1.1652 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12018/2499940 | global iter:   6010/1249970 | loss: 1.1464 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  12020/2499940 | global iter:   6011/1249970 | loss: 0.5563 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12022/2499940 | global iter:   6012/1249970 | loss: 1.4943 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12022/2499940 | global iter:   6012/1249970 | loss: 0.9823 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12024/2499940 | global iter:   6013/1249970 | loss: 1.3145 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12026/2499940 | global iter:   6014/1249970 | loss: 1.0571 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12028/2499940 | global iter:   6015/1249970 | loss: 0.6731 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12030/2499940 | global iter:   6016/1249970 | loss: 1.2444 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12030/2499940 | global iter:   6016/1249970 | loss: 1.1453 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12032/2499940 | global iter:   6017/1249970 | loss: 0.6653 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12034/2499940 | global iter:   6018/1249970 | loss: 1.5875 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12036/2499940 | global iter:   6019/1249970 | loss: 1.8652 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12038/2499940 | global iter:   6020/1249970 | loss: 1.1100 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12038/2499940 | global iter:   6020/1249970 | loss: 1.1067 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12040/2499940 | global iter:   6021/1249970 | loss: 1.1423 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12042/2499940 | global iter:   6022/1249970 | loss: 1.0565 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  12044/2499940 | global iter:   6023/1249970 | loss: 0.6669 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12046/2499940 | global iter:   6024/1249970 | loss: 1.6276 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12046/2499940 | global iter:   6024/1249970 | loss: 1.2344 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12048/2499940 | global iter:   6025/1249970 | loss: 1.2694 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12050/2499940 | global iter:   6026/1249970 | loss: 0.9896 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12052/2499940 | global iter:   6027/1249970 | loss: 0.6722 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12054/2499940 | global iter:   6028/1249970 | loss: 1.7255 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12054/2499940 | global iter:   6028/1249970 | loss: 1.1488 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12056/2499940 | global iter:   6029/1249970 | loss: 2.6652 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  12058/2499940 | global iter:   6030/1249970 | loss: 1.5975 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12060/2499940 | global iter:   6031/1249970 | loss: 1.1971 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  12062/2499940 | global iter:   6032/1249970 | loss: 0.5629 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12062/2499940 | global iter:   6032/1249970 | loss: 1.2827 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12064/2499940 | global iter:   6033/1249970 | loss: 1.2854 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12066/2499940 | global iter:   6034/1249970 | loss: 0.9146 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12068/2499940 | global iter:   6035/1249970 | loss: 1.2481 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12070/2499940 | global iter:   6036/1249970 | loss: 0.9302 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12070/2499940 | global iter:   6036/1249970 | loss: 1.1996 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12072/2499940 | global iter:   6037/1249970 | loss: 1.3036 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12074/2499940 | global iter:   6038/1249970 | loss: 0.8030 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  12076/2499940 | global iter:   6039/1249970 | loss: 1.8594 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12078/2499940 | global iter:   6040/1249970 | loss: 1.3688 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12078/2499940 | global iter:   6040/1249970 | loss: 1.2849 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12080/2499940 | global iter:   6041/1249970 | loss: 0.7030 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12082/2499940 | global iter:   6042/1249970 | loss: 1.4108 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12084/2499940 | global iter:   6043/1249970 | loss: 0.9507 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12086/2499940 | global iter:   6044/1249970 | loss: 0.9251 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12086/2499940 | global iter:   6044/1249970 | loss: 0.8207 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12088/2499940 | global iter:   6045/1249970 | loss: 0.7266 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12090/2499940 | global iter:   6046/1249970 | loss: 0.8708 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  12092/2499940 | global iter:   6047/1249970 | loss: 0.8675 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  12094/2499940 | global iter:   6048/1249970 | loss: 0.1913 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12094/2499940 | global iter:   6048/1249970 | loss: 0.6693 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12096/2499940 | global iter:   6049/1249970 | loss: 1.3297 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12098/2499940 | global iter:   6050/1249970 | loss: 1.8689 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  12100/2499940 | global iter:   6051/1249970 | loss: 0.8985 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  12102/2499940 | global iter:   6052/1249970 | loss: 0.2369 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12102/2499940 | global iter:   6052/1249970 | loss: 1.1296 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12104/2499940 | global iter:   6053/1249970 | loss: 1.3278 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12106/2499940 | global iter:   6054/1249970 | loss: 0.6424 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12108/2499940 | global iter:   6055/1249970 | loss: 1.2106 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  12110/2499940 | global iter:   6056/1249970 | loss: 0.9945 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12110/2499940 | global iter:   6056/1249970 | loss: 0.9130 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12112/2499940 | global iter:   6057/1249970 | loss: 1.3649 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12114/2499940 | global iter:   6058/1249970 | loss: 0.9140 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12116/2499940 | global iter:   6059/1249970 | loss: 1.2493 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.410 | step time: 0.000
train | epoch   0 | Iter:  12118/2499940 | global iter:   6060/1249970 | loss: 1.0810 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12118/2499940 | global iter:   6060/1249970 | loss: 1.1624 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12120/2499940 | global iter:   6061/1249970 | loss: 0.6023 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12122/2499940 | global iter:   6062/1249970 | loss: 1.4386 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12124/2499940 | global iter:   6063/1249970 | loss: 1.5331 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12126/2499940 | global iter:   6064/1249970 | loss: 0.3870 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12126/2499940 | global iter:   6064/1249970 | loss: 0.7983 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12128/2499940 | global iter:   6065/1249970 | loss: 0.7065 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12130/2499940 | global iter:   6066/1249970 | loss: 1.2629 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12132/2499940 | global iter:   6067/1249970 | loss: 1.7767 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12134/2499940 | global iter:   6068/1249970 | loss: 0.4473 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12134/2499940 | global iter:   6068/1249970 | loss: 1.0076 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12136/2499940 | global iter:   6069/1249970 | loss: 0.8342 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  12138/2499940 | global iter:   6070/1249970 | loss: 0.9595 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12140/2499940 | global iter:   6071/1249970 | loss: 0.2963 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12142/2499940 | global iter:   6072/1249970 | loss: 0.8467 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12142/2499940 | global iter:   6072/1249970 | loss: 0.9439 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12144/2499940 | global iter:   6073/1249970 | loss: 1.5673 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12146/2499940 | global iter:   6074/1249970 | loss: 0.9983 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  12148/2499940 | global iter:   6075/1249970 | loss: 0.8734 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12150/2499940 | global iter:   6076/1249970 | loss: 1.5892 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12150/2499940 | global iter:   6076/1249970 | loss: 1.1777 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12152/2499940 | global iter:   6077/1249970 | loss: 1.4406 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12154/2499940 | global iter:   6078/1249970 | loss: 0.7131 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  12156/2499940 | global iter:   6079/1249970 | loss: 0.9235 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12158/2499940 | global iter:   6080/1249970 | loss: 1.1410 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12158/2499940 | global iter:   6080/1249970 | loss: 1.1203 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12160/2499940 | global iter:   6081/1249970 | loss: 2.3002 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  12162/2499940 | global iter:   6082/1249970 | loss: 0.5635 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12164/2499940 | global iter:   6083/1249970 | loss: 0.6808 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12166/2499940 | global iter:   6084/1249970 | loss: 0.7931 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12166/2499940 | global iter:   6084/1249970 | loss: 1.0694 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12168/2499940 | global iter:   6085/1249970 | loss: 1.7577 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12170/2499940 | global iter:   6086/1249970 | loss: 1.2186 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  12172/2499940 | global iter:   6087/1249970 | loss: 1.4759 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12174/2499940 | global iter:   6088/1249970 | loss: 0.4402 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12174/2499940 | global iter:   6088/1249970 | loss: 1.3044 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12176/2499940 | global iter:   6089/1249970 | loss: 1.0370 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12178/2499940 | global iter:   6090/1249970 | loss: 1.0240 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12180/2499940 | global iter:   6091/1249970 | loss: 1.5179 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12182/2499940 | global iter:   6092/1249970 | loss: 1.7361 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12182/2499940 | global iter:   6092/1249970 | loss: 1.3115 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12184/2499940 | global iter:   6093/1249970 | loss: 1.0520 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  12186/2499940 | global iter:   6094/1249970 | loss: 1.1909 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12188/2499940 | global iter:   6095/1249970 | loss: 1.5129 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12190/2499940 | global iter:   6096/1249970 | loss: 1.0320 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12190/2499940 | global iter:   6096/1249970 | loss: 1.0629 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12192/2499940 | global iter:   6097/1249970 | loss: 0.8366 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12194/2499940 | global iter:   6098/1249970 | loss: 0.5534 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12196/2499940 | global iter:   6099/1249970 | loss: 1.8483 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12198/2499940 | global iter:   6100/1249970 | loss: 1.3471 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12198/2499940 | global iter:   6100/1249970 | loss: 1.1022 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12200/2499940 | global iter:   6101/1249970 | loss: 1.6818 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12202/2499940 | global iter:   6102/1249970 | loss: 1.1427 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12204/2499940 | global iter:   6103/1249970 | loss: 1.2208 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.412 | step time: 0.000
train | epoch   0 | Iter:  12206/2499940 | global iter:   6104/1249970 | loss: 1.4126 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12206/2499940 | global iter:   6104/1249970 | loss: 1.3570 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12208/2499940 | global iter:   6105/1249970 | loss: 1.0184 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12210/2499940 | global iter:   6106/1249970 | loss: 0.5405 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  12212/2499940 | global iter:   6107/1249970 | loss: 0.9751 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12214/2499940 | global iter:   6108/1249970 | loss: 0.6994 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12214/2499940 | global iter:   6108/1249970 | loss: 0.9982 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12216/2499940 | global iter:   6109/1249970 | loss: 0.9639 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12218/2499940 | global iter:   6110/1249970 | loss: 0.4709 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12220/2499940 | global iter:   6111/1249970 | loss: 0.2691 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12222/2499940 | global iter:   6112/1249970 | loss: 1.3993 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12222/2499940 | global iter:   6112/1249970 | loss: 0.8925 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12224/2499940 | global iter:   6113/1249970 | loss: 1.3688 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12226/2499940 | global iter:   6114/1249970 | loss: 1.3580 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12228/2499940 | global iter:   6115/1249970 | loss: 1.2072 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12230/2499940 | global iter:   6116/1249970 | loss: 0.7101 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12230/2499940 | global iter:   6116/1249970 | loss: 1.2565 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12232/2499940 | global iter:   6117/1249970 | loss: 0.4474 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  12234/2499940 | global iter:   6118/1249970 | loss: 1.4173 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12236/2499940 | global iter:   6119/1249970 | loss: 1.8040 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12238/2499940 | global iter:   6120/1249970 | loss: 0.4049 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12238/2499940 | global iter:   6120/1249970 | loss: 1.2273 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12240/2499940 | global iter:   6121/1249970 | loss: 0.5113 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12242/2499940 | global iter:   6122/1249970 | loss: 0.7755 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12244/2499940 | global iter:   6123/1249970 | loss: 1.3129 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12246/2499940 | global iter:   6124/1249970 | loss: 1.5293 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12246/2499940 | global iter:   6124/1249970 | loss: 1.0252 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12248/2499940 | global iter:   6125/1249970 | loss: 1.0944 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12250/2499940 | global iter:   6126/1249970 | loss: 1.0555 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  12252/2499940 | global iter:   6127/1249970 | loss: 1.4728 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12254/2499940 | global iter:   6128/1249970 | loss: 1.2058 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12254/2499940 | global iter:   6128/1249970 | loss: 1.1063 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12256/2499940 | global iter:   6129/1249970 | loss: 1.4751 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12258/2499940 | global iter:   6130/1249970 | loss: 1.1617 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12260/2499940 | global iter:   6131/1249970 | loss: 1.2715 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12262/2499940 | global iter:   6132/1249970 | loss: 1.0124 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12262/2499940 | global iter:   6132/1249970 | loss: 1.1704 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12264/2499940 | global iter:   6133/1249970 | loss: 1.3275 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12266/2499940 | global iter:   6134/1249970 | loss: 1.1388 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12268/2499940 | global iter:   6135/1249970 | loss: 1.2313 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12270/2499940 | global iter:   6136/1249970 | loss: 1.0563 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12270/2499940 | global iter:   6136/1249970 | loss: 1.2185 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12272/2499940 | global iter:   6137/1249970 | loss: 1.0010 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12274/2499940 | global iter:   6138/1249970 | loss: 1.7450 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12276/2499940 | global iter:   6139/1249970 | loss: 1.2951 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12278/2499940 | global iter:   6140/1249970 | loss: 0.3953 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12278/2499940 | global iter:   6140/1249970 | loss: 0.9577 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12280/2499940 | global iter:   6141/1249970 | loss: 0.6194 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12282/2499940 | global iter:   6142/1249970 | loss: 1.5941 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12284/2499940 | global iter:   6143/1249970 | loss: 1.2242 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12286/2499940 | global iter:   6144/1249970 | loss: 1.0449 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12286/2499940 | global iter:   6144/1249970 | loss: 1.1786 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12288/2499940 | global iter:   6145/1249970 | loss: 1.0599 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12290/2499940 | global iter:   6146/1249970 | loss: 0.3441 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.409 | step time: 0.000
train | epoch   0 | Iter:  12292/2499940 | global iter:   6147/1249970 | loss: 1.0941 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12294/2499940 | global iter:   6148/1249970 | loss: 0.2089 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12294/2499940 | global iter:   6148/1249970 | loss: 0.9318 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12296/2499940 | global iter:   6149/1249970 | loss: 0.4282 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12298/2499940 | global iter:   6150/1249970 | loss: 1.8246 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12300/2499940 | global iter:   6151/1249970 | loss: 1.0802 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12302/2499940 | global iter:   6152/1249970 | loss: 0.5192 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12302/2499940 | global iter:   6152/1249970 | loss: 1.0548 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12304/2499940 | global iter:   6153/1249970 | loss: 1.5959 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12306/2499940 | global iter:   6154/1249970 | loss: 1.3960 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12308/2499940 | global iter:   6155/1249970 | loss: 0.9690 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12310/2499940 | global iter:   6156/1249970 | loss: 0.7968 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12310/2499940 | global iter:   6156/1249970 | loss: 1.1532 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12312/2499940 | global iter:   6157/1249970 | loss: 0.2908 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12314/2499940 | global iter:   6158/1249970 | loss: 1.1493 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12316/2499940 | global iter:   6159/1249970 | loss: 0.8407 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12318/2499940 | global iter:   6160/1249970 | loss: 1.0673 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12318/2499940 | global iter:   6160/1249970 | loss: 0.9574 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12320/2499940 | global iter:   6161/1249970 | loss: 1.3937 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12322/2499940 | global iter:   6162/1249970 | loss: 1.0099 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12324/2499940 | global iter:   6163/1249970 | loss: 0.8079 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12326/2499940 | global iter:   6164/1249970 | loss: 0.2431 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12326/2499940 | global iter:   6164/1249970 | loss: 1.0317 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12328/2499940 | global iter:   6165/1249970 | loss: 1.0924 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12330/2499940 | global iter:   6166/1249970 | loss: 1.2377 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12332/2499940 | global iter:   6167/1249970 | loss: 0.8952 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12334/2499940 | global iter:   6168/1249970 | loss: 1.0223 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12334/2499940 | global iter:   6168/1249970 | loss: 1.3035 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12336/2499940 | global iter:   6169/1249970 | loss: 2.4061 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12338/2499940 | global iter:   6170/1249970 | loss: 0.9358 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  12340/2499940 | global iter:   6171/1249970 | loss: 1.8435 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12342/2499940 | global iter:   6172/1249970 | loss: 0.5315 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12342/2499940 | global iter:   6172/1249970 | loss: 1.2135 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12344/2499940 | global iter:   6173/1249970 | loss: 1.1776 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12346/2499940 | global iter:   6174/1249970 | loss: 0.8614 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  12348/2499940 | global iter:   6175/1249970 | loss: 0.0099 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12350/2499940 | global iter:   6176/1249970 | loss: 1.6549 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12350/2499940 | global iter:   6176/1249970 | loss: 1.1698 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12352/2499940 | global iter:   6177/1249970 | loss: 0.5971 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12354/2499940 | global iter:   6178/1249970 | loss: 1.0016 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12356/2499940 | global iter:   6179/1249970 | loss: 0.3681 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12358/2499940 | global iter:   6180/1249970 | loss: 0.7618 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12358/2499940 | global iter:   6180/1249970 | loss: 0.8252 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12360/2499940 | global iter:   6181/1249970 | loss: 1.2947 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12362/2499940 | global iter:   6182/1249970 | loss: 1.2855 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12364/2499940 | global iter:   6183/1249970 | loss: 1.4818 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12366/2499940 | global iter:   6184/1249970 | loss: 1.1973 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12366/2499940 | global iter:   6184/1249970 | loss: 1.2239 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12368/2499940 | global iter:   6185/1249970 | loss: 1.2226 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  12370/2499940 | global iter:   6186/1249970 | loss: 0.0082 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  12372/2499940 | global iter:   6187/1249970 | loss: 0.4903 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12374/2499940 | global iter:   6188/1249970 | loss: 2.0839 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12374/2499940 | global iter:   6188/1249970 | loss: 1.2153 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12376/2499940 | global iter:   6189/1249970 | loss: 0.9411 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.410 | step time: 0.000
train | epoch   0 | Iter:  12378/2499940 | global iter:   6190/1249970 | loss: 1.3638 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  12380/2499940 | global iter:   6191/1249970 | loss: 0.8889 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12382/2499940 | global iter:   6192/1249970 | loss: 0.5264 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12382/2499940 | global iter:   6192/1249970 | loss: 1.1137 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12384/2499940 | global iter:   6193/1249970 | loss: 1.2891 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12386/2499940 | global iter:   6194/1249970 | loss: 1.5620 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12388/2499940 | global iter:   6195/1249970 | loss: 0.3746 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  12390/2499940 | global iter:   6196/1249970 | loss: 0.3617 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12390/2499940 | global iter:   6196/1249970 | loss: 0.8907 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12392/2499940 | global iter:   6197/1249970 | loss: 0.7565 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12394/2499940 | global iter:   6198/1249970 | loss: 1.4048 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12396/2499940 | global iter:   6199/1249970 | loss: 1.2205 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12398/2499940 | global iter:   6200/1249970 | loss: 0.8910 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12398/2499940 | global iter:   6200/1249970 | loss: 1.1702 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12400/2499940 | global iter:   6201/1249970 | loss: 0.7824 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12402/2499940 | global iter:   6202/1249970 | loss: 1.2263 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12404/2499940 | global iter:   6203/1249970 | loss: 1.1883 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12406/2499940 | global iter:   6204/1249970 | loss: 1.4499 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12406/2499940 | global iter:   6204/1249970 | loss: 1.3040 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12408/2499940 | global iter:   6205/1249970 | loss: 0.5135 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  12410/2499940 | global iter:   6206/1249970 | loss: 1.1099 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12412/2499940 | global iter:   6207/1249970 | loss: 1.5657 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12414/2499940 | global iter:   6208/1249970 | loss: 1.3986 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12414/2499940 | global iter:   6208/1249970 | loss: 1.1002 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12416/2499940 | global iter:   6209/1249970 | loss: 1.6975 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12418/2499940 | global iter:   6210/1249970 | loss: 1.3695 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  12420/2499940 | global iter:   6211/1249970 | loss: 1.6228 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12422/2499940 | global iter:   6212/1249970 | loss: 1.2065 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12422/2499940 | global iter:   6212/1249970 | loss: 1.3834 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12424/2499940 | global iter:   6213/1249970 | loss: 1.2764 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12426/2499940 | global iter:   6214/1249970 | loss: 0.9944 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12428/2499940 | global iter:   6215/1249970 | loss: 0.9100 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12430/2499940 | global iter:   6216/1249970 | loss: 0.8493 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12430/2499940 | global iter:   6216/1249970 | loss: 0.9755 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12432/2499940 | global iter:   6217/1249970 | loss: 1.2098 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12434/2499940 | global iter:   6218/1249970 | loss: 0.3544 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12436/2499940 | global iter:   6219/1249970 | loss: 1.6693 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12438/2499940 | global iter:   6220/1249970 | loss: 1.4346 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12438/2499940 | global iter:   6220/1249970 | loss: 1.2491 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12440/2499940 | global iter:   6221/1249970 | loss: 1.6329 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12442/2499940 | global iter:   6222/1249970 | loss: 0.3930 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12444/2499940 | global iter:   6223/1249970 | loss: 0.6874 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12446/2499940 | global iter:   6224/1249970 | loss: 1.3599 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12446/2499940 | global iter:   6224/1249970 | loss: 0.9163 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12448/2499940 | global iter:   6225/1249970 | loss: 0.9743 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12450/2499940 | global iter:   6226/1249970 | loss: 0.7539 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12452/2499940 | global iter:   6227/1249970 | loss: 1.2448 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12454/2499940 | global iter:   6228/1249970 | loss: 0.0579 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12454/2499940 | global iter:   6228/1249970 | loss: 0.8056 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12456/2499940 | global iter:   6229/1249970 | loss: 1.3840 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12458/2499940 | global iter:   6230/1249970 | loss: 0.3872 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12460/2499940 | global iter:   6231/1249970 | loss: 1.3076 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12462/2499940 | global iter:   6232/1249970 | loss: 1.1499 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.406 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12462/2499940 | global iter:   6232/1249970 | loss: 1.0227 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.406 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12464/2499940 | global iter:   6233/1249970 | loss: 0.8802 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.411 | step time: 0.000
train | epoch   0 | Iter:  12466/2499940 | global iter:   6234/1249970 | loss: 1.1935 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12468/2499940 | global iter:   6235/1249970 | loss: 0.0252 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12470/2499940 | global iter:   6236/1249970 | loss: 1.0065 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12470/2499940 | global iter:   6236/1249970 | loss: 0.9254 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12472/2499940 | global iter:   6237/1249970 | loss: 0.2380 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  12474/2499940 | global iter:   6238/1249970 | loss: 1.4556 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  12476/2499940 | global iter:   6239/1249970 | loss: 1.1512 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12478/2499940 | global iter:   6240/1249970 | loss: 1.3277 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12478/2499940 | global iter:   6240/1249970 | loss: 1.1284 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12480/2499940 | global iter:   6241/1249970 | loss: 0.9636 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12482/2499940 | global iter:   6242/1249970 | loss: 2.0400 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12484/2499940 | global iter:   6243/1249970 | loss: 1.7985 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12486/2499940 | global iter:   6244/1249970 | loss: 1.3770 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12486/2499940 | global iter:   6244/1249970 | loss: 1.2874 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12488/2499940 | global iter:   6245/1249970 | loss: 1.3547 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12490/2499940 | global iter:   6246/1249970 | loss: 1.9549 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12492/2499940 | global iter:   6247/1249970 | loss: 0.4814 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12494/2499940 | global iter:   6248/1249970 | loss: 1.4879 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12494/2499940 | global iter:   6248/1249970 | loss: 1.1512 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12496/2499940 | global iter:   6249/1249970 | loss: 1.7693 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12498/2499940 | global iter:   6250/1249970 | loss: 1.2345 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  12500/2499940 | global iter:   6251/1249970 | loss: 0.9956 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12502/2499940 | global iter:   6252/1249970 | loss: 0.1379 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12502/2499940 | global iter:   6252/1249970 | loss: 1.1004 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12504/2499940 | global iter:   6253/1249970 | loss: 0.7990 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  12506/2499940 | global iter:   6254/1249970 | loss: 0.9214 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12508/2499940 | global iter:   6255/1249970 | loss: 2.1260 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12510/2499940 | global iter:   6256/1249970 | loss: 1.4181 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12510/2499940 | global iter:   6256/1249970 | loss: 1.1190 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12512/2499940 | global iter:   6257/1249970 | loss: 1.4622 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12514/2499940 | global iter:   6258/1249970 | loss: 0.7935 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  12516/2499940 | global iter:   6259/1249970 | loss: 0.9475 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12518/2499940 | global iter:   6260/1249970 | loss: 1.7873 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12518/2499940 | global iter:   6260/1249970 | loss: 1.1812 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12520/2499940 | global iter:   6261/1249970 | loss: 1.3820 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12522/2499940 | global iter:   6262/1249970 | loss: 1.2569 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  12524/2499940 | global iter:   6263/1249970 | loss: 1.4425 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12526/2499940 | global iter:   6264/1249970 | loss: 0.9353 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12526/2499940 | global iter:   6264/1249970 | loss: 1.0395 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12528/2499940 | global iter:   6265/1249970 | loss: 1.8368 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12530/2499940 | global iter:   6266/1249970 | loss: 0.5653 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  12532/2499940 | global iter:   6267/1249970 | loss: 0.8507 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12534/2499940 | global iter:   6268/1249970 | loss: 1.0849 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12534/2499940 | global iter:   6268/1249970 | loss: 1.0977 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12536/2499940 | global iter:   6269/1249970 | loss: 1.6933 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12538/2499940 | global iter:   6270/1249970 | loss: 1.5161 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12540/2499940 | global iter:   6271/1249970 | loss: 1.2020 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12542/2499940 | global iter:   6272/1249970 | loss: 1.1319 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12542/2499940 | global iter:   6272/1249970 | loss: 1.1641 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12544/2499940 | global iter:   6273/1249970 | loss: 0.7921 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12546/2499940 | global iter:   6274/1249970 | loss: 1.0819 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12548/2499940 | global iter:   6275/1249970 | loss: 1.4641 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12550/2499940 | global iter:   6276/1249970 | loss: 0.9824 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12550/2499940 | global iter:   6276/1249970 | loss: 1.1389 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12552/2499940 | global iter:   6277/1249970 | loss: 0.9274 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12554/2499940 | global iter:   6278/1249970 | loss: 1.1384 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  12556/2499940 | global iter:   6279/1249970 | loss: 1.3013 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12558/2499940 | global iter:   6280/1249970 | loss: 1.1002 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12558/2499940 | global iter:   6280/1249970 | loss: 1.2777 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12560/2499940 | global iter:   6281/1249970 | loss: 1.1741 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12562/2499940 | global iter:   6282/1249970 | loss: 0.7739 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12564/2499940 | global iter:   6283/1249970 | loss: 0.6895 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12566/2499940 | global iter:   6284/1249970 | loss: 1.3582 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12566/2499940 | global iter:   6284/1249970 | loss: 1.0019 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12568/2499940 | global iter:   6285/1249970 | loss: 1.7575 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12570/2499940 | global iter:   6286/1249970 | loss: 0.8065 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12572/2499940 | global iter:   6287/1249970 | loss: 1.2272 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12574/2499940 | global iter:   6288/1249970 | loss: 1.7453 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12574/2499940 | global iter:   6288/1249970 | loss: 1.2917 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12576/2499940 | global iter:   6289/1249970 | loss: 1.0567 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12578/2499940 | global iter:   6290/1249970 | loss: 1.5688 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  12580/2499940 | global iter:   6291/1249970 | loss: 1.5993 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12582/2499940 | global iter:   6292/1249970 | loss: 1.2931 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12582/2499940 | global iter:   6292/1249970 | loss: 1.2819 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12584/2499940 | global iter:   6293/1249970 | loss: 1.4326 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12586/2499940 | global iter:   6294/1249970 | loss: 0.8232 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12588/2499940 | global iter:   6295/1249970 | loss: 1.3959 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12590/2499940 | global iter:   6296/1249970 | loss: 1.1482 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12590/2499940 | global iter:   6296/1249970 | loss: 1.1928 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12592/2499940 | global iter:   6297/1249970 | loss: 1.0538 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12594/2499940 | global iter:   6298/1249970 | loss: 1.7680 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12596/2499940 | global iter:   6299/1249970 | loss: 0.6829 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12598/2499940 | global iter:   6300/1249970 | loss: 0.9956 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12598/2499940 | global iter:   6300/1249970 | loss: 1.1934 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12600/2499940 | global iter:   6301/1249970 | loss: 2.0443 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12602/2499940 | global iter:   6302/1249970 | loss: 1.0148 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12604/2499940 | global iter:   6303/1249970 | loss: 1.7562 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12606/2499940 | global iter:   6304/1249970 | loss: 1.6641 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12606/2499940 | global iter:   6304/1249970 | loss: 1.2109 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12608/2499940 | global iter:   6305/1249970 | loss: 1.1256 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12610/2499940 | global iter:   6306/1249970 | loss: 0.7906 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12612/2499940 | global iter:   6307/1249970 | loss: 0.6866 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  12614/2499940 | global iter:   6308/1249970 | loss: 1.5919 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12614/2499940 | global iter:   6308/1249970 | loss: 1.0504 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12616/2499940 | global iter:   6309/1249970 | loss: 1.5306 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  12618/2499940 | global iter:   6310/1249970 | loss: 1.1196 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12620/2499940 | global iter:   6311/1249970 | loss: 0.5035 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12622/2499940 | global iter:   6312/1249970 | loss: 0.4566 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12622/2499940 | global iter:   6312/1249970 | loss: 0.8858 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12624/2499940 | global iter:   6313/1249970 | loss: 1.2737 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12626/2499940 | global iter:   6314/1249970 | loss: 0.9984 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  12628/2499940 | global iter:   6315/1249970 | loss: 1.0553 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12630/2499940 | global iter:   6316/1249970 | loss: 0.8456 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12630/2499940 | global iter:   6316/1249970 | loss: 1.0006 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12632/2499940 | global iter:   6317/1249970 | loss: 1.5210 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12634/2499940 | global iter:   6318/1249970 | loss: 0.5975 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  12636/2499940 | global iter:   6319/1249970 | loss: 1.0219 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.404 | step time: 0.000
train | epoch   0 | Iter:  12638/2499940 | global iter:   6320/1249970 | loss: 1.5394 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12638/2499940 | global iter:   6320/1249970 | loss: 0.9328 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12640/2499940 | global iter:   6321/1249970 | loss: 1.0200 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12642/2499940 | global iter:   6322/1249970 | loss: 0.9000 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12644/2499940 | global iter:   6323/1249970 | loss: 1.5549 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12646/2499940 | global iter:   6324/1249970 | loss: 1.6491 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12646/2499940 | global iter:   6324/1249970 | loss: 1.1262 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12648/2499940 | global iter:   6325/1249970 | loss: 0.8798 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  12650/2499940 | global iter:   6326/1249970 | loss: 2.0801 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12652/2499940 | global iter:   6327/1249970 | loss: 1.1192 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12654/2499940 | global iter:   6328/1249970 | loss: 1.9549 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12654/2499940 | global iter:   6328/1249970 | loss: 1.2645 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12656/2499940 | global iter:   6329/1249970 | loss: 0.1948 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12658/2499940 | global iter:   6330/1249970 | loss: 0.7491 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12660/2499940 | global iter:   6331/1249970 | loss: 1.7816 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12662/2499940 | global iter:   6332/1249970 | loss: 1.0192 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12662/2499940 | global iter:   6332/1249970 | loss: 1.0242 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12664/2499940 | global iter:   6333/1249970 | loss: 0.7462 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12666/2499940 | global iter:   6334/1249970 | loss: 1.1738 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12668/2499940 | global iter:   6335/1249970 | loss: 0.9723 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12670/2499940 | global iter:   6336/1249970 | loss: 1.3536 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12670/2499940 | global iter:   6336/1249970 | loss: 1.1134 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12672/2499940 | global iter:   6337/1249970 | loss: 0.8738 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12674/2499940 | global iter:   6338/1249970 | loss: 0.9652 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12676/2499940 | global iter:   6339/1249970 | loss: 1.7587 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  12678/2499940 | global iter:   6340/1249970 | loss: 1.4333 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12678/2499940 | global iter:   6340/1249970 | loss: 1.2161 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12680/2499940 | global iter:   6341/1249970 | loss: 1.0304 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12682/2499940 | global iter:   6342/1249970 | loss: 1.0602 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12684/2499940 | global iter:   6343/1249970 | loss: 0.0538 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12686/2499940 | global iter:   6344/1249970 | loss: 1.2544 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12686/2499940 | global iter:   6344/1249970 | loss: 0.9719 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12688/2499940 | global iter:   6345/1249970 | loss: 1.2142 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12690/2499940 | global iter:   6346/1249970 | loss: 0.8196 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12692/2499940 | global iter:   6347/1249970 | loss: 1.8751 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12694/2499940 | global iter:   6348/1249970 | loss: 1.6540 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12694/2499940 | global iter:   6348/1249970 | loss: 1.3645 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12696/2499940 | global iter:   6349/1249970 | loss: 1.2334 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12698/2499940 | global iter:   6350/1249970 | loss: 1.2471 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12700/2499940 | global iter:   6351/1249970 | loss: 0.3164 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12702/2499940 | global iter:   6352/1249970 | loss: 0.8374 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12702/2499940 | global iter:   6352/1249970 | loss: 1.0659 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12704/2499940 | global iter:   6353/1249970 | loss: 1.4783 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12706/2499940 | global iter:   6354/1249970 | loss: 1.2962 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12708/2499940 | global iter:   6355/1249970 | loss: 0.4957 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  12710/2499940 | global iter:   6356/1249970 | loss: 1.3262 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12710/2499940 | global iter:   6356/1249970 | loss: 1.1855 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12712/2499940 | global iter:   6357/1249970 | loss: 0.4467 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12714/2499940 | global iter:   6358/1249970 | loss: 1.0412 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12716/2499940 | global iter:   6359/1249970 | loss: 1.2146 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12718/2499940 | global iter:   6360/1249970 | loss: 0.6435 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12718/2499940 | global iter:   6360/1249970 | loss: 0.9884 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12720/2499940 | global iter:   6361/1249970 | loss: 1.4803 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12722/2499940 | global iter:   6362/1249970 | loss: 1.1148 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12724/2499940 | global iter:   6363/1249970 | loss: 1.5602 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  12726/2499940 | global iter:   6364/1249970 | loss: 1.0809 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12726/2499940 | global iter:   6364/1249970 | loss: 1.4312 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12728/2499940 | global iter:   6365/1249970 | loss: 0.3584 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  12730/2499940 | global iter:   6366/1249970 | loss: 0.8448 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  12732/2499940 | global iter:   6367/1249970 | loss: 1.5029 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12734/2499940 | global iter:   6368/1249970 | loss: 0.9202 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12734/2499940 | global iter:   6368/1249970 | loss: 1.0586 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12736/2499940 | global iter:   6369/1249970 | loss: 0.5453 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12738/2499940 | global iter:   6370/1249970 | loss: 0.8644 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12740/2499940 | global iter:   6371/1249970 | loss: 0.9541 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12742/2499940 | global iter:   6372/1249970 | loss: 0.8751 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12742/2499940 | global iter:   6372/1249970 | loss: 1.1578 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12744/2499940 | global iter:   6373/1249970 | loss: 0.2734 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12746/2499940 | global iter:   6374/1249970 | loss: 1.1324 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12748/2499940 | global iter:   6375/1249970 | loss: 1.2710 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12750/2499940 | global iter:   6376/1249970 | loss: 1.1493 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12750/2499940 | global iter:   6376/1249970 | loss: 1.0626 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12752/2499940 | global iter:   6377/1249970 | loss: 1.7206 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12754/2499940 | global iter:   6378/1249970 | loss: 0.8727 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  12756/2499940 | global iter:   6379/1249970 | loss: 0.7796 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12758/2499940 | global iter:   6380/1249970 | loss: 1.2647 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12758/2499940 | global iter:   6380/1249970 | loss: 0.9953 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12760/2499940 | global iter:   6381/1249970 | loss: 1.4813 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12762/2499940 | global iter:   6382/1249970 | loss: 0.5754 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  12764/2499940 | global iter:   6383/1249970 | loss: 1.4776 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12766/2499940 | global iter:   6384/1249970 | loss: 1.1519 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12766/2499940 | global iter:   6384/1249970 | loss: 1.1584 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12768/2499940 | global iter:   6385/1249970 | loss: 1.4424 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12770/2499940 | global iter:   6386/1249970 | loss: 0.4764 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12772/2499940 | global iter:   6387/1249970 | loss: 1.2167 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12774/2499940 | global iter:   6388/1249970 | loss: 1.1934 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12774/2499940 | global iter:   6388/1249970 | loss: 1.3243 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12776/2499940 | global iter:   6389/1249970 | loss: 0.4454 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12778/2499940 | global iter:   6390/1249970 | loss: 0.7884 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12780/2499940 | global iter:   6391/1249970 | loss: 1.8654 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12782/2499940 | global iter:   6392/1249970 | loss: 1.8918 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12782/2499940 | global iter:   6392/1249970 | loss: 1.2363 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12784/2499940 | global iter:   6393/1249970 | loss: 0.4473 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12786/2499940 | global iter:   6394/1249970 | loss: 1.1297 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12788/2499940 | global iter:   6395/1249970 | loss: 1.3433 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12790/2499940 | global iter:   6396/1249970 | loss: 0.7414 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12790/2499940 | global iter:   6396/1249970 | loss: 1.2750 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12792/2499940 | global iter:   6397/1249970 | loss: 1.1923 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12794/2499940 | global iter:   6398/1249970 | loss: 1.0951 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12796/2499940 | global iter:   6399/1249970 | loss: 1.2428 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12798/2499940 | global iter:   6400/1249970 | loss: 0.4356 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12798/2499940 | global iter:   6400/1249970 | loss: 1.1596 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12800/2499940 | global iter:   6401/1249970 | loss: 1.9743 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12802/2499940 | global iter:   6402/1249970 | loss: 1.1444 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  12804/2499940 | global iter:   6403/1249970 | loss: 1.7895 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12806/2499940 | global iter:   6404/1249970 | loss: 1.6816 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12806/2499940 | global iter:   6404/1249970 | loss: 1.1771 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12808/2499940 | global iter:   6405/1249970 | loss: 1.1564 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12810/2499940 | global iter:   6406/1249970 | loss: 1.0495 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12812/2499940 | global iter:   6407/1249970 | loss: 0.4869 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12814/2499940 | global iter:   6408/1249970 | loss: 1.1158 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12814/2499940 | global iter:   6408/1249970 | loss: 0.9112 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12816/2499940 | global iter:   6409/1249970 | loss: 0.6857 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12818/2499940 | global iter:   6410/1249970 | loss: 1.0594 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12820/2499940 | global iter:   6411/1249970 | loss: 0.8125 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12822/2499940 | global iter:   6412/1249970 | loss: 1.1535 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12822/2499940 | global iter:   6412/1249970 | loss: 0.9512 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12824/2499940 | global iter:   6413/1249970 | loss: 1.6347 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12826/2499940 | global iter:   6414/1249970 | loss: 1.7572 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  12828/2499940 | global iter:   6415/1249970 | loss: 1.2308 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12830/2499940 | global iter:   6416/1249970 | loss: 0.9482 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12830/2499940 | global iter:   6416/1249970 | loss: 1.1449 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12832/2499940 | global iter:   6417/1249970 | loss: 0.6788 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12834/2499940 | global iter:   6418/1249970 | loss: 0.8232 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12836/2499940 | global iter:   6419/1249970 | loss: 1.0189 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12838/2499940 | global iter:   6420/1249970 | loss: 0.5162 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12838/2499940 | global iter:   6420/1249970 | loss: 1.0981 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12840/2499940 | global iter:   6421/1249970 | loss: 0.9569 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12842/2499940 | global iter:   6422/1249970 | loss: 0.3841 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  12844/2499940 | global iter:   6423/1249970 | loss: 1.3059 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12846/2499940 | global iter:   6424/1249970 | loss: 0.7717 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12846/2499940 | global iter:   6424/1249970 | loss: 0.9468 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12848/2499940 | global iter:   6425/1249970 | loss: 1.0875 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12850/2499940 | global iter:   6426/1249970 | loss: 1.7435 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12852/2499940 | global iter:   6427/1249970 | loss: 1.0571 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  12854/2499940 | global iter:   6428/1249970 | loss: 1.5400 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12854/2499940 | global iter:   6428/1249970 | loss: 1.3138 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12856/2499940 | global iter:   6429/1249970 | loss: 1.3606 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  12858/2499940 | global iter:   6430/1249970 | loss: 1.0484 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12860/2499940 | global iter:   6431/1249970 | loss: 1.0705 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12862/2499940 | global iter:   6432/1249970 | loss: 0.1698 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12862/2499940 | global iter:   6432/1249970 | loss: 0.9768 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12864/2499940 | global iter:   6433/1249970 | loss: 1.3011 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12866/2499940 | global iter:   6434/1249970 | loss: 1.3589 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12868/2499940 | global iter:   6435/1249970 | loss: 1.0689 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12870/2499940 | global iter:   6436/1249970 | loss: 1.4676 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12870/2499940 | global iter:   6436/1249970 | loss: 1.1549 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12872/2499940 | global iter:   6437/1249970 | loss: 1.6529 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  12874/2499940 | global iter:   6438/1249970 | loss: 0.7440 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12876/2499940 | global iter:   6439/1249970 | loss: 1.1476 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  12878/2499940 | global iter:   6440/1249970 | loss: 0.9628 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12878/2499940 | global iter:   6440/1249970 | loss: 1.0589 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12880/2499940 | global iter:   6441/1249970 | loss: 1.0085 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  12882/2499940 | global iter:   6442/1249970 | loss: 0.7127 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12884/2499940 | global iter:   6443/1249970 | loss: 1.1092 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12886/2499940 | global iter:   6444/1249970 | loss: 0.4230 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12886/2499940 | global iter:   6444/1249970 | loss: 0.9142 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12888/2499940 | global iter:   6445/1249970 | loss: 1.6234 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12890/2499940 | global iter:   6446/1249970 | loss: 0.6900 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12892/2499940 | global iter:   6447/1249970 | loss: 1.6822 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12894/2499940 | global iter:   6448/1249970 | loss: 1.4091 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12894/2499940 | global iter:   6448/1249970 | loss: 1.2801 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12896/2499940 | global iter:   6449/1249970 | loss: 0.8984 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.406 | step time: 0.000
train | epoch   0 | Iter:  12898/2499940 | global iter:   6450/1249970 | loss: 1.3257 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12900/2499940 | global iter:   6451/1249970 | loss: 0.4876 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12902/2499940 | global iter:   6452/1249970 | loss: 1.8047 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12902/2499940 | global iter:   6452/1249970 | loss: 1.1539 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12904/2499940 | global iter:   6453/1249970 | loss: 0.1642 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12906/2499940 | global iter:   6454/1249970 | loss: 1.3841 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  12908/2499940 | global iter:   6455/1249970 | loss: 0.5992 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12910/2499940 | global iter:   6456/1249970 | loss: 0.7043 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12910/2499940 | global iter:   6456/1249970 | loss: 0.9535 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12912/2499940 | global iter:   6457/1249970 | loss: 1.4939 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12914/2499940 | global iter:   6458/1249970 | loss: 0.8933 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  12916/2499940 | global iter:   6459/1249970 | loss: 1.2739 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  12918/2499940 | global iter:   6460/1249970 | loss: 1.0994 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12918/2499940 | global iter:   6460/1249970 | loss: 1.1833 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12920/2499940 | global iter:   6461/1249970 | loss: 0.2663 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12922/2499940 | global iter:   6462/1249970 | loss: 1.9273 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  12924/2499940 | global iter:   6463/1249970 | loss: 0.9268 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12926/2499940 | global iter:   6464/1249970 | loss: 0.8277 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12926/2499940 | global iter:   6464/1249970 | loss: 0.9623 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12928/2499940 | global iter:   6465/1249970 | loss: 0.4044 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12930/2499940 | global iter:   6466/1249970 | loss: 0.4188 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12932/2499940 | global iter:   6467/1249970 | loss: 1.1619 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12934/2499940 | global iter:   6468/1249970 | loss: 1.3110 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12934/2499940 | global iter:   6468/1249970 | loss: 0.7800 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12936/2499940 | global iter:   6469/1249970 | loss: 1.3615 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12938/2499940 | global iter:   6470/1249970 | loss: 0.9179 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  12940/2499940 | global iter:   6471/1249970 | loss: 1.7619 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  12942/2499940 | global iter:   6472/1249970 | loss: 0.8285 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12942/2499940 | global iter:   6472/1249970 | loss: 1.3202 | ds_loss: 0.0000 | lr: 9.9994e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.686
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12944/2499940 | global iter:   6473/1249970 | loss: 0.2654 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12946/2499940 | global iter:   6474/1249970 | loss: 0.8677 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12948/2499940 | global iter:   6475/1249970 | loss: 1.2967 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12950/2499940 | global iter:   6476/1249970 | loss: 1.0737 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12950/2499940 | global iter:   6476/1249970 | loss: 1.1481 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12952/2499940 | global iter:   6477/1249970 | loss: 1.5602 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  12954/2499940 | global iter:   6478/1249970 | loss: 1.4127 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12956/2499940 | global iter:   6479/1249970 | loss: 0.7136 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12958/2499940 | global iter:   6480/1249970 | loss: 1.6039 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12958/2499940 | global iter:   6480/1249970 | loss: 1.2604 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12960/2499940 | global iter:   6481/1249970 | loss: 0.7565 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  12962/2499940 | global iter:   6482/1249970 | loss: 1.5560 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12964/2499940 | global iter:   6483/1249970 | loss: 0.8629 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12966/2499940 | global iter:   6484/1249970 | loss: 0.8401 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12966/2499940 | global iter:   6484/1249970 | loss: 0.9921 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12968/2499940 | global iter:   6485/1249970 | loss: 0.5953 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12970/2499940 | global iter:   6486/1249970 | loss: 1.1505 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12972/2499940 | global iter:   6487/1249970 | loss: 1.4703 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12974/2499940 | global iter:   6488/1249970 | loss: 0.8360 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12974/2499940 | global iter:   6488/1249970 | loss: 0.9947 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12976/2499940 | global iter:   6489/1249970 | loss: 1.0286 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12978/2499940 | global iter:   6490/1249970 | loss: 1.2933 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12980/2499940 | global iter:   6491/1249970 | loss: 0.8322 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  12982/2499940 | global iter:   6492/1249970 | loss: 1.2133 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12982/2499940 | global iter:   6492/1249970 | loss: 1.0716 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12984/2499940 | global iter:   6493/1249970 | loss: 0.5608 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12986/2499940 | global iter:   6494/1249970 | loss: 1.1466 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12988/2499940 | global iter:   6495/1249970 | loss: 1.2461 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12990/2499940 | global iter:   6496/1249970 | loss: 1.5200 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12990/2499940 | global iter:   6496/1249970 | loss: 1.2303 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  12992/2499940 | global iter:   6497/1249970 | loss: 1.1947 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  12994/2499940 | global iter:   6498/1249970 | loss: 0.8491 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  12996/2499940 | global iter:   6499/1249970 | loss: 1.4894 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  12998/2499940 | global iter:   6500/1249970 | loss: 0.0662 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.392 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  12998/2499940 | global iter:   6500/1249970 | loss: 0.9495 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.392 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13000/2499940 | global iter:   6501/1249970 | loss: 1.2509 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13002/2499940 | global iter:   6502/1249970 | loss: 1.3542 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  13004/2499940 | global iter:   6503/1249970 | loss: 1.5675 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13006/2499940 | global iter:   6504/1249970 | loss: 0.1809 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13006/2499940 | global iter:   6504/1249970 | loss: 1.2438 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13008/2499940 | global iter:   6505/1249970 | loss: 0.2688 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13010/2499940 | global iter:   6506/1249970 | loss: 0.5705 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13012/2499940 | global iter:   6507/1249970 | loss: 1.7070 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13014/2499940 | global iter:   6508/1249970 | loss: 0.8342 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13014/2499940 | global iter:   6508/1249970 | loss: 1.0175 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13016/2499940 | global iter:   6509/1249970 | loss: 0.7381 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13018/2499940 | global iter:   6510/1249970 | loss: 1.1818 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13020/2499940 | global iter:   6511/1249970 | loss: 0.8454 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13022/2499940 | global iter:   6512/1249970 | loss: 1.7138 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13022/2499940 | global iter:   6512/1249970 | loss: 1.1993 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13024/2499940 | global iter:   6513/1249970 | loss: 0.4988 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13026/2499940 | global iter:   6514/1249970 | loss: 0.7097 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13028/2499940 | global iter:   6515/1249970 | loss: 1.0690 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13030/2499940 | global iter:   6516/1249970 | loss: 1.5362 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13030/2499940 | global iter:   6516/1249970 | loss: 1.1060 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13032/2499940 | global iter:   6517/1249970 | loss: 0.6513 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13034/2499940 | global iter:   6518/1249970 | loss: 0.2768 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13036/2499940 | global iter:   6519/1249970 | loss: 1.7318 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13038/2499940 | global iter:   6520/1249970 | loss: 1.2183 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13038/2499940 | global iter:   6520/1249970 | loss: 1.0371 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13040/2499940 | global iter:   6521/1249970 | loss: 0.0229 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13042/2499940 | global iter:   6522/1249970 | loss: 0.3679 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  13044/2499940 | global iter:   6523/1249970 | loss: 0.1364 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13046/2499940 | global iter:   6524/1249970 | loss: 1.4357 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13046/2499940 | global iter:   6524/1249970 | loss: 0.6832 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13048/2499940 | global iter:   6525/1249970 | loss: 0.7041 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13050/2499940 | global iter:   6526/1249970 | loss: 0.9958 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  13052/2499940 | global iter:   6527/1249970 | loss: 1.6577 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:  13054/2499940 | global iter:   6528/1249970 | loss: 2.0119 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13054/2499940 | global iter:   6528/1249970 | loss: 1.1797 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13056/2499940 | global iter:   6529/1249970 | loss: 1.3154 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13058/2499940 | global iter:   6530/1249970 | loss: 0.7897 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  13060/2499940 | global iter:   6531/1249970 | loss: 1.4104 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13062/2499940 | global iter:   6532/1249970 | loss: 1.1241 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13062/2499940 | global iter:   6532/1249970 | loss: 0.9140 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13064/2499940 | global iter:   6533/1249970 | loss: 0.7864 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13066/2499940 | global iter:   6534/1249970 | loss: 0.6409 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  13068/2499940 | global iter:   6535/1249970 | loss: 1.0210 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13070/2499940 | global iter:   6536/1249970 | loss: 0.7662 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13070/2499940 | global iter:   6536/1249970 | loss: 1.0116 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13072/2499940 | global iter:   6537/1249970 | loss: 1.0342 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13074/2499940 | global iter:   6538/1249970 | loss: 0.8787 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  13076/2499940 | global iter:   6539/1249970 | loss: 0.7533 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13078/2499940 | global iter:   6540/1249970 | loss: 1.2805 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13078/2499940 | global iter:   6540/1249970 | loss: 0.9875 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13080/2499940 | global iter:   6541/1249970 | loss: 0.8302 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13082/2499940 | global iter:   6542/1249970 | loss: 0.8987 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13084/2499940 | global iter:   6543/1249970 | loss: 0.6586 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13086/2499940 | global iter:   6544/1249970 | loss: 0.6887 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13086/2499940 | global iter:   6544/1249970 | loss: 0.8827 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13088/2499940 | global iter:   6545/1249970 | loss: 0.8499 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13090/2499940 | global iter:   6546/1249970 | loss: 0.9600 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13092/2499940 | global iter:   6547/1249970 | loss: 0.3585 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  13094/2499940 | global iter:   6548/1249970 | loss: 0.7481 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13094/2499940 | global iter:   6548/1249970 | loss: 1.1248 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13096/2499940 | global iter:   6549/1249970 | loss: 0.6576 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13098/2499940 | global iter:   6550/1249970 | loss: 1.7206 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13100/2499940 | global iter:   6551/1249970 | loss: 0.4172 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13102/2499940 | global iter:   6552/1249970 | loss: 1.3532 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13102/2499940 | global iter:   6552/1249970 | loss: 1.0747 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13104/2499940 | global iter:   6553/1249970 | loss: 1.2188 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13106/2499940 | global iter:   6554/1249970 | loss: 2.0458 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13108/2499940 | global iter:   6555/1249970 | loss: 1.1393 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13110/2499940 | global iter:   6556/1249970 | loss: 1.8679 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13110/2499940 | global iter:   6556/1249970 | loss: 1.4640 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13112/2499940 | global iter:   6557/1249970 | loss: 0.4912 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13114/2499940 | global iter:   6558/1249970 | loss: 1.4086 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  13116/2499940 | global iter:   6559/1249970 | loss: 1.7088 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13118/2499940 | global iter:   6560/1249970 | loss: 0.3315 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13118/2499940 | global iter:   6560/1249970 | loss: 1.2439 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13120/2499940 | global iter:   6561/1249970 | loss: 1.1651 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13122/2499940 | global iter:   6562/1249970 | loss: 1.4555 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  13124/2499940 | global iter:   6563/1249970 | loss: 1.2902 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13126/2499940 | global iter:   6564/1249970 | loss: 1.4367 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13126/2499940 | global iter:   6564/1249970 | loss: 0.9169 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13128/2499940 | global iter:   6565/1249970 | loss: 1.0943 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13130/2499940 | global iter:   6566/1249970 | loss: 0.7405 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13132/2499940 | global iter:   6567/1249970 | loss: 0.9709 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13134/2499940 | global iter:   6568/1249970 | loss: 1.0792 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13134/2499940 | global iter:   6568/1249970 | loss: 0.9556 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13136/2499940 | global iter:   6569/1249970 | loss: 1.7190 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13138/2499940 | global iter:   6570/1249970 | loss: 0.8779 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13140/2499940 | global iter:   6571/1249970 | loss: 1.2140 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13142/2499940 | global iter:   6572/1249970 | loss: 1.1498 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13142/2499940 | global iter:   6572/1249970 | loss: 0.9977 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13144/2499940 | global iter:   6573/1249970 | loss: 0.1928 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13146/2499940 | global iter:   6574/1249970 | loss: 0.7327 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13148/2499940 | global iter:   6575/1249970 | loss: 1.2320 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13150/2499940 | global iter:   6576/1249970 | loss: 1.8664 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13150/2499940 | global iter:   6576/1249970 | loss: 1.1789 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13152/2499940 | global iter:   6577/1249970 | loss: 1.6072 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13154/2499940 | global iter:   6578/1249970 | loss: 1.4735 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13156/2499940 | global iter:   6579/1249970 | loss: 0.3196 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13158/2499940 | global iter:   6580/1249970 | loss: 0.9115 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.410 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13158/2499940 | global iter:   6580/1249970 | loss: 1.2931 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.410 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13160/2499940 | global iter:   6581/1249970 | loss: 0.7438 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13162/2499940 | global iter:   6582/1249970 | loss: 1.0795 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  13164/2499940 | global iter:   6583/1249970 | loss: 0.8118 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  13166/2499940 | global iter:   6584/1249970 | loss: 1.8191 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13166/2499940 | global iter:   6584/1249970 | loss: 1.1676 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13168/2499940 | global iter:   6585/1249970 | loss: 1.4407 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13170/2499940 | global iter:   6586/1249970 | loss: 1.3616 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13172/2499940 | global iter:   6587/1249970 | loss: 0.9231 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13174/2499940 | global iter:   6588/1249970 | loss: 1.6643 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13174/2499940 | global iter:   6588/1249970 | loss: 1.0951 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13176/2499940 | global iter:   6589/1249970 | loss: 0.7996 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13178/2499940 | global iter:   6590/1249970 | loss: 0.6235 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13180/2499940 | global iter:   6591/1249970 | loss: 1.2043 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13182/2499940 | global iter:   6592/1249970 | loss: 0.8189 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13182/2499940 | global iter:   6592/1249970 | loss: 0.9145 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13184/2499940 | global iter:   6593/1249970 | loss: 0.8819 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13186/2499940 | global iter:   6594/1249970 | loss: 0.6517 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13188/2499940 | global iter:   6595/1249970 | loss: 0.9567 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  13190/2499940 | global iter:   6596/1249970 | loss: 1.7755 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13190/2499940 | global iter:   6596/1249970 | loss: 1.1309 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13192/2499940 | global iter:   6597/1249970 | loss: 0.7777 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13194/2499940 | global iter:   6598/1249970 | loss: 1.3788 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  13196/2499940 | global iter:   6599/1249970 | loss: 0.8216 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13198/2499940 | global iter:   6600/1249970 | loss: 0.6454 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13198/2499940 | global iter:   6600/1249970 | loss: 1.0578 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13200/2499940 | global iter:   6601/1249970 | loss: 1.6621 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13202/2499940 | global iter:   6602/1249970 | loss: 1.1975 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13204/2499940 | global iter:   6603/1249970 | loss: 1.6633 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13206/2499940 | global iter:   6604/1249970 | loss: 1.2150 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13206/2499940 | global iter:   6604/1249970 | loss: 1.4553 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13208/2499940 | global iter:   6605/1249970 | loss: 0.6123 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13210/2499940 | global iter:   6606/1249970 | loss: 1.0342 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13212/2499940 | global iter:   6607/1249970 | loss: 1.2719 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13214/2499940 | global iter:   6608/1249970 | loss: 1.1439 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13214/2499940 | global iter:   6608/1249970 | loss: 0.9620 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13216/2499940 | global iter:   6609/1249970 | loss: 0.5780 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13218/2499940 | global iter:   6610/1249970 | loss: 1.5623 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  13220/2499940 | global iter:   6611/1249970 | loss: 0.3228 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13222/2499940 | global iter:   6612/1249970 | loss: 0.7896 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13222/2499940 | global iter:   6612/1249970 | loss: 0.9217 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13224/2499940 | global iter:   6613/1249970 | loss: 1.0959 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13226/2499940 | global iter:   6614/1249970 | loss: 1.9729 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13228/2499940 | global iter:   6615/1249970 | loss: 1.4121 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13230/2499940 | global iter:   6616/1249970 | loss: 0.7007 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13230/2499940 | global iter:   6616/1249970 | loss: 1.3062 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13232/2499940 | global iter:   6617/1249970 | loss: 0.4444 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13234/2499940 | global iter:   6618/1249970 | loss: 0.7746 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  13236/2499940 | global iter:   6619/1249970 | loss: 0.4841 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13238/2499940 | global iter:   6620/1249970 | loss: 1.5447 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13238/2499940 | global iter:   6620/1249970 | loss: 0.8214 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13240/2499940 | global iter:   6621/1249970 | loss: 0.5202 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13242/2499940 | global iter:   6622/1249970 | loss: 0.9455 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  13244/2499940 | global iter:   6623/1249970 | loss: 0.6121 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13246/2499940 | global iter:   6624/1249970 | loss: 1.4598 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13246/2499940 | global iter:   6624/1249970 | loss: 1.3059 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13248/2499940 | global iter:   6625/1249970 | loss: 1.4303 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13250/2499940 | global iter:   6626/1249970 | loss: 0.7862 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  13252/2499940 | global iter:   6627/1249970 | loss: 1.3348 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13254/2499940 | global iter:   6628/1249970 | loss: 1.9568 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13254/2499940 | global iter:   6628/1249970 | loss: 1.1719 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13256/2499940 | global iter:   6629/1249970 | loss: 0.8941 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  13258/2499940 | global iter:   6630/1249970 | loss: 1.4621 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13260/2499940 | global iter:   6631/1249970 | loss: 1.2512 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13262/2499940 | global iter:   6632/1249970 | loss: 1.3542 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13262/2499940 | global iter:   6632/1249970 | loss: 1.2154 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13264/2499940 | global iter:   6633/1249970 | loss: 1.1066 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13266/2499940 | global iter:   6634/1249970 | loss: 0.7214 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13268/2499940 | global iter:   6635/1249970 | loss: 1.8744 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13270/2499940 | global iter:   6636/1249970 | loss: 1.7907 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13270/2499940 | global iter:   6636/1249970 | loss: 1.3293 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13272/2499940 | global iter:   6637/1249970 | loss: 1.2203 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13274/2499940 | global iter:   6638/1249970 | loss: 1.0051 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13276/2499940 | global iter:   6639/1249970 | loss: 1.4547 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:  13278/2499940 | global iter:   6640/1249970 | loss: 1.1449 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13278/2499940 | global iter:   6640/1249970 | loss: 1.1832 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13280/2499940 | global iter:   6641/1249970 | loss: 1.4870 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13282/2499940 | global iter:   6642/1249970 | loss: 1.0995 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  13284/2499940 | global iter:   6643/1249970 | loss: 1.4460 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13286/2499940 | global iter:   6644/1249970 | loss: 0.7217 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13286/2499940 | global iter:   6644/1249970 | loss: 1.1744 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13288/2499940 | global iter:   6645/1249970 | loss: 1.0856 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13290/2499940 | global iter:   6646/1249970 | loss: 0.6095 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13292/2499940 | global iter:   6647/1249970 | loss: 1.1819 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13294/2499940 | global iter:   6648/1249970 | loss: 1.3770 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13294/2499940 | global iter:   6648/1249970 | loss: 1.2103 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13296/2499940 | global iter:   6649/1249970 | loss: 2.2481 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13298/2499940 | global iter:   6650/1249970 | loss: 0.6957 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13300/2499940 | global iter:   6651/1249970 | loss: 1.5707 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13302/2499940 | global iter:   6652/1249970 | loss: 1.4648 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13302/2499940 | global iter:   6652/1249970 | loss: 1.2267 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13304/2499940 | global iter:   6653/1249970 | loss: 0.5248 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13306/2499940 | global iter:   6654/1249970 | loss: 1.2799 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  13308/2499940 | global iter:   6655/1249970 | loss: 1.3556 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13310/2499940 | global iter:   6656/1249970 | loss: 1.7356 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13310/2499940 | global iter:   6656/1249970 | loss: 1.1391 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13312/2499940 | global iter:   6657/1249970 | loss: 1.8221 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13314/2499940 | global iter:   6658/1249970 | loss: 1.1903 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13316/2499940 | global iter:   6659/1249970 | loss: 0.8223 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  13318/2499940 | global iter:   6660/1249970 | loss: 1.5367 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13318/2499940 | global iter:   6660/1249970 | loss: 1.2682 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13320/2499940 | global iter:   6661/1249970 | loss: 1.2324 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13322/2499940 | global iter:   6662/1249970 | loss: 1.4139 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13324/2499940 | global iter:   6663/1249970 | loss: 1.0779 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13326/2499940 | global iter:   6664/1249970 | loss: 0.9739 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13326/2499940 | global iter:   6664/1249970 | loss: 1.1705 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13328/2499940 | global iter:   6665/1249970 | loss: 0.8257 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13330/2499940 | global iter:   6666/1249970 | loss: 1.2937 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.407 | step time: 0.000
train | epoch   0 | Iter:  13332/2499940 | global iter:   6667/1249970 | loss: 1.4341 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13334/2499940 | global iter:   6668/1249970 | loss: 1.0284 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13334/2499940 | global iter:   6668/1249970 | loss: 1.1786 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.695
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13336/2499940 | global iter:   6669/1249970 | loss: 1.9145 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  13338/2499940 | global iter:   6670/1249970 | loss: 1.0436 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13340/2499940 | global iter:   6671/1249970 | loss: 0.9576 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13342/2499940 | global iter:   6672/1249970 | loss: 1.6616 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13342/2499940 | global iter:   6672/1249970 | loss: 1.3046 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13344/2499940 | global iter:   6673/1249970 | loss: 0.7351 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13346/2499940 | global iter:   6674/1249970 | loss: 0.7066 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13348/2499940 | global iter:   6675/1249970 | loss: 0.6488 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  13350/2499940 | global iter:   6676/1249970 | loss: 0.9406 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13350/2499940 | global iter:   6676/1249970 | loss: 0.8547 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13352/2499940 | global iter:   6677/1249970 | loss: 1.3492 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13354/2499940 | global iter:   6678/1249970 | loss: 1.4979 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13356/2499940 | global iter:   6679/1249970 | loss: 0.2496 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13358/2499940 | global iter:   6680/1249970 | loss: 2.2082 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13358/2499940 | global iter:   6680/1249970 | loss: 1.2724 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13360/2499940 | global iter:   6681/1249970 | loss: 1.5920 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  13362/2499940 | global iter:   6682/1249970 | loss: 1.4650 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13364/2499940 | global iter:   6683/1249970 | loss: 0.8384 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  13366/2499940 | global iter:   6684/1249970 | loss: 1.0328 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13366/2499940 | global iter:   6684/1249970 | loss: 1.3299 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13368/2499940 | global iter:   6685/1249970 | loss: 0.6220 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13370/2499940 | global iter:   6686/1249970 | loss: 1.2915 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13372/2499940 | global iter:   6687/1249970 | loss: 1.3317 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13374/2499940 | global iter:   6688/1249970 | loss: 0.9206 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13374/2499940 | global iter:   6688/1249970 | loss: 0.8878 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13376/2499940 | global iter:   6689/1249970 | loss: 1.1123 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13378/2499940 | global iter:   6690/1249970 | loss: 1.1015 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  13380/2499940 | global iter:   6691/1249970 | loss: 1.1895 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13382/2499940 | global iter:   6692/1249970 | loss: 0.8235 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13382/2499940 | global iter:   6692/1249970 | loss: 0.9751 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13384/2499940 | global iter:   6693/1249970 | loss: 1.8171 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13386/2499940 | global iter:   6694/1249970 | loss: 1.2955 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.391 | step time: 0.000
train | epoch   0 | Iter:  13388/2499940 | global iter:   6695/1249970 | loss: 1.2786 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13390/2499940 | global iter:   6696/1249970 | loss: 1.1780 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13390/2499940 | global iter:   6696/1249970 | loss: 1.2314 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13392/2499940 | global iter:   6697/1249970 | loss: 1.7023 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  13394/2499940 | global iter:   6698/1249970 | loss: 0.8067 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13396/2499940 | global iter:   6699/1249970 | loss: 1.5289 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:  13398/2499940 | global iter:   6700/1249970 | loss: 0.8621 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13398/2499940 | global iter:   6700/1249970 | loss: 1.1009 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13400/2499940 | global iter:   6701/1249970 | loss: 0.9145 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13402/2499940 | global iter:   6702/1249970 | loss: 1.2421 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13404/2499940 | global iter:   6703/1249970 | loss: 1.2992 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13406/2499940 | global iter:   6704/1249970 | loss: 1.1589 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13406/2499940 | global iter:   6704/1249970 | loss: 1.3381 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13408/2499940 | global iter:   6705/1249970 | loss: 1.6806 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13410/2499940 | global iter:   6706/1249970 | loss: 0.7868 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  13412/2499940 | global iter:   6707/1249970 | loss: 1.0086 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13414/2499940 | global iter:   6708/1249970 | loss: 1.1241 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13414/2499940 | global iter:   6708/1249970 | loss: 1.1832 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13416/2499940 | global iter:   6709/1249970 | loss: 1.5864 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13418/2499940 | global iter:   6710/1249970 | loss: 1.3489 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.409 | step time: 0.000
train | epoch   0 | Iter:  13420/2499940 | global iter:   6711/1249970 | loss: 1.7768 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13422/2499940 | global iter:   6712/1249970 | loss: 1.0061 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13422/2499940 | global iter:   6712/1249970 | loss: 1.0409 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.395 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13424/2499940 | global iter:   6713/1249970 | loss: 0.6509 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13426/2499940 | global iter:   6714/1249970 | loss: 0.8010 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13428/2499940 | global iter:   6715/1249970 | loss: 1.7167 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13430/2499940 | global iter:   6716/1249970 | loss: 0.5397 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13430/2499940 | global iter:   6716/1249970 | loss: 1.0638 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13432/2499940 | global iter:   6717/1249970 | loss: 2.0198 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13434/2499940 | global iter:   6718/1249970 | loss: 0.6061 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13436/2499940 | global iter:   6719/1249970 | loss: 0.2962 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13438/2499940 | global iter:   6720/1249970 | loss: 1.4323 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13438/2499940 | global iter:   6720/1249970 | loss: 0.9678 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13440/2499940 | global iter:   6721/1249970 | loss: 1.7034 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13442/2499940 | global iter:   6722/1249970 | loss: 1.0561 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13444/2499940 | global iter:   6723/1249970 | loss: 0.8428 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13446/2499940 | global iter:   6724/1249970 | loss: 1.4544 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13446/2499940 | global iter:   6724/1249970 | loss: 1.3046 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13448/2499940 | global iter:   6725/1249970 | loss: 0.9427 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13450/2499940 | global iter:   6726/1249970 | loss: 1.0615 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13452/2499940 | global iter:   6727/1249970 | loss: 1.1772 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13454/2499940 | global iter:   6728/1249970 | loss: 0.6160 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13454/2499940 | global iter:   6728/1249970 | loss: 1.0140 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13456/2499940 | global iter:   6729/1249970 | loss: 0.8959 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13458/2499940 | global iter:   6730/1249970 | loss: 1.4574 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.392 | step time: 0.000
train | epoch   0 | Iter:  13460/2499940 | global iter:   6731/1249970 | loss: 1.6835 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13462/2499940 | global iter:   6732/1249970 | loss: 0.9627 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13462/2499940 | global iter:   6732/1249970 | loss: 1.1517 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13464/2499940 | global iter:   6733/1249970 | loss: 1.1563 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13466/2499940 | global iter:   6734/1249970 | loss: 0.8042 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13468/2499940 | global iter:   6735/1249970 | loss: 0.8729 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13470/2499940 | global iter:   6736/1249970 | loss: 1.5073 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13470/2499940 | global iter:   6736/1249970 | loss: 1.0133 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13472/2499940 | global iter:   6737/1249970 | loss: 1.8241 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13474/2499940 | global iter:   6738/1249970 | loss: 0.7593 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13476/2499940 | global iter:   6739/1249970 | loss: 1.4680 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13478/2499940 | global iter:   6740/1249970 | loss: 0.6109 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13478/2499940 | global iter:   6740/1249970 | loss: 1.1164 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13480/2499940 | global iter:   6741/1249970 | loss: 0.7130 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  13482/2499940 | global iter:   6742/1249970 | loss: 1.6072 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  13484/2499940 | global iter:   6743/1249970 | loss: 1.1713 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13486/2499940 | global iter:   6744/1249970 | loss: 0.6281 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13486/2499940 | global iter:   6744/1249970 | loss: 1.0778 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  4096.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13488/2499940 | global iter:   6745/1249970 | loss: 1.0701 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13490/2499940 | global iter:   6746/1249970 | loss: 1.5923 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13492/2499940 | global iter:   6747/1249970 | loss: 1.5039 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13494/2499940 | global iter:   6748/1249970 | loss: 1.4704 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13494/2499940 | global iter:   6748/1249970 | loss: 1.4976 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13496/2499940 | global iter:   6749/1249970 | loss: 0.9633 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13498/2499940 | global iter:   6750/1249970 | loss: 1.4619 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13500/2499940 | global iter:   6751/1249970 | loss: 0.9000 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  13502/2499940 | global iter:   6752/1249970 | loss: 1.6629 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13502/2499940 | global iter:   6752/1249970 | loss: 1.2750 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13504/2499940 | global iter:   6753/1249970 | loss: 1.3827 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13506/2499940 | global iter:   6754/1249970 | loss: 0.8532 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13508/2499940 | global iter:   6755/1249970 | loss: 0.7346 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13510/2499940 | global iter:   6756/1249970 | loss: 1.1229 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13510/2499940 | global iter:   6756/1249970 | loss: 1.1143 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13512/2499940 | global iter:   6757/1249970 | loss: 1.2263 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13514/2499940 | global iter:   6758/1249970 | loss: 1.4631 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  13516/2499940 | global iter:   6759/1249970 | loss: 0.6973 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13518/2499940 | global iter:   6760/1249970 | loss: 1.0220 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13518/2499940 | global iter:   6760/1249970 | loss: 1.0797 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13520/2499940 | global iter:   6761/1249970 | loss: 1.2090 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13522/2499940 | global iter:   6762/1249970 | loss: 1.0782 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13524/2499940 | global iter:   6763/1249970 | loss: 1.6775 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13526/2499940 | global iter:   6764/1249970 | loss: 1.5704 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13526/2499940 | global iter:   6764/1249970 | loss: 1.2663 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13528/2499940 | global iter:   6765/1249970 | loss: 1.3007 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  13530/2499940 | global iter:   6766/1249970 | loss: 1.0294 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13532/2499940 | global iter:   6767/1249970 | loss: 0.9345 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13534/2499940 | global iter:   6768/1249970 | loss: 1.0485 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13534/2499940 | global iter:   6768/1249970 | loss: 1.1432 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13536/2499940 | global iter:   6769/1249970 | loss: 0.6405 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13538/2499940 | global iter:   6770/1249970 | loss: 0.7491 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13540/2499940 | global iter:   6771/1249970 | loss: 1.3045 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13542/2499940 | global iter:   6772/1249970 | loss: 0.3838 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13542/2499940 | global iter:   6772/1249970 | loss: 1.0271 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13544/2499940 | global iter:   6773/1249970 | loss: 1.1302 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13546/2499940 | global iter:   6774/1249970 | loss: 1.7064 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13548/2499940 | global iter:   6775/1249970 | loss: 0.9808 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13550/2499940 | global iter:   6776/1249970 | loss: 0.7345 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13550/2499940 | global iter:   6776/1249970 | loss: 1.1294 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13552/2499940 | global iter:   6777/1249970 | loss: 1.0405 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13554/2499940 | global iter:   6778/1249970 | loss: 1.2404 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13556/2499940 | global iter:   6779/1249970 | loss: 1.3690 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  13558/2499940 | global iter:   6780/1249970 | loss: 1.4184 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13558/2499940 | global iter:   6780/1249970 | loss: 1.2429 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13560/2499940 | global iter:   6781/1249970 | loss: 0.7838 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13562/2499940 | global iter:   6782/1249970 | loss: 1.1694 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  13564/2499940 | global iter:   6783/1249970 | loss: 0.8470 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13566/2499940 | global iter:   6784/1249970 | loss: 1.1211 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13566/2499940 | global iter:   6784/1249970 | loss: 0.9442 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13568/2499940 | global iter:   6785/1249970 | loss: 0.2558 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13570/2499940 | global iter:   6786/1249970 | loss: 1.3691 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  13572/2499940 | global iter:   6787/1249970 | loss: 1.1061 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13574/2499940 | global iter:   6788/1249970 | loss: 0.7015 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13574/2499940 | global iter:   6788/1249970 | loss: 0.9695 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13576/2499940 | global iter:   6789/1249970 | loss: 0.7046 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13578/2499940 | global iter:   6790/1249970 | loss: 0.7057 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13580/2499940 | global iter:   6791/1249970 | loss: 1.6987 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13582/2499940 | global iter:   6792/1249970 | loss: 1.0584 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13582/2499940 | global iter:   6792/1249970 | loss: 1.2069 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13584/2499940 | global iter:   6793/1249970 | loss: 1.0001 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13586/2499940 | global iter:   6794/1249970 | loss: 0.7511 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13588/2499940 | global iter:   6795/1249970 | loss: 0.9230 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13590/2499940 | global iter:   6796/1249970 | loss: 0.9733 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.407 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13590/2499940 | global iter:   6796/1249970 | loss: 0.8974 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.407 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13592/2499940 | global iter:   6797/1249970 | loss: 1.5150 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  13594/2499940 | global iter:   6798/1249970 | loss: 0.6389 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13596/2499940 | global iter:   6799/1249970 | loss: 0.7669 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13598/2499940 | global iter:   6800/1249970 | loss: 1.7700 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13598/2499940 | global iter:   6800/1249970 | loss: 1.1309 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13600/2499940 | global iter:   6801/1249970 | loss: 0.5900 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13602/2499940 | global iter:   6802/1249970 | loss: 1.3527 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13604/2499940 | global iter:   6803/1249970 | loss: 0.7854 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13606/2499940 | global iter:   6804/1249970 | loss: 0.8208 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13606/2499940 | global iter:   6804/1249970 | loss: 1.0790 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13608/2499940 | global iter:   6805/1249970 | loss: 0.7639 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13610/2499940 | global iter:   6806/1249970 | loss: 1.3415 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13612/2499940 | global iter:   6807/1249970 | loss: 1.1746 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13614/2499940 | global iter:   6808/1249970 | loss: 1.3471 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13614/2499940 | global iter:   6808/1249970 | loss: 1.0981 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13616/2499940 | global iter:   6809/1249970 | loss: 0.9827 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13618/2499940 | global iter:   6810/1249970 | loss: 1.3949 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.392 | step time: 0.000
train | epoch   0 | Iter:  13620/2499940 | global iter:   6811/1249970 | loss: 0.4564 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13622/2499940 | global iter:   6812/1249970 | loss: 0.1977 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13622/2499940 | global iter:   6812/1249970 | loss: 0.9100 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13624/2499940 | global iter:   6813/1249970 | loss: 0.5136 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13626/2499940 | global iter:   6814/1249970 | loss: 0.8043 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13628/2499940 | global iter:   6815/1249970 | loss: 1.3543 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:  13630/2499940 | global iter:   6816/1249970 | loss: 0.9215 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13630/2499940 | global iter:   6816/1249970 | loss: 1.0807 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13632/2499940 | global iter:   6817/1249970 | loss: 1.2175 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13634/2499940 | global iter:   6818/1249970 | loss: 0.8374 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13636/2499940 | global iter:   6819/1249970 | loss: 1.8882 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  13638/2499940 | global iter:   6820/1249970 | loss: 0.5773 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13638/2499940 | global iter:   6820/1249970 | loss: 1.0646 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13640/2499940 | global iter:   6821/1249970 | loss: 0.6707 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13642/2499940 | global iter:   6822/1249970 | loss: 0.6878 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13644/2499940 | global iter:   6823/1249970 | loss: 0.7141 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13646/2499940 | global iter:   6824/1249970 | loss: 1.8351 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13646/2499940 | global iter:   6824/1249970 | loss: 1.0094 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13648/2499940 | global iter:   6825/1249970 | loss: 1.3817 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13650/2499940 | global iter:   6826/1249970 | loss: 1.2705 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13652/2499940 | global iter:   6827/1249970 | loss: 1.2585 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13654/2499940 | global iter:   6828/1249970 | loss: 1.0237 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13654/2499940 | global iter:   6828/1249970 | loss: 0.9382 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13656/2499940 | global iter:   6829/1249970 | loss: 1.6811 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13658/2499940 | global iter:   6830/1249970 | loss: 1.2698 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13660/2499940 | global iter:   6831/1249970 | loss: 1.6763 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  13662/2499940 | global iter:   6832/1249970 | loss: 1.3733 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13662/2499940 | global iter:   6832/1249970 | loss: 1.4419 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13664/2499940 | global iter:   6833/1249970 | loss: 0.7191 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13666/2499940 | global iter:   6834/1249970 | loss: 0.2292 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13668/2499940 | global iter:   6835/1249970 | loss: 1.2343 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13670/2499940 | global iter:   6836/1249970 | loss: 1.2677 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13670/2499940 | global iter:   6836/1249970 | loss: 0.9956 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13672/2499940 | global iter:   6837/1249970 | loss: 1.3048 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13674/2499940 | global iter:   6838/1249970 | loss: 0.7252 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  13676/2499940 | global iter:   6839/1249970 | loss: 1.0274 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13678/2499940 | global iter:   6840/1249970 | loss: 0.9342 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.410 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13678/2499940 | global iter:   6840/1249970 | loss: 1.0491 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.410 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13680/2499940 | global iter:   6841/1249970 | loss: 0.7769 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13682/2499940 | global iter:   6842/1249970 | loss: 1.2759 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  13684/2499940 | global iter:   6843/1249970 | loss: 1.9193 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13686/2499940 | global iter:   6844/1249970 | loss: 1.2764 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13686/2499940 | global iter:   6844/1249970 | loss: 1.0925 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13688/2499940 | global iter:   6845/1249970 | loss: 0.9333 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13690/2499940 | global iter:   6846/1249970 | loss: 1.6728 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13692/2499940 | global iter:   6847/1249970 | loss: 1.0370 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13694/2499940 | global iter:   6848/1249970 | loss: 0.7596 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13694/2499940 | global iter:   6848/1249970 | loss: 1.1495 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13696/2499940 | global iter:   6849/1249970 | loss: 0.9192 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13698/2499940 | global iter:   6850/1249970 | loss: 1.0469 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13700/2499940 | global iter:   6851/1249970 | loss: 1.1407 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13702/2499940 | global iter:   6852/1249970 | loss: 0.8826 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13702/2499940 | global iter:   6852/1249970 | loss: 0.9599 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13704/2499940 | global iter:   6853/1249970 | loss: 1.6754 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13706/2499940 | global iter:   6854/1249970 | loss: 1.7107 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13708/2499940 | global iter:   6855/1249970 | loss: 1.6065 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13710/2499940 | global iter:   6856/1249970 | loss: 1.9273 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13710/2499940 | global iter:   6856/1249970 | loss: 1.4704 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13712/2499940 | global iter:   6857/1249970 | loss: 0.5991 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13714/2499940 | global iter:   6858/1249970 | loss: 0.5530 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  13716/2499940 | global iter:   6859/1249970 | loss: 0.6346 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13718/2499940 | global iter:   6860/1249970 | loss: 1.0788 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13718/2499940 | global iter:   6860/1249970 | loss: 1.0608 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13720/2499940 | global iter:   6861/1249970 | loss: 1.2199 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13722/2499940 | global iter:   6862/1249970 | loss: 1.5783 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13724/2499940 | global iter:   6863/1249970 | loss: 1.3869 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13726/2499940 | global iter:   6864/1249970 | loss: 1.4930 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13726/2499940 | global iter:   6864/1249970 | loss: 1.3812 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13728/2499940 | global iter:   6865/1249970 | loss: 0.7150 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13730/2499940 | global iter:   6866/1249970 | loss: 0.8726 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  13732/2499940 | global iter:   6867/1249970 | loss: 1.5420 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13734/2499940 | global iter:   6868/1249970 | loss: 1.6065 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13734/2499940 | global iter:   6868/1249970 | loss: 1.2428 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13736/2499940 | global iter:   6869/1249970 | loss: 1.1208 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13738/2499940 | global iter:   6870/1249970 | loss: 1.3047 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13740/2499940 | global iter:   6871/1249970 | loss: 1.0551 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13742/2499940 | global iter:   6872/1249970 | loss: 0.7672 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13742/2499940 | global iter:   6872/1249970 | loss: 1.0484 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13744/2499940 | global iter:   6873/1249970 | loss: 0.7529 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13746/2499940 | global iter:   6874/1249970 | loss: 1.4186 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13748/2499940 | global iter:   6875/1249970 | loss: 0.6930 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  13750/2499940 | global iter:   6876/1249970 | loss: 1.1761 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13750/2499940 | global iter:   6876/1249970 | loss: 0.9902 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13752/2499940 | global iter:   6877/1249970 | loss: 1.1335 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13754/2499940 | global iter:   6878/1249970 | loss: 0.5772 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13756/2499940 | global iter:   6879/1249970 | loss: 0.5158 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13758/2499940 | global iter:   6880/1249970 | loss: 0.9382 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13758/2499940 | global iter:   6880/1249970 | loss: 0.7946 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13760/2499940 | global iter:   6881/1249970 | loss: 1.2991 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13762/2499940 | global iter:   6882/1249970 | loss: 1.1786 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13764/2499940 | global iter:   6883/1249970 | loss: 0.9158 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.407 | step time: 0.000
train | epoch   0 | Iter:  13766/2499940 | global iter:   6884/1249970 | loss: 1.0303 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13766/2499940 | global iter:   6884/1249970 | loss: 1.0603 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13768/2499940 | global iter:   6885/1249970 | loss: 0.9406 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13770/2499940 | global iter:   6886/1249970 | loss: 0.1778 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  13772/2499940 | global iter:   6887/1249970 | loss: 1.6397 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13774/2499940 | global iter:   6888/1249970 | loss: 0.6998 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13774/2499940 | global iter:   6888/1249970 | loss: 0.8630 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13776/2499940 | global iter:   6889/1249970 | loss: 1.4329 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13778/2499940 | global iter:   6890/1249970 | loss: 1.2915 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13780/2499940 | global iter:   6891/1249970 | loss: 1.0092 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13782/2499940 | global iter:   6892/1249970 | loss: 1.7595 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13782/2499940 | global iter:   6892/1249970 | loss: 1.2699 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13784/2499940 | global iter:   6893/1249970 | loss: 0.9973 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13786/2499940 | global iter:   6894/1249970 | loss: 0.9894 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.391 | step time: 0.000
train | epoch   0 | Iter:  13788/2499940 | global iter:   6895/1249970 | loss: 1.5340 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13790/2499940 | global iter:   6896/1249970 | loss: 1.4591 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13790/2499940 | global iter:   6896/1249970 | loss: 1.3535 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13792/2499940 | global iter:   6897/1249970 | loss: 0.5098 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13794/2499940 | global iter:   6898/1249970 | loss: 0.2401 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13796/2499940 | global iter:   6899/1249970 | loss: 0.7344 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  13798/2499940 | global iter:   6900/1249970 | loss: 1.3558 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13798/2499940 | global iter:   6900/1249970 | loss: 0.9180 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13800/2499940 | global iter:   6901/1249970 | loss: 0.7483 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13802/2499940 | global iter:   6902/1249970 | loss: 1.1313 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13804/2499940 | global iter:   6903/1249970 | loss: 1.4114 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13806/2499940 | global iter:   6904/1249970 | loss: 0.7439 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13806/2499940 | global iter:   6904/1249970 | loss: 1.1348 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13808/2499940 | global iter:   6905/1249970 | loss: 1.1917 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13810/2499940 | global iter:   6906/1249970 | loss: 1.1829 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  13812/2499940 | global iter:   6907/1249970 | loss: 1.3876 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  13814/2499940 | global iter:   6908/1249970 | loss: 0.6645 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13814/2499940 | global iter:   6908/1249970 | loss: 1.1636 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13816/2499940 | global iter:   6909/1249970 | loss: 0.8806 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13818/2499940 | global iter:   6910/1249970 | loss: 1.5720 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13820/2499940 | global iter:   6911/1249970 | loss: 0.5819 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13822/2499940 | global iter:   6912/1249970 | loss: 1.1488 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13822/2499940 | global iter:   6912/1249970 | loss: 0.8828 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13824/2499940 | global iter:   6913/1249970 | loss: 1.5757 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13826/2499940 | global iter:   6914/1249970 | loss: 1.5663 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  13828/2499940 | global iter:   6915/1249970 | loss: 1.4781 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13830/2499940 | global iter:   6916/1249970 | loss: 0.8777 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13830/2499940 | global iter:   6916/1249970 | loss: 0.9967 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13832/2499940 | global iter:   6917/1249970 | loss: 1.2961 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13834/2499940 | global iter:   6918/1249970 | loss: 1.3801 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13836/2499940 | global iter:   6919/1249970 | loss: 1.2799 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13838/2499940 | global iter:   6920/1249970 | loss: 1.1052 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13838/2499940 | global iter:   6920/1249970 | loss: 1.1292 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13840/2499940 | global iter:   6921/1249970 | loss: 0.0287 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13842/2499940 | global iter:   6922/1249970 | loss: 1.2958 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  13844/2499940 | global iter:   6923/1249970 | loss: 1.6140 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13846/2499940 | global iter:   6924/1249970 | loss: 0.9993 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13846/2499940 | global iter:   6924/1249970 | loss: 0.9639 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13848/2499940 | global iter:   6925/1249970 | loss: 0.8872 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13850/2499940 | global iter:   6926/1249970 | loss: 1.6053 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.407 | step time: 0.000
train | epoch   0 | Iter:  13852/2499940 | global iter:   6927/1249970 | loss: 1.2202 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13854/2499940 | global iter:   6928/1249970 | loss: 1.5196 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13854/2499940 | global iter:   6928/1249970 | loss: 1.3739 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13856/2499940 | global iter:   6929/1249970 | loss: 1.0967 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13858/2499940 | global iter:   6930/1249970 | loss: 1.0550 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13860/2499940 | global iter:   6931/1249970 | loss: 1.5204 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13862/2499940 | global iter:   6932/1249970 | loss: 1.5593 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13862/2499940 | global iter:   6932/1249970 | loss: 1.0623 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13864/2499940 | global iter:   6933/1249970 | loss: 0.7889 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13866/2499940 | global iter:   6934/1249970 | loss: 1.6757 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13868/2499940 | global iter:   6935/1249970 | loss: 1.0751 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13870/2499940 | global iter:   6936/1249970 | loss: 1.0645 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13870/2499940 | global iter:   6936/1249970 | loss: 1.2325 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13872/2499940 | global iter:   6937/1249970 | loss: 2.0527 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13874/2499940 | global iter:   6938/1249970 | loss: 1.7237 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.392 | step time: 0.000
train | epoch   0 | Iter:  13876/2499940 | global iter:   6939/1249970 | loss: 0.5189 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13878/2499940 | global iter:   6940/1249970 | loss: 1.3970 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13878/2499940 | global iter:   6940/1249970 | loss: 1.3852 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13880/2499940 | global iter:   6941/1249970 | loss: 1.3282 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13882/2499940 | global iter:   6942/1249970 | loss: 1.8117 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13884/2499940 | global iter:   6943/1249970 | loss: 1.2222 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13886/2499940 | global iter:   6944/1249970 | loss: 0.4284 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13886/2499940 | global iter:   6944/1249970 | loss: 1.0356 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13888/2499940 | global iter:   6945/1249970 | loss: 0.7851 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13890/2499940 | global iter:   6946/1249970 | loss: 1.1305 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13892/2499940 | global iter:   6947/1249970 | loss: 0.1415 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13894/2499940 | global iter:   6948/1249970 | loss: 0.5848 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13894/2499940 | global iter:   6948/1249970 | loss: 0.8274 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13896/2499940 | global iter:   6949/1249970 | loss: 1.4604 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13898/2499940 | global iter:   6950/1249970 | loss: 0.8315 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  13900/2499940 | global iter:   6951/1249970 | loss: 0.9893 | ds_loss: 0.0000 | lr: 9.9993e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13902/2499940 | global iter:   6952/1249970 | loss: 1.5625 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13902/2499940 | global iter:   6952/1249970 | loss: 1.3415 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13904/2499940 | global iter:   6953/1249970 | loss: 0.7159 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13906/2499940 | global iter:   6954/1249970 | loss: 1.2891 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13908/2499940 | global iter:   6955/1249970 | loss: 1.3471 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13910/2499940 | global iter:   6956/1249970 | loss: 0.8236 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13910/2499940 | global iter:   6956/1249970 | loss: 1.1443 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13912/2499940 | global iter:   6957/1249970 | loss: 1.1358 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13914/2499940 | global iter:   6958/1249970 | loss: 1.2838 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  13916/2499940 | global iter:   6959/1249970 | loss: 1.6255 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  13918/2499940 | global iter:   6960/1249970 | loss: 1.3620 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13918/2499940 | global iter:   6960/1249970 | loss: 1.2589 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13920/2499940 | global iter:   6961/1249970 | loss: 1.3896 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13922/2499940 | global iter:   6962/1249970 | loss: 0.5950 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13924/2499940 | global iter:   6963/1249970 | loss: 1.6556 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13926/2499940 | global iter:   6964/1249970 | loss: 1.1800 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13926/2499940 | global iter:   6964/1249970 | loss: 0.8358 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13928/2499940 | global iter:   6965/1249970 | loss: 0.9548 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13930/2499940 | global iter:   6966/1249970 | loss: 1.1479 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13932/2499940 | global iter:   6967/1249970 | loss: 0.5583 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13934/2499940 | global iter:   6968/1249970 | loss: 1.3392 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13934/2499940 | global iter:   6968/1249970 | loss: 1.0791 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13936/2499940 | global iter:   6969/1249970 | loss: 0.7430 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.410 | step time: 0.000
train | epoch   0 | Iter:  13938/2499940 | global iter:   6970/1249970 | loss: 1.7629 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.408 | step time: 0.000
train | epoch   0 | Iter:  13940/2499940 | global iter:   6971/1249970 | loss: 2.2242 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13942/2499940 | global iter:   6972/1249970 | loss: 1.1921 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13942/2499940 | global iter:   6972/1249970 | loss: 1.2658 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.696
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13944/2499940 | global iter:   6973/1249970 | loss: 0.8108 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13946/2499940 | global iter:   6974/1249970 | loss: 0.4085 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13948/2499940 | global iter:   6975/1249970 | loss: 0.9959 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13950/2499940 | global iter:   6976/1249970 | loss: 1.2834 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13950/2499940 | global iter:   6976/1249970 | loss: 1.0462 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13952/2499940 | global iter:   6977/1249970 | loss: 1.3621 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13954/2499940 | global iter:   6978/1249970 | loss: 0.5385 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  13956/2499940 | global iter:   6979/1249970 | loss: 0.9627 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13958/2499940 | global iter:   6980/1249970 | loss: 1.7723 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13958/2499940 | global iter:   6980/1249970 | loss: 1.1597 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13960/2499940 | global iter:   6981/1249970 | loss: 1.1720 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13962/2499940 | global iter:   6982/1249970 | loss: 1.2121 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13964/2499940 | global iter:   6983/1249970 | loss: 1.8133 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  13966/2499940 | global iter:   6984/1249970 | loss: 0.7004 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13966/2499940 | global iter:   6984/1249970 | loss: 1.0742 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13968/2499940 | global iter:   6985/1249970 | loss: 0.6915 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13970/2499940 | global iter:   6986/1249970 | loss: 1.0229 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13972/2499940 | global iter:   6987/1249970 | loss: 0.5389 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  13974/2499940 | global iter:   6988/1249970 | loss: 0.8029 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13974/2499940 | global iter:   6988/1249970 | loss: 0.8739 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13976/2499940 | global iter:   6989/1249970 | loss: 1.3988 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13978/2499940 | global iter:   6990/1249970 | loss: 1.5876 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13980/2499940 | global iter:   6991/1249970 | loss: 2.1299 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13982/2499940 | global iter:   6992/1249970 | loss: 1.2416 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13982/2499940 | global iter:   6992/1249970 | loss: 1.2145 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13984/2499940 | global iter:   6993/1249970 | loss: 1.4065 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  13986/2499940 | global iter:   6994/1249970 | loss: 1.1032 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  13988/2499940 | global iter:   6995/1249970 | loss: 1.2494 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13990/2499940 | global iter:   6996/1249970 | loss: 1.3986 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13990/2499940 | global iter:   6996/1249970 | loss: 1.3082 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  13992/2499940 | global iter:   6997/1249970 | loss: 0.6060 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  13994/2499940 | global iter:   6998/1249970 | loss: 1.0601 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  13996/2499940 | global iter:   6999/1249970 | loss: 0.8324 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  13998/2499940 | global iter:   7000/1249970 | loss: 1.7758 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  13998/2499940 | global iter:   7000/1249970 | loss: 1.2419 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14000/2499940 | global iter:   7001/1249970 | loss: 1.5037 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14002/2499940 | global iter:   7002/1249970 | loss: 0.8153 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14004/2499940 | global iter:   7003/1249970 | loss: 0.2632 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14006/2499940 | global iter:   7004/1249970 | loss: 0.7750 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14006/2499940 | global iter:   7004/1249970 | loss: 1.0281 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14008/2499940 | global iter:   7005/1249970 | loss: 1.2225 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14010/2499940 | global iter:   7006/1249970 | loss: 0.5481 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14012/2499940 | global iter:   7007/1249970 | loss: 0.5817 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14014/2499940 | global iter:   7008/1249970 | loss: 1.0714 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14014/2499940 | global iter:   7008/1249970 | loss: 0.8804 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14016/2499940 | global iter:   7009/1249970 | loss: 1.0292 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14018/2499940 | global iter:   7010/1249970 | loss: 1.2460 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14020/2499940 | global iter:   7011/1249970 | loss: 0.8661 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14022/2499940 | global iter:   7012/1249970 | loss: 0.9491 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14022/2499940 | global iter:   7012/1249970 | loss: 1.0130 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14024/2499940 | global iter:   7013/1249970 | loss: 0.1463 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14026/2499940 | global iter:   7014/1249970 | loss: 2.1159 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14028/2499940 | global iter:   7015/1249970 | loss: 1.5422 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14030/2499940 | global iter:   7016/1249970 | loss: 1.0427 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14030/2499940 | global iter:   7016/1249970 | loss: 1.0620 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14032/2499940 | global iter:   7017/1249970 | loss: 1.2518 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14034/2499940 | global iter:   7018/1249970 | loss: 0.7078 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14036/2499940 | global iter:   7019/1249970 | loss: 0.9656 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14038/2499940 | global iter:   7020/1249970 | loss: 0.7215 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14038/2499940 | global iter:   7020/1249970 | loss: 0.9316 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14040/2499940 | global iter:   7021/1249970 | loss: 1.2793 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14042/2499940 | global iter:   7022/1249970 | loss: 0.2923 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14044/2499940 | global iter:   7023/1249970 | loss: 1.7115 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14046/2499940 | global iter:   7024/1249970 | loss: 1.5134 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14046/2499940 | global iter:   7024/1249970 | loss: 1.1821 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14048/2499940 | global iter:   7025/1249970 | loss: 1.5632 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14050/2499940 | global iter:   7026/1249970 | loss: 1.3526 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  14052/2499940 | global iter:   7027/1249970 | loss: 1.4629 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14054/2499940 | global iter:   7028/1249970 | loss: 1.2531 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14054/2499940 | global iter:   7028/1249970 | loss: 1.2804 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14056/2499940 | global iter:   7029/1249970 | loss: 1.1467 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14058/2499940 | global iter:   7030/1249970 | loss: 1.5024 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14060/2499940 | global iter:   7031/1249970 | loss: 0.6809 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14062/2499940 | global iter:   7032/1249970 | loss: 1.0044 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14062/2499940 | global iter:   7032/1249970 | loss: 1.1027 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14064/2499940 | global iter:   7033/1249970 | loss: 0.8819 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14066/2499940 | global iter:   7034/1249970 | loss: 1.1609 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14068/2499940 | global iter:   7035/1249970 | loss: 0.8058 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  14070/2499940 | global iter:   7036/1249970 | loss: 0.6448 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14070/2499940 | global iter:   7036/1249970 | loss: 0.9114 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14072/2499940 | global iter:   7037/1249970 | loss: 1.0050 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14074/2499940 | global iter:   7038/1249970 | loss: 0.7115 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14076/2499940 | global iter:   7039/1249970 | loss: 1.2408 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14078/2499940 | global iter:   7040/1249970 | loss: 0.8517 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14078/2499940 | global iter:   7040/1249970 | loss: 0.8062 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14080/2499940 | global iter:   7041/1249970 | loss: 0.8212 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14082/2499940 | global iter:   7042/1249970 | loss: 0.9316 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14084/2499940 | global iter:   7043/1249970 | loss: 1.4651 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14086/2499940 | global iter:   7044/1249970 | loss: 1.1264 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14086/2499940 | global iter:   7044/1249970 | loss: 1.0841 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14088/2499940 | global iter:   7045/1249970 | loss: 0.5299 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14090/2499940 | global iter:   7046/1249970 | loss: 1.0966 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14092/2499940 | global iter:   7047/1249970 | loss: 0.6831 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14094/2499940 | global iter:   7048/1249970 | loss: 1.3960 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14094/2499940 | global iter:   7048/1249970 | loss: 0.9282 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14096/2499940 | global iter:   7049/1249970 | loss: 1.0378 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14098/2499940 | global iter:   7050/1249970 | loss: 0.1748 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14100/2499940 | global iter:   7051/1249970 | loss: 1.1080 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14102/2499940 | global iter:   7052/1249970 | loss: 1.1489 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14102/2499940 | global iter:   7052/1249970 | loss: 0.9486 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14104/2499940 | global iter:   7053/1249970 | loss: 1.4077 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  14106/2499940 | global iter:   7054/1249970 | loss: 0.8930 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14108/2499940 | global iter:   7055/1249970 | loss: 1.4074 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14110/2499940 | global iter:   7056/1249970 | loss: 1.2905 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.407 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14110/2499940 | global iter:   7056/1249970 | loss: 1.2470 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.407 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14112/2499940 | global iter:   7057/1249970 | loss: 1.0767 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14114/2499940 | global iter:   7058/1249970 | loss: 1.6267 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14116/2499940 | global iter:   7059/1249970 | loss: 1.3091 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14118/2499940 | global iter:   7060/1249970 | loss: 1.0104 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14118/2499940 | global iter:   7060/1249970 | loss: 1.0526 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14120/2499940 | global iter:   7061/1249970 | loss: 0.4999 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14122/2499940 | global iter:   7062/1249970 | loss: 0.8671 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14124/2499940 | global iter:   7063/1249970 | loss: 1.0289 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14126/2499940 | global iter:   7064/1249970 | loss: 1.5939 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14126/2499940 | global iter:   7064/1249970 | loss: 0.9807 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14128/2499940 | global iter:   7065/1249970 | loss: 0.3322 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14130/2499940 | global iter:   7066/1249970 | loss: 0.7780 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14132/2499940 | global iter:   7067/1249970 | loss: 1.1436 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  14134/2499940 | global iter:   7068/1249970 | loss: 0.6875 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14134/2499940 | global iter:   7068/1249970 | loss: 0.8328 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14136/2499940 | global iter:   7069/1249970 | loss: 0.3213 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14138/2499940 | global iter:   7070/1249970 | loss: 1.0422 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  14140/2499940 | global iter:   7071/1249970 | loss: 1.3110 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14142/2499940 | global iter:   7072/1249970 | loss: 1.7587 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14142/2499940 | global iter:   7072/1249970 | loss: 1.0600 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14144/2499940 | global iter:   7073/1249970 | loss: 1.4966 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14146/2499940 | global iter:   7074/1249970 | loss: 1.0950 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:  14148/2499940 | global iter:   7075/1249970 | loss: 1.3787 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  14150/2499940 | global iter:   7076/1249970 | loss: 1.3317 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14150/2499940 | global iter:   7076/1249970 | loss: 1.2204 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14152/2499940 | global iter:   7077/1249970 | loss: 1.2368 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  14154/2499940 | global iter:   7078/1249970 | loss: 1.1687 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14156/2499940 | global iter:   7079/1249970 | loss: 1.3011 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  14158/2499940 | global iter:   7080/1249970 | loss: 1.0428 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14158/2499940 | global iter:   7080/1249970 | loss: 1.1114 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14160/2499940 | global iter:   7081/1249970 | loss: 1.1815 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14162/2499940 | global iter:   7082/1249970 | loss: 1.5159 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  14164/2499940 | global iter:   7083/1249970 | loss: 0.6994 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14166/2499940 | global iter:   7084/1249970 | loss: 1.6492 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14166/2499940 | global iter:   7084/1249970 | loss: 1.2937 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14168/2499940 | global iter:   7085/1249970 | loss: 0.6012 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14170/2499940 | global iter:   7086/1249970 | loss: 1.4039 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14172/2499940 | global iter:   7087/1249970 | loss: 0.8001 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14174/2499940 | global iter:   7088/1249970 | loss: 0.3941 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14174/2499940 | global iter:   7088/1249970 | loss: 0.7025 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14176/2499940 | global iter:   7089/1249970 | loss: 1.7932 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14178/2499940 | global iter:   7090/1249970 | loss: 1.5054 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14180/2499940 | global iter:   7091/1249970 | loss: 1.4020 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14182/2499940 | global iter:   7092/1249970 | loss: 1.1487 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14182/2499940 | global iter:   7092/1249970 | loss: 1.2974 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14184/2499940 | global iter:   7093/1249970 | loss: 1.5901 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14186/2499940 | global iter:   7094/1249970 | loss: 0.4840 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14188/2499940 | global iter:   7095/1249970 | loss: 0.5542 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14190/2499940 | global iter:   7096/1249970 | loss: 0.4139 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14190/2499940 | global iter:   7096/1249970 | loss: 0.9914 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14192/2499940 | global iter:   7097/1249970 | loss: 1.4852 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14194/2499940 | global iter:   7098/1249970 | loss: 0.4456 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14196/2499940 | global iter:   7099/1249970 | loss: 1.9561 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.410 | step time: 0.000
train | epoch   0 | Iter:  14198/2499940 | global iter:   7100/1249970 | loss: 1.3670 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.410 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14198/2499940 | global iter:   7100/1249970 | loss: 1.0883 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.410 | step time: 0.695
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14200/2499940 | global iter:   7101/1249970 | loss: 0.2598 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14202/2499940 | global iter:   7102/1249970 | loss: 1.0895 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14204/2499940 | global iter:   7103/1249970 | loss: 0.5159 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14206/2499940 | global iter:   7104/1249970 | loss: 1.7381 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14206/2499940 | global iter:   7104/1249970 | loss: 0.9330 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14208/2499940 | global iter:   7105/1249970 | loss: 1.6350 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14210/2499940 | global iter:   7106/1249970 | loss: 1.1876 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  14212/2499940 | global iter:   7107/1249970 | loss: 1.2031 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14214/2499940 | global iter:   7108/1249970 | loss: 1.3902 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14214/2499940 | global iter:   7108/1249970 | loss: 1.2011 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14216/2499940 | global iter:   7109/1249970 | loss: 0.8549 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  14218/2499940 | global iter:   7110/1249970 | loss: 0.8183 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14220/2499940 | global iter:   7111/1249970 | loss: 0.4759 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14222/2499940 | global iter:   7112/1249970 | loss: 0.5177 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14222/2499940 | global iter:   7112/1249970 | loss: 0.9819 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14224/2499940 | global iter:   7113/1249970 | loss: 0.4059 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14226/2499940 | global iter:   7114/1249970 | loss: 1.2011 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14228/2499940 | global iter:   7115/1249970 | loss: 0.1182 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14230/2499940 | global iter:   7116/1249970 | loss: 1.1490 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14230/2499940 | global iter:   7116/1249970 | loss: 1.0776 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14232/2499940 | global iter:   7117/1249970 | loss: 1.1859 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14234/2499940 | global iter:   7118/1249970 | loss: 0.4524 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14236/2499940 | global iter:   7119/1249970 | loss: 0.4499 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14238/2499940 | global iter:   7120/1249970 | loss: 1.3970 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14238/2499940 | global iter:   7120/1249970 | loss: 0.9493 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14240/2499940 | global iter:   7121/1249970 | loss: 0.5209 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14242/2499940 | global iter:   7122/1249970 | loss: 1.2389 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  14244/2499940 | global iter:   7123/1249970 | loss: 1.7413 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14246/2499940 | global iter:   7124/1249970 | loss: 1.4068 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14246/2499940 | global iter:   7124/1249970 | loss: 1.3227 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14248/2499940 | global iter:   7125/1249970 | loss: 1.4086 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14250/2499940 | global iter:   7126/1249970 | loss: 1.5293 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14252/2499940 | global iter:   7127/1249970 | loss: 1.2489 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14254/2499940 | global iter:   7128/1249970 | loss: 1.2982 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14254/2499940 | global iter:   7128/1249970 | loss: 1.3908 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14256/2499940 | global iter:   7129/1249970 | loss: 1.2311 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14258/2499940 | global iter:   7130/1249970 | loss: 0.6671 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14260/2499940 | global iter:   7131/1249970 | loss: 1.9264 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14262/2499940 | global iter:   7132/1249970 | loss: 0.9990 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14262/2499940 | global iter:   7132/1249970 | loss: 1.1023 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14264/2499940 | global iter:   7133/1249970 | loss: 0.9047 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14266/2499940 | global iter:   7134/1249970 | loss: 0.3817 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14268/2499940 | global iter:   7135/1249970 | loss: 2.0433 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14270/2499940 | global iter:   7136/1249970 | loss: 0.2430 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14270/2499940 | global iter:   7136/1249970 | loss: 1.0658 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14272/2499940 | global iter:   7137/1249970 | loss: 1.1725 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14274/2499940 | global iter:   7138/1249970 | loss: 0.8136 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14276/2499940 | global iter:   7139/1249970 | loss: 0.7133 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14278/2499940 | global iter:   7140/1249970 | loss: 1.4309 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14278/2499940 | global iter:   7140/1249970 | loss: 1.0767 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14280/2499940 | global iter:   7141/1249970 | loss: 1.3791 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14282/2499940 | global iter:   7142/1249970 | loss: 0.8865 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14284/2499940 | global iter:   7143/1249970 | loss: 0.8360 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  14286/2499940 | global iter:   7144/1249970 | loss: 0.2603 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14286/2499940 | global iter:   7144/1249970 | loss: 1.0176 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14288/2499940 | global iter:   7145/1249970 | loss: 1.0713 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14290/2499940 | global iter:   7146/1249970 | loss: 1.9541 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  14292/2499940 | global iter:   7147/1249970 | loss: 0.5379 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14294/2499940 | global iter:   7148/1249970 | loss: 1.6402 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14294/2499940 | global iter:   7148/1249970 | loss: 1.3433 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14296/2499940 | global iter:   7149/1249970 | loss: 2.2343 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14298/2499940 | global iter:   7150/1249970 | loss: 1.6860 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  14300/2499940 | global iter:   7151/1249970 | loss: 1.4648 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14302/2499940 | global iter:   7152/1249970 | loss: 0.5797 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14302/2499940 | global iter:   7152/1249970 | loss: 1.4807 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14304/2499940 | global iter:   7153/1249970 | loss: 1.5057 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14306/2499940 | global iter:   7154/1249970 | loss: 0.8418 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14308/2499940 | global iter:   7155/1249970 | loss: 1.4750 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14310/2499940 | global iter:   7156/1249970 | loss: 0.7762 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14310/2499940 | global iter:   7156/1249970 | loss: 1.2450 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14312/2499940 | global iter:   7157/1249970 | loss: 0.8661 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14314/2499940 | global iter:   7158/1249970 | loss: 1.4611 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14316/2499940 | global iter:   7159/1249970 | loss: 1.5266 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14318/2499940 | global iter:   7160/1249970 | loss: 1.0110 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14318/2499940 | global iter:   7160/1249970 | loss: 1.3065 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14320/2499940 | global iter:   7161/1249970 | loss: 1.5097 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14322/2499940 | global iter:   7162/1249970 | loss: 1.1628 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14324/2499940 | global iter:   7163/1249970 | loss: 0.4843 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14326/2499940 | global iter:   7164/1249970 | loss: 1.5883 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14326/2499940 | global iter:   7164/1249970 | loss: 1.2231 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14328/2499940 | global iter:   7165/1249970 | loss: 1.6668 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14330/2499940 | global iter:   7166/1249970 | loss: 0.6656 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14332/2499940 | global iter:   7167/1249970 | loss: 0.8271 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14334/2499940 | global iter:   7168/1249970 | loss: 0.2419 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14334/2499940 | global iter:   7168/1249970 | loss: 0.9388 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14336/2499940 | global iter:   7169/1249970 | loss: 1.0157 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14338/2499940 | global iter:   7170/1249970 | loss: 1.2597 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14340/2499940 | global iter:   7171/1249970 | loss: 1.0991 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14342/2499940 | global iter:   7172/1249970 | loss: 0.7210 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14342/2499940 | global iter:   7172/1249970 | loss: 1.0754 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14344/2499940 | global iter:   7173/1249970 | loss: 0.4078 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14346/2499940 | global iter:   7174/1249970 | loss: 1.2217 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14348/2499940 | global iter:   7175/1249970 | loss: 1.0213 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14350/2499940 | global iter:   7176/1249970 | loss: 1.3902 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14350/2499940 | global iter:   7176/1249970 | loss: 0.9996 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14352/2499940 | global iter:   7177/1249970 | loss: 1.4760 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14354/2499940 | global iter:   7178/1249970 | loss: 1.3516 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14356/2499940 | global iter:   7179/1249970 | loss: 0.8915 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14358/2499940 | global iter:   7180/1249970 | loss: 1.7251 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14358/2499940 | global iter:   7180/1249970 | loss: 1.2366 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14360/2499940 | global iter:   7181/1249970 | loss: 1.4271 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14362/2499940 | global iter:   7182/1249970 | loss: 1.0974 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  14364/2499940 | global iter:   7183/1249970 | loss: 1.6959 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14366/2499940 | global iter:   7184/1249970 | loss: 1.0094 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14366/2499940 | global iter:   7184/1249970 | loss: 1.1292 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14368/2499940 | global iter:   7185/1249970 | loss: 1.1464 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  14370/2499940 | global iter:   7186/1249970 | loss: 1.4777 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.405 | step time: 0.000
train | epoch   0 | Iter:  14372/2499940 | global iter:   7187/1249970 | loss: 0.9516 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14374/2499940 | global iter:   7188/1249970 | loss: 1.0773 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14374/2499940 | global iter:   7188/1249970 | loss: 1.1917 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14376/2499940 | global iter:   7189/1249970 | loss: 1.4089 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  14378/2499940 | global iter:   7190/1249970 | loss: 1.1101 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14380/2499940 | global iter:   7191/1249970 | loss: 1.4436 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14382/2499940 | global iter:   7192/1249970 | loss: 0.7544 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14382/2499940 | global iter:   7192/1249970 | loss: 1.2112 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14384/2499940 | global iter:   7193/1249970 | loss: 1.6157 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14386/2499940 | global iter:   7194/1249970 | loss: 0.1253 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14388/2499940 | global iter:   7195/1249970 | loss: 1.3381 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14390/2499940 | global iter:   7196/1249970 | loss: 0.9582 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14390/2499940 | global iter:   7196/1249970 | loss: 1.1847 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14392/2499940 | global iter:   7197/1249970 | loss: 0.5667 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14394/2499940 | global iter:   7198/1249970 | loss: 1.0524 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14396/2499940 | global iter:   7199/1249970 | loss: 0.8057 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14398/2499940 | global iter:   7200/1249970 | loss: 0.9870 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14398/2499940 | global iter:   7200/1249970 | loss: 0.9625 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14400/2499940 | global iter:   7201/1249970 | loss: 1.0237 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14402/2499940 | global iter:   7202/1249970 | loss: 1.4218 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  14404/2499940 | global iter:   7203/1249970 | loss: 0.5972 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14406/2499940 | global iter:   7204/1249970 | loss: 1.1052 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14406/2499940 | global iter:   7204/1249970 | loss: 1.1113 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14408/2499940 | global iter:   7205/1249970 | loss: 1.3237 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14410/2499940 | global iter:   7206/1249970 | loss: 1.4579 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14412/2499940 | global iter:   7207/1249970 | loss: 0.5375 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14414/2499940 | global iter:   7208/1249970 | loss: 0.6230 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14414/2499940 | global iter:   7208/1249970 | loss: 0.7003 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14416/2499940 | global iter:   7209/1249970 | loss: 1.6977 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  14418/2499940 | global iter:   7210/1249970 | loss: 0.6452 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14420/2499940 | global iter:   7211/1249970 | loss: 1.3324 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14422/2499940 | global iter:   7212/1249970 | loss: 1.1094 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14422/2499940 | global iter:   7212/1249970 | loss: 1.3022 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14424/2499940 | global iter:   7213/1249970 | loss: 1.3999 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14426/2499940 | global iter:   7214/1249970 | loss: 1.2584 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14428/2499940 | global iter:   7215/1249970 | loss: 0.5557 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  14430/2499940 | global iter:   7216/1249970 | loss: 1.5170 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14430/2499940 | global iter:   7216/1249970 | loss: 0.9935 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14432/2499940 | global iter:   7217/1249970 | loss: 0.8424 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14434/2499940 | global iter:   7218/1249970 | loss: 0.6545 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14436/2499940 | global iter:   7219/1249970 | loss: 0.1625 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14438/2499940 | global iter:   7220/1249970 | loss: 1.5096 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14438/2499940 | global iter:   7220/1249970 | loss: 1.1446 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14440/2499940 | global iter:   7221/1249970 | loss: 1.3092 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14442/2499940 | global iter:   7222/1249970 | loss: 0.6915 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  14444/2499940 | global iter:   7223/1249970 | loss: 1.2062 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14446/2499940 | global iter:   7224/1249970 | loss: 1.8008 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14446/2499940 | global iter:   7224/1249970 | loss: 1.1715 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14448/2499940 | global iter:   7225/1249970 | loss: 0.9916 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14450/2499940 | global iter:   7226/1249970 | loss: 1.4743 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14452/2499940 | global iter:   7227/1249970 | loss: 0.7759 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14454/2499940 | global iter:   7228/1249970 | loss: 0.3060 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14454/2499940 | global iter:   7228/1249970 | loss: 0.8903 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14456/2499940 | global iter:   7229/1249970 | loss: 0.9815 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.408 | step time: 0.000
train | epoch   0 | Iter:  14458/2499940 | global iter:   7230/1249970 | loss: 0.6925 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.410 | step time: 0.000
train | epoch   0 | Iter:  14460/2499940 | global iter:   7231/1249970 | loss: 0.7808 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  14462/2499940 | global iter:   7232/1249970 | loss: 1.7538 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14462/2499940 | global iter:   7232/1249970 | loss: 1.2075 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.696
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14464/2499940 | global iter:   7233/1249970 | loss: 1.4467 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14466/2499940 | global iter:   7234/1249970 | loss: 1.2732 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14468/2499940 | global iter:   7235/1249970 | loss: 0.9536 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14470/2499940 | global iter:   7236/1249970 | loss: 0.1654 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14470/2499940 | global iter:   7236/1249970 | loss: 1.2154 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14472/2499940 | global iter:   7237/1249970 | loss: 1.4159 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14474/2499940 | global iter:   7238/1249970 | loss: 1.4145 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14476/2499940 | global iter:   7239/1249970 | loss: 0.2008 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14478/2499940 | global iter:   7240/1249970 | loss: 1.1376 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14478/2499940 | global iter:   7240/1249970 | loss: 0.9299 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14480/2499940 | global iter:   7241/1249970 | loss: 0.5063 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14482/2499940 | global iter:   7242/1249970 | loss: 1.0500 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14484/2499940 | global iter:   7243/1249970 | loss: 1.3750 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14486/2499940 | global iter:   7244/1249970 | loss: 1.7991 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14486/2499940 | global iter:   7244/1249970 | loss: 1.1559 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14488/2499940 | global iter:   7245/1249970 | loss: 1.0384 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14490/2499940 | global iter:   7246/1249970 | loss: 0.5551 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14492/2499940 | global iter:   7247/1249970 | loss: 0.9019 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14494/2499940 | global iter:   7248/1249970 | loss: 0.8004 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14494/2499940 | global iter:   7248/1249970 | loss: 0.8610 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14496/2499940 | global iter:   7249/1249970 | loss: 0.9658 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14498/2499940 | global iter:   7250/1249970 | loss: 1.3103 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14500/2499940 | global iter:   7251/1249970 | loss: 2.0822 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14502/2499940 | global iter:   7252/1249970 | loss: 1.3863 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14502/2499940 | global iter:   7252/1249970 | loss: 1.1568 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14504/2499940 | global iter:   7253/1249970 | loss: 1.1361 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  14506/2499940 | global iter:   7254/1249970 | loss: 1.8650 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14508/2499940 | global iter:   7255/1249970 | loss: 1.1609 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  14510/2499940 | global iter:   7256/1249970 | loss: 1.1962 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14510/2499940 | global iter:   7256/1249970 | loss: 1.2551 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14512/2499940 | global iter:   7257/1249970 | loss: 1.2827 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14514/2499940 | global iter:   7258/1249970 | loss: 0.8086 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14516/2499940 | global iter:   7259/1249970 | loss: 0.8978 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14518/2499940 | global iter:   7260/1249970 | loss: 1.2659 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14518/2499940 | global iter:   7260/1249970 | loss: 1.1179 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14520/2499940 | global iter:   7261/1249970 | loss: 1.1137 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14522/2499940 | global iter:   7262/1249970 | loss: 1.0546 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14524/2499940 | global iter:   7263/1249970 | loss: 0.9896 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14526/2499940 | global iter:   7264/1249970 | loss: 0.9087 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14526/2499940 | global iter:   7264/1249970 | loss: 1.2984 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14528/2499940 | global iter:   7265/1249970 | loss: 0.7969 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14530/2499940 | global iter:   7266/1249970 | loss: 0.5300 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  14532/2499940 | global iter:   7267/1249970 | loss: 1.1133 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14534/2499940 | global iter:   7268/1249970 | loss: 1.1319 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14534/2499940 | global iter:   7268/1249970 | loss: 1.1415 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14536/2499940 | global iter:   7269/1249970 | loss: 1.0238 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14538/2499940 | global iter:   7270/1249970 | loss: 0.9865 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14540/2499940 | global iter:   7271/1249970 | loss: 1.8742 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14542/2499940 | global iter:   7272/1249970 | loss: 1.4514 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14542/2499940 | global iter:   7272/1249970 | loss: 1.2086 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14544/2499940 | global iter:   7273/1249970 | loss: 1.8389 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.407 | step time: 0.000
train | epoch   0 | Iter:  14546/2499940 | global iter:   7274/1249970 | loss: 1.5354 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  14548/2499940 | global iter:   7275/1249970 | loss: 1.3574 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14550/2499940 | global iter:   7276/1249970 | loss: 1.7302 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14550/2499940 | global iter:   7276/1249970 | loss: 1.2441 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14552/2499940 | global iter:   7277/1249970 | loss: 1.2582 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14554/2499940 | global iter:   7278/1249970 | loss: 1.1980 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14556/2499940 | global iter:   7279/1249970 | loss: 1.3841 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14558/2499940 | global iter:   7280/1249970 | loss: 0.8837 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14558/2499940 | global iter:   7280/1249970 | loss: 1.0920 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14560/2499940 | global iter:   7281/1249970 | loss: 1.4412 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14562/2499940 | global iter:   7282/1249970 | loss: 0.7266 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14564/2499940 | global iter:   7283/1249970 | loss: 1.5785 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14566/2499940 | global iter:   7284/1249970 | loss: 0.5918 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14566/2499940 | global iter:   7284/1249970 | loss: 1.1226 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14568/2499940 | global iter:   7285/1249970 | loss: 0.4365 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14570/2499940 | global iter:   7286/1249970 | loss: 1.7050 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14572/2499940 | global iter:   7287/1249970 | loss: 0.2654 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14574/2499940 | global iter:   7288/1249970 | loss: 1.5765 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14574/2499940 | global iter:   7288/1249970 | loss: 1.0875 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14576/2499940 | global iter:   7289/1249970 | loss: 0.8192 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14578/2499940 | global iter:   7290/1249970 | loss: 0.2599 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14580/2499940 | global iter:   7291/1249970 | loss: 1.6340 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14582/2499940 | global iter:   7292/1249970 | loss: 0.9603 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14582/2499940 | global iter:   7292/1249970 | loss: 1.0572 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14584/2499940 | global iter:   7293/1249970 | loss: 0.2116 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14586/2499940 | global iter:   7294/1249970 | loss: 1.1473 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14588/2499940 | global iter:   7295/1249970 | loss: 1.2029 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14590/2499940 | global iter:   7296/1249970 | loss: 0.7151 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14590/2499940 | global iter:   7296/1249970 | loss: 1.0092 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14592/2499940 | global iter:   7297/1249970 | loss: 0.6389 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14594/2499940 | global iter:   7298/1249970 | loss: 1.4701 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  14596/2499940 | global iter:   7299/1249970 | loss: 1.1624 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14598/2499940 | global iter:   7300/1249970 | loss: 1.4226 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14598/2499940 | global iter:   7300/1249970 | loss: 0.9941 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14600/2499940 | global iter:   7301/1249970 | loss: 0.6995 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14602/2499940 | global iter:   7302/1249970 | loss: 1.3457 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14604/2499940 | global iter:   7303/1249970 | loss: 0.6702 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14606/2499940 | global iter:   7304/1249970 | loss: 1.3857 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14606/2499940 | global iter:   7304/1249970 | loss: 0.8969 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14608/2499940 | global iter:   7305/1249970 | loss: 0.7300 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14610/2499940 | global iter:   7306/1249970 | loss: 0.0422 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14612/2499940 | global iter:   7307/1249970 | loss: 1.4872 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14614/2499940 | global iter:   7308/1249970 | loss: 0.8631 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14614/2499940 | global iter:   7308/1249970 | loss: 1.0181 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14616/2499940 | global iter:   7309/1249970 | loss: 0.8304 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14618/2499940 | global iter:   7310/1249970 | loss: 1.7434 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14620/2499940 | global iter:   7311/1249970 | loss: 1.2059 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14622/2499940 | global iter:   7312/1249970 | loss: 0.8411 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14622/2499940 | global iter:   7312/1249970 | loss: 1.0805 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14624/2499940 | global iter:   7313/1249970 | loss: 1.4558 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14626/2499940 | global iter:   7314/1249970 | loss: 1.8403 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14628/2499940 | global iter:   7315/1249970 | loss: 0.8588 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14630/2499940 | global iter:   7316/1249970 | loss: 1.1882 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.409 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14630/2499940 | global iter:   7316/1249970 | loss: 1.0670 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.409 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14632/2499940 | global iter:   7317/1249970 | loss: 1.3220 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14634/2499940 | global iter:   7318/1249970 | loss: 2.0179 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14636/2499940 | global iter:   7319/1249970 | loss: 1.3471 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14638/2499940 | global iter:   7320/1249970 | loss: 1.7508 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14638/2499940 | global iter:   7320/1249970 | loss: 1.2512 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14640/2499940 | global iter:   7321/1249970 | loss: 0.0386 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14642/2499940 | global iter:   7322/1249970 | loss: 1.6949 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  14644/2499940 | global iter:   7323/1249970 | loss: 0.7867 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14646/2499940 | global iter:   7324/1249970 | loss: 1.5159 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14646/2499940 | global iter:   7324/1249970 | loss: 1.2224 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14648/2499940 | global iter:   7325/1249970 | loss: 1.4402 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14650/2499940 | global iter:   7326/1249970 | loss: 1.4365 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14652/2499940 | global iter:   7327/1249970 | loss: 0.4572 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14654/2499940 | global iter:   7328/1249970 | loss: 0.7722 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14654/2499940 | global iter:   7328/1249970 | loss: 1.1507 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14656/2499940 | global iter:   7329/1249970 | loss: 1.1225 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14658/2499940 | global iter:   7330/1249970 | loss: 0.9754 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14660/2499940 | global iter:   7331/1249970 | loss: 0.9406 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14662/2499940 | global iter:   7332/1249970 | loss: 1.5144 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14662/2499940 | global iter:   7332/1249970 | loss: 1.2391 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14664/2499940 | global iter:   7333/1249970 | loss: 1.3569 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  14666/2499940 | global iter:   7334/1249970 | loss: 1.4889 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  14668/2499940 | global iter:   7335/1249970 | loss: 1.4567 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14670/2499940 | global iter:   7336/1249970 | loss: 0.8297 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14670/2499940 | global iter:   7336/1249970 | loss: 1.2672 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14672/2499940 | global iter:   7337/1249970 | loss: 1.2294 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  14674/2499940 | global iter:   7338/1249970 | loss: 1.3325 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14676/2499940 | global iter:   7339/1249970 | loss: 0.6243 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14678/2499940 | global iter:   7340/1249970 | loss: 1.0984 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14678/2499940 | global iter:   7340/1249970 | loss: 1.1547 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14680/2499940 | global iter:   7341/1249970 | loss: 0.6222 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14682/2499940 | global iter:   7342/1249970 | loss: 0.6748 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14684/2499940 | global iter:   7343/1249970 | loss: 0.9931 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14686/2499940 | global iter:   7344/1249970 | loss: 0.3559 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14686/2499940 | global iter:   7344/1249970 | loss: 0.8647 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14688/2499940 | global iter:   7345/1249970 | loss: 1.5934 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14690/2499940 | global iter:   7346/1249970 | loss: 0.6631 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14692/2499940 | global iter:   7347/1249970 | loss: 0.8893 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14694/2499940 | global iter:   7348/1249970 | loss: 0.6248 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14694/2499940 | global iter:   7348/1249970 | loss: 1.0113 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14696/2499940 | global iter:   7349/1249970 | loss: 1.3871 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14698/2499940 | global iter:   7350/1249970 | loss: 1.5931 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  14700/2499940 | global iter:   7351/1249970 | loss: 1.8722 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14702/2499940 | global iter:   7352/1249970 | loss: 1.6444 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14702/2499940 | global iter:   7352/1249970 | loss: 1.3718 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.393 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14704/2499940 | global iter:   7353/1249970 | loss: 1.2146 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14706/2499940 | global iter:   7354/1249970 | loss: 0.8348 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  14708/2499940 | global iter:   7355/1249970 | loss: 0.7473 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14710/2499940 | global iter:   7356/1249970 | loss: 1.2719 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14710/2499940 | global iter:   7356/1249970 | loss: 1.1388 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14712/2499940 | global iter:   7357/1249970 | loss: 0.8364 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14714/2499940 | global iter:   7358/1249970 | loss: 0.9931 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  14716/2499940 | global iter:   7359/1249970 | loss: 0.7268 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.409 | step time: 0.000
train | epoch   0 | Iter:  14718/2499940 | global iter:   7360/1249970 | loss: 0.6910 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.409 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14718/2499940 | global iter:   7360/1249970 | loss: 1.0452 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.409 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14720/2499940 | global iter:   7361/1249970 | loss: 1.3541 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14722/2499940 | global iter:   7362/1249970 | loss: 1.2532 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14724/2499940 | global iter:   7363/1249970 | loss: 1.8173 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14726/2499940 | global iter:   7364/1249970 | loss: 0.6944 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14726/2499940 | global iter:   7364/1249970 | loss: 1.2204 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14728/2499940 | global iter:   7365/1249970 | loss: 0.7153 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14730/2499940 | global iter:   7366/1249970 | loss: 0.5454 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14732/2499940 | global iter:   7367/1249970 | loss: 1.1693 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  14734/2499940 | global iter:   7368/1249970 | loss: 1.9118 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14734/2499940 | global iter:   7368/1249970 | loss: 1.1892 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14736/2499940 | global iter:   7369/1249970 | loss: 0.6462 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  14738/2499940 | global iter:   7370/1249970 | loss: 1.2134 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14740/2499940 | global iter:   7371/1249970 | loss: 0.6596 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14742/2499940 | global iter:   7372/1249970 | loss: 1.5772 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14742/2499940 | global iter:   7372/1249970 | loss: 1.1282 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14744/2499940 | global iter:   7373/1249970 | loss: 1.2570 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  14746/2499940 | global iter:   7374/1249970 | loss: 0.5815 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14748/2499940 | global iter:   7375/1249970 | loss: 1.0820 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14750/2499940 | global iter:   7376/1249970 | loss: 1.6515 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14750/2499940 | global iter:   7376/1249970 | loss: 1.1799 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14752/2499940 | global iter:   7377/1249970 | loss: 0.9372 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  14754/2499940 | global iter:   7378/1249970 | loss: 1.2896 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:  14756/2499940 | global iter:   7379/1249970 | loss: 0.2889 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14758/2499940 | global iter:   7380/1249970 | loss: 0.9072 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14758/2499940 | global iter:   7380/1249970 | loss: 1.1809 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14760/2499940 | global iter:   7381/1249970 | loss: 1.2953 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14762/2499940 | global iter:   7382/1249970 | loss: 1.1240 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14764/2499940 | global iter:   7383/1249970 | loss: 0.6781 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14766/2499940 | global iter:   7384/1249970 | loss: 1.7085 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14766/2499940 | global iter:   7384/1249970 | loss: 1.2698 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14768/2499940 | global iter:   7385/1249970 | loss: 1.2433 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14770/2499940 | global iter:   7386/1249970 | loss: 0.5032 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  14772/2499940 | global iter:   7387/1249970 | loss: 0.8336 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14774/2499940 | global iter:   7388/1249970 | loss: 0.5595 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14774/2499940 | global iter:   7388/1249970 | loss: 0.9820 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14776/2499940 | global iter:   7389/1249970 | loss: 1.1717 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14778/2499940 | global iter:   7390/1249970 | loss: 0.9239 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:  14780/2499940 | global iter:   7391/1249970 | loss: 1.3768 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  14782/2499940 | global iter:   7392/1249970 | loss: 1.9117 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14782/2499940 | global iter:   7392/1249970 | loss: 1.1916 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14784/2499940 | global iter:   7393/1249970 | loss: 1.3192 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14786/2499940 | global iter:   7394/1249970 | loss: 0.0988 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14788/2499940 | global iter:   7395/1249970 | loss: 0.8755 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14790/2499940 | global iter:   7396/1249970 | loss: 0.8234 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14790/2499940 | global iter:   7396/1249970 | loss: 0.9049 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14792/2499940 | global iter:   7397/1249970 | loss: 0.9327 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14794/2499940 | global iter:   7398/1249970 | loss: 1.1237 | ds_loss: 0.0000 | lr: 9.9992e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14796/2499940 | global iter:   7399/1249970 | loss: 1.1431 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14798/2499940 | global iter:   7400/1249970 | loss: 1.0207 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14798/2499940 | global iter:   7400/1249970 | loss: 0.9326 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14800/2499940 | global iter:   7401/1249970 | loss: 1.2128 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14802/2499940 | global iter:   7402/1249970 | loss: 1.2644 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14804/2499940 | global iter:   7403/1249970 | loss: 0.5919 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14806/2499940 | global iter:   7404/1249970 | loss: 1.7819 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14806/2499940 | global iter:   7404/1249970 | loss: 1.2014 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14808/2499940 | global iter:   7405/1249970 | loss: 1.6896 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14810/2499940 | global iter:   7406/1249970 | loss: 1.4371 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  14812/2499940 | global iter:   7407/1249970 | loss: 1.2875 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14814/2499940 | global iter:   7408/1249970 | loss: 1.3369 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14814/2499940 | global iter:   7408/1249970 | loss: 1.3521 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14816/2499940 | global iter:   7409/1249970 | loss: 2.1023 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  14818/2499940 | global iter:   7410/1249970 | loss: 1.5337 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14820/2499940 | global iter:   7411/1249970 | loss: 0.6505 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14822/2499940 | global iter:   7412/1249970 | loss: 0.8839 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14822/2499940 | global iter:   7412/1249970 | loss: 1.0816 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14824/2499940 | global iter:   7413/1249970 | loss: 0.4465 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14826/2499940 | global iter:   7414/1249970 | loss: 0.8329 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14828/2499940 | global iter:   7415/1249970 | loss: 1.0308 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14830/2499940 | global iter:   7416/1249970 | loss: 1.3515 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14830/2499940 | global iter:   7416/1249970 | loss: 0.8067 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14832/2499940 | global iter:   7417/1249970 | loss: 1.2994 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14834/2499940 | global iter:   7418/1249970 | loss: 1.0059 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14836/2499940 | global iter:   7419/1249970 | loss: 0.5778 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14838/2499940 | global iter:   7420/1249970 | loss: 0.9175 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14838/2499940 | global iter:   7420/1249970 | loss: 1.1270 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14840/2499940 | global iter:   7421/1249970 | loss: 1.3333 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14842/2499940 | global iter:   7422/1249970 | loss: 1.0459 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14844/2499940 | global iter:   7423/1249970 | loss: 1.7019 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14846/2499940 | global iter:   7424/1249970 | loss: 1.5524 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14846/2499940 | global iter:   7424/1249970 | loss: 1.2323 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14848/2499940 | global iter:   7425/1249970 | loss: 1.3135 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14850/2499940 | global iter:   7426/1249970 | loss: 0.6898 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14852/2499940 | global iter:   7427/1249970 | loss: 1.1129 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14854/2499940 | global iter:   7428/1249970 | loss: 1.4415 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14854/2499940 | global iter:   7428/1249970 | loss: 1.3265 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14856/2499940 | global iter:   7429/1249970 | loss: 1.3808 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14858/2499940 | global iter:   7430/1249970 | loss: 1.3392 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14860/2499940 | global iter:   7431/1249970 | loss: 1.0387 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  14862/2499940 | global iter:   7432/1249970 | loss: 1.2207 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14862/2499940 | global iter:   7432/1249970 | loss: 1.1899 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14864/2499940 | global iter:   7433/1249970 | loss: 1.5594 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14866/2499940 | global iter:   7434/1249970 | loss: 0.6498 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  14868/2499940 | global iter:   7435/1249970 | loss: 0.7627 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14870/2499940 | global iter:   7436/1249970 | loss: 0.5451 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14870/2499940 | global iter:   7436/1249970 | loss: 0.9917 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14872/2499940 | global iter:   7437/1249970 | loss: 0.0757 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14874/2499940 | global iter:   7438/1249970 | loss: 1.4456 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  14876/2499940 | global iter:   7439/1249970 | loss: 0.9988 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14878/2499940 | global iter:   7440/1249970 | loss: 1.3118 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14878/2499940 | global iter:   7440/1249970 | loss: 0.9813 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14880/2499940 | global iter:   7441/1249970 | loss: 1.4610 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14882/2499940 | global iter:   7442/1249970 | loss: 1.2763 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14884/2499940 | global iter:   7443/1249970 | loss: 0.2184 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14886/2499940 | global iter:   7444/1249970 | loss: 0.2282 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14886/2499940 | global iter:   7444/1249970 | loss: 0.7015 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14888/2499940 | global iter:   7445/1249970 | loss: 1.3200 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14890/2499940 | global iter:   7446/1249970 | loss: 2.1688 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.413 | step time: 0.000
train | epoch   0 | Iter:  14892/2499940 | global iter:   7447/1249970 | loss: 1.0360 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14894/2499940 | global iter:   7448/1249970 | loss: 0.4800 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14894/2499940 | global iter:   7448/1249970 | loss: 1.1560 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14896/2499940 | global iter:   7449/1249970 | loss: 0.9185 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14898/2499940 | global iter:   7450/1249970 | loss: 1.1688 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14900/2499940 | global iter:   7451/1249970 | loss: 1.5237 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14902/2499940 | global iter:   7452/1249970 | loss: 0.9706 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14902/2499940 | global iter:   7452/1249970 | loss: 1.1250 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14904/2499940 | global iter:   7453/1249970 | loss: 1.6864 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14906/2499940 | global iter:   7454/1249970 | loss: 0.6522 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14908/2499940 | global iter:   7455/1249970 | loss: 1.6279 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14910/2499940 | global iter:   7456/1249970 | loss: 0.6572 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14910/2499940 | global iter:   7456/1249970 | loss: 0.9954 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14912/2499940 | global iter:   7457/1249970 | loss: 0.9547 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14914/2499940 | global iter:   7458/1249970 | loss: 1.1930 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  14916/2499940 | global iter:   7459/1249970 | loss: 0.9744 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  14918/2499940 | global iter:   7460/1249970 | loss: 0.4214 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14918/2499940 | global iter:   7460/1249970 | loss: 0.8780 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14920/2499940 | global iter:   7461/1249970 | loss: 1.4369 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14922/2499940 | global iter:   7462/1249970 | loss: 0.6808 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14924/2499940 | global iter:   7463/1249970 | loss: 0.8994 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14926/2499940 | global iter:   7464/1249970 | loss: 1.2412 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14926/2499940 | global iter:   7464/1249970 | loss: 0.8843 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14928/2499940 | global iter:   7465/1249970 | loss: 0.8944 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14930/2499940 | global iter:   7466/1249970 | loss: 1.7238 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  14932/2499940 | global iter:   7467/1249970 | loss: 1.4300 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14934/2499940 | global iter:   7468/1249970 | loss: 1.3665 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14934/2499940 | global iter:   7468/1249970 | loss: 1.2186 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14936/2499940 | global iter:   7469/1249970 | loss: 0.1492 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14938/2499940 | global iter:   7470/1249970 | loss: 0.5546 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:  14940/2499940 | global iter:   7471/1249970 | loss: 0.5438 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  14942/2499940 | global iter:   7472/1249970 | loss: 1.6343 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14942/2499940 | global iter:   7472/1249970 | loss: 0.8730 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14944/2499940 | global iter:   7473/1249970 | loss: 0.8199 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14946/2499940 | global iter:   7474/1249970 | loss: 1.4444 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  14948/2499940 | global iter:   7475/1249970 | loss: 0.1950 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14950/2499940 | global iter:   7476/1249970 | loss: 0.4216 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14950/2499940 | global iter:   7476/1249970 | loss: 0.7661 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14952/2499940 | global iter:   7477/1249970 | loss: 1.3195 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14954/2499940 | global iter:   7478/1249970 | loss: 0.5468 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.392 | step time: 0.000
train | epoch   0 | Iter:  14956/2499940 | global iter:   7479/1249970 | loss: 0.9442 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14958/2499940 | global iter:   7480/1249970 | loss: 1.5492 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14958/2499940 | global iter:   7480/1249970 | loss: 1.1204 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14960/2499940 | global iter:   7481/1249970 | loss: 1.3021 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14962/2499940 | global iter:   7482/1249970 | loss: 1.2094 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  14964/2499940 | global iter:   7483/1249970 | loss: 1.2606 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14966/2499940 | global iter:   7484/1249970 | loss: 1.6674 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14966/2499940 | global iter:   7484/1249970 | loss: 1.4042 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14968/2499940 | global iter:   7485/1249970 | loss: 1.0912 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  14970/2499940 | global iter:   7486/1249970 | loss: 0.5341 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  14972/2499940 | global iter:   7487/1249970 | loss: 0.5425 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14974/2499940 | global iter:   7488/1249970 | loss: 1.1160 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14974/2499940 | global iter:   7488/1249970 | loss: 0.9218 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14976/2499940 | global iter:   7489/1249970 | loss: 1.7489 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14978/2499940 | global iter:   7490/1249970 | loss: 1.3474 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  14980/2499940 | global iter:   7491/1249970 | loss: 1.1410 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14982/2499940 | global iter:   7492/1249970 | loss: 1.3168 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14982/2499940 | global iter:   7492/1249970 | loss: 1.1952 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14984/2499940 | global iter:   7493/1249970 | loss: 1.3773 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  14986/2499940 | global iter:   7494/1249970 | loss: 1.6008 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  14988/2499940 | global iter:   7495/1249970 | loss: 1.2861 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14990/2499940 | global iter:   7496/1249970 | loss: 0.7354 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14990/2499940 | global iter:   7496/1249970 | loss: 0.9886 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  14992/2499940 | global iter:   7497/1249970 | loss: 0.7598 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  14994/2499940 | global iter:   7498/1249970 | loss: 1.5336 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  14996/2499940 | global iter:   7499/1249970 | loss: 1.5388 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  14998/2499940 | global iter:   7500/1249970 | loss: 1.2461 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  14998/2499940 | global iter:   7500/1249970 | loss: 1.0352 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15000/2499940 | global iter:   7501/1249970 | loss: 0.9268 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15002/2499940 | global iter:   7502/1249970 | loss: 0.9226 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  15004/2499940 | global iter:   7503/1249970 | loss: 1.4883 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15006/2499940 | global iter:   7504/1249970 | loss: 0.8334 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15006/2499940 | global iter:   7504/1249970 | loss: 1.0993 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15008/2499940 | global iter:   7505/1249970 | loss: 1.6784 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15010/2499940 | global iter:   7506/1249970 | loss: 1.3121 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15012/2499940 | global iter:   7507/1249970 | loss: 1.2039 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15014/2499940 | global iter:   7508/1249970 | loss: 0.9032 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15014/2499940 | global iter:   7508/1249970 | loss: 1.4366 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15016/2499940 | global iter:   7509/1249970 | loss: 1.1863 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15018/2499940 | global iter:   7510/1249970 | loss: 0.9218 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15020/2499940 | global iter:   7511/1249970 | loss: 1.5208 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:  15022/2499940 | global iter:   7512/1249970 | loss: 1.7608 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.405 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15022/2499940 | global iter:   7512/1249970 | loss: 1.1240 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.405 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15024/2499940 | global iter:   7513/1249970 | loss: 1.8600 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.407 | step time: 0.000
train | epoch   0 | Iter:  15026/2499940 | global iter:   7514/1249970 | loss: 1.2465 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.404 | step time: 0.000
train | epoch   0 | Iter:  15028/2499940 | global iter:   7515/1249970 | loss: 0.7751 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.404 | step time: 0.000
train | epoch   0 | Iter:  15030/2499940 | global iter:   7516/1249970 | loss: 0.6535 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15030/2499940 | global iter:   7516/1249970 | loss: 1.0935 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.700
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15032/2499940 | global iter:   7517/1249970 | loss: 1.1991 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15034/2499940 | global iter:   7518/1249970 | loss: 1.0708 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15036/2499940 | global iter:   7519/1249970 | loss: 0.8923 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:  15038/2499940 | global iter:   7520/1249970 | loss: 2.1259 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15038/2499940 | global iter:   7520/1249970 | loss: 1.2605 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15040/2499940 | global iter:   7521/1249970 | loss: 0.7994 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15042/2499940 | global iter:   7522/1249970 | loss: 1.3231 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15044/2499940 | global iter:   7523/1249970 | loss: 0.4756 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15046/2499940 | global iter:   7524/1249970 | loss: 0.7921 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15046/2499940 | global iter:   7524/1249970 | loss: 0.9140 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15048/2499940 | global iter:   7525/1249970 | loss: 1.4036 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:  15050/2499940 | global iter:   7526/1249970 | loss: 1.0849 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15052/2499940 | global iter:   7527/1249970 | loss: 1.4279 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.404 | step time: 0.000
train | epoch   0 | Iter:  15054/2499940 | global iter:   7528/1249970 | loss: 1.3584 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.403 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15054/2499940 | global iter:   7528/1249970 | loss: 1.1782 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.403 | step time: 0.696
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15056/2499940 | global iter:   7529/1249970 | loss: 0.9677 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.404 | step time: 0.000
train | epoch   0 | Iter:  15058/2499940 | global iter:   7530/1249970 | loss: 0.7889 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15060/2499940 | global iter:   7531/1249970 | loss: 0.6490 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:  15062/2499940 | global iter:   7532/1249970 | loss: 1.3688 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15062/2499940 | global iter:   7532/1249970 | loss: 1.1372 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.696
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15064/2499940 | global iter:   7533/1249970 | loss: 1.6210 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:  15066/2499940 | global iter:   7534/1249970 | loss: 1.6486 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15068/2499940 | global iter:   7535/1249970 | loss: 1.8397 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15070/2499940 | global iter:   7536/1249970 | loss: 1.7450 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.405 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15070/2499940 | global iter:   7536/1249970 | loss: 1.4749 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.405 | step time: 0.697
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15072/2499940 | global iter:   7537/1249970 | loss: 1.0620 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.404 | step time: 0.000
train | epoch   0 | Iter:  15074/2499940 | global iter:   7538/1249970 | loss: 1.3455 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.405 | step time: 0.000
train | epoch   0 | Iter:  15076/2499940 | global iter:   7539/1249970 | loss: 1.3617 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15078/2499940 | global iter:   7540/1249970 | loss: 0.8808 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15078/2499940 | global iter:   7540/1249970 | loss: 1.1679 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.696
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15080/2499940 | global iter:   7541/1249970 | loss: 1.8568 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15082/2499940 | global iter:   7542/1249970 | loss: 1.3825 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  15084/2499940 | global iter:   7543/1249970 | loss: 0.3691 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15086/2499940 | global iter:   7544/1249970 | loss: 1.4184 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15086/2499940 | global iter:   7544/1249970 | loss: 1.2855 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15088/2499940 | global iter:   7545/1249970 | loss: 1.5684 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15090/2499940 | global iter:   7546/1249970 | loss: 1.4455 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.405 | step time: 0.000
train | epoch   0 | Iter:  15092/2499940 | global iter:   7547/1249970 | loss: 1.6651 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:  15094/2499940 | global iter:   7548/1249970 | loss: 1.1013 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15094/2499940 | global iter:   7548/1249970 | loss: 1.0606 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15096/2499940 | global iter:   7549/1249970 | loss: 1.3852 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.404 | step time: 0.000
train | epoch   0 | Iter:  15098/2499940 | global iter:   7550/1249970 | loss: 1.2248 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15100/2499940 | global iter:   7551/1249970 | loss: 1.0245 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15102/2499940 | global iter:   7552/1249970 | loss: 0.3491 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15102/2499940 | global iter:   7552/1249970 | loss: 1.1182 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.696
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15104/2499940 | global iter:   7553/1249970 | loss: 1.7180 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:  15106/2499940 | global iter:   7554/1249970 | loss: 1.4042 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15108/2499940 | global iter:   7555/1249970 | loss: 1.2342 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.405 | step time: 0.000
train | epoch   0 | Iter:  15110/2499940 | global iter:   7556/1249970 | loss: 1.0723 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15110/2499940 | global iter:   7556/1249970 | loss: 1.1489 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.697
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15112/2499940 | global iter:   7557/1249970 | loss: 1.2105 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.404 | step time: 0.000
train | epoch   0 | Iter:  15114/2499940 | global iter:   7558/1249970 | loss: 1.7036 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.405 | step time: 0.000
train | epoch   0 | Iter:  15116/2499940 | global iter:   7559/1249970 | loss: 1.2786 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.407 | step time: 0.000
train | epoch   0 | Iter:  15118/2499940 | global iter:   7560/1249970 | loss: 0.8969 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15118/2499940 | global iter:   7560/1249970 | loss: 1.1855 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.700
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15120/2499940 | global iter:   7561/1249970 | loss: 0.5246 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15122/2499940 | global iter:   7562/1249970 | loss: 0.6149 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15124/2499940 | global iter:   7563/1249970 | loss: 1.1691 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15126/2499940 | global iter:   7564/1249970 | loss: 1.3461 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15126/2499940 | global iter:   7564/1249970 | loss: 1.0204 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15128/2499940 | global iter:   7565/1249970 | loss: 2.0270 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15130/2499940 | global iter:   7566/1249970 | loss: 0.7662 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15132/2499940 | global iter:   7567/1249970 | loss: 1.7824 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:  15134/2499940 | global iter:   7568/1249970 | loss: 1.0203 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15134/2499940 | global iter:   7568/1249970 | loss: 1.2628 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15136/2499940 | global iter:   7569/1249970 | loss: 1.2975 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15138/2499940 | global iter:   7570/1249970 | loss: 0.7987 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15140/2499940 | global iter:   7571/1249970 | loss: 1.4717 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15142/2499940 | global iter:   7572/1249970 | loss: 0.6480 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15142/2499940 | global iter:   7572/1249970 | loss: 1.2115 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15144/2499940 | global iter:   7573/1249970 | loss: 1.4987 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15146/2499940 | global iter:   7574/1249970 | loss: 1.9381 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15148/2499940 | global iter:   7575/1249970 | loss: 0.7838 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:  15150/2499940 | global iter:   7576/1249970 | loss: 1.5724 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15150/2499940 | global iter:   7576/1249970 | loss: 1.3604 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.697
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15152/2499940 | global iter:   7577/1249970 | loss: 1.6687 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15154/2499940 | global iter:   7578/1249970 | loss: 1.4690 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  15156/2499940 | global iter:   7579/1249970 | loss: 1.2446 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15158/2499940 | global iter:   7580/1249970 | loss: 0.8630 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15158/2499940 | global iter:   7580/1249970 | loss: 1.3618 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15160/2499940 | global iter:   7581/1249970 | loss: 0.7495 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15162/2499940 | global iter:   7582/1249970 | loss: 0.8481 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15164/2499940 | global iter:   7583/1249970 | loss: 1.1197 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.404 | step time: 0.000
train | epoch   0 | Iter:  15166/2499940 | global iter:   7584/1249970 | loss: 0.9277 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15166/2499940 | global iter:   7584/1249970 | loss: 1.0784 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15168/2499940 | global iter:   7585/1249970 | loss: 1.4861 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.405 | step time: 0.000
train | epoch   0 | Iter:  15170/2499940 | global iter:   7586/1249970 | loss: 1.4189 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.408 | step time: 0.000
train | epoch   0 | Iter:  15172/2499940 | global iter:   7587/1249970 | loss: 0.7304 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.406 | step time: 0.000
train | epoch   0 | Iter:  15174/2499940 | global iter:   7588/1249970 | loss: 0.8572 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15174/2499940 | global iter:   7588/1249970 | loss: 1.2213 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.699
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15176/2499940 | global iter:   7589/1249970 | loss: 1.6331 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15178/2499940 | global iter:   7590/1249970 | loss: 0.5995 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15180/2499940 | global iter:   7591/1249970 | loss: 1.5553 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15182/2499940 | global iter:   7592/1249970 | loss: 0.8520 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15182/2499940 | global iter:   7592/1249970 | loss: 1.1801 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15184/2499940 | global iter:   7593/1249970 | loss: 2.0202 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15186/2499940 | global iter:   7594/1249970 | loss: 0.9068 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15188/2499940 | global iter:   7595/1249970 | loss: 1.2003 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.404 | step time: 0.000
train | epoch   0 | Iter:  15190/2499940 | global iter:   7596/1249970 | loss: 0.9903 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15190/2499940 | global iter:   7596/1249970 | loss: 1.2164 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15192/2499940 | global iter:   7597/1249970 | loss: 1.8660 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.405 | step time: 0.000
train | epoch   0 | Iter:  15194/2499940 | global iter:   7598/1249970 | loss: 1.9122 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15196/2499940 | global iter:   7599/1249970 | loss: 1.1475 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.405 | step time: 0.000
train | epoch   0 | Iter:  15198/2499940 | global iter:   7600/1249970 | loss: 1.4748 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.403 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15198/2499940 | global iter:   7600/1249970 | loss: 1.4342 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.403 | step time: 0.697
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15200/2499940 | global iter:   7601/1249970 | loss: 1.2622 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.406 | step time: 0.000
train | epoch   0 | Iter:  15202/2499940 | global iter:   7602/1249970 | loss: 1.2802 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.404 | step time: 0.000
train | epoch   0 | Iter:  15204/2499940 | global iter:   7603/1249970 | loss: 1.3168 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.405 | step time: 0.000
train | epoch   0 | Iter:  15206/2499940 | global iter:   7604/1249970 | loss: 1.0224 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15206/2499940 | global iter:   7604/1249970 | loss: 1.1593 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.699
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15208/2499940 | global iter:   7605/1249970 | loss: 1.0743 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15210/2499940 | global iter:   7606/1249970 | loss: 0.7888 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.404 | step time: 0.000
train | epoch   0 | Iter:  15212/2499940 | global iter:   7607/1249970 | loss: 1.2496 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.408 | step time: 0.000
train | epoch   0 | Iter:  15214/2499940 | global iter:   7608/1249970 | loss: 0.4951 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.406 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15214/2499940 | global iter:   7608/1249970 | loss: 1.0840 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.406 | step time: 0.699
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15216/2499940 | global iter:   7609/1249970 | loss: 0.9897 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.405 | step time: 0.000
train | epoch   0 | Iter:  15218/2499940 | global iter:   7610/1249970 | loss: 1.3621 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  15220/2499940 | global iter:   7611/1249970 | loss: 1.3145 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.404 | step time: 0.000
train | epoch   0 | Iter:  15222/2499940 | global iter:   7612/1249970 | loss: 1.2224 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15222/2499940 | global iter:   7612/1249970 | loss: 0.9730 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15224/2499940 | global iter:   7613/1249970 | loss: 1.5022 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15226/2499940 | global iter:   7614/1249970 | loss: 0.8086 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15228/2499940 | global iter:   7615/1249970 | loss: 0.8945 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  15230/2499940 | global iter:   7616/1249970 | loss: 1.2812 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15230/2499940 | global iter:   7616/1249970 | loss: 1.1328 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15232/2499940 | global iter:   7617/1249970 | loss: 0.3692 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15234/2499940 | global iter:   7618/1249970 | loss: 1.3137 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15236/2499940 | global iter:   7619/1249970 | loss: 1.2759 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15238/2499940 | global iter:   7620/1249970 | loss: 0.4960 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15238/2499940 | global iter:   7620/1249970 | loss: 1.0424 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15240/2499940 | global iter:   7621/1249970 | loss: 1.0114 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15242/2499940 | global iter:   7622/1249970 | loss: 0.9619 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  15244/2499940 | global iter:   7623/1249970 | loss: 1.4394 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15246/2499940 | global iter:   7624/1249970 | loss: 0.9957 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15246/2499940 | global iter:   7624/1249970 | loss: 1.1303 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15248/2499940 | global iter:   7625/1249970 | loss: 0.6511 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15250/2499940 | global iter:   7626/1249970 | loss: 0.4843 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15252/2499940 | global iter:   7627/1249970 | loss: 0.7802 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15254/2499940 | global iter:   7628/1249970 | loss: 1.4180 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.403 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15254/2499940 | global iter:   7628/1249970 | loss: 0.9435 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.403 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15256/2499940 | global iter:   7629/1249970 | loss: 0.4819 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.405 | step time: 0.000
train | epoch   0 | Iter:  15258/2499940 | global iter:   7630/1249970 | loss: 1.2208 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.404 | step time: 0.000
train | epoch   0 | Iter:  15260/2499940 | global iter:   7631/1249970 | loss: 0.4377 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:  15262/2499940 | global iter:   7632/1249970 | loss: 0.9824 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15262/2499940 | global iter:   7632/1249970 | loss: 0.8727 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.696
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15264/2499940 | global iter:   7633/1249970 | loss: 1.0024 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15266/2499940 | global iter:   7634/1249970 | loss: 0.4471 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  15268/2499940 | global iter:   7635/1249970 | loss: 0.4265 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15270/2499940 | global iter:   7636/1249970 | loss: 0.4167 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15270/2499940 | global iter:   7636/1249970 | loss: 0.9860 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15272/2499940 | global iter:   7637/1249970 | loss: 0.6505 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15274/2499940 | global iter:   7638/1249970 | loss: 1.2516 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15276/2499940 | global iter:   7639/1249970 | loss: 1.1212 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15278/2499940 | global iter:   7640/1249970 | loss: 1.5488 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15278/2499940 | global iter:   7640/1249970 | loss: 1.2879 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15280/2499940 | global iter:   7641/1249970 | loss: 1.6972 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15282/2499940 | global iter:   7642/1249970 | loss: 0.9873 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  15284/2499940 | global iter:   7643/1249970 | loss: 1.5628 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15286/2499940 | global iter:   7644/1249970 | loss: 1.4031 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15286/2499940 | global iter:   7644/1249970 | loss: 1.3081 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15288/2499940 | global iter:   7645/1249970 | loss: 1.2188 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15290/2499940 | global iter:   7646/1249970 | loss: 1.7389 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15292/2499940 | global iter:   7647/1249970 | loss: 1.5547 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.404 | step time: 0.000
train | epoch   0 | Iter:  15294/2499940 | global iter:   7648/1249970 | loss: 0.4838 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.403 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15294/2499940 | global iter:   7648/1249970 | loss: 1.0618 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.403 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15296/2499940 | global iter:   7649/1249970 | loss: 0.5549 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.407 | step time: 0.000
train | epoch   0 | Iter:  15298/2499940 | global iter:   7650/1249970 | loss: 1.6469 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15300/2499940 | global iter:   7651/1249970 | loss: 0.3002 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:  15302/2499940 | global iter:   7652/1249970 | loss: 0.8043 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15302/2499940 | global iter:   7652/1249970 | loss: 1.0587 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.696
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15304/2499940 | global iter:   7653/1249970 | loss: 0.6341 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15306/2499940 | global iter:   7654/1249970 | loss: 1.3564 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  15308/2499940 | global iter:   7655/1249970 | loss: 1.3880 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15310/2499940 | global iter:   7656/1249970 | loss: 1.0074 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15310/2499940 | global iter:   7656/1249970 | loss: 1.1112 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15312/2499940 | global iter:   7657/1249970 | loss: 1.0622 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15314/2499940 | global iter:   7658/1249970 | loss: 1.0412 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15316/2499940 | global iter:   7659/1249970 | loss: 1.4687 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15318/2499940 | global iter:   7660/1249970 | loss: 0.5490 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15318/2499940 | global iter:   7660/1249970 | loss: 1.1437 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15320/2499940 | global iter:   7661/1249970 | loss: 1.5612 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15322/2499940 | global iter:   7662/1249970 | loss: 0.9330 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.407 | step time: 0.000
train | epoch   0 | Iter:  15324/2499940 | global iter:   7663/1249970 | loss: 1.6999 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15326/2499940 | global iter:   7664/1249970 | loss: 1.5717 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15326/2499940 | global iter:   7664/1249970 | loss: 1.2464 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.697
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15328/2499940 | global iter:   7665/1249970 | loss: 1.3754 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15330/2499940 | global iter:   7666/1249970 | loss: 0.5692 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15332/2499940 | global iter:   7667/1249970 | loss: 0.8883 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15334/2499940 | global iter:   7668/1249970 | loss: 1.3822 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15334/2499940 | global iter:   7668/1249970 | loss: 0.9022 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15336/2499940 | global iter:   7669/1249970 | loss: 1.1476 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.407 | step time: 0.000
train | epoch   0 | Iter:  15338/2499940 | global iter:   7670/1249970 | loss: 0.6062 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.405 | step time: 0.000
train | epoch   0 | Iter:  15340/2499940 | global iter:   7671/1249970 | loss: 0.6619 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.406 | step time: 0.000
train | epoch   0 | Iter:  15342/2499940 | global iter:   7672/1249970 | loss: 1.2311 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15342/2499940 | global iter:   7672/1249970 | loss: 0.9218 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.699
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15344/2499940 | global iter:   7673/1249970 | loss: 0.8198 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15346/2499940 | global iter:   7674/1249970 | loss: 1.2841 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15348/2499940 | global iter:   7675/1249970 | loss: 0.8163 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15350/2499940 | global iter:   7676/1249970 | loss: 0.5773 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15350/2499940 | global iter:   7676/1249970 | loss: 1.0371 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15352/2499940 | global iter:   7677/1249970 | loss: 1.0946 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15354/2499940 | global iter:   7678/1249970 | loss: 1.1912 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15356/2499940 | global iter:   7679/1249970 | loss: 0.8105 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15358/2499940 | global iter:   7680/1249970 | loss: 1.4638 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15358/2499940 | global iter:   7680/1249970 | loss: 1.1223 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15360/2499940 | global iter:   7681/1249970 | loss: 1.4370 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15362/2499940 | global iter:   7682/1249970 | loss: 1.1030 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15364/2499940 | global iter:   7683/1249970 | loss: 0.1325 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15366/2499940 | global iter:   7684/1249970 | loss: 1.0402 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15366/2499940 | global iter:   7684/1249970 | loss: 0.9352 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15368/2499940 | global iter:   7685/1249970 | loss: 0.5798 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15370/2499940 | global iter:   7686/1249970 | loss: 1.3320 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15372/2499940 | global iter:   7687/1249970 | loss: 0.4593 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15374/2499940 | global iter:   7688/1249970 | loss: 0.7624 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15374/2499940 | global iter:   7688/1249970 | loss: 0.8664 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15376/2499940 | global iter:   7689/1249970 | loss: 0.6097 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15378/2499940 | global iter:   7690/1249970 | loss: 1.7739 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15380/2499940 | global iter:   7691/1249970 | loss: 1.7085 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:  15382/2499940 | global iter:   7692/1249970 | loss: 0.7849 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15382/2499940 | global iter:   7692/1249970 | loss: 1.2369 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.695
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15384/2499940 | global iter:   7693/1249970 | loss: 1.1190 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15386/2499940 | global iter:   7694/1249970 | loss: 1.1237 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15388/2499940 | global iter:   7695/1249970 | loss: 1.5895 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15390/2499940 | global iter:   7696/1249970 | loss: 1.0879 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15390/2499940 | global iter:   7696/1249970 | loss: 1.2226 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15392/2499940 | global iter:   7697/1249970 | loss: 0.6335 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.404 | step time: 0.000
train | epoch   0 | Iter:  15394/2499940 | global iter:   7698/1249970 | loss: 1.2198 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15396/2499940 | global iter:   7699/1249970 | loss: 0.7999 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15398/2499940 | global iter:   7700/1249970 | loss: 1.3725 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15398/2499940 | global iter:   7700/1249970 | loss: 1.1391 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15400/2499940 | global iter:   7701/1249970 | loss: 1.2001 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  15402/2499940 | global iter:   7702/1249970 | loss: 1.0442 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15404/2499940 | global iter:   7703/1249970 | loss: 1.4324 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15406/2499940 | global iter:   7704/1249970 | loss: 0.9922 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15406/2499940 | global iter:   7704/1249970 | loss: 1.0822 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15408/2499940 | global iter:   7705/1249970 | loss: 1.6061 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.413 | step time: 0.000
train | epoch   0 | Iter:  15410/2499940 | global iter:   7706/1249970 | loss: 1.8801 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15412/2499940 | global iter:   7707/1249970 | loss: 1.3589 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15414/2499940 | global iter:   7708/1249970 | loss: 0.3675 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15414/2499940 | global iter:   7708/1249970 | loss: 1.0236 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15416/2499940 | global iter:   7709/1249970 | loss: 1.3398 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15418/2499940 | global iter:   7710/1249970 | loss: 0.9677 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15420/2499940 | global iter:   7711/1249970 | loss: 0.4975 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15422/2499940 | global iter:   7712/1249970 | loss: 0.9972 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15422/2499940 | global iter:   7712/1249970 | loss: 0.9758 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15424/2499940 | global iter:   7713/1249970 | loss: 1.7287 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15426/2499940 | global iter:   7714/1249970 | loss: 1.1653 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15428/2499940 | global iter:   7715/1249970 | loss: 0.4158 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15430/2499940 | global iter:   7716/1249970 | loss: 1.3281 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15430/2499940 | global iter:   7716/1249970 | loss: 1.1468 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15432/2499940 | global iter:   7717/1249970 | loss: 1.3691 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15434/2499940 | global iter:   7718/1249970 | loss: 0.7271 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  15436/2499940 | global iter:   7719/1249970 | loss: 1.1624 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15438/2499940 | global iter:   7720/1249970 | loss: 1.3886 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15438/2499940 | global iter:   7720/1249970 | loss: 1.0604 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15440/2499940 | global iter:   7721/1249970 | loss: 1.5367 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15442/2499940 | global iter:   7722/1249970 | loss: 0.3231 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  15444/2499940 | global iter:   7723/1249970 | loss: 0.8927 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15446/2499940 | global iter:   7724/1249970 | loss: 1.4689 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15446/2499940 | global iter:   7724/1249970 | loss: 1.1247 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15448/2499940 | global iter:   7725/1249970 | loss: 0.7822 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15450/2499940 | global iter:   7726/1249970 | loss: 1.2853 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15452/2499940 | global iter:   7727/1249970 | loss: 0.8814 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15454/2499940 | global iter:   7728/1249970 | loss: 1.0153 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15454/2499940 | global iter:   7728/1249970 | loss: 1.1672 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15456/2499940 | global iter:   7729/1249970 | loss: 1.8954 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15458/2499940 | global iter:   7730/1249970 | loss: 1.8785 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15460/2499940 | global iter:   7731/1249970 | loss: 1.1030 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15462/2499940 | global iter:   7732/1249970 | loss: 0.9290 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15462/2499940 | global iter:   7732/1249970 | loss: 1.3802 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15464/2499940 | global iter:   7733/1249970 | loss: 0.7566 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15466/2499940 | global iter:   7734/1249970 | loss: 1.4737 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15468/2499940 | global iter:   7735/1249970 | loss: 1.2923 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  15470/2499940 | global iter:   7736/1249970 | loss: 1.5681 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15470/2499940 | global iter:   7736/1249970 | loss: 1.2238 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15472/2499940 | global iter:   7737/1249970 | loss: 0.3793 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15474/2499940 | global iter:   7738/1249970 | loss: 1.0374 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15476/2499940 | global iter:   7739/1249970 | loss: 1.2801 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15478/2499940 | global iter:   7740/1249970 | loss: 1.4589 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15478/2499940 | global iter:   7740/1249970 | loss: 0.9679 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15480/2499940 | global iter:   7741/1249970 | loss: 1.3942 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15482/2499940 | global iter:   7742/1249970 | loss: 1.3647 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  15484/2499940 | global iter:   7743/1249970 | loss: 1.1814 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15486/2499940 | global iter:   7744/1249970 | loss: 1.0339 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15486/2499940 | global iter:   7744/1249970 | loss: 1.1065 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15488/2499940 | global iter:   7745/1249970 | loss: 1.0190 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15490/2499940 | global iter:   7746/1249970 | loss: 1.2624 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15492/2499940 | global iter:   7747/1249970 | loss: 1.0409 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15494/2499940 | global iter:   7748/1249970 | loss: 1.3421 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15494/2499940 | global iter:   7748/1249970 | loss: 1.1019 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15496/2499940 | global iter:   7749/1249970 | loss: 0.9838 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15498/2499940 | global iter:   7750/1249970 | loss: 1.3099 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15500/2499940 | global iter:   7751/1249970 | loss: 1.3488 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15502/2499940 | global iter:   7752/1249970 | loss: 1.3720 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15502/2499940 | global iter:   7752/1249970 | loss: 1.0318 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.398 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15504/2499940 | global iter:   7753/1249970 | loss: 1.5638 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15506/2499940 | global iter:   7754/1249970 | loss: 0.8332 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  15508/2499940 | global iter:   7755/1249970 | loss: 0.0267 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15510/2499940 | global iter:   7756/1249970 | loss: 1.0563 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15510/2499940 | global iter:   7756/1249970 | loss: 0.9615 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.395 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15512/2499940 | global iter:   7757/1249970 | loss: 1.0904 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15514/2499940 | global iter:   7758/1249970 | loss: 0.6133 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  15516/2499940 | global iter:   7759/1249970 | loss: 1.5083 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15518/2499940 | global iter:   7760/1249970 | loss: 1.8370 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15518/2499940 | global iter:   7760/1249970 | loss: 1.3078 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15520/2499940 | global iter:   7761/1249970 | loss: 1.1327 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15522/2499940 | global iter:   7762/1249970 | loss: 0.8010 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15524/2499940 | global iter:   7763/1249970 | loss: 0.0551 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15526/2499940 | global iter:   7764/1249970 | loss: 1.6797 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15526/2499940 | global iter:   7764/1249970 | loss: 1.0284 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15528/2499940 | global iter:   7765/1249970 | loss: 1.4977 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15530/2499940 | global iter:   7766/1249970 | loss: 1.3923 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  15532/2499940 | global iter:   7767/1249970 | loss: 1.0641 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  15534/2499940 | global iter:   7768/1249970 | loss: 1.5601 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15534/2499940 | global iter:   7768/1249970 | loss: 1.2053 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.395 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15536/2499940 | global iter:   7769/1249970 | loss: 1.2891 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15538/2499940 | global iter:   7770/1249970 | loss: 1.0032 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  15540/2499940 | global iter:   7771/1249970 | loss: 1.4706 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15542/2499940 | global iter:   7772/1249970 | loss: 0.8836 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15542/2499940 | global iter:   7772/1249970 | loss: 1.0787 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15544/2499940 | global iter:   7773/1249970 | loss: 0.9061 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15546/2499940 | global iter:   7774/1249970 | loss: 1.6385 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15548/2499940 | global iter:   7775/1249970 | loss: 1.1183 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15550/2499940 | global iter:   7776/1249970 | loss: 1.1994 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15550/2499940 | global iter:   7776/1249970 | loss: 1.2177 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15552/2499940 | global iter:   7777/1249970 | loss: 1.1868 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15554/2499940 | global iter:   7778/1249970 | loss: 1.1101 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15556/2499940 | global iter:   7779/1249970 | loss: 1.4957 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15558/2499940 | global iter:   7780/1249970 | loss: 0.7011 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15558/2499940 | global iter:   7780/1249970 | loss: 1.0936 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale: 16384.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
[2025-04-20 17:43:12,926] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16384, reducing to 8192
train | epoch   0 | Iter:  15560/2499940 | global iter:   7781/1249970 | loss: 1.0927 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.312 | step time: 0.000
train | epoch   0 | Iter:  15562/2499940 | global iter:   7782/1249970 | loss: 1.6750 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15564/2499940 | global iter:   7783/1249970 | loss: 1.1279 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15566/2499940 | global iter:   7784/1249970 | loss: 0.1574 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15566/2499940 | global iter:   7784/1249970 | loss: 0.9960 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.667
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15568/2499940 | global iter:   7785/1249970 | loss: 1.3585 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15570/2499940 | global iter:   7786/1249970 | loss: 0.7178 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  15572/2499940 | global iter:   7787/1249970 | loss: 0.7229 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15574/2499940 | global iter:   7788/1249970 | loss: 1.5201 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15574/2499940 | global iter:   7788/1249970 | loss: 1.1303 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15576/2499940 | global iter:   7789/1249970 | loss: 1.4758 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15578/2499940 | global iter:   7790/1249970 | loss: 0.1479 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:  15580/2499940 | global iter:   7791/1249970 | loss: 1.1097 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15582/2499940 | global iter:   7792/1249970 | loss: 0.7501 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.408 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15582/2499940 | global iter:   7792/1249970 | loss: 1.1326 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.408 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15584/2499940 | global iter:   7793/1249970 | loss: 1.4223 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15586/2499940 | global iter:   7794/1249970 | loss: 1.8132 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  15588/2499940 | global iter:   7795/1249970 | loss: 0.9165 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15590/2499940 | global iter:   7796/1249970 | loss: 0.6822 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15590/2499940 | global iter:   7796/1249970 | loss: 1.3579 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15592/2499940 | global iter:   7797/1249970 | loss: 1.5417 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15594/2499940 | global iter:   7798/1249970 | loss: 0.9510 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  15596/2499940 | global iter:   7799/1249970 | loss: 1.1835 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15598/2499940 | global iter:   7800/1249970 | loss: 1.2184 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15598/2499940 | global iter:   7800/1249970 | loss: 1.1333 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15600/2499940 | global iter:   7801/1249970 | loss: 0.7288 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15602/2499940 | global iter:   7802/1249970 | loss: 1.3118 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  15604/2499940 | global iter:   7803/1249970 | loss: 1.1973 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15606/2499940 | global iter:   7804/1249970 | loss: 0.7654 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15606/2499940 | global iter:   7804/1249970 | loss: 1.1677 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15608/2499940 | global iter:   7805/1249970 | loss: 1.1203 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15610/2499940 | global iter:   7806/1249970 | loss: 0.8405 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15612/2499940 | global iter:   7807/1249970 | loss: 0.5483 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15614/2499940 | global iter:   7808/1249970 | loss: 0.9512 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15614/2499940 | global iter:   7808/1249970 | loss: 1.0975 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15616/2499940 | global iter:   7809/1249970 | loss: 1.0611 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15618/2499940 | global iter:   7810/1249970 | loss: 1.5076 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  15620/2499940 | global iter:   7811/1249970 | loss: 1.3971 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15622/2499940 | global iter:   7812/1249970 | loss: 1.4117 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15622/2499940 | global iter:   7812/1249970 | loss: 1.0949 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15624/2499940 | global iter:   7813/1249970 | loss: 1.2587 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15626/2499940 | global iter:   7814/1249970 | loss: 0.5136 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15628/2499940 | global iter:   7815/1249970 | loss: 0.2470 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15630/2499940 | global iter:   7816/1249970 | loss: 1.6583 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15630/2499940 | global iter:   7816/1249970 | loss: 1.0449 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15632/2499940 | global iter:   7817/1249970 | loss: 1.1833 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15634/2499940 | global iter:   7818/1249970 | loss: 0.6942 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  15636/2499940 | global iter:   7819/1249970 | loss: 1.4713 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15638/2499940 | global iter:   7820/1249970 | loss: 1.1383 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15638/2499940 | global iter:   7820/1249970 | loss: 1.0068 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15640/2499940 | global iter:   7821/1249970 | loss: 1.3266 | ds_loss: 0.0000 | lr: 9.9991e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15642/2499940 | global iter:   7822/1249970 | loss: 1.6649 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  15644/2499940 | global iter:   7823/1249970 | loss: 1.0902 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15646/2499940 | global iter:   7824/1249970 | loss: 1.2052 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15646/2499940 | global iter:   7824/1249970 | loss: 1.1150 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.393 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15648/2499940 | global iter:   7825/1249970 | loss: 0.9780 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  15650/2499940 | global iter:   7826/1249970 | loss: 1.6329 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15652/2499940 | global iter:   7827/1249970 | loss: 1.4967 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15654/2499940 | global iter:   7828/1249970 | loss: 1.1377 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15654/2499940 | global iter:   7828/1249970 | loss: 1.1708 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15656/2499940 | global iter:   7829/1249970 | loss: 1.0350 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15658/2499940 | global iter:   7830/1249970 | loss: 1.0764 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  15660/2499940 | global iter:   7831/1249970 | loss: 0.5657 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15662/2499940 | global iter:   7832/1249970 | loss: 0.8364 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15662/2499940 | global iter:   7832/1249970 | loss: 0.8673 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.393 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15664/2499940 | global iter:   7833/1249970 | loss: 0.4557 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15666/2499940 | global iter:   7834/1249970 | loss: 0.5108 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15668/2499940 | global iter:   7835/1249970 | loss: 0.8774 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15670/2499940 | global iter:   7836/1249970 | loss: 1.1026 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.409 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15670/2499940 | global iter:   7836/1249970 | loss: 0.8700 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.409 | step time: 0.694
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15672/2499940 | global iter:   7837/1249970 | loss: 0.7302 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15674/2499940 | global iter:   7838/1249970 | loss: 1.2392 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15676/2499940 | global iter:   7839/1249970 | loss: 1.4153 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15678/2499940 | global iter:   7840/1249970 | loss: 0.1005 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15678/2499940 | global iter:   7840/1249970 | loss: 1.1272 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15680/2499940 | global iter:   7841/1249970 | loss: 1.8308 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15682/2499940 | global iter:   7842/1249970 | loss: 1.1012 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15684/2499940 | global iter:   7843/1249970 | loss: 1.4858 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15686/2499940 | global iter:   7844/1249970 | loss: 0.9698 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15686/2499940 | global iter:   7844/1249970 | loss: 1.3476 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15688/2499940 | global iter:   7845/1249970 | loss: 1.3127 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15690/2499940 | global iter:   7846/1249970 | loss: 0.4880 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  15692/2499940 | global iter:   7847/1249970 | loss: 1.5684 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15694/2499940 | global iter:   7848/1249970 | loss: 1.1232 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15694/2499940 | global iter:   7848/1249970 | loss: 1.2429 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15696/2499940 | global iter:   7849/1249970 | loss: 0.6831 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15698/2499940 | global iter:   7850/1249970 | loss: 0.8691 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15700/2499940 | global iter:   7851/1249970 | loss: 0.1962 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15702/2499940 | global iter:   7852/1249970 | loss: 1.7695 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15702/2499940 | global iter:   7852/1249970 | loss: 0.8695 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15704/2499940 | global iter:   7853/1249970 | loss: 0.7167 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15706/2499940 | global iter:   7854/1249970 | loss: 1.2552 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  15708/2499940 | global iter:   7855/1249970 | loss: 1.5301 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15710/2499940 | global iter:   7856/1249970 | loss: 0.9359 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15710/2499940 | global iter:   7856/1249970 | loss: 1.0318 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15712/2499940 | global iter:   7857/1249970 | loss: 1.2307 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15714/2499940 | global iter:   7858/1249970 | loss: 0.1511 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  15716/2499940 | global iter:   7859/1249970 | loss: 1.1433 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15718/2499940 | global iter:   7860/1249970 | loss: 0.6472 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15718/2499940 | global iter:   7860/1249970 | loss: 1.0296 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15720/2499940 | global iter:   7861/1249970 | loss: 0.9815 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15722/2499940 | global iter:   7862/1249970 | loss: 1.0077 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15724/2499940 | global iter:   7863/1249970 | loss: 1.7346 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15726/2499940 | global iter:   7864/1249970 | loss: 0.9645 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15726/2499940 | global iter:   7864/1249970 | loss: 1.0613 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15728/2499940 | global iter:   7865/1249970 | loss: 0.5527 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15730/2499940 | global iter:   7866/1249970 | loss: 0.8393 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  15732/2499940 | global iter:   7867/1249970 | loss: 0.6708 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15734/2499940 | global iter:   7868/1249970 | loss: 1.3935 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15734/2499940 | global iter:   7868/1249970 | loss: 0.9672 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15736/2499940 | global iter:   7869/1249970 | loss: 1.9439 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15738/2499940 | global iter:   7870/1249970 | loss: 0.8448 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15740/2499940 | global iter:   7871/1249970 | loss: 1.1328 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15742/2499940 | global iter:   7872/1249970 | loss: 0.0326 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15742/2499940 | global iter:   7872/1249970 | loss: 0.9110 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15744/2499940 | global iter:   7873/1249970 | loss: 1.3597 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15746/2499940 | global iter:   7874/1249970 | loss: 0.9075 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  15748/2499940 | global iter:   7875/1249970 | loss: 1.0013 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15750/2499940 | global iter:   7876/1249970 | loss: 1.0123 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15750/2499940 | global iter:   7876/1249970 | loss: 1.1770 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15752/2499940 | global iter:   7877/1249970 | loss: 0.6025 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15754/2499940 | global iter:   7878/1249970 | loss: 1.4419 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  15756/2499940 | global iter:   7879/1249970 | loss: 1.1698 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.408 | step time: 0.000
train | epoch   0 | Iter:  15758/2499940 | global iter:   7880/1249970 | loss: 1.0558 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15758/2499940 | global iter:   7880/1249970 | loss: 1.3267 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15760/2499940 | global iter:   7881/1249970 | loss: 0.4302 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15762/2499940 | global iter:   7882/1249970 | loss: 1.4311 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15764/2499940 | global iter:   7883/1249970 | loss: 1.3092 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15766/2499940 | global iter:   7884/1249970 | loss: 1.2580 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15766/2499940 | global iter:   7884/1249970 | loss: 1.2397 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15768/2499940 | global iter:   7885/1249970 | loss: 0.9179 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15770/2499940 | global iter:   7886/1249970 | loss: 1.2167 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15772/2499940 | global iter:   7887/1249970 | loss: 0.3359 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15774/2499940 | global iter:   7888/1249970 | loss: 2.3266 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15774/2499940 | global iter:   7888/1249970 | loss: 0.9408 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15776/2499940 | global iter:   7889/1249970 | loss: 0.8003 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15778/2499940 | global iter:   7890/1249970 | loss: 1.2757 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15780/2499940 | global iter:   7891/1249970 | loss: 1.0585 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15782/2499940 | global iter:   7892/1249970 | loss: 0.7837 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15782/2499940 | global iter:   7892/1249970 | loss: 1.0251 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.393 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15784/2499940 | global iter:   7893/1249970 | loss: 0.9939 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15786/2499940 | global iter:   7894/1249970 | loss: 1.5929 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15788/2499940 | global iter:   7895/1249970 | loss: 0.1226 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15790/2499940 | global iter:   7896/1249970 | loss: 1.1924 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15790/2499940 | global iter:   7896/1249970 | loss: 1.1146 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15792/2499940 | global iter:   7897/1249970 | loss: 0.3244 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15794/2499940 | global iter:   7898/1249970 | loss: 0.8438 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15796/2499940 | global iter:   7899/1249970 | loss: 1.0651 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15798/2499940 | global iter:   7900/1249970 | loss: 2.2393 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.392 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15798/2499940 | global iter:   7900/1249970 | loss: 1.1055 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.392 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15800/2499940 | global iter:   7901/1249970 | loss: 1.4344 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  15802/2499940 | global iter:   7902/1249970 | loss: 1.0509 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  15804/2499940 | global iter:   7903/1249970 | loss: 1.7056 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15806/2499940 | global iter:   7904/1249970 | loss: 0.5435 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15806/2499940 | global iter:   7904/1249970 | loss: 1.1793 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.687
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15808/2499940 | global iter:   7905/1249970 | loss: 0.1775 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15810/2499940 | global iter:   7906/1249970 | loss: 1.2726 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15812/2499940 | global iter:   7907/1249970 | loss: 1.1869 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15814/2499940 | global iter:   7908/1249970 | loss: 1.0710 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15814/2499940 | global iter:   7908/1249970 | loss: 1.0603 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15816/2499940 | global iter:   7909/1249970 | loss: 1.3439 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15818/2499940 | global iter:   7910/1249970 | loss: 0.4987 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15820/2499940 | global iter:   7911/1249970 | loss: 0.8323 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15822/2499940 | global iter:   7912/1249970 | loss: 0.5886 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.392 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15822/2499940 | global iter:   7912/1249970 | loss: 0.9863 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.392 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15824/2499940 | global iter:   7913/1249970 | loss: 1.2598 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  15826/2499940 | global iter:   7914/1249970 | loss: 1.5089 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15828/2499940 | global iter:   7915/1249970 | loss: 0.6681 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15830/2499940 | global iter:   7916/1249970 | loss: 0.9059 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15830/2499940 | global iter:   7916/1249970 | loss: 1.0869 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15832/2499940 | global iter:   7917/1249970 | loss: 0.5729 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15834/2499940 | global iter:   7918/1249970 | loss: 0.9829 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  15836/2499940 | global iter:   7919/1249970 | loss: 1.6843 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15838/2499940 | global iter:   7920/1249970 | loss: 0.9886 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15838/2499940 | global iter:   7920/1249970 | loss: 1.0865 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15840/2499940 | global iter:   7921/1249970 | loss: 0.4154 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.402 | step time: 0.000
train | epoch   0 | Iter:  15842/2499940 | global iter:   7922/1249970 | loss: 1.6712 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.403 | step time: 0.000
train | epoch   0 | Iter:  15844/2499940 | global iter:   7923/1249970 | loss: 1.7671 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  15846/2499940 | global iter:   7924/1249970 | loss: 0.7809 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15846/2499940 | global iter:   7924/1249970 | loss: 1.2668 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15848/2499940 | global iter:   7925/1249970 | loss: 0.2008 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15850/2499940 | global iter:   7926/1249970 | loss: 1.2547 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15852/2499940 | global iter:   7927/1249970 | loss: 0.6914 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15854/2499940 | global iter:   7928/1249970 | loss: 0.8540 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15854/2499940 | global iter:   7928/1249970 | loss: 0.9107 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15856/2499940 | global iter:   7929/1249970 | loss: 0.5969 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15858/2499940 | global iter:   7930/1249970 | loss: 0.9631 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15860/2499940 | global iter:   7931/1249970 | loss: 0.2374 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15862/2499940 | global iter:   7932/1249970 | loss: 1.6347 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15862/2499940 | global iter:   7932/1249970 | loss: 1.0106 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15864/2499940 | global iter:   7933/1249970 | loss: 1.0169 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15866/2499940 | global iter:   7934/1249970 | loss: 1.4704 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15868/2499940 | global iter:   7935/1249970 | loss: 1.3004 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15870/2499940 | global iter:   7936/1249970 | loss: 1.0082 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15870/2499940 | global iter:   7936/1249970 | loss: 1.1013 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15872/2499940 | global iter:   7937/1249970 | loss: 1.3007 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15874/2499940 | global iter:   7938/1249970 | loss: 1.5830 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  15876/2499940 | global iter:   7939/1249970 | loss: 1.1570 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15878/2499940 | global iter:   7940/1249970 | loss: 0.3083 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15878/2499940 | global iter:   7940/1249970 | loss: 1.0441 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15880/2499940 | global iter:   7941/1249970 | loss: 0.6398 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15882/2499940 | global iter:   7942/1249970 | loss: 0.7031 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  15884/2499940 | global iter:   7943/1249970 | loss: 0.8724 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15886/2499940 | global iter:   7944/1249970 | loss: 0.7520 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15886/2499940 | global iter:   7944/1249970 | loss: 0.9737 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15888/2499940 | global iter:   7945/1249970 | loss: 0.7261 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15890/2499940 | global iter:   7946/1249970 | loss: 1.7147 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15892/2499940 | global iter:   7947/1249970 | loss: 0.5199 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15894/2499940 | global iter:   7948/1249970 | loss: 1.4561 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15894/2499940 | global iter:   7948/1249970 | loss: 0.9077 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15896/2499940 | global iter:   7949/1249970 | loss: 0.8443 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15898/2499940 | global iter:   7950/1249970 | loss: 0.7584 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
train | epoch   0 | Iter:  15900/2499940 | global iter:   7951/1249970 | loss: 0.4597 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15902/2499940 | global iter:   7952/1249970 | loss: 0.6269 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15902/2499940 | global iter:   7952/1249970 | loss: 0.7469 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15904/2499940 | global iter:   7953/1249970 | loss: 0.6410 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15906/2499940 | global iter:   7954/1249970 | loss: 0.7445 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15908/2499940 | global iter:   7955/1249970 | loss: 1.0697 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15910/2499940 | global iter:   7956/1249970 | loss: 1.6459 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15910/2499940 | global iter:   7956/1249970 | loss: 0.8697 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.393 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15912/2499940 | global iter:   7957/1249970 | loss: 0.6237 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15914/2499940 | global iter:   7958/1249970 | loss: 1.1948 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  15916/2499940 | global iter:   7959/1249970 | loss: 0.6060 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15918/2499940 | global iter:   7960/1249970 | loss: 0.7236 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15918/2499940 | global iter:   7960/1249970 | loss: 1.1686 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.689
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15920/2499940 | global iter:   7961/1249970 | loss: 1.2824 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15922/2499940 | global iter:   7962/1249970 | loss: 1.4716 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15924/2499940 | global iter:   7963/1249970 | loss: 1.2528 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15926/2499940 | global iter:   7964/1249970 | loss: 1.1574 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15926/2499940 | global iter:   7964/1249970 | loss: 0.9362 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15928/2499940 | global iter:   7965/1249970 | loss: 0.7912 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15930/2499940 | global iter:   7966/1249970 | loss: 0.8119 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  15932/2499940 | global iter:   7967/1249970 | loss: 1.2890 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15934/2499940 | global iter:   7968/1249970 | loss: 1.3006 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15934/2499940 | global iter:   7968/1249970 | loss: 1.1662 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15936/2499940 | global iter:   7969/1249970 | loss: 1.6900 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15938/2499940 | global iter:   7970/1249970 | loss: 0.7544 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15940/2499940 | global iter:   7971/1249970 | loss: 1.3038 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15942/2499940 | global iter:   7972/1249970 | loss: 0.6736 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15942/2499940 | global iter:   7972/1249970 | loss: 1.0114 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15944/2499940 | global iter:   7973/1249970 | loss: 1.8914 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15946/2499940 | global iter:   7974/1249970 | loss: 0.6435 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  15948/2499940 | global iter:   7975/1249970 | loss: 1.3866 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15950/2499940 | global iter:   7976/1249970 | loss: 1.0675 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15950/2499940 | global iter:   7976/1249970 | loss: 1.1330 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15952/2499940 | global iter:   7977/1249970 | loss: 1.8675 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15954/2499940 | global iter:   7978/1249970 | loss: 0.8774 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  15956/2499940 | global iter:   7979/1249970 | loss: 1.3314 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15958/2499940 | global iter:   7980/1249970 | loss: 2.0175 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15958/2499940 | global iter:   7980/1249970 | loss: 1.3089 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15960/2499940 | global iter:   7981/1249970 | loss: 1.2689 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15962/2499940 | global iter:   7982/1249970 | loss: 0.5638 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  15964/2499940 | global iter:   7983/1249970 | loss: 1.3843 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15966/2499940 | global iter:   7984/1249970 | loss: 1.0131 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15966/2499940 | global iter:   7984/1249970 | loss: 1.0411 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15968/2499940 | global iter:   7985/1249970 | loss: 0.7484 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15970/2499940 | global iter:   7986/1249970 | loss: 0.3732 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15972/2499940 | global iter:   7987/1249970 | loss: 0.7713 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15974/2499940 | global iter:   7988/1249970 | loss: 0.7274 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15974/2499940 | global iter:   7988/1249970 | loss: 0.8382 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15976/2499940 | global iter:   7989/1249970 | loss: 1.0829 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15978/2499940 | global iter:   7990/1249970 | loss: 0.8628 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15980/2499940 | global iter:   7991/1249970 | loss: 0.9857 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15982/2499940 | global iter:   7992/1249970 | loss: 0.9043 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15982/2499940 | global iter:   7992/1249970 | loss: 1.0006 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15984/2499940 | global iter:   7993/1249970 | loss: 0.9672 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15986/2499940 | global iter:   7994/1249970 | loss: 0.9973 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  15988/2499940 | global iter:   7995/1249970 | loss: 1.0813 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  15990/2499940 | global iter:   7996/1249970 | loss: 1.2344 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15990/2499940 | global iter:   7996/1249970 | loss: 1.1131 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  15992/2499940 | global iter:   7997/1249970 | loss: 0.5196 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15994/2499940 | global iter:   7998/1249970 | loss: 1.8089 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  15996/2499940 | global iter:   7999/1249970 | loss: 1.4368 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  15998/2499940 | global iter:   8000/1249970 | loss: 0.4626 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  15998/2499940 | global iter:   8000/1249970 | loss: 1.0043 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
Model save to ./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1/8000
dp size 2
0/63
Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
1/63
Evaluating:   2%|▏         | 1/63 [00:07<07:44,  7.49s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2/63
Evaluating:   3%|▎         | 2/63 [00:15<07:55,  7.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
3/63
Evaluating:   5%|▍         | 3/63 [00:22<07:22,  7.37s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
4/63
Evaluating:   6%|▋         | 4/63 [00:30<07:29,  7.62s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
5/63
Evaluating:   8%|▊         | 5/63 [00:37<07:07,  7.38s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
6/63
Evaluating:  10%|▉         | 6/63 [00:45<07:12,  7.59s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
7/63
Evaluating:  11%|█         | 7/63 [00:53<07:11,  7.71s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
8/63
Evaluating:  13%|█▎        | 8/63 [01:01<07:09,  7.81s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
9/63
Evaluating:  14%|█▍        | 9/63 [01:08<06:56,  7.72s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
10/63
Evaluating:  16%|█▌        | 10/63 [01:16<06:42,  7.60s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
11/63
Evaluating:  17%|█▋        | 11/63 [01:24<06:41,  7.72s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
12/63
Evaluating:  19%|█▉        | 12/63 [01:32<06:37,  7.80s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
13/63
Evaluating:  21%|██        | 13/63 [01:39<06:30,  7.81s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
14/63
Evaluating:  22%|██▏       | 14/63 [01:47<06:25,  7.86s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
15/63
Evaluating:  24%|██▍       | 15/63 [01:55<06:19,  7.91s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
16/63
Evaluating:  25%|██▌       | 16/63 [02:03<06:13,  7.94s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
17/63
Evaluating:  27%|██▋       | 17/63 [02:11<06:05,  7.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
18/63
Evaluating:  29%|██▊       | 18/63 [02:19<05:58,  7.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
19/63
Evaluating:  30%|███       | 19/63 [02:27<05:43,  7.80s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
20/63
Evaluating:  32%|███▏      | 20/63 [02:35<05:38,  7.86s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
21/63
Evaluating:  33%|███▎      | 21/63 [02:43<05:31,  7.90s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
22/63
Evaluating:  35%|███▍      | 22/63 [02:51<05:25,  7.93s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
23/63
Evaluating:  37%|███▋      | 23/63 [02:59<05:18,  7.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
24/63
Evaluating:  38%|███▊      | 24/63 [03:07<05:11,  7.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
25/63
Evaluating:  40%|███▉      | 25/63 [03:15<05:03,  7.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
26/63
Evaluating:  41%|████▏     | 26/63 [03:23<04:55,  7.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
27/63
Evaluating:  43%|████▎     | 27/63 [03:31<04:47,  7.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
28/63
Evaluating:  44%|████▍     | 28/63 [03:39<04:35,  7.88s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
29/63
Evaluating:  46%|████▌     | 29/63 [03:47<04:29,  7.92s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
30/63
Evaluating:  48%|████▊     | 30/63 [03:54<04:15,  7.73s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
31/63
Evaluating:  49%|████▉     | 31/63 [04:02<04:10,  7.82s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
32/63
Evaluating:  51%|█████     | 32/63 [04:10<04:04,  7.88s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
33/63
Evaluating:  52%|█████▏    | 33/63 [04:18<03:57,  7.92s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
34/63
Evaluating:  54%|█████▍    | 34/63 [04:26<03:50,  7.94s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
35/63
Evaluating:  56%|█████▌    | 35/63 [04:33<03:36,  7.74s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
36/63
Evaluating:  57%|█████▋    | 36/63 [04:41<03:31,  7.82s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
37/63
Evaluating:  59%|█████▊    | 37/63 [04:49<03:24,  7.87s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
38/63
Evaluating:  60%|██████    | 38/63 [04:57<03:17,  7.92s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
39/63
Evaluating:  62%|██████▏   | 39/63 [05:05<03:10,  7.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
40/63
Evaluating:  63%|██████▎   | 40/63 [05:13<03:03,  7.97s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
41/63
Evaluating:  65%|██████▌   | 41/63 [05:21<02:51,  7.78s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
42/63
Evaluating:  67%|██████▋   | 42/63 [05:29<02:44,  7.85s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
43/63
Evaluating:  68%|██████▊   | 43/63 [05:36<02:34,  7.70s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
44/63
Evaluating:  70%|██████▉   | 44/63 [05:44<02:28,  7.80s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
45/63
Evaluating:  71%|███████▏  | 45/63 [05:51<02:17,  7.62s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
46/63
Evaluating:  73%|███████▎  | 46/63 [05:59<02:11,  7.74s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
47/63
Evaluating:  75%|███████▍  | 47/63 [06:07<02:05,  7.83s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
48/63
Evaluating:  76%|███████▌  | 48/63 [06:15<01:58,  7.89s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
49/63
Evaluating:  78%|███████▊  | 49/63 [06:23<01:51,  7.93s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
50/63
Evaluating:  79%|███████▉  | 50/63 [06:31<01:43,  7.97s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
51/63
Evaluating:  81%|████████  | 51/63 [06:39<01:33,  7.80s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
52/63
Evaluating:  83%|████████▎ | 52/63 [06:47<01:26,  7.87s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
53/63
Evaluating:  84%|████████▍ | 53/63 [06:55<01:19,  7.91s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
54/63
Evaluating:  86%|████████▌ | 54/63 [07:03<01:11,  7.94s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
55/63
Evaluating:  87%|████████▋ | 55/63 [07:11<01:03,  7.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
56/63
Evaluating:  89%|████████▉ | 56/63 [07:19<00:55,  7.90s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
57/63
Evaluating:  90%|█████████ | 57/63 [07:26<00:45,  7.61s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
58/63
Evaluating:  92%|█████████▏| 58/63 [07:33<00:38,  7.68s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
59/63
Evaluating:  94%|█████████▎| 59/63 [07:41<00:31,  7.76s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
60/63
Evaluating:  95%|█████████▌| 60/63 [07:49<00:23,  7.82s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
61/63
Evaluating:  97%|█████████▋| 61/63 [07:57<00:15,  7.86s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
62/63
Evaluating:  98%|█████████▊| 62/63 [08:05<00:07,  7.90s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
Evaluating: 100%|██████████| 63/63 [08:11<00:00,  7.28s/it]Evaluating: 100%|██████████| 63/63 [08:11<00:00,  7.80s/it]
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1/eval/0
dev | avg_loss: 1.2524336557539681 | {'exact_match': 0.0, 'rougeL': 34.2106}
train | epoch   0 | Iter:  16000/2499940 | global iter:   8001/1249970 | loss: 1.0976 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  16002/2499940 | global iter:   8002/1249970 | loss: 1.3324 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  16004/2499940 | global iter:   8003/1249970 | loss: 1.8621 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  16006/2499940 | global iter:   8004/1249970 | loss: 1.0453 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  16006/2499940 | global iter:   8004/1249970 | loss: 1.1942 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.683
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  16008/2499940 | global iter:   8005/1249970 | loss: 1.1557 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  16010/2499940 | global iter:   8006/1249970 | loss: 0.7968 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  16012/2499940 | global iter:   8007/1249970 | loss: 0.8274 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  16014/2499940 | global iter:   8008/1249970 | loss: 1.2052 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  16014/2499940 | global iter:   8008/1249970 | loss: 0.8961 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  16016/2499940 | global iter:   8009/1249970 | loss: 1.3537 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  16018/2499940 | global iter:   8010/1249970 | loss: 1.1892 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  16020/2499940 | global iter:   8011/1249970 | loss: 0.9795 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  16022/2499940 | global iter:   8012/1249970 | loss: 1.9354 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  16022/2499940 | global iter:   8012/1249970 | loss: 1.1659 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  16024/2499940 | global iter:   8013/1249970 | loss: 1.2842 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  16026/2499940 | global iter:   8014/1249970 | loss: 1.6285 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  16028/2499940 | global iter:   8015/1249970 | loss: 1.3762 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  16030/2499940 | global iter:   8016/1249970 | loss: 1.4804 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  16030/2499940 | global iter:   8016/1249970 | loss: 1.2308 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  16032/2499940 | global iter:   8017/1249970 | loss: 1.5845 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  16034/2499940 | global iter:   8018/1249970 | loss: 0.3896 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  16036/2499940 | global iter:   8019/1249970 | loss: 1.3455 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  16038/2499940 | global iter:   8020/1249970 | loss: 1.4473 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  16038/2499940 | global iter:   8020/1249970 | loss: 1.0888 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  16040/2499940 | global iter:   8021/1249970 | loss: 1.0349 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  16042/2499940 | global iter:   8022/1249970 | loss: 1.1508 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  16044/2499940 | global iter:   8023/1249970 | loss: 1.7480 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  16046/2499940 | global iter:   8024/1249970 | loss: 1.4813 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  16046/2499940 | global iter:   8024/1249970 | loss: 1.2580 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  16048/2499940 | global iter:   8025/1249970 | loss: 0.9347 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  16050/2499940 | global iter:   8026/1249970 | loss: 1.3314 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  16052/2499940 | global iter:   8027/1249970 | loss: 0.1861 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  16054/2499940 | global iter:   8028/1249970 | loss: 0.7557 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  16054/2499940 | global iter:   8028/1249970 | loss: 0.8955 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  16056/2499940 | global iter:   8029/1249970 | loss: 0.5074 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  16058/2499940 | global iter:   8030/1249970 | loss: 1.3821 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
train | epoch   0 | Iter:  16060/2499940 | global iter:   8031/1249970 | loss: 1.5466 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  16062/2499940 | global iter:   8032/1249970 | loss: 1.5395 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  16062/2499940 | global iter:   8032/1249970 | loss: 1.1528 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  16064/2499940 | global iter:   8033/1249970 | loss: 1.6001 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  16066/2499940 | global iter:   8034/1249970 | loss: 1.1291 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  16068/2499940 | global iter:   8035/1249970 | loss: 0.2254 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  16070/2499940 | global iter:   8036/1249970 | loss: 1.0815 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  16070/2499940 | global iter:   8036/1249970 | loss: 1.0688 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  16072/2499940 | global iter:   8037/1249970 | loss: 0.4929 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  16074/2499940 | global iter:   8038/1249970 | loss: 1.9561 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  16076/2499940 | global iter:   8039/1249970 | loss: 0.4143 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  16078/2499940 | global iter:   8040/1249970 | loss: 0.4165 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  16078/2499940 | global iter:   8040/1249970 | loss: 0.8840 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.395 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  16080/2499940 | global iter:   8041/1249970 | loss: 1.2612 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  16082/2499940 | global iter:   8042/1249970 | loss: 1.2592 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  16084/2499940 | global iter:   8043/1249970 | loss: 0.7888 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  16086/2499940 | global iter:   8044/1249970 | loss: 1.2394 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  16086/2499940 | global iter:   8044/1249970 | loss: 1.2256 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  16088/2499940 | global iter:   8045/1249970 | loss: 0.7313 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  16090/2499940 | global iter:   8046/1249970 | loss: 1.5483 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:  16092/2499940 | global iter:   8047/1249970 | loss: 1.2288 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  16094/2499940 | global iter:   8048/1249970 | loss: 0.4098 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  16094/2499940 | global iter:   8048/1249970 | loss: 1.0230 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.688
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  16096/2499940 | global iter:   8049/1249970 | loss: 0.4946 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  16098/2499940 | global iter:   8050/1249970 | loss: 0.7836 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  16100/2499940 | global iter:   8051/1249970 | loss: 1.4900 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  16102/2499940 | global iter:   8052/1249970 | loss: 1.5726 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  16102/2499940 | global iter:   8052/1249970 | loss: 0.9621 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  16104/2499940 | global iter:   8053/1249970 | loss: 1.3647 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  16106/2499940 | global iter:   8054/1249970 | loss: 0.6756 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  16108/2499940 | global iter:   8055/1249970 | loss: 1.2459 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  16110/2499940 | global iter:   8056/1249970 | loss: 0.9293 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  16110/2499940 | global iter:   8056/1249970 | loss: 1.1420 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.394 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  16112/2499940 | global iter:   8057/1249970 | loss: 1.3966 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  16114/2499940 | global iter:   8058/1249970 | loss: 1.1907 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  16116/2499940 | global iter:   8059/1249970 | loss: 1.6083 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  16118/2499940 | global iter:   8060/1249970 | loss: 1.8347 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  16118/2499940 | global iter:   8060/1249970 | loss: 1.3833 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.693
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  16120/2499940 | global iter:   8061/1249970 | loss: 0.7628 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.398 | step time: 0.000
train | epoch   0 | Iter:  16122/2499940 | global iter:   8062/1249970 | loss: 1.3710 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  16124/2499940 | global iter:   8063/1249970 | loss: 1.3706 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  16126/2499940 | global iter:   8064/1249970 | loss: 1.6306 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  16126/2499940 | global iter:   8064/1249970 | loss: 1.2367 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  16128/2499940 | global iter:   8065/1249970 | loss: 0.6458 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  16130/2499940 | global iter:   8066/1249970 | loss: 0.8740 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  16132/2499940 | global iter:   8067/1249970 | loss: 1.4204 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
train | epoch   0 | Iter:  16134/2499940 | global iter:   8068/1249970 | loss: 1.4559 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  16134/2499940 | global iter:   8068/1249970 | loss: 1.0124 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.397 | step time: 0.691
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  16136/2499940 | global iter:   8069/1249970 | loss: 0.7860 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  16138/2499940 | global iter:   8070/1249970 | loss: 1.3490 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.396 | step time: 0.000
train | epoch   0 | Iter:  16140/2499940 | global iter:   8071/1249970 | loss: 0.6680 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  16142/2499940 | global iter:   8072/1249970 | loss: 1.4418 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  16142/2499940 | global iter:   8072/1249970 | loss: 0.8983 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  16144/2499940 | global iter:   8073/1249970 | loss: 1.3138 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  16146/2499940 | global iter:   8074/1249970 | loss: 0.8608 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  16148/2499940 | global iter:   8075/1249970 | loss: 0.8141 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
train | epoch   0 | Iter:  16150/2499940 | global iter:   8076/1249970 | loss: 1.1456 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  16150/2499940 | global iter:   8076/1249970 | loss: 0.9520 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  16152/2499940 | global iter:   8077/1249970 | loss: 0.9681 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.401 | step time: 0.000
train | epoch   0 | Iter:  16154/2499940 | global iter:   8078/1249970 | loss: 1.2254 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  16156/2499940 | global iter:   8079/1249970 | loss: 1.4373 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  16158/2499940 | global iter:   8080/1249970 | loss: 1.0044 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  16158/2499940 | global iter:   8080/1249970 | loss: 1.3513 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.399 | step time: 0.692
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  16160/2499940 | global iter:   8081/1249970 | loss: 1.2340 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  16162/2499940 | global iter:   8082/1249970 | loss: 0.5742 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.393 | step time: 0.000
train | epoch   0 | Iter:  16164/2499940 | global iter:   8083/1249970 | loss: 0.8621 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
train | epoch   0 | Iter:  16166/2499940 | global iter:   8084/1249970 | loss: 0.5756 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:  16166/2499940 | global iter:   8084/1249970 | loss: 1.0174 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.400 | step time: 0.690
./results/qwen2.5/train/sft/qwen2.5-0.5B-Instruct/e10-bs1-lr1e-05-G2-N2-NN1
****************************************************************************************************
train | epoch   0 | Iter:  16168/2499940 | global iter:   8085/1249970 | loss: 1.1075 | ds_loss: 0.0000 | lr: 9.9990e-06 | scale:  8192.0000 | micro time: 0.403 | step time: 0.000
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** JOB 8867010 ON compsci-cluster-fitz-03 CANCELLED AT 2025-04-20T17:55:03 ***
