compsci-cluster-fitz-32
Sat Apr 19 10:28:54 AM EDT 2025
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
The token `llama3` has been saved to /dev/shm/hf-home/stored_tokens
Your token has been saved to /dev/shm/hf-home/token
Login successful.
The current active token is: `llama3`
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2012 ./finetune.py --base-path . --model-path gpt2-xl --ckpt-name gpt2-xlarge --n-gpu 4 --data-dir ./processed_data/dolly_spanish/full/gpt2/ --num-workers 0 --dev-num 1000 --lr 0.00005 --batch-size 2 --eval-batch-size 4 --gradient-accumulation-steps 1 --warmup-iters 0 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --epochs 10 --max-length 512 --max-prompt-length 256 --do-train --do-valid --eval-gen --save-interval 1000 --eval-interval 1000 --log-interval 4 --mid-log-num 10 --save ./results/gpt2/train/sft/gpt2-xlarge-spanish/ --seed 10 --seed-order 10 --deepspeed --deepspeed_config ./configs/deepspeed/ds_config_zero1_fp16.json --type lm --do-sample --top-k 0 --top-p 1.0 --temperature 1.0
PYTHONPATH=.
W0419 10:28:59.722000 3396810 torch/distributed/run.py:792] 
W0419 10:28:59.722000 3396810 torch/distributed/run.py:792] *****************************************
W0419 10:28:59.722000 3396810 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0419 10:28:59.722000 3396810 torch/distributed/run.py:792] *****************************************
[2025-04-19 10:29:05,108] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-04-19 10:29:05,109] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-04-19 10:29:05,112] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-04-19 10:29:05,114] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /home/users/ap794/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /home/users/ap794/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /home/users/ap794/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /home/users/ap794/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
/home/users/ap794/final_project_distillLLM/venv/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/home/users/ap794/final_project_distillLLM/venv/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/home/users/ap794/final_project_distillLLM/venv/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/home/users/ap794/final_project_distillLLM/venv/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
using world size: 4
[2025-04-19 10:29:13,127] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-04-19 10:29:13,127] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_path ................... gpt2-xl
  ckpt_name .................... gpt2-xlarge
  model_type ................... gpt2
  teacher_model_type ........... None
  n_gpu ........................ 4
  n_nodes ...................... 1
  teacher_model_path ........... None
  teacher_ckpt_name ............ None
  teacher_model_fp16 ........... False
  model_parallel ............... False
  model_parallel_size .......... None
  no_value ..................... False
  dropout_path_rate ............ None
  dtype ........................ torch.float16
  type ......................... lm
  do_train ..................... True
  do_valid ..................... True
  do_eval ...................... False
  base_path .................... .
  load ......................... None
  save ......................... ./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
  log_interval ................. 4
  mid_log_num .................. 10
  save_interval ................ 1000
  eval_interval ................ 1000
  local_rank ................... 0
  save_additional_suffix ....... 
  save_rollout ................. False
  eb_sample_times .............. 3
  data_dir ..................... ./processed_data/dolly_spanish/full/gpt2/
  processed_data_dir ........... None
  force_process ................ False
  force_process_demo ........... False
  data_process_workers ......... -1
  train_num .................... -1
  train_ratio .................. 1
  dev_num ...................... 1000
  dev_ratio .................... 1
  gen_num ...................... -1
  data_names ................... None
  prompt_type .................. None
  num_workers .................. 0
  max_prompt_length ............ 256
  min_prompt_length ............ 128
  json_data .................... False
  bin_data ..................... False
  txt_data ..................... False
  prompt_data_dir .............. None
  lm_data_dir .................. None
  eval_ppl ..................... False
  eval_rw ...................... False
  eval_gen ..................... True
  only_prompt .................. False
  batch_size ................... 2
  eval_batch_size .............. 4
  clip_grad .................... 1.0
  total_iters .................. None
  train_iters_per_epoch ........ -1
  max_length ................... 512
  seed ......................... 10
  seed_order ................... 10
  seed_data .................... 42
  seed_ppo ..................... 42
  seed_lm ...................... 7
  epochs ....................... 10
  training_epochs .............. 10000
  gradient_accumulation_steps .. 1
  gradient_checkpointing ....... False
  attn_dtype ................... None
  lr ........................... 5e-05
  lr_min ....................... 1e-07
  weight_decay ................. 0.01
  loss_scale ................... 65536
  kd_ratio ..................... None
  warmup_iters ................. 0
  lr_decay_iters ............... None
  lr_decay_style ............... cosine
  scheduler_name ............... constant_trm
  reward_scaling ............... None
  cliprange_reward ............. 1
  ppo_epochs ................... None
  num_rollouts ................. 256
  num_rollouts_per_device ...... None
  cliprange .................... 0.2
  chunk_size ................... None
  gamma ........................ 0.95
  length_norm .................. False
  single_step_reg .............. False
  teacher_mixed_alpha .......... None
  lm_coef ...................... 1
  top_k ........................ 0
  top_p ........................ 1.0
  do_sample .................... True
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  num_beams .................... 1
  temperature .................. 1.0
  peft ......................... None
  peft_lora_r .................. 8
  peft_lora_alpha .............. 32
  peft_lora_dropout ............ 0.1
  peft_name .................... None
  peft_path .................... None
  teacher_peft_name ............ None
  teacher_peft_path ............ None
  deepspeed .................... True
  deepspeed_config ............. ./configs/deepspeed/ds_config_zero1_fp16.json
  deepscale .................... False
  deepscale_config ............. None
  rank ......................... 0
  world_size ................... 4
[2025-04-19 10:29:13,355] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-04-19 10:29:13,358] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-04-19 10:29:13,630] [INFO] [comm.py:658:init_distributed] cdb=None
Sat Apr 19 10:29:13 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                    0 |
| 30%   23C    P8             15W /  230W |       4MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                    0 |
| 30%   23C    P2             20W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                    0 |
| 30%   21C    P2             17W /  230W |     209MiB /  23028MiB |      2%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                    0 |
| 30%   21C    P2             14W /  230W |      59MiB /  23028MiB |      1%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3396816      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    2   N/A  N/A   3396817      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    3   N/A  N/A   3396818      C   ...project_distillLLM/venv/bin/python3         52MiB |
+-----------------------------------------------------------------------------------------+

Sat Apr 19 10:29:13 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                    0 |
| 30%   23C    P8             17W /  230W |       4MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                    0 |
| 30%   24C    P2             31W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                    0 |
| 30%   21C    P2             26W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                    0 |
| 30%   22C    P2             24W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3396816      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    2   N/A  N/A   3396817      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    3   N/A  N/A   3396818      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

Sat Apr 19 10:29:13 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                    0 |
| 30%   23C    P8             17W /  230W |       4MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                    0 |
| 30%   24C    P2             31W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                    0 |
| 30%   21C    P2             26W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                    0 |
| 30%   22C    P2             24W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3396816      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    2   N/A  N/A   3396817      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    3   N/A  N/A   3396818      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

Sat Apr 19 10:29:13 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                    0 |
| 30%   23C    P8             21W /  230W |       4MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                    0 |
| 30%   24C    P2             60W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                    0 |
| 30%   22C    P2             50W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                    0 |
| 30%   22C    P2             55W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3396816      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    2   N/A  N/A   3396817      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    3   N/A  N/A   3396818      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

Sat Apr 19 10:29:14 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                    0 |
| 30%   23C    P8             21W /  230W |       4MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                    0 |
| 30%   24C    P2             60W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                    0 |
| 30%   22C    P2             50W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                    0 |
| 30%   22C    P2             56W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3396816      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    2   N/A  N/A   3396817      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    3   N/A  N/A   3396818      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

Sat Apr 19 10:29:14 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                    0 |
| 30%   23C    P8             21W /  230W |       4MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                    0 |
| 30%   24C    P2             60W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                    0 |
| 30%   22C    P2             50W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                    0 |
| 30%   22C    P2             56W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3396816      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    2   N/A  N/A   3396817      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    3   N/A  N/A   3396818      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

Sat Apr 19 10:29:14 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                    0 |
| 30%   23C    P8             21W /  230W |       4MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                    0 |
| 30%   24C    P2             60W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                    0 |
| 30%   22C    P2             55W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                    0 |
| 30%   22C    P2             56W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3396816      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    2   N/A  N/A   3396817      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    3   N/A  N/A   3396818      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

Sat Apr 19 10:29:15 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                    0 |
| 30%   23C    P8             16W /  230W |       4MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                    0 |
| 30%   24C    P2             63W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                    0 |
| 30%   22C    P2             55W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                    0 |
| 30%   22C    P2             56W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3396816      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    2   N/A  N/A   3396817      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    3   N/A  N/A   3396818      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

Probing Dataset
Probing end. Max data state 1, total length 10405
10405
Num LM instances: 10405
train num 10405
Probing Dataset
Probing end. Max data state 1, total length 777
777
Num LM instances: 777
Train iters per epoch 1300
total_iters 13000
Sat Apr 19 10:29:16 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                    0 |
| 30%   22C    P8             16W /  230W |       4MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                    0 |
| 30%   24C    P2             63W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                    0 |
| 30%   22C    P2             55W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                    0 |
| 30%   22C    P2             56W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3396816      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    2   N/A  N/A   3396817      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    3   N/A  N/A   3396818      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

Sat Apr 19 10:29:16 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                    0 |
| 30%   22C    P8             16W /  230W |       4MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                    0 |
| 30%   24C    P2             63W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                    0 |
| 30%   22C    P2             55W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                    0 |
| 30%   22C    P2             56W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3396816      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    2   N/A  N/A   3396817      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    3   N/A  N/A   3396818      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

Sat Apr 19 10:29:16 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                    0 |
| 30%   22C    P8             15W /  230W |       4MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                    0 |
| 30%   25C    P2             63W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                    0 |
| 30%   22C    P2             55W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                    0 |
| 30%   22C    P2             56W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3396816      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    2   N/A  N/A   3396817      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    3   N/A  N/A   3396818      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

Sat Apr 19 10:29:16 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                    0 |
| 30%   22C    P8             15W /  230W |       4MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                    0 |
| 30%   25C    P2             63W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                    0 |
| 30%   22C    P2             55W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                    0 |
| 30%   22C    P2             56W /  230W |     209MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3396816      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    2   N/A  N/A   3396817      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    3   N/A  N/A   3396818      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

 > number of parameters: 1557611200
Model load time: 54.79241871833801s
Optimizer = AdamW
[2025-04-19 10:30:12,267] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed info: version=0.16.4, git-hash=unknown, git-branch=unknown
[2025-04-19 10:30:12,281] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 4
[2025-04-19 10:30:12,313] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 4
[2025-04-19 10:30:12,326] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 4
[2025-04-19 10:30:12,335] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 4
[2025-04-19 10:30:13,255] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-04-19 10:30:13,271] [INFO] [logging.py:128:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2025-04-19 10:30:13,271] [INFO] [logging.py:128:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-04-19 10:30:13,388] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2025-04-19 10:30:13,394] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2025-04-19 10:30:13,394] [INFO] [logging.py:128:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 1 optimizer
[2025-04-19 10:30:13,394] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 500000000
[2025-04-19 10:30:13,394] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 500000000
[2025-04-19 10:30:13,394] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2025-04-19 10:30:13,394] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
Sat Apr 19 10:30:20 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                    0 |
| 30%   26C    P2             57W /  230W |    3381MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                    0 |
| 30%   27C    P2             64W /  230W |    5611MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                    0 |
| 30%   24C    P2             55W /  230W |    3381MiB /  23028MiB |      2%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                    0 |
| 30%   25C    P2             57W /  230W |    6373MiB /  23028MiB |     14%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3396815      C   ...project_distillLLM/venv/bin/python3       5604MiB |
|    1   N/A  N/A   3396816      C   ...project_distillLLM/venv/bin/python3       5604MiB |
|    2   N/A  N/A   3396817      C   ...project_distillLLM/venv/bin/python3       3374MiB |
|    3   N/A  N/A   3396818      C   ...project_distillLLM/venv/bin/python3       6366MiB |
+-----------------------------------------------------------------------------------------+

[2025-04-19 10:30:20,720] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[2025-04-19 10:30:20,721] [INFO] [utils.py:782:see_memory_usage] MA 4.4 GB         Max_MA 4.4 GB         CA 4.42 GB         Max_CA 4 GB 
[2025-04-19 10:30:20,722] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 59.36 GB, percent = 5.9%
[2025-04-19 10:30:20,847] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[2025-04-19 10:30:20,848] [INFO] [utils.py:782:see_memory_usage] MA 4.4 GB         Max_MA 5.85 GB         CA 5.87 GB         Max_CA 6 GB 
[2025-04-19 10:30:20,849] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 59.38 GB, percent = 5.9%
[2025-04-19 10:30:20,849] [INFO] [stage_1_and_2.py:550:__init__] optimizer state initialized
[2025-04-19 10:30:20,963] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[2025-04-19 10:30:20,964] [INFO] [utils.py:782:see_memory_usage] MA 4.4 GB         Max_MA 4.4 GB         CA 5.87 GB         Max_CA 6 GB 
[2025-04-19 10:30:20,965] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 59.38 GB, percent = 5.9%
[2025-04-19 10:30:20,969] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer
[2025-04-19 10:30:20,969] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2025-04-19 10:30:20,969] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7fa7e89a3880>
[2025-04-19 10:30:20,969] [INFO] [logging.py:128:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-05, 5e-05], mom=[(0.9, 0.999), (0.9, 0.999)]
[2025-04-19 10:30:20,971] [INFO] [config.py:1001:print] DeepSpeedEngine configuration:
[2025-04-19 10:30:20,971] [INFO] [config.py:1005:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-04-19 10:30:20,972] [INFO] [config.py:1005:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-04-19 10:30:20,972] [INFO] [config.py:1005:print]   amp_enabled .................. False
[2025-04-19 10:30:20,972] [INFO] [config.py:1005:print]   amp_params ................... False
[2025-04-19 10:30:20,972] [INFO] [config.py:1005:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-04-19 10:30:20,972] [INFO] [config.py:1005:print]   bfloat16_enabled ............. False
[2025-04-19 10:30:20,972] [INFO] [config.py:1005:print]   bfloat16_immediate_grad_update  False
[2025-04-19 10:30:20,973] [INFO] [config.py:1005:print]   checkpoint_parallel_write_pipeline  False
[2025-04-19 10:30:20,973] [INFO] [config.py:1005:print]   checkpoint_tag_validation_enabled  True
[2025-04-19 10:30:20,973] [INFO] [config.py:1005:print]   checkpoint_tag_validation_fail  False
[2025-04-19 10:30:20,973] [INFO] [config.py:1005:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fa7e8acc0a0>
[2025-04-19 10:30:20,973] [INFO] [config.py:1005:print]   communication_data_type ...... None
[2025-04-19 10:30:20,973] [INFO] [config.py:1005:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-04-19 10:30:20,973] [INFO] [config.py:1005:print]   curriculum_enabled_legacy .... False
[2025-04-19 10:30:20,973] [INFO] [config.py:1005:print]   curriculum_params_legacy ..... False
[2025-04-19 10:30:20,973] [INFO] [config.py:1005:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-04-19 10:30:20,974] [INFO] [config.py:1005:print]   data_efficiency_enabled ...... False
[2025-04-19 10:30:20,974] [INFO] [config.py:1005:print]   dataloader_drop_last ......... False
[2025-04-19 10:30:20,974] [INFO] [config.py:1005:print]   disable_allgather ............ False
[2025-04-19 10:30:20,974] [INFO] [config.py:1005:print]   dump_state ................... False
[2025-04-19 10:30:20,974] [INFO] [config.py:1005:print]   dynamic_loss_scale_args ...... None
[2025-04-19 10:30:20,974] [INFO] [config.py:1005:print]   eigenvalue_enabled ........... False
[2025-04-19 10:30:20,974] [INFO] [config.py:1005:print]   eigenvalue_gas_boundary_resolution  1
[2025-04-19 10:30:20,974] [INFO] [config.py:1005:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-04-19 10:30:20,974] [INFO] [config.py:1005:print]   eigenvalue_layer_num ......... 0
[2025-04-19 10:30:20,974] [INFO] [config.py:1005:print]   eigenvalue_max_iter .......... 100
[2025-04-19 10:30:20,974] [INFO] [config.py:1005:print]   eigenvalue_stability ......... 1e-06
[2025-04-19 10:30:20,975] [INFO] [config.py:1005:print]   eigenvalue_tol ............... 0.01
[2025-04-19 10:30:20,975] [INFO] [config.py:1005:print]   eigenvalue_verbose ........... False
[2025-04-19 10:30:20,975] [INFO] [config.py:1005:print]   elasticity_enabled ........... False
[2025-04-19 10:30:20,975] [INFO] [config.py:1005:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-04-19 10:30:20,975] [INFO] [config.py:1005:print]   fp16_auto_cast ............... None
[2025-04-19 10:30:20,975] [INFO] [config.py:1005:print]   fp16_enabled ................. False
[2025-04-19 10:30:20,975] [INFO] [config.py:1005:print]   fp16_master_weights_and_gradients  False
[2025-04-19 10:30:20,975] [INFO] [config.py:1005:print]   global_rank .................. 0
[2025-04-19 10:30:20,975] [INFO] [config.py:1005:print]   grad_accum_dtype ............. None
[2025-04-19 10:30:20,976] [INFO] [config.py:1005:print]   gradient_accumulation_steps .. 1
[2025-04-19 10:30:20,976] [INFO] [config.py:1005:print]   gradient_clipping ............ 1.0
[2025-04-19 10:30:20,976] [INFO] [config.py:1005:print]   gradient_predivide_factor .... 1.0
[2025-04-19 10:30:20,976] [INFO] [config.py:1005:print]   graph_harvesting ............. False
[2025-04-19 10:30:20,976] [INFO] [config.py:1005:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-04-19 10:30:20,976] [INFO] [config.py:1005:print]   initial_dynamic_scale ........ 65536
[2025-04-19 10:30:20,976] [INFO] [config.py:1005:print]   load_universal_checkpoint .... False
[2025-04-19 10:30:20,976] [INFO] [config.py:1005:print]   loss_scale ................... 0
[2025-04-19 10:30:20,976] [INFO] [config.py:1005:print]   memory_breakdown ............. False
[2025-04-19 10:30:20,976] [INFO] [config.py:1005:print]   mics_hierarchial_params_gather  False
[2025-04-19 10:30:20,977] [INFO] [config.py:1005:print]   mics_shard_size .............. -1
[2025-04-19 10:30:20,977] [INFO] [config.py:1005:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2025-04-19 10:30:20,977] [INFO] [config.py:1005:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-04-19 10:30:20,977] [INFO] [config.py:1005:print]   optimizer_legacy_fusion ...... False
[2025-04-19 10:30:20,977] [INFO] [config.py:1005:print]   optimizer_name ............... None
[2025-04-19 10:30:20,977] [INFO] [config.py:1005:print]   optimizer_params ............. None
[2025-04-19 10:30:20,977] [INFO] [config.py:1005:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-04-19 10:30:20,977] [INFO] [config.py:1005:print]   pld_enabled .................. False
[2025-04-19 10:30:20,978] [INFO] [config.py:1005:print]   pld_params ................... False
[2025-04-19 10:30:20,978] [INFO] [config.py:1005:print]   prescale_gradients ........... False
[2025-04-19 10:30:20,978] [INFO] [config.py:1005:print]   scheduler_name ............... None
[2025-04-19 10:30:20,978] [INFO] [config.py:1005:print]   scheduler_params ............. None
[2025-04-19 10:30:20,978] [INFO] [config.py:1005:print]   seq_parallel_communication_data_type  torch.float32
[2025-04-19 10:30:20,978] [INFO] [config.py:1005:print]   sparse_attention ............. None
[2025-04-19 10:30:20,978] [INFO] [config.py:1005:print]   sparse_gradients_enabled ..... False
[2025-04-19 10:30:20,978] [INFO] [config.py:1005:print]   steps_per_print .............. 10000000
[2025-04-19 10:30:20,978] [INFO] [config.py:1005:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False
[2025-04-19 10:30:20,979] [INFO] [config.py:1005:print]   timers_config ................ enabled=True synchronized=True
[2025-04-19 10:30:20,979] [INFO] [config.py:1005:print]   train_batch_size ............. 8
[2025-04-19 10:30:20,979] [INFO] [config.py:1005:print]   train_micro_batch_size_per_gpu  2
[2025-04-19 10:30:20,979] [INFO] [config.py:1005:print]   use_data_before_expert_parallel_  False
[2025-04-19 10:30:20,979] [INFO] [config.py:1005:print]   use_node_local_storage ....... False
[2025-04-19 10:30:20,979] [INFO] [config.py:1005:print]   wall_clock_breakdown ......... False
[2025-04-19 10:30:20,979] [INFO] [config.py:1005:print]   weight_quantization_config ... None
[2025-04-19 10:30:20,979] [INFO] [config.py:1005:print]   world_size ................... 4
[2025-04-19 10:30:20,979] [INFO] [config.py:1005:print]   zero_allow_untested_optimizer  True
[2025-04-19 10:30:20,980] [INFO] [config.py:1005:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False
[2025-04-19 10:30:20,980] [INFO] [config.py:1005:print]   zero_enabled ................. True
[2025-04-19 10:30:20,980] [INFO] [config.py:1005:print]   zero_force_ds_cpu_optimizer .. True
[2025-04-19 10:30:20,980] [INFO] [config.py:1005:print]   zero_optimization_stage ...... 1
[2025-04-19 10:30:20,980] [INFO] [config.py:991:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 2, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 1
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": false, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1.000000e+07
}
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   4504 MiB |   4504 MiB |   9771 MiB |   5267 MiB |
|       from large pool |   4455 MiB |   4455 MiB |   9718 MiB |   5263 MiB |
|       from small pool |     48 MiB |     48 MiB |     52 MiB |      3 MiB |
|---------------------------------------------------------------------------|
| Active memory         |   4504 MiB |   4504 MiB |   9771 MiB |   5267 MiB |
|       from large pool |   4455 MiB |   4455 MiB |   9718 MiB |   5263 MiB |
|       from small pool |     48 MiB |     48 MiB |     52 MiB |      3 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |   4504 MiB |   4504 MiB |   9703 MiB |   5199 MiB |
|       from large pool |   4455 MiB |   4455 MiB |   9651 MiB |   5195 MiB |
|       from small pool |     48 MiB |     48 MiB |     52 MiB |      3 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6014 MiB |   6014 MiB |   9808 MiB |   3794 MiB |
|       from large pool |   5962 MiB |   5962 MiB |   9756 MiB |   3794 MiB |
|       from small pool |     52 MiB |     52 MiB |     52 MiB |      0 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  22132 KiB |  22132 KiB |   1056 MiB |   1034 MiB |
|       from large pool |  21087 KiB |  21087 KiB |   1024 MiB |   1003 MiB |
|       from small pool |   1045 KiB |   1045 KiB |     31 MiB |     30 MiB |
|---------------------------------------------------------------------------|
| Allocations           |     100    |     100    |    1264    |    1164    |
|       from large pool |       3    |       3    |     199    |     196    |
|       from small pool |      97    |      97    |    1065    |     968    |
|---------------------------------------------------------------------------|
| Active allocs         |     100    |     100    |    1264    |    1164    |
|       from large pool |       3    |       3    |     199    |     196    |
|       from small pool |      97    |      97    |    1065    |     968    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      30    |      30    |     177    |     147    |
|       from large pool |       4    |       4    |     151    |     147    |
|       from small pool |      26    |      26    |      26    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       6    |       6    |     281    |     275    |
|       from large pool |       3    |       3    |     101    |      98    |
|       from small pool |       3    |       3    |     180    |     177    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Start Fine-tuning
Sat Apr 19 10:30:20 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                    0 |
| 30%   26C    P2             58W /  230W |    4887MiB /  23028MiB |      9%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                    0 |
| 30%   27C    P2             65W /  230W |    6373MiB /  23028MiB |      2%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                    0 |
| 30%   25C    P2             56W /  230W |    4867MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                    0 |
| 30%   25C    P2             57W /  230W |    6373MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3396815      C   ...project_distillLLM/venv/bin/python3       4880MiB |
|    1   N/A  N/A   3396816      C   ...project_distillLLM/venv/bin/python3       6366MiB |
|    2   N/A  N/A   3396817      C   ...project_distillLLM/venv/bin/python3       4860MiB |
|    3   N/A  N/A   3396818      C   ...project_distillLLM/venv/bin/python3       6366MiB |
+-----------------------------------------------------------------------------------------+

Sat Apr 19 10:30:20 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                    0 |
| 30%   26C    P2             58W /  230W |    6373MiB /  23028MiB |      9%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                    0 |
| 30%   27C    P2             65W /  230W |    6373MiB /  23028MiB |      9%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                    0 |
| 30%   25C    P2             56W /  230W |    6373MiB /  23028MiB |      1%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                    0 |
| 30%   25C    P2             57W /  230W |    6373MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3396815      C   ...project_distillLLM/venv/bin/python3       6366MiB |
|    1   N/A  N/A   3396816      C   ...project_distillLLM/venv/bin/python3       6366MiB |
|    2   N/A  N/A   3396817      C   ...project_distillLLM/venv/bin/python3       6366MiB |
|    3   N/A  N/A   3396818      C   ...project_distillLLM/venv/bin/python3       6366MiB |
+-----------------------------------------------------------------------------------------+

Sat Apr 19 10:30:21 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                    0 |
| 30%   26C    P2             58W /  230W |    6373MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                    0 |
| 30%   27C    P2             64W /  230W |    6373MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                    0 |
| 30%   25C    P2             56W /  230W |    6373MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                    0 |
| 30%   25C    P2             57W /  230W |    6373MiB /  23028MiB |      1%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3396815      C   ...project_distillLLM/venv/bin/python3       6366MiB |
|    1   N/A  N/A   3396816      C   ...project_distillLLM/venv/bin/python3       6366MiB |
|    2   N/A  N/A   3396817      C   ...project_distillLLM/venv/bin/python3       6366MiB |
|    3   N/A  N/A   3396818      C   ...project_distillLLM/venv/bin/python3       6366MiB |
+-----------------------------------------------------------------------------------------+

Sat Apr 19 10:30:21 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                    0 |
| 30%   26C    P2             58W /  230W |    6373MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                    0 |
| 30%   27C    P2             64W /  230W |    6373MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                    0 |
| 30%   25C    P2             55W /  230W |    6373MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                    0 |
| 30%   25C    P2             56W /  230W |    6373MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3396815      C   ...project_distillLLM/venv/bin/python3       6366MiB |
|    1   N/A  N/A   3396816      C   ...project_distillLLM/venv/bin/python3       6366MiB |
|    2   N/A  N/A   3396817      C   ...project_distillLLM/venv/bin/python3       6366MiB |
|    3   N/A  N/A   3396818      C   ...project_distillLLM/venv/bin/python3       6366MiB |
+-----------------------------------------------------------------------------------------+

Start Fine-tuning
Sat Apr 19 10:30:22 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                    0 |
| 30%   26C    P2             58W /  230W |    6373MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                    0 |
| 30%   27C    P2             64W /  230W |    6373MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                    0 |
| 30%   25C    P2             55W /  230W |    6373MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                    0 |
| 30%   25C    P2             57W /  230W |    6383MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3396815      C   ...project_distillLLM/venv/bin/python3       6366MiB |
|    1   N/A  N/A   3396816      C   ...project_distillLLM/venv/bin/python3       6366MiB |
|    2   N/A  N/A   3396817      C   ...project_distillLLM/venv/bin/python3       6366MiB |
|    3   N/A  N/A   3396818      C   ...project_distillLLM/venv/bin/python3       6376MiB |
+-----------------------------------------------------------------------------------------+

Sat Apr 19 10:30:22 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                    0 |
| 30%   26C    P2             58W /  230W |    6373MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                    0 |
| 30%   27C    P2             64W /  230W |    6373MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                    0 |
| 30%   25C    P2             55W /  230W |    6373MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                    0 |
| 30%   25C    P2             57W /  230W |    6389MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3396815      C   ...project_distillLLM/venv/bin/python3       6366MiB |
|    1   N/A  N/A   3396816      C   ...project_distillLLM/venv/bin/python3       6366MiB |
|    2   N/A  N/A   3396817      C   ...project_distillLLM/venv/bin/python3       6366MiB |
|    3   N/A  N/A   3396818      C   ...project_distillLLM/venv/bin/python3       6382MiB |
+-----------------------------------------------------------------------------------------+

dp size 4
Sat Apr 19 10:30:22 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                    0 |
| 30%   26C    P2             58W /  230W |    6373MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                    0 |
| 30%   27C    P2             64W /  230W |    6373MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                    0 |
| 30%   25C    P2             55W /  230W |    6373MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                    0 |
| 30%   25C    P2             57W /  230W |    6389MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3396815      C   ...project_distillLLM/venv/bin/python3       6366MiB |
|    1   N/A  N/A   3396816      C   ...project_distillLLM/venv/bin/python3       6366MiB |
|    2   N/A  N/A   3396817      C   ...project_distillLLM/venv/bin/python3       6366MiB |
|    3   N/A  N/A   3396818      C   ...project_distillLLM/venv/bin/python3       6382MiB |
+-----------------------------------------------------------------------------------------+

0/63
1/63
2/63
3/63
4/63
5/63
6/63
7/63
8/63
9/63
10/63
11/63
12/63
13/63
14/63
15/63

Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]
Evaluating:   2%|         | 1/63 [00:18<19:29, 18.87s/it]
Evaluating:   3%|         | 2/63 [00:37<18:48, 18.50s/it]
Evaluating:   5%|         | 3/63 [00:55<18:27, 18.46s/it]
Evaluating:   6%|         | 4/63 [01:14<18:09, 18.47s/it]
Evaluating:   8%|         | 5/63 [01:32<17:51, 18.47s/it]
Evaluating:  10%|         | 6/63 [01:50<17:32, 18.46s/it]
Evaluating:  11%|         | 7/63 [02:09<17:14, 18.47s/it]
Evaluating:  13%|        | 8/63 [02:27<16:55, 18.47s/it]
Evaluating:  14%|        | 9/63 [02:46<16:37, 18.48s/it]
Evaluating:  16%|        | 10/63 [03:04<16:19, 18.48s/it]
Evaluating:  17%|        | 11/63 [03:23<16:00, 18.47s/it]
Evaluating:  19%|        | 12/63 [03:41<15:42, 18.47s/it]
Evaluating:  21%|        | 13/63 [04:00<15:23, 18.46s/it]
Evaluating:  22%|       | 14/63 [04:18<15:04, 18.46s/it]
Evaluating:  24%|       | 15/63 [04:37<14:45, 18.45s/it]
Evaluating:  25%|     16/63
17/63
18/63
19/63
20/63
21/63
22/63
23/63
24/63
25/63
26/63
27/63
28/63
29/63
30/63
  | 16/63 [04:55<14:27, 18.45s/it]
Evaluating:  27%|       | 17/63 [05:14<14:08, 18.45s/it]
Evaluating:  29%|       | 18/63 [05:32<13:51, 18.48s/it]
Evaluating:  30%|       | 19/63 [05:50<13:31, 18.45s/it]
Evaluating:  32%|      | 20/63 [06:09<13:14, 18.47s/it]
Evaluating:  33%|      | 21/63 [06:27<12:55, 18.46s/it]
Evaluating:  35%|      | 22/63 [06:46<12:37, 18.47s/it]
Evaluating:  37%|      | 23/63 [07:04<12:19, 18.49s/it]
Evaluating:  38%|      | 24/63 [07:23<12:00, 18.48s/it]
Evaluating:  40%|      | 25/63 [07:41<11:41, 18.47s/it]
Evaluating:  41%|     | 26/63 [08:00<11:22, 18.44s/it]
Evaluating:  43%|     | 27/63 [08:18<11:04, 18.45s/it]
Evaluating:  44%|     | 28/63 [08:37<10:46, 18.47s/it]
Evaluating:  46%|     | 29/63 [08:55<10:27, 18.45s/it]
Evaluating:  48%|     | 30/63 [09:14<10:08, 18.45s/it]
Evaluating:  49%| 31/63
32/63
33/63
34/63
35/63
36/63
37/63
38/63
39/63
40/63
41/63
42/63
43/63
44/63
    | 31/63 [09:32<09:50, 18.44s/it]
Evaluating:  51%|     | 32/63 [09:50<09:31, 18.45s/it]
Evaluating:  52%|    | 33/63 [10:09<09:13, 18.45s/it]
Evaluating:  54%|    | 34/63 [10:27<08:54, 18.44s/it]
Evaluating:  56%|    | 35/63 [10:46<08:36, 18.44s/it]
Evaluating:  57%|    | 36/63 [11:04<08:17, 18.44s/it]
Evaluating:  59%|    | 37/63 [11:23<07:58, 18.42s/it]
Evaluating:  60%|    | 38/63 [11:41<07:40, 18.41s/it]
Evaluating:  62%|   | 39/63 [11:59<07:21, 18.39s/it]
Evaluating:  63%|   | 40/63 [12:18<07:03, 18.40s/it]
Evaluating:  65%|   | 41/63 [12:36<06:45, 18.42s/it]
Evaluating:  67%|   | 42/63 [12:55<06:26, 18.41s/it]
Evaluating:  68%|   | 43/63 [13:13<06:08, 18.44s/it]
Evaluating:  70%|   | 44/63 [13:32<05:50, 18.47s/it]
Evaluating:  71%|45/63
46/63
47/63
Distributed index stop interation. Idx: 779 Total_length: 777
Distributed index stop interation. Idx: 778 Total_length: 777
Distributed index stop interation. Idx: 777 Total_length: 777
Distributed index stop interation. Idx: 780 Total_length: 777
  | 45/63 [13:50<05:32, 18.47s/it]
Evaluating:  73%|  | 46/63 [14:08<05:13, 18.46s/it]
Evaluating:  75%|  | 47/63 [14:27<04:55, 18.44s/it]
Evaluating:  76%|  | 48/63 [14:44<04:32, 18.19s/it]
Evaluating:  76%|  | 48/63 [14:45<04:36, 18.44s/it]
Sat Apr 19 10:45:08 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                    0 |
| 30%   36C    P2             88W /  230W |    7703MiB /  23028MiB |      4%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                    0 |
| 30%   37C    P2             90W /  230W |    7703MiB /  23028MiB |     21%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                    0 |
| 30%   34C    P2             79W /  230W |    7703MiB /  23028MiB |     33%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                    0 |
| 30%   35C    P2             84W /  230W |    7703MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3396815      C   ...project_distillLLM/venv/bin/python3       7696MiB |
|    1   N/A  N/A   3396816      C   ...project_distillLLM/venv/bin/python3       7696MiB |
|    2   N/A  N/A   3396817      C   ...project_distillLLM/venv/bin/python3       7696MiB |
|    3   N/A  N/A   3396818      C   ...project_distillLLM/venv/bin/python3       7696MiB |
+-----------------------------------------------------------------------------------------+

Sat Apr 19 10:45:08 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                    0 |
| 30%   36C    P2             88W /  230W |    7703MiB /  23028MiB |      4%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                    0 |
| 30%   37C    P2             90W /  230W |    7703MiB /  23028MiB |     21%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                    0 |
| 30%   34C    P2             78W /  230W |    7703MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                    0 |
| 30%   35C    P2             82W /  230W |    7703MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3396815      C   ...project_distillLLM/venv/bin/python3       7696MiB |
|    1   N/A  N/A   3396816      C   ...project_distillLLM/venv/bin/python3       7696MiB |
|    2   N/A  N/A   3396817      C   ...project_distillLLM/venv/bin/python3       7696MiB |
|    3   N/A  N/A   3396818      C   ...project_distillLLM/venv/bin/python3       7696MiB |
+-----------------------------------------------------------------------------------------+

Sat Apr 19 10:45:08 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                    0 |
| 30%   36C    P2             83W /  230W |    7703MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                    0 |
| 30%   37C    P2             84W /  230W |    7703MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                    0 |
| 30%   34C    P2             73W /  230W |    7703MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                    0 |
| 30%   36C    P2             86W /  230W |    8399MiB /  23028MiB |     26%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3396815      C   ...project_distillLLM/venv/bin/python3       7696MiB |
|    1   N/A  N/A   3396816      C   ...project_distillLLM/venv/bin/python3       7696MiB |
|    2   N/A  N/A   3396817      C   ...project_distillLLM/venv/bin/python3       7696MiB |
|    3   N/A  N/A   3396818      C   ...project_distillLLM/venv/bin/python3       8392MiB |
+-----------------------------------------------------------------------------------------+

./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1/eval/0
dev | avg_loss: 3.0522867838541665 | {'exact_match': 0.0, 'rougeL': 3.5571}
Sat Apr 19 10:45:16 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                    0 |
| 30%   35C    P2             62W /  230W |    7703MiB /  23028MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                    0 |
| 30%   38C    P2             94W /  230W |   20931MiB /  23028MiB |    100%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                    0 |
| 30%   35C    P2             82W /  230W |   20931MiB /  23028MiB |    100%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                    0 |
| 30%   35C    P2             87W /  230W |   21869MiB /  23028MiB |    100%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3396815      C   ...project_distillLLM/venv/bin/python3       7696MiB |
|    1   N/A  N/A   3396816      C   ...project_distillLLM/venv/bin/python3      20924MiB |
|    2   N/A  N/A   3396817      C   ...project_distillLLM/venv/bin/python3      20924MiB |
|    3   N/A  N/A   3396818      C   ...project_distillLLM/venv/bin/python3      21862MiB |
+-----------------------------------------------------------------------------------------+

[2025-04-19 10:45:18,214] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648
train | epoch   0 | Iter:      1/ 13000 | global iter:      1/ 13000 | loss: 3.4312 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 2147483648.0000 | micro time: 1.348 | step time: 0.000
[2025-04-19 10:45:19,619] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648, reducing to 1073741824
train | epoch   0 | Iter:      2/ 13000 | global iter:      2/ 13000 | loss: 2.9954 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 1073741824.0000 | micro time: 1.413 | step time: 0.000
[2025-04-19 10:45:20,761] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1073741824, reducing to 536870912
train | epoch   0 | Iter:      3/ 13000 | global iter:      3/ 13000 | loss: 3.0629 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 536870912.0000 | micro time: 1.129 | step time: 0.000
[2025-04-19 10:45:21,893] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 536870912, reducing to 268435456
train | epoch   0 | Iter:      4/ 13000 | global iter:      4/ 13000 | loss: 3.4471 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 268435456.0000 | micro time: 1.122 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:      4/ 13000 | global iter:      4/ 13000 | loss: 3.2341 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 268435456.0000 | micro time: 1.122 | step time: 1.253
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
[2025-04-19 10:45:23,021] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 268435456, reducing to 134217728
train | epoch   0 | Iter:      5/ 13000 | global iter:      5/ 13000 | loss: 3.6495 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 134217728.0000 | micro time: 1.103 | step time: 0.000
[2025-04-19 10:45:24,141] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 134217728, reducing to 67108864
train | epoch   0 | Iter:      6/ 13000 | global iter:      6/ 13000 | loss: 2.8885 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 67108864.0000 | micro time: 1.120 | step time: 0.000
[2025-04-19 10:45:25,313] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 67108864, reducing to 33554432
train | epoch   0 | Iter:      7/ 13000 | global iter:      7/ 13000 | loss: 2.7877 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 33554432.0000 | micro time: 1.182 | step time: 0.000
[2025-04-19 10:45:26,429] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 33554432, reducing to 16777216
train | epoch   0 | Iter:      8/ 13000 | global iter:      8/ 13000 | loss: 4.0029 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 16777216.0000 | micro time: 1.112 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:      8/ 13000 | global iter:      8/ 13000 | loss: 3.3322 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 16777216.0000 | micro time: 1.112 | step time: 1.129
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
[2025-04-19 10:45:27,549] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16777216, reducing to 8388608
train | epoch   0 | Iter:      9/ 13000 | global iter:      9/ 13000 | loss: 3.4400 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 8388608.0000 | micro time: 1.100 | step time: 0.000
[2025-04-19 10:45:28,685] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608, reducing to 4194304
train | epoch   0 | Iter:     10/ 13000 | global iter:     10/ 13000 | loss: 3.1614 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 4194304.0000 | micro time: 1.162 | step time: 0.000
[2025-04-19 10:45:29,823] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152
train | epoch   0 | Iter:     11/ 13000 | global iter:     11/ 13000 | loss: 3.3135 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 2097152.0000 | micro time: 1.143 | step time: 0.000
[2025-04-19 10:45:30,956] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2097152, reducing to 1048576
train | epoch   0 | Iter:     12/ 13000 | global iter:     12/ 13000 | loss: 3.5059 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 1048576.0000 | micro time: 1.100 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     12/ 13000 | global iter:     12/ 13000 | loss: 3.3552 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 1048576.0000 | micro time: 1.100 | step time: 1.126
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
[2025-04-19 10:45:32,109] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1048576, reducing to 524288
train | epoch   0 | Iter:     13/ 13000 | global iter:     13/ 13000 | loss: 3.3438 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 524288.0000 | micro time: 1.150 | step time: 0.000
[2025-04-19 10:45:33,239] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 524288, reducing to 262144
train | epoch   0 | Iter:     14/ 13000 | global iter:     14/ 13000 | loss: 3.6938 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 262144.0000 | micro time: 1.130 | step time: 0.000
train | epoch   0 | Iter:     15/ 13000 | global iter:     15/ 13000 | loss: 3.2134 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 262144.0000 | micro time: 1.527 | step time: 0.000
train | epoch   0 | Iter:     16/ 13000 | global iter:     16/ 13000 | loss: 3.0395 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 262144.0000 | micro time: 1.851 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     16/ 13000 | global iter:     16/ 13000 | loss: 3.3226 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 262144.0000 | micro time: 1.851 | step time: 1.414
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
[2025-04-19 10:45:38,137] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 262144, reducing to 131072
train | epoch   0 | Iter:     17/ 13000 | global iter:     17/ 13000 | loss: 2.9012 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.499 | step time: 0.000
train | epoch   0 | Iter:     18/ 13000 | global iter:     18/ 13000 | loss: 3.4053 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.858 | step time: 0.000
train | epoch   0 | Iter:     19/ 13000 | global iter:     19/ 13000 | loss: 2.6118 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.715 | step time: 0.000
train | epoch   0 | Iter:     20/ 13000 | global iter:     20/ 13000 | loss: 3.5026 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.749 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     20/ 13000 | global iter:     20/ 13000 | loss: 3.1052 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.749 | step time: 1.705
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:     21/ 13000 | global iter:     21/ 13000 | loss: 2.4344 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.749 | step time: 0.000
train | epoch   0 | Iter:     22/ 13000 | global iter:     22/ 13000 | loss: 3.1093 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.819 | step time: 0.000
train | epoch   0 | Iter:     23/ 13000 | global iter:     23/ 13000 | loss: 3.2454 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.723 | step time: 0.000
train | epoch   0 | Iter:     24/ 13000 | global iter:     24/ 13000 | loss: 2.9053 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.857 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     24/ 13000 | global iter:     24/ 13000 | loss: 2.9236 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.857 | step time: 1.787
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:     25/ 13000 | global iter:     25/ 13000 | loss: 2.9723 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.826 | step time: 0.000
train | epoch   0 | Iter:     26/ 13000 | global iter:     26/ 13000 | loss: 3.2001 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.870 | step time: 0.000
train | epoch   0 | Iter:     27/ 13000 | global iter:     27/ 13000 | loss: 2.7147 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.816 | step time: 0.000
train | epoch   0 | Iter:     28/ 13000 | global iter:     28/ 13000 | loss: 3.4634 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.811 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     28/ 13000 | global iter:     28/ 13000 | loss: 3.0876 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.811 | step time: 1.831
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:     29/ 13000 | global iter:     29/ 13000 | loss: 2.9130 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.849 | step time: 0.000
train | epoch   0 | Iter:     30/ 13000 | global iter:     30/ 13000 | loss: 3.1692 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.831 | step time: 0.000
train | epoch   0 | Iter:     31/ 13000 | global iter:     31/ 13000 | loss: 3.3186 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.767 | step time: 0.000
train | epoch   0 | Iter:     32/ 13000 | global iter:     32/ 13000 | loss: 2.9632 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.819 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     32/ 13000 | global iter:     32/ 13000 | loss: 3.0910 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.819 | step time: 1.816
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:     33/ 13000 | global iter:     33/ 13000 | loss: 3.1088 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.814 | step time: 0.000
train | epoch   0 | Iter:     34/ 13000 | global iter:     34/ 13000 | loss: 2.9592 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.864 | step time: 0.000
train | epoch   0 | Iter:     35/ 13000 | global iter:     35/ 13000 | loss: 2.9782 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.764 | step time: 0.000
train | epoch   0 | Iter:     36/ 13000 | global iter:     36/ 13000 | loss: 2.9496 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.810 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     36/ 13000 | global iter:     36/ 13000 | loss: 2.9990 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.810 | step time: 1.813
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:     37/ 13000 | global iter:     37/ 13000 | loss: 2.6419 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.872 | step time: 0.000
train | epoch   0 | Iter:     38/ 13000 | global iter:     38/ 13000 | loss: 2.7606 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.883 | step time: 0.000
train | epoch   0 | Iter:     39/ 13000 | global iter:     39/ 13000 | loss: 2.6477 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.879 | step time: 0.000
train | epoch   0 | Iter:     40/ 13000 | global iter:     40/ 13000 | loss: 2.1095 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.841 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     40/ 13000 | global iter:     40/ 13000 | loss: 2.5399 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.841 | step time: 1.869
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:     41/ 13000 | global iter:     41/ 13000 | loss: 2.3772 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 131072.0000 | micro time: 1.842 | step time: 0.000
[2025-04-19 10:46:23,409] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 131072, reducing to 65536
train | epoch   0 | Iter:     42/ 13000 | global iter:     42/ 13000 | loss: 3.1295 | ds_loss: 0.0000 | lr: 5.0000e-05 | scale: 65536.0000 | micro time: 1.536 | step time: 0.000
train | epoch   0 | Iter:     43/ 13000 | global iter:     43/ 13000 | loss: 3.1414 | ds_loss: 0.0000 | lr: 4.9999e-05 | scale: 65536.0000 | micro time: 1.810 | step time: 0.000
train | epoch   0 | Iter:     44/ 13000 | global iter:     44/ 13000 | loss: 2.4072 | ds_loss: 0.0000 | lr: 4.9999e-05 | scale: 65536.0000 | micro time: 1.813 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     44/ 13000 | global iter:     44/ 13000 | loss: 2.7638 | ds_loss: 0.0000 | lr: 4.9999e-05 | scale: 65536.0000 | micro time: 1.813 | step time: 1.750
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:     45/ 13000 | global iter:     45/ 13000 | loss: 2.9202 | ds_loss: 0.0000 | lr: 4.9999e-05 | scale: 65536.0000 | micro time: 1.816 | step time: 0.000
train | epoch   0 | Iter:     46/ 13000 | global iter:     46/ 13000 | loss: 2.8763 | ds_loss: 0.0000 | lr: 4.9999e-05 | scale: 65536.0000 | micro time: 1.835 | step time: 0.000
train | epoch   0 | Iter:     47/ 13000 | global iter:     47/ 13000 | loss: 3.2288 | ds_loss: 0.0000 | lr: 4.9999e-05 | scale: 65536.0000 | micro time: 1.775 | step time: 0.000
train | epoch   0 | Iter:     48/ 13000 | global iter:     48/ 13000 | loss: 3.0053 | ds_loss: 0.0000 | lr: 4.9999e-05 | scale: 65536.0000 | micro time: 1.836 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     48/ 13000 | global iter:     48/ 13000 | loss: 3.0076 | ds_loss: 0.0000 | lr: 4.9999e-05 | scale: 65536.0000 | micro time: 1.836 | step time: 1.815
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:     49/ 13000 | global iter:     49/ 13000 | loss: 3.0968 | ds_loss: 0.0000 | lr: 4.9999e-05 | scale: 65536.0000 | micro time: 1.813 | step time: 0.000
train | epoch   0 | Iter:     50/ 13000 | global iter:     50/ 13000 | loss: 2.2776 | ds_loss: 0.0000 | lr: 4.9999e-05 | scale: 65536.0000 | micro time: 1.715 | step time: 0.000
train | epoch   0 | Iter:     51/ 13000 | global iter:     51/ 13000 | loss: 3.3276 | ds_loss: 0.0000 | lr: 4.9999e-05 | scale: 65536.0000 | micro time: 1.883 | step time: 0.000
train | epoch   0 | Iter:     52/ 13000 | global iter:     52/ 13000 | loss: 2.9059 | ds_loss: 0.0000 | lr: 4.9999e-05 | scale: 65536.0000 | micro time: 1.839 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     52/ 13000 | global iter:     52/ 13000 | loss: 2.9020 | ds_loss: 0.0000 | lr: 4.9999e-05 | scale: 65536.0000 | micro time: 1.839 | step time: 1.812
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:     53/ 13000 | global iter:     53/ 13000 | loss: 2.8615 | ds_loss: 0.0000 | lr: 4.9999e-05 | scale: 65536.0000 | micro time: 1.806 | step time: 0.000
train | epoch   0 | Iter:     54/ 13000 | global iter:     54/ 13000 | loss: 2.6569 | ds_loss: 0.0000 | lr: 4.9999e-05 | scale: 65536.0000 | micro time: 1.803 | step time: 0.000
train | epoch   0 | Iter:     55/ 13000 | global iter:     55/ 13000 | loss: 3.2382 | ds_loss: 0.0000 | lr: 4.9999e-05 | scale: 65536.0000 | micro time: 1.750 | step time: 0.000
train | epoch   0 | Iter:     56/ 13000 | global iter:     56/ 13000 | loss: 3.3376 | ds_loss: 0.0000 | lr: 4.9999e-05 | scale: 65536.0000 | micro time: 1.783 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     56/ 13000 | global iter:     56/ 13000 | loss: 3.0235 | ds_loss: 0.0000 | lr: 4.9999e-05 | scale: 65536.0000 | micro time: 1.783 | step time: 1.786
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:     57/ 13000 | global iter:     57/ 13000 | loss: 2.4429 | ds_loss: 0.0000 | lr: 4.9999e-05 | scale: 65536.0000 | micro time: 1.721 | step time: 0.000
train | epoch   0 | Iter:     58/ 13000 | global iter:     58/ 13000 | loss: 3.0875 | ds_loss: 0.0000 | lr: 4.9999e-05 | scale: 65536.0000 | micro time: 1.884 | step time: 0.000
train | epoch   0 | Iter:     59/ 13000 | global iter:     59/ 13000 | loss: 2.6320 | ds_loss: 0.0000 | lr: 4.9999e-05 | scale: 65536.0000 | micro time: 1.818 | step time: 0.000
train | epoch   0 | Iter:     60/ 13000 | global iter:     60/ 13000 | loss: 2.9187 | ds_loss: 0.0000 | lr: 4.9999e-05 | scale: 65536.0000 | micro time: 1.914 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     60/ 13000 | global iter:     60/ 13000 | loss: 2.7703 | ds_loss: 0.0000 | lr: 4.9999e-05 | scale: 65536.0000 | micro time: 1.914 | step time: 1.834
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:     61/ 13000 | global iter:     61/ 13000 | loss: 2.8938 | ds_loss: 0.0000 | lr: 4.9999e-05 | scale: 65536.0000 | micro time: 1.851 | step time: 0.000
train | epoch   0 | Iter:     62/ 13000 | global iter:     62/ 13000 | loss: 2.8701 | ds_loss: 0.0000 | lr: 4.9998e-05 | scale: 65536.0000 | micro time: 1.789 | step time: 0.000
train | epoch   0 | Iter:     63/ 13000 | global iter:     63/ 13000 | loss: 3.0688 | ds_loss: 0.0000 | lr: 4.9998e-05 | scale: 65536.0000 | micro time: 1.730 | step time: 0.000
train | epoch   0 | Iter:     64/ 13000 | global iter:     64/ 13000 | loss: 2.7532 | ds_loss: 0.0000 | lr: 4.9998e-05 | scale: 65536.0000 | micro time: 1.777 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     64/ 13000 | global iter:     64/ 13000 | loss: 2.8965 | ds_loss: 0.0000 | lr: 4.9998e-05 | scale: 65536.0000 | micro time: 1.777 | step time: 1.787
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:     65/ 13000 | global iter:     65/ 13000 | loss: 2.4426 | ds_loss: 0.0000 | lr: 4.9998e-05 | scale: 65536.0000 | micro time: 1.814 | step time: 0.000
train | epoch   0 | Iter:     66/ 13000 | global iter:     66/ 13000 | loss: 2.9939 | ds_loss: 0.0000 | lr: 4.9998e-05 | scale: 65536.0000 | micro time: 1.799 | step time: 0.000
train | epoch   0 | Iter:     67/ 13000 | global iter:     67/ 13000 | loss: 3.2223 | ds_loss: 0.0000 | lr: 4.9998e-05 | scale: 65536.0000 | micro time: 1.807 | step time: 0.000
train | epoch   0 | Iter:     68/ 13000 | global iter:     68/ 13000 | loss: 2.9495 | ds_loss: 0.0000 | lr: 4.9998e-05 | scale: 65536.0000 | micro time: 1.773 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     68/ 13000 | global iter:     68/ 13000 | loss: 2.9021 | ds_loss: 0.0000 | lr: 4.9998e-05 | scale: 65536.0000 | micro time: 1.773 | step time: 1.798
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:     69/ 13000 | global iter:     69/ 13000 | loss: 2.4838 | ds_loss: 0.0000 | lr: 4.9998e-05 | scale: 65536.0000 | micro time: 1.754 | step time: 0.000
train | epoch   0 | Iter:     70/ 13000 | global iter:     70/ 13000 | loss: 3.3485 | ds_loss: 0.0000 | lr: 4.9998e-05 | scale: 65536.0000 | micro time: 1.830 | step time: 0.000
train | epoch   0 | Iter:     71/ 13000 | global iter:     71/ 13000 | loss: 3.0092 | ds_loss: 0.0000 | lr: 4.9998e-05 | scale: 65536.0000 | micro time: 1.876 | step time: 0.000
train | epoch   0 | Iter:     72/ 13000 | global iter:     72/ 13000 | loss: 3.5642 | ds_loss: 0.0000 | lr: 4.9998e-05 | scale: 65536.0000 | micro time: 1.866 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     72/ 13000 | global iter:     72/ 13000 | loss: 3.1014 | ds_loss: 0.0000 | lr: 4.9998e-05 | scale: 65536.0000 | micro time: 1.866 | step time: 1.831
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:     73/ 13000 | global iter:     73/ 13000 | loss: 2.9657 | ds_loss: 0.0000 | lr: 4.9998e-05 | scale: 65536.0000 | micro time: 1.687 | step time: 0.000
train | epoch   0 | Iter:     74/ 13000 | global iter:     74/ 13000 | loss: 3.4154 | ds_loss: 0.0000 | lr: 4.9998e-05 | scale: 65536.0000 | micro time: 1.779 | step time: 0.000
train | epoch   0 | Iter:     75/ 13000 | global iter:     75/ 13000 | loss: 2.1910 | ds_loss: 0.0000 | lr: 4.9997e-05 | scale: 65536.0000 | micro time: 1.727 | step time: 0.000
train | epoch   0 | Iter:     76/ 13000 | global iter:     76/ 13000 | loss: 2.9265 | ds_loss: 0.0000 | lr: 4.9997e-05 | scale: 65536.0000 | micro time: 1.864 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     76/ 13000 | global iter:     76/ 13000 | loss: 2.8747 | ds_loss: 0.0000 | lr: 4.9997e-05 | scale: 65536.0000 | micro time: 1.864 | step time: 1.764
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:     77/ 13000 | global iter:     77/ 13000 | loss: 3.1028 | ds_loss: 0.0000 | lr: 4.9997e-05 | scale: 65536.0000 | micro time: 1.822 | step time: 0.000
train | epoch   0 | Iter:     78/ 13000 | global iter:     78/ 13000 | loss: 2.9877 | ds_loss: 0.0000 | lr: 4.9997e-05 | scale: 65536.0000 | micro time: 1.707 | step time: 0.000
train | epoch   0 | Iter:     79/ 13000 | global iter:     79/ 13000 | loss: 2.5738 | ds_loss: 0.0000 | lr: 4.9997e-05 | scale: 65536.0000 | micro time: 1.827 | step time: 0.000
train | epoch   0 | Iter:     80/ 13000 | global iter:     80/ 13000 | loss: 2.2877 | ds_loss: 0.0000 | lr: 4.9997e-05 | scale: 65536.0000 | micro time: 1.703 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     80/ 13000 | global iter:     80/ 13000 | loss: 2.7380 | ds_loss: 0.0000 | lr: 4.9997e-05 | scale: 65536.0000 | micro time: 1.703 | step time: 1.765
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:     81/ 13000 | global iter:     81/ 13000 | loss: 3.3121 | ds_loss: 0.0000 | lr: 4.9997e-05 | scale: 65536.0000 | micro time: 1.802 | step time: 0.000
train | epoch   0 | Iter:     82/ 13000 | global iter:     82/ 13000 | loss: 3.1780 | ds_loss: 0.0000 | lr: 4.9997e-05 | scale: 65536.0000 | micro time: 1.800 | step time: 0.000
train | epoch   0 | Iter:     83/ 13000 | global iter:     83/ 13000 | loss: 3.2219 | ds_loss: 0.0000 | lr: 4.9997e-05 | scale: 65536.0000 | micro time: 1.846 | step time: 0.000
train | epoch   0 | Iter:     84/ 13000 | global iter:     84/ 13000 | loss: 3.2193 | ds_loss: 0.0000 | lr: 4.9997e-05 | scale: 65536.0000 | micro time: 1.703 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     84/ 13000 | global iter:     84/ 13000 | loss: 3.2328 | ds_loss: 0.0000 | lr: 4.9997e-05 | scale: 65536.0000 | micro time: 1.703 | step time: 1.788
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:     85/ 13000 | global iter:     85/ 13000 | loss: 2.8720 | ds_loss: 0.0000 | lr: 4.9997e-05 | scale: 65536.0000 | micro time: 1.810 | step time: 0.000
train | epoch   0 | Iter:     86/ 13000 | global iter:     86/ 13000 | loss: 2.9135 | ds_loss: 0.0000 | lr: 4.9996e-05 | scale: 65536.0000 | micro time: 1.825 | step time: 0.000
train | epoch   0 | Iter:     87/ 13000 | global iter:     87/ 13000 | loss: 3.2248 | ds_loss: 0.0000 | lr: 4.9996e-05 | scale: 65536.0000 | micro time: 1.776 | step time: 0.000
train | epoch   0 | Iter:     88/ 13000 | global iter:     88/ 13000 | loss: 2.5778 | ds_loss: 0.0000 | lr: 4.9996e-05 | scale: 65536.0000 | micro time: 1.795 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     88/ 13000 | global iter:     88/ 13000 | loss: 2.8970 | ds_loss: 0.0000 | lr: 4.9996e-05 | scale: 65536.0000 | micro time: 1.795 | step time: 1.802
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:     89/ 13000 | global iter:     89/ 13000 | loss: 2.3301 | ds_loss: 0.0000 | lr: 4.9996e-05 | scale: 65536.0000 | micro time: 1.830 | step time: 0.000
train | epoch   0 | Iter:     90/ 13000 | global iter:     90/ 13000 | loss: 2.4856 | ds_loss: 0.0000 | lr: 4.9996e-05 | scale: 65536.0000 | micro time: 1.760 | step time: 0.000
train | epoch   0 | Iter:     91/ 13000 | global iter:     91/ 13000 | loss: 2.7881 | ds_loss: 0.0000 | lr: 4.9996e-05 | scale: 65536.0000 | micro time: 1.746 | step time: 0.000
train | epoch   0 | Iter:     92/ 13000 | global iter:     92/ 13000 | loss: 2.7207 | ds_loss: 0.0000 | lr: 4.9996e-05 | scale: 65536.0000 | micro time: 1.775 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     92/ 13000 | global iter:     92/ 13000 | loss: 2.5811 | ds_loss: 0.0000 | lr: 4.9996e-05 | scale: 65536.0000 | micro time: 1.775 | step time: 1.778
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:     93/ 13000 | global iter:     93/ 13000 | loss: 2.4071 | ds_loss: 0.0000 | lr: 4.9996e-05 | scale: 65536.0000 | micro time: 1.874 | step time: 0.000
train | epoch   0 | Iter:     94/ 13000 | global iter:     94/ 13000 | loss: 2.9850 | ds_loss: 0.0000 | lr: 4.9996e-05 | scale: 65536.0000 | micro time: 1.695 | step time: 0.000
train | epoch   0 | Iter:     95/ 13000 | global iter:     95/ 13000 | loss: 2.9832 | ds_loss: 0.0000 | lr: 4.9995e-05 | scale: 65536.0000 | micro time: 1.783 | step time: 0.000
train | epoch   0 | Iter:     96/ 13000 | global iter:     96/ 13000 | loss: 2.4375 | ds_loss: 0.0000 | lr: 4.9995e-05 | scale: 65536.0000 | micro time: 1.715 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     96/ 13000 | global iter:     96/ 13000 | loss: 2.7032 | ds_loss: 0.0000 | lr: 4.9995e-05 | scale: 65536.0000 | micro time: 1.715 | step time: 1.767
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:     97/ 13000 | global iter:     97/ 13000 | loss: 2.9391 | ds_loss: 0.0000 | lr: 4.9995e-05 | scale: 65536.0000 | micro time: 1.738 | step time: 0.000
train | epoch   0 | Iter:     98/ 13000 | global iter:     98/ 13000 | loss: 2.1588 | ds_loss: 0.0000 | lr: 4.9995e-05 | scale: 65536.0000 | micro time: 1.766 | step time: 0.000
train | epoch   0 | Iter:     99/ 13000 | global iter:     99/ 13000 | loss: 3.2862 | ds_loss: 0.0000 | lr: 4.9995e-05 | scale: 65536.0000 | micro time: 1.844 | step time: 0.000
train | epoch   0 | Iter:    100/ 13000 | global iter:    100/ 13000 | loss: 3.1292 | ds_loss: 0.0000 | lr: 4.9995e-05 | scale: 65536.0000 | micro time: 1.739 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    100/ 13000 | global iter:    100/ 13000 | loss: 2.8783 | ds_loss: 0.0000 | lr: 4.9995e-05 | scale: 65536.0000 | micro time: 1.739 | step time: 1.772
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:    101/ 13000 | global iter:    101/ 13000 | loss: 3.2799 | ds_loss: 0.0000 | lr: 4.9995e-05 | scale: 65536.0000 | micro time: 1.762 | step time: 0.000
train | epoch   0 | Iter:    102/ 13000 | global iter:    102/ 13000 | loss: 2.7089 | ds_loss: 0.0000 | lr: 4.9995e-05 | scale: 65536.0000 | micro time: 1.827 | step time: 0.000
train | epoch   0 | Iter:    103/ 13000 | global iter:    103/ 13000 | loss: 2.2647 | ds_loss: 0.0000 | lr: 4.9994e-05 | scale: 65536.0000 | micro time: 1.847 | step time: 0.000
train | epoch   0 | Iter:    104/ 13000 | global iter:    104/ 13000 | loss: 3.3267 | ds_loss: 0.0000 | lr: 4.9994e-05 | scale: 65536.0000 | micro time: 1.844 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    104/ 13000 | global iter:    104/ 13000 | loss: 2.8951 | ds_loss: 0.0000 | lr: 4.9994e-05 | scale: 65536.0000 | micro time: 1.844 | step time: 1.820
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:    105/ 13000 | global iter:    105/ 13000 | loss: 2.9234 | ds_loss: 0.0000 | lr: 4.9994e-05 | scale: 65536.0000 | micro time: 1.720 | step time: 0.000
train | epoch   0 | Iter:    106/ 13000 | global iter:    106/ 13000 | loss: 2.6700 | ds_loss: 0.0000 | lr: 4.9994e-05 | scale: 65536.0000 | micro time: 1.835 | step time: 0.000
train | epoch   0 | Iter:    107/ 13000 | global iter:    107/ 13000 | loss: 2.9180 | ds_loss: 0.0000 | lr: 4.9994e-05 | scale: 65536.0000 | micro time: 1.739 | step time: 0.000
train | epoch   0 | Iter:    108/ 13000 | global iter:    108/ 13000 | loss: 3.1834 | ds_loss: 0.0000 | lr: 4.9994e-05 | scale: 65536.0000 | micro time: 1.846 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    108/ 13000 | global iter:    108/ 13000 | loss: 2.9237 | ds_loss: 0.0000 | lr: 4.9994e-05 | scale: 65536.0000 | micro time: 1.846 | step time: 1.785
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:    109/ 13000 | global iter:    109/ 13000 | loss: 3.0112 | ds_loss: 0.0000 | lr: 4.9994e-05 | scale: 65536.0000 | micro time: 1.693 | step time: 0.000
train | epoch   0 | Iter:    110/ 13000 | global iter:    110/ 13000 | loss: 2.9362 | ds_loss: 0.0000 | lr: 4.9994e-05 | scale: 65536.0000 | micro time: 1.871 | step time: 0.000
train | epoch   0 | Iter:    111/ 13000 | global iter:    111/ 13000 | loss: 2.3050 | ds_loss: 0.0000 | lr: 4.9993e-05 | scale: 65536.0000 | micro time: 1.843 | step time: 0.000
train | epoch   0 | Iter:    112/ 13000 | global iter:    112/ 13000 | loss: 2.1695 | ds_loss: 0.0000 | lr: 4.9993e-05 | scale: 65536.0000 | micro time: 1.823 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    112/ 13000 | global iter:    112/ 13000 | loss: 2.6055 | ds_loss: 0.0000 | lr: 4.9993e-05 | scale: 65536.0000 | micro time: 1.823 | step time: 1.807
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:    113/ 13000 | global iter:    113/ 13000 | loss: 2.2143 | ds_loss: 0.0000 | lr: 4.9993e-05 | scale: 65536.0000 | micro time: 1.798 | step time: 0.000
train | epoch   0 | Iter:    114/ 13000 | global iter:    114/ 13000 | loss: 2.8548 | ds_loss: 0.0000 | lr: 4.9993e-05 | scale: 65536.0000 | micro time: 1.786 | step time: 0.000
train | epoch   0 | Iter:    115/ 13000 | global iter:    115/ 13000 | loss: 3.2688 | ds_loss: 0.0000 | lr: 4.9993e-05 | scale: 65536.0000 | micro time: 1.923 | step time: 0.000
train | epoch   0 | Iter:    116/ 13000 | global iter:    116/ 13000 | loss: 2.7141 | ds_loss: 0.0000 | lr: 4.9993e-05 | scale: 65536.0000 | micro time: 1.715 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    116/ 13000 | global iter:    116/ 13000 | loss: 2.7630 | ds_loss: 0.0000 | lr: 4.9993e-05 | scale: 65536.0000 | micro time: 1.715 | step time: 1.805
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:    117/ 13000 | global iter:    117/ 13000 | loss: 2.2531 | ds_loss: 0.0000 | lr: 4.9993e-05 | scale: 65536.0000 | micro time: 1.763 | step time: 0.000
train | epoch   0 | Iter:    118/ 13000 | global iter:    118/ 13000 | loss: 3.1241 | ds_loss: 0.0000 | lr: 4.9992e-05 | scale: 65536.0000 | micro time: 1.729 | step time: 0.000
train | epoch   0 | Iter:    119/ 13000 | global iter:    119/ 13000 | loss: 2.8342 | ds_loss: 0.0000 | lr: 4.9992e-05 | scale: 65536.0000 | micro time: 1.836 | step time: 0.000
train | epoch   0 | Iter:    120/ 13000 | global iter:    120/ 13000 | loss: 2.8179 | ds_loss: 0.0000 | lr: 4.9992e-05 | scale: 65536.0000 | micro time: 1.855 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    120/ 13000 | global iter:    120/ 13000 | loss: 2.7573 | ds_loss: 0.0000 | lr: 4.9992e-05 | scale: 65536.0000 | micro time: 1.855 | step time: 1.796
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:    121/ 13000 | global iter:    121/ 13000 | loss: 3.3404 | ds_loss: 0.0000 | lr: 4.9992e-05 | scale: 65536.0000 | micro time: 1.848 | step time: 0.000
train | epoch   0 | Iter:    122/ 13000 | global iter:    122/ 13000 | loss: 2.9952 | ds_loss: 0.0000 | lr: 4.9992e-05 | scale: 65536.0000 | micro time: 1.863 | step time: 0.000
train | epoch   0 | Iter:    123/ 13000 | global iter:    123/ 13000 | loss: 2.5094 | ds_loss: 0.0000 | lr: 4.9992e-05 | scale: 65536.0000 | micro time: 1.775 | step time: 0.000
train | epoch   0 | Iter:    124/ 13000 | global iter:    124/ 13000 | loss: 2.8360 | ds_loss: 0.0000 | lr: 4.9992e-05 | scale: 65536.0000 | micro time: 1.808 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    124/ 13000 | global iter:    124/ 13000 | loss: 2.9203 | ds_loss: 0.0000 | lr: 4.9992e-05 | scale: 65536.0000 | micro time: 1.808 | step time: 1.824
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:    125/ 13000 | global iter:    125/ 13000 | loss: 3.4049 | ds_loss: 0.0000 | lr: 4.9991e-05 | scale: 65536.0000 | micro time: 1.839 | step time: 0.000
train | epoch   0 | Iter:    126/ 13000 | global iter:    126/ 13000 | loss: 2.1917 | ds_loss: 0.0000 | lr: 4.9991e-05 | scale: 65536.0000 | micro time: 1.783 | step time: 0.000
train | epoch   0 | Iter:    127/ 13000 | global iter:    127/ 13000 | loss: 3.3482 | ds_loss: 0.0000 | lr: 4.9991e-05 | scale: 65536.0000 | micro time: 1.789 | step time: 0.000
train | epoch   0 | Iter:    128/ 13000 | global iter:    128/ 13000 | loss: 2.2551 | ds_loss: 0.0000 | lr: 4.9991e-05 | scale: 65536.0000 | micro time: 1.723 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    128/ 13000 | global iter:    128/ 13000 | loss: 2.8000 | ds_loss: 0.0000 | lr: 4.9991e-05 | scale: 65536.0000 | micro time: 1.723 | step time: 1.783
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:    129/ 13000 | global iter:    129/ 13000 | loss: 2.2899 | ds_loss: 0.0000 | lr: 4.9991e-05 | scale: 65536.0000 | micro time: 1.739 | step time: 0.000
train | epoch   0 | Iter:    130/ 13000 | global iter:    130/ 13000 | loss: 2.2486 | ds_loss: 0.0000 | lr: 4.9991e-05 | scale: 65536.0000 | micro time: 1.759 | step time: 0.000
train | epoch   0 | Iter:    131/ 13000 | global iter:    131/ 13000 | loss: 2.8007 | ds_loss: 0.0000 | lr: 4.9990e-05 | scale: 65536.0000 | micro time: 1.799 | step time: 0.000
train | epoch   0 | Iter:    132/ 13000 | global iter:    132/ 13000 | loss: 3.0009 | ds_loss: 0.0000 | lr: 4.9990e-05 | scale: 65536.0000 | micro time: 1.855 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    132/ 13000 | global iter:    132/ 13000 | loss: 2.5850 | ds_loss: 0.0000 | lr: 4.9990e-05 | scale: 65536.0000 | micro time: 1.855 | step time: 1.788
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:    133/ 13000 | global iter:    133/ 13000 | loss: 3.3647 | ds_loss: 0.0000 | lr: 4.9990e-05 | scale: 65536.0000 | micro time: 1.747 | step time: 0.000
train | epoch   0 | Iter:    134/ 13000 | global iter:    134/ 13000 | loss: 2.5264 | ds_loss: 0.0000 | lr: 4.9990e-05 | scale: 65536.0000 | micro time: 1.687 | step time: 0.000
train | epoch   0 | Iter:    135/ 13000 | global iter:    135/ 13000 | loss: 3.1455 | ds_loss: 0.0000 | lr: 4.9990e-05 | scale: 65536.0000 | micro time: 1.875 | step time: 0.000
train | epoch   0 | Iter:    136/ 13000 | global iter:    136/ 13000 | loss: 3.0806 | ds_loss: 0.0000 | lr: 4.9990e-05 | scale: 65536.0000 | micro time: 1.831 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    136/ 13000 | global iter:    136/ 13000 | loss: 3.0293 | ds_loss: 0.0000 | lr: 4.9990e-05 | scale: 65536.0000 | micro time: 1.831 | step time: 1.785
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:    137/ 13000 | global iter:    137/ 13000 | loss: 2.8502 | ds_loss: 0.0000 | lr: 4.9989e-05 | scale: 65536.0000 | micro time: 1.846 | step time: 0.000
train | epoch   0 | Iter:    138/ 13000 | global iter:    138/ 13000 | loss: 2.6290 | ds_loss: 0.0000 | lr: 4.9989e-05 | scale: 65536.0000 | micro time: 1.743 | step time: 0.000
train | epoch   0 | Iter:    139/ 13000 | global iter:    139/ 13000 | loss: 3.0363 | ds_loss: 0.0000 | lr: 4.9989e-05 | scale: 65536.0000 | micro time: 1.863 | step time: 0.000
train | epoch   0 | Iter:    140/ 13000 | global iter:    140/ 13000 | loss: 2.7699 | ds_loss: 0.0000 | lr: 4.9989e-05 | scale: 65536.0000 | micro time: 1.883 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    140/ 13000 | global iter:    140/ 13000 | loss: 2.8214 | ds_loss: 0.0000 | lr: 4.9989e-05 | scale: 65536.0000 | micro time: 1.883 | step time: 1.834
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:    141/ 13000 | global iter:    141/ 13000 | loss: 2.6390 | ds_loss: 0.0000 | lr: 4.9989e-05 | scale: 65536.0000 | micro time: 1.822 | step time: 0.000
train | epoch   0 | Iter:    142/ 13000 | global iter:    142/ 13000 | loss: 2.7962 | ds_loss: 0.0000 | lr: 4.9988e-05 | scale: 65536.0000 | micro time: 1.799 | step time: 0.000
train | epoch   0 | Iter:    143/ 13000 | global iter:    143/ 13000 | loss: 2.7491 | ds_loss: 0.0000 | lr: 4.9988e-05 | scale: 65536.0000 | micro time: 1.952 | step time: 0.000
train | epoch   0 | Iter:    144/ 13000 | global iter:    144/ 13000 | loss: 2.3672 | ds_loss: 0.0000 | lr: 4.9988e-05 | scale: 65536.0000 | micro time: 1.842 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    144/ 13000 | global iter:    144/ 13000 | loss: 2.6379 | ds_loss: 0.0000 | lr: 4.9988e-05 | scale: 65536.0000 | micro time: 1.842 | step time: 1.854
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:    145/ 13000 | global iter:    145/ 13000 | loss: 2.8658 | ds_loss: 0.0000 | lr: 4.9988e-05 | scale: 65536.0000 | micro time: 1.836 | step time: 0.000
train | epoch   0 | Iter:    146/ 13000 | global iter:    146/ 13000 | loss: 3.0666 | ds_loss: 0.0000 | lr: 4.9988e-05 | scale: 65536.0000 | micro time: 1.830 | step time: 0.000
train | epoch   0 | Iter:    147/ 13000 | global iter:    147/ 13000 | loss: 2.6105 | ds_loss: 0.0000 | lr: 4.9987e-05 | scale: 65536.0000 | micro time: 1.801 | step time: 0.000
train | epoch   0 | Iter:    148/ 13000 | global iter:    148/ 13000 | loss: 3.0037 | ds_loss: 0.0000 | lr: 4.9987e-05 | scale: 65536.0000 | micro time: 1.865 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    148/ 13000 | global iter:    148/ 13000 | loss: 2.8866 | ds_loss: 0.0000 | lr: 4.9987e-05 | scale: 65536.0000 | micro time: 1.865 | step time: 1.833
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:    149/ 13000 | global iter:    149/ 13000 | loss: 2.8739 | ds_loss: 0.0000 | lr: 4.9987e-05 | scale: 65536.0000 | micro time: 1.829 | step time: 0.000
train | epoch   0 | Iter:    150/ 13000 | global iter:    150/ 13000 | loss: 2.8358 | ds_loss: 0.0000 | lr: 4.9987e-05 | scale: 65536.0000 | micro time: 1.738 | step time: 0.000
train | epoch   0 | Iter:    151/ 13000 | global iter:    151/ 13000 | loss: 2.6668 | ds_loss: 0.0000 | lr: 4.9987e-05 | scale: 65536.0000 | micro time: 1.859 | step time: 0.000
train | epoch   0 | Iter:    152/ 13000 | global iter:    152/ 13000 | loss: 3.1364 | ds_loss: 0.0000 | lr: 4.9987e-05 | scale: 65536.0000 | micro time: 1.787 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    152/ 13000 | global iter:    152/ 13000 | loss: 2.8782 | ds_loss: 0.0000 | lr: 4.9987e-05 | scale: 65536.0000 | micro time: 1.787 | step time: 1.803
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:    153/ 13000 | global iter:    153/ 13000 | loss: 2.6781 | ds_loss: 0.0000 | lr: 4.9986e-05 | scale: 65536.0000 | micro time: 1.767 | step time: 0.000
train | epoch   0 | Iter:    154/ 13000 | global iter:    154/ 13000 | loss: 3.2989 | ds_loss: 0.0000 | lr: 4.9986e-05 | scale: 65536.0000 | micro time: 1.835 | step time: 0.000
train | epoch   0 | Iter:    155/ 13000 | global iter:    155/ 13000 | loss: 2.6461 | ds_loss: 0.0000 | lr: 4.9986e-05 | scale: 65536.0000 | micro time: 1.804 | step time: 0.000
train | epoch   0 | Iter:    156/ 13000 | global iter:    156/ 13000 | loss: 2.9406 | ds_loss: 0.0000 | lr: 4.9986e-05 | scale: 65536.0000 | micro time: 1.806 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    156/ 13000 | global iter:    156/ 13000 | loss: 2.8909 | ds_loss: 0.0000 | lr: 4.9986e-05 | scale: 65536.0000 | micro time: 1.806 | step time: 1.803
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:    157/ 13000 | global iter:    157/ 13000 | loss: 2.5555 | ds_loss: 0.0000 | lr: 4.9986e-05 | scale: 65536.0000 | micro time: 1.794 | step time: 0.000
train | epoch   0 | Iter:    158/ 13000 | global iter:    158/ 13000 | loss: 3.0459 | ds_loss: 0.0000 | lr: 4.9985e-05 | scale: 65536.0000 | micro time: 1.849 | step time: 0.000
train | epoch   0 | Iter:    159/ 13000 | global iter:    159/ 13000 | loss: 3.4446 | ds_loss: 0.0000 | lr: 4.9985e-05 | scale: 65536.0000 | micro time: 1.863 | step time: 0.000
train | epoch   0 | Iter:    160/ 13000 | global iter:    160/ 13000 | loss: 2.3940 | ds_loss: 0.0000 | lr: 4.9985e-05 | scale: 65536.0000 | micro time: 1.815 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    160/ 13000 | global iter:    160/ 13000 | loss: 2.8600 | ds_loss: 0.0000 | lr: 4.9985e-05 | scale: 65536.0000 | micro time: 1.815 | step time: 1.830
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:    161/ 13000 | global iter:    161/ 13000 | loss: 2.9789 | ds_loss: 0.0000 | lr: 4.9985e-05 | scale: 65536.0000 | micro time: 1.795 | step time: 0.000
train | epoch   0 | Iter:    162/ 13000 | global iter:    162/ 13000 | loss: 3.3379 | ds_loss: 0.0000 | lr: 4.9984e-05 | scale: 65536.0000 | micro time: 1.771 | step time: 0.000
train | epoch   0 | Iter:    163/ 13000 | global iter:    163/ 13000 | loss: 2.6677 | ds_loss: 0.0000 | lr: 4.9984e-05 | scale: 65536.0000 | micro time: 1.799 | step time: 0.000
train | epoch   0 | Iter:    164/ 13000 | global iter:    164/ 13000 | loss: 2.6490 | ds_loss: 0.0000 | lr: 4.9984e-05 | scale: 65536.0000 | micro time: 1.871 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    164/ 13000 | global iter:    164/ 13000 | loss: 2.9084 | ds_loss: 0.0000 | lr: 4.9984e-05 | scale: 65536.0000 | micro time: 1.871 | step time: 1.809
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:    165/ 13000 | global iter:    165/ 13000 | loss: 2.9154 | ds_loss: 0.0000 | lr: 4.9984e-05 | scale: 65536.0000 | micro time: 1.731 | step time: 0.000
train | epoch   0 | Iter:    166/ 13000 | global iter:    166/ 13000 | loss: 3.0696 | ds_loss: 0.0000 | lr: 4.9984e-05 | scale: 65536.0000 | micro time: 1.738 | step time: 0.000
train | epoch   0 | Iter:    167/ 13000 | global iter:    167/ 13000 | loss: 2.9270 | ds_loss: 0.0000 | lr: 4.9983e-05 | scale: 65536.0000 | micro time: 1.779 | step time: 0.000
train | epoch   0 | Iter:    168/ 13000 | global iter:    168/ 13000 | loss: 2.7055 | ds_loss: 0.0000 | lr: 4.9983e-05 | scale: 65536.0000 | micro time: 1.715 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    168/ 13000 | global iter:    168/ 13000 | loss: 2.9044 | ds_loss: 0.0000 | lr: 4.9983e-05 | scale: 65536.0000 | micro time: 1.715 | step time: 1.741
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:    169/ 13000 | global iter:    169/ 13000 | loss: 2.7728 | ds_loss: 0.0000 | lr: 4.9983e-05 | scale: 65536.0000 | micro time: 1.842 | step time: 0.000
train | epoch   0 | Iter:    170/ 13000 | global iter:    170/ 13000 | loss: 2.3356 | ds_loss: 0.0000 | lr: 4.9983e-05 | scale: 65536.0000 | micro time: 1.803 | step time: 0.000
train | epoch   0 | Iter:    171/ 13000 | global iter:    171/ 13000 | loss: 2.5576 | ds_loss: 0.0000 | lr: 4.9982e-05 | scale: 65536.0000 | micro time: 1.731 | step time: 0.000
train | epoch   0 | Iter:    172/ 13000 | global iter:    172/ 13000 | loss: 3.0609 | ds_loss: 0.0000 | lr: 4.9982e-05 | scale: 65536.0000 | micro time: 1.813 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    172/ 13000 | global iter:    172/ 13000 | loss: 2.6817 | ds_loss: 0.0000 | lr: 4.9982e-05 | scale: 65536.0000 | micro time: 1.813 | step time: 1.797
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:    173/ 13000 | global iter:    173/ 13000 | loss: 2.1387 | ds_loss: 0.0000 | lr: 4.9982e-05 | scale: 65536.0000 | micro time: 1.751 | step time: 0.000
train | epoch   0 | Iter:    174/ 13000 | global iter:    174/ 13000 | loss: 3.2060 | ds_loss: 0.0000 | lr: 4.9982e-05 | scale: 65536.0000 | micro time: 1.727 | step time: 0.000
train | epoch   0 | Iter:    175/ 13000 | global iter:    175/ 13000 | loss: 3.0342 | ds_loss: 0.0000 | lr: 4.9982e-05 | scale: 65536.0000 | micro time: 1.867 | step time: 0.000
train | epoch   0 | Iter:    176/ 13000 | global iter:    176/ 13000 | loss: 2.6664 | ds_loss: 0.0000 | lr: 4.9981e-05 | scale: 65536.0000 | micro time: 1.803 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    176/ 13000 | global iter:    176/ 13000 | loss: 2.7613 | ds_loss: 0.0000 | lr: 4.9981e-05 | scale: 65536.0000 | micro time: 1.803 | step time: 1.787
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:    177/ 13000 | global iter:    177/ 13000 | loss: 2.2153 | ds_loss: 0.0000 | lr: 4.9981e-05 | scale: 65536.0000 | micro time: 1.770 | step time: 0.000
train | epoch   0 | Iter:    178/ 13000 | global iter:    178/ 13000 | loss: 2.2819 | ds_loss: 0.0000 | lr: 4.9981e-05 | scale: 65536.0000 | micro time: 1.707 | step time: 0.000
train | epoch   0 | Iter:    179/ 13000 | global iter:    179/ 13000 | loss: 3.2791 | ds_loss: 0.0000 | lr: 4.9981e-05 | scale: 65536.0000 | micro time: 1.835 | step time: 0.000
train | epoch   0 | Iter:    180/ 13000 | global iter:    180/ 13000 | loss: 2.5699 | ds_loss: 0.0000 | lr: 4.9980e-05 | scale: 65536.0000 | micro time: 1.765 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    180/ 13000 | global iter:    180/ 13000 | loss: 2.5866 | ds_loss: 0.0000 | lr: 4.9980e-05 | scale: 65536.0000 | micro time: 1.765 | step time: 1.769
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:    181/ 13000 | global iter:    181/ 13000 | loss: 2.4305 | ds_loss: 0.0000 | lr: 4.9980e-05 | scale: 65536.0000 | micro time: 1.739 | step time: 0.000
train | epoch   0 | Iter:    182/ 13000 | global iter:    182/ 13000 | loss: 2.5664 | ds_loss: 0.0000 | lr: 4.9980e-05 | scale: 65536.0000 | micro time: 1.863 | step time: 0.000
train | epoch   0 | Iter:    183/ 13000 | global iter:    183/ 13000 | loss: 2.7997 | ds_loss: 0.0000 | lr: 4.9980e-05 | scale: 65536.0000 | micro time: 1.764 | step time: 0.000
train | epoch   0 | Iter:    184/ 13000 | global iter:    184/ 13000 | loss: 2.7776 | ds_loss: 0.0000 | lr: 4.9979e-05 | scale: 65536.0000 | micro time: 1.796 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    184/ 13000 | global iter:    184/ 13000 | loss: 2.6435 | ds_loss: 0.0000 | lr: 4.9979e-05 | scale: 65536.0000 | micro time: 1.796 | step time: 1.791
./results/gpt2/train/sft/gpt2-xlarge-spanish/e10-bs2-lr5e-05-G1-N4-NN1
****************************************************************************************************
train | epoch   0 | Iter:    185/ 13000 | global iter:    185/ 13000 | loss: 3.2188 | ds_loss: 0.0000 | lr: 4.9979e-05 | scale: 65536.0000 | micro time: 1.702 | step time: 0.000
train | epoch   0 | Iter:    186/ 13000 | global iter:    186/ 13000 | loss: 3.0664 | ds_loss: 0.0000 | lr: 4.9979e-05 | scale: 65536.0000 | micro time: 1.775 | step time: 0.000
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** JOB 8864244 ON compsci-cluster-fitz-32 CANCELLED AT 2025-04-19T10:50:44 ***
slurmstepd: error: *** STEP 8864244.2 ON compsci-cluster-fitz-32 CANCELLED AT 2025-04-19T10:50:44 ***
