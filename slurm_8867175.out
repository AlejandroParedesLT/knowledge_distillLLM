compsci-cluster-fitz-15
Sun Apr 20 06:32:47 PM EDT 2025
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
The token `upload_files` has been saved to /dev/shm/hf-home/stored_tokens
Your token has been saved to /dev/shm/hf-home/token
Login successful.
The current active token is: `upload_files`
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2012 ./finetune.py --base-path . --model-path gpt2 --teacher-model-path ./results/gpt2/train/sft/gpt2-xlarge-SFT/e10-bs2-lr5e-05-G1-N4-NN1/10000 --ckpt-name gpt2-base --teacher-ckpt-name xlarge-sft --teacher-model-fp16 --n-gpu 4 --data-dir ./processed_data/pytorrent/full/gpt2 --num-workers 4 --dev-num 1000 --lr 0.0001 --batch-size 8 --eval-batch-size 8 --gradient-accumulation-steps 1 --warmup-iters 0 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --epochs 10 --kd-ratio 0.5 --max-length 512 --max-prompt-length 256 --do-train --do-valid --eval-gen --save-interval 4000 --eval-interval 4000 --log-interval 4 --mid-log-num 4 --save ./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/ --seed 10 --deepspeed --deepspeed_config ./configs/deepspeed/ds_config_zero1_fp16.json --type kd --do-sample --top-k 0 --top-p 1.0 --temperature 1.0
PYTHONPATH=.
W0420 18:32:51.132000 3537468 torch/distributed/run.py:792] 
W0420 18:32:51.132000 3537468 torch/distributed/run.py:792] *****************************************
W0420 18:32:51.132000 3537468 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0420 18:32:51.132000 3537468 torch/distributed/run.py:792] *****************************************
[2025-04-20 18:32:56,687] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-04-20 18:32:56,688] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-04-20 18:32:56,691] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-04-20 18:32:56,691] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /home/users/ap794/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /home/users/ap794/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /home/users/ap794/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /home/users/ap794/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
/home/users/ap794/final_project_distillLLM/venv/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/home/users/ap794/final_project_distillLLM/venv/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/home/users/ap794/final_project_distillLLM/venv/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/home/users/ap794/final_project_distillLLM/venv/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
using world size: 4
[2025-04-20 18:33:03,767] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-04-20 18:33:03,767] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_path ................... gpt2
  ckpt_name .................... gpt2-base
  model_type ................... gpt2
  teacher_model_type ........... None
  n_gpu ........................ 4
  n_nodes ...................... 1
  teacher_model_path ........... ./results/gpt2/train/sft/gpt2-xlarge-SFT/e10-bs2-lr5e-05-G1-N4-NN1/10000
  teacher_ckpt_name ............ xlarge-sft
  teacher_model_fp16 ........... True
  model_parallel ............... False
  model_parallel_size .......... None
  no_value ..................... False
  dropout_path_rate ............ None
  dtype ........................ torch.float16
  type ......................... kd
  do_train ..................... True
  do_valid ..................... True
  do_eval ...................... False
  base_path .................... .
  load ......................... None
  save ......................... ./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
  log_interval ................. 4
  mid_log_num .................. 4
  save_interval ................ 4000
  eval_interval ................ 4000
  local_rank ................... 0
  save_additional_suffix ....... 
  save_rollout ................. False
  eb_sample_times .............. 3
  data_dir ..................... ./processed_data/pytorrent/full/gpt2
  processed_data_dir ........... None
  force_process ................ False
  force_process_demo ........... False
  data_process_workers ......... -1
  train_num .................... -1
  train_ratio .................. 1
  dev_num ...................... 1000
  dev_ratio .................... 1
  gen_num ...................... -1
  data_names ................... None
  prompt_type .................. None
  num_workers .................. 4
  max_prompt_length ............ 256
  min_prompt_length ............ 128
  json_data .................... False
  bin_data ..................... False
  txt_data ..................... False
  prompt_data_dir .............. None
  lm_data_dir .................. None
  eval_ppl ..................... False
  eval_rw ...................... False
  eval_gen ..................... True
  only_prompt .................. False
  batch_size ................... 8
  eval_batch_size .............. 8
  clip_grad .................... 1.0
  total_iters .................. None
  train_iters_per_epoch ........ -1
  max_length ................... 512
  seed ......................... 10
  seed_order ................... 42
  seed_data .................... 42
  seed_ppo ..................... 42
  seed_lm ...................... 7
  epochs ....................... 10
  training_epochs .............. 10000
  gradient_accumulation_steps .. 1
  gradient_checkpointing ....... False
  attn_dtype ................... None
  lr ........................... 0.0001
  lr_min ....................... 1e-07
  weight_decay ................. 0.01
  loss_scale ................... 65536
  kd_ratio ..................... 0.5
  warmup_iters ................. 0
  lr_decay_iters ............... None
  lr_decay_style ............... cosine
  scheduler_name ............... constant_trm
  reward_scaling ............... None
  cliprange_reward ............. 1
  ppo_epochs ................... None
  num_rollouts ................. 256
  num_rollouts_per_device ...... None
  cliprange .................... 0.2
  chunk_size ................... None
  gamma ........................ 0.95
  length_norm .................. False
  single_step_reg .............. False
  teacher_mixed_alpha .......... None
  lm_coef ...................... 1
  top_k ........................ 0
  top_p ........................ 1.0
  do_sample .................... True
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  num_beams .................... 1
  temperature .................. 1.0
  peft ......................... None
  peft_lora_r .................. 8
  peft_lora_alpha .............. 32
  peft_lora_dropout ............ 0.1
  peft_name .................... None
  peft_path .................... None
  teacher_peft_name ............ None
  teacher_peft_path ............ None
  deepspeed .................... True
  deepspeed_config ............. ./configs/deepspeed/ds_config_zero1_fp16.json
  deepscale .................... False
  deepscale_config ............. None
  rank ......................... 0
  world_size ................... 4
[2025-04-20 18:33:04,067] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-04-20 18:33:04,341] [INFO] [comm.py:658:init_distributed] cdb=None
Sun Apr 20 18:33:03 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   18C    P8             17W /  230W |       4MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   20C    P0             22W /  230W |      25MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   25C    P0             20W /  230W |      19MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   25C    P0             25W /  230W |      25MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3         20MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3         12MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3         18MiB |
+-----------------------------------------------------------------------------------------+

[2025-04-20 18:33:04,349] [INFO] [comm.py:658:init_distributed] cdb=None
Sun Apr 20 18:33:04 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   19C    P8             18W /  230W |       4MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   21C    P2             32W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   26C    P2             28W /  230W |     209MiB /  24564MiB |      1%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   26C    P2             34W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

Sun Apr 20 18:33:04 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   18C    P8             20W /  230W |       4MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   21C    P2             50W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   26C    P2             46W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   26C    P2             53W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

Sun Apr 20 18:33:04 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   18C    P8             20W /  230W |       4MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   21C    P2             50W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   26C    P2             46W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   26C    P2             53W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

Sun Apr 20 18:33:04 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   18C    P8             20W /  230W |       4MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   21C    P2             50W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   26C    P2             46W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   26C    P2             64W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

Sun Apr 20 18:33:04 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   19C    P8             20W /  230W |       4MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   21C    P2             59W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   27C    P2             57W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   26C    P2             64W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

Probing Dataset
Probing end. Max data state 1, total length 499938
Sun Apr 20 18:33:06 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   19C    P8             18W /  230W |       4MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   21C    P2             58W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   27C    P2             57W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   27C    P2             64W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

Sun Apr 20 18:33:06 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   19C    P8             18W /  230W |       4MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   21C    P2             58W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   27C    P2             57W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   27C    P2             64W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

499938
Num LM instances: 499938
train num 499938
Probing Dataset
Probing end. Max data state 1, total length 1000
1000
Num LM instances: 1000
Train iters per epoch 15623
total_iters 156230
Sun Apr 20 18:33:17 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   18C    P8             17W /  230W |       4MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   23C    P2             58W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   28C    P2             56W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   28C    P2             62W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

Sun Apr 20 18:33:17 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   18C    P8             17W /  230W |       4MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   23C    P2             58W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   28C    P2             56W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   28C    P2             62W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

Sun Apr 20 18:33:17 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   18C    P8             17W /  230W |       4MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   23C    P2             58W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   28C    P2             56W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   28C    P2             62W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

Sun Apr 20 18:33:17 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   18C    P8             17W /  230W |       4MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   23C    P2             58W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   28C    P2             56W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   28C    P2             63W /  230W |     209MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3        202MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3        202MiB |
+-----------------------------------------------------------------------------------------+

[2025-04-20 18:33:23,858] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 4
[2025-04-20 18:33:23,862] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 4
[2025-04-20 18:33:23,885] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 4
 > number of parameters: 124439808
Model load time: 6.103396654129028s
Optimizer = AdamW
[2025-04-20 18:33:23,902] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed info: version=0.16.4, git-hash=unknown, git-branch=unknown
[2025-04-20 18:33:23,902] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 4
[2025-04-20 18:33:24,988] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-04-20 18:33:24,989] [INFO] [logging.py:128:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2025-04-20 18:33:24,990] [INFO] [logging.py:128:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-04-20 18:33:24,996] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2025-04-20 18:33:24,996] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2025-04-20 18:33:24,996] [INFO] [logging.py:128:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 1 optimizer
[2025-04-20 18:33:24,996] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 500000000
[2025-04-20 18:33:25,011] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 500000000
[2025-04-20 18:33:25,012] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2025-04-20 18:33:25,012] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2025-04-20 18:33:26,516] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[2025-04-20 18:33:26,518] [INFO] [utils.py:782:see_memory_usage] MA 0.36 GB         Max_MA 0.36 GB         CA 0.36 GB         Max_CA 0 GB 
[2025-04-20 18:33:26,525] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 19.36 GB, percent = 2.6%
[2025-04-20 18:33:27,146] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[2025-04-20 18:33:27,148] [INFO] [utils.py:782:see_memory_usage] MA 0.36 GB         Max_MA 0.48 GB         CA 0.48 GB         Max_CA 0 GB 
[2025-04-20 18:33:27,149] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 20.26 GB, percent = 2.7%
[2025-04-20 18:33:27,149] [INFO] [stage_1_and_2.py:550:__init__] optimizer state initialized
[2025-04-20 18:33:27,633] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[2025-04-20 18:33:27,634] [INFO] [utils.py:782:see_memory_usage] MA 0.36 GB         Max_MA 0.36 GB         CA 0.48 GB         Max_CA 0 GB 
[2025-04-20 18:33:27,635] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 19.63 GB, percent = 2.6%
[2025-04-20 18:33:27,637] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer
[2025-04-20 18:33:27,637] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2025-04-20 18:33:27,637] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7fd80ab65de0>
[2025-04-20 18:33:27,638] [INFO] [logging.py:128:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0001], mom=[(0.9, 0.999), (0.9, 0.999)]
[2025-04-20 18:33:27,639] [INFO] [config.py:1001:print] DeepSpeedEngine configuration:
[2025-04-20 18:33:27,639] [INFO] [config.py:1005:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-04-20 18:33:27,639] [INFO] [config.py:1005:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-04-20 18:33:27,640] [INFO] [config.py:1005:print]   amp_enabled .................. False
[2025-04-20 18:33:27,640] [INFO] [config.py:1005:print]   amp_params ................... False
[2025-04-20 18:33:27,640] [INFO] [config.py:1005:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-04-20 18:33:27,641] [INFO] [config.py:1005:print]   bfloat16_enabled ............. False
[2025-04-20 18:33:27,641] [INFO] [config.py:1005:print]   bfloat16_immediate_grad_update  False
[2025-04-20 18:33:27,641] [INFO] [config.py:1005:print]   checkpoint_parallel_write_pipeline  False
[2025-04-20 18:33:27,641] [INFO] [config.py:1005:print]   checkpoint_tag_validation_enabled  True
[2025-04-20 18:33:27,642] [INFO] [config.py:1005:print]   checkpoint_tag_validation_fail  False
[2025-04-20 18:33:27,642] [INFO] [config.py:1005:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fd7c8f341c0>
[2025-04-20 18:33:27,642] [INFO] [config.py:1005:print]   communication_data_type ...... None
[2025-04-20 18:33:27,642] [INFO] [config.py:1005:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-04-20 18:33:27,643] [INFO] [config.py:1005:print]   curriculum_enabled_legacy .... False
[2025-04-20 18:33:27,643] [INFO] [config.py:1005:print]   curriculum_params_legacy ..... False
[2025-04-20 18:33:27,656] [INFO] [config.py:1005:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-04-20 18:33:27,656] [INFO] [config.py:1005:print]   data_efficiency_enabled ...... False
[2025-04-20 18:33:27,656] [INFO] [config.py:1005:print]   dataloader_drop_last ......... False
[2025-04-20 18:33:27,656] [INFO] [config.py:1005:print]   disable_allgather ............ False
[2025-04-20 18:33:27,657] [INFO] [config.py:1005:print]   dump_state ................... False
[2025-04-20 18:33:27,657] [INFO] [config.py:1005:print]   dynamic_loss_scale_args ...... None
[2025-04-20 18:33:27,657] [INFO] [config.py:1005:print]   eigenvalue_enabled ........... False
[2025-04-20 18:33:27,657] [INFO] [config.py:1005:print]   eigenvalue_gas_boundary_resolution  1
[2025-04-20 18:33:27,657] [INFO] [config.py:1005:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-04-20 18:33:27,658] [INFO] [config.py:1005:print]   eigenvalue_layer_num ......... 0
[2025-04-20 18:33:27,658] [INFO] [config.py:1005:print]   eigenvalue_max_iter .......... 100
[2025-04-20 18:33:27,659] [INFO] [config.py:1005:print]   eigenvalue_stability ......... 1e-06
[2025-04-20 18:33:27,659] [INFO] [config.py:1005:print]   eigenvalue_tol ............... 0.01
[2025-04-20 18:33:27,659] [INFO] [config.py:1005:print]   eigenvalue_verbose ........... False
[2025-04-20 18:33:27,659] [INFO] [config.py:1005:print]   elasticity_enabled ........... False
[2025-04-20 18:33:27,659] [INFO] [config.py:1005:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-04-20 18:33:27,660] [INFO] [config.py:1005:print]   fp16_auto_cast ............... None
[2025-04-20 18:33:27,660] [INFO] [config.py:1005:print]   fp16_enabled ................. False
[2025-04-20 18:33:27,660] [INFO] [config.py:1005:print]   fp16_master_weights_and_gradients  False
[2025-04-20 18:33:27,660] [INFO] [config.py:1005:print]   global_rank .................. 0
[2025-04-20 18:33:27,660] [INFO] [config.py:1005:print]   grad_accum_dtype ............. None
[2025-04-20 18:33:27,660] [INFO] [config.py:1005:print]   gradient_accumulation_steps .. 1
[2025-04-20 18:33:27,661] [INFO] [config.py:1005:print]   gradient_clipping ............ 1.0
[2025-04-20 18:33:27,661] [INFO] [config.py:1005:print]   gradient_predivide_factor .... 1.0
[2025-04-20 18:33:27,661] [INFO] [config.py:1005:print]   graph_harvesting ............. False
[2025-04-20 18:33:27,661] [INFO] [config.py:1005:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-04-20 18:33:27,661] [INFO] [config.py:1005:print]   initial_dynamic_scale ........ 65536
[2025-04-20 18:33:27,661] [INFO] [config.py:1005:print]   load_universal_checkpoint .... False
[2025-04-20 18:33:27,661] [INFO] [config.py:1005:print]   loss_scale ................... 0
[2025-04-20 18:33:27,662] [INFO] [config.py:1005:print]   memory_breakdown ............. False
[2025-04-20 18:33:27,662] [INFO] [config.py:1005:print]   mics_hierarchial_params_gather  False
[2025-04-20 18:33:27,662] [INFO] [config.py:1005:print]   mics_shard_size .............. -1
[2025-04-20 18:33:27,662] [INFO] [config.py:1005:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2025-04-20 18:33:27,662] [INFO] [config.py:1005:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-04-20 18:33:27,663] [INFO] [config.py:1005:print]   optimizer_legacy_fusion ...... False
[2025-04-20 18:33:27,663] [INFO] [config.py:1005:print]   optimizer_name ............... None
[2025-04-20 18:33:27,663] [INFO] [config.py:1005:print]   optimizer_params ............. None
[2025-04-20 18:33:27,663] [INFO] [config.py:1005:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-04-20 18:33:27,663] [INFO] [config.py:1005:print]   pld_enabled .................. False
[2025-04-20 18:33:27,663] [INFO] [config.py:1005:print]   pld_params ................... False
[2025-04-20 18:33:27,663] [INFO] [config.py:1005:print]   prescale_gradients ........... False
[2025-04-20 18:33:27,664] [INFO] [config.py:1005:print]   scheduler_name ............... None
[2025-04-20 18:33:27,664] [INFO] [config.py:1005:print]   scheduler_params ............. None
[2025-04-20 18:33:27,664] [INFO] [config.py:1005:print]   seq_parallel_communication_data_type  torch.float32
[2025-04-20 18:33:27,664] [INFO] [config.py:1005:print]   sparse_attention ............. None
[2025-04-20 18:33:27,664] [INFO] [config.py:1005:print]   sparse_gradients_enabled ..... False
[2025-04-20 18:33:27,664] [INFO] [config.py:1005:print]   steps_per_print .............. 10000000
[2025-04-20 18:33:27,664] [INFO] [config.py:1005:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False
[2025-04-20 18:33:27,665] [INFO] [config.py:1005:print]   timers_config ................ enabled=True synchronized=True
[2025-04-20 18:33:27,665] [INFO] [config.py:1005:print]   train_batch_size ............. 32
[2025-04-20 18:33:27,665] [INFO] [config.py:1005:print]   train_micro_batch_size_per_gpu  8
[2025-04-20 18:33:27,665] [INFO] [config.py:1005:print]   use_data_before_expert_parallel_  False
[2025-04-20 18:33:27,665] [INFO] [config.py:1005:print]   use_node_local_storage ....... False
[2025-04-20 18:33:27,665] [INFO] [config.py:1005:print]   wall_clock_breakdown ......... False
[2025-04-20 18:33:27,665] [INFO] [config.py:1005:print]   weight_quantization_config ... None
[2025-04-20 18:33:27,666] [INFO] [config.py:1005:print]   world_size ................... 4
[2025-04-20 18:33:27,666] [INFO] [config.py:1005:print]   zero_allow_untested_optimizer  True
[2025-04-20 18:33:27,666] [INFO] [config.py:1005:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False
[2025-04-20 18:33:27,666] [INFO] [config.py:1005:print]   zero_enabled ................. True
[2025-04-20 18:33:27,666] [INFO] [config.py:1005:print]   zero_force_ds_cpu_optimizer .. True
[2025-04-20 18:33:27,666] [INFO] [config.py:1005:print]   zero_optimization_stage ...... 1
[2025-04-20 18:33:27,667] [INFO] [config.py:991:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 8, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 1
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": false, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1.000000e+07
}
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      | 377766 KiB | 377766 KiB |    791 MiB | 432422 KiB |
|       from large pool | 365117 KiB | 365117 KiB |    778 MiB | 431933 KiB |
|       from small pool |  12649 KiB |  12649 KiB |     12 MiB |    489 KiB |
|---------------------------------------------------------------------------|
| Active memory         | 377766 KiB | 377766 KiB |    791 MiB | 432422 KiB |
|       from large pool | 365117 KiB | 365117 KiB |    778 MiB | 431933 KiB |
|       from small pool |  12649 KiB |  12649 KiB |     12 MiB |    489 KiB |
|---------------------------------------------------------------------------|
| Requested memory      | 376857 KiB | 376857 KiB |    783 MiB | 425331 KiB |
|       from large pool | 364214 KiB | 364214 KiB |    770 MiB | 424916 KiB |
|       from small pool |  12643 KiB |  12643 KiB |     12 MiB |    415 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   | 503808 KiB | 503808 KiB |    806 MiB | 321536 KiB |
|       from large pool | 489472 KiB | 489472 KiB |    792 MiB | 321536 KiB |
|       from small pool |  14336 KiB |  14336 KiB |     14 MiB |      0 KiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   3161 KiB |   3161 KiB | 305770 KiB | 302609 KiB |
|       from large pool |   1475 KiB |   1475 KiB | 297094 KiB | 295619 KiB |
|       from small pool |   1686 KiB |   1686 KiB |   8676 KiB |   6990 KiB |
|---------------------------------------------------------------------------|
| Allocations           |      28    |      28    |     328    |     300    |
|       from large pool |       2    |       2    |      54    |      52    |
|       from small pool |      26    |      26    |     274    |     248    |
|---------------------------------------------------------------------------|
| Active allocs         |      28    |      28    |     328    |     300    |
|       from large pool |       2    |       2    |      54    |      52    |
|       from small pool |      26    |      26    |     274    |     248    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      10    |      10    |      21    |      11    |
|       from large pool |       3    |       3    |      14    |      11    |
|       from small pool |       7    |       7    |       7    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       6    |       6    |      80    |      74    |
|       from large pool |       1    |       1    |      23    |      22    |
|       from small pool |       5    |       5    |      57    |      52    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

 > number of parameters: 1557611200
Sun Apr 20 18:33:40 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   22C    P2             57W /  230W |    7131MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   24C    P2             58W /  230W |    7131MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   30C    P2             56W /  230W |    7179MiB /  24564MiB |      1%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   30C    P2             62W /  230W |    7131MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3537471      C   ...project_distillLLM/venv/bin/python3       7124MiB |
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3       7124MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3       7124MiB |
+-----------------------------------------------------------------------------------------+

Sun Apr 20 18:33:40 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   23C    P2             57W /  230W |    7179MiB /  24564MiB |      1%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   24C    P2             59W /  230W |    7179MiB /  24564MiB |      1%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   30C    P2             57W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   30C    P2             63W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3537471      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3       7172MiB |
+-----------------------------------------------------------------------------------------+

Start Fine-tuning
Sun Apr 20 18:33:40 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   23C    P2             58W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   24C    P2             59W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   30C    P2             57W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   30C    P2             64W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3537471      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3       7172MiB |
+-----------------------------------------------------------------------------------------+

Sun Apr 20 18:33:41 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   23C    P2             58W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   24C    P2             59W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   30C    P2             57W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   30C    P2             64W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3537471      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3       7172MiB |
+-----------------------------------------------------------------------------------------+

/home/users/ap794/final_project_distillLLM/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Sun Apr 20 18:33:41 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   23C    P2             58W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   25C    P2             59W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   30C    P2             57W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   30C    P2             64W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3537471      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3       7172MiB |
+-----------------------------------------------------------------------------------------+

Sun Apr 20 18:33:41 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   23C    P2             58W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   25C    P2             59W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   30C    P2             57W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   30C    P2             64W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3537471      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3       7172MiB |
+-----------------------------------------------------------------------------------------+

/home/users/ap794/final_project_distillLLM/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Sun Apr 20 18:33:41 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   23C    P2             58W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   24C    P2             59W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   30C    P2             57W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   30C    P2             64W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3537471      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3       7172MiB |
+-----------------------------------------------------------------------------------------+

Start Fine-tuning
/home/users/ap794/final_project_distillLLM/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Sun Apr 20 18:33:42 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   23C    P2             58W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   24C    P2             59W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   30C    P2             57W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   30C    P2             64W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3537471      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3       7172MiB |
+-----------------------------------------------------------------------------------------+

/home/users/ap794/final_project_distillLLM/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Sun Apr 20 18:33:42 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   23C    P2             58W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   24C    P2             59W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   30C    P2             57W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   30C    P2             65W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3537471      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3       7172MiB |
+-----------------------------------------------------------------------------------------+

dp size 4
/home/users/ap794/final_project_distillLLM/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Sun Apr 20 18:33:42 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   23C    P2             58W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   24C    P2             59W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   30C    P2             57W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   30C    P2             65W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3537471      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3       7172MiB |
+-----------------------------------------------------------------------------------------+
Sun Apr 20 18:33:42 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   23C    P2             58W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   24C    P2             59W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   30C    P2             57W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   30C    P2             65W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3537471      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3       7172MiB |
+-----------------------------------------------------------------------------------------+


/home/users/ap794/final_project_distillLLM/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]/home/users/ap794/final_project_distillLLM/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
0/32
Sun Apr 20 18:33:44 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   23C    P2             58W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   25C    P2             59W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   30C    P2             58W /  230W |    7189MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   30C    P2             64W /  230W |    7179MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3537471      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3       7172MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3       7182MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3       7172MiB |
+-----------------------------------------------------------------------------------------+

/home/users/ap794/final_project_distillLLM/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
1/32
2/32
3/32
4/32
5/32
6/32
7/32
8/32
9/32
10/32
11/32
12/32
13/32
14/32
15/32
Evaluating:   3%|         | 1/32 [00:08<04:21,  8.44s/it]Evaluating:   6%|         | 2/32 [00:13<03:19,  6.64s/it]Evaluating:   9%|         | 3/32 [00:19<02:55,  6.06s/it]Evaluating:  12%|        | 4/32 [00:24<02:42,  5.79s/it]Evaluating:  16%|        | 5/32 [00:29<02:32,  5.64s/it]Evaluating:  19%|        | 6/32 [00:35<02:24,  5.57s/it]Evaluating:  22%|       | 7/32 [00:40<02:17,  5.50s/it]Evaluating:  25%|       | 8/32 [00:46<02:10,  5.46s/it]Evaluating:  28%|       | 9/32 [00:51<02:05,  5.44s/it]Evaluating:  31%|      | 10/32 [00:56<01:59,  5.41s/it]Evaluating:  34%|      | 11/32 [01:02<01:53,  5.40s/it]Evaluating:  38%|      | 12/32 [01:07<01:48,  5.41s/it]Evaluating:  41%|      | 13/32 [01:12<01:42,  5.39s/it]Evaluating:  44%|     | 14/32 [01:18<01:36,  5.38s/it]Evaluating:  47%|     | 15/32 [01:23<01:31,  5.38s/it]Evaluating:  50%|     | 16/3216/32
17/32
18/32
19/32
20/32
21/32
22/32
23/32
24/32
25/32
26/32
27/32
28/32
29/32
 [01:29<01:25,  5.37s/it]Evaluating:  53%|    | 17/32 [01:34<01:20,  5.39s/it]Evaluating:  56%|    | 18/32 [01:39<01:15,  5.38s/it]Evaluating:  59%|    | 19/32 [01:45<01:09,  5.38s/it]Evaluating:  62%|   | 20/32 [01:50<01:04,  5.38s/it]Evaluating:  66%|   | 21/32 [01:55<00:59,  5.37s/it]Evaluating:  69%|   | 22/32 [02:01<00:53,  5.36s/it]Evaluating:  72%|  | 23/32 [02:06<00:48,  5.38s/it]Evaluating:  75%|  | 24/32 [02:12<00:42,  5.37s/it]Evaluating:  78%|  | 25/32 [02:17<00:37,  5.36s/it]Evaluating:  81%| | 26/32 [02:22<00:32,  5.36s/it]Evaluating:  84%| | 27/32 [02:28<00:26,  5.35s/it]Evaluating:  88%| | 28/32 [02:33<00:21,  5.36s/it]Evaluating:  91%| | 29/32 [02:38<00:16,  5.38s/it]Evaluating:  94%|30/32
31/32
| 30/32 [02:44<00:10,  5.37s/it]Evaluating:  97%|| 31/32 [02:49<00:05,  5.36s/it]Evaluating: 100%|| 32/32 [02:54<00:00,  5.36s/it]Evaluating: 100%|| 32/32 [02:55<00:00,  5.49s/it]
Sun Apr 20 18:36:39 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   30C    P2             76W /  230W |    8497MiB /  24564MiB |      7%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   31C    P2             61W /  230W |    8497MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   36C    P2             71W /  230W |    8497MiB /  24564MiB |      6%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   35C    P2             64W /  230W |    8497MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3537471      C   ...project_distillLLM/venv/bin/python3       8490MiB |
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3       8490MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3       8490MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3       8490MiB |
+-----------------------------------------------------------------------------------------+

/home/users/ap794/final_project_distillLLM/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Sun Apr 20 18:36:39 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   30C    P2             75W /  230W |    8497MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   31C    P2             61W /  230W |    8497MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   36C    P2             71W /  230W |    8497MiB /  24564MiB |      6%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   35C    P2             64W /  230W |    8497MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3537471      C   ...project_distillLLM/venv/bin/python3       8490MiB |
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3       8490MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3       8490MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3       8490MiB |
+-----------------------------------------------------------------------------------------+

/home/users/ap794/final_project_distillLLM/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Sun Apr 20 18:36:40 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   30C    P2             76W /  230W |    8497MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   31C    P2             61W /  230W |    8497MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   36C    P2             73W /  230W |    8497MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   35C    P2             64W /  230W |    8497MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3537471      C   ...project_distillLLM/venv/bin/python3       8490MiB |
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3       8490MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3       8490MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3       8490MiB |
+-----------------------------------------------------------------------------------------+

/home/users/ap794/final_project_distillLLM/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5/eval/0
dev | avg_loss: 2.75830078125 | {'exact_match': 0.0, 'rougeL': 5.9377}
Sun Apr 20 18:36:56 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               Off |   00000000:17:00.0 Off |                  Off |
| 30%   28C    P5             57W /  230W |    8497MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               Off |   00000000:31:00.0 Off |                  Off |
| 30%   33C    P2             88W /  230W |   15771MiB /  24564MiB |    100%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               Off |   00000000:B1:00.0 Off |                  Off |
| 30%   38C    P2             84W /  230W |   15771MiB /  24564MiB |    100%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               Off |   00000000:CA:00.0 Off |                  Off |
| 30%   38C    P2             94W /  230W |   15771MiB /  24564MiB |    100%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   3537471      C   ...project_distillLLM/venv/bin/python3       8490MiB |
|    1   N/A  N/A   3537472      C   ...project_distillLLM/venv/bin/python3      15764MiB |
|    2   N/A  N/A   3537473      C   ...project_distillLLM/venv/bin/python3      15764MiB |
|    3   N/A  N/A   3537474      C   ...project_distillLLM/venv/bin/python3      15764MiB |
+-----------------------------------------------------------------------------------------+

/home/users/ap794/final_project_distillLLM/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[2025-04-20 18:36:59,332] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648
train | epoch   0 | Iter:      1/156230 | global iter:      1/156230 | loss: 3.0979 | ds_loss: 3.1315 | lr: 1.0000e-04 | scale: 2147483648.0000 | micro time: 1.531 | step time: 0.000
[2025-04-20 18:37:00,630] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648, reducing to 1073741824
train | epoch   0 | Iter:      2/156230 | global iter:      2/156230 | loss: 2.9206 | ds_loss: 2.9438 | lr: 1.0000e-04 | scale: 1073741824.0000 | micro time: 1.280 | step time: 0.000
[2025-04-20 18:37:01,936] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1073741824, reducing to 536870912
train | epoch   0 | Iter:      3/156230 | global iter:      3/156230 | loss: 2.7751 | ds_loss: 2.7902 | lr: 1.0000e-04 | scale: 536870912.0000 | micro time: 1.296 | step time: 0.000
[2025-04-20 18:37:03,232] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 536870912, reducing to 268435456
train | epoch   0 | Iter:      4/156230 | global iter:      4/156230 | loss: 2.8923 | ds_loss: 2.9080 | lr: 1.0000e-04 | scale: 268435456.0000 | micro time: 1.274 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:      4/156230 | global iter:      4/156230 | loss: 2.9215 | ds_loss: 2.9434 | lr: 1.0000e-04 | scale: 268435456.0000 | micro time: 1.274 | step time: 1.345
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
[2025-04-20 18:37:04,519] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 268435456, reducing to 134217728
train | epoch   0 | Iter:      5/156230 | global iter:      5/156230 | loss: 2.9496 | ds_loss: 2.9624 | lr: 1.0000e-04 | scale: 134217728.0000 | micro time: 1.259 | step time: 0.000
[2025-04-20 18:37:05,791] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 134217728, reducing to 67108864
train | epoch   0 | Iter:      6/156230 | global iter:      6/156230 | loss: 2.8020 | ds_loss: 2.8324 | lr: 1.0000e-04 | scale: 67108864.0000 | micro time: 1.288 | step time: 0.000
[2025-04-20 18:37:07,075] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 67108864, reducing to 33554432
train | epoch   0 | Iter:      7/156230 | global iter:      7/156230 | loss: 2.9814 | ds_loss: 2.9809 | lr: 1.0000e-04 | scale: 33554432.0000 | micro time: 1.284 | step time: 0.000
[2025-04-20 18:37:08,342] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 33554432, reducing to 16777216
train | epoch   0 | Iter:      8/156230 | global iter:      8/156230 | loss: 2.8808 | ds_loss: 2.9148 | lr: 1.0000e-04 | scale: 16777216.0000 | micro time: 1.257 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:      8/156230 | global iter:      8/156230 | loss: 2.9034 | ds_loss: 2.9226 | lr: 1.0000e-04 | scale: 16777216.0000 | micro time: 1.257 | step time: 1.272
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
[2025-04-20 18:37:09,651] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16777216, reducing to 8388608
train | epoch   0 | Iter:      9/156230 | global iter:      9/156230 | loss: 2.8336 | ds_loss: 2.8595 | lr: 1.0000e-04 | scale: 8388608.0000 | micro time: 1.292 | step time: 0.000
[2025-04-20 18:37:10,950] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608, reducing to 4194304
train | epoch   0 | Iter:     10/156230 | global iter:     10/156230 | loss: 3.1329 | ds_loss: 3.1395 | lr: 1.0000e-04 | scale: 4194304.0000 | micro time: 1.283 | step time: 0.000
[2025-04-20 18:37:12,284] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152
train | epoch   0 | Iter:     11/156230 | global iter:     11/156230 | loss: 2.9819 | ds_loss: 3.0192 | lr: 1.0000e-04 | scale: 2097152.0000 | micro time: 1.358 | step time: 0.000
[2025-04-20 18:37:13,588] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2097152, reducing to 1048576
train | epoch   0 | Iter:     12/156230 | global iter:     12/156230 | loss: 2.9589 | ds_loss: 2.9922 | lr: 1.0000e-04 | scale: 1048576.0000 | micro time: 1.261 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     12/156230 | global iter:     12/156230 | loss: 2.9768 | ds_loss: 3.0026 | lr: 1.0000e-04 | scale: 1048576.0000 | micro time: 1.261 | step time: 1.299
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
[2025-04-20 18:37:14,901] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1048576, reducing to 524288
train | epoch   0 | Iter:     13/156230 | global iter:     13/156230 | loss: 3.0216 | ds_loss: 3.0405 | lr: 1.0000e-04 | scale: 524288.0000 | micro time: 1.306 | step time: 0.000
[2025-04-20 18:37:16,202] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 524288, reducing to 262144
train | epoch   0 | Iter:     14/156230 | global iter:     14/156230 | loss: 3.0014 | ds_loss: 3.0203 | lr: 1.0000e-04 | scale: 262144.0000 | micro time: 1.295 | step time: 0.000
[2025-04-20 18:37:17,479] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 262144, reducing to 131072
train | epoch   0 | Iter:     15/156230 | global iter:     15/156230 | loss: 2.9135 | ds_loss: 2.9411 | lr: 1.0000e-04 | scale: 131072.0000 | micro time: 1.268 | step time: 0.000
[2025-04-20 18:37:18,783] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 131072, reducing to 65536
train | epoch   0 | Iter:     16/156230 | global iter:     16/156230 | loss: 2.9729 | ds_loss: 2.9951 | lr: 1.0000e-04 | scale: 65536.0000 | micro time: 1.299 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     16/156230 | global iter:     16/156230 | loss: 2.9773 | ds_loss: 2.9993 | lr: 1.0000e-04 | scale: 65536.0000 | micro time: 1.299 | step time: 1.292
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
[2025-04-20 18:37:20,067] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768
train | epoch   0 | Iter:     17/156230 | global iter:     17/156230 | loss: 3.0419 | ds_loss: 3.0616 | lr: 1.0000e-04 | scale: 32768.0000 | micro time: 1.260 | step time: 0.000
[2025-04-20 18:37:21,387] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 32768, reducing to 16384
train | epoch   0 | Iter:     18/156230 | global iter:     18/156230 | loss: 3.0937 | ds_loss: 3.1118 | lr: 1.0000e-04 | scale: 16384.0000 | micro time: 1.320 | step time: 0.000
[2025-04-20 18:37:22,707] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16384, reducing to 8192
train | epoch   0 | Iter:     19/156230 | global iter:     19/156230 | loss: 2.9510 | ds_loss: 2.9863 | lr: 1.0000e-04 | scale:  8192.0000 | micro time: 1.304 | step time: 0.000
[2025-04-20 18:37:24,007] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8192, reducing to 4096
train | epoch   0 | Iter:     20/156230 | global iter:     20/156230 | loss: 2.9643 | ds_loss: 3.0066 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.303 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     20/156230 | global iter:     20/156230 | loss: 3.0127 | ds_loss: 3.0416 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.303 | step time: 1.297
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:     21/156230 | global iter:     21/156230 | loss: 2.8643 | ds_loss: 2.8704 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.536 | step time: 0.000
train | epoch   0 | Iter:     22/156230 | global iter:     22/156230 | loss: 2.6349 | ds_loss: 2.6665 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:     23/156230 | global iter:     23/156230 | loss: 2.4333 | ds_loss: 2.4423 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:     24/156230 | global iter:     24/156230 | loss: 2.0850 | ds_loss: 2.0895 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     24/156230 | global iter:     24/156230 | loss: 2.5043 | ds_loss: 2.5172 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.361 | step time: 1.399
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:     25/156230 | global iter:     25/156230 | loss: 1.9825 | ds_loss: 2.0118 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:     26/156230 | global iter:     26/156230 | loss: 2.0816 | ds_loss: 2.0882 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:     27/156230 | global iter:     27/156230 | loss: 1.9802 | ds_loss: 1.9946 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:     28/156230 | global iter:     28/156230 | loss: 1.8893 | ds_loss: 1.9138 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.325 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     28/156230 | global iter:     28/156230 | loss: 1.9834 | ds_loss: 2.0021 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.325 | step time: 1.330
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:     29/156230 | global iter:     29/156230 | loss: 1.8442 | ds_loss: 1.8535 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:     30/156230 | global iter:     30/156230 | loss: 1.7154 | ds_loss: 1.7334 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:     31/156230 | global iter:     31/156230 | loss: 1.8064 | ds_loss: 1.8128 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:     32/156230 | global iter:     32/156230 | loss: 1.8677 | ds_loss: 1.8908 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.339 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     32/156230 | global iter:     32/156230 | loss: 1.8084 | ds_loss: 1.8226 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.339 | step time: 1.343
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:     33/156230 | global iter:     33/156230 | loss: 1.7456 | ds_loss: 1.7473 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:     34/156230 | global iter:     34/156230 | loss: 1.8925 | ds_loss: 1.9002 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:     35/156230 | global iter:     35/156230 | loss: 1.6161 | ds_loss: 1.6469 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:     36/156230 | global iter:     36/156230 | loss: 1.8015 | ds_loss: 1.8152 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.324 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     36/156230 | global iter:     36/156230 | loss: 1.7639 | ds_loss: 1.7774 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.324 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:     37/156230 | global iter:     37/156230 | loss: 1.8059 | ds_loss: 1.8299 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:     38/156230 | global iter:     38/156230 | loss: 1.7638 | ds_loss: 1.7796 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:     39/156230 | global iter:     39/156230 | loss: 1.6399 | ds_loss: 1.6531 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:     40/156230 | global iter:     40/156230 | loss: 1.6482 | ds_loss: 1.6626 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.339 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     40/156230 | global iter:     40/156230 | loss: 1.7145 | ds_loss: 1.7313 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.339 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:     41/156230 | global iter:     41/156230 | loss: 1.5862 | ds_loss: 1.6076 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:     42/156230 | global iter:     42/156230 | loss: 1.6294 | ds_loss: 1.6419 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:     43/156230 | global iter:     43/156230 | loss: 1.6653 | ds_loss: 1.6704 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:     44/156230 | global iter:     44/156230 | loss: 1.7576 | ds_loss: 1.7799 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     44/156230 | global iter:     44/156230 | loss: 1.6596 | ds_loss: 1.6750 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.400 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:     45/156230 | global iter:     45/156230 | loss: 1.6098 | ds_loss: 1.6324 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.318 | step time: 0.000
train | epoch   0 | Iter:     46/156230 | global iter:     46/156230 | loss: 1.6535 | ds_loss: 1.6642 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:     47/156230 | global iter:     47/156230 | loss: 1.6995 | ds_loss: 1.7056 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:     48/156230 | global iter:     48/156230 | loss: 1.5640 | ds_loss: 1.5678 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     48/156230 | global iter:     48/156230 | loss: 1.6317 | ds_loss: 1.6425 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.368 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:     49/156230 | global iter:     49/156230 | loss: 1.8274 | ds_loss: 1.8420 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:     50/156230 | global iter:     50/156230 | loss: 1.6279 | ds_loss: 1.6474 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:     51/156230 | global iter:     51/156230 | loss: 1.6032 | ds_loss: 1.6171 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:     52/156230 | global iter:     52/156230 | loss: 1.6707 | ds_loss: 1.6929 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     52/156230 | global iter:     52/156230 | loss: 1.6823 | ds_loss: 1.6999 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.364 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:     53/156230 | global iter:     53/156230 | loss: 1.5629 | ds_loss: 1.5610 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:     54/156230 | global iter:     54/156230 | loss: 1.6660 | ds_loss: 1.6843 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:     55/156230 | global iter:     55/156230 | loss: 1.3587 | ds_loss: 1.3754 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:     56/156230 | global iter:     56/156230 | loss: 1.6749 | ds_loss: 1.6907 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     56/156230 | global iter:     56/156230 | loss: 1.5656 | ds_loss: 1.5778 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.377 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:     57/156230 | global iter:     57/156230 | loss: 1.6548 | ds_loss: 1.6936 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:     58/156230 | global iter:     58/156230 | loss: 1.4705 | ds_loss: 1.4772 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:     59/156230 | global iter:     59/156230 | loss: 1.5783 | ds_loss: 1.5893 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:     60/156230 | global iter:     60/156230 | loss: 1.5178 | ds_loss: 1.5298 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.341 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     60/156230 | global iter:     60/156230 | loss: 1.5553 | ds_loss: 1.5725 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.341 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:     61/156230 | global iter:     61/156230 | loss: 1.5578 | ds_loss: 1.5723 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:     62/156230 | global iter:     62/156230 | loss: 1.6115 | ds_loss: 1.6243 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:     63/156230 | global iter:     63/156230 | loss: 1.6149 | ds_loss: 1.6360 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:     64/156230 | global iter:     64/156230 | loss: 1.6814 | ds_loss: 1.6990 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.327 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     64/156230 | global iter:     64/156230 | loss: 1.6164 | ds_loss: 1.6329 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.327 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:     65/156230 | global iter:     65/156230 | loss: 1.4939 | ds_loss: 1.4895 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:     66/156230 | global iter:     66/156230 | loss: 1.5684 | ds_loss: 1.5726 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.420 | step time: 0.000
train | epoch   0 | Iter:     67/156230 | global iter:     67/156230 | loss: 1.5107 | ds_loss: 1.5370 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:     68/156230 | global iter:     68/156230 | loss: 1.4678 | ds_loss: 1.4783 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     68/156230 | global iter:     68/156230 | loss: 1.5102 | ds_loss: 1.5194 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.360 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:     69/156230 | global iter:     69/156230 | loss: 1.6475 | ds_loss: 1.6662 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:     70/156230 | global iter:     70/156230 | loss: 1.4516 | ds_loss: 1.4582 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:     71/156230 | global iter:     71/156230 | loss: 1.4775 | ds_loss: 1.4896 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.413 | step time: 0.000
train | epoch   0 | Iter:     72/156230 | global iter:     72/156230 | loss: 1.5985 | ds_loss: 1.5976 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.338 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     72/156230 | global iter:     72/156230 | loss: 1.5438 | ds_loss: 1.5529 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.338 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:     73/156230 | global iter:     73/156230 | loss: 1.5031 | ds_loss: 1.5209 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:     74/156230 | global iter:     74/156230 | loss: 1.5067 | ds_loss: 1.5081 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:     75/156230 | global iter:     75/156230 | loss: 1.5595 | ds_loss: 1.5657 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:     76/156230 | global iter:     76/156230 | loss: 1.6025 | ds_loss: 1.6031 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.372 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     76/156230 | global iter:     76/156230 | loss: 1.5429 | ds_loss: 1.5495 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.372 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:     77/156230 | global iter:     77/156230 | loss: 1.5982 | ds_loss: 1.6092 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:     78/156230 | global iter:     78/156230 | loss: 1.5688 | ds_loss: 1.5934 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:     79/156230 | global iter:     79/156230 | loss: 1.4868 | ds_loss: 1.4931 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:     80/156230 | global iter:     80/156230 | loss: 1.5559 | ds_loss: 1.5539 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     80/156230 | global iter:     80/156230 | loss: 1.5524 | ds_loss: 1.5624 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.376 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:     81/156230 | global iter:     81/156230 | loss: 1.5238 | ds_loss: 1.5373 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:     82/156230 | global iter:     82/156230 | loss: 1.6783 | ds_loss: 1.6936 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.427 | step time: 0.000
train | epoch   0 | Iter:     83/156230 | global iter:     83/156230 | loss: 1.5699 | ds_loss: 1.5929 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:     84/156230 | global iter:     84/156230 | loss: 1.5866 | ds_loss: 1.6109 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     84/156230 | global iter:     84/156230 | loss: 1.5896 | ds_loss: 1.6087 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.362 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:     85/156230 | global iter:     85/156230 | loss: 1.4976 | ds_loss: 1.4951 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:     86/156230 | global iter:     86/156230 | loss: 1.5531 | ds_loss: 1.5605 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:     87/156230 | global iter:     87/156230 | loss: 1.4548 | ds_loss: 1.4629 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:     88/156230 | global iter:     88/156230 | loss: 1.4942 | ds_loss: 1.5287 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.335 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     88/156230 | global iter:     88/156230 | loss: 1.4999 | ds_loss: 1.5118 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.335 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:     89/156230 | global iter:     89/156230 | loss: 1.5414 | ds_loss: 1.5571 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:     90/156230 | global iter:     90/156230 | loss: 1.5911 | ds_loss: 1.6070 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:     91/156230 | global iter:     91/156230 | loss: 1.6680 | ds_loss: 1.6616 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:     92/156230 | global iter:     92/156230 | loss: 1.5784 | ds_loss: 1.5826 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.371 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     92/156230 | global iter:     92/156230 | loss: 1.5947 | ds_loss: 1.6021 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.371 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:     93/156230 | global iter:     93/156230 | loss: 1.7135 | ds_loss: 1.7320 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.320 | step time: 0.000
train | epoch   0 | Iter:     94/156230 | global iter:     94/156230 | loss: 1.6108 | ds_loss: 1.6333 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:     95/156230 | global iter:     95/156230 | loss: 1.3388 | ds_loss: 1.3624 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.404 | step time: 0.000
train | epoch   0 | Iter:     96/156230 | global iter:     96/156230 | loss: 1.4276 | ds_loss: 1.4241 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.336 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:     96/156230 | global iter:     96/156230 | loss: 1.5227 | ds_loss: 1.5379 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.336 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:     97/156230 | global iter:     97/156230 | loss: 1.3853 | ds_loss: 1.3948 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:     98/156230 | global iter:     98/156230 | loss: 1.5902 | ds_loss: 1.5823 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:     99/156230 | global iter:     99/156230 | loss: 1.5535 | ds_loss: 1.5756 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:    100/156230 | global iter:    100/156230 | loss: 1.3680 | ds_loss: 1.3989 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    100/156230 | global iter:    100/156230 | loss: 1.4743 | ds_loss: 1.4879 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.381 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    101/156230 | global iter:    101/156230 | loss: 1.4306 | ds_loss: 1.4369 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:    102/156230 | global iter:    102/156230 | loss: 1.3902 | ds_loss: 1.3992 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:    103/156230 | global iter:    103/156230 | loss: 1.5151 | ds_loss: 1.5264 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.432 | step time: 0.000
train | epoch   0 | Iter:    104/156230 | global iter:    104/156230 | loss: 1.5941 | ds_loss: 1.5864 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    104/156230 | global iter:    104/156230 | loss: 1.4825 | ds_loss: 1.4872 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.373 | step time: 1.393
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    105/156230 | global iter:    105/156230 | loss: 1.4210 | ds_loss: 1.4427 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:    106/156230 | global iter:    106/156230 | loss: 1.5938 | ds_loss: 1.5963 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:    107/156230 | global iter:    107/156230 | loss: 1.4071 | ds_loss: 1.4152 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:    108/156230 | global iter:    108/156230 | loss: 1.4358 | ds_loss: 1.4159 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.383 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    108/156230 | global iter:    108/156230 | loss: 1.4644 | ds_loss: 1.4675 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.383 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    109/156230 | global iter:    109/156230 | loss: 1.4200 | ds_loss: 1.4377 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:    110/156230 | global iter:    110/156230 | loss: 1.3908 | ds_loss: 1.4063 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:    111/156230 | global iter:    111/156230 | loss: 1.4223 | ds_loss: 1.4521 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.409 | step time: 0.000
train | epoch   0 | Iter:    112/156230 | global iter:    112/156230 | loss: 1.5012 | ds_loss: 1.5270 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    112/156230 | global iter:    112/156230 | loss: 1.4336 | ds_loss: 1.4558 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.361 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    113/156230 | global iter:    113/156230 | loss: 1.3196 | ds_loss: 1.3284 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:    114/156230 | global iter:    114/156230 | loss: 1.5393 | ds_loss: 1.5664 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:    115/156230 | global iter:    115/156230 | loss: 1.4870 | ds_loss: 1.5078 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:    116/156230 | global iter:    116/156230 | loss: 1.4065 | ds_loss: 1.4321 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    116/156230 | global iter:    116/156230 | loss: 1.4381 | ds_loss: 1.4587 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.365 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    117/156230 | global iter:    117/156230 | loss: 1.5445 | ds_loss: 1.5574 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:    118/156230 | global iter:    118/156230 | loss: 1.5667 | ds_loss: 1.5738 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:    119/156230 | global iter:    119/156230 | loss: 1.5864 | ds_loss: 1.5923 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:    120/156230 | global iter:    120/156230 | loss: 1.4512 | ds_loss: 1.4686 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    120/156230 | global iter:    120/156230 | loss: 1.5372 | ds_loss: 1.5480 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.369 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    121/156230 | global iter:    121/156230 | loss: 1.4057 | ds_loss: 1.4236 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:    122/156230 | global iter:    122/156230 | loss: 1.4131 | ds_loss: 1.4222 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:    123/156230 | global iter:    123/156230 | loss: 1.5380 | ds_loss: 1.5505 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:    124/156230 | global iter:    124/156230 | loss: 1.2891 | ds_loss: 1.2913 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    124/156230 | global iter:    124/156230 | loss: 1.4115 | ds_loss: 1.4219 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.364 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    125/156230 | global iter:    125/156230 | loss: 1.5058 | ds_loss: 1.5235 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.403 | step time: 0.000
train | epoch   0 | Iter:    126/156230 | global iter:    126/156230 | loss: 1.5452 | ds_loss: 1.5564 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:    127/156230 | global iter:    127/156230 | loss: 1.4022 | ds_loss: 1.4174 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:    128/156230 | global iter:    128/156230 | loss: 1.5227 | ds_loss: 1.5416 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.384 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    128/156230 | global iter:    128/156230 | loss: 1.4940 | ds_loss: 1.5097 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.384 | step time: 1.382
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    129/156230 | global iter:    129/156230 | loss: 1.4612 | ds_loss: 1.4729 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:    130/156230 | global iter:    130/156230 | loss: 1.4659 | ds_loss: 1.4769 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:    131/156230 | global iter:    131/156230 | loss: 1.4190 | ds_loss: 1.4192 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:    132/156230 | global iter:    132/156230 | loss: 1.4563 | ds_loss: 1.4907 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    132/156230 | global iter:    132/156230 | loss: 1.4506 | ds_loss: 1.4649 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.373 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    133/156230 | global iter:    133/156230 | loss: 1.4384 | ds_loss: 1.4568 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:    134/156230 | global iter:    134/156230 | loss: 1.4947 | ds_loss: 1.5197 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:    135/156230 | global iter:    135/156230 | loss: 1.3177 | ds_loss: 1.3363 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:    136/156230 | global iter:    136/156230 | loss: 1.4915 | ds_loss: 1.5189 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    136/156230 | global iter:    136/156230 | loss: 1.4356 | ds_loss: 1.4579 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.355 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    137/156230 | global iter:    137/156230 | loss: 1.5234 | ds_loss: 1.5240 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:    138/156230 | global iter:    138/156230 | loss: 1.4671 | ds_loss: 1.4710 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:    139/156230 | global iter:    139/156230 | loss: 1.5134 | ds_loss: 1.5349 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:    140/156230 | global iter:    140/156230 | loss: 1.4598 | ds_loss: 1.4714 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.388 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    140/156230 | global iter:    140/156230 | loss: 1.4909 | ds_loss: 1.5003 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.388 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    141/156230 | global iter:    141/156230 | loss: 1.3147 | ds_loss: 1.3205 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:    142/156230 | global iter:    142/156230 | loss: 1.3707 | ds_loss: 1.3734 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:    143/156230 | global iter:    143/156230 | loss: 1.5680 | ds_loss: 1.5564 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:    144/156230 | global iter:    144/156230 | loss: 1.3822 | ds_loss: 1.3914 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.356 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    144/156230 | global iter:    144/156230 | loss: 1.4089 | ds_loss: 1.4104 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.356 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    145/156230 | global iter:    145/156230 | loss: 1.4611 | ds_loss: 1.4903 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:    146/156230 | global iter:    146/156230 | loss: 1.3426 | ds_loss: 1.3646 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:    147/156230 | global iter:    147/156230 | loss: 1.5918 | ds_loss: 1.5990 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:    148/156230 | global iter:    148/156230 | loss: 1.6578 | ds_loss: 1.6549 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.372 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    148/156230 | global iter:    148/156230 | loss: 1.5133 | ds_loss: 1.5272 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.372 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    149/156230 | global iter:    149/156230 | loss: 1.4968 | ds_loss: 1.4967 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:    150/156230 | global iter:    150/156230 | loss: 1.5017 | ds_loss: 1.5001 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:    151/156230 | global iter:    151/156230 | loss: 1.5018 | ds_loss: 1.5067 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:    152/156230 | global iter:    152/156230 | loss: 1.4587 | ds_loss: 1.4592 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.338 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    152/156230 | global iter:    152/156230 | loss: 1.4897 | ds_loss: 1.4907 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.338 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    153/156230 | global iter:    153/156230 | loss: 1.3800 | ds_loss: 1.3898 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:    154/156230 | global iter:    154/156230 | loss: 1.4435 | ds_loss: 1.4510 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:    155/156230 | global iter:    155/156230 | loss: 1.7060 | ds_loss: 1.7099 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.416 | step time: 0.000
train | epoch   0 | Iter:    156/156230 | global iter:    156/156230 | loss: 1.5173 | ds_loss: 1.5025 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    156/156230 | global iter:    156/156230 | loss: 1.5117 | ds_loss: 1.5133 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.385 | step time: 1.385
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    157/156230 | global iter:    157/156230 | loss: 1.3354 | ds_loss: 1.3604 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:    158/156230 | global iter:    158/156230 | loss: 1.4197 | ds_loss: 1.4414 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:    159/156230 | global iter:    159/156230 | loss: 1.4130 | ds_loss: 1.4164 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:    160/156230 | global iter:    160/156230 | loss: 1.4976 | ds_loss: 1.5042 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    160/156230 | global iter:    160/156230 | loss: 1.4164 | ds_loss: 1.4306 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.373 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    161/156230 | global iter:    161/156230 | loss: 1.2985 | ds_loss: 1.2872 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:    162/156230 | global iter:    162/156230 | loss: 1.2988 | ds_loss: 1.2901 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:    163/156230 | global iter:    163/156230 | loss: 1.4610 | ds_loss: 1.4632 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:    164/156230 | global iter:    164/156230 | loss: 1.3913 | ds_loss: 1.3957 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.384 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    164/156230 | global iter:    164/156230 | loss: 1.3624 | ds_loss: 1.3591 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.384 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    165/156230 | global iter:    165/156230 | loss: 1.4261 | ds_loss: 1.4432 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:    166/156230 | global iter:    166/156230 | loss: 1.6089 | ds_loss: 1.6124 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:    167/156230 | global iter:    167/156230 | loss: 1.4068 | ds_loss: 1.4115 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:    168/156230 | global iter:    168/156230 | loss: 1.4698 | ds_loss: 1.4804 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    168/156230 | global iter:    168/156230 | loss: 1.4779 | ds_loss: 1.4869 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.365 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    169/156230 | global iter:    169/156230 | loss: 1.4838 | ds_loss: 1.5040 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:    170/156230 | global iter:    170/156230 | loss: 1.4340 | ds_loss: 1.4431 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:    171/156230 | global iter:    171/156230 | loss: 1.4372 | ds_loss: 1.4430 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:    172/156230 | global iter:    172/156230 | loss: 1.3756 | ds_loss: 1.3783 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    172/156230 | global iter:    172/156230 | loss: 1.4327 | ds_loss: 1.4421 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.385 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    173/156230 | global iter:    173/156230 | loss: 1.2978 | ds_loss: 1.2973 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:    174/156230 | global iter:    174/156230 | loss: 1.3894 | ds_loss: 1.4025 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:    175/156230 | global iter:    175/156230 | loss: 1.4266 | ds_loss: 1.4244 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:    176/156230 | global iter:    176/156230 | loss: 1.5159 | ds_loss: 1.5263 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.389 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    176/156230 | global iter:    176/156230 | loss: 1.4074 | ds_loss: 1.4126 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.389 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    177/156230 | global iter:    177/156230 | loss: 1.4201 | ds_loss: 1.4367 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:    178/156230 | global iter:    178/156230 | loss: 1.2936 | ds_loss: 1.3182 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:    179/156230 | global iter:    179/156230 | loss: 1.4533 | ds_loss: 1.4520 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:    180/156230 | global iter:    180/156230 | loss: 1.3684 | ds_loss: 1.3782 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    180/156230 | global iter:    180/156230 | loss: 1.3838 | ds_loss: 1.3963 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.376 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    181/156230 | global iter:    181/156230 | loss: 1.4672 | ds_loss: 1.4677 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:    182/156230 | global iter:    182/156230 | loss: 1.3822 | ds_loss: 1.3664 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:    183/156230 | global iter:    183/156230 | loss: 1.5055 | ds_loss: 1.5273 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:    184/156230 | global iter:    184/156230 | loss: 1.5182 | ds_loss: 1.5210 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    184/156230 | global iter:    184/156230 | loss: 1.4683 | ds_loss: 1.4706 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.368 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    185/156230 | global iter:    185/156230 | loss: 1.4227 | ds_loss: 1.4327 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:    186/156230 | global iter:    186/156230 | loss: 1.4532 | ds_loss: 1.4657 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:    187/156230 | global iter:    187/156230 | loss: 1.4226 | ds_loss: 1.4393 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:    188/156230 | global iter:    188/156230 | loss: 1.2982 | ds_loss: 1.2916 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    188/156230 | global iter:    188/156230 | loss: 1.3991 | ds_loss: 1.4073 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.357 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    189/156230 | global iter:    189/156230 | loss: 1.3702 | ds_loss: 1.3910 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:    190/156230 | global iter:    190/156230 | loss: 1.3017 | ds_loss: 1.3298 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:    191/156230 | global iter:    191/156230 | loss: 1.2690 | ds_loss: 1.2799 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:    192/156230 | global iter:    192/156230 | loss: 1.4746 | ds_loss: 1.4819 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.336 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    192/156230 | global iter:    192/156230 | loss: 1.3539 | ds_loss: 1.3707 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.336 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    193/156230 | global iter:    193/156230 | loss: 1.3477 | ds_loss: 1.3518 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:    194/156230 | global iter:    194/156230 | loss: 1.3981 | ds_loss: 1.4082 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:    195/156230 | global iter:    195/156230 | loss: 1.3832 | ds_loss: 1.3930 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:    196/156230 | global iter:    196/156230 | loss: 1.3424 | ds_loss: 1.3408 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.405 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    196/156230 | global iter:    196/156230 | loss: 1.3678 | ds_loss: 1.3734 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.405 | step time: 1.380
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    197/156230 | global iter:    197/156230 | loss: 1.4852 | ds_loss: 1.4837 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:    198/156230 | global iter:    198/156230 | loss: 1.4568 | ds_loss: 1.4573 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:    199/156230 | global iter:    199/156230 | loss: 1.3508 | ds_loss: 1.3369 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.406 | step time: 0.000
train | epoch   0 | Iter:    200/156230 | global iter:    200/156230 | loss: 1.3366 | ds_loss: 1.3590 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.313 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    200/156230 | global iter:    200/156230 | loss: 1.4074 | ds_loss: 1.4092 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.313 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    201/156230 | global iter:    201/156230 | loss: 1.5801 | ds_loss: 1.5987 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:    202/156230 | global iter:    202/156230 | loss: 1.5110 | ds_loss: 1.5164 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:    203/156230 | global iter:    203/156230 | loss: 1.4615 | ds_loss: 1.4773 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:    204/156230 | global iter:    204/156230 | loss: 1.5338 | ds_loss: 1.5516 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    204/156230 | global iter:    204/156230 | loss: 1.5216 | ds_loss: 1.5360 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.369 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    205/156230 | global iter:    205/156230 | loss: 1.4708 | ds_loss: 1.4709 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:    206/156230 | global iter:    206/156230 | loss: 1.5823 | ds_loss: 1.5903 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:    207/156230 | global iter:    207/156230 | loss: 1.5693 | ds_loss: 1.5820 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:    208/156230 | global iter:    208/156230 | loss: 1.3895 | ds_loss: 1.3992 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    208/156230 | global iter:    208/156230 | loss: 1.5030 | ds_loss: 1.5106 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.357 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    209/156230 | global iter:    209/156230 | loss: 1.3378 | ds_loss: 1.3540 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:    210/156230 | global iter:    210/156230 | loss: 1.3382 | ds_loss: 1.3312 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:    211/156230 | global iter:    211/156230 | loss: 1.4222 | ds_loss: 1.4393 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:    212/156230 | global iter:    212/156230 | loss: 1.3371 | ds_loss: 1.3319 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.404 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    212/156230 | global iter:    212/156230 | loss: 1.3588 | ds_loss: 1.3641 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.404 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    213/156230 | global iter:    213/156230 | loss: 1.4204 | ds_loss: 1.4341 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:    214/156230 | global iter:    214/156230 | loss: 1.4736 | ds_loss: 1.4718 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:    215/156230 | global iter:    215/156230 | loss: 1.4550 | ds_loss: 1.4660 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:    216/156230 | global iter:    216/156230 | loss: 1.3745 | ds_loss: 1.3891 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    216/156230 | global iter:    216/156230 | loss: 1.4309 | ds_loss: 1.4402 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.362 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    217/156230 | global iter:    217/156230 | loss: 1.5397 | ds_loss: 1.5511 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:    218/156230 | global iter:    218/156230 | loss: 1.3313 | ds_loss: 1.3424 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.404 | step time: 0.000
train | epoch   0 | Iter:    219/156230 | global iter:    219/156230 | loss: 1.2840 | ds_loss: 1.2976 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:    220/156230 | global iter:    220/156230 | loss: 1.4726 | ds_loss: 1.4808 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    220/156230 | global iter:    220/156230 | loss: 1.4069 | ds_loss: 1.4180 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.370 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    221/156230 | global iter:    221/156230 | loss: 1.3729 | ds_loss: 1.3730 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:    222/156230 | global iter:    222/156230 | loss: 1.4556 | ds_loss: 1.4805 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:    223/156230 | global iter:    223/156230 | loss: 1.4110 | ds_loss: 1.4307 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:    224/156230 | global iter:    224/156230 | loss: 1.3828 | ds_loss: 1.3931 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.348 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    224/156230 | global iter:    224/156230 | loss: 1.4056 | ds_loss: 1.4193 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.348 | step time: 1.345
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    225/156230 | global iter:    225/156230 | loss: 1.4835 | ds_loss: 1.4943 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:    226/156230 | global iter:    226/156230 | loss: 1.4095 | ds_loss: 1.3993 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:    227/156230 | global iter:    227/156230 | loss: 1.3044 | ds_loss: 1.3160 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:    228/156230 | global iter:    228/156230 | loss: 1.5703 | ds_loss: 1.5692 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.371 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    228/156230 | global iter:    228/156230 | loss: 1.4419 | ds_loss: 1.4447 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.371 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    229/156230 | global iter:    229/156230 | loss: 1.3025 | ds_loss: 1.3099 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:    230/156230 | global iter:    230/156230 | loss: 1.3633 | ds_loss: 1.3754 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:    231/156230 | global iter:    231/156230 | loss: 1.4872 | ds_loss: 1.5037 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.416 | step time: 0.000
train | epoch   0 | Iter:    232/156230 | global iter:    232/156230 | loss: 1.4298 | ds_loss: 1.4400 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.340 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    232/156230 | global iter:    232/156230 | loss: 1.3957 | ds_loss: 1.4072 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.340 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    233/156230 | global iter:    233/156230 | loss: 1.4501 | ds_loss: 1.4812 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:    234/156230 | global iter:    234/156230 | loss: 1.4612 | ds_loss: 1.4760 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:    235/156230 | global iter:    235/156230 | loss: 1.4779 | ds_loss: 1.4934 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:    236/156230 | global iter:    236/156230 | loss: 1.3783 | ds_loss: 1.3791 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    236/156230 | global iter:    236/156230 | loss: 1.4419 | ds_loss: 1.4574 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.349 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    237/156230 | global iter:    237/156230 | loss: 1.4032 | ds_loss: 1.4146 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:    238/156230 | global iter:    238/156230 | loss: 1.3397 | ds_loss: 1.3572 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:    239/156230 | global iter:    239/156230 | loss: 1.4394 | ds_loss: 1.4431 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:    240/156230 | global iter:    240/156230 | loss: 1.3476 | ds_loss: 1.3547 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.403 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    240/156230 | global iter:    240/156230 | loss: 1.3825 | ds_loss: 1.3924 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.403 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    241/156230 | global iter:    241/156230 | loss: 1.4195 | ds_loss: 1.4189 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:    242/156230 | global iter:    242/156230 | loss: 1.3675 | ds_loss: 1.3655 | lr: 1.0000e-04 | scale:  4096.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:    243/156230 | global iter:    243/156230 | loss: 1.4848 | ds_loss: 1.4796 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:    244/156230 | global iter:    244/156230 | loss: 1.3487 | ds_loss: 1.3590 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    244/156230 | global iter:    244/156230 | loss: 1.4051 | ds_loss: 1.4057 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    245/156230 | global iter:    245/156230 | loss: 1.3350 | ds_loss: 1.3342 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:    246/156230 | global iter:    246/156230 | loss: 1.2717 | ds_loss: 1.2699 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:    247/156230 | global iter:    247/156230 | loss: 1.3899 | ds_loss: 1.4233 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:    248/156230 | global iter:    248/156230 | loss: 1.4424 | ds_loss: 1.4605 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    248/156230 | global iter:    248/156230 | loss: 1.3598 | ds_loss: 1.3720 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.366 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    249/156230 | global iter:    249/156230 | loss: 1.4321 | ds_loss: 1.4269 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:    250/156230 | global iter:    250/156230 | loss: 1.3855 | ds_loss: 1.4025 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:    251/156230 | global iter:    251/156230 | loss: 1.3572 | ds_loss: 1.3678 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:    252/156230 | global iter:    252/156230 | loss: 1.1667 | ds_loss: 1.1695 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.340 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    252/156230 | global iter:    252/156230 | loss: 1.3354 | ds_loss: 1.3417 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.340 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    253/156230 | global iter:    253/156230 | loss: 1.3429 | ds_loss: 1.3330 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:    254/156230 | global iter:    254/156230 | loss: 1.3298 | ds_loss: 1.3346 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:    255/156230 | global iter:    255/156230 | loss: 1.3693 | ds_loss: 1.3690 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.405 | step time: 0.000
train | epoch   0 | Iter:    256/156230 | global iter:    256/156230 | loss: 1.2753 | ds_loss: 1.3028 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    256/156230 | global iter:    256/156230 | loss: 1.3293 | ds_loss: 1.3348 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.353 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    257/156230 | global iter:    257/156230 | loss: 1.3472 | ds_loss: 1.3590 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:    258/156230 | global iter:    258/156230 | loss: 1.4494 | ds_loss: 1.4735 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:    259/156230 | global iter:    259/156230 | loss: 1.3349 | ds_loss: 1.3410 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:    260/156230 | global iter:    260/156230 | loss: 1.2379 | ds_loss: 1.2530 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    260/156230 | global iter:    260/156230 | loss: 1.3423 | ds_loss: 1.3566 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.396 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    261/156230 | global iter:    261/156230 | loss: 1.4464 | ds_loss: 1.4620 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:    262/156230 | global iter:    262/156230 | loss: 1.4536 | ds_loss: 1.4736 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:    263/156230 | global iter:    263/156230 | loss: 1.5357 | ds_loss: 1.5408 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:    264/156230 | global iter:    264/156230 | loss: 1.4729 | ds_loss: 1.4788 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    264/156230 | global iter:    264/156230 | loss: 1.4772 | ds_loss: 1.4888 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    265/156230 | global iter:    265/156230 | loss: 1.4725 | ds_loss: 1.4732 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:    266/156230 | global iter:    266/156230 | loss: 1.2143 | ds_loss: 1.2335 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:    267/156230 | global iter:    267/156230 | loss: 1.3301 | ds_loss: 1.3409 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:    268/156230 | global iter:    268/156230 | loss: 1.4386 | ds_loss: 1.4480 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    268/156230 | global iter:    268/156230 | loss: 1.3639 | ds_loss: 1.3739 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    269/156230 | global iter:    269/156230 | loss: 1.5279 | ds_loss: 1.5392 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:    270/156230 | global iter:    270/156230 | loss: 1.4345 | ds_loss: 1.4345 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:    271/156230 | global iter:    271/156230 | loss: 1.4633 | ds_loss: 1.4722 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:    272/156230 | global iter:    272/156230 | loss: 1.3078 | ds_loss: 1.3084 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    272/156230 | global iter:    272/156230 | loss: 1.4334 | ds_loss: 1.4386 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.368 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    273/156230 | global iter:    273/156230 | loss: 1.4343 | ds_loss: 1.4330 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:    274/156230 | global iter:    274/156230 | loss: 1.4332 | ds_loss: 1.4270 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:    275/156230 | global iter:    275/156230 | loss: 1.4392 | ds_loss: 1.4557 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:    276/156230 | global iter:    276/156230 | loss: 1.2853 | ds_loss: 1.2968 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.379 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    276/156230 | global iter:    276/156230 | loss: 1.3980 | ds_loss: 1.4031 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.379 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    277/156230 | global iter:    277/156230 | loss: 1.3692 | ds_loss: 1.3696 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:    278/156230 | global iter:    278/156230 | loss: 1.4073 | ds_loss: 1.4125 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:    279/156230 | global iter:    279/156230 | loss: 1.3925 | ds_loss: 1.4028 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:    280/156230 | global iter:    280/156230 | loss: 1.2466 | ds_loss: 1.2422 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.325 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    280/156230 | global iter:    280/156230 | loss: 1.3539 | ds_loss: 1.3568 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.325 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    281/156230 | global iter:    281/156230 | loss: 1.4141 | ds_loss: 1.4306 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.409 | step time: 0.000
train | epoch   0 | Iter:    282/156230 | global iter:    282/156230 | loss: 1.2280 | ds_loss: 1.2356 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.306 | step time: 0.000
train | epoch   0 | Iter:    283/156230 | global iter:    283/156230 | loss: 1.3959 | ds_loss: 1.4092 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.322 | step time: 0.000
train | epoch   0 | Iter:    284/156230 | global iter:    284/156230 | loss: 1.3792 | ds_loss: 1.3825 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    284/156230 | global iter:    284/156230 | loss: 1.3543 | ds_loss: 1.3645 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    285/156230 | global iter:    285/156230 | loss: 1.4448 | ds_loss: 1.4456 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:    286/156230 | global iter:    286/156230 | loss: 1.3519 | ds_loss: 1.3535 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.415 | step time: 0.000
train | epoch   0 | Iter:    287/156230 | global iter:    287/156230 | loss: 1.3743 | ds_loss: 1.3940 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:    288/156230 | global iter:    288/156230 | loss: 1.4673 | ds_loss: 1.4738 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    288/156230 | global iter:    288/156230 | loss: 1.4096 | ds_loss: 1.4167 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.373 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    289/156230 | global iter:    289/156230 | loss: 1.4421 | ds_loss: 1.4459 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:    290/156230 | global iter:    290/156230 | loss: 1.4444 | ds_loss: 1.4607 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:    291/156230 | global iter:    291/156230 | loss: 1.3289 | ds_loss: 1.3320 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:    292/156230 | global iter:    292/156230 | loss: 1.3108 | ds_loss: 1.3102 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    292/156230 | global iter:    292/156230 | loss: 1.3815 | ds_loss: 1.3872 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.354 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    293/156230 | global iter:    293/156230 | loss: 1.4759 | ds_loss: 1.4632 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:    294/156230 | global iter:    294/156230 | loss: 1.3720 | ds_loss: 1.3753 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:    295/156230 | global iter:    295/156230 | loss: 1.2726 | ds_loss: 1.2955 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:    296/156230 | global iter:    296/156230 | loss: 1.4474 | ds_loss: 1.4748 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.339 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    296/156230 | global iter:    296/156230 | loss: 1.3920 | ds_loss: 1.4022 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.339 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    297/156230 | global iter:    297/156230 | loss: 1.2608 | ds_loss: 1.2700 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:    298/156230 | global iter:    298/156230 | loss: 1.3471 | ds_loss: 1.3757 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:    299/156230 | global iter:    299/156230 | loss: 1.2520 | ds_loss: 1.2780 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:    300/156230 | global iter:    300/156230 | loss: 1.4186 | ds_loss: 1.4119 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.335 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    300/156230 | global iter:    300/156230 | loss: 1.3196 | ds_loss: 1.3339 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.335 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    301/156230 | global iter:    301/156230 | loss: 1.3792 | ds_loss: 1.4101 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.404 | step time: 0.000
train | epoch   0 | Iter:    302/156230 | global iter:    302/156230 | loss: 1.3585 | ds_loss: 1.3698 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:    303/156230 | global iter:    303/156230 | loss: 1.4541 | ds_loss: 1.4631 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:    304/156230 | global iter:    304/156230 | loss: 1.4337 | ds_loss: 1.4264 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.328 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    304/156230 | global iter:    304/156230 | loss: 1.4064 | ds_loss: 1.4173 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.328 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    305/156230 | global iter:    305/156230 | loss: 1.4916 | ds_loss: 1.4975 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:    306/156230 | global iter:    306/156230 | loss: 1.4538 | ds_loss: 1.4700 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.401 | step time: 0.000
train | epoch   0 | Iter:    307/156230 | global iter:    307/156230 | loss: 1.5262 | ds_loss: 1.5380 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:    308/156230 | global iter:    308/156230 | loss: 1.3265 | ds_loss: 1.3240 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.317 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    308/156230 | global iter:    308/156230 | loss: 1.4495 | ds_loss: 1.4574 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.317 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    309/156230 | global iter:    309/156230 | loss: 1.4833 | ds_loss: 1.4908 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:    310/156230 | global iter:    310/156230 | loss: 1.1905 | ds_loss: 1.2078 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:    311/156230 | global iter:    311/156230 | loss: 1.3923 | ds_loss: 1.3929 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.402 | step time: 0.000
train | epoch   0 | Iter:    312/156230 | global iter:    312/156230 | loss: 1.3927 | ds_loss: 1.3981 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.375 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    312/156230 | global iter:    312/156230 | loss: 1.3647 | ds_loss: 1.3724 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.375 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    313/156230 | global iter:    313/156230 | loss: 1.2026 | ds_loss: 1.2505 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:    314/156230 | global iter:    314/156230 | loss: 1.4463 | ds_loss: 1.4471 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:    315/156230 | global iter:    315/156230 | loss: 1.4817 | ds_loss: 1.4851 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:    316/156230 | global iter:    316/156230 | loss: 1.3905 | ds_loss: 1.4005 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.344 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    316/156230 | global iter:    316/156230 | loss: 1.3803 | ds_loss: 1.3958 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.344 | step time: 1.342
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    317/156230 | global iter:    317/156230 | loss: 1.2755 | ds_loss: 1.2936 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:    318/156230 | global iter:    318/156230 | loss: 1.3369 | ds_loss: 1.3605 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:    319/156230 | global iter:    319/156230 | loss: 1.4647 | ds_loss: 1.4565 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:    320/156230 | global iter:    320/156230 | loss: 1.4183 | ds_loss: 1.4331 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    320/156230 | global iter:    320/156230 | loss: 1.3739 | ds_loss: 1.3859 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.385 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    321/156230 | global iter:    321/156230 | loss: 1.3934 | ds_loss: 1.3993 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:    322/156230 | global iter:    322/156230 | loss: 1.2497 | ds_loss: 1.2551 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:    323/156230 | global iter:    323/156230 | loss: 1.3487 | ds_loss: 1.3530 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:    324/156230 | global iter:    324/156230 | loss: 1.4617 | ds_loss: 1.4471 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    324/156230 | global iter:    324/156230 | loss: 1.3634 | ds_loss: 1.3636 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.381 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    325/156230 | global iter:    325/156230 | loss: 1.1823 | ds_loss: 1.1934 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.309 | step time: 0.000
train | epoch   0 | Iter:    326/156230 | global iter:    326/156230 | loss: 1.3180 | ds_loss: 1.3410 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:    327/156230 | global iter:    327/156230 | loss: 1.3735 | ds_loss: 1.3824 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:    328/156230 | global iter:    328/156230 | loss: 1.4142 | ds_loss: 1.4155 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    328/156230 | global iter:    328/156230 | loss: 1.3220 | ds_loss: 1.3331 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.345 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    329/156230 | global iter:    329/156230 | loss: 1.3243 | ds_loss: 1.3231 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:    330/156230 | global iter:    330/156230 | loss: 1.3428 | ds_loss: 1.3558 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:    331/156230 | global iter:    331/156230 | loss: 1.3056 | ds_loss: 1.3163 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.319 | step time: 0.000
train | epoch   0 | Iter:    332/156230 | global iter:    332/156230 | loss: 1.2484 | ds_loss: 1.2743 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.375 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    332/156230 | global iter:    332/156230 | loss: 1.3053 | ds_loss: 1.3174 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.375 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    333/156230 | global iter:    333/156230 | loss: 1.4801 | ds_loss: 1.5128 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:    334/156230 | global iter:    334/156230 | loss: 1.3130 | ds_loss: 1.3255 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.404 | step time: 0.000
train | epoch   0 | Iter:    335/156230 | global iter:    335/156230 | loss: 1.5175 | ds_loss: 1.5248 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:    336/156230 | global iter:    336/156230 | loss: 1.2906 | ds_loss: 1.2818 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.337 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    336/156230 | global iter:    336/156230 | loss: 1.4003 | ds_loss: 1.4112 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.337 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    337/156230 | global iter:    337/156230 | loss: 1.3548 | ds_loss: 1.3638 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:    338/156230 | global iter:    338/156230 | loss: 1.4405 | ds_loss: 1.4413 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:    339/156230 | global iter:    339/156230 | loss: 1.3631 | ds_loss: 1.3779 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:    340/156230 | global iter:    340/156230 | loss: 1.4560 | ds_loss: 1.4739 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.386 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    340/156230 | global iter:    340/156230 | loss: 1.4036 | ds_loss: 1.4142 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.386 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    341/156230 | global iter:    341/156230 | loss: 1.3541 | ds_loss: 1.3527 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:    342/156230 | global iter:    342/156230 | loss: 1.5535 | ds_loss: 1.5475 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:    343/156230 | global iter:    343/156230 | loss: 1.4767 | ds_loss: 1.4787 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.316 | step time: 0.000
train | epoch   0 | Iter:    344/156230 | global iter:    344/156230 | loss: 1.3424 | ds_loss: 1.3473 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    344/156230 | global iter:    344/156230 | loss: 1.4317 | ds_loss: 1.4316 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.397 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    345/156230 | global iter:    345/156230 | loss: 1.3939 | ds_loss: 1.4051 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:    346/156230 | global iter:    346/156230 | loss: 1.3331 | ds_loss: 1.3255 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:    347/156230 | global iter:    347/156230 | loss: 1.2864 | ds_loss: 1.3040 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:    348/156230 | global iter:    348/156230 | loss: 1.3855 | ds_loss: 1.3839 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    348/156230 | global iter:    348/156230 | loss: 1.3497 | ds_loss: 1.3546 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.369 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    349/156230 | global iter:    349/156230 | loss: 1.3385 | ds_loss: 1.3491 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:    350/156230 | global iter:    350/156230 | loss: 1.2072 | ds_loss: 1.2208 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.317 | step time: 0.000
train | epoch   0 | Iter:    351/156230 | global iter:    351/156230 | loss: 1.3377 | ds_loss: 1.3493 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:    352/156230 | global iter:    352/156230 | loss: 1.3698 | ds_loss: 1.3757 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.386 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    352/156230 | global iter:    352/156230 | loss: 1.3133 | ds_loss: 1.3237 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.386 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    353/156230 | global iter:    353/156230 | loss: 1.3080 | ds_loss: 1.3154 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:    354/156230 | global iter:    354/156230 | loss: 1.4010 | ds_loss: 1.4238 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:    355/156230 | global iter:    355/156230 | loss: 1.3155 | ds_loss: 1.3326 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:    356/156230 | global iter:    356/156230 | loss: 1.3917 | ds_loss: 1.3831 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    356/156230 | global iter:    356/156230 | loss: 1.3540 | ds_loss: 1.3638 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.398 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    357/156230 | global iter:    357/156230 | loss: 1.4289 | ds_loss: 1.4329 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:    358/156230 | global iter:    358/156230 | loss: 1.3612 | ds_loss: 1.3717 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:    359/156230 | global iter:    359/156230 | loss: 1.3485 | ds_loss: 1.3675 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:    360/156230 | global iter:    360/156230 | loss: 1.3199 | ds_loss: 1.3215 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    360/156230 | global iter:    360/156230 | loss: 1.3646 | ds_loss: 1.3734 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.347 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    361/156230 | global iter:    361/156230 | loss: 1.3928 | ds_loss: 1.4113 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:    362/156230 | global iter:    362/156230 | loss: 1.3331 | ds_loss: 1.3399 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:    363/156230 | global iter:    363/156230 | loss: 1.3942 | ds_loss: 1.3981 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:    364/156230 | global iter:    364/156230 | loss: 1.4502 | ds_loss: 1.4538 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.391 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    364/156230 | global iter:    364/156230 | loss: 1.3926 | ds_loss: 1.4008 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.391 | step time: 1.380
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    365/156230 | global iter:    365/156230 | loss: 1.4421 | ds_loss: 1.4587 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:    366/156230 | global iter:    366/156230 | loss: 1.3644 | ds_loss: 1.3652 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:    367/156230 | global iter:    367/156230 | loss: 1.3276 | ds_loss: 1.3416 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.405 | step time: 0.000
train | epoch   0 | Iter:    368/156230 | global iter:    368/156230 | loss: 1.4348 | ds_loss: 1.4404 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    368/156230 | global iter:    368/156230 | loss: 1.3922 | ds_loss: 1.4015 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.397 | step time: 1.381
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    369/156230 | global iter:    369/156230 | loss: 1.3769 | ds_loss: 1.3886 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:    370/156230 | global iter:    370/156230 | loss: 1.3571 | ds_loss: 1.3670 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:    371/156230 | global iter:    371/156230 | loss: 1.2377 | ds_loss: 1.2483 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:    372/156230 | global iter:    372/156230 | loss: 1.3744 | ds_loss: 1.3652 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    372/156230 | global iter:    372/156230 | loss: 1.3365 | ds_loss: 1.3423 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.350 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    373/156230 | global iter:    373/156230 | loss: 1.4581 | ds_loss: 1.4628 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:    374/156230 | global iter:    374/156230 | loss: 1.3989 | ds_loss: 1.4009 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:    375/156230 | global iter:    375/156230 | loss: 1.2462 | ds_loss: 1.2578 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:    376/156230 | global iter:    376/156230 | loss: 1.3237 | ds_loss: 1.3497 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.352 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    376/156230 | global iter:    376/156230 | loss: 1.3567 | ds_loss: 1.3678 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.352 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    377/156230 | global iter:    377/156230 | loss: 1.4403 | ds_loss: 1.4594 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:    378/156230 | global iter:    378/156230 | loss: 1.4086 | ds_loss: 1.4116 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:    379/156230 | global iter:    379/156230 | loss: 1.3812 | ds_loss: 1.3938 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.427 | step time: 0.000
train | epoch   0 | Iter:    380/156230 | global iter:    380/156230 | loss: 1.4711 | ds_loss: 1.4783 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    380/156230 | global iter:    380/156230 | loss: 1.4253 | ds_loss: 1.4358 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.364 | step time: 1.388
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    381/156230 | global iter:    381/156230 | loss: 1.3151 | ds_loss: 1.3289 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:    382/156230 | global iter:    382/156230 | loss: 1.2860 | ds_loss: 1.2962 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.409 | step time: 0.000
train | epoch   0 | Iter:    383/156230 | global iter:    383/156230 | loss: 1.2744 | ds_loss: 1.2638 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:    384/156230 | global iter:    384/156230 | loss: 1.4051 | ds_loss: 1.4179 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    384/156230 | global iter:    384/156230 | loss: 1.3201 | ds_loss: 1.3267 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.368 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    385/156230 | global iter:    385/156230 | loss: 1.3975 | ds_loss: 1.4036 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:    386/156230 | global iter:    386/156230 | loss: 1.4680 | ds_loss: 1.4815 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:    387/156230 | global iter:    387/156230 | loss: 1.3381 | ds_loss: 1.3239 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.313 | step time: 0.000
train | epoch   0 | Iter:    388/156230 | global iter:    388/156230 | loss: 1.2448 | ds_loss: 1.2374 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.333 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    388/156230 | global iter:    388/156230 | loss: 1.3621 | ds_loss: 1.3616 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.333 | step time: 1.340
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    389/156230 | global iter:    389/156230 | loss: 1.3203 | ds_loss: 1.3141 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:    390/156230 | global iter:    390/156230 | loss: 1.2121 | ds_loss: 1.2046 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:    391/156230 | global iter:    391/156230 | loss: 1.1466 | ds_loss: 1.1523 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:    392/156230 | global iter:    392/156230 | loss: 1.3392 | ds_loss: 1.3488 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    392/156230 | global iter:    392/156230 | loss: 1.2545 | ds_loss: 1.2549 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.360 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    393/156230 | global iter:    393/156230 | loss: 1.4603 | ds_loss: 1.4492 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:    394/156230 | global iter:    394/156230 | loss: 1.4364 | ds_loss: 1.4402 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:    395/156230 | global iter:    395/156230 | loss: 1.2951 | ds_loss: 1.3062 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:    396/156230 | global iter:    396/156230 | loss: 1.4274 | ds_loss: 1.4389 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    396/156230 | global iter:    396/156230 | loss: 1.4048 | ds_loss: 1.4086 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.345 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    397/156230 | global iter:    397/156230 | loss: 1.4990 | ds_loss: 1.4964 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:    398/156230 | global iter:    398/156230 | loss: 1.2417 | ds_loss: 1.2515 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:    399/156230 | global iter:    399/156230 | loss: 1.2390 | ds_loss: 1.2638 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:    400/156230 | global iter:    400/156230 | loss: 1.2931 | ds_loss: 1.2997 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    400/156230 | global iter:    400/156230 | loss: 1.3182 | ds_loss: 1.3278 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.393 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    401/156230 | global iter:    401/156230 | loss: 1.4940 | ds_loss: 1.5092 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:    402/156230 | global iter:    402/156230 | loss: 1.2548 | ds_loss: 1.2464 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:    403/156230 | global iter:    403/156230 | loss: 1.4991 | ds_loss: 1.5006 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:    404/156230 | global iter:    404/156230 | loss: 1.3295 | ds_loss: 1.3459 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.388 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    404/156230 | global iter:    404/156230 | loss: 1.3943 | ds_loss: 1.4005 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.388 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    405/156230 | global iter:    405/156230 | loss: 1.4171 | ds_loss: 1.4229 | lr: 9.9999e-05 | scale:  4096.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:    406/156230 | global iter:    406/156230 | loss: 1.4577 | ds_loss: 1.4696 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:    407/156230 | global iter:    407/156230 | loss: 1.3413 | ds_loss: 1.3487 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:    408/156230 | global iter:    408/156230 | loss: 1.2584 | ds_loss: 1.2654 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.386 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    408/156230 | global iter:    408/156230 | loss: 1.3686 | ds_loss: 1.3767 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.386 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    409/156230 | global iter:    409/156230 | loss: 1.3127 | ds_loss: 1.3300 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:    410/156230 | global iter:    410/156230 | loss: 1.2353 | ds_loss: 1.2466 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.412 | step time: 0.000
train | epoch   0 | Iter:    411/156230 | global iter:    411/156230 | loss: 1.2471 | ds_loss: 1.2505 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:    412/156230 | global iter:    412/156230 | loss: 1.4743 | ds_loss: 1.4729 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.348 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    412/156230 | global iter:    412/156230 | loss: 1.3173 | ds_loss: 1.3250 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.348 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    413/156230 | global iter:    413/156230 | loss: 1.3554 | ds_loss: 1.3905 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:    414/156230 | global iter:    414/156230 | loss: 1.4927 | ds_loss: 1.4944 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:    415/156230 | global iter:    415/156230 | loss: 1.4364 | ds_loss: 1.4413 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:    416/156230 | global iter:    416/156230 | loss: 1.3145 | ds_loss: 1.3060 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    416/156230 | global iter:    416/156230 | loss: 1.3997 | ds_loss: 1.4080 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.370 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    417/156230 | global iter:    417/156230 | loss: 1.4383 | ds_loss: 1.4430 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:    418/156230 | global iter:    418/156230 | loss: 1.3757 | ds_loss: 1.3741 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:    419/156230 | global iter:    419/156230 | loss: 1.4257 | ds_loss: 1.4391 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:    420/156230 | global iter:    420/156230 | loss: 1.2409 | ds_loss: 1.2622 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.336 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    420/156230 | global iter:    420/156230 | loss: 1.3702 | ds_loss: 1.3796 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.336 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    421/156230 | global iter:    421/156230 | loss: 1.1696 | ds_loss: 1.1836 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:    422/156230 | global iter:    422/156230 | loss: 1.3691 | ds_loss: 1.3833 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:    423/156230 | global iter:    423/156230 | loss: 1.2764 | ds_loss: 1.2981 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.419 | step time: 0.000
train | epoch   0 | Iter:    424/156230 | global iter:    424/156230 | loss: 1.3753 | ds_loss: 1.3987 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.339 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    424/156230 | global iter:    424/156230 | loss: 1.2976 | ds_loss: 1.3159 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.339 | step time: 1.376
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    425/156230 | global iter:    425/156230 | loss: 1.3278 | ds_loss: 1.3271 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:    426/156230 | global iter:    426/156230 | loss: 1.4375 | ds_loss: 1.4394 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:    427/156230 | global iter:    427/156230 | loss: 1.3463 | ds_loss: 1.3722 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:    428/156230 | global iter:    428/156230 | loss: 1.4531 | ds_loss: 1.4506 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    428/156230 | global iter:    428/156230 | loss: 1.3912 | ds_loss: 1.3973 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.381 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    429/156230 | global iter:    429/156230 | loss: 1.3825 | ds_loss: 1.3877 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:    430/156230 | global iter:    430/156230 | loss: 1.3720 | ds_loss: 1.3997 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:    431/156230 | global iter:    431/156230 | loss: 1.3648 | ds_loss: 1.3650 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:    432/156230 | global iter:    432/156230 | loss: 1.3818 | ds_loss: 1.3969 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    432/156230 | global iter:    432/156230 | loss: 1.3753 | ds_loss: 1.3873 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.363 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    433/156230 | global iter:    433/156230 | loss: 1.4121 | ds_loss: 1.4201 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:    434/156230 | global iter:    434/156230 | loss: 1.4221 | ds_loss: 1.4394 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:    435/156230 | global iter:    435/156230 | loss: 1.3703 | ds_loss: 1.3782 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:    436/156230 | global iter:    436/156230 | loss: 1.2740 | ds_loss: 1.2869 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    436/156230 | global iter:    436/156230 | loss: 1.3696 | ds_loss: 1.3811 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.365 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    437/156230 | global iter:    437/156230 | loss: 1.3122 | ds_loss: 1.3060 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:    438/156230 | global iter:    438/156230 | loss: 1.4313 | ds_loss: 1.4553 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:    439/156230 | global iter:    439/156230 | loss: 1.3687 | ds_loss: 1.3814 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:    440/156230 | global iter:    440/156230 | loss: 1.3353 | ds_loss: 1.3467 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    440/156230 | global iter:    440/156230 | loss: 1.3619 | ds_loss: 1.3724 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    441/156230 | global iter:    441/156230 | loss: 1.2818 | ds_loss: 1.3071 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:    442/156230 | global iter:    442/156230 | loss: 1.2554 | ds_loss: 1.2661 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:    443/156230 | global iter:    443/156230 | loss: 1.2257 | ds_loss: 1.2476 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:    444/156230 | global iter:    444/156230 | loss: 1.3337 | ds_loss: 1.3370 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.407 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    444/156230 | global iter:    444/156230 | loss: 1.2742 | ds_loss: 1.2895 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.407 | step time: 1.379
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    445/156230 | global iter:    445/156230 | loss: 1.3777 | ds_loss: 1.3658 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:    446/156230 | global iter:    446/156230 | loss: 1.4131 | ds_loss: 1.4165 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:    447/156230 | global iter:    447/156230 | loss: 1.3295 | ds_loss: 1.3475 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:    448/156230 | global iter:    448/156230 | loss: 1.3313 | ds_loss: 1.3307 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.331 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    448/156230 | global iter:    448/156230 | loss: 1.3629 | ds_loss: 1.3651 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.331 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    449/156230 | global iter:    449/156230 | loss: 1.3033 | ds_loss: 1.2976 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:    450/156230 | global iter:    450/156230 | loss: 1.2662 | ds_loss: 1.2836 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:    451/156230 | global iter:    451/156230 | loss: 1.2516 | ds_loss: 1.2557 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:    452/156230 | global iter:    452/156230 | loss: 1.3836 | ds_loss: 1.4019 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    452/156230 | global iter:    452/156230 | loss: 1.3012 | ds_loss: 1.3097 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    453/156230 | global iter:    453/156230 | loss: 1.4390 | ds_loss: 1.4324 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.320 | step time: 0.000
train | epoch   0 | Iter:    454/156230 | global iter:    454/156230 | loss: 1.2435 | ds_loss: 1.2398 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:    455/156230 | global iter:    455/156230 | loss: 1.4339 | ds_loss: 1.4456 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.318 | step time: 0.000
train | epoch   0 | Iter:    456/156230 | global iter:    456/156230 | loss: 1.3955 | ds_loss: 1.3998 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.348 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    456/156230 | global iter:    456/156230 | loss: 1.3780 | ds_loss: 1.3794 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.348 | step time: 1.344
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    457/156230 | global iter:    457/156230 | loss: 1.3579 | ds_loss: 1.3678 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:    458/156230 | global iter:    458/156230 | loss: 1.3820 | ds_loss: 1.3863 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:    459/156230 | global iter:    459/156230 | loss: 1.3367 | ds_loss: 1.3400 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:    460/156230 | global iter:    460/156230 | loss: 1.3245 | ds_loss: 1.3120 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.348 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    460/156230 | global iter:    460/156230 | loss: 1.3503 | ds_loss: 1.3515 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.348 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    461/156230 | global iter:    461/156230 | loss: 1.2633 | ds_loss: 1.2746 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:    462/156230 | global iter:    462/156230 | loss: 1.3132 | ds_loss: 1.3229 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:    463/156230 | global iter:    463/156230 | loss: 1.2028 | ds_loss: 1.2146 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:    464/156230 | global iter:    464/156230 | loss: 1.2903 | ds_loss: 1.3012 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.346 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    464/156230 | global iter:    464/156230 | loss: 1.2674 | ds_loss: 1.2783 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.346 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    465/156230 | global iter:    465/156230 | loss: 1.2778 | ds_loss: 1.2793 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:    466/156230 | global iter:    466/156230 | loss: 1.3255 | ds_loss: 1.3437 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:    467/156230 | global iter:    467/156230 | loss: 1.2034 | ds_loss: 1.1941 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:    468/156230 | global iter:    468/156230 | loss: 1.3987 | ds_loss: 1.4257 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.371 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    468/156230 | global iter:    468/156230 | loss: 1.3014 | ds_loss: 1.3107 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.371 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    469/156230 | global iter:    469/156230 | loss: 1.3411 | ds_loss: 1.3447 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:    470/156230 | global iter:    470/156230 | loss: 1.3580 | ds_loss: 1.3583 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:    471/156230 | global iter:    471/156230 | loss: 1.2096 | ds_loss: 1.2037 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:    472/156230 | global iter:    472/156230 | loss: 1.2488 | ds_loss: 1.2513 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.343 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    472/156230 | global iter:    472/156230 | loss: 1.2894 | ds_loss: 1.2895 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.343 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    473/156230 | global iter:    473/156230 | loss: 1.2379 | ds_loss: 1.2373 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:    474/156230 | global iter:    474/156230 | loss: 1.3184 | ds_loss: 1.3353 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:    475/156230 | global iter:    475/156230 | loss: 1.3411 | ds_loss: 1.3658 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:    476/156230 | global iter:    476/156230 | loss: 1.2557 | ds_loss: 1.2575 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.303 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    476/156230 | global iter:    476/156230 | loss: 1.2883 | ds_loss: 1.2990 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.303 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    477/156230 | global iter:    477/156230 | loss: 1.3469 | ds_loss: 1.3366 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.412 | step time: 0.000
train | epoch   0 | Iter:    478/156230 | global iter:    478/156230 | loss: 1.1870 | ds_loss: 1.1990 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.318 | step time: 0.000
train | epoch   0 | Iter:    479/156230 | global iter:    479/156230 | loss: 1.2937 | ds_loss: 1.3126 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:    480/156230 | global iter:    480/156230 | loss: 1.3089 | ds_loss: 1.3181 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.356 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    480/156230 | global iter:    480/156230 | loss: 1.2841 | ds_loss: 1.2915 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.356 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    481/156230 | global iter:    481/156230 | loss: 1.4834 | ds_loss: 1.4920 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:    482/156230 | global iter:    482/156230 | loss: 1.2124 | ds_loss: 1.2124 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:    483/156230 | global iter:    483/156230 | loss: 1.4839 | ds_loss: 1.4895 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:    484/156230 | global iter:    484/156230 | loss: 1.4947 | ds_loss: 1.4936 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    484/156230 | global iter:    484/156230 | loss: 1.4186 | ds_loss: 1.4219 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.369 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    485/156230 | global iter:    485/156230 | loss: 1.4067 | ds_loss: 1.3841 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:    486/156230 | global iter:    486/156230 | loss: 1.2258 | ds_loss: 1.2203 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:    487/156230 | global iter:    487/156230 | loss: 1.4303 | ds_loss: 1.4261 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:    488/156230 | global iter:    488/156230 | loss: 1.2782 | ds_loss: 1.2837 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    488/156230 | global iter:    488/156230 | loss: 1.3352 | ds_loss: 1.3286 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.349 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    489/156230 | global iter:    489/156230 | loss: 1.2092 | ds_loss: 1.2070 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:    490/156230 | global iter:    490/156230 | loss: 1.3853 | ds_loss: 1.3878 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:    491/156230 | global iter:    491/156230 | loss: 1.2793 | ds_loss: 1.2941 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:    492/156230 | global iter:    492/156230 | loss: 1.4387 | ds_loss: 1.4393 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    492/156230 | global iter:    492/156230 | loss: 1.3281 | ds_loss: 1.3321 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    493/156230 | global iter:    493/156230 | loss: 1.3695 | ds_loss: 1.3696 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.403 | step time: 0.000
train | epoch   0 | Iter:    494/156230 | global iter:    494/156230 | loss: 1.3309 | ds_loss: 1.3217 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:    495/156230 | global iter:    495/156230 | loss: 1.0759 | ds_loss: 1.0714 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:    496/156230 | global iter:    496/156230 | loss: 1.2219 | ds_loss: 1.2300 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.356 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    496/156230 | global iter:    496/156230 | loss: 1.2496 | ds_loss: 1.2482 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.356 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    497/156230 | global iter:    497/156230 | loss: 1.3493 | ds_loss: 1.3684 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:    498/156230 | global iter:    498/156230 | loss: 1.3587 | ds_loss: 1.3890 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:    499/156230 | global iter:    499/156230 | loss: 1.2787 | ds_loss: 1.2808 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:    500/156230 | global iter:    500/156230 | loss: 1.2751 | ds_loss: 1.2885 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    500/156230 | global iter:    500/156230 | loss: 1.3154 | ds_loss: 1.3317 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.376 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    501/156230 | global iter:    501/156230 | loss: 1.3805 | ds_loss: 1.3885 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:    502/156230 | global iter:    502/156230 | loss: 1.5493 | ds_loss: 1.5347 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:    503/156230 | global iter:    503/156230 | loss: 1.3568 | ds_loss: 1.3681 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:    504/156230 | global iter:    504/156230 | loss: 1.3235 | ds_loss: 1.3439 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    504/156230 | global iter:    504/156230 | loss: 1.4025 | ds_loss: 1.4088 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.397 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    505/156230 | global iter:    505/156230 | loss: 1.1845 | ds_loss: 1.2016 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:    506/156230 | global iter:    506/156230 | loss: 1.2595 | ds_loss: 1.2586 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:    507/156230 | global iter:    507/156230 | loss: 1.3358 | ds_loss: 1.3343 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:    508/156230 | global iter:    508/156230 | loss: 1.3138 | ds_loss: 1.3266 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    508/156230 | global iter:    508/156230 | loss: 1.2734 | ds_loss: 1.2803 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.373 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    509/156230 | global iter:    509/156230 | loss: 1.3246 | ds_loss: 1.3392 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:    510/156230 | global iter:    510/156230 | loss: 1.3697 | ds_loss: 1.3852 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:    511/156230 | global iter:    511/156230 | loss: 1.3170 | ds_loss: 1.3165 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:    512/156230 | global iter:    512/156230 | loss: 1.3922 | ds_loss: 1.3984 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    512/156230 | global iter:    512/156230 | loss: 1.3509 | ds_loss: 1.3598 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.363 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    513/156230 | global iter:    513/156230 | loss: 1.4404 | ds_loss: 1.4475 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:    514/156230 | global iter:    514/156230 | loss: 1.1776 | ds_loss: 1.1935 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:    515/156230 | global iter:    515/156230 | loss: 1.3212 | ds_loss: 1.3146 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:    516/156230 | global iter:    516/156230 | loss: 1.1956 | ds_loss: 1.2055 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.379 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    516/156230 | global iter:    516/156230 | loss: 1.2837 | ds_loss: 1.2903 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.379 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    517/156230 | global iter:    517/156230 | loss: 1.4183 | ds_loss: 1.4235 | lr: 9.9998e-05 | scale:  4096.0000 | micro time: 1.411 | step time: 0.000
train | epoch   0 | Iter:    518/156230 | global iter:    518/156230 | loss: 1.3602 | ds_loss: 1.3603 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:    519/156230 | global iter:    519/156230 | loss: 1.4958 | ds_loss: 1.4921 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:    520/156230 | global iter:    520/156230 | loss: 1.5158 | ds_loss: 1.5036 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    520/156230 | global iter:    520/156230 | loss: 1.4475 | ds_loss: 1.4449 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.365 | step time: 1.384
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    521/156230 | global iter:    521/156230 | loss: 1.4656 | ds_loss: 1.4508 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:    522/156230 | global iter:    522/156230 | loss: 1.3711 | ds_loss: 1.3908 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:    523/156230 | global iter:    523/156230 | loss: 1.3230 | ds_loss: 1.3353 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:    524/156230 | global iter:    524/156230 | loss: 1.3122 | ds_loss: 1.3246 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    524/156230 | global iter:    524/156230 | loss: 1.3679 | ds_loss: 1.3754 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.378 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    525/156230 | global iter:    525/156230 | loss: 1.2970 | ds_loss: 1.3002 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:    526/156230 | global iter:    526/156230 | loss: 1.4051 | ds_loss: 1.4076 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:    527/156230 | global iter:    527/156230 | loss: 1.3908 | ds_loss: 1.3821 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:    528/156230 | global iter:    528/156230 | loss: 1.3836 | ds_loss: 1.4011 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.343 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    528/156230 | global iter:    528/156230 | loss: 1.3691 | ds_loss: 1.3728 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.343 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    529/156230 | global iter:    529/156230 | loss: 1.4890 | ds_loss: 1.4950 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:    530/156230 | global iter:    530/156230 | loss: 1.2807 | ds_loss: 1.2918 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:    531/156230 | global iter:    531/156230 | loss: 1.2082 | ds_loss: 1.2015 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:    532/156230 | global iter:    532/156230 | loss: 1.2873 | ds_loss: 1.3045 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.356 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    532/156230 | global iter:    532/156230 | loss: 1.3163 | ds_loss: 1.3232 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.356 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    533/156230 | global iter:    533/156230 | loss: 1.3017 | ds_loss: 1.2982 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:    534/156230 | global iter:    534/156230 | loss: 1.4168 | ds_loss: 1.4235 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:    535/156230 | global iter:    535/156230 | loss: 1.3565 | ds_loss: 1.3471 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:    536/156230 | global iter:    536/156230 | loss: 1.3527 | ds_loss: 1.3733 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    536/156230 | global iter:    536/156230 | loss: 1.3569 | ds_loss: 1.3605 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.362 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    537/156230 | global iter:    537/156230 | loss: 1.3196 | ds_loss: 1.3283 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:    538/156230 | global iter:    538/156230 | loss: 1.3540 | ds_loss: 1.3547 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:    539/156230 | global iter:    539/156230 | loss: 1.3136 | ds_loss: 1.3176 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:    540/156230 | global iter:    540/156230 | loss: 1.2998 | ds_loss: 1.3128 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.332 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    540/156230 | global iter:    540/156230 | loss: 1.3218 | ds_loss: 1.3284 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.332 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    541/156230 | global iter:    541/156230 | loss: 1.3131 | ds_loss: 1.3152 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:    542/156230 | global iter:    542/156230 | loss: 1.2527 | ds_loss: 1.2731 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:    543/156230 | global iter:    543/156230 | loss: 1.4555 | ds_loss: 1.4674 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:    544/156230 | global iter:    544/156230 | loss: 1.2248 | ds_loss: 1.2233 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    544/156230 | global iter:    544/156230 | loss: 1.3115 | ds_loss: 1.3197 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.364 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    545/156230 | global iter:    545/156230 | loss: 1.2871 | ds_loss: 1.2861 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:    546/156230 | global iter:    546/156230 | loss: 1.1642 | ds_loss: 1.1818 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:    547/156230 | global iter:    547/156230 | loss: 1.3095 | ds_loss: 1.3169 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:    548/156230 | global iter:    548/156230 | loss: 1.1038 | ds_loss: 1.1391 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.372 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    548/156230 | global iter:    548/156230 | loss: 1.2162 | ds_loss: 1.2310 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.372 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    549/156230 | global iter:    549/156230 | loss: 1.2894 | ds_loss: 1.3152 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:    550/156230 | global iter:    550/156230 | loss: 1.4692 | ds_loss: 1.4919 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:    551/156230 | global iter:    551/156230 | loss: 1.3139 | ds_loss: 1.3015 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.325 | step time: 0.000
train | epoch   0 | Iter:    552/156230 | global iter:    552/156230 | loss: 1.4178 | ds_loss: 1.4271 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.322 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    552/156230 | global iter:    552/156230 | loss: 1.3726 | ds_loss: 1.3839 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.322 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    553/156230 | global iter:    553/156230 | loss: 1.3000 | ds_loss: 1.2958 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:    554/156230 | global iter:    554/156230 | loss: 1.2824 | ds_loss: 1.2831 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:    555/156230 | global iter:    555/156230 | loss: 1.1628 | ds_loss: 1.1814 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:    556/156230 | global iter:    556/156230 | loss: 1.2766 | ds_loss: 1.2694 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    556/156230 | global iter:    556/156230 | loss: 1.2554 | ds_loss: 1.2574 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.362 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    557/156230 | global iter:    557/156230 | loss: 1.2819 | ds_loss: 1.2892 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:    558/156230 | global iter:    558/156230 | loss: 1.4574 | ds_loss: 1.4678 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:    559/156230 | global iter:    559/156230 | loss: 1.1884 | ds_loss: 1.1907 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.404 | step time: 0.000
train | epoch   0 | Iter:    560/156230 | global iter:    560/156230 | loss: 1.4946 | ds_loss: 1.4974 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    560/156230 | global iter:    560/156230 | loss: 1.3556 | ds_loss: 1.3613 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.360 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    561/156230 | global iter:    561/156230 | loss: 1.2077 | ds_loss: 1.2107 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:    562/156230 | global iter:    562/156230 | loss: 1.3510 | ds_loss: 1.3710 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:    563/156230 | global iter:    563/156230 | loss: 1.0946 | ds_loss: 1.0988 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:    564/156230 | global iter:    564/156230 | loss: 1.3120 | ds_loss: 1.3174 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    564/156230 | global iter:    564/156230 | loss: 1.2413 | ds_loss: 1.2495 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.361 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    565/156230 | global iter:    565/156230 | loss: 1.5345 | ds_loss: 1.5488 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.320 | step time: 0.000
train | epoch   0 | Iter:    566/156230 | global iter:    566/156230 | loss: 1.3308 | ds_loss: 1.3344 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:    567/156230 | global iter:    567/156230 | loss: 1.3424 | ds_loss: 1.3417 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:    568/156230 | global iter:    568/156230 | loss: 1.3857 | ds_loss: 1.3986 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.375 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    568/156230 | global iter:    568/156230 | loss: 1.3983 | ds_loss: 1.4059 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.375 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    569/156230 | global iter:    569/156230 | loss: 1.2905 | ds_loss: 1.2991 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:    570/156230 | global iter:    570/156230 | loss: 1.4209 | ds_loss: 1.4297 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:    571/156230 | global iter:    571/156230 | loss: 1.2449 | ds_loss: 1.2657 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:    572/156230 | global iter:    572/156230 | loss: 1.3260 | ds_loss: 1.3308 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    572/156230 | global iter:    572/156230 | loss: 1.3206 | ds_loss: 1.3313 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.366 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    573/156230 | global iter:    573/156230 | loss: 1.1268 | ds_loss: 1.1389 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:    574/156230 | global iter:    574/156230 | loss: 1.2419 | ds_loss: 1.2427 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:    575/156230 | global iter:    575/156230 | loss: 1.1933 | ds_loss: 1.2043 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:    576/156230 | global iter:    576/156230 | loss: 1.4849 | ds_loss: 1.4956 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    576/156230 | global iter:    576/156230 | loss: 1.2617 | ds_loss: 1.2704 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.361 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    577/156230 | global iter:    577/156230 | loss: 1.2302 | ds_loss: 1.2357 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:    578/156230 | global iter:    578/156230 | loss: 1.2632 | ds_loss: 1.2786 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:    579/156230 | global iter:    579/156230 | loss: 1.2158 | ds_loss: 1.2005 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:    580/156230 | global iter:    580/156230 | loss: 1.2966 | ds_loss: 1.2954 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.333 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    580/156230 | global iter:    580/156230 | loss: 1.2514 | ds_loss: 1.2526 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.333 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    581/156230 | global iter:    581/156230 | loss: 1.2390 | ds_loss: 1.2289 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:    582/156230 | global iter:    582/156230 | loss: 1.2758 | ds_loss: 1.2782 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:    583/156230 | global iter:    583/156230 | loss: 1.1864 | ds_loss: 1.1864 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.437 | step time: 0.000
train | epoch   0 | Iter:    584/156230 | global iter:    584/156230 | loss: 1.3564 | ds_loss: 1.3627 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    584/156230 | global iter:    584/156230 | loss: 1.2644 | ds_loss: 1.2641 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.370 | step time: 1.388
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    585/156230 | global iter:    585/156230 | loss: 1.1842 | ds_loss: 1.2050 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:    586/156230 | global iter:    586/156230 | loss: 1.1055 | ds_loss: 1.1185 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.310 | step time: 0.000
train | epoch   0 | Iter:    587/156230 | global iter:    587/156230 | loss: 1.3415 | ds_loss: 1.3547 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:    588/156230 | global iter:    588/156230 | loss: 1.2399 | ds_loss: 1.2647 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    588/156230 | global iter:    588/156230 | loss: 1.2178 | ds_loss: 1.2357 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.349 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    589/156230 | global iter:    589/156230 | loss: 1.2723 | ds_loss: 1.2704 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:    590/156230 | global iter:    590/156230 | loss: 1.1062 | ds_loss: 1.1092 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:    591/156230 | global iter:    591/156230 | loss: 1.2755 | ds_loss: 1.2823 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:    592/156230 | global iter:    592/156230 | loss: 1.4099 | ds_loss: 1.4266 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    592/156230 | global iter:    592/156230 | loss: 1.2660 | ds_loss: 1.2721 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    593/156230 | global iter:    593/156230 | loss: 1.3421 | ds_loss: 1.3643 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:    594/156230 | global iter:    594/156230 | loss: 1.3269 | ds_loss: 1.3359 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:    595/156230 | global iter:    595/156230 | loss: 1.3721 | ds_loss: 1.3841 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:    596/156230 | global iter:    596/156230 | loss: 1.3621 | ds_loss: 1.3713 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.367 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    596/156230 | global iter:    596/156230 | loss: 1.3508 | ds_loss: 1.3639 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.367 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    597/156230 | global iter:    597/156230 | loss: 1.1546 | ds_loss: 1.1829 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:    598/156230 | global iter:    598/156230 | loss: 1.2798 | ds_loss: 1.2869 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:    599/156230 | global iter:    599/156230 | loss: 1.2794 | ds_loss: 1.2722 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:    600/156230 | global iter:    600/156230 | loss: 1.4289 | ds_loss: 1.4511 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    600/156230 | global iter:    600/156230 | loss: 1.2857 | ds_loss: 1.2983 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.347 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    601/156230 | global iter:    601/156230 | loss: 1.3964 | ds_loss: 1.4004 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:    602/156230 | global iter:    602/156230 | loss: 1.2709 | ds_loss: 1.2818 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:    603/156230 | global iter:    603/156230 | loss: 1.2676 | ds_loss: 1.2954 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.307 | step time: 0.000
train | epoch   0 | Iter:    604/156230 | global iter:    604/156230 | loss: 1.5272 | ds_loss: 1.5439 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    604/156230 | global iter:    604/156230 | loss: 1.3655 | ds_loss: 1.3804 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.373 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    605/156230 | global iter:    605/156230 | loss: 1.2477 | ds_loss: 1.2542 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:    606/156230 | global iter:    606/156230 | loss: 1.4297 | ds_loss: 1.4361 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:    607/156230 | global iter:    607/156230 | loss: 1.3981 | ds_loss: 1.3971 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:    608/156230 | global iter:    608/156230 | loss: 1.2582 | ds_loss: 1.2818 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    608/156230 | global iter:    608/156230 | loss: 1.3334 | ds_loss: 1.3423 | lr: 9.9997e-05 | scale:  4096.0000 | micro time: 1.342 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    609/156230 | global iter:    609/156230 | loss: 1.3031 | ds_loss: 1.3071 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:    610/156230 | global iter:    610/156230 | loss: 1.3285 | ds_loss: 1.3441 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:    611/156230 | global iter:    611/156230 | loss: 1.2636 | ds_loss: 1.2648 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:    612/156230 | global iter:    612/156230 | loss: 1.3046 | ds_loss: 1.3047 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.340 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    612/156230 | global iter:    612/156230 | loss: 1.3000 | ds_loss: 1.3052 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.340 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    613/156230 | global iter:    613/156230 | loss: 1.4355 | ds_loss: 1.4381 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:    614/156230 | global iter:    614/156230 | loss: 1.4134 | ds_loss: 1.4068 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:    615/156230 | global iter:    615/156230 | loss: 1.4020 | ds_loss: 1.4113 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:    616/156230 | global iter:    616/156230 | loss: 1.2671 | ds_loss: 1.2524 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    616/156230 | global iter:    616/156230 | loss: 1.3795 | ds_loss: 1.3772 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.365 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    617/156230 | global iter:    617/156230 | loss: 1.1123 | ds_loss: 1.1080 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:    618/156230 | global iter:    618/156230 | loss: 1.2814 | ds_loss: 1.2856 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:    619/156230 | global iter:    619/156230 | loss: 1.2385 | ds_loss: 1.2547 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:    620/156230 | global iter:    620/156230 | loss: 1.2593 | ds_loss: 1.2673 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    620/156230 | global iter:    620/156230 | loss: 1.2229 | ds_loss: 1.2289 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.345 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    621/156230 | global iter:    621/156230 | loss: 1.4224 | ds_loss: 1.4277 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:    622/156230 | global iter:    622/156230 | loss: 1.2431 | ds_loss: 1.2684 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:    623/156230 | global iter:    623/156230 | loss: 1.2681 | ds_loss: 1.2685 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:    624/156230 | global iter:    624/156230 | loss: 1.2594 | ds_loss: 1.2807 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.367 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    624/156230 | global iter:    624/156230 | loss: 1.2983 | ds_loss: 1.3113 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.367 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    625/156230 | global iter:    625/156230 | loss: 1.3426 | ds_loss: 1.3556 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:    626/156230 | global iter:    626/156230 | loss: 1.3946 | ds_loss: 1.4259 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:    627/156230 | global iter:    627/156230 | loss: 1.2708 | ds_loss: 1.2746 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.421 | step time: 0.000
train | epoch   0 | Iter:    628/156230 | global iter:    628/156230 | loss: 1.4200 | ds_loss: 1.4133 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    628/156230 | global iter:    628/156230 | loss: 1.3570 | ds_loss: 1.3673 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 1.383
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    629/156230 | global iter:    629/156230 | loss: 1.2924 | ds_loss: 1.2821 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:    630/156230 | global iter:    630/156230 | loss: 1.2674 | ds_loss: 1.2703 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:    631/156230 | global iter:    631/156230 | loss: 1.2635 | ds_loss: 1.2782 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:    632/156230 | global iter:    632/156230 | loss: 1.3880 | ds_loss: 1.4018 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    632/156230 | global iter:    632/156230 | loss: 1.3028 | ds_loss: 1.3081 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.365 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    633/156230 | global iter:    633/156230 | loss: 1.2840 | ds_loss: 1.2975 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:    634/156230 | global iter:    634/156230 | loss: 1.1746 | ds_loss: 1.1939 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:    635/156230 | global iter:    635/156230 | loss: 1.4956 | ds_loss: 1.4861 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:    636/156230 | global iter:    636/156230 | loss: 1.1549 | ds_loss: 1.1590 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.389 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    636/156230 | global iter:    636/156230 | loss: 1.2773 | ds_loss: 1.2841 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.389 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    637/156230 | global iter:    637/156230 | loss: 1.2117 | ds_loss: 1.2113 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:    638/156230 | global iter:    638/156230 | loss: 1.3878 | ds_loss: 1.3984 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:    639/156230 | global iter:    639/156230 | loss: 1.2804 | ds_loss: 1.2767 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:    640/156230 | global iter:    640/156230 | loss: 1.4446 | ds_loss: 1.4437 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.341 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    640/156230 | global iter:    640/156230 | loss: 1.3311 | ds_loss: 1.3326 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.341 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    641/156230 | global iter:    641/156230 | loss: 1.3259 | ds_loss: 1.3438 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:    642/156230 | global iter:    642/156230 | loss: 1.4504 | ds_loss: 1.4647 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:    643/156230 | global iter:    643/156230 | loss: 1.1501 | ds_loss: 1.1552 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:    644/156230 | global iter:    644/156230 | loss: 1.2775 | ds_loss: 1.2991 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    644/156230 | global iter:    644/156230 | loss: 1.3010 | ds_loss: 1.3157 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.373 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    645/156230 | global iter:    645/156230 | loss: 1.3352 | ds_loss: 1.3395 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.402 | step time: 0.000
train | epoch   0 | Iter:    646/156230 | global iter:    646/156230 | loss: 1.2598 | ds_loss: 1.2660 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:    647/156230 | global iter:    647/156230 | loss: 1.2739 | ds_loss: 1.2870 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:    648/156230 | global iter:    648/156230 | loss: 1.3217 | ds_loss: 1.3183 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    648/156230 | global iter:    648/156230 | loss: 1.2976 | ds_loss: 1.3027 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.345 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    649/156230 | global iter:    649/156230 | loss: 1.3636 | ds_loss: 1.3813 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:    650/156230 | global iter:    650/156230 | loss: 1.1326 | ds_loss: 1.1439 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:    651/156230 | global iter:    651/156230 | loss: 1.3582 | ds_loss: 1.3666 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:    652/156230 | global iter:    652/156230 | loss: 1.1826 | ds_loss: 1.1851 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.328 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    652/156230 | global iter:    652/156230 | loss: 1.2592 | ds_loss: 1.2692 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.328 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    653/156230 | global iter:    653/156230 | loss: 1.2831 | ds_loss: 1.2839 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:    654/156230 | global iter:    654/156230 | loss: 1.3930 | ds_loss: 1.4129 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:    655/156230 | global iter:    655/156230 | loss: 1.2638 | ds_loss: 1.2632 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:    656/156230 | global iter:    656/156230 | loss: 1.4346 | ds_loss: 1.4190 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    656/156230 | global iter:    656/156230 | loss: 1.3436 | ds_loss: 1.3448 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.365 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    657/156230 | global iter:    657/156230 | loss: 1.1346 | ds_loss: 1.1494 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:    658/156230 | global iter:    658/156230 | loss: 1.3215 | ds_loss: 1.3293 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:    659/156230 | global iter:    659/156230 | loss: 1.3168 | ds_loss: 1.3397 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.321 | step time: 0.000
train | epoch   0 | Iter:    660/156230 | global iter:    660/156230 | loss: 1.2927 | ds_loss: 1.3107 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.389 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    660/156230 | global iter:    660/156230 | loss: 1.2664 | ds_loss: 1.2823 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.389 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    661/156230 | global iter:    661/156230 | loss: 1.4758 | ds_loss: 1.4854 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.400 | step time: 0.000
train | epoch   0 | Iter:    662/156230 | global iter:    662/156230 | loss: 1.3616 | ds_loss: 1.3643 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:    663/156230 | global iter:    663/156230 | loss: 1.4748 | ds_loss: 1.4912 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:    664/156230 | global iter:    664/156230 | loss: 1.2614 | ds_loss: 1.2662 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    664/156230 | global iter:    664/156230 | loss: 1.3934 | ds_loss: 1.4018 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    665/156230 | global iter:    665/156230 | loss: 1.3457 | ds_loss: 1.3577 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:    666/156230 | global iter:    666/156230 | loss: 1.3881 | ds_loss: 1.3945 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:    667/156230 | global iter:    667/156230 | loss: 1.1609 | ds_loss: 1.1693 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:    668/156230 | global iter:    668/156230 | loss: 1.3701 | ds_loss: 1.3932 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    668/156230 | global iter:    668/156230 | loss: 1.3162 | ds_loss: 1.3287 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.385 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    669/156230 | global iter:    669/156230 | loss: 1.3365 | ds_loss: 1.3380 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:    670/156230 | global iter:    670/156230 | loss: 1.2842 | ds_loss: 1.2840 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.429 | step time: 0.000
train | epoch   0 | Iter:    671/156230 | global iter:    671/156230 | loss: 1.4038 | ds_loss: 1.4102 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:    672/156230 | global iter:    672/156230 | loss: 1.3533 | ds_loss: 1.3627 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    672/156230 | global iter:    672/156230 | loss: 1.3444 | ds_loss: 1.3487 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.353 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    673/156230 | global iter:    673/156230 | loss: 1.4276 | ds_loss: 1.4291 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:    674/156230 | global iter:    674/156230 | loss: 1.2649 | ds_loss: 1.2754 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.318 | step time: 0.000
train | epoch   0 | Iter:    675/156230 | global iter:    675/156230 | loss: 1.3557 | ds_loss: 1.3428 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:    676/156230 | global iter:    676/156230 | loss: 1.2907 | ds_loss: 1.3088 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    676/156230 | global iter:    676/156230 | loss: 1.3347 | ds_loss: 1.3390 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.393 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    677/156230 | global iter:    677/156230 | loss: 1.3184 | ds_loss: 1.3304 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:    678/156230 | global iter:    678/156230 | loss: 1.1696 | ds_loss: 1.1737 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:    679/156230 | global iter:    679/156230 | loss: 1.1840 | ds_loss: 1.1722 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:    680/156230 | global iter:    680/156230 | loss: 1.5236 | ds_loss: 1.5377 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.324 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    680/156230 | global iter:    680/156230 | loss: 1.2989 | ds_loss: 1.3035 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.324 | step time: 1.342
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    681/156230 | global iter:    681/156230 | loss: 1.0918 | ds_loss: 1.1031 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:    682/156230 | global iter:    682/156230 | loss: 1.2617 | ds_loss: 1.2429 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:    683/156230 | global iter:    683/156230 | loss: 1.4434 | ds_loss: 1.4422 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:    684/156230 | global iter:    684/156230 | loss: 1.3993 | ds_loss: 1.4029 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    684/156230 | global iter:    684/156230 | loss: 1.2990 | ds_loss: 1.2978 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    685/156230 | global iter:    685/156230 | loss: 1.4131 | ds_loss: 1.4271 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:    686/156230 | global iter:    686/156230 | loss: 1.3133 | ds_loss: 1.3416 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.401 | step time: 0.000
train | epoch   0 | Iter:    687/156230 | global iter:    687/156230 | loss: 1.1595 | ds_loss: 1.1762 | lr: 9.9996e-05 | scale:  4096.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:    688/156230 | global iter:    688/156230 | loss: 1.2568 | ds_loss: 1.2539 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.333 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    688/156230 | global iter:    688/156230 | loss: 1.2856 | ds_loss: 1.2997 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.333 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    689/156230 | global iter:    689/156230 | loss: 1.2520 | ds_loss: 1.2543 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:    690/156230 | global iter:    690/156230 | loss: 1.2562 | ds_loss: 1.2710 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:    691/156230 | global iter:    691/156230 | loss: 1.3113 | ds_loss: 1.3272 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:    692/156230 | global iter:    692/156230 | loss: 1.4294 | ds_loss: 1.4215 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    692/156230 | global iter:    692/156230 | loss: 1.3122 | ds_loss: 1.3185 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.385 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    693/156230 | global iter:    693/156230 | loss: 1.0842 | ds_loss: 1.0864 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:    694/156230 | global iter:    694/156230 | loss: 1.2987 | ds_loss: 1.3091 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:    695/156230 | global iter:    695/156230 | loss: 1.2741 | ds_loss: 1.2905 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.401 | step time: 0.000
train | epoch   0 | Iter:    696/156230 | global iter:    696/156230 | loss: 1.2885 | ds_loss: 1.3016 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    696/156230 | global iter:    696/156230 | loss: 1.2363 | ds_loss: 1.2469 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    697/156230 | global iter:    697/156230 | loss: 1.3103 | ds_loss: 1.3170 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:    698/156230 | global iter:    698/156230 | loss: 1.2914 | ds_loss: 1.2994 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:    699/156230 | global iter:    699/156230 | loss: 1.2827 | ds_loss: 1.2905 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.321 | step time: 0.000
train | epoch   0 | Iter:    700/156230 | global iter:    700/156230 | loss: 1.2854 | ds_loss: 1.2877 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.375 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    700/156230 | global iter:    700/156230 | loss: 1.2925 | ds_loss: 1.2987 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.375 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    701/156230 | global iter:    701/156230 | loss: 1.3363 | ds_loss: 1.3519 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:    702/156230 | global iter:    702/156230 | loss: 1.3511 | ds_loss: 1.3530 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:    703/156230 | global iter:    703/156230 | loss: 1.4054 | ds_loss: 1.4074 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:    704/156230 | global iter:    704/156230 | loss: 1.3314 | ds_loss: 1.3220 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    704/156230 | global iter:    704/156230 | loss: 1.3560 | ds_loss: 1.3586 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.374 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    705/156230 | global iter:    705/156230 | loss: 1.3022 | ds_loss: 1.3046 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:    706/156230 | global iter:    706/156230 | loss: 1.4845 | ds_loss: 1.4911 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:    707/156230 | global iter:    707/156230 | loss: 1.2546 | ds_loss: 1.2570 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:    708/156230 | global iter:    708/156230 | loss: 1.3288 | ds_loss: 1.3352 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    708/156230 | global iter:    708/156230 | loss: 1.3425 | ds_loss: 1.3470 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.355 | step time: 1.345
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    709/156230 | global iter:    709/156230 | loss: 1.2755 | ds_loss: 1.2690 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:    710/156230 | global iter:    710/156230 | loss: 1.2837 | ds_loss: 1.2954 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:    711/156230 | global iter:    711/156230 | loss: 1.2006 | ds_loss: 1.1998 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:    712/156230 | global iter:    712/156230 | loss: 1.2535 | ds_loss: 1.2592 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    712/156230 | global iter:    712/156230 | loss: 1.2533 | ds_loss: 1.2558 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.349 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    713/156230 | global iter:    713/156230 | loss: 1.3958 | ds_loss: 1.4072 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:    714/156230 | global iter:    714/156230 | loss: 1.3775 | ds_loss: 1.3940 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:    715/156230 | global iter:    715/156230 | loss: 1.1653 | ds_loss: 1.1558 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:    716/156230 | global iter:    716/156230 | loss: 1.1658 | ds_loss: 1.1818 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.337 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    716/156230 | global iter:    716/156230 | loss: 1.2761 | ds_loss: 1.2847 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.337 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    717/156230 | global iter:    717/156230 | loss: 1.1886 | ds_loss: 1.1987 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:    718/156230 | global iter:    718/156230 | loss: 1.1414 | ds_loss: 1.1535 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:    719/156230 | global iter:    719/156230 | loss: 1.2701 | ds_loss: 1.2703 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:    720/156230 | global iter:    720/156230 | loss: 1.2315 | ds_loss: 1.2475 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.336 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    720/156230 | global iter:    720/156230 | loss: 1.2079 | ds_loss: 1.2175 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.336 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    721/156230 | global iter:    721/156230 | loss: 1.2467 | ds_loss: 1.2536 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:    722/156230 | global iter:    722/156230 | loss: 1.3332 | ds_loss: 1.3487 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:    723/156230 | global iter:    723/156230 | loss: 1.1325 | ds_loss: 1.1480 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:    724/156230 | global iter:    724/156230 | loss: 1.3484 | ds_loss: 1.3487 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.328 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    724/156230 | global iter:    724/156230 | loss: 1.2652 | ds_loss: 1.2748 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.328 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    725/156230 | global iter:    725/156230 | loss: 1.0898 | ds_loss: 1.0954 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:    726/156230 | global iter:    726/156230 | loss: 1.4351 | ds_loss: 1.4438 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:    727/156230 | global iter:    727/156230 | loss: 1.2639 | ds_loss: 1.2857 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:    728/156230 | global iter:    728/156230 | loss: 1.2657 | ds_loss: 1.2926 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.338 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    728/156230 | global iter:    728/156230 | loss: 1.2636 | ds_loss: 1.2794 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.338 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    729/156230 | global iter:    729/156230 | loss: 1.2380 | ds_loss: 1.2428 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.403 | step time: 0.000
train | epoch   0 | Iter:    730/156230 | global iter:    730/156230 | loss: 1.4050 | ds_loss: 1.4181 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:    731/156230 | global iter:    731/156230 | loss: 1.2990 | ds_loss: 1.3028 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:    732/156230 | global iter:    732/156230 | loss: 1.2087 | ds_loss: 1.2009 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    732/156230 | global iter:    732/156230 | loss: 1.2877 | ds_loss: 1.2911 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 1.380
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    733/156230 | global iter:    733/156230 | loss: 1.3399 | ds_loss: 1.3463 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:    734/156230 | global iter:    734/156230 | loss: 1.3454 | ds_loss: 1.3449 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:    735/156230 | global iter:    735/156230 | loss: 1.4533 | ds_loss: 1.4759 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:    736/156230 | global iter:    736/156230 | loss: 1.3952 | ds_loss: 1.3971 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.437 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    736/156230 | global iter:    736/156230 | loss: 1.3835 | ds_loss: 1.3911 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.437 | step time: 1.392
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    737/156230 | global iter:    737/156230 | loss: 1.1948 | ds_loss: 1.2102 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:    738/156230 | global iter:    738/156230 | loss: 1.1481 | ds_loss: 1.1427 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:    739/156230 | global iter:    739/156230 | loss: 1.2122 | ds_loss: 1.2194 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:    740/156230 | global iter:    740/156230 | loss: 1.3324 | ds_loss: 1.3435 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    740/156230 | global iter:    740/156230 | loss: 1.2219 | ds_loss: 1.2289 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.366 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    741/156230 | global iter:    741/156230 | loss: 1.2648 | ds_loss: 1.2682 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:    742/156230 | global iter:    742/156230 | loss: 1.1391 | ds_loss: 1.1337 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:    743/156230 | global iter:    743/156230 | loss: 1.1279 | ds_loss: 1.1520 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:    744/156230 | global iter:    744/156230 | loss: 1.2247 | ds_loss: 1.2365 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.343 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    744/156230 | global iter:    744/156230 | loss: 1.1891 | ds_loss: 1.1976 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.343 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    745/156230 | global iter:    745/156230 | loss: 1.1422 | ds_loss: 1.1476 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:    746/156230 | global iter:    746/156230 | loss: 1.3351 | ds_loss: 1.3276 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:    747/156230 | global iter:    747/156230 | loss: 1.2382 | ds_loss: 1.2441 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:    748/156230 | global iter:    748/156230 | loss: 1.1184 | ds_loss: 1.1301 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    748/156230 | global iter:    748/156230 | loss: 1.2085 | ds_loss: 1.2124 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.381 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    749/156230 | global iter:    749/156230 | loss: 1.2857 | ds_loss: 1.3084 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:    750/156230 | global iter:    750/156230 | loss: 1.2015 | ds_loss: 1.2165 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.409 | step time: 0.000
train | epoch   0 | Iter:    751/156230 | global iter:    751/156230 | loss: 1.3582 | ds_loss: 1.3726 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:    752/156230 | global iter:    752/156230 | loss: 1.2108 | ds_loss: 1.2093 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.392 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    752/156230 | global iter:    752/156230 | loss: 1.2640 | ds_loss: 1.2767 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.392 | step time: 1.387
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    753/156230 | global iter:    753/156230 | loss: 1.2490 | ds_loss: 1.2497 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:    754/156230 | global iter:    754/156230 | loss: 1.4111 | ds_loss: 1.4131 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:    755/156230 | global iter:    755/156230 | loss: 1.2553 | ds_loss: 1.2634 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:    756/156230 | global iter:    756/156230 | loss: 1.3037 | ds_loss: 1.3104 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    756/156230 | global iter:    756/156230 | loss: 1.3048 | ds_loss: 1.3091 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.373 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    757/156230 | global iter:    757/156230 | loss: 1.2982 | ds_loss: 1.3034 | lr: 9.9995e-05 | scale:  4096.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:    758/156230 | global iter:    758/156230 | loss: 1.0813 | ds_loss: 1.0858 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:    759/156230 | global iter:    759/156230 | loss: 1.0802 | ds_loss: 1.0868 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:    760/156230 | global iter:    760/156230 | loss: 1.4561 | ds_loss: 1.4805 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    760/156230 | global iter:    760/156230 | loss: 1.2290 | ds_loss: 1.2391 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    761/156230 | global iter:    761/156230 | loss: 1.4168 | ds_loss: 1.4249 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:    762/156230 | global iter:    762/156230 | loss: 1.1268 | ds_loss: 1.1228 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:    763/156230 | global iter:    763/156230 | loss: 1.3413 | ds_loss: 1.3325 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:    764/156230 | global iter:    764/156230 | loss: 1.2591 | ds_loss: 1.2830 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    764/156230 | global iter:    764/156230 | loss: 1.2860 | ds_loss: 1.2908 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.350 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    765/156230 | global iter:    765/156230 | loss: 1.2019 | ds_loss: 1.2012 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:    766/156230 | global iter:    766/156230 | loss: 1.3218 | ds_loss: 1.3226 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:    767/156230 | global iter:    767/156230 | loss: 1.1464 | ds_loss: 1.1442 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:    768/156230 | global iter:    768/156230 | loss: 1.1722 | ds_loss: 1.1887 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    768/156230 | global iter:    768/156230 | loss: 1.2106 | ds_loss: 1.2142 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.393 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    769/156230 | global iter:    769/156230 | loss: 1.0446 | ds_loss: 1.0627 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.316 | step time: 0.000
train | epoch   0 | Iter:    770/156230 | global iter:    770/156230 | loss: 1.1897 | ds_loss: 1.1848 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:    771/156230 | global iter:    771/156230 | loss: 1.2360 | ds_loss: 1.2409 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:    772/156230 | global iter:    772/156230 | loss: 1.1598 | ds_loss: 1.1781 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    772/156230 | global iter:    772/156230 | loss: 1.1575 | ds_loss: 1.1666 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.361 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    773/156230 | global iter:    773/156230 | loss: 1.1678 | ds_loss: 1.1823 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:    774/156230 | global iter:    774/156230 | loss: 1.1706 | ds_loss: 1.1732 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:    775/156230 | global iter:    775/156230 | loss: 1.3339 | ds_loss: 1.3401 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:    776/156230 | global iter:    776/156230 | loss: 1.3456 | ds_loss: 1.3630 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    776/156230 | global iter:    776/156230 | loss: 1.2545 | ds_loss: 1.2647 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.365 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    777/156230 | global iter:    777/156230 | loss: 1.2712 | ds_loss: 1.2736 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:    778/156230 | global iter:    778/156230 | loss: 1.1660 | ds_loss: 1.1722 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:    779/156230 | global iter:    779/156230 | loss: 1.1199 | ds_loss: 1.1201 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:    780/156230 | global iter:    780/156230 | loss: 1.2853 | ds_loss: 1.2863 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    780/156230 | global iter:    780/156230 | loss: 1.2106 | ds_loss: 1.2131 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.354 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    781/156230 | global iter:    781/156230 | loss: 1.2473 | ds_loss: 1.2742 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:    782/156230 | global iter:    782/156230 | loss: 1.1846 | ds_loss: 1.2021 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:    783/156230 | global iter:    783/156230 | loss: 1.2106 | ds_loss: 1.2238 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:    784/156230 | global iter:    784/156230 | loss: 1.3500 | ds_loss: 1.3592 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    784/156230 | global iter:    784/156230 | loss: 1.2481 | ds_loss: 1.2649 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.347 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    785/156230 | global iter:    785/156230 | loss: 1.0740 | ds_loss: 1.1019 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:    786/156230 | global iter:    786/156230 | loss: 1.4392 | ds_loss: 1.4395 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:    787/156230 | global iter:    787/156230 | loss: 1.2916 | ds_loss: 1.2864 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:    788/156230 | global iter:    788/156230 | loss: 1.1548 | ds_loss: 1.1603 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.344 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    788/156230 | global iter:    788/156230 | loss: 1.2399 | ds_loss: 1.2470 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.344 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    789/156230 | global iter:    789/156230 | loss: 1.2798 | ds_loss: 1.2795 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:    790/156230 | global iter:    790/156230 | loss: 1.3999 | ds_loss: 1.3908 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:    791/156230 | global iter:    791/156230 | loss: 1.3253 | ds_loss: 1.3316 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:    792/156230 | global iter:    792/156230 | loss: 1.1592 | ds_loss: 1.1651 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    792/156230 | global iter:    792/156230 | loss: 1.2911 | ds_loss: 1.2917 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    793/156230 | global iter:    793/156230 | loss: 1.2695 | ds_loss: 1.2846 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:    794/156230 | global iter:    794/156230 | loss: 1.1580 | ds_loss: 1.1656 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:    795/156230 | global iter:    795/156230 | loss: 1.3519 | ds_loss: 1.3560 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:    796/156230 | global iter:    796/156230 | loss: 1.2089 | ds_loss: 1.2258 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    796/156230 | global iter:    796/156230 | loss: 1.2471 | ds_loss: 1.2580 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.393 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    797/156230 | global iter:    797/156230 | loss: 1.1715 | ds_loss: 1.1885 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:    798/156230 | global iter:    798/156230 | loss: 1.0834 | ds_loss: 1.0948 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.316 | step time: 0.000
train | epoch   0 | Iter:    799/156230 | global iter:    799/156230 | loss: 1.3427 | ds_loss: 1.3415 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:    800/156230 | global iter:    800/156230 | loss: 1.1864 | ds_loss: 1.1938 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    800/156230 | global iter:    800/156230 | loss: 1.1960 | ds_loss: 1.2046 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.345 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    801/156230 | global iter:    801/156230 | loss: 1.3153 | ds_loss: 1.3279 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.411 | step time: 0.000
train | epoch   0 | Iter:    802/156230 | global iter:    802/156230 | loss: 1.2879 | ds_loss: 1.3012 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:    803/156230 | global iter:    803/156230 | loss: 1.1512 | ds_loss: 1.1563 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:    804/156230 | global iter:    804/156230 | loss: 1.3193 | ds_loss: 1.3188 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.409 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    804/156230 | global iter:    804/156230 | loss: 1.2684 | ds_loss: 1.2760 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.409 | step time: 1.391
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    805/156230 | global iter:    805/156230 | loss: 1.1867 | ds_loss: 1.1868 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:    806/156230 | global iter:    806/156230 | loss: 1.1889 | ds_loss: 1.1846 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:    807/156230 | global iter:    807/156230 | loss: 1.1530 | ds_loss: 1.1509 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:    808/156230 | global iter:    808/156230 | loss: 1.1635 | ds_loss: 1.1643 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    808/156230 | global iter:    808/156230 | loss: 1.1730 | ds_loss: 1.1716 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.347 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    809/156230 | global iter:    809/156230 | loss: 1.2280 | ds_loss: 1.2393 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.309 | step time: 0.000
train | epoch   0 | Iter:    810/156230 | global iter:    810/156230 | loss: 1.3956 | ds_loss: 1.4085 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:    811/156230 | global iter:    811/156230 | loss: 1.2699 | ds_loss: 1.2738 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.408 | step time: 0.000
train | epoch   0 | Iter:    812/156230 | global iter:    812/156230 | loss: 1.2485 | ds_loss: 1.2602 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.338 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    812/156230 | global iter:    812/156230 | loss: 1.2855 | ds_loss: 1.2955 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.338 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    813/156230 | global iter:    813/156230 | loss: 1.2859 | ds_loss: 1.2994 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.311 | step time: 0.000
train | epoch   0 | Iter:    814/156230 | global iter:    814/156230 | loss: 1.1418 | ds_loss: 1.1456 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.426 | step time: 0.000
train | epoch   0 | Iter:    815/156230 | global iter:    815/156230 | loss: 1.2010 | ds_loss: 1.2295 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.400 | step time: 0.000
train | epoch   0 | Iter:    816/156230 | global iter:    816/156230 | loss: 1.2597 | ds_loss: 1.2851 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.321 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    816/156230 | global iter:    816/156230 | loss: 1.2221 | ds_loss: 1.2399 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.321 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    817/156230 | global iter:    817/156230 | loss: 1.0959 | ds_loss: 1.0895 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:    818/156230 | global iter:    818/156230 | loss: 1.1559 | ds_loss: 1.1675 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:    819/156230 | global iter:    819/156230 | loss: 1.2701 | ds_loss: 1.2707 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:    820/156230 | global iter:    820/156230 | loss: 1.3894 | ds_loss: 1.3786 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.330 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    820/156230 | global iter:    820/156230 | loss: 1.2278 | ds_loss: 1.2266 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.330 | step time: 1.345
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    821/156230 | global iter:    821/156230 | loss: 1.2540 | ds_loss: 1.2760 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:    822/156230 | global iter:    822/156230 | loss: 1.2306 | ds_loss: 1.2399 | lr: 9.9994e-05 | scale:  4096.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:    823/156230 | global iter:    823/156230 | loss: 1.3103 | ds_loss: 1.3123 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:    824/156230 | global iter:    824/156230 | loss: 1.2199 | ds_loss: 1.2401 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    824/156230 | global iter:    824/156230 | loss: 1.2537 | ds_loss: 1.2671 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.385 | step time: 1.381
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    825/156230 | global iter:    825/156230 | loss: 1.2110 | ds_loss: 1.2264 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:    826/156230 | global iter:    826/156230 | loss: 1.2170 | ds_loss: 1.2380 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:    827/156230 | global iter:    827/156230 | loss: 1.1388 | ds_loss: 1.1365 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:    828/156230 | global iter:    828/156230 | loss: 1.0846 | ds_loss: 1.1120 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    828/156230 | global iter:    828/156230 | loss: 1.1628 | ds_loss: 1.1782 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.364 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    829/156230 | global iter:    829/156230 | loss: 1.2505 | ds_loss: 1.2630 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:    830/156230 | global iter:    830/156230 | loss: 1.3164 | ds_loss: 1.3200 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:    831/156230 | global iter:    831/156230 | loss: 1.3967 | ds_loss: 1.4087 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:    832/156230 | global iter:    832/156230 | loss: 1.1371 | ds_loss: 1.1541 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    832/156230 | global iter:    832/156230 | loss: 1.2752 | ds_loss: 1.2864 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.364 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    833/156230 | global iter:    833/156230 | loss: 1.2652 | ds_loss: 1.2686 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:    834/156230 | global iter:    834/156230 | loss: 1.1724 | ds_loss: 1.1889 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:    835/156230 | global iter:    835/156230 | loss: 1.2115 | ds_loss: 1.2303 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:    836/156230 | global iter:    836/156230 | loss: 1.2895 | ds_loss: 1.2826 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    836/156230 | global iter:    836/156230 | loss: 1.2347 | ds_loss: 1.2426 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    837/156230 | global iter:    837/156230 | loss: 1.2473 | ds_loss: 1.2566 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:    838/156230 | global iter:    838/156230 | loss: 1.3699 | ds_loss: 1.3735 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:    839/156230 | global iter:    839/156230 | loss: 1.1990 | ds_loss: 1.2041 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:    840/156230 | global iter:    840/156230 | loss: 1.1820 | ds_loss: 1.1832 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    840/156230 | global iter:    840/156230 | loss: 1.2495 | ds_loss: 1.2543 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.381 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    841/156230 | global iter:    841/156230 | loss: 1.2360 | ds_loss: 1.2296 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:    842/156230 | global iter:    842/156230 | loss: 1.3112 | ds_loss: 1.3306 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:    843/156230 | global iter:    843/156230 | loss: 1.0525 | ds_loss: 1.0597 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:    844/156230 | global iter:    844/156230 | loss: 1.1352 | ds_loss: 1.1267 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.329 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    844/156230 | global iter:    844/156230 | loss: 1.1837 | ds_loss: 1.1866 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.329 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    845/156230 | global iter:    845/156230 | loss: 1.2194 | ds_loss: 1.2318 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:    846/156230 | global iter:    846/156230 | loss: 1.3641 | ds_loss: 1.3858 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:    847/156230 | global iter:    847/156230 | loss: 1.3681 | ds_loss: 1.3661 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:    848/156230 | global iter:    848/156230 | loss: 1.2073 | ds_loss: 1.2062 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    848/156230 | global iter:    848/156230 | loss: 1.2897 | ds_loss: 1.2975 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.378 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    849/156230 | global iter:    849/156230 | loss: 1.3928 | ds_loss: 1.3964 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:    850/156230 | global iter:    850/156230 | loss: 1.3777 | ds_loss: 1.3821 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:    851/156230 | global iter:    851/156230 | loss: 1.3590 | ds_loss: 1.3655 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:    852/156230 | global iter:    852/156230 | loss: 1.3793 | ds_loss: 1.3797 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    852/156230 | global iter:    852/156230 | loss: 1.3772 | ds_loss: 1.3809 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.394 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    853/156230 | global iter:    853/156230 | loss: 1.3968 | ds_loss: 1.4132 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:    854/156230 | global iter:    854/156230 | loss: 1.1348 | ds_loss: 1.1362 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:    855/156230 | global iter:    855/156230 | loss: 1.2774 | ds_loss: 1.2767 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:    856/156230 | global iter:    856/156230 | loss: 1.3327 | ds_loss: 1.3396 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    856/156230 | global iter:    856/156230 | loss: 1.2854 | ds_loss: 1.2914 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.363 | step time: 1.348
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    857/156230 | global iter:    857/156230 | loss: 1.4103 | ds_loss: 1.4233 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:    858/156230 | global iter:    858/156230 | loss: 1.2388 | ds_loss: 1.2519 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:    859/156230 | global iter:    859/156230 | loss: 1.2569 | ds_loss: 1.2592 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:    860/156230 | global iter:    860/156230 | loss: 1.2121 | ds_loss: 1.2407 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    860/156230 | global iter:    860/156230 | loss: 1.2796 | ds_loss: 1.2938 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.365 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    861/156230 | global iter:    861/156230 | loss: 1.3477 | ds_loss: 1.3648 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:    862/156230 | global iter:    862/156230 | loss: 1.3985 | ds_loss: 1.4004 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:    863/156230 | global iter:    863/156230 | loss: 1.3171 | ds_loss: 1.3284 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:    864/156230 | global iter:    864/156230 | loss: 1.4518 | ds_loss: 1.4382 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.371 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    864/156230 | global iter:    864/156230 | loss: 1.3788 | ds_loss: 1.3829 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.371 | step time: 1.348
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    865/156230 | global iter:    865/156230 | loss: 1.4444 | ds_loss: 1.4533 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.404 | step time: 0.000
train | epoch   0 | Iter:    866/156230 | global iter:    866/156230 | loss: 1.1804 | ds_loss: 1.1901 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:    867/156230 | global iter:    867/156230 | loss: 1.3891 | ds_loss: 1.3952 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:    868/156230 | global iter:    868/156230 | loss: 1.2785 | ds_loss: 1.2784 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    868/156230 | global iter:    868/156230 | loss: 1.3231 | ds_loss: 1.3293 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.381 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    869/156230 | global iter:    869/156230 | loss: 1.3063 | ds_loss: 1.3122 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:    870/156230 | global iter:    870/156230 | loss: 1.2198 | ds_loss: 1.2304 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:    871/156230 | global iter:    871/156230 | loss: 1.2722 | ds_loss: 1.2789 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:    872/156230 | global iter:    872/156230 | loss: 1.1599 | ds_loss: 1.1586 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    872/156230 | global iter:    872/156230 | loss: 1.2395 | ds_loss: 1.2450 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.353 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    873/156230 | global iter:    873/156230 | loss: 1.1181 | ds_loss: 1.1486 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:    874/156230 | global iter:    874/156230 | loss: 1.3414 | ds_loss: 1.3552 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:    875/156230 | global iter:    875/156230 | loss: 1.3601 | ds_loss: 1.3595 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:    876/156230 | global iter:    876/156230 | loss: 1.1922 | ds_loss: 1.1933 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    876/156230 | global iter:    876/156230 | loss: 1.2530 | ds_loss: 1.2642 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.366 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    877/156230 | global iter:    877/156230 | loss: 1.2336 | ds_loss: 1.2529 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:    878/156230 | global iter:    878/156230 | loss: 1.3872 | ds_loss: 1.3858 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:    879/156230 | global iter:    879/156230 | loss: 1.1877 | ds_loss: 1.1870 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:    880/156230 | global iter:    880/156230 | loss: 1.2616 | ds_loss: 1.2600 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.333 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    880/156230 | global iter:    880/156230 | loss: 1.2675 | ds_loss: 1.2714 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.333 | step time: 1.347
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    881/156230 | global iter:    881/156230 | loss: 1.4160 | ds_loss: 1.4238 | lr: 9.9993e-05 | scale:  4096.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:    882/156230 | global iter:    882/156230 | loss: 1.1693 | ds_loss: 1.1747 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:    883/156230 | global iter:    883/156230 | loss: 1.2624 | ds_loss: 1.2708 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:    884/156230 | global iter:    884/156230 | loss: 1.2810 | ds_loss: 1.2708 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.375 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    884/156230 | global iter:    884/156230 | loss: 1.2822 | ds_loss: 1.2850 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.375 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    885/156230 | global iter:    885/156230 | loss: 1.0863 | ds_loss: 1.0987 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:    886/156230 | global iter:    886/156230 | loss: 1.3554 | ds_loss: 1.3563 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:    887/156230 | global iter:    887/156230 | loss: 1.3206 | ds_loss: 1.3334 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:    888/156230 | global iter:    888/156230 | loss: 1.3118 | ds_loss: 1.3206 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.356 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    888/156230 | global iter:    888/156230 | loss: 1.2685 | ds_loss: 1.2773 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.356 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    889/156230 | global iter:    889/156230 | loss: 1.0906 | ds_loss: 1.0856 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:    890/156230 | global iter:    890/156230 | loss: 1.2208 | ds_loss: 1.2267 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:    891/156230 | global iter:    891/156230 | loss: 1.3665 | ds_loss: 1.3648 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:    892/156230 | global iter:    892/156230 | loss: 1.1466 | ds_loss: 1.1521 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    892/156230 | global iter:    892/156230 | loss: 1.2061 | ds_loss: 1.2073 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.350 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    893/156230 | global iter:    893/156230 | loss: 1.1550 | ds_loss: 1.1740 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:    894/156230 | global iter:    894/156230 | loss: 1.1904 | ds_loss: 1.1928 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:    895/156230 | global iter:    895/156230 | loss: 1.2332 | ds_loss: 1.2426 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:    896/156230 | global iter:    896/156230 | loss: 1.1780 | ds_loss: 1.1922 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    896/156230 | global iter:    896/156230 | loss: 1.1892 | ds_loss: 1.2004 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.354 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    897/156230 | global iter:    897/156230 | loss: 1.2728 | ds_loss: 1.2626 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:    898/156230 | global iter:    898/156230 | loss: 1.2865 | ds_loss: 1.2867 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:    899/156230 | global iter:    899/156230 | loss: 1.1645 | ds_loss: 1.1857 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:    900/156230 | global iter:    900/156230 | loss: 1.1471 | ds_loss: 1.1590 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    900/156230 | global iter:    900/156230 | loss: 1.2177 | ds_loss: 1.2235 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.395 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    901/156230 | global iter:    901/156230 | loss: 1.2305 | ds_loss: 1.2663 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:    902/156230 | global iter:    902/156230 | loss: 1.2152 | ds_loss: 1.2188 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:    903/156230 | global iter:    903/156230 | loss: 1.2490 | ds_loss: 1.2605 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:    904/156230 | global iter:    904/156230 | loss: 1.2680 | ds_loss: 1.2638 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.417 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    904/156230 | global iter:    904/156230 | loss: 1.2407 | ds_loss: 1.2523 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.417 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    905/156230 | global iter:    905/156230 | loss: 1.2690 | ds_loss: 1.2860 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:    906/156230 | global iter:    906/156230 | loss: 1.3423 | ds_loss: 1.3409 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:    907/156230 | global iter:    907/156230 | loss: 1.3114 | ds_loss: 1.3300 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:    908/156230 | global iter:    908/156230 | loss: 1.3627 | ds_loss: 1.3761 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    908/156230 | global iter:    908/156230 | loss: 1.3213 | ds_loss: 1.3332 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.376 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    909/156230 | global iter:    909/156230 | loss: 1.4294 | ds_loss: 1.4217 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:    910/156230 | global iter:    910/156230 | loss: 1.2436 | ds_loss: 1.2479 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:    911/156230 | global iter:    911/156230 | loss: 1.3159 | ds_loss: 1.3349 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.402 | step time: 0.000
train | epoch   0 | Iter:    912/156230 | global iter:    912/156230 | loss: 1.3600 | ds_loss: 1.3525 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.402 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    912/156230 | global iter:    912/156230 | loss: 1.3372 | ds_loss: 1.3392 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.402 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    913/156230 | global iter:    913/156230 | loss: 1.2412 | ds_loss: 1.2403 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:    914/156230 | global iter:    914/156230 | loss: 1.2338 | ds_loss: 1.2404 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:    915/156230 | global iter:    915/156230 | loss: 1.2721 | ds_loss: 1.2892 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.325 | step time: 0.000
train | epoch   0 | Iter:    916/156230 | global iter:    916/156230 | loss: 1.2598 | ds_loss: 1.2671 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.337 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    916/156230 | global iter:    916/156230 | loss: 1.2517 | ds_loss: 1.2593 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.337 | step time: 1.341
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    917/156230 | global iter:    917/156230 | loss: 1.4274 | ds_loss: 1.4331 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:    918/156230 | global iter:    918/156230 | loss: 1.3161 | ds_loss: 1.3207 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:    919/156230 | global iter:    919/156230 | loss: 1.3083 | ds_loss: 1.3175 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:    920/156230 | global iter:    920/156230 | loss: 1.0148 | ds_loss: 1.0161 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    920/156230 | global iter:    920/156230 | loss: 1.2667 | ds_loss: 1.2718 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.360 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    921/156230 | global iter:    921/156230 | loss: 1.1011 | ds_loss: 1.1019 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:    922/156230 | global iter:    922/156230 | loss: 1.1349 | ds_loss: 1.1275 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:    923/156230 | global iter:    923/156230 | loss: 1.2709 | ds_loss: 1.2828 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:    924/156230 | global iter:    924/156230 | loss: 1.2878 | ds_loss: 1.2990 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    924/156230 | global iter:    924/156230 | loss: 1.1987 | ds_loss: 1.2028 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.355 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    925/156230 | global iter:    925/156230 | loss: 1.2064 | ds_loss: 1.2228 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:    926/156230 | global iter:    926/156230 | loss: 1.1090 | ds_loss: 1.1046 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:    927/156230 | global iter:    927/156230 | loss: 1.1825 | ds_loss: 1.1929 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:    928/156230 | global iter:    928/156230 | loss: 1.1658 | ds_loss: 1.1547 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    928/156230 | global iter:    928/156230 | loss: 1.1659 | ds_loss: 1.1687 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.347 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    929/156230 | global iter:    929/156230 | loss: 1.2077 | ds_loss: 1.2237 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:    930/156230 | global iter:    930/156230 | loss: 0.9613 | ds_loss: 0.9547 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:    931/156230 | global iter:    931/156230 | loss: 1.1903 | ds_loss: 1.1969 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:    932/156230 | global iter:    932/156230 | loss: 1.3207 | ds_loss: 1.3371 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    932/156230 | global iter:    932/156230 | loss: 1.1700 | ds_loss: 1.1781 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    933/156230 | global iter:    933/156230 | loss: 1.3481 | ds_loss: 1.3575 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:    934/156230 | global iter:    934/156230 | loss: 1.2465 | ds_loss: 1.2589 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:    935/156230 | global iter:    935/156230 | loss: 1.3921 | ds_loss: 1.4163 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.404 | step time: 0.000
train | epoch   0 | Iter:    936/156230 | global iter:    936/156230 | loss: 1.3682 | ds_loss: 1.3767 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.343 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    936/156230 | global iter:    936/156230 | loss: 1.3387 | ds_loss: 1.3523 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.343 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    937/156230 | global iter:    937/156230 | loss: 1.3993 | ds_loss: 1.4019 | lr: 9.9992e-05 | scale:  4096.0000 | micro time: 1.406 | step time: 0.000
train | epoch   0 | Iter:    938/156230 | global iter:    938/156230 | loss: 1.3006 | ds_loss: 1.3015 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:    939/156230 | global iter:    939/156230 | loss: 1.2430 | ds_loss: 1.2504 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:    940/156230 | global iter:    940/156230 | loss: 1.1023 | ds_loss: 1.1039 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    940/156230 | global iter:    940/156230 | loss: 1.2613 | ds_loss: 1.2644 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.394 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    941/156230 | global iter:    941/156230 | loss: 1.2591 | ds_loss: 1.2526 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:    942/156230 | global iter:    942/156230 | loss: 1.3788 | ds_loss: 1.3671 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:    943/156230 | global iter:    943/156230 | loss: 1.1351 | ds_loss: 1.1436 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:    944/156230 | global iter:    944/156230 | loss: 1.2166 | ds_loss: 1.2373 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    944/156230 | global iter:    944/156230 | loss: 1.2474 | ds_loss: 1.2501 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    945/156230 | global iter:    945/156230 | loss: 1.3314 | ds_loss: 1.3269 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:    946/156230 | global iter:    946/156230 | loss: 1.0991 | ds_loss: 1.0975 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:    947/156230 | global iter:    947/156230 | loss: 1.3184 | ds_loss: 1.3218 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:    948/156230 | global iter:    948/156230 | loss: 1.3537 | ds_loss: 1.3592 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    948/156230 | global iter:    948/156230 | loss: 1.2757 | ds_loss: 1.2763 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.397 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    949/156230 | global iter:    949/156230 | loss: 1.4050 | ds_loss: 1.4159 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:    950/156230 | global iter:    950/156230 | loss: 1.2213 | ds_loss: 1.2364 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:    951/156230 | global iter:    951/156230 | loss: 1.3467 | ds_loss: 1.3423 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:    952/156230 | global iter:    952/156230 | loss: 1.2213 | ds_loss: 1.2367 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    952/156230 | global iter:    952/156230 | loss: 1.2986 | ds_loss: 1.3078 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.351 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    953/156230 | global iter:    953/156230 | loss: 1.1293 | ds_loss: 1.1377 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:    954/156230 | global iter:    954/156230 | loss: 1.1777 | ds_loss: 1.1949 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:    955/156230 | global iter:    955/156230 | loss: 1.2736 | ds_loss: 1.2688 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:    956/156230 | global iter:    956/156230 | loss: 1.3752 | ds_loss: 1.3715 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    956/156230 | global iter:    956/156230 | loss: 1.2390 | ds_loss: 1.2432 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.399 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    957/156230 | global iter:    957/156230 | loss: 1.3679 | ds_loss: 1.3701 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.412 | step time: 0.000
train | epoch   0 | Iter:    958/156230 | global iter:    958/156230 | loss: 1.2272 | ds_loss: 1.2249 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.325 | step time: 0.000
train | epoch   0 | Iter:    959/156230 | global iter:    959/156230 | loss: 1.1942 | ds_loss: 1.2035 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:    960/156230 | global iter:    960/156230 | loss: 1.1149 | ds_loss: 1.1125 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.335 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    960/156230 | global iter:    960/156230 | loss: 1.2260 | ds_loss: 1.2278 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.335 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    961/156230 | global iter:    961/156230 | loss: 1.3431 | ds_loss: 1.3344 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:    962/156230 | global iter:    962/156230 | loss: 1.3534 | ds_loss: 1.3739 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:    963/156230 | global iter:    963/156230 | loss: 1.1168 | ds_loss: 1.1098 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:    964/156230 | global iter:    964/156230 | loss: 1.2215 | ds_loss: 1.2430 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    964/156230 | global iter:    964/156230 | loss: 1.2587 | ds_loss: 1.2653 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.355 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    965/156230 | global iter:    965/156230 | loss: 1.2925 | ds_loss: 1.2965 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:    966/156230 | global iter:    966/156230 | loss: 1.2002 | ds_loss: 1.2018 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:    967/156230 | global iter:    967/156230 | loss: 1.2231 | ds_loss: 1.2509 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:    968/156230 | global iter:    968/156230 | loss: 1.1549 | ds_loss: 1.1651 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    968/156230 | global iter:    968/156230 | loss: 1.2177 | ds_loss: 1.2286 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.362 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    969/156230 | global iter:    969/156230 | loss: 1.3081 | ds_loss: 1.3128 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:    970/156230 | global iter:    970/156230 | loss: 1.1059 | ds_loss: 1.1190 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:    971/156230 | global iter:    971/156230 | loss: 1.0603 | ds_loss: 1.0633 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:    972/156230 | global iter:    972/156230 | loss: 1.2857 | ds_loss: 1.2781 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    972/156230 | global iter:    972/156230 | loss: 1.1900 | ds_loss: 1.1933 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.363 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    973/156230 | global iter:    973/156230 | loss: 1.3916 | ds_loss: 1.4052 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:    974/156230 | global iter:    974/156230 | loss: 1.1910 | ds_loss: 1.1966 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:    975/156230 | global iter:    975/156230 | loss: 1.1965 | ds_loss: 1.1888 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.401 | step time: 0.000
train | epoch   0 | Iter:    976/156230 | global iter:    976/156230 | loss: 1.0787 | ds_loss: 1.0801 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    976/156230 | global iter:    976/156230 | loss: 1.2144 | ds_loss: 1.2177 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.347 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    977/156230 | global iter:    977/156230 | loss: 1.2223 | ds_loss: 1.2275 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:    978/156230 | global iter:    978/156230 | loss: 1.3108 | ds_loss: 1.3130 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:    979/156230 | global iter:    979/156230 | loss: 1.4953 | ds_loss: 1.4931 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:    980/156230 | global iter:    980/156230 | loss: 1.2017 | ds_loss: 1.2229 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    980/156230 | global iter:    980/156230 | loss: 1.3075 | ds_loss: 1.3141 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.366 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    981/156230 | global iter:    981/156230 | loss: 1.2897 | ds_loss: 1.2749 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:    982/156230 | global iter:    982/156230 | loss: 1.0812 | ds_loss: 1.1066 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:    983/156230 | global iter:    983/156230 | loss: 1.3140 | ds_loss: 1.3136 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:    984/156230 | global iter:    984/156230 | loss: 1.1591 | ds_loss: 1.1582 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.331 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    984/156230 | global iter:    984/156230 | loss: 1.2110 | ds_loss: 1.2133 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.331 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    985/156230 | global iter:    985/156230 | loss: 1.2050 | ds_loss: 1.2147 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:    986/156230 | global iter:    986/156230 | loss: 1.2734 | ds_loss: 1.2753 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:    987/156230 | global iter:    987/156230 | loss: 1.1517 | ds_loss: 1.1621 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:    988/156230 | global iter:    988/156230 | loss: 1.3517 | ds_loss: 1.3348 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.387 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    988/156230 | global iter:    988/156230 | loss: 1.2455 | ds_loss: 1.2467 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.387 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    989/156230 | global iter:    989/156230 | loss: 1.3228 | ds_loss: 1.3257 | lr: 9.9991e-05 | scale:  4096.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:    990/156230 | global iter:    990/156230 | loss: 1.2945 | ds_loss: 1.2990 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:    991/156230 | global iter:    991/156230 | loss: 1.1517 | ds_loss: 1.1563 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:    992/156230 | global iter:    992/156230 | loss: 1.1924 | ds_loss: 1.1987 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.338 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    992/156230 | global iter:    992/156230 | loss: 1.2403 | ds_loss: 1.2449 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.338 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    993/156230 | global iter:    993/156230 | loss: 1.4056 | ds_loss: 1.4040 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:    994/156230 | global iter:    994/156230 | loss: 0.9370 | ds_loss: 0.9331 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:    995/156230 | global iter:    995/156230 | loss: 1.1152 | ds_loss: 1.1172 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:    996/156230 | global iter:    996/156230 | loss: 1.3481 | ds_loss: 1.3475 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.383 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:    996/156230 | global iter:    996/156230 | loss: 1.2015 | ds_loss: 1.2004 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.383 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:    997/156230 | global iter:    997/156230 | loss: 1.2758 | ds_loss: 1.2808 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:    998/156230 | global iter:    998/156230 | loss: 1.1570 | ds_loss: 1.1573 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:    999/156230 | global iter:    999/156230 | loss: 1.3334 | ds_loss: 1.3575 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   1000/156230 | global iter:   1000/156230 | loss: 1.1107 | ds_loss: 1.1144 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.324 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1000/156230 | global iter:   1000/156230 | loss: 1.2192 | ds_loss: 1.2275 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.324 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1001/156230 | global iter:   1001/156230 | loss: 1.3600 | ds_loss: 1.3562 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   1002/156230 | global iter:   1002/156230 | loss: 1.1058 | ds_loss: 1.1184 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   1003/156230 | global iter:   1003/156230 | loss: 1.3775 | ds_loss: 1.3926 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   1004/156230 | global iter:   1004/156230 | loss: 1.2527 | ds_loss: 1.2696 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1004/156230 | global iter:   1004/156230 | loss: 1.2740 | ds_loss: 1.2842 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.376 | step time: 1.384
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1005/156230 | global iter:   1005/156230 | loss: 1.3383 | ds_loss: 1.3299 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   1006/156230 | global iter:   1006/156230 | loss: 1.2610 | ds_loss: 1.2634 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   1007/156230 | global iter:   1007/156230 | loss: 1.1111 | ds_loss: 1.1188 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   1008/156230 | global iter:   1008/156230 | loss: 1.2594 | ds_loss: 1.2862 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1008/156230 | global iter:   1008/156230 | loss: 1.2425 | ds_loss: 1.2496 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1009/156230 | global iter:   1009/156230 | loss: 1.2285 | ds_loss: 1.2306 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   1010/156230 | global iter:   1010/156230 | loss: 1.1867 | ds_loss: 1.1854 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   1011/156230 | global iter:   1011/156230 | loss: 1.3348 | ds_loss: 1.3434 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   1012/156230 | global iter:   1012/156230 | loss: 1.0737 | ds_loss: 1.0796 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1012/156230 | global iter:   1012/156230 | loss: 1.2059 | ds_loss: 1.2098 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.373 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1013/156230 | global iter:   1013/156230 | loss: 1.3188 | ds_loss: 1.3183 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   1014/156230 | global iter:   1014/156230 | loss: 1.3683 | ds_loss: 1.3901 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   1015/156230 | global iter:   1015/156230 | loss: 1.2695 | ds_loss: 1.2820 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   1016/156230 | global iter:   1016/156230 | loss: 1.1078 | ds_loss: 1.1268 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.320 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1016/156230 | global iter:   1016/156230 | loss: 1.2661 | ds_loss: 1.2793 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.320 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1017/156230 | global iter:   1017/156230 | loss: 1.2776 | ds_loss: 1.2950 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   1018/156230 | global iter:   1018/156230 | loss: 1.2549 | ds_loss: 1.2495 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.317 | step time: 0.000
train | epoch   0 | Iter:   1019/156230 | global iter:   1019/156230 | loss: 1.1006 | ds_loss: 1.1054 | lr: 9.9990e-05 | scale:  4096.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   1020/156230 | global iter:   1020/156230 | loss: 1.3297 | ds_loss: 1.3466 | lr: 9.9990e-05 | scale:  8192.0000 | micro time: 1.429 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1020/156230 | global iter:   1020/156230 | loss: 1.2407 | ds_loss: 1.2491 | lr: 9.9990e-05 | scale:  8192.0000 | micro time: 1.429 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1021/156230 | global iter:   1021/156230 | loss: 1.2283 | ds_loss: 1.2302 | lr: 9.9990e-05 | scale:  8192.0000 | micro time: 1.403 | step time: 0.000
train | epoch   0 | Iter:   1022/156230 | global iter:   1022/156230 | loss: 1.1637 | ds_loss: 1.1752 | lr: 9.9990e-05 | scale:  8192.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   1023/156230 | global iter:   1023/156230 | loss: 1.2009 | ds_loss: 1.2116 | lr: 9.9990e-05 | scale:  8192.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   1024/156230 | global iter:   1024/156230 | loss: 1.2188 | ds_loss: 1.2133 | lr: 9.9990e-05 | scale:  8192.0000 | micro time: 1.356 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1024/156230 | global iter:   1024/156230 | loss: 1.2029 | ds_loss: 1.2076 | lr: 9.9990e-05 | scale:  8192.0000 | micro time: 1.356 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1025/156230 | global iter:   1025/156230 | loss: 1.2095 | ds_loss: 1.2286 | lr: 9.9990e-05 | scale:  8192.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   1026/156230 | global iter:   1026/156230 | loss: 1.3264 | ds_loss: 1.3209 | lr: 9.9990e-05 | scale:  8192.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   1027/156230 | global iter:   1027/156230 | loss: 1.1816 | ds_loss: 1.1831 | lr: 9.9990e-05 | scale:  8192.0000 | micro time: 1.406 | step time: 0.000
train | epoch   0 | Iter:   1028/156230 | global iter:   1028/156230 | loss: 1.1214 | ds_loss: 1.1261 | lr: 9.9990e-05 | scale:  8192.0000 | micro time: 1.383 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1028/156230 | global iter:   1028/156230 | loss: 1.2097 | ds_loss: 1.2147 | lr: 9.9990e-05 | scale:  8192.0000 | micro time: 1.383 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1029/156230 | global iter:   1029/156230 | loss: 1.2427 | ds_loss: 1.2400 | lr: 9.9990e-05 | scale:  8192.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   1030/156230 | global iter:   1030/156230 | loss: 1.2686 | ds_loss: 1.2883 | lr: 9.9990e-05 | scale:  8192.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   1031/156230 | global iter:   1031/156230 | loss: 1.4308 | ds_loss: 1.4514 | lr: 9.9990e-05 | scale:  8192.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   1032/156230 | global iter:   1032/156230 | loss: 1.1916 | ds_loss: 1.1998 | lr: 9.9990e-05 | scale:  8192.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1032/156230 | global iter:   1032/156230 | loss: 1.2834 | ds_loss: 1.2949 | lr: 9.9990e-05 | scale:  8192.0000 | micro time: 1.355 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1033/156230 | global iter:   1033/156230 | loss: 1.0341 | ds_loss: 1.0384 | lr: 9.9990e-05 | scale:  8192.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   1034/156230 | global iter:   1034/156230 | loss: 1.2470 | ds_loss: 1.2405 | lr: 9.9990e-05 | scale:  8192.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   1035/156230 | global iter:   1035/156230 | loss: 1.1126 | ds_loss: 1.1354 | lr: 9.9990e-05 | scale:  8192.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   1036/156230 | global iter:   1036/156230 | loss: 1.2283 | ds_loss: 1.2357 | lr: 9.9990e-05 | scale:  8192.0000 | micro time: 1.375 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1036/156230 | global iter:   1036/156230 | loss: 1.1555 | ds_loss: 1.1625 | lr: 9.9990e-05 | scale:  8192.0000 | micro time: 1.375 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1037/156230 | global iter:   1037/156230 | loss: 1.2636 | ds_loss: 1.2684 | lr: 9.9990e-05 | scale:  8192.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   1038/156230 | global iter:   1038/156230 | loss: 1.3355 | ds_loss: 1.3440 | lr: 9.9990e-05 | scale:  8192.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   1039/156230 | global iter:   1039/156230 | loss: 1.2840 | ds_loss: 1.2810 | lr: 9.9990e-05 | scale:  8192.0000 | micro time: 1.401 | step time: 0.000
train | epoch   0 | Iter:   1040/156230 | global iter:   1040/156230 | loss: 1.3081 | ds_loss: 1.3305 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.331 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1040/156230 | global iter:   1040/156230 | loss: 1.2978 | ds_loss: 1.3060 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.331 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1041/156230 | global iter:   1041/156230 | loss: 1.2858 | ds_loss: 1.2872 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   1042/156230 | global iter:   1042/156230 | loss: 1.1704 | ds_loss: 1.1675 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.404 | step time: 0.000
train | epoch   0 | Iter:   1043/156230 | global iter:   1043/156230 | loss: 1.2305 | ds_loss: 1.2348 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   1044/156230 | global iter:   1044/156230 | loss: 1.1252 | ds_loss: 1.1366 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1044/156230 | global iter:   1044/156230 | loss: 1.2030 | ds_loss: 1.2065 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.345 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1045/156230 | global iter:   1045/156230 | loss: 1.4192 | ds_loss: 1.4239 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   1046/156230 | global iter:   1046/156230 | loss: 1.0601 | ds_loss: 1.0556 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   1047/156230 | global iter:   1047/156230 | loss: 1.0856 | ds_loss: 1.1049 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   1048/156230 | global iter:   1048/156230 | loss: 1.1456 | ds_loss: 1.1582 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.358 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1048/156230 | global iter:   1048/156230 | loss: 1.1776 | ds_loss: 1.1856 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.358 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1049/156230 | global iter:   1049/156230 | loss: 1.2924 | ds_loss: 1.2960 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   1050/156230 | global iter:   1050/156230 | loss: 1.1908 | ds_loss: 1.1950 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.406 | step time: 0.000
train | epoch   0 | Iter:   1051/156230 | global iter:   1051/156230 | loss: 1.1319 | ds_loss: 1.1437 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   1052/156230 | global iter:   1052/156230 | loss: 1.1367 | ds_loss: 1.1335 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1052/156230 | global iter:   1052/156230 | loss: 1.1880 | ds_loss: 1.1921 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.357 | step time: 1.382
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1053/156230 | global iter:   1053/156230 | loss: 1.2382 | ds_loss: 1.2344 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   1054/156230 | global iter:   1054/156230 | loss: 1.2374 | ds_loss: 1.2521 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   1055/156230 | global iter:   1055/156230 | loss: 1.3499 | ds_loss: 1.3529 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   1056/156230 | global iter:   1056/156230 | loss: 1.2118 | ds_loss: 1.2251 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.356 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1056/156230 | global iter:   1056/156230 | loss: 1.2593 | ds_loss: 1.2661 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.356 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1057/156230 | global iter:   1057/156230 | loss: 1.2970 | ds_loss: 1.2984 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   1058/156230 | global iter:   1058/156230 | loss: 1.0973 | ds_loss: 1.1084 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   1059/156230 | global iter:   1059/156230 | loss: 1.2714 | ds_loss: 1.2891 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   1060/156230 | global iter:   1060/156230 | loss: 1.0855 | ds_loss: 1.0855 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.330 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1060/156230 | global iter:   1060/156230 | loss: 1.1878 | ds_loss: 1.1954 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.330 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1061/156230 | global iter:   1061/156230 | loss: 1.2654 | ds_loss: 1.2723 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   1062/156230 | global iter:   1062/156230 | loss: 1.2717 | ds_loss: 1.2802 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   1063/156230 | global iter:   1063/156230 | loss: 1.3246 | ds_loss: 1.3215 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:   1064/156230 | global iter:   1064/156230 | loss: 1.1605 | ds_loss: 1.1760 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1064/156230 | global iter:   1064/156230 | loss: 1.2555 | ds_loss: 1.2625 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.393 | step time: 1.394
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1065/156230 | global iter:   1065/156230 | loss: 1.2343 | ds_loss: 1.2623 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   1066/156230 | global iter:   1066/156230 | loss: 1.3103 | ds_loss: 1.3164 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   1067/156230 | global iter:   1067/156230 | loss: 1.1470 | ds_loss: 1.1541 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.315 | step time: 0.000
train | epoch   0 | Iter:   1068/156230 | global iter:   1068/156230 | loss: 1.2253 | ds_loss: 1.2157 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1068/156230 | global iter:   1068/156230 | loss: 1.2293 | ds_loss: 1.2371 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.365 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1069/156230 | global iter:   1069/156230 | loss: 1.2516 | ds_loss: 1.2692 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   1070/156230 | global iter:   1070/156230 | loss: 1.2856 | ds_loss: 1.2936 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   1071/156230 | global iter:   1071/156230 | loss: 1.3520 | ds_loss: 1.3364 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   1072/156230 | global iter:   1072/156230 | loss: 1.2448 | ds_loss: 1.2501 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1072/156230 | global iter:   1072/156230 | loss: 1.2835 | ds_loss: 1.2873 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1073/156230 | global iter:   1073/156230 | loss: 1.3444 | ds_loss: 1.3548 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   1074/156230 | global iter:   1074/156230 | loss: 1.2406 | ds_loss: 1.2542 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   1075/156230 | global iter:   1075/156230 | loss: 1.1345 | ds_loss: 1.1542 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   1076/156230 | global iter:   1076/156230 | loss: 1.2202 | ds_loss: 1.2125 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.343 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1076/156230 | global iter:   1076/156230 | loss: 1.2349 | ds_loss: 1.2440 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.343 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1077/156230 | global iter:   1077/156230 | loss: 1.0943 | ds_loss: 1.1057 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   1078/156230 | global iter:   1078/156230 | loss: 1.1903 | ds_loss: 1.1998 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   1079/156230 | global iter:   1079/156230 | loss: 0.9931 | ds_loss: 1.0029 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   1080/156230 | global iter:   1080/156230 | loss: 1.1492 | ds_loss: 1.1599 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1080/156230 | global iter:   1080/156230 | loss: 1.1067 | ds_loss: 1.1171 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.365 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1081/156230 | global iter:   1081/156230 | loss: 1.2472 | ds_loss: 1.2560 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   1082/156230 | global iter:   1082/156230 | loss: 1.2528 | ds_loss: 1.2673 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   1083/156230 | global iter:   1083/156230 | loss: 1.2805 | ds_loss: 1.2865 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   1084/156230 | global iter:   1084/156230 | loss: 1.2588 | ds_loss: 1.2665 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1084/156230 | global iter:   1084/156230 | loss: 1.2598 | ds_loss: 1.2691 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1085/156230 | global iter:   1085/156230 | loss: 1.1326 | ds_loss: 1.1613 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.407 | step time: 0.000
train | epoch   0 | Iter:   1086/156230 | global iter:   1086/156230 | loss: 1.2139 | ds_loss: 1.2031 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   1087/156230 | global iter:   1087/156230 | loss: 1.2252 | ds_loss: 1.2330 | lr: 9.9989e-05 | scale:  8192.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   1088/156230 | global iter:   1088/156230 | loss: 1.1155 | ds_loss: 1.1269 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.359 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1088/156230 | global iter:   1088/156230 | loss: 1.1718 | ds_loss: 1.1811 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.359 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1089/156230 | global iter:   1089/156230 | loss: 1.2027 | ds_loss: 1.2006 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.320 | step time: 0.000
train | epoch   0 | Iter:   1090/156230 | global iter:   1090/156230 | loss: 1.2823 | ds_loss: 1.2995 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   1091/156230 | global iter:   1091/156230 | loss: 1.0537 | ds_loss: 1.0699 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   1092/156230 | global iter:   1092/156230 | loss: 1.2354 | ds_loss: 1.2388 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1092/156230 | global iter:   1092/156230 | loss: 1.1935 | ds_loss: 1.2022 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.393 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1093/156230 | global iter:   1093/156230 | loss: 1.2579 | ds_loss: 1.2652 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   1094/156230 | global iter:   1094/156230 | loss: 1.2656 | ds_loss: 1.2576 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   1095/156230 | global iter:   1095/156230 | loss: 1.0507 | ds_loss: 1.0512 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   1096/156230 | global iter:   1096/156230 | loss: 1.1645 | ds_loss: 1.1854 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.408 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1096/156230 | global iter:   1096/156230 | loss: 1.1847 | ds_loss: 1.1898 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.408 | step time: 1.376
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1097/156230 | global iter:   1097/156230 | loss: 1.2245 | ds_loss: 1.2335 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   1098/156230 | global iter:   1098/156230 | loss: 1.1227 | ds_loss: 1.1326 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   1099/156230 | global iter:   1099/156230 | loss: 1.2819 | ds_loss: 1.2804 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   1100/156230 | global iter:   1100/156230 | loss: 1.3144 | ds_loss: 1.3277 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1100/156230 | global iter:   1100/156230 | loss: 1.2359 | ds_loss: 1.2436 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1101/156230 | global iter:   1101/156230 | loss: 1.2870 | ds_loss: 1.2863 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   1102/156230 | global iter:   1102/156230 | loss: 1.1712 | ds_loss: 1.1608 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.318 | step time: 0.000
train | epoch   0 | Iter:   1103/156230 | global iter:   1103/156230 | loss: 1.1847 | ds_loss: 1.1870 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   1104/156230 | global iter:   1104/156230 | loss: 1.1830 | ds_loss: 1.1908 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.330 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1104/156230 | global iter:   1104/156230 | loss: 1.2064 | ds_loss: 1.2062 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.330 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1105/156230 | global iter:   1105/156230 | loss: 1.3130 | ds_loss: 1.3202 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   1106/156230 | global iter:   1106/156230 | loss: 1.0501 | ds_loss: 1.0503 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   1107/156230 | global iter:   1107/156230 | loss: 1.3854 | ds_loss: 1.3976 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   1108/156230 | global iter:   1108/156230 | loss: 1.1863 | ds_loss: 1.1846 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1108/156230 | global iter:   1108/156230 | loss: 1.2337 | ds_loss: 1.2382 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.385 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1109/156230 | global iter:   1109/156230 | loss: 1.2600 | ds_loss: 1.2657 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   1110/156230 | global iter:   1110/156230 | loss: 1.3404 | ds_loss: 1.3477 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   1111/156230 | global iter:   1111/156230 | loss: 1.1508 | ds_loss: 1.1508 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   1112/156230 | global iter:   1112/156230 | loss: 1.1184 | ds_loss: 1.1220 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.384 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1112/156230 | global iter:   1112/156230 | loss: 1.2174 | ds_loss: 1.2216 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.384 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1113/156230 | global iter:   1113/156230 | loss: 1.2792 | ds_loss: 1.2676 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   1114/156230 | global iter:   1114/156230 | loss: 1.0871 | ds_loss: 1.0760 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   1115/156230 | global iter:   1115/156230 | loss: 1.3468 | ds_loss: 1.3330 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   1116/156230 | global iter:   1116/156230 | loss: 1.2397 | ds_loss: 1.2376 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1116/156230 | global iter:   1116/156230 | loss: 1.2382 | ds_loss: 1.2286 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.393 | step time: 1.381
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1117/156230 | global iter:   1117/156230 | loss: 1.3419 | ds_loss: 1.3484 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   1118/156230 | global iter:   1118/156230 | loss: 1.3038 | ds_loss: 1.2944 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   1119/156230 | global iter:   1119/156230 | loss: 1.1394 | ds_loss: 1.1375 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   1120/156230 | global iter:   1120/156230 | loss: 1.2213 | ds_loss: 1.2286 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1120/156230 | global iter:   1120/156230 | loss: 1.2516 | ds_loss: 1.2522 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.347 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1121/156230 | global iter:   1121/156230 | loss: 1.2329 | ds_loss: 1.2412 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   1122/156230 | global iter:   1122/156230 | loss: 1.3844 | ds_loss: 1.3958 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   1123/156230 | global iter:   1123/156230 | loss: 1.2458 | ds_loss: 1.2459 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   1124/156230 | global iter:   1124/156230 | loss: 1.1403 | ds_loss: 1.1599 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.332 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1124/156230 | global iter:   1124/156230 | loss: 1.2508 | ds_loss: 1.2607 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.332 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1125/156230 | global iter:   1125/156230 | loss: 1.3151 | ds_loss: 1.3401 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   1126/156230 | global iter:   1126/156230 | loss: 1.1885 | ds_loss: 1.1933 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   1127/156230 | global iter:   1127/156230 | loss: 1.2149 | ds_loss: 1.2192 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   1128/156230 | global iter:   1128/156230 | loss: 1.1113 | ds_loss: 1.1162 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.341 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1128/156230 | global iter:   1128/156230 | loss: 1.2074 | ds_loss: 1.2172 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.341 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1129/156230 | global iter:   1129/156230 | loss: 1.3469 | ds_loss: 1.3643 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   1130/156230 | global iter:   1130/156230 | loss: 1.2339 | ds_loss: 1.2409 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   1131/156230 | global iter:   1131/156230 | loss: 1.1123 | ds_loss: 1.1153 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   1132/156230 | global iter:   1132/156230 | loss: 1.3775 | ds_loss: 1.3871 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1132/156230 | global iter:   1132/156230 | loss: 1.2676 | ds_loss: 1.2769 | lr: 9.9988e-05 | scale:  8192.0000 | micro time: 1.373 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1133/156230 | global iter:   1133/156230 | loss: 1.1885 | ds_loss: 1.2103 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   1134/156230 | global iter:   1134/156230 | loss: 1.2293 | ds_loss: 1.2327 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   1135/156230 | global iter:   1135/156230 | loss: 1.2994 | ds_loss: 1.2930 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   1136/156230 | global iter:   1136/156230 | loss: 1.2774 | ds_loss: 1.2853 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.380 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1136/156230 | global iter:   1136/156230 | loss: 1.2487 | ds_loss: 1.2553 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.380 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1137/156230 | global iter:   1137/156230 | loss: 1.2709 | ds_loss: 1.2777 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   1138/156230 | global iter:   1138/156230 | loss: 1.3479 | ds_loss: 1.3602 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   1139/156230 | global iter:   1139/156230 | loss: 1.0360 | ds_loss: 1.0455 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   1140/156230 | global iter:   1140/156230 | loss: 1.2902 | ds_loss: 1.2980 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.348 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1140/156230 | global iter:   1140/156230 | loss: 1.2362 | ds_loss: 1.2453 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.348 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1141/156230 | global iter:   1141/156230 | loss: 1.1537 | ds_loss: 1.1538 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   1142/156230 | global iter:   1142/156230 | loss: 1.3338 | ds_loss: 1.3327 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   1143/156230 | global iter:   1143/156230 | loss: 1.2010 | ds_loss: 1.2016 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   1144/156230 | global iter:   1144/156230 | loss: 1.2527 | ds_loss: 1.2494 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1144/156230 | global iter:   1144/156230 | loss: 1.2353 | ds_loss: 1.2344 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.370 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1145/156230 | global iter:   1145/156230 | loss: 1.2040 | ds_loss: 1.2152 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   1146/156230 | global iter:   1146/156230 | loss: 1.3258 | ds_loss: 1.3217 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   1147/156230 | global iter:   1147/156230 | loss: 1.2040 | ds_loss: 1.2053 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   1148/156230 | global iter:   1148/156230 | loss: 1.2541 | ds_loss: 1.2629 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1148/156230 | global iter:   1148/156230 | loss: 1.2469 | ds_loss: 1.2513 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1149/156230 | global iter:   1149/156230 | loss: 1.3086 | ds_loss: 1.3151 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   1150/156230 | global iter:   1150/156230 | loss: 1.1486 | ds_loss: 1.1622 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   1151/156230 | global iter:   1151/156230 | loss: 1.2060 | ds_loss: 1.2069 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.465 | step time: 0.000
train | epoch   0 | Iter:   1152/156230 | global iter:   1152/156230 | loss: 1.2146 | ds_loss: 1.2171 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.331 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1152/156230 | global iter:   1152/156230 | loss: 1.2194 | ds_loss: 1.2254 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.331 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1153/156230 | global iter:   1153/156230 | loss: 1.3181 | ds_loss: 1.3246 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   1154/156230 | global iter:   1154/156230 | loss: 1.3171 | ds_loss: 1.3136 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   1155/156230 | global iter:   1155/156230 | loss: 1.1880 | ds_loss: 1.2016 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   1156/156230 | global iter:   1156/156230 | loss: 1.1408 | ds_loss: 1.1553 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1156/156230 | global iter:   1156/156230 | loss: 1.2410 | ds_loss: 1.2488 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1157/156230 | global iter:   1157/156230 | loss: 1.2573 | ds_loss: 1.2564 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   1158/156230 | global iter:   1158/156230 | loss: 1.0000 | ds_loss: 1.0087 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   1159/156230 | global iter:   1159/156230 | loss: 1.3171 | ds_loss: 1.3352 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.402 | step time: 0.000
train | epoch   0 | Iter:   1160/156230 | global iter:   1160/156230 | loss: 1.0850 | ds_loss: 1.0926 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1160/156230 | global iter:   1160/156230 | loss: 1.1648 | ds_loss: 1.1733 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.357 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1161/156230 | global iter:   1161/156230 | loss: 1.4059 | ds_loss: 1.4149 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   1162/156230 | global iter:   1162/156230 | loss: 1.3042 | ds_loss: 1.3087 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.407 | step time: 0.000
train | epoch   0 | Iter:   1163/156230 | global iter:   1163/156230 | loss: 1.4708 | ds_loss: 1.4670 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.308 | step time: 0.000
train | epoch   0 | Iter:   1164/156230 | global iter:   1164/156230 | loss: 1.2472 | ds_loss: 1.2517 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.405 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1164/156230 | global iter:   1164/156230 | loss: 1.3570 | ds_loss: 1.3606 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.405 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1165/156230 | global iter:   1165/156230 | loss: 1.0565 | ds_loss: 1.0660 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   1166/156230 | global iter:   1166/156230 | loss: 1.2258 | ds_loss: 1.2378 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   1167/156230 | global iter:   1167/156230 | loss: 1.4003 | ds_loss: 1.4056 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   1168/156230 | global iter:   1168/156230 | loss: 1.2507 | ds_loss: 1.2459 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1168/156230 | global iter:   1168/156230 | loss: 1.2333 | ds_loss: 1.2388 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.373 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1169/156230 | global iter:   1169/156230 | loss: 1.2005 | ds_loss: 1.1938 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   1170/156230 | global iter:   1170/156230 | loss: 1.0857 | ds_loss: 1.0953 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   1171/156230 | global iter:   1171/156230 | loss: 1.2208 | ds_loss: 1.2088 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   1172/156230 | global iter:   1172/156230 | loss: 1.1583 | ds_loss: 1.1652 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.390 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1172/156230 | global iter:   1172/156230 | loss: 1.1663 | ds_loss: 1.1658 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.390 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1173/156230 | global iter:   1173/156230 | loss: 1.1507 | ds_loss: 1.1573 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.407 | step time: 0.000
train | epoch   0 | Iter:   1174/156230 | global iter:   1174/156230 | loss: 1.3137 | ds_loss: 1.3199 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   1175/156230 | global iter:   1175/156230 | loss: 1.3014 | ds_loss: 1.2975 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   1176/156230 | global iter:   1176/156230 | loss: 1.3269 | ds_loss: 1.3464 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.372 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1176/156230 | global iter:   1176/156230 | loss: 1.2732 | ds_loss: 1.2803 | lr: 9.9987e-05 | scale:  8192.0000 | micro time: 1.372 | step time: 1.382
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1177/156230 | global iter:   1177/156230 | loss: 1.2919 | ds_loss: 1.2950 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:   1178/156230 | global iter:   1178/156230 | loss: 1.1006 | ds_loss: 1.1068 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   1179/156230 | global iter:   1179/156230 | loss: 1.2988 | ds_loss: 1.3088 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   1180/156230 | global iter:   1180/156230 | loss: 1.1514 | ds_loss: 1.1493 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.344 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1180/156230 | global iter:   1180/156230 | loss: 1.2107 | ds_loss: 1.2150 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.344 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1181/156230 | global iter:   1181/156230 | loss: 1.0948 | ds_loss: 1.1097 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   1182/156230 | global iter:   1182/156230 | loss: 1.2220 | ds_loss: 1.2331 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   1183/156230 | global iter:   1183/156230 | loss: 1.2614 | ds_loss: 1.2690 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   1184/156230 | global iter:   1184/156230 | loss: 1.2545 | ds_loss: 1.2637 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1184/156230 | global iter:   1184/156230 | loss: 1.2082 | ds_loss: 1.2189 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.368 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1185/156230 | global iter:   1185/156230 | loss: 1.2391 | ds_loss: 1.2599 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   1186/156230 | global iter:   1186/156230 | loss: 1.3141 | ds_loss: 1.3245 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   1187/156230 | global iter:   1187/156230 | loss: 1.3955 | ds_loss: 1.3990 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   1188/156230 | global iter:   1188/156230 | loss: 1.1584 | ds_loss: 1.1686 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.356 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1188/156230 | global iter:   1188/156230 | loss: 1.2768 | ds_loss: 1.2880 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.356 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1189/156230 | global iter:   1189/156230 | loss: 1.2255 | ds_loss: 1.2247 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   1190/156230 | global iter:   1190/156230 | loss: 1.1856 | ds_loss: 1.1857 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   1191/156230 | global iter:   1191/156230 | loss: 1.3253 | ds_loss: 1.3274 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.413 | step time: 0.000
train | epoch   0 | Iter:   1192/156230 | global iter:   1192/156230 | loss: 1.1919 | ds_loss: 1.1855 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1192/156230 | global iter:   1192/156230 | loss: 1.2321 | ds_loss: 1.2308 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1193/156230 | global iter:   1193/156230 | loss: 1.3090 | ds_loss: 1.3073 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   1194/156230 | global iter:   1194/156230 | loss: 1.1732 | ds_loss: 1.1739 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.410 | step time: 0.000
train | epoch   0 | Iter:   1195/156230 | global iter:   1195/156230 | loss: 1.2932 | ds_loss: 1.3059 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   1196/156230 | global iter:   1196/156230 | loss: 1.1286 | ds_loss: 1.1347 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.380 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1196/156230 | global iter:   1196/156230 | loss: 1.2260 | ds_loss: 1.2305 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.380 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1197/156230 | global iter:   1197/156230 | loss: 1.3122 | ds_loss: 1.3276 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   1198/156230 | global iter:   1198/156230 | loss: 1.1979 | ds_loss: 1.2076 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   1199/156230 | global iter:   1199/156230 | loss: 1.2001 | ds_loss: 1.2104 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.402 | step time: 0.000
train | epoch   0 | Iter:   1200/156230 | global iter:   1200/156230 | loss: 1.3262 | ds_loss: 1.3288 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.339 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1200/156230 | global iter:   1200/156230 | loss: 1.2591 | ds_loss: 1.2686 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.339 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1201/156230 | global iter:   1201/156230 | loss: 1.1835 | ds_loss: 1.1896 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   1202/156230 | global iter:   1202/156230 | loss: 1.3447 | ds_loss: 1.3415 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   1203/156230 | global iter:   1203/156230 | loss: 1.1610 | ds_loss: 1.1580 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   1204/156230 | global iter:   1204/156230 | loss: 1.3623 | ds_loss: 1.3707 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.333 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1204/156230 | global iter:   1204/156230 | loss: 1.2629 | ds_loss: 1.2649 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.333 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1205/156230 | global iter:   1205/156230 | loss: 0.9641 | ds_loss: 0.9849 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   1206/156230 | global iter:   1206/156230 | loss: 1.4100 | ds_loss: 1.4148 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   1207/156230 | global iter:   1207/156230 | loss: 1.2084 | ds_loss: 1.2017 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   1208/156230 | global iter:   1208/156230 | loss: 1.2664 | ds_loss: 1.2789 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1208/156230 | global iter:   1208/156230 | loss: 1.2122 | ds_loss: 1.2200 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.350 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1209/156230 | global iter:   1209/156230 | loss: 1.0498 | ds_loss: 1.0541 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   1210/156230 | global iter:   1210/156230 | loss: 1.1825 | ds_loss: 1.1899 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   1211/156230 | global iter:   1211/156230 | loss: 1.4331 | ds_loss: 1.4699 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   1212/156230 | global iter:   1212/156230 | loss: 1.1327 | ds_loss: 1.1423 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.375 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1212/156230 | global iter:   1212/156230 | loss: 1.1995 | ds_loss: 1.2141 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.375 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1213/156230 | global iter:   1213/156230 | loss: 1.2242 | ds_loss: 1.2243 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   1214/156230 | global iter:   1214/156230 | loss: 1.2285 | ds_loss: 1.2259 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   1215/156230 | global iter:   1215/156230 | loss: 1.2866 | ds_loss: 1.2727 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   1216/156230 | global iter:   1216/156230 | loss: 1.3366 | ds_loss: 1.3552 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.383 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1216/156230 | global iter:   1216/156230 | loss: 1.2690 | ds_loss: 1.2695 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.383 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1217/156230 | global iter:   1217/156230 | loss: 1.3666 | ds_loss: 1.3734 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   1218/156230 | global iter:   1218/156230 | loss: 1.3542 | ds_loss: 1.3413 | lr: 9.9986e-05 | scale:  8192.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   1219/156230 | global iter:   1219/156230 | loss: 1.1832 | ds_loss: 1.1821 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   1220/156230 | global iter:   1220/156230 | loss: 1.2413 | ds_loss: 1.2526 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.358 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1220/156230 | global iter:   1220/156230 | loss: 1.2864 | ds_loss: 1.2874 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.358 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1221/156230 | global iter:   1221/156230 | loss: 1.3633 | ds_loss: 1.3710 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   1222/156230 | global iter:   1222/156230 | loss: 1.2433 | ds_loss: 1.2536 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   1223/156230 | global iter:   1223/156230 | loss: 1.1784 | ds_loss: 1.1877 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   1224/156230 | global iter:   1224/156230 | loss: 1.1949 | ds_loss: 1.1959 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1224/156230 | global iter:   1224/156230 | loss: 1.2450 | ds_loss: 1.2521 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.350 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1225/156230 | global iter:   1225/156230 | loss: 1.1455 | ds_loss: 1.1356 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   1226/156230 | global iter:   1226/156230 | loss: 1.2967 | ds_loss: 1.2923 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   1227/156230 | global iter:   1227/156230 | loss: 1.2105 | ds_loss: 1.2264 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   1228/156230 | global iter:   1228/156230 | loss: 1.0784 | ds_loss: 1.0928 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1228/156230 | global iter:   1228/156230 | loss: 1.1828 | ds_loss: 1.1868 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.373 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1229/156230 | global iter:   1229/156230 | loss: 1.2215 | ds_loss: 1.2250 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   1230/156230 | global iter:   1230/156230 | loss: 1.1356 | ds_loss: 1.1420 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   1231/156230 | global iter:   1231/156230 | loss: 1.2879 | ds_loss: 1.2916 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   1232/156230 | global iter:   1232/156230 | loss: 1.2617 | ds_loss: 1.2735 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1232/156230 | global iter:   1232/156230 | loss: 1.2267 | ds_loss: 1.2330 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1233/156230 | global iter:   1233/156230 | loss: 1.2449 | ds_loss: 1.2526 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   1234/156230 | global iter:   1234/156230 | loss: 1.2200 | ds_loss: 1.2421 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   1235/156230 | global iter:   1235/156230 | loss: 1.0946 | ds_loss: 1.1007 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   1236/156230 | global iter:   1236/156230 | loss: 1.2100 | ds_loss: 1.2255 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1236/156230 | global iter:   1236/156230 | loss: 1.1924 | ds_loss: 1.2053 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.365 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1237/156230 | global iter:   1237/156230 | loss: 1.0917 | ds_loss: 1.1108 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   1238/156230 | global iter:   1238/156230 | loss: 1.0362 | ds_loss: 1.0374 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   1239/156230 | global iter:   1239/156230 | loss: 1.2048 | ds_loss: 1.2293 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   1240/156230 | global iter:   1240/156230 | loss: 1.1822 | ds_loss: 1.1702 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.338 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1240/156230 | global iter:   1240/156230 | loss: 1.1287 | ds_loss: 1.1369 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.338 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1241/156230 | global iter:   1241/156230 | loss: 1.4189 | ds_loss: 1.4301 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   1242/156230 | global iter:   1242/156230 | loss: 1.1329 | ds_loss: 1.1217 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   1243/156230 | global iter:   1243/156230 | loss: 1.2760 | ds_loss: 1.2529 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.322 | step time: 0.000
train | epoch   0 | Iter:   1244/156230 | global iter:   1244/156230 | loss: 1.4426 | ds_loss: 1.4327 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.421 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1244/156230 | global iter:   1244/156230 | loss: 1.3176 | ds_loss: 1.3093 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.421 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1245/156230 | global iter:   1245/156230 | loss: 1.2474 | ds_loss: 1.2479 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   1246/156230 | global iter:   1246/156230 | loss: 1.1490 | ds_loss: 1.1543 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   1247/156230 | global iter:   1247/156230 | loss: 1.2803 | ds_loss: 1.2760 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   1248/156230 | global iter:   1248/156230 | loss: 1.2596 | ds_loss: 1.2558 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.387 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1248/156230 | global iter:   1248/156230 | loss: 1.2340 | ds_loss: 1.2335 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.387 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1249/156230 | global iter:   1249/156230 | loss: 1.2133 | ds_loss: 1.2144 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   1250/156230 | global iter:   1250/156230 | loss: 1.2398 | ds_loss: 1.2452 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   1251/156230 | global iter:   1251/156230 | loss: 1.1971 | ds_loss: 1.1973 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   1252/156230 | global iter:   1252/156230 | loss: 1.2182 | ds_loss: 1.2409 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1252/156230 | global iter:   1252/156230 | loss: 1.2171 | ds_loss: 1.2244 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1253/156230 | global iter:   1253/156230 | loss: 1.3552 | ds_loss: 1.3581 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   1254/156230 | global iter:   1254/156230 | loss: 1.0981 | ds_loss: 1.0861 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   1255/156230 | global iter:   1255/156230 | loss: 1.0555 | ds_loss: 1.0569 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   1256/156230 | global iter:   1256/156230 | loss: 1.1550 | ds_loss: 1.1556 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1256/156230 | global iter:   1256/156230 | loss: 1.1660 | ds_loss: 1.1642 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.376 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1257/156230 | global iter:   1257/156230 | loss: 1.2765 | ds_loss: 1.2807 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   1258/156230 | global iter:   1258/156230 | loss: 1.2009 | ds_loss: 1.2021 | lr: 9.9985e-05 | scale:  8192.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   1259/156230 | global iter:   1259/156230 | loss: 1.3702 | ds_loss: 1.3687 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   1260/156230 | global iter:   1260/156230 | loss: 1.4270 | ds_loss: 1.4115 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1260/156230 | global iter:   1260/156230 | loss: 1.3187 | ds_loss: 1.3158 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.376 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1261/156230 | global iter:   1261/156230 | loss: 1.2106 | ds_loss: 1.2102 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   1262/156230 | global iter:   1262/156230 | loss: 1.0656 | ds_loss: 1.0794 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   1263/156230 | global iter:   1263/156230 | loss: 1.2790 | ds_loss: 1.2796 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   1264/156230 | global iter:   1264/156230 | loss: 1.1225 | ds_loss: 1.1216 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.333 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1264/156230 | global iter:   1264/156230 | loss: 1.1694 | ds_loss: 1.1727 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.333 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1265/156230 | global iter:   1265/156230 | loss: 1.2545 | ds_loss: 1.2707 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   1266/156230 | global iter:   1266/156230 | loss: 1.1547 | ds_loss: 1.1553 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.408 | step time: 0.000
train | epoch   0 | Iter:   1267/156230 | global iter:   1267/156230 | loss: 1.2265 | ds_loss: 1.2161 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   1268/156230 | global iter:   1268/156230 | loss: 1.3356 | ds_loss: 1.3229 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.359 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1268/156230 | global iter:   1268/156230 | loss: 1.2428 | ds_loss: 1.2412 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.359 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1269/156230 | global iter:   1269/156230 | loss: 1.0544 | ds_loss: 1.0650 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   1270/156230 | global iter:   1270/156230 | loss: 1.0384 | ds_loss: 1.0505 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   1271/156230 | global iter:   1271/156230 | loss: 1.1861 | ds_loss: 1.1991 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   1272/156230 | global iter:   1272/156230 | loss: 1.2738 | ds_loss: 1.2727 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1272/156230 | global iter:   1272/156230 | loss: 1.1382 | ds_loss: 1.1468 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1273/156230 | global iter:   1273/156230 | loss: 1.1805 | ds_loss: 1.1866 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   1274/156230 | global iter:   1274/156230 | loss: 1.4168 | ds_loss: 1.3971 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   1275/156230 | global iter:   1275/156230 | loss: 1.2544 | ds_loss: 1.2608 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   1276/156230 | global iter:   1276/156230 | loss: 1.2005 | ds_loss: 1.2043 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.346 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1276/156230 | global iter:   1276/156230 | loss: 1.2630 | ds_loss: 1.2622 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.346 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1277/156230 | global iter:   1277/156230 | loss: 1.0350 | ds_loss: 1.0267 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   1278/156230 | global iter:   1278/156230 | loss: 1.3598 | ds_loss: 1.3680 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   1279/156230 | global iter:   1279/156230 | loss: 1.3244 | ds_loss: 1.3280 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   1280/156230 | global iter:   1280/156230 | loss: 1.1878 | ds_loss: 1.1882 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1280/156230 | global iter:   1280/156230 | loss: 1.2267 | ds_loss: 1.2277 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.378 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1281/156230 | global iter:   1281/156230 | loss: 1.4095 | ds_loss: 1.3972 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   1282/156230 | global iter:   1282/156230 | loss: 1.2788 | ds_loss: 1.2819 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.422 | step time: 0.000
train | epoch   0 | Iter:   1283/156230 | global iter:   1283/156230 | loss: 1.2227 | ds_loss: 1.2424 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.415 | step time: 0.000
train | epoch   0 | Iter:   1284/156230 | global iter:   1284/156230 | loss: 1.2490 | ds_loss: 1.2423 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.356 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1284/156230 | global iter:   1284/156230 | loss: 1.2900 | ds_loss: 1.2909 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.356 | step time: 1.388
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1285/156230 | global iter:   1285/156230 | loss: 1.1864 | ds_loss: 1.1791 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   1286/156230 | global iter:   1286/156230 | loss: 1.2072 | ds_loss: 1.2121 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.412 | step time: 0.000
train | epoch   0 | Iter:   1287/156230 | global iter:   1287/156230 | loss: 1.1807 | ds_loss: 1.1954 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   1288/156230 | global iter:   1288/156230 | loss: 1.0680 | ds_loss: 1.0920 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1288/156230 | global iter:   1288/156230 | loss: 1.1606 | ds_loss: 1.1697 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.394 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1289/156230 | global iter:   1289/156230 | loss: 1.0290 | ds_loss: 1.0574 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   1290/156230 | global iter:   1290/156230 | loss: 1.1005 | ds_loss: 1.1226 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:   1291/156230 | global iter:   1291/156230 | loss: 1.2561 | ds_loss: 1.2571 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   1292/156230 | global iter:   1292/156230 | loss: 1.2894 | ds_loss: 1.2927 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.403 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1292/156230 | global iter:   1292/156230 | loss: 1.1687 | ds_loss: 1.1824 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.403 | step time: 1.382
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1293/156230 | global iter:   1293/156230 | loss: 1.2473 | ds_loss: 1.2605 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   1294/156230 | global iter:   1294/156230 | loss: 1.1621 | ds_loss: 1.1652 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   1295/156230 | global iter:   1295/156230 | loss: 1.1963 | ds_loss: 1.1942 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   1296/156230 | global iter:   1296/156230 | loss: 1.1997 | ds_loss: 1.2166 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.382 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1296/156230 | global iter:   1296/156230 | loss: 1.2013 | ds_loss: 1.2091 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.382 | step time: 1.382
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1297/156230 | global iter:   1297/156230 | loss: 1.2533 | ds_loss: 1.2524 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   1298/156230 | global iter:   1298/156230 | loss: 1.0492 | ds_loss: 1.0659 | lr: 9.9984e-05 | scale:  8192.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   1299/156230 | global iter:   1299/156230 | loss: 1.2466 | ds_loss: 1.2671 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   1300/156230 | global iter:   1300/156230 | loss: 1.4230 | ds_loss: 1.4288 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.415 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1300/156230 | global iter:   1300/156230 | loss: 1.2430 | ds_loss: 1.2535 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.415 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1301/156230 | global iter:   1301/156230 | loss: 1.2458 | ds_loss: 1.2376 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   1302/156230 | global iter:   1302/156230 | loss: 1.4502 | ds_loss: 1.4582 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   1303/156230 | global iter:   1303/156230 | loss: 1.2042 | ds_loss: 1.2304 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   1304/156230 | global iter:   1304/156230 | loss: 1.2683 | ds_loss: 1.2840 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.340 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1304/156230 | global iter:   1304/156230 | loss: 1.2922 | ds_loss: 1.3026 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.340 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1305/156230 | global iter:   1305/156230 | loss: 1.3194 | ds_loss: 1.3192 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   1306/156230 | global iter:   1306/156230 | loss: 1.2712 | ds_loss: 1.2679 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   1307/156230 | global iter:   1307/156230 | loss: 1.3341 | ds_loss: 1.3391 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   1308/156230 | global iter:   1308/156230 | loss: 1.4048 | ds_loss: 1.4222 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.388 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1308/156230 | global iter:   1308/156230 | loss: 1.3324 | ds_loss: 1.3371 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.388 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1309/156230 | global iter:   1309/156230 | loss: 1.1804 | ds_loss: 1.1816 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:   1310/156230 | global iter:   1310/156230 | loss: 1.2425 | ds_loss: 1.2579 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   1311/156230 | global iter:   1311/156230 | loss: 1.4280 | ds_loss: 1.4165 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   1312/156230 | global iter:   1312/156230 | loss: 1.2954 | ds_loss: 1.2952 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1312/156230 | global iter:   1312/156230 | loss: 1.2866 | ds_loss: 1.2878 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.394 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1313/156230 | global iter:   1313/156230 | loss: 1.2382 | ds_loss: 1.2532 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   1314/156230 | global iter:   1314/156230 | loss: 1.2011 | ds_loss: 1.2024 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   1315/156230 | global iter:   1315/156230 | loss: 1.0981 | ds_loss: 1.0835 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   1316/156230 | global iter:   1316/156230 | loss: 1.2218 | ds_loss: 1.2103 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.338 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1316/156230 | global iter:   1316/156230 | loss: 1.1898 | ds_loss: 1.1873 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.338 | step time: 1.345
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1317/156230 | global iter:   1317/156230 | loss: 1.4503 | ds_loss: 1.4667 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   1318/156230 | global iter:   1318/156230 | loss: 1.2945 | ds_loss: 1.3167 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   1319/156230 | global iter:   1319/156230 | loss: 1.2354 | ds_loss: 1.2342 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   1320/156230 | global iter:   1320/156230 | loss: 1.3050 | ds_loss: 1.2942 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1320/156230 | global iter:   1320/156230 | loss: 1.3213 | ds_loss: 1.3280 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.376 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1321/156230 | global iter:   1321/156230 | loss: 1.3005 | ds_loss: 1.3040 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   1322/156230 | global iter:   1322/156230 | loss: 1.2622 | ds_loss: 1.2621 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   1323/156230 | global iter:   1323/156230 | loss: 1.2314 | ds_loss: 1.2275 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   1324/156230 | global iter:   1324/156230 | loss: 1.2579 | ds_loss: 1.2611 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.391 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1324/156230 | global iter:   1324/156230 | loss: 1.2630 | ds_loss: 1.2637 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.391 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1325/156230 | global iter:   1325/156230 | loss: 1.2720 | ds_loss: 1.2722 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   1326/156230 | global iter:   1326/156230 | loss: 1.2298 | ds_loss: 1.2254 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   1327/156230 | global iter:   1327/156230 | loss: 1.1181 | ds_loss: 1.1050 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   1328/156230 | global iter:   1328/156230 | loss: 1.4090 | ds_loss: 1.4116 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1328/156230 | global iter:   1328/156230 | loss: 1.2572 | ds_loss: 1.2535 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.363 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1329/156230 | global iter:   1329/156230 | loss: 1.1321 | ds_loss: 1.1288 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   1330/156230 | global iter:   1330/156230 | loss: 1.2366 | ds_loss: 1.2467 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   1331/156230 | global iter:   1331/156230 | loss: 1.1540 | ds_loss: 1.1501 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.412 | step time: 0.000
train | epoch   0 | Iter:   1332/156230 | global iter:   1332/156230 | loss: 1.0609 | ds_loss: 1.0699 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.328 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1332/156230 | global iter:   1332/156230 | loss: 1.1459 | ds_loss: 1.1489 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.328 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1333/156230 | global iter:   1333/156230 | loss: 1.0353 | ds_loss: 1.0419 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   1334/156230 | global iter:   1334/156230 | loss: 1.2110 | ds_loss: 1.2084 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   1335/156230 | global iter:   1335/156230 | loss: 1.3574 | ds_loss: 1.3609 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   1336/156230 | global iter:   1336/156230 | loss: 1.3484 | ds_loss: 1.3634 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1336/156230 | global iter:   1336/156230 | loss: 1.2380 | ds_loss: 1.2437 | lr: 9.9983e-05 | scale:  8192.0000 | micro time: 1.381 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1337/156230 | global iter:   1337/156230 | loss: 1.0667 | ds_loss: 1.0546 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   1338/156230 | global iter:   1338/156230 | loss: 1.2939 | ds_loss: 1.2943 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   1339/156230 | global iter:   1339/156230 | loss: 1.3863 | ds_loss: 1.3827 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   1340/156230 | global iter:   1340/156230 | loss: 1.1787 | ds_loss: 1.1850 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.326 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1340/156230 | global iter:   1340/156230 | loss: 1.2314 | ds_loss: 1.2291 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.326 | step time: 1.344
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1341/156230 | global iter:   1341/156230 | loss: 1.2690 | ds_loss: 1.2679 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.316 | step time: 0.000
train | epoch   0 | Iter:   1342/156230 | global iter:   1342/156230 | loss: 1.2668 | ds_loss: 1.2793 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   1343/156230 | global iter:   1343/156230 | loss: 1.2460 | ds_loss: 1.2502 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   1344/156230 | global iter:   1344/156230 | loss: 1.2459 | ds_loss: 1.2390 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.367 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1344/156230 | global iter:   1344/156230 | loss: 1.2569 | ds_loss: 1.2591 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.367 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1345/156230 | global iter:   1345/156230 | loss: 1.3674 | ds_loss: 1.3637 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.325 | step time: 0.000
train | epoch   0 | Iter:   1346/156230 | global iter:   1346/156230 | loss: 1.3311 | ds_loss: 1.3263 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   1347/156230 | global iter:   1347/156230 | loss: 1.1222 | ds_loss: 1.1229 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   1348/156230 | global iter:   1348/156230 | loss: 1.1678 | ds_loss: 1.1772 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1348/156230 | global iter:   1348/156230 | loss: 1.2471 | ds_loss: 1.2475 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.377 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1349/156230 | global iter:   1349/156230 | loss: 1.4840 | ds_loss: 1.4766 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   1350/156230 | global iter:   1350/156230 | loss: 1.2682 | ds_loss: 1.2827 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   1351/156230 | global iter:   1351/156230 | loss: 1.1626 | ds_loss: 1.1589 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   1352/156230 | global iter:   1352/156230 | loss: 1.1782 | ds_loss: 1.1885 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.309 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1352/156230 | global iter:   1352/156230 | loss: 1.2732 | ds_loss: 1.2767 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.309 | step time: 1.340
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1353/156230 | global iter:   1353/156230 | loss: 1.2999 | ds_loss: 1.3005 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.404 | step time: 0.000
train | epoch   0 | Iter:   1354/156230 | global iter:   1354/156230 | loss: 1.2351 | ds_loss: 1.2540 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   1355/156230 | global iter:   1355/156230 | loss: 1.2258 | ds_loss: 1.2230 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.322 | step time: 0.000
train | epoch   0 | Iter:   1356/156230 | global iter:   1356/156230 | loss: 1.0805 | ds_loss: 1.0925 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.346 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1356/156230 | global iter:   1356/156230 | loss: 1.2103 | ds_loss: 1.2175 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.346 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1357/156230 | global iter:   1357/156230 | loss: 1.0474 | ds_loss: 1.0625 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   1358/156230 | global iter:   1358/156230 | loss: 1.3197 | ds_loss: 1.3347 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   1359/156230 | global iter:   1359/156230 | loss: 1.1825 | ds_loss: 1.2073 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   1360/156230 | global iter:   1360/156230 | loss: 1.1952 | ds_loss: 1.2045 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1360/156230 | global iter:   1360/156230 | loss: 1.1862 | ds_loss: 1.2023 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.360 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1361/156230 | global iter:   1361/156230 | loss: 1.2942 | ds_loss: 1.3109 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   1362/156230 | global iter:   1362/156230 | loss: 1.3047 | ds_loss: 1.3053 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:   1363/156230 | global iter:   1363/156230 | loss: 1.3124 | ds_loss: 1.3207 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   1364/156230 | global iter:   1364/156230 | loss: 1.2305 | ds_loss: 1.2420 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1364/156230 | global iter:   1364/156230 | loss: 1.2855 | ds_loss: 1.2947 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.376 | step time: 1.382
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1365/156230 | global iter:   1365/156230 | loss: 1.3076 | ds_loss: 1.3044 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   1366/156230 | global iter:   1366/156230 | loss: 1.2503 | ds_loss: 1.2457 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.429 | step time: 0.000
train | epoch   0 | Iter:   1367/156230 | global iter:   1367/156230 | loss: 1.1974 | ds_loss: 1.2210 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   1368/156230 | global iter:   1368/156230 | loss: 1.2924 | ds_loss: 1.3007 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.402 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1368/156230 | global iter:   1368/156230 | loss: 1.2619 | ds_loss: 1.2680 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.402 | step time: 1.379
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1369/156230 | global iter:   1369/156230 | loss: 1.2824 | ds_loss: 1.2891 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   1370/156230 | global iter:   1370/156230 | loss: 1.2199 | ds_loss: 1.2321 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   1371/156230 | global iter:   1371/156230 | loss: 1.2012 | ds_loss: 1.1984 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   1372/156230 | global iter:   1372/156230 | loss: 1.1893 | ds_loss: 1.1978 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.371 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1372/156230 | global iter:   1372/156230 | loss: 1.2232 | ds_loss: 1.2294 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.371 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1373/156230 | global iter:   1373/156230 | loss: 1.1405 | ds_loss: 1.1469 | lr: 9.9982e-05 | scale:  8192.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   1374/156230 | global iter:   1374/156230 | loss: 1.2192 | ds_loss: 1.2217 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   1375/156230 | global iter:   1375/156230 | loss: 1.1165 | ds_loss: 1.1116 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   1376/156230 | global iter:   1376/156230 | loss: 1.2362 | ds_loss: 1.2598 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.315 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1376/156230 | global iter:   1376/156230 | loss: 1.1781 | ds_loss: 1.1850 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.315 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1377/156230 | global iter:   1377/156230 | loss: 1.3878 | ds_loss: 1.3924 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   1378/156230 | global iter:   1378/156230 | loss: 1.2999 | ds_loss: 1.3009 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   1379/156230 | global iter:   1379/156230 | loss: 1.2944 | ds_loss: 1.2982 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   1380/156230 | global iter:   1380/156230 | loss: 1.1593 | ds_loss: 1.1766 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.343 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1380/156230 | global iter:   1380/156230 | loss: 1.2853 | ds_loss: 1.2920 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.343 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1381/156230 | global iter:   1381/156230 | loss: 1.1205 | ds_loss: 1.1225 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   1382/156230 | global iter:   1382/156230 | loss: 1.2035 | ds_loss: 1.2160 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   1383/156230 | global iter:   1383/156230 | loss: 1.2448 | ds_loss: 1.2491 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   1384/156230 | global iter:   1384/156230 | loss: 1.1720 | ds_loss: 1.1577 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1384/156230 | global iter:   1384/156230 | loss: 1.1852 | ds_loss: 1.1863 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.377 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1385/156230 | global iter:   1385/156230 | loss: 1.1767 | ds_loss: 1.1867 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   1386/156230 | global iter:   1386/156230 | loss: 1.2621 | ds_loss: 1.2756 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   1387/156230 | global iter:   1387/156230 | loss: 1.2601 | ds_loss: 1.2571 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   1388/156230 | global iter:   1388/156230 | loss: 1.0717 | ds_loss: 1.0872 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1388/156230 | global iter:   1388/156230 | loss: 1.1927 | ds_loss: 1.2017 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.377 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1389/156230 | global iter:   1389/156230 | loss: 1.2010 | ds_loss: 1.2045 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   1390/156230 | global iter:   1390/156230 | loss: 1.2483 | ds_loss: 1.2342 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   1391/156230 | global iter:   1391/156230 | loss: 1.2131 | ds_loss: 1.2066 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:   1392/156230 | global iter:   1392/156230 | loss: 1.3273 | ds_loss: 1.3351 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1392/156230 | global iter:   1392/156230 | loss: 1.2474 | ds_loss: 1.2451 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.360 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1393/156230 | global iter:   1393/156230 | loss: 1.1925 | ds_loss: 1.2215 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   1394/156230 | global iter:   1394/156230 | loss: 1.3007 | ds_loss: 1.3160 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   1395/156230 | global iter:   1395/156230 | loss: 1.1742 | ds_loss: 1.1647 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   1396/156230 | global iter:   1396/156230 | loss: 1.2168 | ds_loss: 1.2366 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.367 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1396/156230 | global iter:   1396/156230 | loss: 1.2210 | ds_loss: 1.2347 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.367 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1397/156230 | global iter:   1397/156230 | loss: 1.3182 | ds_loss: 1.3261 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.405 | step time: 0.000
train | epoch   0 | Iter:   1398/156230 | global iter:   1398/156230 | loss: 1.3119 | ds_loss: 1.3069 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   1399/156230 | global iter:   1399/156230 | loss: 1.2139 | ds_loss: 1.2124 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   1400/156230 | global iter:   1400/156230 | loss: 1.1070 | ds_loss: 1.1057 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.328 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1400/156230 | global iter:   1400/156230 | loss: 1.2378 | ds_loss: 1.2378 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.328 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1401/156230 | global iter:   1401/156230 | loss: 1.3356 | ds_loss: 1.3473 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   1402/156230 | global iter:   1402/156230 | loss: 1.0228 | ds_loss: 1.0299 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   1403/156230 | global iter:   1403/156230 | loss: 1.2086 | ds_loss: 1.2125 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   1404/156230 | global iter:   1404/156230 | loss: 1.0983 | ds_loss: 1.0975 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1404/156230 | global iter:   1404/156230 | loss: 1.1663 | ds_loss: 1.1718 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.360 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1405/156230 | global iter:   1405/156230 | loss: 1.0201 | ds_loss: 1.0359 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   1406/156230 | global iter:   1406/156230 | loss: 1.1012 | ds_loss: 1.1120 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   1407/156230 | global iter:   1407/156230 | loss: 1.3722 | ds_loss: 1.3965 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   1408/156230 | global iter:   1408/156230 | loss: 1.2939 | ds_loss: 1.2935 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1408/156230 | global iter:   1408/156230 | loss: 1.1969 | ds_loss: 1.2095 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.366 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1409/156230 | global iter:   1409/156230 | loss: 1.2738 | ds_loss: 1.2771 | lr: 9.9981e-05 | scale:  8192.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   1410/156230 | global iter:   1410/156230 | loss: 1.2348 | ds_loss: 1.2603 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   1411/156230 | global iter:   1411/156230 | loss: 1.1438 | ds_loss: 1.1482 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   1412/156230 | global iter:   1412/156230 | loss: 1.3781 | ds_loss: 1.3822 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1412/156230 | global iter:   1412/156230 | loss: 1.2576 | ds_loss: 1.2669 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.378 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1413/156230 | global iter:   1413/156230 | loss: 1.2224 | ds_loss: 1.2307 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   1414/156230 | global iter:   1414/156230 | loss: 1.2166 | ds_loss: 1.2199 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   1415/156230 | global iter:   1415/156230 | loss: 0.9473 | ds_loss: 0.9585 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   1416/156230 | global iter:   1416/156230 | loss: 1.2345 | ds_loss: 1.2466 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1416/156230 | global iter:   1416/156230 | loss: 1.1552 | ds_loss: 1.1639 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.362 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1417/156230 | global iter:   1417/156230 | loss: 1.1087 | ds_loss: 1.1261 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   1418/156230 | global iter:   1418/156230 | loss: 1.1176 | ds_loss: 1.1347 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   1419/156230 | global iter:   1419/156230 | loss: 1.0150 | ds_loss: 1.0238 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.407 | step time: 0.000
train | epoch   0 | Iter:   1420/156230 | global iter:   1420/156230 | loss: 0.9297 | ds_loss: 0.9526 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.371 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1420/156230 | global iter:   1420/156230 | loss: 1.0427 | ds_loss: 1.0593 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.371 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1421/156230 | global iter:   1421/156230 | loss: 1.3470 | ds_loss: 1.3483 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   1422/156230 | global iter:   1422/156230 | loss: 1.0804 | ds_loss: 1.0986 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   1423/156230 | global iter:   1423/156230 | loss: 1.3303 | ds_loss: 1.3412 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   1424/156230 | global iter:   1424/156230 | loss: 1.1929 | ds_loss: 1.1888 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1424/156230 | global iter:   1424/156230 | loss: 1.2376 | ds_loss: 1.2442 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.350 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1425/156230 | global iter:   1425/156230 | loss: 1.1521 | ds_loss: 1.1603 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.402 | step time: 0.000
train | epoch   0 | Iter:   1426/156230 | global iter:   1426/156230 | loss: 1.0394 | ds_loss: 1.0497 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   1427/156230 | global iter:   1427/156230 | loss: 1.4498 | ds_loss: 1.4414 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   1428/156230 | global iter:   1428/156230 | loss: 1.3666 | ds_loss: 1.3729 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.372 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1428/156230 | global iter:   1428/156230 | loss: 1.2520 | ds_loss: 1.2561 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.372 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1429/156230 | global iter:   1429/156230 | loss: 1.1844 | ds_loss: 1.2035 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   1430/156230 | global iter:   1430/156230 | loss: 1.0772 | ds_loss: 1.0867 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.409 | step time: 0.000
train | epoch   0 | Iter:   1431/156230 | global iter:   1431/156230 | loss: 1.2434 | ds_loss: 1.2599 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   1432/156230 | global iter:   1432/156230 | loss: 1.2703 | ds_loss: 1.2695 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.318 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1432/156230 | global iter:   1432/156230 | loss: 1.1938 | ds_loss: 1.2049 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.318 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1433/156230 | global iter:   1433/156230 | loss: 1.4403 | ds_loss: 1.4381 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   1434/156230 | global iter:   1434/156230 | loss: 1.2266 | ds_loss: 1.2404 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   1435/156230 | global iter:   1435/156230 | loss: 1.1899 | ds_loss: 1.1855 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   1436/156230 | global iter:   1436/156230 | loss: 1.3117 | ds_loss: 1.3030 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.372 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1436/156230 | global iter:   1436/156230 | loss: 1.2921 | ds_loss: 1.2917 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.372 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1437/156230 | global iter:   1437/156230 | loss: 1.4048 | ds_loss: 1.3947 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   1438/156230 | global iter:   1438/156230 | loss: 1.0683 | ds_loss: 1.0805 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   1439/156230 | global iter:   1439/156230 | loss: 1.1551 | ds_loss: 1.1511 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   1440/156230 | global iter:   1440/156230 | loss: 1.1613 | ds_loss: 1.1746 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.409 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1440/156230 | global iter:   1440/156230 | loss: 1.1974 | ds_loss: 1.2002 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.409 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1441/156230 | global iter:   1441/156230 | loss: 1.3696 | ds_loss: 1.3754 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   1442/156230 | global iter:   1442/156230 | loss: 1.3000 | ds_loss: 1.3035 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   1443/156230 | global iter:   1443/156230 | loss: 1.1936 | ds_loss: 1.2035 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   1444/156230 | global iter:   1444/156230 | loss: 1.2562 | ds_loss: 1.2654 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.339 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1444/156230 | global iter:   1444/156230 | loss: 1.2799 | ds_loss: 1.2869 | lr: 9.9980e-05 | scale:  8192.0000 | micro time: 1.339 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1445/156230 | global iter:   1445/156230 | loss: 1.2044 | ds_loss: 1.2081 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   1446/156230 | global iter:   1446/156230 | loss: 1.2432 | ds_loss: 1.2380 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   1447/156230 | global iter:   1447/156230 | loss: 1.1982 | ds_loss: 1.2097 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   1448/156230 | global iter:   1448/156230 | loss: 1.3824 | ds_loss: 1.4043 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.409 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1448/156230 | global iter:   1448/156230 | loss: 1.2570 | ds_loss: 1.2650 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.409 | step time: 1.389
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1449/156230 | global iter:   1449/156230 | loss: 1.3014 | ds_loss: 1.3048 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   1450/156230 | global iter:   1450/156230 | loss: 1.1875 | ds_loss: 1.1969 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   1451/156230 | global iter:   1451/156230 | loss: 1.1559 | ds_loss: 1.1622 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.309 | step time: 0.000
train | epoch   0 | Iter:   1452/156230 | global iter:   1452/156230 | loss: 1.1397 | ds_loss: 1.1461 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1452/156230 | global iter:   1452/156230 | loss: 1.1961 | ds_loss: 1.2025 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.381 | step time: 1.344
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1453/156230 | global iter:   1453/156230 | loss: 1.3476 | ds_loss: 1.3441 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   1454/156230 | global iter:   1454/156230 | loss: 1.1449 | ds_loss: 1.1394 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   1455/156230 | global iter:   1455/156230 | loss: 1.3285 | ds_loss: 1.3327 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   1456/156230 | global iter:   1456/156230 | loss: 1.2553 | ds_loss: 1.2621 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.418 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1456/156230 | global iter:   1456/156230 | loss: 1.2691 | ds_loss: 1.2696 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.418 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1457/156230 | global iter:   1457/156230 | loss: 1.3159 | ds_loss: 1.3142 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   1458/156230 | global iter:   1458/156230 | loss: 1.3382 | ds_loss: 1.3379 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   1459/156230 | global iter:   1459/156230 | loss: 1.1762 | ds_loss: 1.1933 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   1460/156230 | global iter:   1460/156230 | loss: 1.2367 | ds_loss: 1.2516 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1460/156230 | global iter:   1460/156230 | loss: 1.2667 | ds_loss: 1.2743 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.362 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1461/156230 | global iter:   1461/156230 | loss: 1.1530 | ds_loss: 1.1657 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.400 | step time: 0.000
train | epoch   0 | Iter:   1462/156230 | global iter:   1462/156230 | loss: 1.1487 | ds_loss: 1.1555 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   1463/156230 | global iter:   1463/156230 | loss: 1.2291 | ds_loss: 1.2135 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   1464/156230 | global iter:   1464/156230 | loss: 1.3069 | ds_loss: 1.3050 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1464/156230 | global iter:   1464/156230 | loss: 1.2094 | ds_loss: 1.2099 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.349 | step time: 1.376
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1465/156230 | global iter:   1465/156230 | loss: 1.3057 | ds_loss: 1.3045 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   1466/156230 | global iter:   1466/156230 | loss: 1.1125 | ds_loss: 1.1263 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   1467/156230 | global iter:   1467/156230 | loss: 1.2811 | ds_loss: 1.2822 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   1468/156230 | global iter:   1468/156230 | loss: 1.2077 | ds_loss: 1.2134 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.387 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1468/156230 | global iter:   1468/156230 | loss: 1.2268 | ds_loss: 1.2316 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.387 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1469/156230 | global iter:   1469/156230 | loss: 1.1342 | ds_loss: 1.1481 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   1470/156230 | global iter:   1470/156230 | loss: 0.8384 | ds_loss: 0.8543 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   1471/156230 | global iter:   1471/156230 | loss: 1.1751 | ds_loss: 1.1835 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   1472/156230 | global iter:   1472/156230 | loss: 1.3576 | ds_loss: 1.3789 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.359 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1472/156230 | global iter:   1472/156230 | loss: 1.1263 | ds_loss: 1.1412 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.359 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1473/156230 | global iter:   1473/156230 | loss: 1.2861 | ds_loss: 1.3021 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   1474/156230 | global iter:   1474/156230 | loss: 1.1812 | ds_loss: 1.1810 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   1475/156230 | global iter:   1475/156230 | loss: 1.3628 | ds_loss: 1.3732 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   1476/156230 | global iter:   1476/156230 | loss: 1.2547 | ds_loss: 1.2596 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.336 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1476/156230 | global iter:   1476/156230 | loss: 1.2712 | ds_loss: 1.2790 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.336 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1477/156230 | global iter:   1477/156230 | loss: 1.3517 | ds_loss: 1.3496 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   1478/156230 | global iter:   1478/156230 | loss: 1.2667 | ds_loss: 1.2738 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   1479/156230 | global iter:   1479/156230 | loss: 1.3013 | ds_loss: 1.2952 | lr: 9.9979e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   1480/156230 | global iter:   1480/156230 | loss: 1.2494 | ds_loss: 1.2352 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.375 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1480/156230 | global iter:   1480/156230 | loss: 1.2923 | ds_loss: 1.2884 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.375 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1481/156230 | global iter:   1481/156230 | loss: 1.3176 | ds_loss: 1.3222 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   1482/156230 | global iter:   1482/156230 | loss: 1.4004 | ds_loss: 1.3990 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   1483/156230 | global iter:   1483/156230 | loss: 1.1177 | ds_loss: 1.1311 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   1484/156230 | global iter:   1484/156230 | loss: 1.2198 | ds_loss: 1.2247 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1484/156230 | global iter:   1484/156230 | loss: 1.2639 | ds_loss: 1.2692 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.349 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1485/156230 | global iter:   1485/156230 | loss: 1.2730 | ds_loss: 1.2792 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   1486/156230 | global iter:   1486/156230 | loss: 1.2834 | ds_loss: 1.2792 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   1487/156230 | global iter:   1487/156230 | loss: 1.2349 | ds_loss: 1.2432 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   1488/156230 | global iter:   1488/156230 | loss: 1.4016 | ds_loss: 1.4124 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.390 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1488/156230 | global iter:   1488/156230 | loss: 1.2982 | ds_loss: 1.3035 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.390 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1489/156230 | global iter:   1489/156230 | loss: 1.2087 | ds_loss: 1.2054 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.312 | step time: 0.000
train | epoch   0 | Iter:   1490/156230 | global iter:   1490/156230 | loss: 1.2502 | ds_loss: 1.2621 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   1491/156230 | global iter:   1491/156230 | loss: 1.2131 | ds_loss: 1.2111 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   1492/156230 | global iter:   1492/156230 | loss: 1.2626 | ds_loss: 1.2562 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.321 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1492/156230 | global iter:   1492/156230 | loss: 1.2337 | ds_loss: 1.2337 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.321 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1493/156230 | global iter:   1493/156230 | loss: 1.1602 | ds_loss: 1.1802 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   1494/156230 | global iter:   1494/156230 | loss: 1.2054 | ds_loss: 1.2119 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   1495/156230 | global iter:   1495/156230 | loss: 1.1857 | ds_loss: 1.1839 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   1496/156230 | global iter:   1496/156230 | loss: 1.3996 | ds_loss: 1.4220 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1496/156230 | global iter:   1496/156230 | loss: 1.2377 | ds_loss: 1.2495 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.355 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1497/156230 | global iter:   1497/156230 | loss: 1.2671 | ds_loss: 1.2707 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   1498/156230 | global iter:   1498/156230 | loss: 1.2233 | ds_loss: 1.2352 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.409 | step time: 0.000
train | epoch   0 | Iter:   1499/156230 | global iter:   1499/156230 | loss: 1.2170 | ds_loss: 1.2409 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.308 | step time: 0.000
train | epoch   0 | Iter:   1500/156230 | global iter:   1500/156230 | loss: 1.1771 | ds_loss: 1.1867 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.406 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1500/156230 | global iter:   1500/156230 | loss: 1.2211 | ds_loss: 1.2334 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.406 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1501/156230 | global iter:   1501/156230 | loss: 1.2866 | ds_loss: 1.3033 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   1502/156230 | global iter:   1502/156230 | loss: 1.1879 | ds_loss: 1.1659 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   1503/156230 | global iter:   1503/156230 | loss: 1.2704 | ds_loss: 1.2754 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   1504/156230 | global iter:   1504/156230 | loss: 1.1242 | ds_loss: 1.1314 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.383 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1504/156230 | global iter:   1504/156230 | loss: 1.2173 | ds_loss: 1.2190 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.383 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1505/156230 | global iter:   1505/156230 | loss: 1.1927 | ds_loss: 1.1937 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   1506/156230 | global iter:   1506/156230 | loss: 1.1656 | ds_loss: 1.1780 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   1507/156230 | global iter:   1507/156230 | loss: 1.2006 | ds_loss: 1.1919 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   1508/156230 | global iter:   1508/156230 | loss: 1.3186 | ds_loss: 1.3251 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.343 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1508/156230 | global iter:   1508/156230 | loss: 1.2194 | ds_loss: 1.2222 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.343 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1509/156230 | global iter:   1509/156230 | loss: 1.2996 | ds_loss: 1.2931 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   1510/156230 | global iter:   1510/156230 | loss: 1.2948 | ds_loss: 1.2979 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.410 | step time: 0.000
train | epoch   0 | Iter:   1511/156230 | global iter:   1511/156230 | loss: 1.1184 | ds_loss: 1.1254 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   1512/156230 | global iter:   1512/156230 | loss: 1.0767 | ds_loss: 1.0852 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1512/156230 | global iter:   1512/156230 | loss: 1.1974 | ds_loss: 1.2004 | lr: 9.9978e-05 | scale:  8192.0000 | micro time: 1.376 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1513/156230 | global iter:   1513/156230 | loss: 1.2809 | ds_loss: 1.2858 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   1514/156230 | global iter:   1514/156230 | loss: 1.1450 | ds_loss: 1.1625 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   1515/156230 | global iter:   1515/156230 | loss: 1.3218 | ds_loss: 1.3182 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   1516/156230 | global iter:   1516/156230 | loss: 1.3072 | ds_loss: 1.3168 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1516/156230 | global iter:   1516/156230 | loss: 1.2637 | ds_loss: 1.2708 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.364 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1517/156230 | global iter:   1517/156230 | loss: 1.2038 | ds_loss: 1.2147 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   1518/156230 | global iter:   1518/156230 | loss: 1.1982 | ds_loss: 1.2121 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   1519/156230 | global iter:   1519/156230 | loss: 1.2101 | ds_loss: 1.2101 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   1520/156230 | global iter:   1520/156230 | loss: 1.2430 | ds_loss: 1.2575 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1520/156230 | global iter:   1520/156230 | loss: 1.2138 | ds_loss: 1.2236 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.357 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1521/156230 | global iter:   1521/156230 | loss: 1.2676 | ds_loss: 1.2781 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   1522/156230 | global iter:   1522/156230 | loss: 1.1685 | ds_loss: 1.1933 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.427 | step time: 0.000
train | epoch   0 | Iter:   1523/156230 | global iter:   1523/156230 | loss: 1.3062 | ds_loss: 1.3203 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   1524/156230 | global iter:   1524/156230 | loss: 1.2293 | ds_loss: 1.2421 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1524/156230 | global iter:   1524/156230 | loss: 1.2429 | ds_loss: 1.2585 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.360 | step time: 1.385
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1525/156230 | global iter:   1525/156230 | loss: 1.1538 | ds_loss: 1.1525 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.403 | step time: 0.000
train | epoch   0 | Iter:   1526/156230 | global iter:   1526/156230 | loss: 1.2848 | ds_loss: 1.2763 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   1527/156230 | global iter:   1527/156230 | loss: 0.8897 | ds_loss: 0.8971 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   1528/156230 | global iter:   1528/156230 | loss: 1.2228 | ds_loss: 1.2309 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.384 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1528/156230 | global iter:   1528/156230 | loss: 1.1378 | ds_loss: 1.1392 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.384 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1529/156230 | global iter:   1529/156230 | loss: 1.1293 | ds_loss: 1.1420 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   1530/156230 | global iter:   1530/156230 | loss: 1.1142 | ds_loss: 1.1248 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   1531/156230 | global iter:   1531/156230 | loss: 1.1075 | ds_loss: 1.1038 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   1532/156230 | global iter:   1532/156230 | loss: 1.2254 | ds_loss: 1.2201 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.343 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1532/156230 | global iter:   1532/156230 | loss: 1.1441 | ds_loss: 1.1477 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.343 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1533/156230 | global iter:   1533/156230 | loss: 1.0704 | ds_loss: 1.0642 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   1534/156230 | global iter:   1534/156230 | loss: 1.1749 | ds_loss: 1.1892 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   1535/156230 | global iter:   1535/156230 | loss: 1.2902 | ds_loss: 1.3043 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.433 | step time: 0.000
train | epoch   0 | Iter:   1536/156230 | global iter:   1536/156230 | loss: 1.1079 | ds_loss: 1.1224 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.311 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1536/156230 | global iter:   1536/156230 | loss: 1.1609 | ds_loss: 1.1700 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.311 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1537/156230 | global iter:   1537/156230 | loss: 1.2771 | ds_loss: 1.2891 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   1538/156230 | global iter:   1538/156230 | loss: 1.4084 | ds_loss: 1.4069 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.409 | step time: 0.000
train | epoch   0 | Iter:   1539/156230 | global iter:   1539/156230 | loss: 1.1776 | ds_loss: 1.1884 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   1540/156230 | global iter:   1540/156230 | loss: 1.0507 | ds_loss: 1.0539 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.327 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1540/156230 | global iter:   1540/156230 | loss: 1.2285 | ds_loss: 1.2346 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.327 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1541/156230 | global iter:   1541/156230 | loss: 1.2922 | ds_loss: 1.2993 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:   1542/156230 | global iter:   1542/156230 | loss: 1.1779 | ds_loss: 1.1860 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   1543/156230 | global iter:   1543/156230 | loss: 1.2361 | ds_loss: 1.2261 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.413 | step time: 0.000
train | epoch   0 | Iter:   1544/156230 | global iter:   1544/156230 | loss: 1.1733 | ds_loss: 1.1652 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1544/156230 | global iter:   1544/156230 | loss: 1.2199 | ds_loss: 1.2192 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.350 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1545/156230 | global iter:   1545/156230 | loss: 1.3583 | ds_loss: 1.3662 | lr: 9.9977e-05 | scale:  8192.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   1546/156230 | global iter:   1546/156230 | loss: 1.1372 | ds_loss: 1.1426 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.400 | step time: 0.000
train | epoch   0 | Iter:   1547/156230 | global iter:   1547/156230 | loss: 1.2412 | ds_loss: 1.2462 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   1548/156230 | global iter:   1548/156230 | loss: 1.2310 | ds_loss: 1.2343 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1548/156230 | global iter:   1548/156230 | loss: 1.2419 | ds_loss: 1.2473 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.381 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1549/156230 | global iter:   1549/156230 | loss: 1.2069 | ds_loss: 1.2164 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   1550/156230 | global iter:   1550/156230 | loss: 1.2700 | ds_loss: 1.2805 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   1551/156230 | global iter:   1551/156230 | loss: 1.2286 | ds_loss: 1.2380 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   1552/156230 | global iter:   1552/156230 | loss: 1.1239 | ds_loss: 1.1361 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.344 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1552/156230 | global iter:   1552/156230 | loss: 1.2073 | ds_loss: 1.2177 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.344 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1553/156230 | global iter:   1553/156230 | loss: 1.3825 | ds_loss: 1.3788 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   1554/156230 | global iter:   1554/156230 | loss: 1.0050 | ds_loss: 1.0155 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   1555/156230 | global iter:   1555/156230 | loss: 1.2302 | ds_loss: 1.2271 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   1556/156230 | global iter:   1556/156230 | loss: 1.2039 | ds_loss: 1.2064 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1556/156230 | global iter:   1556/156230 | loss: 1.2054 | ds_loss: 1.2069 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.350 | step time: 1.347
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1557/156230 | global iter:   1557/156230 | loss: 1.4103 | ds_loss: 1.4198 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   1558/156230 | global iter:   1558/156230 | loss: 1.2765 | ds_loss: 1.2920 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   1559/156230 | global iter:   1559/156230 | loss: 1.3636 | ds_loss: 1.3690 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   1560/156230 | global iter:   1560/156230 | loss: 1.2609 | ds_loss: 1.2543 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1560/156230 | global iter:   1560/156230 | loss: 1.3278 | ds_loss: 1.3338 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.363 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1561/156230 | global iter:   1561/156230 | loss: 1.3277 | ds_loss: 1.3545 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   1562/156230 | global iter:   1562/156230 | loss: 1.1813 | ds_loss: 1.1840 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   1563/156230 | global iter:   1563/156230 | loss: 1.3021 | ds_loss: 1.3053 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:   1564/156230 | global iter:   1564/156230 | loss: 1.2903 | ds_loss: 1.3099 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.358 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1564/156230 | global iter:   1564/156230 | loss: 1.2753 | ds_loss: 1.2884 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.358 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1565/156230 | global iter:   1565/156230 | loss: 1.3704 | ds_loss: 1.3597 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   1566/156230 | global iter:   1566/156230 | loss: 1.3481 | ds_loss: 1.3490 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   1567/156230 | global iter:   1567/156230 | loss: 1.0752 | ds_loss: 1.0673 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   1568/156230 | global iter:   1568/156230 | loss: 1.2497 | ds_loss: 1.2561 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.380 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1568/156230 | global iter:   1568/156230 | loss: 1.2609 | ds_loss: 1.2581 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.380 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1569/156230 | global iter:   1569/156230 | loss: 1.1835 | ds_loss: 1.1931 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   1570/156230 | global iter:   1570/156230 | loss: 1.2291 | ds_loss: 1.2343 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   1571/156230 | global iter:   1571/156230 | loss: 1.0718 | ds_loss: 1.0772 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   1572/156230 | global iter:   1572/156230 | loss: 1.1634 | ds_loss: 1.1519 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1572/156230 | global iter:   1572/156230 | loss: 1.1619 | ds_loss: 1.1641 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.394 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1573/156230 | global iter:   1573/156230 | loss: 1.1345 | ds_loss: 1.1521 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   1574/156230 | global iter:   1574/156230 | loss: 1.2075 | ds_loss: 1.2118 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   1575/156230 | global iter:   1575/156230 | loss: 1.1297 | ds_loss: 1.1377 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   1576/156230 | global iter:   1576/156230 | loss: 1.2056 | ds_loss: 1.2044 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1576/156230 | global iter:   1576/156230 | loss: 1.1693 | ds_loss: 1.1765 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.374 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1577/156230 | global iter:   1577/156230 | loss: 0.9347 | ds_loss: 0.9346 | lr: 9.9976e-05 | scale:  8192.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   1578/156230 | global iter:   1578/156230 | loss: 1.3103 | ds_loss: 1.3119 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   1579/156230 | global iter:   1579/156230 | loss: 1.3564 | ds_loss: 1.3568 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   1580/156230 | global iter:   1580/156230 | loss: 1.2542 | ds_loss: 1.2572 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1580/156230 | global iter:   1580/156230 | loss: 1.2139 | ds_loss: 1.2151 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.377 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1581/156230 | global iter:   1581/156230 | loss: 1.0760 | ds_loss: 1.0748 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   1582/156230 | global iter:   1582/156230 | loss: 1.1627 | ds_loss: 1.1783 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   1583/156230 | global iter:   1583/156230 | loss: 1.3562 | ds_loss: 1.3668 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   1584/156230 | global iter:   1584/156230 | loss: 1.2343 | ds_loss: 1.2364 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1584/156230 | global iter:   1584/156230 | loss: 1.2073 | ds_loss: 1.2141 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.400 | step time: 1.381
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1585/156230 | global iter:   1585/156230 | loss: 1.1864 | ds_loss: 1.1930 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   1586/156230 | global iter:   1586/156230 | loss: 1.1656 | ds_loss: 1.1747 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   1587/156230 | global iter:   1587/156230 | loss: 1.3446 | ds_loss: 1.3512 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   1588/156230 | global iter:   1588/156230 | loss: 1.1776 | ds_loss: 1.1680 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1588/156230 | global iter:   1588/156230 | loss: 1.2185 | ds_loss: 1.2217 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.349 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1589/156230 | global iter:   1589/156230 | loss: 1.2006 | ds_loss: 1.1945 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   1590/156230 | global iter:   1590/156230 | loss: 1.4683 | ds_loss: 1.4721 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   1591/156230 | global iter:   1591/156230 | loss: 1.1622 | ds_loss: 1.1590 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   1592/156230 | global iter:   1592/156230 | loss: 1.1614 | ds_loss: 1.1613 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.344 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1592/156230 | global iter:   1592/156230 | loss: 1.2481 | ds_loss: 1.2467 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.344 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1593/156230 | global iter:   1593/156230 | loss: 1.1603 | ds_loss: 1.1693 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.423 | step time: 0.000
train | epoch   0 | Iter:   1594/156230 | global iter:   1594/156230 | loss: 1.2385 | ds_loss: 1.2596 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   1595/156230 | global iter:   1595/156230 | loss: 1.1342 | ds_loss: 1.1346 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   1596/156230 | global iter:   1596/156230 | loss: 1.3092 | ds_loss: 1.3263 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1596/156230 | global iter:   1596/156230 | loss: 1.2105 | ds_loss: 1.2224 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1597/156230 | global iter:   1597/156230 | loss: 1.3947 | ds_loss: 1.4008 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:   1598/156230 | global iter:   1598/156230 | loss: 1.2255 | ds_loss: 1.2261 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   1599/156230 | global iter:   1599/156230 | loss: 1.1974 | ds_loss: 1.2018 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   1600/156230 | global iter:   1600/156230 | loss: 1.2830 | ds_loss: 1.2917 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.352 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1600/156230 | global iter:   1600/156230 | loss: 1.2751 | ds_loss: 1.2801 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.352 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1601/156230 | global iter:   1601/156230 | loss: 1.2654 | ds_loss: 1.2708 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.305 | step time: 0.000
train | epoch   0 | Iter:   1602/156230 | global iter:   1602/156230 | loss: 1.1773 | ds_loss: 1.1690 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   1603/156230 | global iter:   1603/156230 | loss: 1.2345 | ds_loss: 1.2228 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   1604/156230 | global iter:   1604/156230 | loss: 1.1233 | ds_loss: 1.1286 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.340 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1604/156230 | global iter:   1604/156230 | loss: 1.2002 | ds_loss: 1.1978 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.340 | step time: 1.344
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1605/156230 | global iter:   1605/156230 | loss: 1.2812 | ds_loss: 1.2983 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   1606/156230 | global iter:   1606/156230 | loss: 0.9355 | ds_loss: 0.9410 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   1607/156230 | global iter:   1607/156230 | loss: 1.2742 | ds_loss: 1.2949 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   1608/156230 | global iter:   1608/156230 | loss: 1.1437 | ds_loss: 1.1498 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1608/156230 | global iter:   1608/156230 | loss: 1.1587 | ds_loss: 1.1710 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.357 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1609/156230 | global iter:   1609/156230 | loss: 1.2836 | ds_loss: 1.2731 | lr: 9.9975e-05 | scale:  8192.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   1610/156230 | global iter:   1610/156230 | loss: 1.3113 | ds_loss: 1.3300 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   1611/156230 | global iter:   1611/156230 | loss: 1.2028 | ds_loss: 1.2014 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   1612/156230 | global iter:   1612/156230 | loss: 1.1589 | ds_loss: 1.1639 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.334 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1612/156230 | global iter:   1612/156230 | loss: 1.2391 | ds_loss: 1.2421 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.334 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1613/156230 | global iter:   1613/156230 | loss: 1.1888 | ds_loss: 1.1936 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.409 | step time: 0.000
train | epoch   0 | Iter:   1614/156230 | global iter:   1614/156230 | loss: 1.3540 | ds_loss: 1.3668 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.410 | step time: 0.000
train | epoch   0 | Iter:   1615/156230 | global iter:   1615/156230 | loss: 1.2607 | ds_loss: 1.2528 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.412 | step time: 0.000
train | epoch   0 | Iter:   1616/156230 | global iter:   1616/156230 | loss: 1.1942 | ds_loss: 1.1897 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1616/156230 | global iter:   1616/156230 | loss: 1.2494 | ds_loss: 1.2507 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.354 | step time: 1.396
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1617/156230 | global iter:   1617/156230 | loss: 1.3378 | ds_loss: 1.3556 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   1618/156230 | global iter:   1618/156230 | loss: 1.1515 | ds_loss: 1.1702 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   1619/156230 | global iter:   1619/156230 | loss: 1.0907 | ds_loss: 1.0714 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   1620/156230 | global iter:   1620/156230 | loss: 1.3241 | ds_loss: 1.3271 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1620/156230 | global iter:   1620/156230 | loss: 1.2260 | ds_loss: 1.2311 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1621/156230 | global iter:   1621/156230 | loss: 1.1705 | ds_loss: 1.1754 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   1622/156230 | global iter:   1622/156230 | loss: 1.0894 | ds_loss: 1.0807 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   1623/156230 | global iter:   1623/156230 | loss: 1.2367 | ds_loss: 1.2397 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   1624/156230 | global iter:   1624/156230 | loss: 1.4815 | ds_loss: 1.4740 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.356 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1624/156230 | global iter:   1624/156230 | loss: 1.2445 | ds_loss: 1.2424 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.356 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1625/156230 | global iter:   1625/156230 | loss: 1.0873 | ds_loss: 1.0983 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   1626/156230 | global iter:   1626/156230 | loss: 1.1737 | ds_loss: 1.1725 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.416 | step time: 0.000
train | epoch   0 | Iter:   1627/156230 | global iter:   1627/156230 | loss: 1.1788 | ds_loss: 1.1913 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   1628/156230 | global iter:   1628/156230 | loss: 1.1113 | ds_loss: 1.1211 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.343 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1628/156230 | global iter:   1628/156230 | loss: 1.1378 | ds_loss: 1.1458 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.343 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1629/156230 | global iter:   1629/156230 | loss: 1.2343 | ds_loss: 1.2451 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   1630/156230 | global iter:   1630/156230 | loss: 1.3628 | ds_loss: 1.3744 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   1631/156230 | global iter:   1631/156230 | loss: 1.2100 | ds_loss: 1.2098 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.416 | step time: 0.000
train | epoch   0 | Iter:   1632/156230 | global iter:   1632/156230 | loss: 1.2200 | ds_loss: 1.2241 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1632/156230 | global iter:   1632/156230 | loss: 1.2568 | ds_loss: 1.2634 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.373 | step time: 1.384
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1633/156230 | global iter:   1633/156230 | loss: 1.0964 | ds_loss: 1.1157 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   1634/156230 | global iter:   1634/156230 | loss: 1.2476 | ds_loss: 1.2577 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   1635/156230 | global iter:   1635/156230 | loss: 1.1289 | ds_loss: 1.1398 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   1636/156230 | global iter:   1636/156230 | loss: 1.1499 | ds_loss: 1.1678 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1636/156230 | global iter:   1636/156230 | loss: 1.1557 | ds_loss: 1.1702 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.373 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1637/156230 | global iter:   1637/156230 | loss: 1.1469 | ds_loss: 1.1593 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   1638/156230 | global iter:   1638/156230 | loss: 1.0976 | ds_loss: 1.0927 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   1639/156230 | global iter:   1639/156230 | loss: 1.1398 | ds_loss: 1.1466 | lr: 9.9974e-05 | scale:  8192.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   1640/156230 | global iter:   1640/156230 | loss: 1.1456 | ds_loss: 1.1548 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.341 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1640/156230 | global iter:   1640/156230 | loss: 1.1325 | ds_loss: 1.1383 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.341 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1641/156230 | global iter:   1641/156230 | loss: 1.2036 | ds_loss: 1.2053 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   1642/156230 | global iter:   1642/156230 | loss: 1.2583 | ds_loss: 1.2452 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.316 | step time: 0.000
train | epoch   0 | Iter:   1643/156230 | global iter:   1643/156230 | loss: 1.3751 | ds_loss: 1.3829 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.401 | step time: 0.000
train | epoch   0 | Iter:   1644/156230 | global iter:   1644/156230 | loss: 1.1326 | ds_loss: 1.1417 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1644/156230 | global iter:   1644/156230 | loss: 1.2424 | ds_loss: 1.2438 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.354 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1645/156230 | global iter:   1645/156230 | loss: 1.1602 | ds_loss: 1.1667 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   1646/156230 | global iter:   1646/156230 | loss: 1.0970 | ds_loss: 1.0947 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.317 | step time: 0.000
train | epoch   0 | Iter:   1647/156230 | global iter:   1647/156230 | loss: 1.2679 | ds_loss: 1.2840 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   1648/156230 | global iter:   1648/156230 | loss: 1.2097 | ds_loss: 1.2096 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.324 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1648/156230 | global iter:   1648/156230 | loss: 1.1837 | ds_loss: 1.1888 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.324 | step time: 1.340
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1649/156230 | global iter:   1649/156230 | loss: 1.3374 | ds_loss: 1.3278 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   1650/156230 | global iter:   1650/156230 | loss: 1.1069 | ds_loss: 1.1157 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   1651/156230 | global iter:   1651/156230 | loss: 1.3880 | ds_loss: 1.3906 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:   1652/156230 | global iter:   1652/156230 | loss: 1.2169 | ds_loss: 1.2333 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.331 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1652/156230 | global iter:   1652/156230 | loss: 1.2623 | ds_loss: 1.2669 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.331 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1653/156230 | global iter:   1653/156230 | loss: 1.1284 | ds_loss: 1.1523 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   1654/156230 | global iter:   1654/156230 | loss: 1.1329 | ds_loss: 1.1340 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   1655/156230 | global iter:   1655/156230 | loss: 1.3306 | ds_loss: 1.3430 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   1656/156230 | global iter:   1656/156230 | loss: 1.2602 | ds_loss: 1.2658 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.388 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1656/156230 | global iter:   1656/156230 | loss: 1.2130 | ds_loss: 1.2238 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.388 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1657/156230 | global iter:   1657/156230 | loss: 1.1465 | ds_loss: 1.1420 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   1658/156230 | global iter:   1658/156230 | loss: 1.0716 | ds_loss: 1.0690 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   1659/156230 | global iter:   1659/156230 | loss: 1.4457 | ds_loss: 1.4568 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   1660/156230 | global iter:   1660/156230 | loss: 1.3149 | ds_loss: 1.3144 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.348 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1660/156230 | global iter:   1660/156230 | loss: 1.2447 | ds_loss: 1.2456 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.348 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1661/156230 | global iter:   1661/156230 | loss: 1.5093 | ds_loss: 1.5223 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   1662/156230 | global iter:   1662/156230 | loss: 1.1375 | ds_loss: 1.1515 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   1663/156230 | global iter:   1663/156230 | loss: 1.3422 | ds_loss: 1.3407 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   1664/156230 | global iter:   1664/156230 | loss: 1.1436 | ds_loss: 1.1351 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1664/156230 | global iter:   1664/156230 | loss: 1.2832 | ds_loss: 1.2874 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1665/156230 | global iter:   1665/156230 | loss: 1.1054 | ds_loss: 1.1132 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   1666/156230 | global iter:   1666/156230 | loss: 1.3127 | ds_loss: 1.3087 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.322 | step time: 0.000
train | epoch   0 | Iter:   1667/156230 | global iter:   1667/156230 | loss: 1.3008 | ds_loss: 1.3056 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   1668/156230 | global iter:   1668/156230 | loss: 1.3465 | ds_loss: 1.3591 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1668/156230 | global iter:   1668/156230 | loss: 1.2663 | ds_loss: 1.2717 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.354 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1669/156230 | global iter:   1669/156230 | loss: 1.3208 | ds_loss: 1.3354 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   1670/156230 | global iter:   1670/156230 | loss: 1.1970 | ds_loss: 1.2130 | lr: 9.9973e-05 | scale:  8192.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   1671/156230 | global iter:   1671/156230 | loss: 1.2238 | ds_loss: 1.2432 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   1672/156230 | global iter:   1672/156230 | loss: 1.0220 | ds_loss: 1.0317 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.380 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1672/156230 | global iter:   1672/156230 | loss: 1.1909 | ds_loss: 1.2058 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.380 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1673/156230 | global iter:   1673/156230 | loss: 1.1796 | ds_loss: 1.1765 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.401 | step time: 0.000
train | epoch   0 | Iter:   1674/156230 | global iter:   1674/156230 | loss: 1.3662 | ds_loss: 1.3511 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   1675/156230 | global iter:   1675/156230 | loss: 1.1981 | ds_loss: 1.1992 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   1676/156230 | global iter:   1676/156230 | loss: 1.2902 | ds_loss: 1.2727 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.372 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1676/156230 | global iter:   1676/156230 | loss: 1.2585 | ds_loss: 1.2499 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.372 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1677/156230 | global iter:   1677/156230 | loss: 1.0821 | ds_loss: 1.0990 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   1678/156230 | global iter:   1678/156230 | loss: 1.3065 | ds_loss: 1.3104 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   1679/156230 | global iter:   1679/156230 | loss: 1.2958 | ds_loss: 1.2937 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   1680/156230 | global iter:   1680/156230 | loss: 1.3554 | ds_loss: 1.3645 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.392 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1680/156230 | global iter:   1680/156230 | loss: 1.2599 | ds_loss: 1.2669 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.392 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1681/156230 | global iter:   1681/156230 | loss: 1.4291 | ds_loss: 1.4481 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   1682/156230 | global iter:   1682/156230 | loss: 1.1536 | ds_loss: 1.1847 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   1683/156230 | global iter:   1683/156230 | loss: 1.0555 | ds_loss: 1.0671 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   1684/156230 | global iter:   1684/156230 | loss: 1.0687 | ds_loss: 1.0612 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1684/156230 | global iter:   1684/156230 | loss: 1.1767 | ds_loss: 1.1902 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.349 | step time: 1.348
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1685/156230 | global iter:   1685/156230 | loss: 1.2296 | ds_loss: 1.2263 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   1686/156230 | global iter:   1686/156230 | loss: 1.1417 | ds_loss: 1.1716 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   1687/156230 | global iter:   1687/156230 | loss: 1.1739 | ds_loss: 1.1838 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   1688/156230 | global iter:   1688/156230 | loss: 1.1373 | ds_loss: 1.1441 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.309 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1688/156230 | global iter:   1688/156230 | loss: 1.1706 | ds_loss: 1.1814 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.309 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1689/156230 | global iter:   1689/156230 | loss: 1.1958 | ds_loss: 1.1982 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   1690/156230 | global iter:   1690/156230 | loss: 1.0097 | ds_loss: 1.0206 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   1691/156230 | global iter:   1691/156230 | loss: 1.2237 | ds_loss: 1.2150 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   1692/156230 | global iter:   1692/156230 | loss: 1.0615 | ds_loss: 1.0514 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1692/156230 | global iter:   1692/156230 | loss: 1.1227 | ds_loss: 1.1213 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.365 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1693/156230 | global iter:   1693/156230 | loss: 1.1665 | ds_loss: 1.1630 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   1694/156230 | global iter:   1694/156230 | loss: 1.2127 | ds_loss: 1.2139 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   1695/156230 | global iter:   1695/156230 | loss: 1.0739 | ds_loss: 1.0773 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   1696/156230 | global iter:   1696/156230 | loss: 1.3979 | ds_loss: 1.4031 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.337 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1696/156230 | global iter:   1696/156230 | loss: 1.2128 | ds_loss: 1.2143 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.337 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1697/156230 | global iter:   1697/156230 | loss: 1.2249 | ds_loss: 1.2245 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   1698/156230 | global iter:   1698/156230 | loss: 1.0559 | ds_loss: 1.0619 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   1699/156230 | global iter:   1699/156230 | loss: 1.1285 | ds_loss: 1.1238 | lr: 9.9972e-05 | scale:  8192.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:   1700/156230 | global iter:   1700/156230 | loss: 1.1917 | ds_loss: 1.1853 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.348 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1700/156230 | global iter:   1700/156230 | loss: 1.1503 | ds_loss: 1.1489 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.348 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1701/156230 | global iter:   1701/156230 | loss: 1.2141 | ds_loss: 1.2305 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   1702/156230 | global iter:   1702/156230 | loss: 1.0868 | ds_loss: 1.0885 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   1703/156230 | global iter:   1703/156230 | loss: 1.0324 | ds_loss: 1.0382 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.322 | step time: 0.000
train | epoch   0 | Iter:   1704/156230 | global iter:   1704/156230 | loss: 1.3026 | ds_loss: 1.3115 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.323 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1704/156230 | global iter:   1704/156230 | loss: 1.1590 | ds_loss: 1.1672 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.323 | step time: 1.341
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1705/156230 | global iter:   1705/156230 | loss: 1.1162 | ds_loss: 1.1163 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   1706/156230 | global iter:   1706/156230 | loss: 1.1617 | ds_loss: 1.1744 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   1707/156230 | global iter:   1707/156230 | loss: 1.1533 | ds_loss: 1.1623 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   1708/156230 | global iter:   1708/156230 | loss: 1.0613 | ds_loss: 1.0685 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1708/156230 | global iter:   1708/156230 | loss: 1.1231 | ds_loss: 1.1304 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1709/156230 | global iter:   1709/156230 | loss: 1.2817 | ds_loss: 1.2898 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   1710/156230 | global iter:   1710/156230 | loss: 1.2340 | ds_loss: 1.2280 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   1711/156230 | global iter:   1711/156230 | loss: 1.0149 | ds_loss: 1.0253 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   1712/156230 | global iter:   1712/156230 | loss: 1.1925 | ds_loss: 1.1690 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1712/156230 | global iter:   1712/156230 | loss: 1.1808 | ds_loss: 1.1780 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 1.376
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1713/156230 | global iter:   1713/156230 | loss: 1.0150 | ds_loss: 1.0237 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   1714/156230 | global iter:   1714/156230 | loss: 1.2737 | ds_loss: 1.2785 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   1715/156230 | global iter:   1715/156230 | loss: 1.0992 | ds_loss: 1.1100 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   1716/156230 | global iter:   1716/156230 | loss: 1.2559 | ds_loss: 1.2648 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.372 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1716/156230 | global iter:   1716/156230 | loss: 1.1610 | ds_loss: 1.1693 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.372 | step time: 1.376
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1717/156230 | global iter:   1717/156230 | loss: 1.2619 | ds_loss: 1.2736 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.410 | step time: 0.000
train | epoch   0 | Iter:   1718/156230 | global iter:   1718/156230 | loss: 1.2104 | ds_loss: 1.2172 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   1719/156230 | global iter:   1719/156230 | loss: 1.2851 | ds_loss: 1.2793 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   1720/156230 | global iter:   1720/156230 | loss: 1.1424 | ds_loss: 1.1420 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.388 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1720/156230 | global iter:   1720/156230 | loss: 1.2250 | ds_loss: 1.2280 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.388 | step time: 1.384
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1721/156230 | global iter:   1721/156230 | loss: 1.1637 | ds_loss: 1.1518 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:   1722/156230 | global iter:   1722/156230 | loss: 1.3119 | ds_loss: 1.3195 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   1723/156230 | global iter:   1723/156230 | loss: 1.1941 | ds_loss: 1.2044 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   1724/156230 | global iter:   1724/156230 | loss: 1.2964 | ds_loss: 1.3058 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1724/156230 | global iter:   1724/156230 | loss: 1.2415 | ds_loss: 1.2454 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.381 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1725/156230 | global iter:   1725/156230 | loss: 1.1246 | ds_loss: 1.1294 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   1726/156230 | global iter:   1726/156230 | loss: 1.1770 | ds_loss: 1.1900 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   1727/156230 | global iter:   1727/156230 | loss: 1.2226 | ds_loss: 1.2174 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   1728/156230 | global iter:   1728/156230 | loss: 1.0943 | ds_loss: 1.0973 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1728/156230 | global iter:   1728/156230 | loss: 1.1546 | ds_loss: 1.1585 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.357 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1729/156230 | global iter:   1729/156230 | loss: 1.2144 | ds_loss: 1.2289 | lr: 9.9971e-05 | scale:  8192.0000 | micro time: 1.405 | step time: 0.000
train | epoch   0 | Iter:   1730/156230 | global iter:   1730/156230 | loss: 1.3365 | ds_loss: 1.3372 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   1731/156230 | global iter:   1731/156230 | loss: 1.1458 | ds_loss: 1.1476 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   1732/156230 | global iter:   1732/156230 | loss: 1.1280 | ds_loss: 1.1366 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1732/156230 | global iter:   1732/156230 | loss: 1.2062 | ds_loss: 1.2126 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.362 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1733/156230 | global iter:   1733/156230 | loss: 1.2054 | ds_loss: 1.2215 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:   1734/156230 | global iter:   1734/156230 | loss: 1.2392 | ds_loss: 1.2593 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   1735/156230 | global iter:   1735/156230 | loss: 1.1021 | ds_loss: 1.0958 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   1736/156230 | global iter:   1736/156230 | loss: 1.0225 | ds_loss: 1.0169 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.321 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1736/156230 | global iter:   1736/156230 | loss: 1.1423 | ds_loss: 1.1484 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.321 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1737/156230 | global iter:   1737/156230 | loss: 1.4789 | ds_loss: 1.4829 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.413 | step time: 0.000
train | epoch   0 | Iter:   1738/156230 | global iter:   1738/156230 | loss: 1.0355 | ds_loss: 1.0356 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   1739/156230 | global iter:   1739/156230 | loss: 1.2577 | ds_loss: 1.2448 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   1740/156230 | global iter:   1740/156230 | loss: 1.1127 | ds_loss: 1.1307 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.359 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1740/156230 | global iter:   1740/156230 | loss: 1.2212 | ds_loss: 1.2235 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.359 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1741/156230 | global iter:   1741/156230 | loss: 1.0651 | ds_loss: 1.0704 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   1742/156230 | global iter:   1742/156230 | loss: 1.1503 | ds_loss: 1.1545 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   1743/156230 | global iter:   1743/156230 | loss: 1.3000 | ds_loss: 1.3022 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   1744/156230 | global iter:   1744/156230 | loss: 1.3563 | ds_loss: 1.3699 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1744/156230 | global iter:   1744/156230 | loss: 1.2179 | ds_loss: 1.2243 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.345 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1745/156230 | global iter:   1745/156230 | loss: 1.2782 | ds_loss: 1.2774 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   1746/156230 | global iter:   1746/156230 | loss: 1.2249 | ds_loss: 1.2267 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   1747/156230 | global iter:   1747/156230 | loss: 1.2973 | ds_loss: 1.3020 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   1748/156230 | global iter:   1748/156230 | loss: 1.2022 | ds_loss: 1.2026 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.389 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1748/156230 | global iter:   1748/156230 | loss: 1.2507 | ds_loss: 1.2522 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.389 | step time: 1.380
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1749/156230 | global iter:   1749/156230 | loss: 1.3159 | ds_loss: 1.3326 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   1750/156230 | global iter:   1750/156230 | loss: 1.1578 | ds_loss: 1.1519 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   1751/156230 | global iter:   1751/156230 | loss: 1.2847 | ds_loss: 1.3049 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.401 | step time: 0.000
train | epoch   0 | Iter:   1752/156230 | global iter:   1752/156230 | loss: 1.3065 | ds_loss: 1.3258 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.346 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1752/156230 | global iter:   1752/156230 | loss: 1.2662 | ds_loss: 1.2788 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.346 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1753/156230 | global iter:   1753/156230 | loss: 1.2342 | ds_loss: 1.2452 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   1754/156230 | global iter:   1754/156230 | loss: 1.2058 | ds_loss: 1.2057 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   1755/156230 | global iter:   1755/156230 | loss: 1.1592 | ds_loss: 1.1757 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   1756/156230 | global iter:   1756/156230 | loss: 1.2660 | ds_loss: 1.2812 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1756/156230 | global iter:   1756/156230 | loss: 1.2163 | ds_loss: 1.2269 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.351 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1757/156230 | global iter:   1757/156230 | loss: 1.2623 | ds_loss: 1.2673 | lr: 9.9970e-05 | scale:  8192.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   1758/156230 | global iter:   1758/156230 | loss: 1.1957 | ds_loss: 1.1987 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   1759/156230 | global iter:   1759/156230 | loss: 1.1695 | ds_loss: 1.1668 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   1760/156230 | global iter:   1760/156230 | loss: 1.2397 | ds_loss: 1.2422 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1760/156230 | global iter:   1760/156230 | loss: 1.2168 | ds_loss: 1.2187 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.377 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1761/156230 | global iter:   1761/156230 | loss: 1.2544 | ds_loss: 1.2753 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   1762/156230 | global iter:   1762/156230 | loss: 1.0772 | ds_loss: 1.0854 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   1763/156230 | global iter:   1763/156230 | loss: 1.1529 | ds_loss: 1.1651 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   1764/156230 | global iter:   1764/156230 | loss: 1.0922 | ds_loss: 1.0995 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.358 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1764/156230 | global iter:   1764/156230 | loss: 1.1442 | ds_loss: 1.1563 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.358 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1765/156230 | global iter:   1765/156230 | loss: 1.0946 | ds_loss: 1.1141 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   1766/156230 | global iter:   1766/156230 | loss: 1.0491 | ds_loss: 1.0369 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   1767/156230 | global iter:   1767/156230 | loss: 1.1877 | ds_loss: 1.1913 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   1768/156230 | global iter:   1768/156230 | loss: 1.1697 | ds_loss: 1.1743 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.387 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1768/156230 | global iter:   1768/156230 | loss: 1.1253 | ds_loss: 1.1292 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.387 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1769/156230 | global iter:   1769/156230 | loss: 1.1589 | ds_loss: 1.1471 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   1770/156230 | global iter:   1770/156230 | loss: 1.1841 | ds_loss: 1.1883 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   1771/156230 | global iter:   1771/156230 | loss: 1.2279 | ds_loss: 1.2311 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   1772/156230 | global iter:   1772/156230 | loss: 1.1188 | ds_loss: 1.1203 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1772/156230 | global iter:   1772/156230 | loss: 1.1724 | ds_loss: 1.1717 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.347 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1773/156230 | global iter:   1773/156230 | loss: 1.2588 | ds_loss: 1.2674 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   1774/156230 | global iter:   1774/156230 | loss: 1.0361 | ds_loss: 1.0567 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   1775/156230 | global iter:   1775/156230 | loss: 1.2232 | ds_loss: 1.2275 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   1776/156230 | global iter:   1776/156230 | loss: 1.2297 | ds_loss: 1.2262 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.336 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1776/156230 | global iter:   1776/156230 | loss: 1.1869 | ds_loss: 1.1945 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.336 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1777/156230 | global iter:   1777/156230 | loss: 1.0139 | ds_loss: 1.0274 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   1778/156230 | global iter:   1778/156230 | loss: 1.2864 | ds_loss: 1.2913 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   1779/156230 | global iter:   1779/156230 | loss: 1.1272 | ds_loss: 1.1567 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   1780/156230 | global iter:   1780/156230 | loss: 1.0514 | ds_loss: 1.0623 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.405 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1780/156230 | global iter:   1780/156230 | loss: 1.1197 | ds_loss: 1.1344 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.405 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1781/156230 | global iter:   1781/156230 | loss: 1.2407 | ds_loss: 1.2491 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   1782/156230 | global iter:   1782/156230 | loss: 1.1378 | ds_loss: 1.1611 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.317 | step time: 0.000
train | epoch   0 | Iter:   1783/156230 | global iter:   1783/156230 | loss: 1.0783 | ds_loss: 1.0757 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   1784/156230 | global iter:   1784/156230 | loss: 1.3119 | ds_loss: 1.3293 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1784/156230 | global iter:   1784/156230 | loss: 1.1922 | ds_loss: 1.2038 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.381 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1785/156230 | global iter:   1785/156230 | loss: 1.1427 | ds_loss: 1.1361 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:   1786/156230 | global iter:   1786/156230 | loss: 1.2474 | ds_loss: 1.2388 | lr: 9.9969e-05 | scale:  8192.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   1787/156230 | global iter:   1787/156230 | loss: 1.1047 | ds_loss: 1.1168 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   1788/156230 | global iter:   1788/156230 | loss: 1.2502 | ds_loss: 1.2609 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1788/156230 | global iter:   1788/156230 | loss: 1.1862 | ds_loss: 1.1882 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.398 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1789/156230 | global iter:   1789/156230 | loss: 1.1308 | ds_loss: 1.1298 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   1790/156230 | global iter:   1790/156230 | loss: 1.2136 | ds_loss: 1.2147 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   1791/156230 | global iter:   1791/156230 | loss: 1.3833 | ds_loss: 1.3873 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   1792/156230 | global iter:   1792/156230 | loss: 1.1920 | ds_loss: 1.1888 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1792/156230 | global iter:   1792/156230 | loss: 1.2299 | ds_loss: 1.2302 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.353 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1793/156230 | global iter:   1793/156230 | loss: 1.2961 | ds_loss: 1.3130 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   1794/156230 | global iter:   1794/156230 | loss: 1.0840 | ds_loss: 1.0931 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   1795/156230 | global iter:   1795/156230 | loss: 1.1718 | ds_loss: 1.1761 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   1796/156230 | global iter:   1796/156230 | loss: 1.1853 | ds_loss: 1.1862 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.389 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1796/156230 | global iter:   1796/156230 | loss: 1.1843 | ds_loss: 1.1921 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.389 | step time: 1.385
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1797/156230 | global iter:   1797/156230 | loss: 1.3257 | ds_loss: 1.3239 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   1798/156230 | global iter:   1798/156230 | loss: 1.2031 | ds_loss: 1.2129 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   1799/156230 | global iter:   1799/156230 | loss: 1.1396 | ds_loss: 1.1474 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   1800/156230 | global iter:   1800/156230 | loss: 1.2124 | ds_loss: 1.2274 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.379 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1800/156230 | global iter:   1800/156230 | loss: 1.2202 | ds_loss: 1.2279 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.379 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1801/156230 | global iter:   1801/156230 | loss: 1.1912 | ds_loss: 1.1965 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   1802/156230 | global iter:   1802/156230 | loss: 1.0782 | ds_loss: 1.0779 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   1803/156230 | global iter:   1803/156230 | loss: 1.2059 | ds_loss: 1.2221 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   1804/156230 | global iter:   1804/156230 | loss: 1.1299 | ds_loss: 1.1292 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1804/156230 | global iter:   1804/156230 | loss: 1.1513 | ds_loss: 1.1564 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.377 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1805/156230 | global iter:   1805/156230 | loss: 1.1363 | ds_loss: 1.1528 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   1806/156230 | global iter:   1806/156230 | loss: 1.1437 | ds_loss: 1.1525 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   1807/156230 | global iter:   1807/156230 | loss: 1.2656 | ds_loss: 1.2560 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   1808/156230 | global iter:   1808/156230 | loss: 1.1897 | ds_loss: 1.1994 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1808/156230 | global iter:   1808/156230 | loss: 1.1838 | ds_loss: 1.1902 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1809/156230 | global iter:   1809/156230 | loss: 1.2517 | ds_loss: 1.2393 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   1810/156230 | global iter:   1810/156230 | loss: 1.1769 | ds_loss: 1.1887 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   1811/156230 | global iter:   1811/156230 | loss: 1.0074 | ds_loss: 1.0238 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   1812/156230 | global iter:   1812/156230 | loss: 1.2039 | ds_loss: 1.2019 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.324 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1812/156230 | global iter:   1812/156230 | loss: 1.1600 | ds_loss: 1.1634 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.324 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1813/156230 | global iter:   1813/156230 | loss: 1.3059 | ds_loss: 1.2931 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   1814/156230 | global iter:   1814/156230 | loss: 1.2910 | ds_loss: 1.3067 | lr: 9.9968e-05 | scale:  8192.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   1815/156230 | global iter:   1815/156230 | loss: 1.1433 | ds_loss: 1.1366 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:   1816/156230 | global iter:   1816/156230 | loss: 1.2783 | ds_loss: 1.2859 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1816/156230 | global iter:   1816/156230 | loss: 1.2546 | ds_loss: 1.2556 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.353 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1817/156230 | global iter:   1817/156230 | loss: 1.2550 | ds_loss: 1.2497 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   1818/156230 | global iter:   1818/156230 | loss: 1.1563 | ds_loss: 1.1667 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   1819/156230 | global iter:   1819/156230 | loss: 1.3027 | ds_loss: 1.3069 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   1820/156230 | global iter:   1820/156230 | loss: 1.1384 | ds_loss: 1.1391 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1820/156230 | global iter:   1820/156230 | loss: 1.2131 | ds_loss: 1.2156 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.370 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1821/156230 | global iter:   1821/156230 | loss: 1.2596 | ds_loss: 1.2624 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   1822/156230 | global iter:   1822/156230 | loss: 1.2244 | ds_loss: 1.2387 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   1823/156230 | global iter:   1823/156230 | loss: 1.1439 | ds_loss: 1.1390 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   1824/156230 | global iter:   1824/156230 | loss: 1.1647 | ds_loss: 1.1733 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1824/156230 | global iter:   1824/156230 | loss: 1.1981 | ds_loss: 1.2033 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.349 | step time: 1.342
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1825/156230 | global iter:   1825/156230 | loss: 1.2593 | ds_loss: 1.2650 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   1826/156230 | global iter:   1826/156230 | loss: 1.5056 | ds_loss: 1.5032 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   1827/156230 | global iter:   1827/156230 | loss: 1.2301 | ds_loss: 1.2381 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   1828/156230 | global iter:   1828/156230 | loss: 1.3188 | ds_loss: 1.3329 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1828/156230 | global iter:   1828/156230 | loss: 1.3285 | ds_loss: 1.3348 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.368 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1829/156230 | global iter:   1829/156230 | loss: 1.2146 | ds_loss: 1.2050 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   1830/156230 | global iter:   1830/156230 | loss: 1.0677 | ds_loss: 1.0600 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   1831/156230 | global iter:   1831/156230 | loss: 1.1980 | ds_loss: 1.2053 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   1832/156230 | global iter:   1832/156230 | loss: 1.0453 | ds_loss: 1.0474 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1832/156230 | global iter:   1832/156230 | loss: 1.1314 | ds_loss: 1.1294 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.362 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1833/156230 | global iter:   1833/156230 | loss: 1.4126 | ds_loss: 1.4132 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   1834/156230 | global iter:   1834/156230 | loss: 1.2451 | ds_loss: 1.2542 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   1835/156230 | global iter:   1835/156230 | loss: 1.0244 | ds_loss: 1.0327 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   1836/156230 | global iter:   1836/156230 | loss: 1.2062 | ds_loss: 1.2233 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1836/156230 | global iter:   1836/156230 | loss: 1.2221 | ds_loss: 1.2309 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.362 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1837/156230 | global iter:   1837/156230 | loss: 1.0304 | ds_loss: 1.0441 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   1838/156230 | global iter:   1838/156230 | loss: 1.3927 | ds_loss: 1.4014 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   1839/156230 | global iter:   1839/156230 | loss: 1.2801 | ds_loss: 1.2954 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   1840/156230 | global iter:   1840/156230 | loss: 1.1750 | ds_loss: 1.1727 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.367 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1840/156230 | global iter:   1840/156230 | loss: 1.2195 | ds_loss: 1.2284 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.367 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1841/156230 | global iter:   1841/156230 | loss: 1.2044 | ds_loss: 1.2121 | lr: 9.9967e-05 | scale:  8192.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   1842/156230 | global iter:   1842/156230 | loss: 1.2854 | ds_loss: 1.3097 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   1843/156230 | global iter:   1843/156230 | loss: 1.2253 | ds_loss: 1.2452 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   1844/156230 | global iter:   1844/156230 | loss: 1.1937 | ds_loss: 1.2053 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.389 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1844/156230 | global iter:   1844/156230 | loss: 1.2272 | ds_loss: 1.2431 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.389 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1845/156230 | global iter:   1845/156230 | loss: 1.2844 | ds_loss: 1.2898 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   1846/156230 | global iter:   1846/156230 | loss: 1.1483 | ds_loss: 1.1651 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   1847/156230 | global iter:   1847/156230 | loss: 1.0989 | ds_loss: 1.1013 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   1848/156230 | global iter:   1848/156230 | loss: 1.2385 | ds_loss: 1.2550 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.390 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1848/156230 | global iter:   1848/156230 | loss: 1.1925 | ds_loss: 1.2028 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.390 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1849/156230 | global iter:   1849/156230 | loss: 1.1672 | ds_loss: 1.1578 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   1850/156230 | global iter:   1850/156230 | loss: 1.0636 | ds_loss: 1.0771 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   1851/156230 | global iter:   1851/156230 | loss: 1.2058 | ds_loss: 1.2059 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   1852/156230 | global iter:   1852/156230 | loss: 1.1346 | ds_loss: 1.1363 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1852/156230 | global iter:   1852/156230 | loss: 1.1428 | ds_loss: 1.1443 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.357 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1853/156230 | global iter:   1853/156230 | loss: 1.3311 | ds_loss: 1.3376 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   1854/156230 | global iter:   1854/156230 | loss: 1.3236 | ds_loss: 1.3218 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   1855/156230 | global iter:   1855/156230 | loss: 1.2629 | ds_loss: 1.2775 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   1856/156230 | global iter:   1856/156230 | loss: 0.9982 | ds_loss: 1.0070 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1856/156230 | global iter:   1856/156230 | loss: 1.2290 | ds_loss: 1.2360 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.373 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1857/156230 | global iter:   1857/156230 | loss: 1.1359 | ds_loss: 1.1372 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   1858/156230 | global iter:   1858/156230 | loss: 1.1227 | ds_loss: 1.1192 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.416 | step time: 0.000
train | epoch   0 | Iter:   1859/156230 | global iter:   1859/156230 | loss: 1.1056 | ds_loss: 1.1074 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   1860/156230 | global iter:   1860/156230 | loss: 1.2845 | ds_loss: 1.2918 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1860/156230 | global iter:   1860/156230 | loss: 1.1622 | ds_loss: 1.1639 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.362 | step time: 1.380
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1861/156230 | global iter:   1861/156230 | loss: 1.1676 | ds_loss: 1.1673 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   1862/156230 | global iter:   1862/156230 | loss: 1.2757 | ds_loss: 1.2799 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   1863/156230 | global iter:   1863/156230 | loss: 1.1448 | ds_loss: 1.1502 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   1864/156230 | global iter:   1864/156230 | loss: 1.0829 | ds_loss: 1.0944 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1864/156230 | global iter:   1864/156230 | loss: 1.1678 | ds_loss: 1.1730 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.385 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1865/156230 | global iter:   1865/156230 | loss: 1.3140 | ds_loss: 1.3179 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   1866/156230 | global iter:   1866/156230 | loss: 1.2061 | ds_loss: 1.2180 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   1867/156230 | global iter:   1867/156230 | loss: 1.2021 | ds_loss: 1.2138 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   1868/156230 | global iter:   1868/156230 | loss: 1.1794 | ds_loss: 1.1856 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.379 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1868/156230 | global iter:   1868/156230 | loss: 1.2254 | ds_loss: 1.2338 | lr: 9.9966e-05 | scale:  8192.0000 | micro time: 1.379 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1869/156230 | global iter:   1869/156230 | loss: 1.2711 | ds_loss: 1.2659 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   1870/156230 | global iter:   1870/156230 | loss: 1.3145 | ds_loss: 1.3087 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   1871/156230 | global iter:   1871/156230 | loss: 1.3027 | ds_loss: 1.2980 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   1872/156230 | global iter:   1872/156230 | loss: 1.2534 | ds_loss: 1.2496 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1872/156230 | global iter:   1872/156230 | loss: 1.2854 | ds_loss: 1.2805 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.353 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1873/156230 | global iter:   1873/156230 | loss: 1.2216 | ds_loss: 1.2471 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   1874/156230 | global iter:   1874/156230 | loss: 1.0064 | ds_loss: 1.0163 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   1875/156230 | global iter:   1875/156230 | loss: 1.1976 | ds_loss: 1.2147 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   1876/156230 | global iter:   1876/156230 | loss: 1.2985 | ds_loss: 1.3042 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1876/156230 | global iter:   1876/156230 | loss: 1.1810 | ds_loss: 1.1956 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.400 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1877/156230 | global iter:   1877/156230 | loss: 1.0321 | ds_loss: 1.0266 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   1878/156230 | global iter:   1878/156230 | loss: 1.1996 | ds_loss: 1.1952 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   1879/156230 | global iter:   1879/156230 | loss: 1.2077 | ds_loss: 1.2073 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   1880/156230 | global iter:   1880/156230 | loss: 1.2230 | ds_loss: 1.2446 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1880/156230 | global iter:   1880/156230 | loss: 1.1656 | ds_loss: 1.1684 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.364 | step time: 1.376
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1881/156230 | global iter:   1881/156230 | loss: 1.3923 | ds_loss: 1.3899 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   1882/156230 | global iter:   1882/156230 | loss: 1.1128 | ds_loss: 1.1144 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   1883/156230 | global iter:   1883/156230 | loss: 1.0119 | ds_loss: 1.0249 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   1884/156230 | global iter:   1884/156230 | loss: 1.2496 | ds_loss: 1.2475 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.417 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1884/156230 | global iter:   1884/156230 | loss: 1.1917 | ds_loss: 1.1942 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.417 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1885/156230 | global iter:   1885/156230 | loss: 1.0490 | ds_loss: 1.0565 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   1886/156230 | global iter:   1886/156230 | loss: 1.3301 | ds_loss: 1.3476 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   1887/156230 | global iter:   1887/156230 | loss: 1.2295 | ds_loss: 1.2371 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   1888/156230 | global iter:   1888/156230 | loss: 1.0345 | ds_loss: 1.0349 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.390 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1888/156230 | global iter:   1888/156230 | loss: 1.1608 | ds_loss: 1.1690 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.390 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1889/156230 | global iter:   1889/156230 | loss: 1.1559 | ds_loss: 1.1594 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   1890/156230 | global iter:   1890/156230 | loss: 1.3305 | ds_loss: 1.3386 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   1891/156230 | global iter:   1891/156230 | loss: 1.3169 | ds_loss: 1.3375 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   1892/156230 | global iter:   1892/156230 | loss: 1.1160 | ds_loss: 1.1237 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1892/156230 | global iter:   1892/156230 | loss: 1.2298 | ds_loss: 1.2398 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.342 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1893/156230 | global iter:   1893/156230 | loss: 1.2307 | ds_loss: 1.2313 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   1894/156230 | global iter:   1894/156230 | loss: 1.0227 | ds_loss: 1.0229 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.441 | step time: 0.000
train | epoch   0 | Iter:   1895/156230 | global iter:   1895/156230 | loss: 1.3147 | ds_loss: 1.3002 | lr: 9.9965e-05 | scale:  8192.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   1896/156230 | global iter:   1896/156230 | loss: 1.1463 | ds_loss: 1.1441 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.333 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1896/156230 | global iter:   1896/156230 | loss: 1.1786 | ds_loss: 1.1746 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.333 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1897/156230 | global iter:   1897/156230 | loss: 1.2441 | ds_loss: 1.2364 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   1898/156230 | global iter:   1898/156230 | loss: 1.1681 | ds_loss: 1.1725 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   1899/156230 | global iter:   1899/156230 | loss: 1.2376 | ds_loss: 1.2495 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   1900/156230 | global iter:   1900/156230 | loss: 1.1304 | ds_loss: 1.1402 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1900/156230 | global iter:   1900/156230 | loss: 1.1950 | ds_loss: 1.1996 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.385 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1901/156230 | global iter:   1901/156230 | loss: 1.0280 | ds_loss: 1.0251 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   1902/156230 | global iter:   1902/156230 | loss: 1.2449 | ds_loss: 1.2383 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.302 | step time: 0.000
train | epoch   0 | Iter:   1903/156230 | global iter:   1903/156230 | loss: 1.3277 | ds_loss: 1.3382 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   1904/156230 | global iter:   1904/156230 | loss: 1.1138 | ds_loss: 1.1117 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1904/156230 | global iter:   1904/156230 | loss: 1.1786 | ds_loss: 1.1783 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.370 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1905/156230 | global iter:   1905/156230 | loss: 1.2198 | ds_loss: 1.2428 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   1906/156230 | global iter:   1906/156230 | loss: 1.2279 | ds_loss: 1.2377 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.321 | step time: 0.000
train | epoch   0 | Iter:   1907/156230 | global iter:   1907/156230 | loss: 1.2504 | ds_loss: 1.2554 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   1908/156230 | global iter:   1908/156230 | loss: 1.2246 | ds_loss: 1.2303 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1908/156230 | global iter:   1908/156230 | loss: 1.2307 | ds_loss: 1.2415 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.400 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1909/156230 | global iter:   1909/156230 | loss: 1.2581 | ds_loss: 1.2647 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   1910/156230 | global iter:   1910/156230 | loss: 1.1428 | ds_loss: 1.1618 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   1911/156230 | global iter:   1911/156230 | loss: 1.1899 | ds_loss: 1.1920 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   1912/156230 | global iter:   1912/156230 | loss: 1.3214 | ds_loss: 1.3268 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.329 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1912/156230 | global iter:   1912/156230 | loss: 1.2281 | ds_loss: 1.2363 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.329 | step time: 1.346
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1913/156230 | global iter:   1913/156230 | loss: 1.2614 | ds_loss: 1.2640 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   1914/156230 | global iter:   1914/156230 | loss: 1.1301 | ds_loss: 1.1382 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   1915/156230 | global iter:   1915/156230 | loss: 1.2517 | ds_loss: 1.2401 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.401 | step time: 0.000
train | epoch   0 | Iter:   1916/156230 | global iter:   1916/156230 | loss: 1.0314 | ds_loss: 1.0348 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.336 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1916/156230 | global iter:   1916/156230 | loss: 1.1686 | ds_loss: 1.1693 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.336 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1917/156230 | global iter:   1917/156230 | loss: 1.2773 | ds_loss: 1.2991 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   1918/156230 | global iter:   1918/156230 | loss: 1.2543 | ds_loss: 1.2591 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   1919/156230 | global iter:   1919/156230 | loss: 1.2537 | ds_loss: 1.2636 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   1920/156230 | global iter:   1920/156230 | loss: 1.0575 | ds_loss: 1.0653 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1920/156230 | global iter:   1920/156230 | loss: 1.2107 | ds_loss: 1.2218 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.354 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1921/156230 | global iter:   1921/156230 | loss: 1.1569 | ds_loss: 1.1486 | lr: 9.9964e-05 | scale:  8192.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   1922/156230 | global iter:   1922/156230 | loss: 1.0991 | ds_loss: 1.1087 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   1923/156230 | global iter:   1923/156230 | loss: 1.2074 | ds_loss: 1.2136 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   1924/156230 | global iter:   1924/156230 | loss: 1.0321 | ds_loss: 1.0440 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.318 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1924/156230 | global iter:   1924/156230 | loss: 1.1239 | ds_loss: 1.1287 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.318 | step time: 1.344
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1925/156230 | global iter:   1925/156230 | loss: 1.1878 | ds_loss: 1.1859 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   1926/156230 | global iter:   1926/156230 | loss: 1.3013 | ds_loss: 1.3103 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   1927/156230 | global iter:   1927/156230 | loss: 1.0285 | ds_loss: 1.0470 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.309 | step time: 0.000
train | epoch   0 | Iter:   1928/156230 | global iter:   1928/156230 | loss: 1.1660 | ds_loss: 1.1460 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.346 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1928/156230 | global iter:   1928/156230 | loss: 1.1709 | ds_loss: 1.1723 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.346 | step time: 1.346
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1929/156230 | global iter:   1929/156230 | loss: 1.2930 | ds_loss: 1.2926 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   1930/156230 | global iter:   1930/156230 | loss: 1.2280 | ds_loss: 1.2316 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   1931/156230 | global iter:   1931/156230 | loss: 1.0878 | ds_loss: 1.0956 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   1932/156230 | global iter:   1932/156230 | loss: 1.2121 | ds_loss: 1.2158 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.358 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1932/156230 | global iter:   1932/156230 | loss: 1.2052 | ds_loss: 1.2089 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.358 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1933/156230 | global iter:   1933/156230 | loss: 1.1255 | ds_loss: 1.1254 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   1934/156230 | global iter:   1934/156230 | loss: 1.3008 | ds_loss: 1.3188 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   1935/156230 | global iter:   1935/156230 | loss: 0.9620 | ds_loss: 0.9796 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   1936/156230 | global iter:   1936/156230 | loss: 1.1556 | ds_loss: 1.1471 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.338 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1936/156230 | global iter:   1936/156230 | loss: 1.1360 | ds_loss: 1.1427 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.338 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1937/156230 | global iter:   1937/156230 | loss: 1.0593 | ds_loss: 1.0688 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   1938/156230 | global iter:   1938/156230 | loss: 1.1984 | ds_loss: 1.2118 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:   1939/156230 | global iter:   1939/156230 | loss: 1.2793 | ds_loss: 1.2714 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   1940/156230 | global iter:   1940/156230 | loss: 1.3279 | ds_loss: 1.3237 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.325 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1940/156230 | global iter:   1940/156230 | loss: 1.2162 | ds_loss: 1.2189 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.325 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1941/156230 | global iter:   1941/156230 | loss: 0.9018 | ds_loss: 0.9057 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   1942/156230 | global iter:   1942/156230 | loss: 1.2452 | ds_loss: 1.2373 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   1943/156230 | global iter:   1943/156230 | loss: 1.0362 | ds_loss: 1.0478 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   1944/156230 | global iter:   1944/156230 | loss: 1.0994 | ds_loss: 1.0914 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1944/156230 | global iter:   1944/156230 | loss: 1.0707 | ds_loss: 1.0705 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.353 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1945/156230 | global iter:   1945/156230 | loss: 1.1342 | ds_loss: 1.1377 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   1946/156230 | global iter:   1946/156230 | loss: 1.3057 | ds_loss: 1.2911 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   1947/156230 | global iter:   1947/156230 | loss: 1.1564 | ds_loss: 1.1647 | lr: 9.9963e-05 | scale:  8192.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   1948/156230 | global iter:   1948/156230 | loss: 1.1617 | ds_loss: 1.1720 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1948/156230 | global iter:   1948/156230 | loss: 1.1895 | ds_loss: 1.1914 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.347 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1949/156230 | global iter:   1949/156230 | loss: 1.0420 | ds_loss: 1.0574 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   1950/156230 | global iter:   1950/156230 | loss: 1.1405 | ds_loss: 1.1533 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   1951/156230 | global iter:   1951/156230 | loss: 1.3224 | ds_loss: 1.3353 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   1952/156230 | global iter:   1952/156230 | loss: 1.2162 | ds_loss: 1.2225 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.387 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1952/156230 | global iter:   1952/156230 | loss: 1.1803 | ds_loss: 1.1921 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.387 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1953/156230 | global iter:   1953/156230 | loss: 1.1589 | ds_loss: 1.1704 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   1954/156230 | global iter:   1954/156230 | loss: 1.2797 | ds_loss: 1.2863 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   1955/156230 | global iter:   1955/156230 | loss: 1.0786 | ds_loss: 1.0753 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   1956/156230 | global iter:   1956/156230 | loss: 1.0357 | ds_loss: 1.0516 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.340 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1956/156230 | global iter:   1956/156230 | loss: 1.1382 | ds_loss: 1.1459 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.340 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1957/156230 | global iter:   1957/156230 | loss: 1.2894 | ds_loss: 1.2885 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.416 | step time: 0.000
train | epoch   0 | Iter:   1958/156230 | global iter:   1958/156230 | loss: 1.2960 | ds_loss: 1.3048 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   1959/156230 | global iter:   1959/156230 | loss: 1.1068 | ds_loss: 1.1030 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   1960/156230 | global iter:   1960/156230 | loss: 1.1815 | ds_loss: 1.1826 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.384 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1960/156230 | global iter:   1960/156230 | loss: 1.2184 | ds_loss: 1.2198 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.384 | step time: 1.381
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1961/156230 | global iter:   1961/156230 | loss: 1.1998 | ds_loss: 1.1913 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   1962/156230 | global iter:   1962/156230 | loss: 1.1022 | ds_loss: 1.0905 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   1963/156230 | global iter:   1963/156230 | loss: 1.1391 | ds_loss: 1.1472 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.406 | step time: 0.000
train | epoch   0 | Iter:   1964/156230 | global iter:   1964/156230 | loss: 1.2557 | ds_loss: 1.2681 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1964/156230 | global iter:   1964/156230 | loss: 1.1742 | ds_loss: 1.1743 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.354 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1965/156230 | global iter:   1965/156230 | loss: 1.1671 | ds_loss: 1.1816 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   1966/156230 | global iter:   1966/156230 | loss: 1.2288 | ds_loss: 1.2141 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   1967/156230 | global iter:   1967/156230 | loss: 1.0214 | ds_loss: 1.0421 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   1968/156230 | global iter:   1968/156230 | loss: 1.2287 | ds_loss: 1.2331 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.384 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1968/156230 | global iter:   1968/156230 | loss: 1.1615 | ds_loss: 1.1677 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.384 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1969/156230 | global iter:   1969/156230 | loss: 1.1222 | ds_loss: 1.1269 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   1970/156230 | global iter:   1970/156230 | loss: 1.2350 | ds_loss: 1.2418 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.313 | step time: 0.000
train | epoch   0 | Iter:   1971/156230 | global iter:   1971/156230 | loss: 1.0867 | ds_loss: 1.0825 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   1972/156230 | global iter:   1972/156230 | loss: 1.3760 | ds_loss: 1.3787 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1972/156230 | global iter:   1972/156230 | loss: 1.2050 | ds_loss: 1.2075 | lr: 9.9962e-05 | scale:  8192.0000 | micro time: 1.350 | step time: 1.347
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1973/156230 | global iter:   1973/156230 | loss: 1.1145 | ds_loss: 1.1111 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   1974/156230 | global iter:   1974/156230 | loss: 1.2410 | ds_loss: 1.2429 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   1975/156230 | global iter:   1975/156230 | loss: 1.1766 | ds_loss: 1.1856 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   1976/156230 | global iter:   1976/156230 | loss: 1.2181 | ds_loss: 1.2361 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1976/156230 | global iter:   1976/156230 | loss: 1.1875 | ds_loss: 1.1939 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.347 | step time: 1.348
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1977/156230 | global iter:   1977/156230 | loss: 1.0708 | ds_loss: 1.0739 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   1978/156230 | global iter:   1978/156230 | loss: 1.1916 | ds_loss: 1.1909 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   1979/156230 | global iter:   1979/156230 | loss: 1.3184 | ds_loss: 1.3259 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.414 | step time: 0.000
train | epoch   0 | Iter:   1980/156230 | global iter:   1980/156230 | loss: 1.0707 | ds_loss: 1.0623 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1980/156230 | global iter:   1980/156230 | loss: 1.1629 | ds_loss: 1.1632 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.376 | step time: 1.385
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1981/156230 | global iter:   1981/156230 | loss: 1.3299 | ds_loss: 1.3379 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   1982/156230 | global iter:   1982/156230 | loss: 1.3474 | ds_loss: 1.3499 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   1983/156230 | global iter:   1983/156230 | loss: 1.2072 | ds_loss: 1.2119 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.325 | step time: 0.000
train | epoch   0 | Iter:   1984/156230 | global iter:   1984/156230 | loss: 1.1073 | ds_loss: 1.1045 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1984/156230 | global iter:   1984/156230 | loss: 1.2479 | ds_loss: 1.2511 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.360 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1985/156230 | global iter:   1985/156230 | loss: 1.2566 | ds_loss: 1.2489 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   1986/156230 | global iter:   1986/156230 | loss: 1.1543 | ds_loss: 1.1407 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   1987/156230 | global iter:   1987/156230 | loss: 1.1396 | ds_loss: 1.1435 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   1988/156230 | global iter:   1988/156230 | loss: 1.1281 | ds_loss: 1.1255 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.392 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1988/156230 | global iter:   1988/156230 | loss: 1.1697 | ds_loss: 1.1647 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.392 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1989/156230 | global iter:   1989/156230 | loss: 1.1300 | ds_loss: 1.1405 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   1990/156230 | global iter:   1990/156230 | loss: 1.2357 | ds_loss: 1.2475 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   1991/156230 | global iter:   1991/156230 | loss: 1.1779 | ds_loss: 1.1726 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   1992/156230 | global iter:   1992/156230 | loss: 1.1513 | ds_loss: 1.1640 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1992/156230 | global iter:   1992/156230 | loss: 1.1737 | ds_loss: 1.1812 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.396 | step time: 1.381
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1993/156230 | global iter:   1993/156230 | loss: 1.2813 | ds_loss: 1.3008 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   1994/156230 | global iter:   1994/156230 | loss: 1.0415 | ds_loss: 1.0523 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   1995/156230 | global iter:   1995/156230 | loss: 1.1545 | ds_loss: 1.1598 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   1996/156230 | global iter:   1996/156230 | loss: 1.2559 | ds_loss: 1.2608 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.326 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   1996/156230 | global iter:   1996/156230 | loss: 1.1833 | ds_loss: 1.1934 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.326 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   1997/156230 | global iter:   1997/156230 | loss: 1.1448 | ds_loss: 1.1443 | lr: 9.9961e-05 | scale:  8192.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   1998/156230 | global iter:   1998/156230 | loss: 1.2002 | ds_loss: 1.2018 | lr: 9.9960e-05 | scale:  8192.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   1999/156230 | global iter:   1999/156230 | loss: 1.3251 | ds_loss: 1.3389 | lr: 9.9960e-05 | scale:  8192.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   2000/156230 | global iter:   2000/156230 | loss: 1.0245 | ds_loss: 1.0337 | lr: 9.9960e-05 | scale:  8192.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2000/156230 | global iter:   2000/156230 | loss: 1.1736 | ds_loss: 1.1797 | lr: 9.9960e-05 | scale:  8192.0000 | micro time: 1.377 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2001/156230 | global iter:   2001/156230 | loss: 1.0922 | ds_loss: 1.1130 | lr: 9.9960e-05 | scale:  8192.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   2002/156230 | global iter:   2002/156230 | loss: 1.2659 | ds_loss: 1.2706 | lr: 9.9960e-05 | scale:  8192.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   2003/156230 | global iter:   2003/156230 | loss: 1.2132 | ds_loss: 1.2268 | lr: 9.9960e-05 | scale:  8192.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   2004/156230 | global iter:   2004/156230 | loss: 1.1046 | ds_loss: 1.1188 | lr: 9.9960e-05 | scale:  8192.0000 | micro time: 1.338 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2004/156230 | global iter:   2004/156230 | loss: 1.1690 | ds_loss: 1.1823 | lr: 9.9960e-05 | scale:  8192.0000 | micro time: 1.338 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2005/156230 | global iter:   2005/156230 | loss: 1.1417 | ds_loss: 1.1420 | lr: 9.9960e-05 | scale:  8192.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   2006/156230 | global iter:   2006/156230 | loss: 1.2280 | ds_loss: 1.2358 | lr: 9.9960e-05 | scale:  8192.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   2007/156230 | global iter:   2007/156230 | loss: 1.2935 | ds_loss: 1.3069 | lr: 9.9960e-05 | scale:  8192.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   2008/156230 | global iter:   2008/156230 | loss: 1.1240 | ds_loss: 1.1351 | lr: 9.9960e-05 | scale:  8192.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2008/156230 | global iter:   2008/156230 | loss: 1.1968 | ds_loss: 1.2050 | lr: 9.9960e-05 | scale:  8192.0000 | micro time: 1.377 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2009/156230 | global iter:   2009/156230 | loss: 1.2229 | ds_loss: 1.2391 | lr: 9.9960e-05 | scale:  8192.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   2010/156230 | global iter:   2010/156230 | loss: 1.3067 | ds_loss: 1.3164 | lr: 9.9960e-05 | scale:  8192.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   2011/156230 | global iter:   2011/156230 | loss: 1.2565 | ds_loss: 1.2657 | lr: 9.9960e-05 | scale:  8192.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   2012/156230 | global iter:   2012/156230 | loss: 1.0611 | ds_loss: 1.0524 | lr: 9.9960e-05 | scale:  8192.0000 | micro time: 1.383 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2012/156230 | global iter:   2012/156230 | loss: 1.2118 | ds_loss: 1.2184 | lr: 9.9960e-05 | scale:  8192.0000 | micro time: 1.383 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2013/156230 | global iter:   2013/156230 | loss: 1.2298 | ds_loss: 1.2519 | lr: 9.9960e-05 | scale:  8192.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   2014/156230 | global iter:   2014/156230 | loss: 1.2034 | ds_loss: 1.1971 | lr: 9.9960e-05 | scale:  8192.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   2015/156230 | global iter:   2015/156230 | loss: 1.2514 | ds_loss: 1.2326 | lr: 9.9960e-05 | scale:  8192.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   2016/156230 | global iter:   2016/156230 | loss: 1.2348 | ds_loss: 1.2297 | lr: 9.9960e-05 | scale:  8192.0000 | micro time: 1.375 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2016/156230 | global iter:   2016/156230 | loss: 1.2299 | ds_loss: 1.2279 | lr: 9.9960e-05 | scale:  8192.0000 | micro time: 1.375 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2017/156230 | global iter:   2017/156230 | loss: 1.2428 | ds_loss: 1.2477 | lr: 9.9960e-05 | scale:  8192.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   2018/156230 | global iter:   2018/156230 | loss: 1.0837 | ds_loss: 1.0842 | lr: 9.9960e-05 | scale:  8192.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   2019/156230 | global iter:   2019/156230 | loss: 1.0505 | ds_loss: 1.0719 | lr: 9.9960e-05 | scale:  8192.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   2020/156230 | global iter:   2020/156230 | loss: 1.2971 | ds_loss: 1.3083 | lr: 9.9960e-05 | scale: 16384.0000 | micro time: 1.333 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2020/156230 | global iter:   2020/156230 | loss: 1.1685 | ds_loss: 1.1780 | lr: 9.9960e-05 | scale: 16384.0000 | micro time: 1.333 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2021/156230 | global iter:   2021/156230 | loss: 1.1566 | ds_loss: 1.1626 | lr: 9.9960e-05 | scale: 16384.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   2022/156230 | global iter:   2022/156230 | loss: 1.1711 | ds_loss: 1.1759 | lr: 9.9960e-05 | scale: 16384.0000 | micro time: 1.418 | step time: 0.000
train | epoch   0 | Iter:   2023/156230 | global iter:   2023/156230 | loss: 1.2902 | ds_loss: 1.3047 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   2024/156230 | global iter:   2024/156230 | loss: 1.0672 | ds_loss: 1.0639 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.336 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2024/156230 | global iter:   2024/156230 | loss: 1.1713 | ds_loss: 1.1767 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.336 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2025/156230 | global iter:   2025/156230 | loss: 1.2122 | ds_loss: 1.2198 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   2026/156230 | global iter:   2026/156230 | loss: 1.1931 | ds_loss: 1.1869 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   2027/156230 | global iter:   2027/156230 | loss: 1.0802 | ds_loss: 1.0747 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   2028/156230 | global iter:   2028/156230 | loss: 1.2245 | ds_loss: 1.2245 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2028/156230 | global iter:   2028/156230 | loss: 1.1775 | ds_loss: 1.1765 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.351 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2029/156230 | global iter:   2029/156230 | loss: 1.1781 | ds_loss: 1.1863 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   2030/156230 | global iter:   2030/156230 | loss: 1.1826 | ds_loss: 1.1602 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   2031/156230 | global iter:   2031/156230 | loss: 1.3240 | ds_loss: 1.3294 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   2032/156230 | global iter:   2032/156230 | loss: 1.2402 | ds_loss: 1.2487 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2032/156230 | global iter:   2032/156230 | loss: 1.2312 | ds_loss: 1.2312 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.360 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2033/156230 | global iter:   2033/156230 | loss: 1.3056 | ds_loss: 1.3072 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   2034/156230 | global iter:   2034/156230 | loss: 1.1854 | ds_loss: 1.1915 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   2035/156230 | global iter:   2035/156230 | loss: 1.1945 | ds_loss: 1.2010 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   2036/156230 | global iter:   2036/156230 | loss: 1.1773 | ds_loss: 1.1846 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2036/156230 | global iter:   2036/156230 | loss: 1.2157 | ds_loss: 1.2211 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2037/156230 | global iter:   2037/156230 | loss: 1.0476 | ds_loss: 1.0343 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   2038/156230 | global iter:   2038/156230 | loss: 1.2199 | ds_loss: 1.2337 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   2039/156230 | global iter:   2039/156230 | loss: 1.1227 | ds_loss: 1.1357 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   2040/156230 | global iter:   2040/156230 | loss: 1.1604 | ds_loss: 1.1652 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2040/156230 | global iter:   2040/156230 | loss: 1.1376 | ds_loss: 1.1423 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.368 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2041/156230 | global iter:   2041/156230 | loss: 1.2534 | ds_loss: 1.2497 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   2042/156230 | global iter:   2042/156230 | loss: 1.3738 | ds_loss: 1.3786 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   2043/156230 | global iter:   2043/156230 | loss: 1.0983 | ds_loss: 1.0913 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   2044/156230 | global iter:   2044/156230 | loss: 1.0787 | ds_loss: 1.0714 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2044/156230 | global iter:   2044/156230 | loss: 1.2011 | ds_loss: 1.1977 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2045/156230 | global iter:   2045/156230 | loss: 1.1634 | ds_loss: 1.1736 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   2046/156230 | global iter:   2046/156230 | loss: 1.1893 | ds_loss: 1.1837 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   2047/156230 | global iter:   2047/156230 | loss: 1.1641 | ds_loss: 1.1613 | lr: 9.9959e-05 | scale: 16384.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   2048/156230 | global iter:   2048/156230 | loss: 1.2089 | ds_loss: 1.2107 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.346 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2048/156230 | global iter:   2048/156230 | loss: 1.1815 | ds_loss: 1.1823 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.346 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2049/156230 | global iter:   2049/156230 | loss: 1.0666 | ds_loss: 1.0732 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   2050/156230 | global iter:   2050/156230 | loss: 1.4000 | ds_loss: 1.3982 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   2051/156230 | global iter:   2051/156230 | loss: 1.3414 | ds_loss: 1.3451 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.312 | step time: 0.000
train | epoch   0 | Iter:   2052/156230 | global iter:   2052/156230 | loss: 1.2776 | ds_loss: 1.2817 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2052/156230 | global iter:   2052/156230 | loss: 1.2714 | ds_loss: 1.2745 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.353 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2053/156230 | global iter:   2053/156230 | loss: 1.2375 | ds_loss: 1.2342 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   2054/156230 | global iter:   2054/156230 | loss: 1.3517 | ds_loss: 1.3568 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:   2055/156230 | global iter:   2055/156230 | loss: 0.9813 | ds_loss: 0.9942 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.317 | step time: 0.000
train | epoch   0 | Iter:   2056/156230 | global iter:   2056/156230 | loss: 1.1132 | ds_loss: 1.1144 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2056/156230 | global iter:   2056/156230 | loss: 1.1709 | ds_loss: 1.1749 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.385 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2057/156230 | global iter:   2057/156230 | loss: 1.1882 | ds_loss: 1.1926 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   2058/156230 | global iter:   2058/156230 | loss: 1.2301 | ds_loss: 1.2441 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   2059/156230 | global iter:   2059/156230 | loss: 1.1166 | ds_loss: 1.1063 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   2060/156230 | global iter:   2060/156230 | loss: 1.2385 | ds_loss: 1.2469 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2060/156230 | global iter:   2060/156230 | loss: 1.1933 | ds_loss: 1.1975 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2061/156230 | global iter:   2061/156230 | loss: 0.9566 | ds_loss: 0.9639 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   2062/156230 | global iter:   2062/156230 | loss: 1.2584 | ds_loss: 1.2570 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   2063/156230 | global iter:   2063/156230 | loss: 1.2205 | ds_loss: 1.2192 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   2064/156230 | global iter:   2064/156230 | loss: 1.1795 | ds_loss: 1.1824 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2064/156230 | global iter:   2064/156230 | loss: 1.1537 | ds_loss: 1.1556 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.400 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2065/156230 | global iter:   2065/156230 | loss: 1.2388 | ds_loss: 1.2384 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   2066/156230 | global iter:   2066/156230 | loss: 1.0152 | ds_loss: 1.0176 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   2067/156230 | global iter:   2067/156230 | loss: 1.1107 | ds_loss: 1.1060 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   2068/156230 | global iter:   2068/156230 | loss: 1.2084 | ds_loss: 1.2245 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.331 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2068/156230 | global iter:   2068/156230 | loss: 1.1433 | ds_loss: 1.1466 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.331 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2069/156230 | global iter:   2069/156230 | loss: 1.1845 | ds_loss: 1.1889 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   2070/156230 | global iter:   2070/156230 | loss: 1.1773 | ds_loss: 1.1784 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   2071/156230 | global iter:   2071/156230 | loss: 1.2174 | ds_loss: 1.2258 | lr: 9.9958e-05 | scale: 16384.0000 | micro time: 1.318 | step time: 0.000
train | epoch   0 | Iter:   2072/156230 | global iter:   2072/156230 | loss: 1.2880 | ds_loss: 1.2617 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2072/156230 | global iter:   2072/156230 | loss: 1.2168 | ds_loss: 1.2137 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.362 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2073/156230 | global iter:   2073/156230 | loss: 1.1634 | ds_loss: 1.1759 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   2074/156230 | global iter:   2074/156230 | loss: 1.2417 | ds_loss: 1.2386 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   2075/156230 | global iter:   2075/156230 | loss: 1.1362 | ds_loss: 1.1429 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   2076/156230 | global iter:   2076/156230 | loss: 1.2379 | ds_loss: 1.2464 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.404 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2076/156230 | global iter:   2076/156230 | loss: 1.1948 | ds_loss: 1.2009 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.404 | step time: 1.379
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2077/156230 | global iter:   2077/156230 | loss: 1.2271 | ds_loss: 1.2431 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.320 | step time: 0.000
train | epoch   0 | Iter:   2078/156230 | global iter:   2078/156230 | loss: 1.3344 | ds_loss: 1.3455 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   2079/156230 | global iter:   2079/156230 | loss: 1.1817 | ds_loss: 1.1867 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   2080/156230 | global iter:   2080/156230 | loss: 0.9858 | ds_loss: 1.0072 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.344 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2080/156230 | global iter:   2080/156230 | loss: 1.1822 | ds_loss: 1.1956 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.344 | step time: 1.348
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2081/156230 | global iter:   2081/156230 | loss: 1.1834 | ds_loss: 1.1922 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   2082/156230 | global iter:   2082/156230 | loss: 1.1261 | ds_loss: 1.1379 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   2083/156230 | global iter:   2083/156230 | loss: 1.1943 | ds_loss: 1.2010 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   2084/156230 | global iter:   2084/156230 | loss: 1.1418 | ds_loss: 1.1323 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2084/156230 | global iter:   2084/156230 | loss: 1.1614 | ds_loss: 1.1659 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.362 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2085/156230 | global iter:   2085/156230 | loss: 1.2222 | ds_loss: 1.2322 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   2086/156230 | global iter:   2086/156230 | loss: 1.2165 | ds_loss: 1.2142 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   2087/156230 | global iter:   2087/156230 | loss: 0.8837 | ds_loss: 0.8733 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   2088/156230 | global iter:   2088/156230 | loss: 1.2738 | ds_loss: 1.2678 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2088/156230 | global iter:   2088/156230 | loss: 1.1490 | ds_loss: 1.1469 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.370 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2089/156230 | global iter:   2089/156230 | loss: 1.1878 | ds_loss: 1.1974 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   2090/156230 | global iter:   2090/156230 | loss: 1.1064 | ds_loss: 1.0996 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   2091/156230 | global iter:   2091/156230 | loss: 0.9825 | ds_loss: 0.9912 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   2092/156230 | global iter:   2092/156230 | loss: 1.1843 | ds_loss: 1.1643 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.320 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2092/156230 | global iter:   2092/156230 | loss: 1.1153 | ds_loss: 1.1132 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.320 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2093/156230 | global iter:   2093/156230 | loss: 1.2868 | ds_loss: 1.2937 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   2094/156230 | global iter:   2094/156230 | loss: 1.2538 | ds_loss: 1.2646 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   2095/156230 | global iter:   2095/156230 | loss: 1.1142 | ds_loss: 1.1204 | lr: 9.9957e-05 | scale: 16384.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   2096/156230 | global iter:   2096/156230 | loss: 1.1049 | ds_loss: 1.1137 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2096/156230 | global iter:   2096/156230 | loss: 1.1899 | ds_loss: 1.1981 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2097/156230 | global iter:   2097/156230 | loss: 1.2064 | ds_loss: 1.2162 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   2098/156230 | global iter:   2098/156230 | loss: 1.2656 | ds_loss: 1.2766 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   2099/156230 | global iter:   2099/156230 | loss: 1.3010 | ds_loss: 1.3143 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   2100/156230 | global iter:   2100/156230 | loss: 1.1482 | ds_loss: 1.1466 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.341 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2100/156230 | global iter:   2100/156230 | loss: 1.2303 | ds_loss: 1.2384 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.341 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2101/156230 | global iter:   2101/156230 | loss: 1.1750 | ds_loss: 1.1653 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   2102/156230 | global iter:   2102/156230 | loss: 1.0081 | ds_loss: 1.0319 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   2103/156230 | global iter:   2103/156230 | loss: 0.9155 | ds_loss: 0.9312 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   2104/156230 | global iter:   2104/156230 | loss: 1.0664 | ds_loss: 1.0759 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2104/156230 | global iter:   2104/156230 | loss: 1.0412 | ds_loss: 1.0511 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.366 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2105/156230 | global iter:   2105/156230 | loss: 1.1907 | ds_loss: 1.1995 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   2106/156230 | global iter:   2106/156230 | loss: 1.1154 | ds_loss: 1.1112 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   2107/156230 | global iter:   2107/156230 | loss: 1.0132 | ds_loss: 1.0053 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   2108/156230 | global iter:   2108/156230 | loss: 1.1704 | ds_loss: 1.1723 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2108/156230 | global iter:   2108/156230 | loss: 1.1224 | ds_loss: 1.1221 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2109/156230 | global iter:   2109/156230 | loss: 1.1849 | ds_loss: 1.1891 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   2110/156230 | global iter:   2110/156230 | loss: 1.0005 | ds_loss: 1.0092 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   2111/156230 | global iter:   2111/156230 | loss: 1.1147 | ds_loss: 1.1175 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:   2112/156230 | global iter:   2112/156230 | loss: 1.1938 | ds_loss: 1.1948 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.414 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2112/156230 | global iter:   2112/156230 | loss: 1.1235 | ds_loss: 1.1276 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.414 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2113/156230 | global iter:   2113/156230 | loss: 1.0912 | ds_loss: 1.1019 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.315 | step time: 0.000
train | epoch   0 | Iter:   2114/156230 | global iter:   2114/156230 | loss: 1.1794 | ds_loss: 1.1695 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   2115/156230 | global iter:   2115/156230 | loss: 1.0866 | ds_loss: 1.0923 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   2116/156230 | global iter:   2116/156230 | loss: 1.1413 | ds_loss: 1.1473 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.343 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2116/156230 | global iter:   2116/156230 | loss: 1.1246 | ds_loss: 1.1278 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.343 | step time: 1.346
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2117/156230 | global iter:   2117/156230 | loss: 1.2998 | ds_loss: 1.3081 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   2118/156230 | global iter:   2118/156230 | loss: 1.1995 | ds_loss: 1.2248 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   2119/156230 | global iter:   2119/156230 | loss: 1.0339 | ds_loss: 1.0407 | lr: 9.9956e-05 | scale: 16384.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   2120/156230 | global iter:   2120/156230 | loss: 1.2314 | ds_loss: 1.2182 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2120/156230 | global iter:   2120/156230 | loss: 1.1912 | ds_loss: 1.1979 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.366 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2121/156230 | global iter:   2121/156230 | loss: 1.2996 | ds_loss: 1.3054 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   2122/156230 | global iter:   2122/156230 | loss: 1.3583 | ds_loss: 1.3547 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   2123/156230 | global iter:   2123/156230 | loss: 1.2163 | ds_loss: 1.2215 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   2124/156230 | global iter:   2124/156230 | loss: 1.1443 | ds_loss: 1.1527 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.325 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2124/156230 | global iter:   2124/156230 | loss: 1.2547 | ds_loss: 1.2586 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.325 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2125/156230 | global iter:   2125/156230 | loss: 1.2801 | ds_loss: 1.2979 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.315 | step time: 0.000
train | epoch   0 | Iter:   2126/156230 | global iter:   2126/156230 | loss: 1.1037 | ds_loss: 1.1115 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   2127/156230 | global iter:   2127/156230 | loss: 1.1294 | ds_loss: 1.1438 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   2128/156230 | global iter:   2128/156230 | loss: 1.1389 | ds_loss: 1.1396 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2128/156230 | global iter:   2128/156230 | loss: 1.1630 | ds_loss: 1.1732 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 1.341
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2129/156230 | global iter:   2129/156230 | loss: 1.0999 | ds_loss: 1.1019 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:   2130/156230 | global iter:   2130/156230 | loss: 1.3054 | ds_loss: 1.3011 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   2131/156230 | global iter:   2131/156230 | loss: 1.1484 | ds_loss: 1.1569 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   2132/156230 | global iter:   2132/156230 | loss: 1.3426 | ds_loss: 1.3461 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2132/156230 | global iter:   2132/156230 | loss: 1.2241 | ds_loss: 1.2265 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2133/156230 | global iter:   2133/156230 | loss: 1.0877 | ds_loss: 1.0873 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   2134/156230 | global iter:   2134/156230 | loss: 1.2385 | ds_loss: 1.2567 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   2135/156230 | global iter:   2135/156230 | loss: 1.0650 | ds_loss: 1.0721 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.439 | step time: 0.000
train | epoch   0 | Iter:   2136/156230 | global iter:   2136/156230 | loss: 1.1336 | ds_loss: 1.1349 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.319 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2136/156230 | global iter:   2136/156230 | loss: 1.1312 | ds_loss: 1.1378 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.319 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2137/156230 | global iter:   2137/156230 | loss: 1.2281 | ds_loss: 1.2271 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   2138/156230 | global iter:   2138/156230 | loss: 1.1441 | ds_loss: 1.1518 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   2139/156230 | global iter:   2139/156230 | loss: 1.3172 | ds_loss: 1.3211 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.402 | step time: 0.000
train | epoch   0 | Iter:   2140/156230 | global iter:   2140/156230 | loss: 1.0688 | ds_loss: 1.0700 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2140/156230 | global iter:   2140/156230 | loss: 1.1896 | ds_loss: 1.1925 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2141/156230 | global iter:   2141/156230 | loss: 1.1059 | ds_loss: 1.0962 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   2142/156230 | global iter:   2142/156230 | loss: 1.0938 | ds_loss: 1.0932 | lr: 9.9955e-05 | scale: 16384.0000 | micro time: 1.408 | step time: 0.000
train | epoch   0 | Iter:   2143/156230 | global iter:   2143/156230 | loss: 1.1417 | ds_loss: 1.1437 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   2144/156230 | global iter:   2144/156230 | loss: 1.2069 | ds_loss: 1.1909 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.340 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2144/156230 | global iter:   2144/156230 | loss: 1.1371 | ds_loss: 1.1310 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.340 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2145/156230 | global iter:   2145/156230 | loss: 1.4212 | ds_loss: 1.4343 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   2146/156230 | global iter:   2146/156230 | loss: 1.2619 | ds_loss: 1.2661 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   2147/156230 | global iter:   2147/156230 | loss: 1.1746 | ds_loss: 1.1641 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   2148/156230 | global iter:   2148/156230 | loss: 1.0714 | ds_loss: 1.0826 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.340 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2148/156230 | global iter:   2148/156230 | loss: 1.2323 | ds_loss: 1.2368 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.340 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2149/156230 | global iter:   2149/156230 | loss: 1.1968 | ds_loss: 1.1888 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   2150/156230 | global iter:   2150/156230 | loss: 1.2373 | ds_loss: 1.2656 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   2151/156230 | global iter:   2151/156230 | loss: 1.2583 | ds_loss: 1.2777 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   2152/156230 | global iter:   2152/156230 | loss: 1.2372 | ds_loss: 1.2197 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2152/156230 | global iter:   2152/156230 | loss: 1.2324 | ds_loss: 1.2380 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2153/156230 | global iter:   2153/156230 | loss: 1.0479 | ds_loss: 1.0514 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   2154/156230 | global iter:   2154/156230 | loss: 1.0150 | ds_loss: 1.0138 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   2155/156230 | global iter:   2155/156230 | loss: 1.0677 | ds_loss: 1.0608 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   2156/156230 | global iter:   2156/156230 | loss: 1.1290 | ds_loss: 1.1354 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2156/156230 | global iter:   2156/156230 | loss: 1.0649 | ds_loss: 1.0654 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.354 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2157/156230 | global iter:   2157/156230 | loss: 1.1586 | ds_loss: 1.1452 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   2158/156230 | global iter:   2158/156230 | loss: 1.3157 | ds_loss: 1.3047 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   2159/156230 | global iter:   2159/156230 | loss: 1.1307 | ds_loss: 1.1451 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   2160/156230 | global iter:   2160/156230 | loss: 1.0817 | ds_loss: 1.0870 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2160/156230 | global iter:   2160/156230 | loss: 1.1717 | ds_loss: 1.1705 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2161/156230 | global iter:   2161/156230 | loss: 1.2832 | ds_loss: 1.2865 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   2162/156230 | global iter:   2162/156230 | loss: 1.1761 | ds_loss: 1.1743 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   2163/156230 | global iter:   2163/156230 | loss: 1.2538 | ds_loss: 1.2598 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   2164/156230 | global iter:   2164/156230 | loss: 1.2841 | ds_loss: 1.2993 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2164/156230 | global iter:   2164/156230 | loss: 1.2493 | ds_loss: 1.2550 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2165/156230 | global iter:   2165/156230 | loss: 1.3163 | ds_loss: 1.3343 | lr: 9.9954e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   2166/156230 | global iter:   2166/156230 | loss: 1.2547 | ds_loss: 1.2757 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   2167/156230 | global iter:   2167/156230 | loss: 1.2088 | ds_loss: 1.2126 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   2168/156230 | global iter:   2168/156230 | loss: 1.3672 | ds_loss: 1.3680 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.302 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2168/156230 | global iter:   2168/156230 | loss: 1.2867 | ds_loss: 1.2977 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.302 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2169/156230 | global iter:   2169/156230 | loss: 1.1799 | ds_loss: 1.1780 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   2170/156230 | global iter:   2170/156230 | loss: 1.1086 | ds_loss: 1.1037 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   2171/156230 | global iter:   2171/156230 | loss: 1.1128 | ds_loss: 1.1221 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   2172/156230 | global iter:   2172/156230 | loss: 1.1000 | ds_loss: 1.1096 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2172/156230 | global iter:   2172/156230 | loss: 1.1253 | ds_loss: 1.1284 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.353 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2173/156230 | global iter:   2173/156230 | loss: 1.1712 | ds_loss: 1.1711 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   2174/156230 | global iter:   2174/156230 | loss: 1.2437 | ds_loss: 1.2548 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   2175/156230 | global iter:   2175/156230 | loss: 1.2403 | ds_loss: 1.2469 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   2176/156230 | global iter:   2176/156230 | loss: 1.3509 | ds_loss: 1.3367 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.391 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2176/156230 | global iter:   2176/156230 | loss: 1.2515 | ds_loss: 1.2524 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.391 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2177/156230 | global iter:   2177/156230 | loss: 1.2014 | ds_loss: 1.2103 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   2178/156230 | global iter:   2178/156230 | loss: 1.1281 | ds_loss: 1.1175 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   2179/156230 | global iter:   2179/156230 | loss: 1.2910 | ds_loss: 1.2905 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   2180/156230 | global iter:   2180/156230 | loss: 1.2593 | ds_loss: 1.2551 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2180/156230 | global iter:   2180/156230 | loss: 1.2199 | ds_loss: 1.2184 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2181/156230 | global iter:   2181/156230 | loss: 0.9759 | ds_loss: 0.9962 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   2182/156230 | global iter:   2182/156230 | loss: 1.3572 | ds_loss: 1.3652 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   2183/156230 | global iter:   2183/156230 | loss: 1.3105 | ds_loss: 1.3173 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   2184/156230 | global iter:   2184/156230 | loss: 1.0656 | ds_loss: 1.0738 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.339 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2184/156230 | global iter:   2184/156230 | loss: 1.1773 | ds_loss: 1.1881 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.339 | step time: 1.348
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2185/156230 | global iter:   2185/156230 | loss: 1.3406 | ds_loss: 1.3354 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:   2186/156230 | global iter:   2186/156230 | loss: 1.0716 | ds_loss: 1.0855 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   2187/156230 | global iter:   2187/156230 | loss: 1.2124 | ds_loss: 1.2201 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   2188/156230 | global iter:   2188/156230 | loss: 1.0583 | ds_loss: 1.0601 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2188/156230 | global iter:   2188/156230 | loss: 1.1707 | ds_loss: 1.1753 | lr: 9.9953e-05 | scale: 16384.0000 | micro time: 1.345 | step time: 1.340
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2189/156230 | global iter:   2189/156230 | loss: 1.1335 | ds_loss: 1.1390 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   2190/156230 | global iter:   2190/156230 | loss: 1.2931 | ds_loss: 1.3135 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   2191/156230 | global iter:   2191/156230 | loss: 1.1564 | ds_loss: 1.1455 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   2192/156230 | global iter:   2192/156230 | loss: 1.2313 | ds_loss: 1.2288 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2192/156230 | global iter:   2192/156230 | loss: 1.2036 | ds_loss: 1.2067 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.362 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2193/156230 | global iter:   2193/156230 | loss: 1.2423 | ds_loss: 1.2382 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   2194/156230 | global iter:   2194/156230 | loss: 1.1428 | ds_loss: 1.1251 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   2195/156230 | global iter:   2195/156230 | loss: 1.1228 | ds_loss: 1.1267 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   2196/156230 | global iter:   2196/156230 | loss: 1.1883 | ds_loss: 1.2015 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.371 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2196/156230 | global iter:   2196/156230 | loss: 1.1740 | ds_loss: 1.1728 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.371 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2197/156230 | global iter:   2197/156230 | loss: 1.1385 | ds_loss: 1.1595 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   2198/156230 | global iter:   2198/156230 | loss: 1.4044 | ds_loss: 1.3995 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   2199/156230 | global iter:   2199/156230 | loss: 1.0271 | ds_loss: 1.0211 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   2200/156230 | global iter:   2200/156230 | loss: 1.3367 | ds_loss: 1.3375 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.454 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2200/156230 | global iter:   2200/156230 | loss: 1.2267 | ds_loss: 1.2294 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.454 | step time: 1.395
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2201/156230 | global iter:   2201/156230 | loss: 1.1875 | ds_loss: 1.1894 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   2202/156230 | global iter:   2202/156230 | loss: 1.2602 | ds_loss: 1.2622 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.414 | step time: 0.000
train | epoch   0 | Iter:   2203/156230 | global iter:   2203/156230 | loss: 1.0952 | ds_loss: 1.1157 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   2204/156230 | global iter:   2204/156230 | loss: 1.2065 | ds_loss: 1.2076 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2204/156230 | global iter:   2204/156230 | loss: 1.1873 | ds_loss: 1.1937 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2205/156230 | global iter:   2205/156230 | loss: 1.0807 | ds_loss: 1.0835 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.320 | step time: 0.000
train | epoch   0 | Iter:   2206/156230 | global iter:   2206/156230 | loss: 1.1598 | ds_loss: 1.1611 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   2207/156230 | global iter:   2207/156230 | loss: 1.3178 | ds_loss: 1.3143 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   2208/156230 | global iter:   2208/156230 | loss: 1.1780 | ds_loss: 1.1717 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2208/156230 | global iter:   2208/156230 | loss: 1.1841 | ds_loss: 1.1826 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2209/156230 | global iter:   2209/156230 | loss: 1.1244 | ds_loss: 1.1037 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.405 | step time: 0.000
train | epoch   0 | Iter:   2210/156230 | global iter:   2210/156230 | loss: 1.1912 | ds_loss: 1.1938 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   2211/156230 | global iter:   2211/156230 | loss: 1.1082 | ds_loss: 1.1043 | lr: 9.9952e-05 | scale: 16384.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   2212/156230 | global iter:   2212/156230 | loss: 1.0976 | ds_loss: 1.1170 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.372 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2212/156230 | global iter:   2212/156230 | loss: 1.1304 | ds_loss: 1.1297 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.372 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2213/156230 | global iter:   2213/156230 | loss: 1.1234 | ds_loss: 1.1382 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   2214/156230 | global iter:   2214/156230 | loss: 1.0651 | ds_loss: 1.0581 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   2215/156230 | global iter:   2215/156230 | loss: 1.0132 | ds_loss: 1.0159 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   2216/156230 | global iter:   2216/156230 | loss: 1.0157 | ds_loss: 1.0220 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.367 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2216/156230 | global iter:   2216/156230 | loss: 1.0543 | ds_loss: 1.0586 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.367 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2217/156230 | global iter:   2217/156230 | loss: 1.1357 | ds_loss: 1.1317 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   2218/156230 | global iter:   2218/156230 | loss: 1.2797 | ds_loss: 1.2747 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   2219/156230 | global iter:   2219/156230 | loss: 1.2193 | ds_loss: 1.2149 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   2220/156230 | global iter:   2220/156230 | loss: 1.2328 | ds_loss: 1.2350 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.379 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2220/156230 | global iter:   2220/156230 | loss: 1.2169 | ds_loss: 1.2141 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.379 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2221/156230 | global iter:   2221/156230 | loss: 0.9738 | ds_loss: 0.9720 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.422 | step time: 0.000
train | epoch   0 | Iter:   2222/156230 | global iter:   2222/156230 | loss: 1.3572 | ds_loss: 1.3545 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   2223/156230 | global iter:   2223/156230 | loss: 1.1911 | ds_loss: 1.2006 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   2224/156230 | global iter:   2224/156230 | loss: 1.2472 | ds_loss: 1.2584 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.389 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2224/156230 | global iter:   2224/156230 | loss: 1.1923 | ds_loss: 1.1964 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.389 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2225/156230 | global iter:   2225/156230 | loss: 1.0781 | ds_loss: 1.0674 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   2226/156230 | global iter:   2226/156230 | loss: 1.1930 | ds_loss: 1.1872 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   2227/156230 | global iter:   2227/156230 | loss: 1.0724 | ds_loss: 1.0588 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.304 | step time: 0.000
train | epoch   0 | Iter:   2228/156230 | global iter:   2228/156230 | loss: 1.2344 | ds_loss: 1.2538 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.372 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2228/156230 | global iter:   2228/156230 | loss: 1.1445 | ds_loss: 1.1418 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.372 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2229/156230 | global iter:   2229/156230 | loss: 1.0753 | ds_loss: 1.0774 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   2230/156230 | global iter:   2230/156230 | loss: 1.2040 | ds_loss: 1.2163 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   2231/156230 | global iter:   2231/156230 | loss: 1.0894 | ds_loss: 1.0875 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   2232/156230 | global iter:   2232/156230 | loss: 1.1718 | ds_loss: 1.1660 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.382 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2232/156230 | global iter:   2232/156230 | loss: 1.1351 | ds_loss: 1.1368 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.382 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2233/156230 | global iter:   2233/156230 | loss: 1.2207 | ds_loss: 1.2307 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   2234/156230 | global iter:   2234/156230 | loss: 1.2784 | ds_loss: 1.2640 | lr: 9.9951e-05 | scale: 16384.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   2235/156230 | global iter:   2235/156230 | loss: 1.1296 | ds_loss: 1.1371 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   2236/156230 | global iter:   2236/156230 | loss: 1.1123 | ds_loss: 1.0938 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.367 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2236/156230 | global iter:   2236/156230 | loss: 1.1853 | ds_loss: 1.1814 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.367 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2237/156230 | global iter:   2237/156230 | loss: 1.0490 | ds_loss: 1.0464 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   2238/156230 | global iter:   2238/156230 | loss: 1.2277 | ds_loss: 1.2447 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   2239/156230 | global iter:   2239/156230 | loss: 1.2602 | ds_loss: 1.2767 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   2240/156230 | global iter:   2240/156230 | loss: 1.1534 | ds_loss: 1.1708 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2240/156230 | global iter:   2240/156230 | loss: 1.1726 | ds_loss: 1.1847 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.363 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2241/156230 | global iter:   2241/156230 | loss: 1.2086 | ds_loss: 1.2278 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   2242/156230 | global iter:   2242/156230 | loss: 1.2734 | ds_loss: 1.2643 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   2243/156230 | global iter:   2243/156230 | loss: 1.3442 | ds_loss: 1.3473 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   2244/156230 | global iter:   2244/156230 | loss: 1.1302 | ds_loss: 1.1250 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2244/156230 | global iter:   2244/156230 | loss: 1.2391 | ds_loss: 1.2411 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2245/156230 | global iter:   2245/156230 | loss: 1.1180 | ds_loss: 1.1258 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   2246/156230 | global iter:   2246/156230 | loss: 1.2294 | ds_loss: 1.2325 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   2247/156230 | global iter:   2247/156230 | loss: 1.1396 | ds_loss: 1.1328 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   2248/156230 | global iter:   2248/156230 | loss: 1.1838 | ds_loss: 1.1846 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.384 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2248/156230 | global iter:   2248/156230 | loss: 1.1677 | ds_loss: 1.1689 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.384 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2249/156230 | global iter:   2249/156230 | loss: 1.0644 | ds_loss: 1.0583 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   2250/156230 | global iter:   2250/156230 | loss: 1.0456 | ds_loss: 1.0508 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   2251/156230 | global iter:   2251/156230 | loss: 1.1015 | ds_loss: 1.1177 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   2252/156230 | global iter:   2252/156230 | loss: 1.0704 | ds_loss: 1.0820 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2252/156230 | global iter:   2252/156230 | loss: 1.0705 | ds_loss: 1.0772 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.351 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2253/156230 | global iter:   2253/156230 | loss: 1.0967 | ds_loss: 1.1157 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:   2254/156230 | global iter:   2254/156230 | loss: 1.1965 | ds_loss: 1.1864 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   2255/156230 | global iter:   2255/156230 | loss: 1.3397 | ds_loss: 1.3630 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   2256/156230 | global iter:   2256/156230 | loss: 1.1063 | ds_loss: 1.1188 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.372 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2256/156230 | global iter:   2256/156230 | loss: 1.1848 | ds_loss: 1.1960 | lr: 9.9950e-05 | scale: 16384.0000 | micro time: 1.372 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2257/156230 | global iter:   2257/156230 | loss: 1.0682 | ds_loss: 1.0729 | lr: 9.9949e-05 | scale: 16384.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   2258/156230 | global iter:   2258/156230 | loss: 0.9870 | ds_loss: 0.9919 | lr: 9.9949e-05 | scale: 16384.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   2259/156230 | global iter:   2259/156230 | loss: 1.2937 | ds_loss: 1.3102 | lr: 9.9949e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   2260/156230 | global iter:   2260/156230 | loss: 1.2337 | ds_loss: 1.2470 | lr: 9.9949e-05 | scale: 16384.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2260/156230 | global iter:   2260/156230 | loss: 1.1457 | ds_loss: 1.1555 | lr: 9.9949e-05 | scale: 16384.0000 | micro time: 1.355 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2261/156230 | global iter:   2261/156230 | loss: 1.1291 | ds_loss: 1.1307 | lr: 9.9949e-05 | scale: 16384.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   2262/156230 | global iter:   2262/156230 | loss: 1.1333 | ds_loss: 1.1390 | lr: 9.9949e-05 | scale: 16384.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   2263/156230 | global iter:   2263/156230 | loss: 1.2439 | ds_loss: 1.2511 | lr: 9.9949e-05 | scale: 16384.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   2264/156230 | global iter:   2264/156230 | loss: 1.2081 | ds_loss: 1.2163 | lr: 9.9949e-05 | scale: 16384.0000 | micro time: 1.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2264/156230 | global iter:   2264/156230 | loss: 1.1786 | ds_loss: 1.1843 | lr: 9.9949e-05 | scale: 16384.0000 | micro time: 1.398 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2265/156230 | global iter:   2265/156230 | loss: 1.2446 | ds_loss: 1.2589 | lr: 9.9949e-05 | scale: 16384.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   2266/156230 | global iter:   2266/156230 | loss: 1.3821 | ds_loss: 1.3944 | lr: 9.9949e-05 | scale: 16384.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   2267/156230 | global iter:   2267/156230 | loss: 1.3567 | ds_loss: 1.3540 | lr: 9.9949e-05 | scale: 16384.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   2268/156230 | global iter:   2268/156230 | loss: 1.1406 | ds_loss: 1.1475 | lr: 9.9949e-05 | scale: 16384.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2268/156230 | global iter:   2268/156230 | loss: 1.2810 | ds_loss: 1.2887 | lr: 9.9949e-05 | scale: 16384.0000 | micro time: 1.385 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2269/156230 | global iter:   2269/156230 | loss: 1.1305 | ds_loss: 1.1211 | lr: 9.9949e-05 | scale: 16384.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   2270/156230 | global iter:   2270/156230 | loss: 1.2133 | ds_loss: 1.2084 | lr: 9.9949e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   2271/156230 | global iter:   2271/156230 | loss: 1.1072 | ds_loss: 1.1204 | lr: 9.9949e-05 | scale: 16384.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   2272/156230 | global iter:   2272/156230 | loss: 1.1666 | ds_loss: 1.1557 | lr: 9.9949e-05 | scale: 16384.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2272/156230 | global iter:   2272/156230 | loss: 1.1544 | ds_loss: 1.1514 | lr: 9.9949e-05 | scale: 16384.0000 | micro time: 1.362 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2273/156230 | global iter:   2273/156230 | loss: 0.9191 | ds_loss: 0.9358 | lr: 9.9949e-05 | scale: 16384.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   2274/156230 | global iter:   2274/156230 | loss: 1.3052 | ds_loss: 1.2935 | lr: 9.9949e-05 | scale: 16384.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   2275/156230 | global iter:   2275/156230 | loss: 1.1604 | ds_loss: 1.1753 | lr: 9.9949e-05 | scale: 16384.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   2276/156230 | global iter:   2276/156230 | loss: 0.9973 | ds_loss: 1.0058 | lr: 9.9949e-05 | scale: 16384.0000 | micro time: 1.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2276/156230 | global iter:   2276/156230 | loss: 1.0955 | ds_loss: 1.1026 | lr: 9.9949e-05 | scale: 16384.0000 | micro time: 1.400 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2277/156230 | global iter:   2277/156230 | loss: 1.2067 | ds_loss: 1.2008 | lr: 9.9949e-05 | scale: 16384.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   2278/156230 | global iter:   2278/156230 | loss: 1.2122 | ds_loss: 1.2125 | lr: 9.9949e-05 | scale: 16384.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   2279/156230 | global iter:   2279/156230 | loss: 1.1915 | ds_loss: 1.1801 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   2280/156230 | global iter:   2280/156230 | loss: 1.1998 | ds_loss: 1.2085 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2280/156230 | global iter:   2280/156230 | loss: 1.2025 | ds_loss: 1.2005 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.394 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2281/156230 | global iter:   2281/156230 | loss: 1.2828 | ds_loss: 1.2940 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   2282/156230 | global iter:   2282/156230 | loss: 1.1494 | ds_loss: 1.1615 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   2283/156230 | global iter:   2283/156230 | loss: 1.2439 | ds_loss: 1.2487 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   2284/156230 | global iter:   2284/156230 | loss: 1.2700 | ds_loss: 1.2745 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2284/156230 | global iter:   2284/156230 | loss: 1.2365 | ds_loss: 1.2447 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.376 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2285/156230 | global iter:   2285/156230 | loss: 1.2930 | ds_loss: 1.2904 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   2286/156230 | global iter:   2286/156230 | loss: 1.2054 | ds_loss: 1.2207 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   2287/156230 | global iter:   2287/156230 | loss: 1.0979 | ds_loss: 1.1003 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   2288/156230 | global iter:   2288/156230 | loss: 1.3055 | ds_loss: 1.3158 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2288/156230 | global iter:   2288/156230 | loss: 1.2255 | ds_loss: 1.2318 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2289/156230 | global iter:   2289/156230 | loss: 1.1282 | ds_loss: 1.1363 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   2290/156230 | global iter:   2290/156230 | loss: 1.0271 | ds_loss: 1.0409 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   2291/156230 | global iter:   2291/156230 | loss: 1.2723 | ds_loss: 1.2792 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   2292/156230 | global iter:   2292/156230 | loss: 1.1754 | ds_loss: 1.1756 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.389 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2292/156230 | global iter:   2292/156230 | loss: 1.1507 | ds_loss: 1.1580 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.389 | step time: 1.385
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2293/156230 | global iter:   2293/156230 | loss: 1.1446 | ds_loss: 1.1514 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   2294/156230 | global iter:   2294/156230 | loss: 0.9989 | ds_loss: 1.0074 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   2295/156230 | global iter:   2295/156230 | loss: 1.1276 | ds_loss: 1.1444 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   2296/156230 | global iter:   2296/156230 | loss: 0.8905 | ds_loss: 0.9057 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2296/156230 | global iter:   2296/156230 | loss: 1.0404 | ds_loss: 1.0522 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.370 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2297/156230 | global iter:   2297/156230 | loss: 1.1728 | ds_loss: 1.1725 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   2298/156230 | global iter:   2298/156230 | loss: 1.1419 | ds_loss: 1.1450 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   2299/156230 | global iter:   2299/156230 | loss: 1.1412 | ds_loss: 1.1428 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:   2300/156230 | global iter:   2300/156230 | loss: 1.0152 | ds_loss: 1.0148 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.325 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2300/156230 | global iter:   2300/156230 | loss: 1.1178 | ds_loss: 1.1188 | lr: 9.9948e-05 | scale: 16384.0000 | micro time: 1.325 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2301/156230 | global iter:   2301/156230 | loss: 1.2172 | ds_loss: 1.2166 | lr: 9.9947e-05 | scale: 16384.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   2302/156230 | global iter:   2302/156230 | loss: 1.2861 | ds_loss: 1.2843 | lr: 9.9947e-05 | scale: 16384.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   2303/156230 | global iter:   2303/156230 | loss: 1.3414 | ds_loss: 1.3264 | lr: 9.9947e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   2304/156230 | global iter:   2304/156230 | loss: 1.2704 | ds_loss: 1.2721 | lr: 9.9947e-05 | scale: 16384.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2304/156230 | global iter:   2304/156230 | loss: 1.2788 | ds_loss: 1.2748 | lr: 9.9947e-05 | scale: 16384.0000 | micro time: 1.362 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2305/156230 | global iter:   2305/156230 | loss: 1.2349 | ds_loss: 1.2209 | lr: 9.9947e-05 | scale: 16384.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   2306/156230 | global iter:   2306/156230 | loss: 1.0660 | ds_loss: 1.0856 | lr: 9.9947e-05 | scale: 16384.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   2307/156230 | global iter:   2307/156230 | loss: 1.3050 | ds_loss: 1.3011 | lr: 9.9947e-05 | scale: 16384.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   2308/156230 | global iter:   2308/156230 | loss: 1.2374 | ds_loss: 1.2455 | lr: 9.9947e-05 | scale: 16384.0000 | micro time: 1.348 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2308/156230 | global iter:   2308/156230 | loss: 1.2108 | ds_loss: 1.2133 | lr: 9.9947e-05 | scale: 16384.0000 | micro time: 1.348 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2309/156230 | global iter:   2309/156230 | loss: 1.1740 | ds_loss: 1.1667 | lr: 9.9947e-05 | scale: 16384.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   2310/156230 | global iter:   2310/156230 | loss: 1.1854 | ds_loss: 1.1799 | lr: 9.9947e-05 | scale: 16384.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   2311/156230 | global iter:   2311/156230 | loss: 1.2908 | ds_loss: 1.2869 | lr: 9.9947e-05 | scale: 16384.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   2312/156230 | global iter:   2312/156230 | loss: 1.2025 | ds_loss: 1.1991 | lr: 9.9947e-05 | scale: 16384.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2312/156230 | global iter:   2312/156230 | loss: 1.2132 | ds_loss: 1.2081 | lr: 9.9947e-05 | scale: 16384.0000 | micro time: 1.378 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2313/156230 | global iter:   2313/156230 | loss: 1.1454 | ds_loss: 1.1424 | lr: 9.9947e-05 | scale: 16384.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   2314/156230 | global iter:   2314/156230 | loss: 1.2057 | ds_loss: 1.2212 | lr: 9.9947e-05 | scale: 16384.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   2315/156230 | global iter:   2315/156230 | loss: 1.0911 | ds_loss: 1.0980 | lr: 9.9947e-05 | scale: 16384.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   2316/156230 | global iter:   2316/156230 | loss: 1.1375 | ds_loss: 1.1534 | lr: 9.9947e-05 | scale: 16384.0000 | micro time: 1.418 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2316/156230 | global iter:   2316/156230 | loss: 1.1449 | ds_loss: 1.1538 | lr: 9.9947e-05 | scale: 16384.0000 | micro time: 1.418 | step time: 1.379
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2317/156230 | global iter:   2317/156230 | loss: 1.1791 | ds_loss: 1.1659 | lr: 9.9947e-05 | scale: 16384.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   2318/156230 | global iter:   2318/156230 | loss: 1.1056 | ds_loss: 1.0975 | lr: 9.9947e-05 | scale: 16384.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   2319/156230 | global iter:   2319/156230 | loss: 1.2222 | ds_loss: 1.2191 | lr: 9.9947e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   2320/156230 | global iter:   2320/156230 | loss: 1.2575 | ds_loss: 1.2519 | lr: 9.9947e-05 | scale: 16384.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2320/156230 | global iter:   2320/156230 | loss: 1.1911 | ds_loss: 1.1836 | lr: 9.9947e-05 | scale: 16384.0000 | micro time: 1.385 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2321/156230 | global iter:   2321/156230 | loss: 1.1052 | ds_loss: 1.1318 | lr: 9.9947e-05 | scale: 16384.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   2322/156230 | global iter:   2322/156230 | loss: 1.1686 | ds_loss: 1.1634 | lr: 9.9946e-05 | scale: 16384.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   2323/156230 | global iter:   2323/156230 | loss: 1.2742 | ds_loss: 1.2716 | lr: 9.9946e-05 | scale: 16384.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   2324/156230 | global iter:   2324/156230 | loss: 1.1533 | ds_loss: 1.1607 | lr: 9.9946e-05 | scale: 16384.0000 | micro time: 1.356 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2324/156230 | global iter:   2324/156230 | loss: 1.1753 | ds_loss: 1.1819 | lr: 9.9946e-05 | scale: 16384.0000 | micro time: 1.356 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2325/156230 | global iter:   2325/156230 | loss: 1.3526 | ds_loss: 1.3647 | lr: 9.9946e-05 | scale: 16384.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   2326/156230 | global iter:   2326/156230 | loss: 1.1574 | ds_loss: 1.1771 | lr: 9.9946e-05 | scale: 16384.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   2327/156230 | global iter:   2327/156230 | loss: 1.2957 | ds_loss: 1.2983 | lr: 9.9946e-05 | scale: 16384.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   2328/156230 | global iter:   2328/156230 | loss: 1.0224 | ds_loss: 1.0282 | lr: 9.9946e-05 | scale: 16384.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2328/156230 | global iter:   2328/156230 | loss: 1.2071 | ds_loss: 1.2171 | lr: 9.9946e-05 | scale: 16384.0000 | micro time: 1.347 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2329/156230 | global iter:   2329/156230 | loss: 1.2139 | ds_loss: 1.2257 | lr: 9.9946e-05 | scale: 16384.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   2330/156230 | global iter:   2330/156230 | loss: 1.2228 | ds_loss: 1.2291 | lr: 9.9946e-05 | scale: 16384.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   2331/156230 | global iter:   2331/156230 | loss: 1.2575 | ds_loss: 1.2616 | lr: 9.9946e-05 | scale: 16384.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   2332/156230 | global iter:   2332/156230 | loss: 1.0669 | ds_loss: 1.0700 | lr: 9.9946e-05 | scale: 16384.0000 | micro time: 1.367 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2332/156230 | global iter:   2332/156230 | loss: 1.1903 | ds_loss: 1.1966 | lr: 9.9946e-05 | scale: 16384.0000 | micro time: 1.367 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2333/156230 | global iter:   2333/156230 | loss: 1.1031 | ds_loss: 1.0969 | lr: 9.9946e-05 | scale: 16384.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   2334/156230 | global iter:   2334/156230 | loss: 0.9713 | ds_loss: 0.9511 | lr: 9.9946e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   2335/156230 | global iter:   2335/156230 | loss: 1.1993 | ds_loss: 1.1987 | lr: 9.9946e-05 | scale: 16384.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   2336/156230 | global iter:   2336/156230 | loss: 1.1988 | ds_loss: 1.2054 | lr: 9.9946e-05 | scale: 16384.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2336/156230 | global iter:   2336/156230 | loss: 1.1181 | ds_loss: 1.1130 | lr: 9.9946e-05 | scale: 16384.0000 | micro time: 1.381 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2337/156230 | global iter:   2337/156230 | loss: 0.9896 | ds_loss: 0.9820 | lr: 9.9946e-05 | scale: 16384.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   2338/156230 | global iter:   2338/156230 | loss: 1.1289 | ds_loss: 1.1243 | lr: 9.9946e-05 | scale: 16384.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   2339/156230 | global iter:   2339/156230 | loss: 1.1516 | ds_loss: 1.1642 | lr: 9.9946e-05 | scale: 16384.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   2340/156230 | global iter:   2340/156230 | loss: 1.1026 | ds_loss: 1.0888 | lr: 9.9946e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2340/156230 | global iter:   2340/156230 | loss: 1.0932 | ds_loss: 1.0898 | lr: 9.9946e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2341/156230 | global iter:   2341/156230 | loss: 1.1576 | ds_loss: 1.1574 | lr: 9.9946e-05 | scale: 16384.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   2342/156230 | global iter:   2342/156230 | loss: 1.3111 | ds_loss: 1.3067 | lr: 9.9946e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   2343/156230 | global iter:   2343/156230 | loss: 1.2183 | ds_loss: 1.2044 | lr: 9.9946e-05 | scale: 16384.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   2344/156230 | global iter:   2344/156230 | loss: 1.0801 | ds_loss: 1.0880 | lr: 9.9945e-05 | scale: 16384.0000 | micro time: 1.336 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2344/156230 | global iter:   2344/156230 | loss: 1.1918 | ds_loss: 1.1891 | lr: 9.9945e-05 | scale: 16384.0000 | micro time: 1.336 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2345/156230 | global iter:   2345/156230 | loss: 1.3063 | ds_loss: 1.3150 | lr: 9.9945e-05 | scale: 16384.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   2346/156230 | global iter:   2346/156230 | loss: 1.1603 | ds_loss: 1.1545 | lr: 9.9945e-05 | scale: 16384.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   2347/156230 | global iter:   2347/156230 | loss: 1.1254 | ds_loss: 1.1311 | lr: 9.9945e-05 | scale: 16384.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   2348/156230 | global iter:   2348/156230 | loss: 1.2110 | ds_loss: 1.2260 | lr: 9.9945e-05 | scale: 16384.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2348/156230 | global iter:   2348/156230 | loss: 1.2008 | ds_loss: 1.2067 | lr: 9.9945e-05 | scale: 16384.0000 | micro time: 1.377 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2349/156230 | global iter:   2349/156230 | loss: 1.2199 | ds_loss: 1.2180 | lr: 9.9945e-05 | scale: 16384.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   2350/156230 | global iter:   2350/156230 | loss: 1.0858 | ds_loss: 1.0826 | lr: 9.9945e-05 | scale: 16384.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   2351/156230 | global iter:   2351/156230 | loss: 1.0670 | ds_loss: 1.0841 | lr: 9.9945e-05 | scale: 16384.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   2352/156230 | global iter:   2352/156230 | loss: 1.1512 | ds_loss: 1.1551 | lr: 9.9945e-05 | scale: 16384.0000 | micro time: 1.367 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2352/156230 | global iter:   2352/156230 | loss: 1.1310 | ds_loss: 1.1350 | lr: 9.9945e-05 | scale: 16384.0000 | micro time: 1.367 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2353/156230 | global iter:   2353/156230 | loss: 1.0329 | ds_loss: 1.0389 | lr: 9.9945e-05 | scale: 16384.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:   2354/156230 | global iter:   2354/156230 | loss: 1.1202 | ds_loss: 1.1096 | lr: 9.9945e-05 | scale: 16384.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   2355/156230 | global iter:   2355/156230 | loss: 1.2975 | ds_loss: 1.3075 | lr: 9.9945e-05 | scale: 16384.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   2356/156230 | global iter:   2356/156230 | loss: 1.1525 | ds_loss: 1.1582 | lr: 9.9945e-05 | scale: 16384.0000 | micro time: 1.379 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2356/156230 | global iter:   2356/156230 | loss: 1.1507 | ds_loss: 1.1535 | lr: 9.9945e-05 | scale: 16384.0000 | micro time: 1.379 | step time: 1.379
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2357/156230 | global iter:   2357/156230 | loss: 1.3945 | ds_loss: 1.3840 | lr: 9.9945e-05 | scale: 16384.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   2358/156230 | global iter:   2358/156230 | loss: 1.1337 | ds_loss: 1.1420 | lr: 9.9945e-05 | scale: 16384.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   2359/156230 | global iter:   2359/156230 | loss: 0.9980 | ds_loss: 1.0036 | lr: 9.9945e-05 | scale: 16384.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   2360/156230 | global iter:   2360/156230 | loss: 1.1545 | ds_loss: 1.1572 | lr: 9.9945e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2360/156230 | global iter:   2360/156230 | loss: 1.1702 | ds_loss: 1.1717 | lr: 9.9945e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2361/156230 | global iter:   2361/156230 | loss: 1.2146 | ds_loss: 1.2375 | lr: 9.9945e-05 | scale: 16384.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   2362/156230 | global iter:   2362/156230 | loss: 1.1169 | ds_loss: 1.1146 | lr: 9.9945e-05 | scale: 16384.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   2363/156230 | global iter:   2363/156230 | loss: 0.9904 | ds_loss: 0.9938 | lr: 9.9945e-05 | scale: 16384.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   2364/156230 | global iter:   2364/156230 | loss: 1.1381 | ds_loss: 1.1465 | lr: 9.9945e-05 | scale: 16384.0000 | micro time: 1.382 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2364/156230 | global iter:   2364/156230 | loss: 1.1150 | ds_loss: 1.1231 | lr: 9.9945e-05 | scale: 16384.0000 | micro time: 1.382 | step time: 1.347
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2365/156230 | global iter:   2365/156230 | loss: 0.9731 | ds_loss: 0.9890 | lr: 9.9944e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   2366/156230 | global iter:   2366/156230 | loss: 1.1904 | ds_loss: 1.1870 | lr: 9.9944e-05 | scale: 16384.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   2367/156230 | global iter:   2367/156230 | loss: 1.2490 | ds_loss: 1.2484 | lr: 9.9944e-05 | scale: 16384.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   2368/156230 | global iter:   2368/156230 | loss: 1.2144 | ds_loss: 1.2092 | lr: 9.9944e-05 | scale: 16384.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2368/156230 | global iter:   2368/156230 | loss: 1.1567 | ds_loss: 1.1584 | lr: 9.9944e-05 | scale: 16384.0000 | micro time: 1.377 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2369/156230 | global iter:   2369/156230 | loss: 1.1531 | ds_loss: 1.1437 | lr: 9.9944e-05 | scale: 16384.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   2370/156230 | global iter:   2370/156230 | loss: 1.1682 | ds_loss: 1.1741 | lr: 9.9944e-05 | scale: 16384.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   2371/156230 | global iter:   2371/156230 | loss: 1.2227 | ds_loss: 1.2183 | lr: 9.9944e-05 | scale: 16384.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   2372/156230 | global iter:   2372/156230 | loss: 1.2657 | ds_loss: 1.2643 | lr: 9.9944e-05 | scale: 16384.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2372/156230 | global iter:   2372/156230 | loss: 1.2024 | ds_loss: 1.2001 | lr: 9.9944e-05 | scale: 16384.0000 | micro time: 1.377 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2373/156230 | global iter:   2373/156230 | loss: 1.0572 | ds_loss: 1.0637 | lr: 9.9944e-05 | scale: 16384.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   2374/156230 | global iter:   2374/156230 | loss: 1.3290 | ds_loss: 1.3270 | lr: 9.9944e-05 | scale: 16384.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:   2375/156230 | global iter:   2375/156230 | loss: 0.9596 | ds_loss: 0.9838 | lr: 9.9944e-05 | scale: 16384.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   2376/156230 | global iter:   2376/156230 | loss: 1.1883 | ds_loss: 1.1972 | lr: 9.9944e-05 | scale: 16384.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2376/156230 | global iter:   2376/156230 | loss: 1.1335 | ds_loss: 1.1429 | lr: 9.9944e-05 | scale: 16384.0000 | micro time: 1.377 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2377/156230 | global iter:   2377/156230 | loss: 1.0774 | ds_loss: 1.0873 | lr: 9.9944e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   2378/156230 | global iter:   2378/156230 | loss: 1.0647 | ds_loss: 1.0847 | lr: 9.9944e-05 | scale: 16384.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   2379/156230 | global iter:   2379/156230 | loss: 1.2060 | ds_loss: 1.2125 | lr: 9.9944e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   2380/156230 | global iter:   2380/156230 | loss: 1.1155 | ds_loss: 1.1256 | lr: 9.9944e-05 | scale: 16384.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2380/156230 | global iter:   2380/156230 | loss: 1.1159 | ds_loss: 1.1275 | lr: 9.9944e-05 | scale: 16384.0000 | micro time: 1.355 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2381/156230 | global iter:   2381/156230 | loss: 1.0622 | ds_loss: 1.0695 | lr: 9.9944e-05 | scale: 16384.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   2382/156230 | global iter:   2382/156230 | loss: 0.8828 | ds_loss: 0.8956 | lr: 9.9944e-05 | scale: 16384.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   2383/156230 | global iter:   2383/156230 | loss: 1.0394 | ds_loss: 1.0362 | lr: 9.9944e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   2384/156230 | global iter:   2384/156230 | loss: 1.2016 | ds_loss: 1.2021 | lr: 9.9944e-05 | scale: 16384.0000 | micro time: 1.375 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2384/156230 | global iter:   2384/156230 | loss: 1.0465 | ds_loss: 1.0508 | lr: 9.9944e-05 | scale: 16384.0000 | micro time: 1.375 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2385/156230 | global iter:   2385/156230 | loss: 1.1519 | ds_loss: 1.1575 | lr: 9.9944e-05 | scale: 16384.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   2386/156230 | global iter:   2386/156230 | loss: 1.1284 | ds_loss: 1.1436 | lr: 9.9943e-05 | scale: 16384.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   2387/156230 | global iter:   2387/156230 | loss: 1.2954 | ds_loss: 1.2870 | lr: 9.9943e-05 | scale: 16384.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   2388/156230 | global iter:   2388/156230 | loss: 1.0824 | ds_loss: 1.0922 | lr: 9.9943e-05 | scale: 16384.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2388/156230 | global iter:   2388/156230 | loss: 1.1645 | ds_loss: 1.1701 | lr: 9.9943e-05 | scale: 16384.0000 | micro time: 1.360 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2389/156230 | global iter:   2389/156230 | loss: 1.0836 | ds_loss: 1.0825 | lr: 9.9943e-05 | scale: 16384.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   2390/156230 | global iter:   2390/156230 | loss: 1.0689 | ds_loss: 1.0669 | lr: 9.9943e-05 | scale: 16384.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   2391/156230 | global iter:   2391/156230 | loss: 1.0997 | ds_loss: 1.0961 | lr: 9.9943e-05 | scale: 16384.0000 | micro time: 1.401 | step time: 0.000
train | epoch   0 | Iter:   2392/156230 | global iter:   2392/156230 | loss: 1.0626 | ds_loss: 1.0625 | lr: 9.9943e-05 | scale: 16384.0000 | micro time: 1.331 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2392/156230 | global iter:   2392/156230 | loss: 1.0787 | ds_loss: 1.0770 | lr: 9.9943e-05 | scale: 16384.0000 | micro time: 1.331 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2393/156230 | global iter:   2393/156230 | loss: 1.1299 | ds_loss: 1.1255 | lr: 9.9943e-05 | scale: 16384.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   2394/156230 | global iter:   2394/156230 | loss: 1.2143 | ds_loss: 1.2277 | lr: 9.9943e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   2395/156230 | global iter:   2395/156230 | loss: 1.0990 | ds_loss: 1.1054 | lr: 9.9943e-05 | scale: 16384.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   2396/156230 | global iter:   2396/156230 | loss: 1.0956 | ds_loss: 1.0967 | lr: 9.9943e-05 | scale: 16384.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2396/156230 | global iter:   2396/156230 | loss: 1.1347 | ds_loss: 1.1389 | lr: 9.9943e-05 | scale: 16384.0000 | micro time: 1.347 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2397/156230 | global iter:   2397/156230 | loss: 1.3206 | ds_loss: 1.3206 | lr: 9.9943e-05 | scale: 16384.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   2398/156230 | global iter:   2398/156230 | loss: 1.2361 | ds_loss: 1.2399 | lr: 9.9943e-05 | scale: 16384.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   2399/156230 | global iter:   2399/156230 | loss: 1.2151 | ds_loss: 1.2137 | lr: 9.9943e-05 | scale: 16384.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   2400/156230 | global iter:   2400/156230 | loss: 1.3767 | ds_loss: 1.3578 | lr: 9.9943e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2400/156230 | global iter:   2400/156230 | loss: 1.2871 | ds_loss: 1.2830 | lr: 9.9943e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 1.344
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2401/156230 | global iter:   2401/156230 | loss: 1.2122 | ds_loss: 1.2272 | lr: 9.9943e-05 | scale: 16384.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   2402/156230 | global iter:   2402/156230 | loss: 1.1801 | ds_loss: 1.1774 | lr: 9.9943e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   2403/156230 | global iter:   2403/156230 | loss: 0.9856 | ds_loss: 0.9944 | lr: 9.9943e-05 | scale: 16384.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   2404/156230 | global iter:   2404/156230 | loss: 0.9233 | ds_loss: 0.9318 | lr: 9.9943e-05 | scale: 16384.0000 | micro time: 1.341 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2404/156230 | global iter:   2404/156230 | loss: 1.0753 | ds_loss: 1.0827 | lr: 9.9943e-05 | scale: 16384.0000 | micro time: 1.341 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2405/156230 | global iter:   2405/156230 | loss: 1.1886 | ds_loss: 1.1937 | lr: 9.9943e-05 | scale: 16384.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   2406/156230 | global iter:   2406/156230 | loss: 1.2959 | ds_loss: 1.2850 | lr: 9.9943e-05 | scale: 16384.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   2407/156230 | global iter:   2407/156230 | loss: 1.2259 | ds_loss: 1.2396 | lr: 9.9942e-05 | scale: 16384.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   2408/156230 | global iter:   2408/156230 | loss: 0.9111 | ds_loss: 0.9131 | lr: 9.9942e-05 | scale: 16384.0000 | micro time: 1.380 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2408/156230 | global iter:   2408/156230 | loss: 1.1554 | ds_loss: 1.1578 | lr: 9.9942e-05 | scale: 16384.0000 | micro time: 1.380 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2409/156230 | global iter:   2409/156230 | loss: 1.1368 | ds_loss: 1.1427 | lr: 9.9942e-05 | scale: 16384.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   2410/156230 | global iter:   2410/156230 | loss: 1.1712 | ds_loss: 1.1728 | lr: 9.9942e-05 | scale: 16384.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   2411/156230 | global iter:   2411/156230 | loss: 1.2541 | ds_loss: 1.2386 | lr: 9.9942e-05 | scale: 16384.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   2412/156230 | global iter:   2412/156230 | loss: 1.2712 | ds_loss: 1.2644 | lr: 9.9942e-05 | scale: 16384.0000 | micro time: 1.343 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2412/156230 | global iter:   2412/156230 | loss: 1.2083 | ds_loss: 1.2046 | lr: 9.9942e-05 | scale: 16384.0000 | micro time: 1.343 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2413/156230 | global iter:   2413/156230 | loss: 1.1321 | ds_loss: 1.1281 | lr: 9.9942e-05 | scale: 16384.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   2414/156230 | global iter:   2414/156230 | loss: 1.0757 | ds_loss: 1.0863 | lr: 9.9942e-05 | scale: 16384.0000 | micro time: 1.407 | step time: 0.000
train | epoch   0 | Iter:   2415/156230 | global iter:   2415/156230 | loss: 1.1649 | ds_loss: 1.1689 | lr: 9.9942e-05 | scale: 16384.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   2416/156230 | global iter:   2416/156230 | loss: 1.1857 | ds_loss: 1.1738 | lr: 9.9942e-05 | scale: 16384.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2416/156230 | global iter:   2416/156230 | loss: 1.1396 | ds_loss: 1.1393 | lr: 9.9942e-05 | scale: 16384.0000 | micro time: 1.368 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2417/156230 | global iter:   2417/156230 | loss: 0.9498 | ds_loss: 0.9518 | lr: 9.9942e-05 | scale: 16384.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   2418/156230 | global iter:   2418/156230 | loss: 1.0334 | ds_loss: 1.0428 | lr: 9.9942e-05 | scale: 16384.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   2419/156230 | global iter:   2419/156230 | loss: 1.1664 | ds_loss: 1.1688 | lr: 9.9942e-05 | scale: 16384.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   2420/156230 | global iter:   2420/156230 | loss: 1.1388 | ds_loss: 1.1349 | lr: 9.9942e-05 | scale: 16384.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2420/156230 | global iter:   2420/156230 | loss: 1.0721 | ds_loss: 1.0746 | lr: 9.9942e-05 | scale: 16384.0000 | micro time: 1.363 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2421/156230 | global iter:   2421/156230 | loss: 1.0909 | ds_loss: 1.0962 | lr: 9.9942e-05 | scale: 16384.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   2422/156230 | global iter:   2422/156230 | loss: 1.2950 | ds_loss: 1.2910 | lr: 9.9942e-05 | scale: 16384.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   2423/156230 | global iter:   2423/156230 | loss: 1.2020 | ds_loss: 1.1958 | lr: 9.9942e-05 | scale: 16384.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   2424/156230 | global iter:   2424/156230 | loss: 1.2861 | ds_loss: 1.2752 | lr: 9.9942e-05 | scale: 16384.0000 | micro time: 1.388 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2424/156230 | global iter:   2424/156230 | loss: 1.2185 | ds_loss: 1.2145 | lr: 9.9942e-05 | scale: 16384.0000 | micro time: 1.388 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2425/156230 | global iter:   2425/156230 | loss: 1.1257 | ds_loss: 1.1297 | lr: 9.9942e-05 | scale: 16384.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   2426/156230 | global iter:   2426/156230 | loss: 1.1883 | ds_loss: 1.1938 | lr: 9.9942e-05 | scale: 16384.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   2427/156230 | global iter:   2427/156230 | loss: 1.2439 | ds_loss: 1.2452 | lr: 9.9942e-05 | scale: 16384.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   2428/156230 | global iter:   2428/156230 | loss: 1.1296 | ds_loss: 1.1368 | lr: 9.9941e-05 | scale: 16384.0000 | micro time: 1.388 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2428/156230 | global iter:   2428/156230 | loss: 1.1718 | ds_loss: 1.1764 | lr: 9.9941e-05 | scale: 16384.0000 | micro time: 1.388 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2429/156230 | global iter:   2429/156230 | loss: 1.2229 | ds_loss: 1.2178 | lr: 9.9941e-05 | scale: 16384.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   2430/156230 | global iter:   2430/156230 | loss: 1.1120 | ds_loss: 1.1077 | lr: 9.9941e-05 | scale: 16384.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   2431/156230 | global iter:   2431/156230 | loss: 1.1172 | ds_loss: 1.1083 | lr: 9.9941e-05 | scale: 16384.0000 | micro time: 1.307 | step time: 0.000
train | epoch   0 | Iter:   2432/156230 | global iter:   2432/156230 | loss: 1.1430 | ds_loss: 1.1567 | lr: 9.9941e-05 | scale: 16384.0000 | micro time: 1.392 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2432/156230 | global iter:   2432/156230 | loss: 1.1488 | ds_loss: 1.1476 | lr: 9.9941e-05 | scale: 16384.0000 | micro time: 1.392 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2433/156230 | global iter:   2433/156230 | loss: 1.1723 | ds_loss: 1.1708 | lr: 9.9941e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   2434/156230 | global iter:   2434/156230 | loss: 1.1307 | ds_loss: 1.1149 | lr: 9.9941e-05 | scale: 16384.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   2435/156230 | global iter:   2435/156230 | loss: 1.2928 | ds_loss: 1.2865 | lr: 9.9941e-05 | scale: 16384.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   2436/156230 | global iter:   2436/156230 | loss: 1.1653 | ds_loss: 1.1619 | lr: 9.9941e-05 | scale: 16384.0000 | micro time: 1.375 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2436/156230 | global iter:   2436/156230 | loss: 1.1902 | ds_loss: 1.1835 | lr: 9.9941e-05 | scale: 16384.0000 | micro time: 1.375 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2437/156230 | global iter:   2437/156230 | loss: 1.0291 | ds_loss: 1.0309 | lr: 9.9941e-05 | scale: 16384.0000 | micro time: 1.410 | step time: 0.000
train | epoch   0 | Iter:   2438/156230 | global iter:   2438/156230 | loss: 1.1609 | ds_loss: 1.1647 | lr: 9.9941e-05 | scale: 16384.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   2439/156230 | global iter:   2439/156230 | loss: 1.1550 | ds_loss: 1.1524 | lr: 9.9941e-05 | scale: 16384.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   2440/156230 | global iter:   2440/156230 | loss: 1.0495 | ds_loss: 1.0650 | lr: 9.9941e-05 | scale: 16384.0000 | micro time: 1.343 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2440/156230 | global iter:   2440/156230 | loss: 1.0986 | ds_loss: 1.1033 | lr: 9.9941e-05 | scale: 16384.0000 | micro time: 1.343 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2441/156230 | global iter:   2441/156230 | loss: 1.2476 | ds_loss: 1.2551 | lr: 9.9941e-05 | scale: 16384.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   2442/156230 | global iter:   2442/156230 | loss: 1.2099 | ds_loss: 1.2322 | lr: 9.9941e-05 | scale: 16384.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   2443/156230 | global iter:   2443/156230 | loss: 1.1615 | ds_loss: 1.1745 | lr: 9.9941e-05 | scale: 16384.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   2444/156230 | global iter:   2444/156230 | loss: 1.2238 | ds_loss: 1.2293 | lr: 9.9941e-05 | scale: 16384.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2444/156230 | global iter:   2444/156230 | loss: 1.2107 | ds_loss: 1.2228 | lr: 9.9941e-05 | scale: 16384.0000 | micro time: 1.374 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2445/156230 | global iter:   2445/156230 | loss: 1.1629 | ds_loss: 1.1707 | lr: 9.9941e-05 | scale: 16384.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   2446/156230 | global iter:   2446/156230 | loss: 1.2491 | ds_loss: 1.2516 | lr: 9.9941e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   2447/156230 | global iter:   2447/156230 | loss: 1.3124 | ds_loss: 1.3467 | lr: 9.9941e-05 | scale: 16384.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   2448/156230 | global iter:   2448/156230 | loss: 1.1718 | ds_loss: 1.1751 | lr: 9.9940e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2448/156230 | global iter:   2448/156230 | loss: 1.2240 | ds_loss: 1.2360 | lr: 9.9940e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2449/156230 | global iter:   2449/156230 | loss: 1.2542 | ds_loss: 1.2663 | lr: 9.9940e-05 | scale: 16384.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   2450/156230 | global iter:   2450/156230 | loss: 1.1635 | ds_loss: 1.1771 | lr: 9.9940e-05 | scale: 16384.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   2451/156230 | global iter:   2451/156230 | loss: 1.1822 | ds_loss: 1.1940 | lr: 9.9940e-05 | scale: 16384.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   2452/156230 | global iter:   2452/156230 | loss: 1.1702 | ds_loss: 1.1724 | lr: 9.9940e-05 | scale: 16384.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2452/156230 | global iter:   2452/156230 | loss: 1.1925 | ds_loss: 1.2024 | lr: 9.9940e-05 | scale: 16384.0000 | micro time: 1.393 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2453/156230 | global iter:   2453/156230 | loss: 1.1495 | ds_loss: 1.1414 | lr: 9.9940e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   2454/156230 | global iter:   2454/156230 | loss: 1.1066 | ds_loss: 1.1033 | lr: 9.9940e-05 | scale: 16384.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   2455/156230 | global iter:   2455/156230 | loss: 1.0776 | ds_loss: 1.0636 | lr: 9.9940e-05 | scale: 16384.0000 | micro time: 1.325 | step time: 0.000
train | epoch   0 | Iter:   2456/156230 | global iter:   2456/156230 | loss: 1.2721 | ds_loss: 1.2769 | lr: 9.9940e-05 | scale: 16384.0000 | micro time: 1.380 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2456/156230 | global iter:   2456/156230 | loss: 1.1514 | ds_loss: 1.1463 | lr: 9.9940e-05 | scale: 16384.0000 | micro time: 1.380 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2457/156230 | global iter:   2457/156230 | loss: 1.1345 | ds_loss: 1.1413 | lr: 9.9940e-05 | scale: 16384.0000 | micro time: 1.409 | step time: 0.000
train | epoch   0 | Iter:   2458/156230 | global iter:   2458/156230 | loss: 1.2836 | ds_loss: 1.2903 | lr: 9.9940e-05 | scale: 16384.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   2459/156230 | global iter:   2459/156230 | loss: 1.2885 | ds_loss: 1.3042 | lr: 9.9940e-05 | scale: 16384.0000 | micro time: 1.325 | step time: 0.000
train | epoch   0 | Iter:   2460/156230 | global iter:   2460/156230 | loss: 1.1179 | ds_loss: 1.1269 | lr: 9.9940e-05 | scale: 16384.0000 | micro time: 1.408 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2460/156230 | global iter:   2460/156230 | loss: 1.2061 | ds_loss: 1.2157 | lr: 9.9940e-05 | scale: 16384.0000 | micro time: 1.408 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2461/156230 | global iter:   2461/156230 | loss: 1.0858 | ds_loss: 1.0815 | lr: 9.9940e-05 | scale: 16384.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   2462/156230 | global iter:   2462/156230 | loss: 1.0288 | ds_loss: 1.0477 | lr: 9.9940e-05 | scale: 16384.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   2463/156230 | global iter:   2463/156230 | loss: 1.0311 | ds_loss: 1.0380 | lr: 9.9940e-05 | scale: 16384.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   2464/156230 | global iter:   2464/156230 | loss: 1.0271 | ds_loss: 1.0423 | lr: 9.9940e-05 | scale: 16384.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2464/156230 | global iter:   2464/156230 | loss: 1.0432 | ds_loss: 1.0523 | lr: 9.9940e-05 | scale: 16384.0000 | micro time: 1.350 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2465/156230 | global iter:   2465/156230 | loss: 1.1778 | ds_loss: 1.1756 | lr: 9.9940e-05 | scale: 16384.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   2466/156230 | global iter:   2466/156230 | loss: 1.2764 | ds_loss: 1.2628 | lr: 9.9940e-05 | scale: 16384.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   2467/156230 | global iter:   2467/156230 | loss: 1.1671 | ds_loss: 1.1636 | lr: 9.9940e-05 | scale: 16384.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   2468/156230 | global iter:   2468/156230 | loss: 0.9378 | ds_loss: 0.9479 | lr: 9.9939e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2468/156230 | global iter:   2468/156230 | loss: 1.1398 | ds_loss: 1.1374 | lr: 9.9939e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2469/156230 | global iter:   2469/156230 | loss: 1.0147 | ds_loss: 1.0174 | lr: 9.9939e-05 | scale: 16384.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   2470/156230 | global iter:   2470/156230 | loss: 1.0401 | ds_loss: 1.0410 | lr: 9.9939e-05 | scale: 16384.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   2471/156230 | global iter:   2471/156230 | loss: 1.0111 | ds_loss: 1.0163 | lr: 9.9939e-05 | scale: 16384.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   2472/156230 | global iter:   2472/156230 | loss: 1.1671 | ds_loss: 1.1655 | lr: 9.9939e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2472/156230 | global iter:   2472/156230 | loss: 1.0582 | ds_loss: 1.0600 | lr: 9.9939e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2473/156230 | global iter:   2473/156230 | loss: 1.1781 | ds_loss: 1.1724 | lr: 9.9939e-05 | scale: 16384.0000 | micro time: 1.318 | step time: 0.000
train | epoch   0 | Iter:   2474/156230 | global iter:   2474/156230 | loss: 1.0536 | ds_loss: 1.0677 | lr: 9.9939e-05 | scale: 16384.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   2475/156230 | global iter:   2475/156230 | loss: 1.1768 | ds_loss: 1.1841 | lr: 9.9939e-05 | scale: 16384.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   2476/156230 | global iter:   2476/156230 | loss: 1.1814 | ds_loss: 1.1999 | lr: 9.9939e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2476/156230 | global iter:   2476/156230 | loss: 1.1475 | ds_loss: 1.1560 | lr: 9.9939e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2477/156230 | global iter:   2477/156230 | loss: 1.0926 | ds_loss: 1.1135 | lr: 9.9939e-05 | scale: 16384.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   2478/156230 | global iter:   2478/156230 | loss: 1.3370 | ds_loss: 1.3285 | lr: 9.9939e-05 | scale: 16384.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   2479/156230 | global iter:   2479/156230 | loss: 1.0781 | ds_loss: 1.0899 | lr: 9.9939e-05 | scale: 16384.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   2480/156230 | global iter:   2480/156230 | loss: 1.2453 | ds_loss: 1.2495 | lr: 9.9939e-05 | scale: 16384.0000 | micro time: 1.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2480/156230 | global iter:   2480/156230 | loss: 1.1883 | ds_loss: 1.1954 | lr: 9.9939e-05 | scale: 16384.0000 | micro time: 1.396 | step time: 1.387
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2481/156230 | global iter:   2481/156230 | loss: 1.2992 | ds_loss: 1.2846 | lr: 9.9939e-05 | scale: 16384.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   2482/156230 | global iter:   2482/156230 | loss: 1.0931 | ds_loss: 1.0764 | lr: 9.9939e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   2483/156230 | global iter:   2483/156230 | loss: 1.1538 | ds_loss: 1.1539 | lr: 9.9939e-05 | scale: 16384.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   2484/156230 | global iter:   2484/156230 | loss: 0.8844 | ds_loss: 0.8962 | lr: 9.9939e-05 | scale: 16384.0000 | micro time: 1.328 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2484/156230 | global iter:   2484/156230 | loss: 1.1076 | ds_loss: 1.1028 | lr: 9.9939e-05 | scale: 16384.0000 | micro time: 1.328 | step time: 1.347
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2485/156230 | global iter:   2485/156230 | loss: 1.2018 | ds_loss: 1.1967 | lr: 9.9939e-05 | scale: 16384.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   2486/156230 | global iter:   2486/156230 | loss: 1.0941 | ds_loss: 1.1152 | lr: 9.9939e-05 | scale: 16384.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   2487/156230 | global iter:   2487/156230 | loss: 1.1602 | ds_loss: 1.1665 | lr: 9.9939e-05 | scale: 16384.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   2488/156230 | global iter:   2488/156230 | loss: 1.2945 | ds_loss: 1.2908 | lr: 9.9938e-05 | scale: 16384.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2488/156230 | global iter:   2488/156230 | loss: 1.1877 | ds_loss: 1.1923 | lr: 9.9938e-05 | scale: 16384.0000 | micro time: 1.374 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2489/156230 | global iter:   2489/156230 | loss: 1.1636 | ds_loss: 1.1893 | lr: 9.9938e-05 | scale: 16384.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   2490/156230 | global iter:   2490/156230 | loss: 1.2025 | ds_loss: 1.2152 | lr: 9.9938e-05 | scale: 16384.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   2491/156230 | global iter:   2491/156230 | loss: 1.1788 | ds_loss: 1.1963 | lr: 9.9938e-05 | scale: 16384.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   2492/156230 | global iter:   2492/156230 | loss: 1.2451 | ds_loss: 1.2478 | lr: 9.9938e-05 | scale: 16384.0000 | micro time: 1.336 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2492/156230 | global iter:   2492/156230 | loss: 1.1975 | ds_loss: 1.2122 | lr: 9.9938e-05 | scale: 16384.0000 | micro time: 1.336 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2493/156230 | global iter:   2493/156230 | loss: 1.1754 | ds_loss: 1.1688 | lr: 9.9938e-05 | scale: 16384.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   2494/156230 | global iter:   2494/156230 | loss: 1.0042 | ds_loss: 1.0080 | lr: 9.9938e-05 | scale: 16384.0000 | micro time: 1.420 | step time: 0.000
train | epoch   0 | Iter:   2495/156230 | global iter:   2495/156230 | loss: 0.9338 | ds_loss: 0.9371 | lr: 9.9938e-05 | scale: 16384.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   2496/156230 | global iter:   2496/156230 | loss: 1.0787 | ds_loss: 1.0852 | lr: 9.9938e-05 | scale: 16384.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2496/156230 | global iter:   2496/156230 | loss: 1.0480 | ds_loss: 1.0498 | lr: 9.9938e-05 | scale: 16384.0000 | micro time: 1.342 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2497/156230 | global iter:   2497/156230 | loss: 1.3154 | ds_loss: 1.3198 | lr: 9.9938e-05 | scale: 16384.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   2498/156230 | global iter:   2498/156230 | loss: 1.1606 | ds_loss: 1.1733 | lr: 9.9938e-05 | scale: 16384.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   2499/156230 | global iter:   2499/156230 | loss: 1.3041 | ds_loss: 1.3187 | lr: 9.9938e-05 | scale: 16384.0000 | micro time: 1.404 | step time: 0.000
train | epoch   0 | Iter:   2500/156230 | global iter:   2500/156230 | loss: 1.2685 | ds_loss: 1.2736 | lr: 9.9938e-05 | scale: 16384.0000 | micro time: 1.326 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2500/156230 | global iter:   2500/156230 | loss: 1.2621 | ds_loss: 1.2713 | lr: 9.9938e-05 | scale: 16384.0000 | micro time: 1.326 | step time: 1.376
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2501/156230 | global iter:   2501/156230 | loss: 1.1022 | ds_loss: 1.1161 | lr: 9.9938e-05 | scale: 16384.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   2502/156230 | global iter:   2502/156230 | loss: 0.8489 | ds_loss: 0.8607 | lr: 9.9938e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   2503/156230 | global iter:   2503/156230 | loss: 1.3815 | ds_loss: 1.3948 | lr: 9.9938e-05 | scale: 16384.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   2504/156230 | global iter:   2504/156230 | loss: 1.1099 | ds_loss: 1.1054 | lr: 9.9938e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2504/156230 | global iter:   2504/156230 | loss: 1.1106 | ds_loss: 1.1192 | lr: 9.9938e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2505/156230 | global iter:   2505/156230 | loss: 1.2230 | ds_loss: 1.2114 | lr: 9.9938e-05 | scale: 16384.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   2506/156230 | global iter:   2506/156230 | loss: 1.3606 | ds_loss: 1.3828 | lr: 9.9938e-05 | scale: 16384.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   2507/156230 | global iter:   2507/156230 | loss: 1.3468 | ds_loss: 1.3604 | lr: 9.9938e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   2508/156230 | global iter:   2508/156230 | loss: 1.2613 | ds_loss: 1.2664 | lr: 9.9937e-05 | scale: 16384.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2508/156230 | global iter:   2508/156230 | loss: 1.2979 | ds_loss: 1.3052 | lr: 9.9937e-05 | scale: 16384.0000 | micro time: 1.385 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2509/156230 | global iter:   2509/156230 | loss: 1.2124 | ds_loss: 1.2137 | lr: 9.9937e-05 | scale: 16384.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   2510/156230 | global iter:   2510/156230 | loss: 1.2805 | ds_loss: 1.2778 | lr: 9.9937e-05 | scale: 16384.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   2511/156230 | global iter:   2511/156230 | loss: 1.1887 | ds_loss: 1.1927 | lr: 9.9937e-05 | scale: 16384.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   2512/156230 | global iter:   2512/156230 | loss: 1.2291 | ds_loss: 1.2512 | lr: 9.9937e-05 | scale: 16384.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2512/156230 | global iter:   2512/156230 | loss: 1.2277 | ds_loss: 1.2338 | lr: 9.9937e-05 | scale: 16384.0000 | micro time: 1.351 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2513/156230 | global iter:   2513/156230 | loss: 1.3028 | ds_loss: 1.3304 | lr: 9.9937e-05 | scale: 16384.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   2514/156230 | global iter:   2514/156230 | loss: 1.1360 | ds_loss: 1.1366 | lr: 9.9937e-05 | scale: 16384.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   2515/156230 | global iter:   2515/156230 | loss: 1.2524 | ds_loss: 1.2502 | lr: 9.9937e-05 | scale: 16384.0000 | micro time: 1.409 | step time: 0.000
train | epoch   0 | Iter:   2516/156230 | global iter:   2516/156230 | loss: 1.1651 | ds_loss: 1.1732 | lr: 9.9937e-05 | scale: 16384.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2516/156230 | global iter:   2516/156230 | loss: 1.2141 | ds_loss: 1.2226 | lr: 9.9937e-05 | scale: 16384.0000 | micro time: 1.345 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2517/156230 | global iter:   2517/156230 | loss: 1.2021 | ds_loss: 1.1999 | lr: 9.9937e-05 | scale: 16384.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   2518/156230 | global iter:   2518/156230 | loss: 1.2966 | ds_loss: 1.3094 | lr: 9.9937e-05 | scale: 16384.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   2519/156230 | global iter:   2519/156230 | loss: 1.2151 | ds_loss: 1.1948 | lr: 9.9937e-05 | scale: 16384.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   2520/156230 | global iter:   2520/156230 | loss: 1.3441 | ds_loss: 1.3325 | lr: 9.9937e-05 | scale: 16384.0000 | micro time: 1.340 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2520/156230 | global iter:   2520/156230 | loss: 1.2645 | ds_loss: 1.2591 | lr: 9.9937e-05 | scale: 16384.0000 | micro time: 1.340 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2521/156230 | global iter:   2521/156230 | loss: 1.1573 | ds_loss: 1.1531 | lr: 9.9937e-05 | scale: 16384.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   2522/156230 | global iter:   2522/156230 | loss: 1.2012 | ds_loss: 1.2084 | lr: 9.9937e-05 | scale: 16384.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   2523/156230 | global iter:   2523/156230 | loss: 1.2474 | ds_loss: 1.2587 | lr: 9.9937e-05 | scale: 16384.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   2524/156230 | global iter:   2524/156230 | loss: 1.2080 | ds_loss: 1.2068 | lr: 9.9937e-05 | scale: 16384.0000 | micro time: 1.379 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2524/156230 | global iter:   2524/156230 | loss: 1.2035 | ds_loss: 1.2068 | lr: 9.9937e-05 | scale: 16384.0000 | micro time: 1.379 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2525/156230 | global iter:   2525/156230 | loss: 0.9627 | ds_loss: 0.9688 | lr: 9.9937e-05 | scale: 16384.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   2526/156230 | global iter:   2526/156230 | loss: 1.1369 | ds_loss: 1.1585 | lr: 9.9937e-05 | scale: 16384.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   2527/156230 | global iter:   2527/156230 | loss: 1.2450 | ds_loss: 1.2582 | lr: 9.9937e-05 | scale: 16384.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   2528/156230 | global iter:   2528/156230 | loss: 1.2325 | ds_loss: 1.2400 | lr: 9.9936e-05 | scale: 16384.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2528/156230 | global iter:   2528/156230 | loss: 1.1443 | ds_loss: 1.1564 | lr: 9.9936e-05 | scale: 16384.0000 | micro time: 1.355 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2529/156230 | global iter:   2529/156230 | loss: 1.1550 | ds_loss: 1.1766 | lr: 9.9936e-05 | scale: 16384.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   2530/156230 | global iter:   2530/156230 | loss: 1.3032 | ds_loss: 1.2959 | lr: 9.9936e-05 | scale: 16384.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   2531/156230 | global iter:   2531/156230 | loss: 1.0963 | ds_loss: 1.0891 | lr: 9.9936e-05 | scale: 16384.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   2532/156230 | global iter:   2532/156230 | loss: 1.1780 | ds_loss: 1.1848 | lr: 9.9936e-05 | scale: 16384.0000 | micro time: 1.340 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2532/156230 | global iter:   2532/156230 | loss: 1.1831 | ds_loss: 1.1866 | lr: 9.9936e-05 | scale: 16384.0000 | micro time: 1.340 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2533/156230 | global iter:   2533/156230 | loss: 1.0373 | ds_loss: 1.0447 | lr: 9.9936e-05 | scale: 16384.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   2534/156230 | global iter:   2534/156230 | loss: 1.1407 | ds_loss: 1.1591 | lr: 9.9936e-05 | scale: 16384.0000 | micro time: 1.313 | step time: 0.000
train | epoch   0 | Iter:   2535/156230 | global iter:   2535/156230 | loss: 1.2277 | ds_loss: 1.2367 | lr: 9.9936e-05 | scale: 16384.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   2536/156230 | global iter:   2536/156230 | loss: 1.1048 | ds_loss: 1.0949 | lr: 9.9936e-05 | scale: 16384.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2536/156230 | global iter:   2536/156230 | loss: 1.1276 | ds_loss: 1.1338 | lr: 9.9936e-05 | scale: 16384.0000 | micro time: 1.370 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2537/156230 | global iter:   2537/156230 | loss: 1.0640 | ds_loss: 1.0630 | lr: 9.9936e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   2538/156230 | global iter:   2538/156230 | loss: 1.2815 | ds_loss: 1.2978 | lr: 9.9936e-05 | scale: 16384.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   2539/156230 | global iter:   2539/156230 | loss: 1.2207 | ds_loss: 1.2192 | lr: 9.9936e-05 | scale: 16384.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   2540/156230 | global iter:   2540/156230 | loss: 1.1534 | ds_loss: 1.1695 | lr: 9.9936e-05 | scale: 16384.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2540/156230 | global iter:   2540/156230 | loss: 1.1799 | ds_loss: 1.1874 | lr: 9.9936e-05 | scale: 16384.0000 | micro time: 1.349 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2541/156230 | global iter:   2541/156230 | loss: 0.9250 | ds_loss: 0.9555 | lr: 9.9936e-05 | scale: 16384.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   2542/156230 | global iter:   2542/156230 | loss: 1.1198 | ds_loss: 1.1295 | lr: 9.9936e-05 | scale: 16384.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   2543/156230 | global iter:   2543/156230 | loss: 1.3475 | ds_loss: 1.3787 | lr: 9.9936e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   2544/156230 | global iter:   2544/156230 | loss: 1.2114 | ds_loss: 1.2154 | lr: 9.9936e-05 | scale: 16384.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2544/156230 | global iter:   2544/156230 | loss: 1.1509 | ds_loss: 1.1698 | lr: 9.9936e-05 | scale: 16384.0000 | micro time: 1.354 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2545/156230 | global iter:   2545/156230 | loss: 1.1819 | ds_loss: 1.2001 | lr: 9.9936e-05 | scale: 16384.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   2546/156230 | global iter:   2546/156230 | loss: 1.3074 | ds_loss: 1.3207 | lr: 9.9936e-05 | scale: 16384.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   2547/156230 | global iter:   2547/156230 | loss: 1.1423 | ds_loss: 1.1499 | lr: 9.9936e-05 | scale: 16384.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   2548/156230 | global iter:   2548/156230 | loss: 1.1048 | ds_loss: 1.1115 | lr: 9.9935e-05 | scale: 16384.0000 | micro time: 1.367 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2548/156230 | global iter:   2548/156230 | loss: 1.1841 | ds_loss: 1.1956 | lr: 9.9935e-05 | scale: 16384.0000 | micro time: 1.367 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2549/156230 | global iter:   2549/156230 | loss: 1.2648 | ds_loss: 1.2664 | lr: 9.9935e-05 | scale: 16384.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   2550/156230 | global iter:   2550/156230 | loss: 1.1067 | ds_loss: 1.1170 | lr: 9.9935e-05 | scale: 16384.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   2551/156230 | global iter:   2551/156230 | loss: 1.0382 | ds_loss: 1.0456 | lr: 9.9935e-05 | scale: 16384.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   2552/156230 | global iter:   2552/156230 | loss: 1.1202 | ds_loss: 1.1010 | lr: 9.9935e-05 | scale: 16384.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2552/156230 | global iter:   2552/156230 | loss: 1.1325 | ds_loss: 1.1325 | lr: 9.9935e-05 | scale: 16384.0000 | micro time: 1.347 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2553/156230 | global iter:   2553/156230 | loss: 1.2144 | ds_loss: 1.2074 | lr: 9.9935e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   2554/156230 | global iter:   2554/156230 | loss: 1.0944 | ds_loss: 1.0985 | lr: 9.9935e-05 | scale: 16384.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   2555/156230 | global iter:   2555/156230 | loss: 1.1522 | ds_loss: 1.1555 | lr: 9.9935e-05 | scale: 16384.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   2556/156230 | global iter:   2556/156230 | loss: 1.2647 | ds_loss: 1.2706 | lr: 9.9935e-05 | scale: 16384.0000 | micro time: 1.388 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2556/156230 | global iter:   2556/156230 | loss: 1.1814 | ds_loss: 1.1830 | lr: 9.9935e-05 | scale: 16384.0000 | micro time: 1.388 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2557/156230 | global iter:   2557/156230 | loss: 1.2075 | ds_loss: 1.2230 | lr: 9.9935e-05 | scale: 16384.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   2558/156230 | global iter:   2558/156230 | loss: 1.1589 | ds_loss: 1.1628 | lr: 9.9935e-05 | scale: 16384.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   2559/156230 | global iter:   2559/156230 | loss: 1.2483 | ds_loss: 1.2411 | lr: 9.9935e-05 | scale: 16384.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   2560/156230 | global iter:   2560/156230 | loss: 1.2266 | ds_loss: 1.2263 | lr: 9.9935e-05 | scale: 16384.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2560/156230 | global iter:   2560/156230 | loss: 1.2103 | ds_loss: 1.2133 | lr: 9.9935e-05 | scale: 16384.0000 | micro time: 1.393 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2561/156230 | global iter:   2561/156230 | loss: 1.2203 | ds_loss: 1.2359 | lr: 9.9935e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   2562/156230 | global iter:   2562/156230 | loss: 1.0986 | ds_loss: 1.1040 | lr: 9.9935e-05 | scale: 16384.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   2563/156230 | global iter:   2563/156230 | loss: 1.3403 | ds_loss: 1.3276 | lr: 9.9935e-05 | scale: 16384.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   2564/156230 | global iter:   2564/156230 | loss: 1.1360 | ds_loss: 1.1381 | lr: 9.9935e-05 | scale: 16384.0000 | micro time: 1.334 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2564/156230 | global iter:   2564/156230 | loss: 1.1988 | ds_loss: 1.2014 | lr: 9.9935e-05 | scale: 16384.0000 | micro time: 1.334 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2565/156230 | global iter:   2565/156230 | loss: 1.2897 | ds_loss: 1.2812 | lr: 9.9935e-05 | scale: 16384.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   2566/156230 | global iter:   2566/156230 | loss: 1.0989 | ds_loss: 1.1037 | lr: 9.9935e-05 | scale: 16384.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   2567/156230 | global iter:   2567/156230 | loss: 1.0346 | ds_loss: 1.0318 | lr: 9.9935e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   2568/156230 | global iter:   2568/156230 | loss: 1.2371 | ds_loss: 1.2518 | lr: 9.9934e-05 | scale: 16384.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2568/156230 | global iter:   2568/156230 | loss: 1.1651 | ds_loss: 1.1671 | lr: 9.9934e-05 | scale: 16384.0000 | micro time: 1.374 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2569/156230 | global iter:   2569/156230 | loss: 1.1970 | ds_loss: 1.2048 | lr: 9.9934e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   2570/156230 | global iter:   2570/156230 | loss: 1.1402 | ds_loss: 1.1554 | lr: 9.9934e-05 | scale: 16384.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   2571/156230 | global iter:   2571/156230 | loss: 0.8445 | ds_loss: 0.8564 | lr: 9.9934e-05 | scale: 16384.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   2572/156230 | global iter:   2572/156230 | loss: 1.2123 | ds_loss: 1.2047 | lr: 9.9934e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2572/156230 | global iter:   2572/156230 | loss: 1.0985 | ds_loss: 1.1053 | lr: 9.9934e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2573/156230 | global iter:   2573/156230 | loss: 1.1079 | ds_loss: 1.1103 | lr: 9.9934e-05 | scale: 16384.0000 | micro time: 1.415 | step time: 0.000
train | epoch   0 | Iter:   2574/156230 | global iter:   2574/156230 | loss: 1.2662 | ds_loss: 1.2741 | lr: 9.9934e-05 | scale: 16384.0000 | micro time: 1.406 | step time: 0.000
train | epoch   0 | Iter:   2575/156230 | global iter:   2575/156230 | loss: 1.1156 | ds_loss: 1.1187 | lr: 9.9934e-05 | scale: 16384.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   2576/156230 | global iter:   2576/156230 | loss: 1.3582 | ds_loss: 1.3655 | lr: 9.9934e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2576/156230 | global iter:   2576/156230 | loss: 1.2120 | ds_loss: 1.2171 | lr: 9.9934e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 1.384
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2577/156230 | global iter:   2577/156230 | loss: 1.1020 | ds_loss: 1.1050 | lr: 9.9934e-05 | scale: 16384.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   2578/156230 | global iter:   2578/156230 | loss: 1.1668 | ds_loss: 1.1754 | lr: 9.9934e-05 | scale: 16384.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   2579/156230 | global iter:   2579/156230 | loss: 1.1484 | ds_loss: 1.1530 | lr: 9.9934e-05 | scale: 16384.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   2580/156230 | global iter:   2580/156230 | loss: 1.2241 | ds_loss: 1.2571 | lr: 9.9934e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2580/156230 | global iter:   2580/156230 | loss: 1.1603 | ds_loss: 1.1726 | lr: 9.9934e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2581/156230 | global iter:   2581/156230 | loss: 1.2516 | ds_loss: 1.2689 | lr: 9.9934e-05 | scale: 16384.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   2582/156230 | global iter:   2582/156230 | loss: 1.0895 | ds_loss: 1.1100 | lr: 9.9934e-05 | scale: 16384.0000 | micro time: 1.401 | step time: 0.000
train | epoch   0 | Iter:   2583/156230 | global iter:   2583/156230 | loss: 1.2700 | ds_loss: 1.2631 | lr: 9.9934e-05 | scale: 16384.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   2584/156230 | global iter:   2584/156230 | loss: 1.0532 | ds_loss: 1.0723 | lr: 9.9934e-05 | scale: 16384.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2584/156230 | global iter:   2584/156230 | loss: 1.1661 | ds_loss: 1.1786 | lr: 9.9934e-05 | scale: 16384.0000 | micro time: 1.349 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2585/156230 | global iter:   2585/156230 | loss: 1.1699 | ds_loss: 1.1735 | lr: 9.9934e-05 | scale: 16384.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   2586/156230 | global iter:   2586/156230 | loss: 1.2045 | ds_loss: 1.2208 | lr: 9.9934e-05 | scale: 16384.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   2587/156230 | global iter:   2587/156230 | loss: 1.3096 | ds_loss: 1.3234 | lr: 9.9933e-05 | scale: 16384.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   2588/156230 | global iter:   2588/156230 | loss: 1.2021 | ds_loss: 1.2184 | lr: 9.9933e-05 | scale: 16384.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2588/156230 | global iter:   2588/156230 | loss: 1.2215 | ds_loss: 1.2340 | lr: 9.9933e-05 | scale: 16384.0000 | micro time: 1.385 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2589/156230 | global iter:   2589/156230 | loss: 1.3242 | ds_loss: 1.3254 | lr: 9.9933e-05 | scale: 16384.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   2590/156230 | global iter:   2590/156230 | loss: 1.1021 | ds_loss: 1.1011 | lr: 9.9933e-05 | scale: 16384.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   2591/156230 | global iter:   2591/156230 | loss: 1.2271 | ds_loss: 1.2184 | lr: 9.9933e-05 | scale: 16384.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   2592/156230 | global iter:   2592/156230 | loss: 1.2538 | ds_loss: 1.2772 | lr: 9.9933e-05 | scale: 16384.0000 | micro time: 1.409 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2592/156230 | global iter:   2592/156230 | loss: 1.2268 | ds_loss: 1.2305 | lr: 9.9933e-05 | scale: 16384.0000 | micro time: 1.409 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2593/156230 | global iter:   2593/156230 | loss: 1.2658 | ds_loss: 1.2701 | lr: 9.9933e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   2594/156230 | global iter:   2594/156230 | loss: 1.0545 | ds_loss: 1.0775 | lr: 9.9933e-05 | scale: 16384.0000 | micro time: 1.402 | step time: 0.000
train | epoch   0 | Iter:   2595/156230 | global iter:   2595/156230 | loss: 1.2131 | ds_loss: 1.2397 | lr: 9.9933e-05 | scale: 16384.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   2596/156230 | global iter:   2596/156230 | loss: 1.0490 | ds_loss: 1.0564 | lr: 9.9933e-05 | scale: 16384.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2596/156230 | global iter:   2596/156230 | loss: 1.1456 | ds_loss: 1.1609 | lr: 9.9933e-05 | scale: 16384.0000 | micro time: 1.377 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2597/156230 | global iter:   2597/156230 | loss: 1.3092 | ds_loss: 1.3057 | lr: 9.9933e-05 | scale: 16384.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   2598/156230 | global iter:   2598/156230 | loss: 1.3014 | ds_loss: 1.3172 | lr: 9.9933e-05 | scale: 16384.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   2599/156230 | global iter:   2599/156230 | loss: 1.1920 | ds_loss: 1.1858 | lr: 9.9933e-05 | scale: 16384.0000 | micro time: 1.316 | step time: 0.000
train | epoch   0 | Iter:   2600/156230 | global iter:   2600/156230 | loss: 1.1181 | ds_loss: 1.1270 | lr: 9.9933e-05 | scale: 16384.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2600/156230 | global iter:   2600/156230 | loss: 1.2302 | ds_loss: 1.2339 | lr: 9.9933e-05 | scale: 16384.0000 | micro time: 1.345 | step time: 1.341
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2601/156230 | global iter:   2601/156230 | loss: 1.1474 | ds_loss: 1.1757 | lr: 9.9933e-05 | scale: 16384.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   2602/156230 | global iter:   2602/156230 | loss: 1.0172 | ds_loss: 1.0157 | lr: 9.9933e-05 | scale: 16384.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   2603/156230 | global iter:   2603/156230 | loss: 1.1868 | ds_loss: 1.1831 | lr: 9.9933e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   2604/156230 | global iter:   2604/156230 | loss: 1.3387 | ds_loss: 1.3302 | lr: 9.9933e-05 | scale: 16384.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2604/156230 | global iter:   2604/156230 | loss: 1.1725 | ds_loss: 1.1762 | lr: 9.9933e-05 | scale: 16384.0000 | micro time: 1.377 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2605/156230 | global iter:   2605/156230 | loss: 1.0077 | ds_loss: 1.0185 | lr: 9.9933e-05 | scale: 16384.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   2606/156230 | global iter:   2606/156230 | loss: 1.1344 | ds_loss: 1.1276 | lr: 9.9932e-05 | scale: 16384.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   2607/156230 | global iter:   2607/156230 | loss: 1.2694 | ds_loss: 1.2762 | lr: 9.9932e-05 | scale: 16384.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   2608/156230 | global iter:   2608/156230 | loss: 1.2198 | ds_loss: 1.2235 | lr: 9.9932e-05 | scale: 16384.0000 | micro time: 1.336 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2608/156230 | global iter:   2608/156230 | loss: 1.1579 | ds_loss: 1.1614 | lr: 9.9932e-05 | scale: 16384.0000 | micro time: 1.336 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2609/156230 | global iter:   2609/156230 | loss: 1.2862 | ds_loss: 1.3000 | lr: 9.9932e-05 | scale: 16384.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   2610/156230 | global iter:   2610/156230 | loss: 1.2482 | ds_loss: 1.2502 | lr: 9.9932e-05 | scale: 16384.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   2611/156230 | global iter:   2611/156230 | loss: 1.1562 | ds_loss: 1.1663 | lr: 9.9932e-05 | scale: 16384.0000 | micro time: 1.401 | step time: 0.000
train | epoch   0 | Iter:   2612/156230 | global iter:   2612/156230 | loss: 1.1416 | ds_loss: 1.1564 | lr: 9.9932e-05 | scale: 16384.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2612/156230 | global iter:   2612/156230 | loss: 1.2081 | ds_loss: 1.2182 | lr: 9.9932e-05 | scale: 16384.0000 | micro time: 1.351 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2613/156230 | global iter:   2613/156230 | loss: 1.0376 | ds_loss: 1.0303 | lr: 9.9932e-05 | scale: 16384.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   2614/156230 | global iter:   2614/156230 | loss: 1.3040 | ds_loss: 1.3033 | lr: 9.9932e-05 | scale: 16384.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:   2615/156230 | global iter:   2615/156230 | loss: 1.0671 | ds_loss: 1.0737 | lr: 9.9932e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   2616/156230 | global iter:   2616/156230 | loss: 1.0771 | ds_loss: 1.0685 | lr: 9.9932e-05 | scale: 16384.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2616/156230 | global iter:   2616/156230 | loss: 1.1214 | ds_loss: 1.1189 | lr: 9.9932e-05 | scale: 16384.0000 | micro time: 1.374 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2617/156230 | global iter:   2617/156230 | loss: 1.2321 | ds_loss: 1.2339 | lr: 9.9932e-05 | scale: 16384.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   2618/156230 | global iter:   2618/156230 | loss: 1.2161 | ds_loss: 1.2528 | lr: 9.9932e-05 | scale: 16384.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   2619/156230 | global iter:   2619/156230 | loss: 1.2352 | ds_loss: 1.2446 | lr: 9.9932e-05 | scale: 16384.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   2620/156230 | global iter:   2620/156230 | loss: 1.2227 | ds_loss: 1.2324 | lr: 9.9932e-05 | scale: 16384.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2620/156230 | global iter:   2620/156230 | loss: 1.2265 | ds_loss: 1.2409 | lr: 9.9932e-05 | scale: 16384.0000 | micro time: 1.385 | step time: 1.379
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2621/156230 | global iter:   2621/156230 | loss: 1.1337 | ds_loss: 1.1391 | lr: 9.9932e-05 | scale: 16384.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   2622/156230 | global iter:   2622/156230 | loss: 1.3182 | ds_loss: 1.3313 | lr: 9.9932e-05 | scale: 16384.0000 | micro time: 1.319 | step time: 0.000
train | epoch   0 | Iter:   2623/156230 | global iter:   2623/156230 | loss: 1.1227 | ds_loss: 1.1336 | lr: 9.9932e-05 | scale: 16384.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   2624/156230 | global iter:   2624/156230 | loss: 1.1012 | ds_loss: 1.1041 | lr: 9.9932e-05 | scale: 16384.0000 | micro time: 1.325 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2624/156230 | global iter:   2624/156230 | loss: 1.1689 | ds_loss: 1.1770 | lr: 9.9932e-05 | scale: 16384.0000 | micro time: 1.325 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2625/156230 | global iter:   2625/156230 | loss: 1.1250 | ds_loss: 1.1400 | lr: 9.9931e-05 | scale: 16384.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   2626/156230 | global iter:   2626/156230 | loss: 1.1132 | ds_loss: 1.1155 | lr: 9.9931e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   2627/156230 | global iter:   2627/156230 | loss: 1.2468 | ds_loss: 1.2408 | lr: 9.9931e-05 | scale: 16384.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:   2628/156230 | global iter:   2628/156230 | loss: 1.3700 | ds_loss: 1.3650 | lr: 9.9931e-05 | scale: 16384.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2628/156230 | global iter:   2628/156230 | loss: 1.2138 | ds_loss: 1.2154 | lr: 9.9931e-05 | scale: 16384.0000 | micro time: 1.378 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2629/156230 | global iter:   2629/156230 | loss: 1.1905 | ds_loss: 1.2005 | lr: 9.9931e-05 | scale: 16384.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   2630/156230 | global iter:   2630/156230 | loss: 1.1882 | ds_loss: 1.1938 | lr: 9.9931e-05 | scale: 16384.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   2631/156230 | global iter:   2631/156230 | loss: 1.1444 | ds_loss: 1.1483 | lr: 9.9931e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   2632/156230 | global iter:   2632/156230 | loss: 1.1461 | ds_loss: 1.1464 | lr: 9.9931e-05 | scale: 16384.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2632/156230 | global iter:   2632/156230 | loss: 1.1673 | ds_loss: 1.1723 | lr: 9.9931e-05 | scale: 16384.0000 | micro time: 1.360 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2633/156230 | global iter:   2633/156230 | loss: 1.2819 | ds_loss: 1.2904 | lr: 9.9931e-05 | scale: 16384.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   2634/156230 | global iter:   2634/156230 | loss: 1.2027 | ds_loss: 1.2040 | lr: 9.9931e-05 | scale: 16384.0000 | micro time: 1.300 | step time: 0.000
train | epoch   0 | Iter:   2635/156230 | global iter:   2635/156230 | loss: 1.2442 | ds_loss: 1.2433 | lr: 9.9931e-05 | scale: 16384.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   2636/156230 | global iter:   2636/156230 | loss: 1.0887 | ds_loss: 1.0835 | lr: 9.9931e-05 | scale: 16384.0000 | micro time: 1.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2636/156230 | global iter:   2636/156230 | loss: 1.2044 | ds_loss: 1.2053 | lr: 9.9931e-05 | scale: 16384.0000 | micro time: 1.397 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2637/156230 | global iter:   2637/156230 | loss: 1.2618 | ds_loss: 1.2730 | lr: 9.9931e-05 | scale: 16384.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   2638/156230 | global iter:   2638/156230 | loss: 1.3044 | ds_loss: 1.2887 | lr: 9.9931e-05 | scale: 16384.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   2639/156230 | global iter:   2639/156230 | loss: 1.1770 | ds_loss: 1.1770 | lr: 9.9931e-05 | scale: 16384.0000 | micro time: 1.433 | step time: 0.000
train | epoch   0 | Iter:   2640/156230 | global iter:   2640/156230 | loss: 1.3170 | ds_loss: 1.3210 | lr: 9.9931e-05 | scale: 16384.0000 | micro time: 1.316 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2640/156230 | global iter:   2640/156230 | loss: 1.2651 | ds_loss: 1.2649 | lr: 9.9931e-05 | scale: 16384.0000 | micro time: 1.316 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2641/156230 | global iter:   2641/156230 | loss: 1.2722 | ds_loss: 1.2787 | lr: 9.9931e-05 | scale: 16384.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   2642/156230 | global iter:   2642/156230 | loss: 1.1128 | ds_loss: 1.1181 | lr: 9.9931e-05 | scale: 16384.0000 | micro time: 1.313 | step time: 0.000
train | epoch   0 | Iter:   2643/156230 | global iter:   2643/156230 | loss: 1.0529 | ds_loss: 1.0607 | lr: 9.9931e-05 | scale: 16384.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   2644/156230 | global iter:   2644/156230 | loss: 1.2606 | ds_loss: 1.2448 | lr: 9.9930e-05 | scale: 16384.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2644/156230 | global iter:   2644/156230 | loss: 1.1746 | ds_loss: 1.1756 | lr: 9.9930e-05 | scale: 16384.0000 | micro time: 1.370 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2645/156230 | global iter:   2645/156230 | loss: 1.2600 | ds_loss: 1.2730 | lr: 9.9930e-05 | scale: 16384.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   2646/156230 | global iter:   2646/156230 | loss: 1.2916 | ds_loss: 1.2989 | lr: 9.9930e-05 | scale: 16384.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   2647/156230 | global iter:   2647/156230 | loss: 1.4843 | ds_loss: 1.4990 | lr: 9.9930e-05 | scale: 16384.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   2648/156230 | global iter:   2648/156230 | loss: 1.2706 | ds_loss: 1.2738 | lr: 9.9930e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2648/156230 | global iter:   2648/156230 | loss: 1.3266 | ds_loss: 1.3361 | lr: 9.9930e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2649/156230 | global iter:   2649/156230 | loss: 1.2315 | ds_loss: 1.2374 | lr: 9.9930e-05 | scale: 16384.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   2650/156230 | global iter:   2650/156230 | loss: 1.2028 | ds_loss: 1.2133 | lr: 9.9930e-05 | scale: 16384.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   2651/156230 | global iter:   2651/156230 | loss: 1.2390 | ds_loss: 1.2544 | lr: 9.9930e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   2652/156230 | global iter:   2652/156230 | loss: 1.0736 | ds_loss: 1.0785 | lr: 9.9930e-05 | scale: 16384.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2652/156230 | global iter:   2652/156230 | loss: 1.1867 | ds_loss: 1.1959 | lr: 9.9930e-05 | scale: 16384.0000 | micro time: 1.378 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2653/156230 | global iter:   2653/156230 | loss: 1.1770 | ds_loss: 1.1692 | lr: 9.9930e-05 | scale: 16384.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   2654/156230 | global iter:   2654/156230 | loss: 1.2063 | ds_loss: 1.2124 | lr: 9.9930e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   2655/156230 | global iter:   2655/156230 | loss: 0.9628 | ds_loss: 0.9821 | lr: 9.9930e-05 | scale: 16384.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   2656/156230 | global iter:   2656/156230 | loss: 0.9957 | ds_loss: 1.0220 | lr: 9.9930e-05 | scale: 16384.0000 | micro time: 1.344 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2656/156230 | global iter:   2656/156230 | loss: 1.0855 | ds_loss: 1.0964 | lr: 9.9930e-05 | scale: 16384.0000 | micro time: 1.344 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2657/156230 | global iter:   2657/156230 | loss: 1.2950 | ds_loss: 1.3074 | lr: 9.9930e-05 | scale: 16384.0000 | micro time: 1.424 | step time: 0.000
train | epoch   0 | Iter:   2658/156230 | global iter:   2658/156230 | loss: 1.0573 | ds_loss: 1.0723 | lr: 9.9930e-05 | scale: 16384.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   2659/156230 | global iter:   2659/156230 | loss: 1.2069 | ds_loss: 1.2235 | lr: 9.9930e-05 | scale: 16384.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   2660/156230 | global iter:   2660/156230 | loss: 1.0871 | ds_loss: 1.0860 | lr: 9.9930e-05 | scale: 16384.0000 | micro time: 1.429 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2660/156230 | global iter:   2660/156230 | loss: 1.1616 | ds_loss: 1.1723 | lr: 9.9930e-05 | scale: 16384.0000 | micro time: 1.429 | step time: 1.385
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2661/156230 | global iter:   2661/156230 | loss: 1.3554 | ds_loss: 1.3708 | lr: 9.9930e-05 | scale: 16384.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   2662/156230 | global iter:   2662/156230 | loss: 1.1609 | ds_loss: 1.1751 | lr: 9.9930e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   2663/156230 | global iter:   2663/156230 | loss: 1.1901 | ds_loss: 1.2035 | lr: 9.9929e-05 | scale: 16384.0000 | micro time: 1.404 | step time: 0.000
train | epoch   0 | Iter:   2664/156230 | global iter:   2664/156230 | loss: 1.2306 | ds_loss: 1.2284 | lr: 9.9929e-05 | scale: 16384.0000 | micro time: 1.325 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2664/156230 | global iter:   2664/156230 | loss: 1.2342 | ds_loss: 1.2445 | lr: 9.9929e-05 | scale: 16384.0000 | micro time: 1.325 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2665/156230 | global iter:   2665/156230 | loss: 1.2294 | ds_loss: 1.2309 | lr: 9.9929e-05 | scale: 16384.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   2666/156230 | global iter:   2666/156230 | loss: 1.2796 | ds_loss: 1.2650 | lr: 9.9929e-05 | scale: 16384.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   2667/156230 | global iter:   2667/156230 | loss: 1.1347 | ds_loss: 1.1414 | lr: 9.9929e-05 | scale: 16384.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   2668/156230 | global iter:   2668/156230 | loss: 1.0482 | ds_loss: 1.0573 | lr: 9.9929e-05 | scale: 16384.0000 | micro time: 1.327 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2668/156230 | global iter:   2668/156230 | loss: 1.1730 | ds_loss: 1.1737 | lr: 9.9929e-05 | scale: 16384.0000 | micro time: 1.327 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2669/156230 | global iter:   2669/156230 | loss: 1.2269 | ds_loss: 1.2324 | lr: 9.9929e-05 | scale: 16384.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   2670/156230 | global iter:   2670/156230 | loss: 1.1817 | ds_loss: 1.1918 | lr: 9.9929e-05 | scale: 16384.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   2671/156230 | global iter:   2671/156230 | loss: 1.0997 | ds_loss: 1.0999 | lr: 9.9929e-05 | scale: 16384.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   2672/156230 | global iter:   2672/156230 | loss: 1.1773 | ds_loss: 1.1682 | lr: 9.9929e-05 | scale: 16384.0000 | micro time: 1.343 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2672/156230 | global iter:   2672/156230 | loss: 1.1714 | ds_loss: 1.1731 | lr: 9.9929e-05 | scale: 16384.0000 | micro time: 1.343 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2673/156230 | global iter:   2673/156230 | loss: 1.2235 | ds_loss: 1.2480 | lr: 9.9929e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   2674/156230 | global iter:   2674/156230 | loss: 1.2456 | ds_loss: 1.2613 | lr: 9.9929e-05 | scale: 16384.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   2675/156230 | global iter:   2675/156230 | loss: 1.2267 | ds_loss: 1.2291 | lr: 9.9929e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   2676/156230 | global iter:   2676/156230 | loss: 1.0501 | ds_loss: 1.0605 | lr: 9.9929e-05 | scale: 16384.0000 | micro time: 1.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2676/156230 | global iter:   2676/156230 | loss: 1.1865 | ds_loss: 1.1997 | lr: 9.9929e-05 | scale: 16384.0000 | micro time: 1.399 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2677/156230 | global iter:   2677/156230 | loss: 1.0959 | ds_loss: 1.1149 | lr: 9.9929e-05 | scale: 16384.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   2678/156230 | global iter:   2678/156230 | loss: 1.0743 | ds_loss: 1.0992 | lr: 9.9929e-05 | scale: 16384.0000 | micro time: 1.317 | step time: 0.000
train | epoch   0 | Iter:   2679/156230 | global iter:   2679/156230 | loss: 1.1370 | ds_loss: 1.1515 | lr: 9.9929e-05 | scale: 16384.0000 | micro time: 1.401 | step time: 0.000
train | epoch   0 | Iter:   2680/156230 | global iter:   2680/156230 | loss: 1.2427 | ds_loss: 1.2584 | lr: 9.9929e-05 | scale: 16384.0000 | micro time: 1.367 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2680/156230 | global iter:   2680/156230 | loss: 1.1375 | ds_loss: 1.1560 | lr: 9.9929e-05 | scale: 16384.0000 | micro time: 1.367 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2681/156230 | global iter:   2681/156230 | loss: 0.9801 | ds_loss: 1.0024 | lr: 9.9929e-05 | scale: 16384.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   2682/156230 | global iter:   2682/156230 | loss: 1.2213 | ds_loss: 1.2221 | lr: 9.9928e-05 | scale: 16384.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   2683/156230 | global iter:   2683/156230 | loss: 1.2856 | ds_loss: 1.2873 | lr: 9.9928e-05 | scale: 16384.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   2684/156230 | global iter:   2684/156230 | loss: 1.1526 | ds_loss: 1.1597 | lr: 9.9928e-05 | scale: 16384.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2684/156230 | global iter:   2684/156230 | loss: 1.1599 | ds_loss: 1.1679 | lr: 9.9928e-05 | scale: 16384.0000 | micro time: 1.381 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2685/156230 | global iter:   2685/156230 | loss: 1.0717 | ds_loss: 1.0917 | lr: 9.9928e-05 | scale: 16384.0000 | micro time: 1.402 | step time: 0.000
train | epoch   0 | Iter:   2686/156230 | global iter:   2686/156230 | loss: 1.0768 | ds_loss: 1.0691 | lr: 9.9928e-05 | scale: 16384.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   2687/156230 | global iter:   2687/156230 | loss: 1.2741 | ds_loss: 1.2691 | lr: 9.9928e-05 | scale: 16384.0000 | micro time: 1.306 | step time: 0.000
train | epoch   0 | Iter:   2688/156230 | global iter:   2688/156230 | loss: 0.9971 | ds_loss: 1.0042 | lr: 9.9928e-05 | scale: 16384.0000 | micro time: 1.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2688/156230 | global iter:   2688/156230 | loss: 1.1049 | ds_loss: 1.1085 | lr: 9.9928e-05 | scale: 16384.0000 | micro time: 1.398 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2689/156230 | global iter:   2689/156230 | loss: 1.1505 | ds_loss: 1.1692 | lr: 9.9928e-05 | scale: 16384.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   2690/156230 | global iter:   2690/156230 | loss: 1.2640 | ds_loss: 1.2519 | lr: 9.9928e-05 | scale: 16384.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   2691/156230 | global iter:   2691/156230 | loss: 1.2184 | ds_loss: 1.2150 | lr: 9.9928e-05 | scale: 16384.0000 | micro time: 1.414 | step time: 0.000
train | epoch   0 | Iter:   2692/156230 | global iter:   2692/156230 | loss: 1.1172 | ds_loss: 1.1236 | lr: 9.9928e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2692/156230 | global iter:   2692/156230 | loss: 1.1875 | ds_loss: 1.1899 | lr: 9.9928e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2693/156230 | global iter:   2693/156230 | loss: 0.9755 | ds_loss: 0.9961 | lr: 9.9928e-05 | scale: 16384.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   2694/156230 | global iter:   2694/156230 | loss: 1.1939 | ds_loss: 1.1868 | lr: 9.9928e-05 | scale: 16384.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   2695/156230 | global iter:   2695/156230 | loss: 1.0805 | ds_loss: 1.0881 | lr: 9.9928e-05 | scale: 16384.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   2696/156230 | global iter:   2696/156230 | loss: 0.8804 | ds_loss: 0.9018 | lr: 9.9928e-05 | scale: 16384.0000 | micro time: 1.325 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2696/156230 | global iter:   2696/156230 | loss: 1.0326 | ds_loss: 1.0432 | lr: 9.9928e-05 | scale: 16384.0000 | micro time: 1.325 | step time: 1.341
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2697/156230 | global iter:   2697/156230 | loss: 1.1489 | ds_loss: 1.1623 | lr: 9.9928e-05 | scale: 16384.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   2698/156230 | global iter:   2698/156230 | loss: 1.1016 | ds_loss: 1.1060 | lr: 9.9928e-05 | scale: 16384.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   2699/156230 | global iter:   2699/156230 | loss: 1.3639 | ds_loss: 1.3552 | lr: 9.9928e-05 | scale: 16384.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   2700/156230 | global iter:   2700/156230 | loss: 1.1605 | ds_loss: 1.1569 | lr: 9.9927e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2700/156230 | global iter:   2700/156230 | loss: 1.1937 | ds_loss: 1.1951 | lr: 9.9927e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2701/156230 | global iter:   2701/156230 | loss: 1.0303 | ds_loss: 1.0295 | lr: 9.9927e-05 | scale: 16384.0000 | micro time: 1.318 | step time: 0.000
train | epoch   0 | Iter:   2702/156230 | global iter:   2702/156230 | loss: 1.2239 | ds_loss: 1.2423 | lr: 9.9927e-05 | scale: 16384.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   2703/156230 | global iter:   2703/156230 | loss: 1.1970 | ds_loss: 1.2107 | lr: 9.9927e-05 | scale: 16384.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   2704/156230 | global iter:   2704/156230 | loss: 1.1846 | ds_loss: 1.1978 | lr: 9.9927e-05 | scale: 16384.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2704/156230 | global iter:   2704/156230 | loss: 1.1589 | ds_loss: 1.1701 | lr: 9.9927e-05 | scale: 16384.0000 | micro time: 1.376 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2705/156230 | global iter:   2705/156230 | loss: 1.2361 | ds_loss: 1.2352 | lr: 9.9927e-05 | scale: 16384.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   2706/156230 | global iter:   2706/156230 | loss: 1.1534 | ds_loss: 1.1573 | lr: 9.9927e-05 | scale: 16384.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   2707/156230 | global iter:   2707/156230 | loss: 1.1727 | ds_loss: 1.1761 | lr: 9.9927e-05 | scale: 16384.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   2708/156230 | global iter:   2708/156230 | loss: 1.3707 | ds_loss: 1.3831 | lr: 9.9927e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2708/156230 | global iter:   2708/156230 | loss: 1.2332 | ds_loss: 1.2379 | lr: 9.9927e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2709/156230 | global iter:   2709/156230 | loss: 1.1905 | ds_loss: 1.2088 | lr: 9.9927e-05 | scale: 16384.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   2710/156230 | global iter:   2710/156230 | loss: 1.1843 | ds_loss: 1.1934 | lr: 9.9927e-05 | scale: 16384.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   2711/156230 | global iter:   2711/156230 | loss: 1.2512 | ds_loss: 1.2629 | lr: 9.9927e-05 | scale: 16384.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   2712/156230 | global iter:   2712/156230 | loss: 1.0319 | ds_loss: 1.0204 | lr: 9.9927e-05 | scale: 16384.0000 | micro time: 1.344 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2712/156230 | global iter:   2712/156230 | loss: 1.1645 | ds_loss: 1.1714 | lr: 9.9927e-05 | scale: 16384.0000 | micro time: 1.344 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2713/156230 | global iter:   2713/156230 | loss: 1.1501 | ds_loss: 1.1401 | lr: 9.9927e-05 | scale: 16384.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   2714/156230 | global iter:   2714/156230 | loss: 1.2655 | ds_loss: 1.2771 | lr: 9.9927e-05 | scale: 16384.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   2715/156230 | global iter:   2715/156230 | loss: 1.2590 | ds_loss: 1.2630 | lr: 9.9927e-05 | scale: 16384.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   2716/156230 | global iter:   2716/156230 | loss: 1.2004 | ds_loss: 1.2083 | lr: 9.9927e-05 | scale: 16384.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2716/156230 | global iter:   2716/156230 | loss: 1.2187 | ds_loss: 1.2221 | lr: 9.9927e-05 | scale: 16384.0000 | micro time: 1.349 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2717/156230 | global iter:   2717/156230 | loss: 1.0547 | ds_loss: 1.0480 | lr: 9.9927e-05 | scale: 16384.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   2718/156230 | global iter:   2718/156230 | loss: 1.1261 | ds_loss: 1.1426 | lr: 9.9927e-05 | scale: 16384.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   2719/156230 | global iter:   2719/156230 | loss: 1.1681 | ds_loss: 1.1751 | lr: 9.9926e-05 | scale: 16384.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   2720/156230 | global iter:   2720/156230 | loss: 1.1701 | ds_loss: 1.1827 | lr: 9.9926e-05 | scale: 16384.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2720/156230 | global iter:   2720/156230 | loss: 1.1297 | ds_loss: 1.1371 | lr: 9.9926e-05 | scale: 16384.0000 | micro time: 1.378 | step time: 1.345
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2721/156230 | global iter:   2721/156230 | loss: 1.2448 | ds_loss: 1.2479 | lr: 9.9926e-05 | scale: 16384.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   2722/156230 | global iter:   2722/156230 | loss: 1.2140 | ds_loss: 1.2238 | lr: 9.9926e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   2723/156230 | global iter:   2723/156230 | loss: 1.0476 | ds_loss: 1.0602 | lr: 9.9926e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   2724/156230 | global iter:   2724/156230 | loss: 1.1670 | ds_loss: 1.1860 | lr: 9.9926e-05 | scale: 16384.0000 | micro time: 1.408 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2724/156230 | global iter:   2724/156230 | loss: 1.1684 | ds_loss: 1.1795 | lr: 9.9926e-05 | scale: 16384.0000 | micro time: 1.408 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2725/156230 | global iter:   2725/156230 | loss: 1.1471 | ds_loss: 1.1528 | lr: 9.9926e-05 | scale: 16384.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   2726/156230 | global iter:   2726/156230 | loss: 1.2227 | ds_loss: 1.2413 | lr: 9.9926e-05 | scale: 16384.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   2727/156230 | global iter:   2727/156230 | loss: 1.2299 | ds_loss: 1.2255 | lr: 9.9926e-05 | scale: 16384.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   2728/156230 | global iter:   2728/156230 | loss: 1.1414 | ds_loss: 1.1410 | lr: 9.9926e-05 | scale: 16384.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2728/156230 | global iter:   2728/156230 | loss: 1.1853 | ds_loss: 1.1901 | lr: 9.9926e-05 | scale: 16384.0000 | micro time: 1.368 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2729/156230 | global iter:   2729/156230 | loss: 1.2702 | ds_loss: 1.2688 | lr: 9.9926e-05 | scale: 16384.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   2730/156230 | global iter:   2730/156230 | loss: 1.0975 | ds_loss: 1.0962 | lr: 9.9926e-05 | scale: 16384.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   2731/156230 | global iter:   2731/156230 | loss: 1.3802 | ds_loss: 1.3893 | lr: 9.9926e-05 | scale: 16384.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   2732/156230 | global iter:   2732/156230 | loss: 1.1374 | ds_loss: 1.1346 | lr: 9.9926e-05 | scale: 16384.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2732/156230 | global iter:   2732/156230 | loss: 1.2213 | ds_loss: 1.2222 | lr: 9.9926e-05 | scale: 16384.0000 | micro time: 1.345 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2733/156230 | global iter:   2733/156230 | loss: 1.0341 | ds_loss: 1.0395 | lr: 9.9926e-05 | scale: 16384.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   2734/156230 | global iter:   2734/156230 | loss: 1.2660 | ds_loss: 1.2697 | lr: 9.9926e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   2735/156230 | global iter:   2735/156230 | loss: 1.1354 | ds_loss: 1.1425 | lr: 9.9926e-05 | scale: 16384.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   2736/156230 | global iter:   2736/156230 | loss: 1.0466 | ds_loss: 1.0572 | lr: 9.9926e-05 | scale: 16384.0000 | micro time: 1.322 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2736/156230 | global iter:   2736/156230 | loss: 1.1205 | ds_loss: 1.1272 | lr: 9.9926e-05 | scale: 16384.0000 | micro time: 1.322 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2737/156230 | global iter:   2737/156230 | loss: 1.0457 | ds_loss: 1.0381 | lr: 9.9925e-05 | scale: 16384.0000 | micro time: 1.325 | step time: 0.000
train | epoch   0 | Iter:   2738/156230 | global iter:   2738/156230 | loss: 1.1710 | ds_loss: 1.1606 | lr: 9.9925e-05 | scale: 16384.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   2739/156230 | global iter:   2739/156230 | loss: 1.2864 | ds_loss: 1.2908 | lr: 9.9925e-05 | scale: 16384.0000 | micro time: 1.404 | step time: 0.000
train | epoch   0 | Iter:   2740/156230 | global iter:   2740/156230 | loss: 1.1397 | ds_loss: 1.1642 | lr: 9.9925e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2740/156230 | global iter:   2740/156230 | loss: 1.1607 | ds_loss: 1.1634 | lr: 9.9925e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2741/156230 | global iter:   2741/156230 | loss: 1.1043 | ds_loss: 1.1256 | lr: 9.9925e-05 | scale: 16384.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   2742/156230 | global iter:   2742/156230 | loss: 1.3441 | ds_loss: 1.3492 | lr: 9.9925e-05 | scale: 16384.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   2743/156230 | global iter:   2743/156230 | loss: 1.2314 | ds_loss: 1.2519 | lr: 9.9925e-05 | scale: 16384.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   2744/156230 | global iter:   2744/156230 | loss: 1.1670 | ds_loss: 1.1725 | lr: 9.9925e-05 | scale: 16384.0000 | micro time: 1.334 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2744/156230 | global iter:   2744/156230 | loss: 1.2117 | ds_loss: 1.2248 | lr: 9.9925e-05 | scale: 16384.0000 | micro time: 1.334 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2745/156230 | global iter:   2745/156230 | loss: 1.0296 | ds_loss: 1.0352 | lr: 9.9925e-05 | scale: 16384.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   2746/156230 | global iter:   2746/156230 | loss: 0.9738 | ds_loss: 0.9870 | lr: 9.9925e-05 | scale: 16384.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   2747/156230 | global iter:   2747/156230 | loss: 1.1248 | ds_loss: 1.1432 | lr: 9.9925e-05 | scale: 16384.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   2748/156230 | global iter:   2748/156230 | loss: 1.1848 | ds_loss: 1.1804 | lr: 9.9925e-05 | scale: 16384.0000 | micro time: 1.335 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2748/156230 | global iter:   2748/156230 | loss: 1.0782 | ds_loss: 1.0864 | lr: 9.9925e-05 | scale: 16384.0000 | micro time: 1.335 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2749/156230 | global iter:   2749/156230 | loss: 1.1754 | ds_loss: 1.1909 | lr: 9.9925e-05 | scale: 16384.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   2750/156230 | global iter:   2750/156230 | loss: 1.0548 | ds_loss: 1.0662 | lr: 9.9925e-05 | scale: 16384.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   2751/156230 | global iter:   2751/156230 | loss: 1.0238 | ds_loss: 1.0283 | lr: 9.9925e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   2752/156230 | global iter:   2752/156230 | loss: 1.2076 | ds_loss: 1.2094 | lr: 9.9925e-05 | scale: 16384.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2752/156230 | global iter:   2752/156230 | loss: 1.1154 | ds_loss: 1.1237 | lr: 9.9925e-05 | scale: 16384.0000 | micro time: 1.349 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2753/156230 | global iter:   2753/156230 | loss: 1.3013 | ds_loss: 1.2841 | lr: 9.9925e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   2754/156230 | global iter:   2754/156230 | loss: 1.0562 | ds_loss: 1.0627 | lr: 9.9925e-05 | scale: 16384.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   2755/156230 | global iter:   2755/156230 | loss: 1.2680 | ds_loss: 1.2880 | lr: 9.9924e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   2756/156230 | global iter:   2756/156230 | loss: 1.1797 | ds_loss: 1.1980 | lr: 9.9924e-05 | scale: 16384.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2756/156230 | global iter:   2756/156230 | loss: 1.2013 | ds_loss: 1.2082 | lr: 9.9924e-05 | scale: 16384.0000 | micro time: 1.350 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2757/156230 | global iter:   2757/156230 | loss: 1.0444 | ds_loss: 1.0731 | lr: 9.9924e-05 | scale: 16384.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   2758/156230 | global iter:   2758/156230 | loss: 1.1818 | ds_loss: 1.1976 | lr: 9.9924e-05 | scale: 16384.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   2759/156230 | global iter:   2759/156230 | loss: 1.1981 | ds_loss: 1.2057 | lr: 9.9924e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   2760/156230 | global iter:   2760/156230 | loss: 1.1491 | ds_loss: 1.1623 | lr: 9.9924e-05 | scale: 16384.0000 | micro time: 1.372 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2760/156230 | global iter:   2760/156230 | loss: 1.1433 | ds_loss: 1.1597 | lr: 9.9924e-05 | scale: 16384.0000 | micro time: 1.372 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2761/156230 | global iter:   2761/156230 | loss: 1.2149 | ds_loss: 1.2218 | lr: 9.9924e-05 | scale: 16384.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   2762/156230 | global iter:   2762/156230 | loss: 1.1751 | ds_loss: 1.1861 | lr: 9.9924e-05 | scale: 16384.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   2763/156230 | global iter:   2763/156230 | loss: 0.9819 | ds_loss: 0.9912 | lr: 9.9924e-05 | scale: 16384.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   2764/156230 | global iter:   2764/156230 | loss: 1.0970 | ds_loss: 1.1164 | lr: 9.9924e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2764/156230 | global iter:   2764/156230 | loss: 1.1172 | ds_loss: 1.1289 | lr: 9.9924e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2765/156230 | global iter:   2765/156230 | loss: 1.1407 | ds_loss: 1.1640 | lr: 9.9924e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   2766/156230 | global iter:   2766/156230 | loss: 0.8992 | ds_loss: 0.8898 | lr: 9.9924e-05 | scale: 16384.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   2767/156230 | global iter:   2767/156230 | loss: 1.2393 | ds_loss: 1.2561 | lr: 9.9924e-05 | scale: 16384.0000 | micro time: 1.414 | step time: 0.000
train | epoch   0 | Iter:   2768/156230 | global iter:   2768/156230 | loss: 1.2470 | ds_loss: 1.2690 | lr: 9.9924e-05 | scale: 16384.0000 | micro time: 1.380 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2768/156230 | global iter:   2768/156230 | loss: 1.1316 | ds_loss: 1.1447 | lr: 9.9924e-05 | scale: 16384.0000 | micro time: 1.380 | step time: 1.381
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2769/156230 | global iter:   2769/156230 | loss: 1.1072 | ds_loss: 1.1288 | lr: 9.9924e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   2770/156230 | global iter:   2770/156230 | loss: 1.3114 | ds_loss: 1.3019 | lr: 9.9924e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   2771/156230 | global iter:   2771/156230 | loss: 1.0626 | ds_loss: 1.0910 | lr: 9.9924e-05 | scale: 16384.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   2772/156230 | global iter:   2772/156230 | loss: 1.1344 | ds_loss: 1.1335 | lr: 9.9924e-05 | scale: 16384.0000 | micro time: 1.413 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2772/156230 | global iter:   2772/156230 | loss: 1.1539 | ds_loss: 1.1638 | lr: 9.9924e-05 | scale: 16384.0000 | micro time: 1.413 | step time: 1.379
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2773/156230 | global iter:   2773/156230 | loss: 1.0503 | ds_loss: 1.0649 | lr: 9.9923e-05 | scale: 16384.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   2774/156230 | global iter:   2774/156230 | loss: 1.1755 | ds_loss: 1.1855 | lr: 9.9923e-05 | scale: 16384.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   2775/156230 | global iter:   2775/156230 | loss: 1.1760 | ds_loss: 1.1746 | lr: 9.9923e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   2776/156230 | global iter:   2776/156230 | loss: 1.1281 | ds_loss: 1.1391 | lr: 9.9923e-05 | scale: 16384.0000 | micro time: 1.338 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2776/156230 | global iter:   2776/156230 | loss: 1.1325 | ds_loss: 1.1410 | lr: 9.9923e-05 | scale: 16384.0000 | micro time: 1.338 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2777/156230 | global iter:   2777/156230 | loss: 1.0849 | ds_loss: 1.0871 | lr: 9.9923e-05 | scale: 16384.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   2778/156230 | global iter:   2778/156230 | loss: 1.2546 | ds_loss: 1.2650 | lr: 9.9923e-05 | scale: 16384.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   2779/156230 | global iter:   2779/156230 | loss: 1.0146 | ds_loss: 1.0281 | lr: 9.9923e-05 | scale: 16384.0000 | micro time: 1.320 | step time: 0.000
train | epoch   0 | Iter:   2780/156230 | global iter:   2780/156230 | loss: 1.2083 | ds_loss: 1.2067 | lr: 9.9923e-05 | scale: 16384.0000 | micro time: 1.389 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2780/156230 | global iter:   2780/156230 | loss: 1.1406 | ds_loss: 1.1467 | lr: 9.9923e-05 | scale: 16384.0000 | micro time: 1.389 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2781/156230 | global iter:   2781/156230 | loss: 1.0971 | ds_loss: 1.1124 | lr: 9.9923e-05 | scale: 16384.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   2782/156230 | global iter:   2782/156230 | loss: 1.1336 | ds_loss: 1.1355 | lr: 9.9923e-05 | scale: 16384.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   2783/156230 | global iter:   2783/156230 | loss: 1.2836 | ds_loss: 1.2858 | lr: 9.9923e-05 | scale: 16384.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   2784/156230 | global iter:   2784/156230 | loss: 1.2127 | ds_loss: 1.2223 | lr: 9.9923e-05 | scale: 16384.0000 | micro time: 1.395 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2784/156230 | global iter:   2784/156230 | loss: 1.1817 | ds_loss: 1.1890 | lr: 9.9923e-05 | scale: 16384.0000 | micro time: 1.395 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2785/156230 | global iter:   2785/156230 | loss: 1.1407 | ds_loss: 1.1591 | lr: 9.9923e-05 | scale: 16384.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   2786/156230 | global iter:   2786/156230 | loss: 1.1528 | ds_loss: 1.1716 | lr: 9.9923e-05 | scale: 16384.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   2787/156230 | global iter:   2787/156230 | loss: 0.9249 | ds_loss: 0.9315 | lr: 9.9923e-05 | scale: 16384.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   2788/156230 | global iter:   2788/156230 | loss: 1.2677 | ds_loss: 1.2741 | lr: 9.9923e-05 | scale: 16384.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2788/156230 | global iter:   2788/156230 | loss: 1.1215 | ds_loss: 1.1341 | lr: 9.9923e-05 | scale: 16384.0000 | micro time: 1.378 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2789/156230 | global iter:   2789/156230 | loss: 1.1808 | ds_loss: 1.1862 | lr: 9.9923e-05 | scale: 16384.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   2790/156230 | global iter:   2790/156230 | loss: 1.2098 | ds_loss: 1.2310 | lr: 9.9923e-05 | scale: 16384.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   2791/156230 | global iter:   2791/156230 | loss: 1.1913 | ds_loss: 1.2000 | lr: 9.9922e-05 | scale: 16384.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   2792/156230 | global iter:   2792/156230 | loss: 1.0437 | ds_loss: 1.0458 | lr: 9.9922e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2792/156230 | global iter:   2792/156230 | loss: 1.1564 | ds_loss: 1.1658 | lr: 9.9922e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2793/156230 | global iter:   2793/156230 | loss: 1.1180 | ds_loss: 1.1285 | lr: 9.9922e-05 | scale: 16384.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   2794/156230 | global iter:   2794/156230 | loss: 1.1890 | ds_loss: 1.1999 | lr: 9.9922e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   2795/156230 | global iter:   2795/156230 | loss: 1.1637 | ds_loss: 1.1729 | lr: 9.9922e-05 | scale: 16384.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:   2796/156230 | global iter:   2796/156230 | loss: 1.0614 | ds_loss: 1.0761 | lr: 9.9922e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2796/156230 | global iter:   2796/156230 | loss: 1.1330 | ds_loss: 1.1444 | lr: 9.9922e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2797/156230 | global iter:   2797/156230 | loss: 1.0260 | ds_loss: 1.0179 | lr: 9.9922e-05 | scale: 16384.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   2798/156230 | global iter:   2798/156230 | loss: 1.1194 | ds_loss: 1.1370 | lr: 9.9922e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   2799/156230 | global iter:   2799/156230 | loss: 1.1612 | ds_loss: 1.1679 | lr: 9.9922e-05 | scale: 16384.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   2800/156230 | global iter:   2800/156230 | loss: 1.1462 | ds_loss: 1.1363 | lr: 9.9922e-05 | scale: 16384.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2800/156230 | global iter:   2800/156230 | loss: 1.1132 | ds_loss: 1.1148 | lr: 9.9922e-05 | scale: 16384.0000 | micro time: 1.353 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2801/156230 | global iter:   2801/156230 | loss: 1.1586 | ds_loss: 1.1793 | lr: 9.9922e-05 | scale: 16384.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   2802/156230 | global iter:   2802/156230 | loss: 1.1066 | ds_loss: 1.1085 | lr: 9.9922e-05 | scale: 16384.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   2803/156230 | global iter:   2803/156230 | loss: 1.1401 | ds_loss: 1.1375 | lr: 9.9922e-05 | scale: 16384.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   2804/156230 | global iter:   2804/156230 | loss: 1.3128 | ds_loss: 1.3195 | lr: 9.9922e-05 | scale: 16384.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2804/156230 | global iter:   2804/156230 | loss: 1.1795 | ds_loss: 1.1862 | lr: 9.9922e-05 | scale: 16384.0000 | micro time: 1.355 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2805/156230 | global iter:   2805/156230 | loss: 1.2540 | ds_loss: 1.2586 | lr: 9.9922e-05 | scale: 16384.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   2806/156230 | global iter:   2806/156230 | loss: 1.2281 | ds_loss: 1.2454 | lr: 9.9922e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   2807/156230 | global iter:   2807/156230 | loss: 1.2885 | ds_loss: 1.2903 | lr: 9.9922e-05 | scale: 16384.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   2808/156230 | global iter:   2808/156230 | loss: 1.0541 | ds_loss: 1.0721 | lr: 9.9922e-05 | scale: 16384.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2808/156230 | global iter:   2808/156230 | loss: 1.2062 | ds_loss: 1.2166 | lr: 9.9922e-05 | scale: 16384.0000 | micro time: 1.366 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2809/156230 | global iter:   2809/156230 | loss: 1.0815 | ds_loss: 1.0866 | lr: 9.9921e-05 | scale: 16384.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   2810/156230 | global iter:   2810/156230 | loss: 1.1883 | ds_loss: 1.1947 | lr: 9.9921e-05 | scale: 16384.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   2811/156230 | global iter:   2811/156230 | loss: 1.1028 | ds_loss: 1.1143 | lr: 9.9921e-05 | scale: 16384.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   2812/156230 | global iter:   2812/156230 | loss: 1.3199 | ds_loss: 1.3175 | lr: 9.9921e-05 | scale: 16384.0000 | micro time: 1.390 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2812/156230 | global iter:   2812/156230 | loss: 1.1731 | ds_loss: 1.1783 | lr: 9.9921e-05 | scale: 16384.0000 | micro time: 1.390 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2813/156230 | global iter:   2813/156230 | loss: 1.1206 | ds_loss: 1.1321 | lr: 9.9921e-05 | scale: 16384.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   2814/156230 | global iter:   2814/156230 | loss: 1.1155 | ds_loss: 1.1196 | lr: 9.9921e-05 | scale: 16384.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   2815/156230 | global iter:   2815/156230 | loss: 1.2530 | ds_loss: 1.2815 | lr: 9.9921e-05 | scale: 16384.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   2816/156230 | global iter:   2816/156230 | loss: 1.1947 | ds_loss: 1.2016 | lr: 9.9921e-05 | scale: 16384.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2816/156230 | global iter:   2816/156230 | loss: 1.1709 | ds_loss: 1.1837 | lr: 9.9921e-05 | scale: 16384.0000 | micro time: 1.370 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2817/156230 | global iter:   2817/156230 | loss: 1.2891 | ds_loss: 1.2981 | lr: 9.9921e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   2818/156230 | global iter:   2818/156230 | loss: 1.1880 | ds_loss: 1.1879 | lr: 9.9921e-05 | scale: 16384.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   2819/156230 | global iter:   2819/156230 | loss: 1.3204 | ds_loss: 1.3177 | lr: 9.9921e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   2820/156230 | global iter:   2820/156230 | loss: 1.0682 | ds_loss: 1.0748 | lr: 9.9921e-05 | scale: 16384.0000 | micro time: 1.346 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2820/156230 | global iter:   2820/156230 | loss: 1.2164 | ds_loss: 1.2196 | lr: 9.9921e-05 | scale: 16384.0000 | micro time: 1.346 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2821/156230 | global iter:   2821/156230 | loss: 1.3125 | ds_loss: 1.3195 | lr: 9.9921e-05 | scale: 16384.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   2822/156230 | global iter:   2822/156230 | loss: 1.1397 | ds_loss: 1.1300 | lr: 9.9921e-05 | scale: 16384.0000 | micro time: 1.400 | step time: 0.000
train | epoch   0 | Iter:   2823/156230 | global iter:   2823/156230 | loss: 0.9605 | ds_loss: 0.9774 | lr: 9.9921e-05 | scale: 16384.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   2824/156230 | global iter:   2824/156230 | loss: 1.1368 | ds_loss: 1.1393 | lr: 9.9921e-05 | scale: 16384.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2824/156230 | global iter:   2824/156230 | loss: 1.1374 | ds_loss: 1.1415 | lr: 9.9921e-05 | scale: 16384.0000 | micro time: 1.350 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2825/156230 | global iter:   2825/156230 | loss: 1.1206 | ds_loss: 1.1361 | lr: 9.9921e-05 | scale: 16384.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   2826/156230 | global iter:   2826/156230 | loss: 1.2354 | ds_loss: 1.2551 | lr: 9.9921e-05 | scale: 16384.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   2827/156230 | global iter:   2827/156230 | loss: 1.2245 | ds_loss: 1.2242 | lr: 9.9920e-05 | scale: 16384.0000 | micro time: 1.413 | step time: 0.000
train | epoch   0 | Iter:   2828/156230 | global iter:   2828/156230 | loss: 1.2952 | ds_loss: 1.3060 | lr: 9.9920e-05 | scale: 16384.0000 | micro time: 1.391 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2828/156230 | global iter:   2828/156230 | loss: 1.2189 | ds_loss: 1.2303 | lr: 9.9920e-05 | scale: 16384.0000 | micro time: 1.391 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2829/156230 | global iter:   2829/156230 | loss: 1.2895 | ds_loss: 1.2999 | lr: 9.9920e-05 | scale: 16384.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   2830/156230 | global iter:   2830/156230 | loss: 1.2098 | ds_loss: 1.2328 | lr: 9.9920e-05 | scale: 16384.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   2831/156230 | global iter:   2831/156230 | loss: 1.1432 | ds_loss: 1.1565 | lr: 9.9920e-05 | scale: 16384.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   2832/156230 | global iter:   2832/156230 | loss: 1.1616 | ds_loss: 1.1671 | lr: 9.9920e-05 | scale: 16384.0000 | micro time: 1.388 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2832/156230 | global iter:   2832/156230 | loss: 1.2010 | ds_loss: 1.2140 | lr: 9.9920e-05 | scale: 16384.0000 | micro time: 1.388 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2833/156230 | global iter:   2833/156230 | loss: 1.2563 | ds_loss: 1.2787 | lr: 9.9920e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   2834/156230 | global iter:   2834/156230 | loss: 1.3038 | ds_loss: 1.3153 | lr: 9.9920e-05 | scale: 16384.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   2835/156230 | global iter:   2835/156230 | loss: 1.1422 | ds_loss: 1.1633 | lr: 9.9920e-05 | scale: 16384.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   2836/156230 | global iter:   2836/156230 | loss: 1.0670 | ds_loss: 1.0862 | lr: 9.9920e-05 | scale: 16384.0000 | micro time: 1.383 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2836/156230 | global iter:   2836/156230 | loss: 1.1923 | ds_loss: 1.2109 | lr: 9.9920e-05 | scale: 16384.0000 | micro time: 1.383 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2837/156230 | global iter:   2837/156230 | loss: 1.3992 | ds_loss: 1.4170 | lr: 9.9920e-05 | scale: 16384.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   2838/156230 | global iter:   2838/156230 | loss: 1.1218 | ds_loss: 1.1172 | lr: 9.9920e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   2839/156230 | global iter:   2839/156230 | loss: 1.0922 | ds_loss: 1.1123 | lr: 9.9920e-05 | scale: 16384.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   2840/156230 | global iter:   2840/156230 | loss: 1.0801 | ds_loss: 1.0793 | lr: 9.9920e-05 | scale: 16384.0000 | micro time: 1.331 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2840/156230 | global iter:   2840/156230 | loss: 1.1733 | ds_loss: 1.1815 | lr: 9.9920e-05 | scale: 16384.0000 | micro time: 1.331 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2841/156230 | global iter:   2841/156230 | loss: 1.1138 | ds_loss: 1.1298 | lr: 9.9920e-05 | scale: 16384.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   2842/156230 | global iter:   2842/156230 | loss: 1.2954 | ds_loss: 1.2962 | lr: 9.9920e-05 | scale: 16384.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:   2843/156230 | global iter:   2843/156230 | loss: 1.1049 | ds_loss: 1.1055 | lr: 9.9920e-05 | scale: 16384.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   2844/156230 | global iter:   2844/156230 | loss: 1.1241 | ds_loss: 1.1358 | lr: 9.9919e-05 | scale: 16384.0000 | micro time: 1.317 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2844/156230 | global iter:   2844/156230 | loss: 1.1596 | ds_loss: 1.1668 | lr: 9.9919e-05 | scale: 16384.0000 | micro time: 1.317 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2845/156230 | global iter:   2845/156230 | loss: 1.1576 | ds_loss: 1.1817 | lr: 9.9919e-05 | scale: 16384.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   2846/156230 | global iter:   2846/156230 | loss: 1.1695 | ds_loss: 1.1970 | lr: 9.9919e-05 | scale: 16384.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   2847/156230 | global iter:   2847/156230 | loss: 1.1341 | ds_loss: 1.1561 | lr: 9.9919e-05 | scale: 16384.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   2848/156230 | global iter:   2848/156230 | loss: 1.2692 | ds_loss: 1.2785 | lr: 9.9919e-05 | scale: 16384.0000 | micro time: 1.391 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2848/156230 | global iter:   2848/156230 | loss: 1.1826 | ds_loss: 1.2033 | lr: 9.9919e-05 | scale: 16384.0000 | micro time: 1.391 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2849/156230 | global iter:   2849/156230 | loss: 1.1348 | ds_loss: 1.1475 | lr: 9.9919e-05 | scale: 16384.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   2850/156230 | global iter:   2850/156230 | loss: 1.3416 | ds_loss: 1.3550 | lr: 9.9919e-05 | scale: 16384.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   2851/156230 | global iter:   2851/156230 | loss: 1.0673 | ds_loss: 1.0661 | lr: 9.9919e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   2852/156230 | global iter:   2852/156230 | loss: 1.1742 | ds_loss: 1.1844 | lr: 9.9919e-05 | scale: 16384.0000 | micro time: 1.332 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2852/156230 | global iter:   2852/156230 | loss: 1.1795 | ds_loss: 1.1883 | lr: 9.9919e-05 | scale: 16384.0000 | micro time: 1.332 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2853/156230 | global iter:   2853/156230 | loss: 1.0961 | ds_loss: 1.0950 | lr: 9.9919e-05 | scale: 16384.0000 | micro time: 1.400 | step time: 0.000
train | epoch   0 | Iter:   2854/156230 | global iter:   2854/156230 | loss: 1.0100 | ds_loss: 1.0348 | lr: 9.9919e-05 | scale: 16384.0000 | micro time: 1.408 | step time: 0.000
train | epoch   0 | Iter:   2855/156230 | global iter:   2855/156230 | loss: 1.2078 | ds_loss: 1.2327 | lr: 9.9919e-05 | scale: 16384.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   2856/156230 | global iter:   2856/156230 | loss: 1.1214 | ds_loss: 1.1178 | lr: 9.9919e-05 | scale: 16384.0000 | micro time: 1.333 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2856/156230 | global iter:   2856/156230 | loss: 1.1088 | ds_loss: 1.1201 | lr: 9.9919e-05 | scale: 16384.0000 | micro time: 1.333 | step time: 1.381
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2857/156230 | global iter:   2857/156230 | loss: 1.1121 | ds_loss: 1.1027 | lr: 9.9919e-05 | scale: 16384.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   2858/156230 | global iter:   2858/156230 | loss: 1.1133 | ds_loss: 1.1151 | lr: 9.9919e-05 | scale: 16384.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   2859/156230 | global iter:   2859/156230 | loss: 1.3256 | ds_loss: 1.3391 | lr: 9.9919e-05 | scale: 16384.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   2860/156230 | global iter:   2860/156230 | loss: 1.1688 | ds_loss: 1.1885 | lr: 9.9919e-05 | scale: 16384.0000 | micro time: 1.372 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2860/156230 | global iter:   2860/156230 | loss: 1.1800 | ds_loss: 1.1863 | lr: 9.9919e-05 | scale: 16384.0000 | micro time: 1.372 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2861/156230 | global iter:   2861/156230 | loss: 1.0277 | ds_loss: 1.0429 | lr: 9.9919e-05 | scale: 16384.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   2862/156230 | global iter:   2862/156230 | loss: 1.1823 | ds_loss: 1.1795 | lr: 9.9918e-05 | scale: 16384.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   2863/156230 | global iter:   2863/156230 | loss: 1.2621 | ds_loss: 1.2761 | lr: 9.9918e-05 | scale: 16384.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   2864/156230 | global iter:   2864/156230 | loss: 1.1680 | ds_loss: 1.1937 | lr: 9.9918e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2864/156230 | global iter:   2864/156230 | loss: 1.1600 | ds_loss: 1.1730 | lr: 9.9918e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2865/156230 | global iter:   2865/156230 | loss: 1.1374 | ds_loss: 1.1490 | lr: 9.9918e-05 | scale: 16384.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   2866/156230 | global iter:   2866/156230 | loss: 1.1543 | ds_loss: 1.1901 | lr: 9.9918e-05 | scale: 16384.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   2867/156230 | global iter:   2867/156230 | loss: 1.0968 | ds_loss: 1.1000 | lr: 9.9918e-05 | scale: 16384.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   2868/156230 | global iter:   2868/156230 | loss: 1.3107 | ds_loss: 1.3154 | lr: 9.9918e-05 | scale: 16384.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2868/156230 | global iter:   2868/156230 | loss: 1.1748 | ds_loss: 1.1886 | lr: 9.9918e-05 | scale: 16384.0000 | micro time: 1.374 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2869/156230 | global iter:   2869/156230 | loss: 0.8896 | ds_loss: 0.8958 | lr: 9.9918e-05 | scale: 16384.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   2870/156230 | global iter:   2870/156230 | loss: 1.0913 | ds_loss: 1.0907 | lr: 9.9918e-05 | scale: 16384.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   2871/156230 | global iter:   2871/156230 | loss: 1.2355 | ds_loss: 1.2645 | lr: 9.9918e-05 | scale: 16384.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   2872/156230 | global iter:   2872/156230 | loss: 1.1444 | ds_loss: 1.1626 | lr: 9.9918e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2872/156230 | global iter:   2872/156230 | loss: 1.0902 | ds_loss: 1.1034 | lr: 9.9918e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2873/156230 | global iter:   2873/156230 | loss: 1.1944 | ds_loss: 1.1768 | lr: 9.9918e-05 | scale: 16384.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   2874/156230 | global iter:   2874/156230 | loss: 1.2779 | ds_loss: 1.2937 | lr: 9.9918e-05 | scale: 16384.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   2875/156230 | global iter:   2875/156230 | loss: 1.2098 | ds_loss: 1.2164 | lr: 9.9918e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   2876/156230 | global iter:   2876/156230 | loss: 1.1459 | ds_loss: 1.1579 | lr: 9.9918e-05 | scale: 16384.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2876/156230 | global iter:   2876/156230 | loss: 1.2070 | ds_loss: 1.2112 | lr: 9.9918e-05 | scale: 16384.0000 | micro time: 1.385 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2877/156230 | global iter:   2877/156230 | loss: 1.1843 | ds_loss: 1.2009 | lr: 9.9918e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   2878/156230 | global iter:   2878/156230 | loss: 1.0154 | ds_loss: 1.0081 | lr: 9.9918e-05 | scale: 16384.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   2879/156230 | global iter:   2879/156230 | loss: 1.1181 | ds_loss: 1.1202 | lr: 9.9917e-05 | scale: 16384.0000 | micro time: 1.416 | step time: 0.000
train | epoch   0 | Iter:   2880/156230 | global iter:   2880/156230 | loss: 1.3079 | ds_loss: 1.3119 | lr: 9.9917e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2880/156230 | global iter:   2880/156230 | loss: 1.1564 | ds_loss: 1.1603 | lr: 9.9917e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2881/156230 | global iter:   2881/156230 | loss: 1.0011 | ds_loss: 1.0093 | lr: 9.9917e-05 | scale: 16384.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   2882/156230 | global iter:   2882/156230 | loss: 1.2333 | ds_loss: 1.2505 | lr: 9.9917e-05 | scale: 16384.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   2883/156230 | global iter:   2883/156230 | loss: 1.1837 | ds_loss: 1.2053 | lr: 9.9917e-05 | scale: 16384.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   2884/156230 | global iter:   2884/156230 | loss: 1.1172 | ds_loss: 1.1317 | lr: 9.9917e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2884/156230 | global iter:   2884/156230 | loss: 1.1338 | ds_loss: 1.1492 | lr: 9.9917e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2885/156230 | global iter:   2885/156230 | loss: 1.0992 | ds_loss: 1.1026 | lr: 9.9917e-05 | scale: 16384.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   2886/156230 | global iter:   2886/156230 | loss: 1.1292 | ds_loss: 1.1411 | lr: 9.9917e-05 | scale: 16384.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   2887/156230 | global iter:   2887/156230 | loss: 1.0473 | ds_loss: 1.0677 | lr: 9.9917e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   2888/156230 | global iter:   2888/156230 | loss: 1.0118 | ds_loss: 1.0162 | lr: 9.9917e-05 | scale: 16384.0000 | micro time: 1.359 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2888/156230 | global iter:   2888/156230 | loss: 1.0719 | ds_loss: 1.0819 | lr: 9.9917e-05 | scale: 16384.0000 | micro time: 1.359 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2889/156230 | global iter:   2889/156230 | loss: 1.1615 | ds_loss: 1.1866 | lr: 9.9917e-05 | scale: 16384.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   2890/156230 | global iter:   2890/156230 | loss: 1.0743 | ds_loss: 1.0825 | lr: 9.9917e-05 | scale: 16384.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   2891/156230 | global iter:   2891/156230 | loss: 1.1608 | ds_loss: 1.1683 | lr: 9.9917e-05 | scale: 16384.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   2892/156230 | global iter:   2892/156230 | loss: 1.1887 | ds_loss: 1.1977 | lr: 9.9917e-05 | scale: 16384.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2892/156230 | global iter:   2892/156230 | loss: 1.1463 | ds_loss: 1.1588 | lr: 9.9917e-05 | scale: 16384.0000 | micro time: 1.363 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2893/156230 | global iter:   2893/156230 | loss: 1.0831 | ds_loss: 1.0885 | lr: 9.9917e-05 | scale: 16384.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   2894/156230 | global iter:   2894/156230 | loss: 1.1847 | ds_loss: 1.2046 | lr: 9.9917e-05 | scale: 16384.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   2895/156230 | global iter:   2895/156230 | loss: 1.0769 | ds_loss: 1.0940 | lr: 9.9917e-05 | scale: 16384.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   2896/156230 | global iter:   2896/156230 | loss: 1.1022 | ds_loss: 1.1051 | lr: 9.9916e-05 | scale: 16384.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2896/156230 | global iter:   2896/156230 | loss: 1.1117 | ds_loss: 1.1231 | lr: 9.9916e-05 | scale: 16384.0000 | micro time: 1.376 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2897/156230 | global iter:   2897/156230 | loss: 0.9678 | ds_loss: 0.9871 | lr: 9.9916e-05 | scale: 16384.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   2898/156230 | global iter:   2898/156230 | loss: 1.2008 | ds_loss: 1.2087 | lr: 9.9916e-05 | scale: 16384.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   2899/156230 | global iter:   2899/156230 | loss: 1.2066 | ds_loss: 1.2215 | lr: 9.9916e-05 | scale: 16384.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   2900/156230 | global iter:   2900/156230 | loss: 0.9131 | ds_loss: 0.9307 | lr: 9.9916e-05 | scale: 16384.0000 | micro time: 1.367 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2900/156230 | global iter:   2900/156230 | loss: 1.0721 | ds_loss: 1.0870 | lr: 9.9916e-05 | scale: 16384.0000 | micro time: 1.367 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2901/156230 | global iter:   2901/156230 | loss: 1.2587 | ds_loss: 1.2618 | lr: 9.9916e-05 | scale: 16384.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   2902/156230 | global iter:   2902/156230 | loss: 1.0589 | ds_loss: 1.0685 | lr: 9.9916e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   2903/156230 | global iter:   2903/156230 | loss: 1.1262 | ds_loss: 1.1454 | lr: 9.9916e-05 | scale: 16384.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   2904/156230 | global iter:   2904/156230 | loss: 1.1665 | ds_loss: 1.1943 | lr: 9.9916e-05 | scale: 16384.0000 | micro time: 1.356 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2904/156230 | global iter:   2904/156230 | loss: 1.1526 | ds_loss: 1.1675 | lr: 9.9916e-05 | scale: 16384.0000 | micro time: 1.356 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2905/156230 | global iter:   2905/156230 | loss: 1.3032 | ds_loss: 1.3117 | lr: 9.9916e-05 | scale: 16384.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   2906/156230 | global iter:   2906/156230 | loss: 1.1783 | ds_loss: 1.1730 | lr: 9.9916e-05 | scale: 16384.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   2907/156230 | global iter:   2907/156230 | loss: 1.2830 | ds_loss: 1.2827 | lr: 9.9916e-05 | scale: 16384.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   2908/156230 | global iter:   2908/156230 | loss: 1.1135 | ds_loss: 1.1249 | lr: 9.9916e-05 | scale: 16384.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2908/156230 | global iter:   2908/156230 | loss: 1.2195 | ds_loss: 1.2231 | lr: 9.9916e-05 | scale: 16384.0000 | micro time: 1.381 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2909/156230 | global iter:   2909/156230 | loss: 1.1649 | ds_loss: 1.1890 | lr: 9.9916e-05 | scale: 16384.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   2910/156230 | global iter:   2910/156230 | loss: 1.1067 | ds_loss: 1.1258 | lr: 9.9916e-05 | scale: 16384.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   2911/156230 | global iter:   2911/156230 | loss: 1.1589 | ds_loss: 1.1656 | lr: 9.9916e-05 | scale: 16384.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   2912/156230 | global iter:   2912/156230 | loss: 1.1208 | ds_loss: 1.1310 | lr: 9.9916e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2912/156230 | global iter:   2912/156230 | loss: 1.1378 | ds_loss: 1.1529 | lr: 9.9916e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2913/156230 | global iter:   2913/156230 | loss: 1.1580 | ds_loss: 1.1842 | lr: 9.9916e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   2914/156230 | global iter:   2914/156230 | loss: 1.1575 | ds_loss: 1.1709 | lr: 9.9915e-05 | scale: 16384.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   2915/156230 | global iter:   2915/156230 | loss: 1.3778 | ds_loss: 1.4024 | lr: 9.9915e-05 | scale: 16384.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   2916/156230 | global iter:   2916/156230 | loss: 1.2409 | ds_loss: 1.2466 | lr: 9.9915e-05 | scale: 16384.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2916/156230 | global iter:   2916/156230 | loss: 1.2335 | ds_loss: 1.2510 | lr: 9.9915e-05 | scale: 16384.0000 | micro time: 1.350 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2917/156230 | global iter:   2917/156230 | loss: 1.2040 | ds_loss: 1.2302 | lr: 9.9915e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   2918/156230 | global iter:   2918/156230 | loss: 1.1024 | ds_loss: 1.1195 | lr: 9.9915e-05 | scale: 16384.0000 | micro time: 1.415 | step time: 0.000
train | epoch   0 | Iter:   2919/156230 | global iter:   2919/156230 | loss: 1.2203 | ds_loss: 1.2350 | lr: 9.9915e-05 | scale: 16384.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   2920/156230 | global iter:   2920/156230 | loss: 0.9964 | ds_loss: 1.0111 | lr: 9.9915e-05 | scale: 16384.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2920/156230 | global iter:   2920/156230 | loss: 1.1308 | ds_loss: 1.1489 | lr: 9.9915e-05 | scale: 16384.0000 | micro time: 1.362 | step time: 1.379
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2921/156230 | global iter:   2921/156230 | loss: 1.1304 | ds_loss: 1.1287 | lr: 9.9915e-05 | scale: 16384.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   2922/156230 | global iter:   2922/156230 | loss: 1.1738 | ds_loss: 1.1674 | lr: 9.9915e-05 | scale: 16384.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   2923/156230 | global iter:   2923/156230 | loss: 1.2335 | ds_loss: 1.2522 | lr: 9.9915e-05 | scale: 16384.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   2924/156230 | global iter:   2924/156230 | loss: 1.1694 | ds_loss: 1.1790 | lr: 9.9915e-05 | scale: 16384.0000 | micro time: 1.344 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2924/156230 | global iter:   2924/156230 | loss: 1.1768 | ds_loss: 1.1818 | lr: 9.9915e-05 | scale: 16384.0000 | micro time: 1.344 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2925/156230 | global iter:   2925/156230 | loss: 1.1848 | ds_loss: 1.1891 | lr: 9.9915e-05 | scale: 16384.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   2926/156230 | global iter:   2926/156230 | loss: 1.1352 | ds_loss: 1.1495 | lr: 9.9915e-05 | scale: 16384.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   2927/156230 | global iter:   2927/156230 | loss: 1.2753 | ds_loss: 1.2934 | lr: 9.9915e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   2928/156230 | global iter:   2928/156230 | loss: 1.3827 | ds_loss: 1.3777 | lr: 9.9915e-05 | scale: 16384.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2928/156230 | global iter:   2928/156230 | loss: 1.2445 | ds_loss: 1.2524 | lr: 9.9915e-05 | scale: 16384.0000 | micro time: 1.370 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2929/156230 | global iter:   2929/156230 | loss: 1.1697 | ds_loss: 1.1784 | lr: 9.9915e-05 | scale: 16384.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   2930/156230 | global iter:   2930/156230 | loss: 1.2254 | ds_loss: 1.2281 | lr: 9.9915e-05 | scale: 16384.0000 | micro time: 1.408 | step time: 0.000
train | epoch   0 | Iter:   2931/156230 | global iter:   2931/156230 | loss: 1.1881 | ds_loss: 1.2068 | lr: 9.9914e-05 | scale: 16384.0000 | micro time: 1.321 | step time: 0.000
train | epoch   0 | Iter:   2932/156230 | global iter:   2932/156230 | loss: 1.2289 | ds_loss: 1.2396 | lr: 9.9914e-05 | scale: 16384.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2932/156230 | global iter:   2932/156230 | loss: 1.2030 | ds_loss: 1.2132 | lr: 9.9914e-05 | scale: 16384.0000 | micro time: 1.385 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2933/156230 | global iter:   2933/156230 | loss: 1.2863 | ds_loss: 1.2908 | lr: 9.9914e-05 | scale: 16384.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   2934/156230 | global iter:   2934/156230 | loss: 1.2734 | ds_loss: 1.2883 | lr: 9.9914e-05 | scale: 16384.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   2935/156230 | global iter:   2935/156230 | loss: 1.1220 | ds_loss: 1.1357 | lr: 9.9914e-05 | scale: 16384.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   2936/156230 | global iter:   2936/156230 | loss: 1.2401 | ds_loss: 1.2401 | lr: 9.9914e-05 | scale: 16384.0000 | micro time: 1.402 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2936/156230 | global iter:   2936/156230 | loss: 1.2305 | ds_loss: 1.2387 | lr: 9.9914e-05 | scale: 16384.0000 | micro time: 1.402 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2937/156230 | global iter:   2937/156230 | loss: 1.2215 | ds_loss: 1.2371 | lr: 9.9914e-05 | scale: 16384.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   2938/156230 | global iter:   2938/156230 | loss: 1.3346 | ds_loss: 1.3435 | lr: 9.9914e-05 | scale: 16384.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   2939/156230 | global iter:   2939/156230 | loss: 1.0978 | ds_loss: 1.1087 | lr: 9.9914e-05 | scale: 16384.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   2940/156230 | global iter:   2940/156230 | loss: 1.1188 | ds_loss: 1.1188 | lr: 9.9914e-05 | scale: 16384.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2940/156230 | global iter:   2940/156230 | loss: 1.1932 | ds_loss: 1.2020 | lr: 9.9914e-05 | scale: 16384.0000 | micro time: 1.349 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2941/156230 | global iter:   2941/156230 | loss: 1.1208 | ds_loss: 1.1248 | lr: 9.9914e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   2942/156230 | global iter:   2942/156230 | loss: 1.2018 | ds_loss: 1.2263 | lr: 9.9914e-05 | scale: 16384.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   2943/156230 | global iter:   2943/156230 | loss: 1.1082 | ds_loss: 1.1184 | lr: 9.9914e-05 | scale: 16384.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   2944/156230 | global iter:   2944/156230 | loss: 1.1296 | ds_loss: 1.1428 | lr: 9.9914e-05 | scale: 16384.0000 | micro time: 1.358 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2944/156230 | global iter:   2944/156230 | loss: 1.1401 | ds_loss: 1.1531 | lr: 9.9914e-05 | scale: 16384.0000 | micro time: 1.358 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2945/156230 | global iter:   2945/156230 | loss: 1.1008 | ds_loss: 1.1054 | lr: 9.9914e-05 | scale: 16384.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   2946/156230 | global iter:   2946/156230 | loss: 1.1288 | ds_loss: 1.1415 | lr: 9.9914e-05 | scale: 16384.0000 | micro time: 1.325 | step time: 0.000
train | epoch   0 | Iter:   2947/156230 | global iter:   2947/156230 | loss: 1.1040 | ds_loss: 1.1294 | lr: 9.9914e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   2948/156230 | global iter:   2948/156230 | loss: 1.2088 | ds_loss: 1.2236 | lr: 9.9913e-05 | scale: 16384.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2948/156230 | global iter:   2948/156230 | loss: 1.1356 | ds_loss: 1.1500 | lr: 9.9913e-05 | scale: 16384.0000 | micro time: 1.374 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2949/156230 | global iter:   2949/156230 | loss: 1.2222 | ds_loss: 1.2130 | lr: 9.9913e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   2950/156230 | global iter:   2950/156230 | loss: 1.2913 | ds_loss: 1.3098 | lr: 9.9913e-05 | scale: 16384.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   2951/156230 | global iter:   2951/156230 | loss: 1.3439 | ds_loss: 1.3337 | lr: 9.9913e-05 | scale: 16384.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   2952/156230 | global iter:   2952/156230 | loss: 1.1597 | ds_loss: 1.1726 | lr: 9.9913e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2952/156230 | global iter:   2952/156230 | loss: 1.2543 | ds_loss: 1.2573 | lr: 9.9913e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2953/156230 | global iter:   2953/156230 | loss: 1.0505 | ds_loss: 1.0620 | lr: 9.9913e-05 | scale: 16384.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   2954/156230 | global iter:   2954/156230 | loss: 1.1296 | ds_loss: 1.1524 | lr: 9.9913e-05 | scale: 16384.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   2955/156230 | global iter:   2955/156230 | loss: 1.2415 | ds_loss: 1.2496 | lr: 9.9913e-05 | scale: 16384.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   2956/156230 | global iter:   2956/156230 | loss: 1.1896 | ds_loss: 1.1879 | lr: 9.9913e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2956/156230 | global iter:   2956/156230 | loss: 1.1528 | ds_loss: 1.1629 | lr: 9.9913e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 1.348
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2957/156230 | global iter:   2957/156230 | loss: 1.0429 | ds_loss: 1.0479 | lr: 9.9913e-05 | scale: 16384.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   2958/156230 | global iter:   2958/156230 | loss: 1.0595 | ds_loss: 1.0780 | lr: 9.9913e-05 | scale: 16384.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   2959/156230 | global iter:   2959/156230 | loss: 1.2070 | ds_loss: 1.2046 | lr: 9.9913e-05 | scale: 16384.0000 | micro time: 1.410 | step time: 0.000
train | epoch   0 | Iter:   2960/156230 | global iter:   2960/156230 | loss: 0.9233 | ds_loss: 0.9268 | lr: 9.9913e-05 | scale: 16384.0000 | micro time: 1.341 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2960/156230 | global iter:   2960/156230 | loss: 1.0581 | ds_loss: 1.0643 | lr: 9.9913e-05 | scale: 16384.0000 | micro time: 1.341 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2961/156230 | global iter:   2961/156230 | loss: 1.1893 | ds_loss: 1.1918 | lr: 9.9913e-05 | scale: 16384.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   2962/156230 | global iter:   2962/156230 | loss: 1.0974 | ds_loss: 1.1047 | lr: 9.9913e-05 | scale: 16384.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   2963/156230 | global iter:   2963/156230 | loss: 1.2104 | ds_loss: 1.2064 | lr: 9.9913e-05 | scale: 16384.0000 | micro time: 1.425 | step time: 0.000
train | epoch   0 | Iter:   2964/156230 | global iter:   2964/156230 | loss: 1.0809 | ds_loss: 1.0912 | lr: 9.9912e-05 | scale: 16384.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2964/156230 | global iter:   2964/156230 | loss: 1.1445 | ds_loss: 1.1485 | lr: 9.9912e-05 | scale: 16384.0000 | micro time: 1.385 | step time: 1.387
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2965/156230 | global iter:   2965/156230 | loss: 1.1733 | ds_loss: 1.1776 | lr: 9.9912e-05 | scale: 16384.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   2966/156230 | global iter:   2966/156230 | loss: 1.0582 | ds_loss: 1.0651 | lr: 9.9912e-05 | scale: 16384.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   2967/156230 | global iter:   2967/156230 | loss: 1.1898 | ds_loss: 1.2082 | lr: 9.9912e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   2968/156230 | global iter:   2968/156230 | loss: 1.2698 | ds_loss: 1.2858 | lr: 9.9912e-05 | scale: 16384.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2968/156230 | global iter:   2968/156230 | loss: 1.1728 | ds_loss: 1.1842 | lr: 9.9912e-05 | scale: 16384.0000 | micro time: 1.353 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2969/156230 | global iter:   2969/156230 | loss: 1.1899 | ds_loss: 1.2079 | lr: 9.9912e-05 | scale: 16384.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   2970/156230 | global iter:   2970/156230 | loss: 0.9509 | ds_loss: 0.9721 | lr: 9.9912e-05 | scale: 16384.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   2971/156230 | global iter:   2971/156230 | loss: 1.2675 | ds_loss: 1.2743 | lr: 9.9912e-05 | scale: 16384.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   2972/156230 | global iter:   2972/156230 | loss: 1.0874 | ds_loss: 1.1022 | lr: 9.9912e-05 | scale: 16384.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2972/156230 | global iter:   2972/156230 | loss: 1.1239 | ds_loss: 1.1391 | lr: 9.9912e-05 | scale: 16384.0000 | micro time: 1.362 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2973/156230 | global iter:   2973/156230 | loss: 1.0581 | ds_loss: 1.0887 | lr: 9.9912e-05 | scale: 16384.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   2974/156230 | global iter:   2974/156230 | loss: 1.3228 | ds_loss: 1.3389 | lr: 9.9912e-05 | scale: 16384.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   2975/156230 | global iter:   2975/156230 | loss: 1.2017 | ds_loss: 1.2092 | lr: 9.9912e-05 | scale: 16384.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   2976/156230 | global iter:   2976/156230 | loss: 1.2119 | ds_loss: 1.2229 | lr: 9.9912e-05 | scale: 16384.0000 | micro time: 1.334 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2976/156230 | global iter:   2976/156230 | loss: 1.1986 | ds_loss: 1.2149 | lr: 9.9912e-05 | scale: 16384.0000 | micro time: 1.334 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2977/156230 | global iter:   2977/156230 | loss: 1.1929 | ds_loss: 1.2102 | lr: 9.9912e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   2978/156230 | global iter:   2978/156230 | loss: 1.0986 | ds_loss: 1.1047 | lr: 9.9912e-05 | scale: 16384.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   2979/156230 | global iter:   2979/156230 | loss: 1.0034 | ds_loss: 0.9997 | lr: 9.9912e-05 | scale: 16384.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   2980/156230 | global iter:   2980/156230 | loss: 1.1081 | ds_loss: 1.1196 | lr: 9.9912e-05 | scale: 16384.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2980/156230 | global iter:   2980/156230 | loss: 1.1008 | ds_loss: 1.1086 | lr: 9.9912e-05 | scale: 16384.0000 | micro time: 1.381 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2981/156230 | global iter:   2981/156230 | loss: 1.0442 | ds_loss: 1.0566 | lr: 9.9911e-05 | scale: 16384.0000 | micro time: 1.310 | step time: 0.000
train | epoch   0 | Iter:   2982/156230 | global iter:   2982/156230 | loss: 1.0107 | ds_loss: 1.0208 | lr: 9.9911e-05 | scale: 16384.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   2983/156230 | global iter:   2983/156230 | loss: 1.2570 | ds_loss: 1.2676 | lr: 9.9911e-05 | scale: 16384.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   2984/156230 | global iter:   2984/156230 | loss: 1.0077 | ds_loss: 1.0231 | lr: 9.9911e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2984/156230 | global iter:   2984/156230 | loss: 1.0799 | ds_loss: 1.0920 | lr: 9.9911e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 1.344
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2985/156230 | global iter:   2985/156230 | loss: 1.3145 | ds_loss: 1.3134 | lr: 9.9911e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   2986/156230 | global iter:   2986/156230 | loss: 1.2764 | ds_loss: 1.2593 | lr: 9.9911e-05 | scale: 16384.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   2987/156230 | global iter:   2987/156230 | loss: 1.1959 | ds_loss: 1.1936 | lr: 9.9911e-05 | scale: 16384.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   2988/156230 | global iter:   2988/156230 | loss: 1.1856 | ds_loss: 1.2001 | lr: 9.9911e-05 | scale: 16384.0000 | micro time: 1.328 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2988/156230 | global iter:   2988/156230 | loss: 1.2431 | ds_loss: 1.2416 | lr: 9.9911e-05 | scale: 16384.0000 | micro time: 1.328 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2989/156230 | global iter:   2989/156230 | loss: 1.3677 | ds_loss: 1.3877 | lr: 9.9911e-05 | scale: 16384.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   2990/156230 | global iter:   2990/156230 | loss: 1.0895 | ds_loss: 1.1115 | lr: 9.9911e-05 | scale: 16384.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   2991/156230 | global iter:   2991/156230 | loss: 1.1347 | ds_loss: 1.1461 | lr: 9.9911e-05 | scale: 16384.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   2992/156230 | global iter:   2992/156230 | loss: 1.1580 | ds_loss: 1.1728 | lr: 9.9911e-05 | scale: 16384.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2992/156230 | global iter:   2992/156230 | loss: 1.1875 | ds_loss: 1.2045 | lr: 9.9911e-05 | scale: 16384.0000 | micro time: 1.376 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2993/156230 | global iter:   2993/156230 | loss: 1.0398 | ds_loss: 1.0367 | lr: 9.9911e-05 | scale: 16384.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   2994/156230 | global iter:   2994/156230 | loss: 1.1987 | ds_loss: 1.1993 | lr: 9.9911e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   2995/156230 | global iter:   2995/156230 | loss: 1.2205 | ds_loss: 1.2420 | lr: 9.9911e-05 | scale: 16384.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   2996/156230 | global iter:   2996/156230 | loss: 1.1076 | ds_loss: 1.1182 | lr: 9.9911e-05 | scale: 16384.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   2996/156230 | global iter:   2996/156230 | loss: 1.1416 | ds_loss: 1.1491 | lr: 9.9911e-05 | scale: 16384.0000 | micro time: 1.381 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   2997/156230 | global iter:   2997/156230 | loss: 1.1551 | ds_loss: 1.1658 | lr: 9.9911e-05 | scale: 16384.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   2998/156230 | global iter:   2998/156230 | loss: 1.1470 | ds_loss: 1.1591 | lr: 9.9910e-05 | scale: 16384.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   2999/156230 | global iter:   2999/156230 | loss: 1.1314 | ds_loss: 1.1479 | lr: 9.9910e-05 | scale: 16384.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   3000/156230 | global iter:   3000/156230 | loss: 1.1968 | ds_loss: 1.2106 | lr: 9.9910e-05 | scale: 16384.0000 | micro time: 1.336 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3000/156230 | global iter:   3000/156230 | loss: 1.1576 | ds_loss: 1.1708 | lr: 9.9910e-05 | scale: 16384.0000 | micro time: 1.336 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3001/156230 | global iter:   3001/156230 | loss: 1.1660 | ds_loss: 1.1818 | lr: 9.9910e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   3002/156230 | global iter:   3002/156230 | loss: 0.9916 | ds_loss: 1.0104 | lr: 9.9910e-05 | scale: 16384.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   3003/156230 | global iter:   3003/156230 | loss: 1.1069 | ds_loss: 1.1073 | lr: 9.9910e-05 | scale: 16384.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   3004/156230 | global iter:   3004/156230 | loss: 1.2100 | ds_loss: 1.2035 | lr: 9.9910e-05 | scale: 16384.0000 | micro time: 1.334 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3004/156230 | global iter:   3004/156230 | loss: 1.1186 | ds_loss: 1.1258 | lr: 9.9910e-05 | scale: 16384.0000 | micro time: 1.334 | step time: 1.347
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3005/156230 | global iter:   3005/156230 | loss: 1.2335 | ds_loss: 1.2611 | lr: 9.9910e-05 | scale: 16384.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   3006/156230 | global iter:   3006/156230 | loss: 1.1199 | ds_loss: 1.1222 | lr: 9.9910e-05 | scale: 16384.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   3007/156230 | global iter:   3007/156230 | loss: 1.2382 | ds_loss: 1.2304 | lr: 9.9910e-05 | scale: 16384.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   3008/156230 | global iter:   3008/156230 | loss: 0.9604 | ds_loss: 0.9534 | lr: 9.9910e-05 | scale: 16384.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3008/156230 | global iter:   3008/156230 | loss: 1.1380 | ds_loss: 1.1418 | lr: 9.9910e-05 | scale: 16384.0000 | micro time: 1.354 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3009/156230 | global iter:   3009/156230 | loss: 1.1106 | ds_loss: 1.1139 | lr: 9.9910e-05 | scale: 16384.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   3010/156230 | global iter:   3010/156230 | loss: 1.1448 | ds_loss: 1.1538 | lr: 9.9910e-05 | scale: 16384.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   3011/156230 | global iter:   3011/156230 | loss: 1.1140 | ds_loss: 1.1322 | lr: 9.9910e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   3012/156230 | global iter:   3012/156230 | loss: 1.1276 | ds_loss: 1.1465 | lr: 9.9910e-05 | scale: 16384.0000 | micro time: 1.346 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3012/156230 | global iter:   3012/156230 | loss: 1.1243 | ds_loss: 1.1366 | lr: 9.9910e-05 | scale: 16384.0000 | micro time: 1.346 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3013/156230 | global iter:   3013/156230 | loss: 0.9545 | ds_loss: 0.9587 | lr: 9.9910e-05 | scale: 16384.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   3014/156230 | global iter:   3014/156230 | loss: 1.1399 | ds_loss: 1.1683 | lr: 9.9909e-05 | scale: 16384.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   3015/156230 | global iter:   3015/156230 | loss: 1.1976 | ds_loss: 1.2106 | lr: 9.9909e-05 | scale: 16384.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   3016/156230 | global iter:   3016/156230 | loss: 1.0380 | ds_loss: 1.0509 | lr: 9.9909e-05 | scale: 16384.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3016/156230 | global iter:   3016/156230 | loss: 1.0825 | ds_loss: 1.0971 | lr: 9.9909e-05 | scale: 16384.0000 | micro time: 1.366 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3017/156230 | global iter:   3017/156230 | loss: 0.8906 | ds_loss: 0.9160 | lr: 9.9909e-05 | scale: 16384.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   3018/156230 | global iter:   3018/156230 | loss: 1.2319 | ds_loss: 1.2496 | lr: 9.9909e-05 | scale: 16384.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   3019/156230 | global iter:   3019/156230 | loss: 1.2653 | ds_loss: 1.2731 | lr: 9.9909e-05 | scale: 16384.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   3020/156230 | global iter:   3020/156230 | loss: 1.3010 | ds_loss: 1.2924 | lr: 9.9909e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3020/156230 | global iter:   3020/156230 | loss: 1.1722 | ds_loss: 1.1828 | lr: 9.9909e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3021/156230 | global iter:   3021/156230 | loss: 1.2364 | ds_loss: 1.2481 | lr: 9.9909e-05 | scale: 32768.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   3022/156230 | global iter:   3022/156230 | loss: 1.1416 | ds_loss: 1.1663 | lr: 9.9909e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   3023/156230 | global iter:   3023/156230 | loss: 1.0328 | ds_loss: 1.0400 | lr: 9.9909e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   3024/156230 | global iter:   3024/156230 | loss: 1.2697 | ds_loss: 1.2928 | lr: 9.9909e-05 | scale: 32768.0000 | micro time: 1.319 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3024/156230 | global iter:   3024/156230 | loss: 1.1701 | ds_loss: 1.1868 | lr: 9.9909e-05 | scale: 32768.0000 | micro time: 1.319 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3025/156230 | global iter:   3025/156230 | loss: 1.2614 | ds_loss: 1.2656 | lr: 9.9909e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   3026/156230 | global iter:   3026/156230 | loss: 1.2245 | ds_loss: 1.2221 | lr: 9.9909e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   3027/156230 | global iter:   3027/156230 | loss: 1.2358 | ds_loss: 1.2509 | lr: 9.9909e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   3028/156230 | global iter:   3028/156230 | loss: 1.0370 | ds_loss: 1.0560 | lr: 9.9909e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3028/156230 | global iter:   3028/156230 | loss: 1.1897 | ds_loss: 1.1986 | lr: 9.9909e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3029/156230 | global iter:   3029/156230 | loss: 1.2337 | ds_loss: 1.2373 | lr: 9.9909e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   3030/156230 | global iter:   3030/156230 | loss: 1.3074 | ds_loss: 1.3105 | lr: 9.9909e-05 | scale: 32768.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   3031/156230 | global iter:   3031/156230 | loss: 1.2445 | ds_loss: 1.2535 | lr: 9.9908e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   3032/156230 | global iter:   3032/156230 | loss: 1.1682 | ds_loss: 1.1943 | lr: 9.9908e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3032/156230 | global iter:   3032/156230 | loss: 1.2385 | ds_loss: 1.2489 | lr: 9.9908e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3033/156230 | global iter:   3033/156230 | loss: 1.0583 | ds_loss: 1.0636 | lr: 9.9908e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   3034/156230 | global iter:   3034/156230 | loss: 1.1060 | ds_loss: 1.1003 | lr: 9.9908e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   3035/156230 | global iter:   3035/156230 | loss: 1.2090 | ds_loss: 1.2245 | lr: 9.9908e-05 | scale: 32768.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   3036/156230 | global iter:   3036/156230 | loss: 1.1293 | ds_loss: 1.1382 | lr: 9.9908e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3036/156230 | global iter:   3036/156230 | loss: 1.1257 | ds_loss: 1.1317 | lr: 9.9908e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3037/156230 | global iter:   3037/156230 | loss: 1.1269 | ds_loss: 1.1422 | lr: 9.9908e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   3038/156230 | global iter:   3038/156230 | loss: 1.1351 | ds_loss: 1.1375 | lr: 9.9908e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   3039/156230 | global iter:   3039/156230 | loss: 1.3001 | ds_loss: 1.3240 | lr: 9.9908e-05 | scale: 32768.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   3040/156230 | global iter:   3040/156230 | loss: 1.0486 | ds_loss: 1.0523 | lr: 9.9908e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3040/156230 | global iter:   3040/156230 | loss: 1.1527 | ds_loss: 1.1640 | lr: 9.9908e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3041/156230 | global iter:   3041/156230 | loss: 1.1104 | ds_loss: 1.1043 | lr: 9.9908e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   3042/156230 | global iter:   3042/156230 | loss: 1.0033 | ds_loss: 1.0202 | lr: 9.9908e-05 | scale: 32768.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   3043/156230 | global iter:   3043/156230 | loss: 1.1598 | ds_loss: 1.1783 | lr: 9.9908e-05 | scale: 32768.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   3044/156230 | global iter:   3044/156230 | loss: 1.0428 | ds_loss: 1.0456 | lr: 9.9908e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3044/156230 | global iter:   3044/156230 | loss: 1.0791 | ds_loss: 1.0871 | lr: 9.9908e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3045/156230 | global iter:   3045/156230 | loss: 1.0678 | ds_loss: 1.0636 | lr: 9.9908e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   3046/156230 | global iter:   3046/156230 | loss: 1.1537 | ds_loss: 1.1682 | lr: 9.9908e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   3047/156230 | global iter:   3047/156230 | loss: 1.0632 | ds_loss: 1.0673 | lr: 9.9907e-05 | scale: 32768.0000 | micro time: 1.402 | step time: 0.000
train | epoch   0 | Iter:   3048/156230 | global iter:   3048/156230 | loss: 1.1165 | ds_loss: 1.1281 | lr: 9.9907e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3048/156230 | global iter:   3048/156230 | loss: 1.1003 | ds_loss: 1.1068 | lr: 9.9907e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3049/156230 | global iter:   3049/156230 | loss: 1.2677 | ds_loss: 1.2678 | lr: 9.9907e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   3050/156230 | global iter:   3050/156230 | loss: 1.0768 | ds_loss: 1.0707 | lr: 9.9907e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   3051/156230 | global iter:   3051/156230 | loss: 1.1450 | ds_loss: 1.1631 | lr: 9.9907e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   3052/156230 | global iter:   3052/156230 | loss: 1.1737 | ds_loss: 1.2034 | lr: 9.9907e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3052/156230 | global iter:   3052/156230 | loss: 1.1658 | ds_loss: 1.1763 | lr: 9.9907e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3053/156230 | global iter:   3053/156230 | loss: 0.9975 | ds_loss: 1.0126 | lr: 9.9907e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   3054/156230 | global iter:   3054/156230 | loss: 1.1844 | ds_loss: 1.1925 | lr: 9.9907e-05 | scale: 32768.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   3055/156230 | global iter:   3055/156230 | loss: 0.9548 | ds_loss: 0.9610 | lr: 9.9907e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   3056/156230 | global iter:   3056/156230 | loss: 1.1608 | ds_loss: 1.1704 | lr: 9.9907e-05 | scale: 32768.0000 | micro time: 1.329 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3056/156230 | global iter:   3056/156230 | loss: 1.0744 | ds_loss: 1.0841 | lr: 9.9907e-05 | scale: 32768.0000 | micro time: 1.329 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3057/156230 | global iter:   3057/156230 | loss: 0.9891 | ds_loss: 0.9936 | lr: 9.9907e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   3058/156230 | global iter:   3058/156230 | loss: 1.1120 | ds_loss: 1.1239 | lr: 9.9907e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   3059/156230 | global iter:   3059/156230 | loss: 1.1784 | ds_loss: 1.1805 | lr: 9.9907e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   3060/156230 | global iter:   3060/156230 | loss: 1.1835 | ds_loss: 1.1823 | lr: 9.9907e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3060/156230 | global iter:   3060/156230 | loss: 1.1158 | ds_loss: 1.1201 | lr: 9.9907e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3061/156230 | global iter:   3061/156230 | loss: 1.1322 | ds_loss: 1.1352 | lr: 9.9907e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   3062/156230 | global iter:   3062/156230 | loss: 1.0843 | ds_loss: 1.0913 | lr: 9.9907e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   3063/156230 | global iter:   3063/156230 | loss: 1.1902 | ds_loss: 1.2048 | lr: 9.9907e-05 | scale: 32768.0000 | micro time: 1.318 | step time: 0.000
train | epoch   0 | Iter:   3064/156230 | global iter:   3064/156230 | loss: 1.2178 | ds_loss: 1.2396 | lr: 9.9906e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3064/156230 | global iter:   3064/156230 | loss: 1.1561 | ds_loss: 1.1677 | lr: 9.9906e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3065/156230 | global iter:   3065/156230 | loss: 1.3206 | ds_loss: 1.3449 | lr: 9.9906e-05 | scale: 32768.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   3066/156230 | global iter:   3066/156230 | loss: 1.1149 | ds_loss: 1.1515 | lr: 9.9906e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   3067/156230 | global iter:   3067/156230 | loss: 1.1216 | ds_loss: 1.1334 | lr: 9.9906e-05 | scale: 32768.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   3068/156230 | global iter:   3068/156230 | loss: 1.1633 | ds_loss: 1.1659 | lr: 9.9906e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3068/156230 | global iter:   3068/156230 | loss: 1.1801 | ds_loss: 1.1989 | lr: 9.9906e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3069/156230 | global iter:   3069/156230 | loss: 1.2525 | ds_loss: 1.2565 | lr: 9.9906e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   3070/156230 | global iter:   3070/156230 | loss: 1.2825 | ds_loss: 1.2813 | lr: 9.9906e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   3071/156230 | global iter:   3071/156230 | loss: 1.1008 | ds_loss: 1.1258 | lr: 9.9906e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   3072/156230 | global iter:   3072/156230 | loss: 1.1421 | ds_loss: 1.1333 | lr: 9.9906e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3072/156230 | global iter:   3072/156230 | loss: 1.1945 | ds_loss: 1.1992 | lr: 9.9906e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3073/156230 | global iter:   3073/156230 | loss: 1.1473 | ds_loss: 1.1705 | lr: 9.9906e-05 | scale: 32768.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   3074/156230 | global iter:   3074/156230 | loss: 1.1252 | ds_loss: 1.1397 | lr: 9.9906e-05 | scale: 32768.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   3075/156230 | global iter:   3075/156230 | loss: 1.1807 | ds_loss: 1.1858 | lr: 9.9906e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   3076/156230 | global iter:   3076/156230 | loss: 1.1888 | ds_loss: 1.2153 | lr: 9.9906e-05 | scale: 32768.0000 | micro time: 1.339 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3076/156230 | global iter:   3076/156230 | loss: 1.1605 | ds_loss: 1.1778 | lr: 9.9906e-05 | scale: 32768.0000 | micro time: 1.339 | step time: 1.345
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3077/156230 | global iter:   3077/156230 | loss: 1.1223 | ds_loss: 1.1372 | lr: 9.9906e-05 | scale: 32768.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   3078/156230 | global iter:   3078/156230 | loss: 1.2548 | ds_loss: 1.2709 | lr: 9.9906e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   3079/156230 | global iter:   3079/156230 | loss: 1.2285 | ds_loss: 1.2488 | lr: 9.9906e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   3080/156230 | global iter:   3080/156230 | loss: 1.2128 | ds_loss: 1.2247 | lr: 9.9905e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3080/156230 | global iter:   3080/156230 | loss: 1.2046 | ds_loss: 1.2204 | lr: 9.9905e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3081/156230 | global iter:   3081/156230 | loss: 0.9554 | ds_loss: 0.9663 | lr: 9.9905e-05 | scale: 32768.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:   3082/156230 | global iter:   3082/156230 | loss: 1.3390 | ds_loss: 1.3441 | lr: 9.9905e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   3083/156230 | global iter:   3083/156230 | loss: 1.0097 | ds_loss: 1.0016 | lr: 9.9905e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   3084/156230 | global iter:   3084/156230 | loss: 1.1124 | ds_loss: 1.1272 | lr: 9.9905e-05 | scale: 32768.0000 | micro time: 1.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3084/156230 | global iter:   3084/156230 | loss: 1.1041 | ds_loss: 1.1098 | lr: 9.9905e-05 | scale: 32768.0000 | micro time: 1.397 | step time: 1.379
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3085/156230 | global iter:   3085/156230 | loss: 1.1793 | ds_loss: 1.1793 | lr: 9.9905e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   3086/156230 | global iter:   3086/156230 | loss: 1.0611 | ds_loss: 1.0715 | lr: 9.9905e-05 | scale: 32768.0000 | micro time: 1.404 | step time: 0.000
train | epoch   0 | Iter:   3087/156230 | global iter:   3087/156230 | loss: 1.2154 | ds_loss: 1.2187 | lr: 9.9905e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   3088/156230 | global iter:   3088/156230 | loss: 0.9745 | ds_loss: 0.9897 | lr: 9.9905e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3088/156230 | global iter:   3088/156230 | loss: 1.1076 | ds_loss: 1.1148 | lr: 9.9905e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3089/156230 | global iter:   3089/156230 | loss: 1.1164 | ds_loss: 1.1335 | lr: 9.9905e-05 | scale: 32768.0000 | micro time: 1.321 | step time: 0.000
train | epoch   0 | Iter:   3090/156230 | global iter:   3090/156230 | loss: 1.1405 | ds_loss: 1.1485 | lr: 9.9905e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   3091/156230 | global iter:   3091/156230 | loss: 1.2391 | ds_loss: 1.2418 | lr: 9.9905e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   3092/156230 | global iter:   3092/156230 | loss: 1.1896 | ds_loss: 1.1959 | lr: 9.9905e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3092/156230 | global iter:   3092/156230 | loss: 1.1714 | ds_loss: 1.1799 | lr: 9.9905e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 1.347
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3093/156230 | global iter:   3093/156230 | loss: 1.1145 | ds_loss: 1.1359 | lr: 9.9905e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   3094/156230 | global iter:   3094/156230 | loss: 1.3477 | ds_loss: 1.3394 | lr: 9.9905e-05 | scale: 32768.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   3095/156230 | global iter:   3095/156230 | loss: 1.1161 | ds_loss: 1.1402 | lr: 9.9905e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   3096/156230 | global iter:   3096/156230 | loss: 1.0331 | ds_loss: 1.0556 | lr: 9.9904e-05 | scale: 32768.0000 | micro time: 1.331 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3096/156230 | global iter:   3096/156230 | loss: 1.1529 | ds_loss: 1.1678 | lr: 9.9904e-05 | scale: 32768.0000 | micro time: 1.331 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3097/156230 | global iter:   3097/156230 | loss: 1.2808 | ds_loss: 1.2884 | lr: 9.9904e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   3098/156230 | global iter:   3098/156230 | loss: 1.0085 | ds_loss: 1.0188 | lr: 9.9904e-05 | scale: 32768.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   3099/156230 | global iter:   3099/156230 | loss: 1.1050 | ds_loss: 1.1151 | lr: 9.9904e-05 | scale: 32768.0000 | micro time: 1.403 | step time: 0.000
train | epoch   0 | Iter:   3100/156230 | global iter:   3100/156230 | loss: 1.1416 | ds_loss: 1.1368 | lr: 9.9904e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3100/156230 | global iter:   3100/156230 | loss: 1.1340 | ds_loss: 1.1398 | lr: 9.9904e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3101/156230 | global iter:   3101/156230 | loss: 1.2551 | ds_loss: 1.2660 | lr: 9.9904e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   3102/156230 | global iter:   3102/156230 | loss: 1.1324 | ds_loss: 1.1323 | lr: 9.9904e-05 | scale: 32768.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   3103/156230 | global iter:   3103/156230 | loss: 1.1220 | ds_loss: 1.1163 | lr: 9.9904e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   3104/156230 | global iter:   3104/156230 | loss: 1.1325 | ds_loss: 1.1437 | lr: 9.9904e-05 | scale: 32768.0000 | micro time: 1.333 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3104/156230 | global iter:   3104/156230 | loss: 1.1605 | ds_loss: 1.1646 | lr: 9.9904e-05 | scale: 32768.0000 | micro time: 1.333 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3105/156230 | global iter:   3105/156230 | loss: 1.2939 | ds_loss: 1.2989 | lr: 9.9904e-05 | scale: 32768.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   3106/156230 | global iter:   3106/156230 | loss: 1.1273 | ds_loss: 1.1268 | lr: 9.9904e-05 | scale: 32768.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   3107/156230 | global iter:   3107/156230 | loss: 1.2771 | ds_loss: 1.2855 | lr: 9.9904e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   3108/156230 | global iter:   3108/156230 | loss: 1.1184 | ds_loss: 1.1442 | lr: 9.9904e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3108/156230 | global iter:   3108/156230 | loss: 1.2042 | ds_loss: 1.2139 | lr: 9.9904e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3109/156230 | global iter:   3109/156230 | loss: 1.2950 | ds_loss: 1.3055 | lr: 9.9904e-05 | scale: 32768.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   3110/156230 | global iter:   3110/156230 | loss: 1.0617 | ds_loss: 1.0515 | lr: 9.9904e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   3111/156230 | global iter:   3111/156230 | loss: 1.0093 | ds_loss: 1.0276 | lr: 9.9904e-05 | scale: 32768.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:   3112/156230 | global iter:   3112/156230 | loss: 1.0496 | ds_loss: 1.0528 | lr: 9.9903e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3112/156230 | global iter:   3112/156230 | loss: 1.1039 | ds_loss: 1.1094 | lr: 9.9903e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3113/156230 | global iter:   3113/156230 | loss: 1.2584 | ds_loss: 1.2657 | lr: 9.9903e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   3114/156230 | global iter:   3114/156230 | loss: 1.1910 | ds_loss: 1.2071 | lr: 9.9903e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   3115/156230 | global iter:   3115/156230 | loss: 1.1636 | ds_loss: 1.1670 | lr: 9.9903e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   3116/156230 | global iter:   3116/156230 | loss: 1.3754 | ds_loss: 1.3786 | lr: 9.9903e-05 | scale: 32768.0000 | micro time: 1.386 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3116/156230 | global iter:   3116/156230 | loss: 1.2471 | ds_loss: 1.2546 | lr: 9.9903e-05 | scale: 32768.0000 | micro time: 1.386 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3117/156230 | global iter:   3117/156230 | loss: 1.2119 | ds_loss: 1.2242 | lr: 9.9903e-05 | scale: 32768.0000 | micro time: 1.444 | step time: 0.000
train | epoch   0 | Iter:   3118/156230 | global iter:   3118/156230 | loss: 0.9635 | ds_loss: 0.9893 | lr: 9.9903e-05 | scale: 32768.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   3119/156230 | global iter:   3119/156230 | loss: 1.2691 | ds_loss: 1.2728 | lr: 9.9903e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   3120/156230 | global iter:   3120/156230 | loss: 1.3628 | ds_loss: 1.3703 | lr: 9.9903e-05 | scale: 32768.0000 | micro time: 1.413 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3120/156230 | global iter:   3120/156230 | loss: 1.2018 | ds_loss: 1.2141 | lr: 9.9903e-05 | scale: 32768.0000 | micro time: 1.413 | step time: 1.390
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3121/156230 | global iter:   3121/156230 | loss: 1.0843 | ds_loss: 1.0938 | lr: 9.9903e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   3122/156230 | global iter:   3122/156230 | loss: 1.0565 | ds_loss: 1.0584 | lr: 9.9903e-05 | scale: 32768.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   3123/156230 | global iter:   3123/156230 | loss: 1.2343 | ds_loss: 1.2415 | lr: 9.9903e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   3124/156230 | global iter:   3124/156230 | loss: 1.0206 | ds_loss: 1.0248 | lr: 9.9903e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3124/156230 | global iter:   3124/156230 | loss: 1.0989 | ds_loss: 1.1046 | lr: 9.9903e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3125/156230 | global iter:   3125/156230 | loss: 0.9747 | ds_loss: 0.9890 | lr: 9.9903e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   3126/156230 | global iter:   3126/156230 | loss: 1.2592 | ds_loss: 1.2693 | lr: 9.9903e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   3127/156230 | global iter:   3127/156230 | loss: 1.4030 | ds_loss: 1.4146 | lr: 9.9903e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   3128/156230 | global iter:   3128/156230 | loss: 1.2053 | ds_loss: 1.2169 | lr: 9.9902e-05 | scale: 32768.0000 | micro time: 1.391 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3128/156230 | global iter:   3128/156230 | loss: 1.2105 | ds_loss: 1.2224 | lr: 9.9902e-05 | scale: 32768.0000 | micro time: 1.391 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3129/156230 | global iter:   3129/156230 | loss: 1.2777 | ds_loss: 1.2911 | lr: 9.9902e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   3130/156230 | global iter:   3130/156230 | loss: 1.1487 | ds_loss: 1.1561 | lr: 9.9902e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   3131/156230 | global iter:   3131/156230 | loss: 1.4370 | ds_loss: 1.4526 | lr: 9.9902e-05 | scale: 32768.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:   3132/156230 | global iter:   3132/156230 | loss: 1.2940 | ds_loss: 1.3235 | lr: 9.9902e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3132/156230 | global iter:   3132/156230 | loss: 1.2893 | ds_loss: 1.3058 | lr: 9.9902e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3133/156230 | global iter:   3133/156230 | loss: 1.1418 | ds_loss: 1.1503 | lr: 9.9902e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   3134/156230 | global iter:   3134/156230 | loss: 1.1779 | ds_loss: 1.1944 | lr: 9.9902e-05 | scale: 32768.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   3135/156230 | global iter:   3135/156230 | loss: 1.0219 | ds_loss: 1.0221 | lr: 9.9902e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   3136/156230 | global iter:   3136/156230 | loss: 1.1365 | ds_loss: 1.1379 | lr: 9.9902e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3136/156230 | global iter:   3136/156230 | loss: 1.1195 | ds_loss: 1.1262 | lr: 9.9902e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3137/156230 | global iter:   3137/156230 | loss: 1.2432 | ds_loss: 1.2590 | lr: 9.9902e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   3138/156230 | global iter:   3138/156230 | loss: 1.2074 | ds_loss: 1.2132 | lr: 9.9902e-05 | scale: 32768.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   3139/156230 | global iter:   3139/156230 | loss: 1.0297 | ds_loss: 1.0303 | lr: 9.9902e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   3140/156230 | global iter:   3140/156230 | loss: 1.1938 | ds_loss: 1.2016 | lr: 9.9902e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3140/156230 | global iter:   3140/156230 | loss: 1.1686 | ds_loss: 1.1760 | lr: 9.9902e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3141/156230 | global iter:   3141/156230 | loss: 1.2919 | ds_loss: 1.2961 | lr: 9.9902e-05 | scale: 32768.0000 | micro time: 1.419 | step time: 0.000
train | epoch   0 | Iter:   3142/156230 | global iter:   3142/156230 | loss: 0.9870 | ds_loss: 1.0047 | lr: 9.9902e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   3143/156230 | global iter:   3143/156230 | loss: 1.2319 | ds_loss: 1.2521 | lr: 9.9902e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   3144/156230 | global iter:   3144/156230 | loss: 1.1309 | ds_loss: 1.1319 | lr: 9.9901e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3144/156230 | global iter:   3144/156230 | loss: 1.1604 | ds_loss: 1.1712 | lr: 9.9901e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3145/156230 | global iter:   3145/156230 | loss: 1.1825 | ds_loss: 1.1900 | lr: 9.9901e-05 | scale: 32768.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   3146/156230 | global iter:   3146/156230 | loss: 1.0491 | ds_loss: 1.0692 | lr: 9.9901e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   3147/156230 | global iter:   3147/156230 | loss: 1.2275 | ds_loss: 1.2506 | lr: 9.9901e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   3148/156230 | global iter:   3148/156230 | loss: 1.1475 | ds_loss: 1.1530 | lr: 9.9901e-05 | scale: 32768.0000 | micro time: 1.328 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3148/156230 | global iter:   3148/156230 | loss: 1.1516 | ds_loss: 1.1657 | lr: 9.9901e-05 | scale: 32768.0000 | micro time: 1.328 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3149/156230 | global iter:   3149/156230 | loss: 1.0028 | ds_loss: 1.0021 | lr: 9.9901e-05 | scale: 32768.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   3150/156230 | global iter:   3150/156230 | loss: 1.1822 | ds_loss: 1.2015 | lr: 9.9901e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   3151/156230 | global iter:   3151/156230 | loss: 1.2215 | ds_loss: 1.2278 | lr: 9.9901e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   3152/156230 | global iter:   3152/156230 | loss: 1.2076 | ds_loss: 1.2273 | lr: 9.9901e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3152/156230 | global iter:   3152/156230 | loss: 1.1535 | ds_loss: 1.1647 | lr: 9.9901e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3153/156230 | global iter:   3153/156230 | loss: 1.0960 | ds_loss: 1.1041 | lr: 9.9901e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   3154/156230 | global iter:   3154/156230 | loss: 1.3885 | ds_loss: 1.4049 | lr: 9.9901e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   3155/156230 | global iter:   3155/156230 | loss: 1.2925 | ds_loss: 1.3111 | lr: 9.9901e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   3156/156230 | global iter:   3156/156230 | loss: 1.2441 | ds_loss: 1.2629 | lr: 9.9901e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3156/156230 | global iter:   3156/156230 | loss: 1.2553 | ds_loss: 1.2707 | lr: 9.9901e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3157/156230 | global iter:   3157/156230 | loss: 1.1163 | ds_loss: 1.1176 | lr: 9.9901e-05 | scale: 32768.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   3158/156230 | global iter:   3158/156230 | loss: 1.3865 | ds_loss: 1.3995 | lr: 9.9901e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   3159/156230 | global iter:   3159/156230 | loss: 1.2068 | ds_loss: 1.2193 | lr: 9.9901e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   3160/156230 | global iter:   3160/156230 | loss: 1.1493 | ds_loss: 1.1716 | lr: 9.9900e-05 | scale: 32768.0000 | micro time: 1.344 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3160/156230 | global iter:   3160/156230 | loss: 1.2147 | ds_loss: 1.2270 | lr: 9.9900e-05 | scale: 32768.0000 | micro time: 1.344 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3161/156230 | global iter:   3161/156230 | loss: 1.0446 | ds_loss: 1.0585 | lr: 9.9900e-05 | scale: 32768.0000 | micro time: 1.317 | step time: 0.000
train | epoch   0 | Iter:   3162/156230 | global iter:   3162/156230 | loss: 1.1349 | ds_loss: 1.1349 | lr: 9.9900e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   3163/156230 | global iter:   3163/156230 | loss: 1.1294 | ds_loss: 1.1461 | lr: 9.9900e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   3164/156230 | global iter:   3164/156230 | loss: 1.1827 | ds_loss: 1.2031 | lr: 9.9900e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3164/156230 | global iter:   3164/156230 | loss: 1.1229 | ds_loss: 1.1357 | lr: 9.9900e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3165/156230 | global iter:   3165/156230 | loss: 0.9266 | ds_loss: 0.9259 | lr: 9.9900e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   3166/156230 | global iter:   3166/156230 | loss: 1.1846 | ds_loss: 1.2064 | lr: 9.9900e-05 | scale: 32768.0000 | micro time: 1.401 | step time: 0.000
train | epoch   0 | Iter:   3167/156230 | global iter:   3167/156230 | loss: 1.0706 | ds_loss: 1.0804 | lr: 9.9900e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   3168/156230 | global iter:   3168/156230 | loss: 1.1030 | ds_loss: 1.0956 | lr: 9.9900e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3168/156230 | global iter:   3168/156230 | loss: 1.0712 | ds_loss: 1.0771 | lr: 9.9900e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3169/156230 | global iter:   3169/156230 | loss: 1.1555 | ds_loss: 1.1668 | lr: 9.9900e-05 | scale: 32768.0000 | micro time: 1.431 | step time: 0.000
train | epoch   0 | Iter:   3170/156230 | global iter:   3170/156230 | loss: 1.2851 | ds_loss: 1.3004 | lr: 9.9900e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   3171/156230 | global iter:   3171/156230 | loss: 1.1238 | ds_loss: 1.1537 | lr: 9.9900e-05 | scale: 32768.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   3172/156230 | global iter:   3172/156230 | loss: 1.2041 | ds_loss: 1.2219 | lr: 9.9900e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3172/156230 | global iter:   3172/156230 | loss: 1.1921 | ds_loss: 1.2107 | lr: 9.9900e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 1.379
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3173/156230 | global iter:   3173/156230 | loss: 1.1724 | ds_loss: 1.1724 | lr: 9.9900e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   3174/156230 | global iter:   3174/156230 | loss: 1.1965 | ds_loss: 1.1906 | lr: 9.9900e-05 | scale: 32768.0000 | micro time: 1.322 | step time: 0.000
train | epoch   0 | Iter:   3175/156230 | global iter:   3175/156230 | loss: 1.1574 | ds_loss: 1.1559 | lr: 9.9900e-05 | scale: 32768.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   3176/156230 | global iter:   3176/156230 | loss: 1.1346 | ds_loss: 1.1510 | lr: 9.9899e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3176/156230 | global iter:   3176/156230 | loss: 1.1652 | ds_loss: 1.1674 | lr: 9.9899e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3177/156230 | global iter:   3177/156230 | loss: 1.2238 | ds_loss: 1.2202 | lr: 9.9899e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   3178/156230 | global iter:   3178/156230 | loss: 1.0858 | ds_loss: 1.1081 | lr: 9.9899e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   3179/156230 | global iter:   3179/156230 | loss: 1.1540 | ds_loss: 1.1628 | lr: 9.9899e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   3180/156230 | global iter:   3180/156230 | loss: 1.2462 | ds_loss: 1.2484 | lr: 9.9899e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3180/156230 | global iter:   3180/156230 | loss: 1.1775 | ds_loss: 1.1849 | lr: 9.9899e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3181/156230 | global iter:   3181/156230 | loss: 1.1152 | ds_loss: 1.1424 | lr: 9.9899e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   3182/156230 | global iter:   3182/156230 | loss: 1.0623 | ds_loss: 1.0643 | lr: 9.9899e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   3183/156230 | global iter:   3183/156230 | loss: 1.0012 | ds_loss: 1.0092 | lr: 9.9899e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   3184/156230 | global iter:   3184/156230 | loss: 0.9153 | ds_loss: 0.9160 | lr: 9.9899e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3184/156230 | global iter:   3184/156230 | loss: 1.0235 | ds_loss: 1.0330 | lr: 9.9899e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3185/156230 | global iter:   3185/156230 | loss: 1.2942 | ds_loss: 1.2944 | lr: 9.9899e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   3186/156230 | global iter:   3186/156230 | loss: 1.2229 | ds_loss: 1.2352 | lr: 9.9899e-05 | scale: 32768.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   3187/156230 | global iter:   3187/156230 | loss: 1.2553 | ds_loss: 1.2716 | lr: 9.9899e-05 | scale: 32768.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   3188/156230 | global iter:   3188/156230 | loss: 1.0802 | ds_loss: 1.0955 | lr: 9.9899e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3188/156230 | global iter:   3188/156230 | loss: 1.2132 | ds_loss: 1.2242 | lr: 9.9899e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3189/156230 | global iter:   3189/156230 | loss: 1.1129 | ds_loss: 1.1161 | lr: 9.9899e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   3190/156230 | global iter:   3190/156230 | loss: 1.0389 | ds_loss: 1.0500 | lr: 9.9899e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   3191/156230 | global iter:   3191/156230 | loss: 1.0337 | ds_loss: 1.0393 | lr: 9.9898e-05 | scale: 32768.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   3192/156230 | global iter:   3192/156230 | loss: 1.1609 | ds_loss: 1.1721 | lr: 9.9898e-05 | scale: 32768.0000 | micro time: 1.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3192/156230 | global iter:   3192/156230 | loss: 1.0866 | ds_loss: 1.0944 | lr: 9.9898e-05 | scale: 32768.0000 | micro time: 1.397 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3193/156230 | global iter:   3193/156230 | loss: 1.1966 | ds_loss: 1.2015 | lr: 9.9898e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   3194/156230 | global iter:   3194/156230 | loss: 1.3179 | ds_loss: 1.3203 | lr: 9.9898e-05 | scale: 32768.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   3195/156230 | global iter:   3195/156230 | loss: 1.2276 | ds_loss: 1.2429 | lr: 9.9898e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   3196/156230 | global iter:   3196/156230 | loss: 0.9812 | ds_loss: 0.9884 | lr: 9.9898e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3196/156230 | global iter:   3196/156230 | loss: 1.1808 | ds_loss: 1.1883 | lr: 9.9898e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3197/156230 | global iter:   3197/156230 | loss: 1.2163 | ds_loss: 1.2172 | lr: 9.9898e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   3198/156230 | global iter:   3198/156230 | loss: 1.1790 | ds_loss: 1.1934 | lr: 9.9898e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   3199/156230 | global iter:   3199/156230 | loss: 1.1213 | ds_loss: 1.1156 | lr: 9.9898e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   3200/156230 | global iter:   3200/156230 | loss: 1.2093 | ds_loss: 1.2257 | lr: 9.9898e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3200/156230 | global iter:   3200/156230 | loss: 1.1815 | ds_loss: 1.1880 | lr: 9.9898e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3201/156230 | global iter:   3201/156230 | loss: 1.2928 | ds_loss: 1.3126 | lr: 9.9898e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   3202/156230 | global iter:   3202/156230 | loss: 1.1520 | ds_loss: 1.1424 | lr: 9.9898e-05 | scale: 32768.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   3203/156230 | global iter:   3203/156230 | loss: 1.1777 | ds_loss: 1.1880 | lr: 9.9898e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   3204/156230 | global iter:   3204/156230 | loss: 1.2797 | ds_loss: 1.2827 | lr: 9.9898e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3204/156230 | global iter:   3204/156230 | loss: 1.2256 | ds_loss: 1.2314 | lr: 9.9898e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3205/156230 | global iter:   3205/156230 | loss: 1.2329 | ds_loss: 1.2485 | lr: 9.9898e-05 | scale: 32768.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   3206/156230 | global iter:   3206/156230 | loss: 1.2215 | ds_loss: 1.2291 | lr: 9.9898e-05 | scale: 32768.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:   3207/156230 | global iter:   3207/156230 | loss: 1.1757 | ds_loss: 1.1728 | lr: 9.9897e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   3208/156230 | global iter:   3208/156230 | loss: 0.9133 | ds_loss: 0.9248 | lr: 9.9897e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3208/156230 | global iter:   3208/156230 | loss: 1.1359 | ds_loss: 1.1438 | lr: 9.9897e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3209/156230 | global iter:   3209/156230 | loss: 1.1670 | ds_loss: 1.1696 | lr: 9.9897e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   3210/156230 | global iter:   3210/156230 | loss: 1.1509 | ds_loss: 1.1741 | lr: 9.9897e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   3211/156230 | global iter:   3211/156230 | loss: 1.2419 | ds_loss: 1.2498 | lr: 9.9897e-05 | scale: 32768.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   3212/156230 | global iter:   3212/156230 | loss: 1.1042 | ds_loss: 1.1206 | lr: 9.9897e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3212/156230 | global iter:   3212/156230 | loss: 1.1660 | ds_loss: 1.1785 | lr: 9.9897e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3213/156230 | global iter:   3213/156230 | loss: 0.9789 | ds_loss: 1.0045 | lr: 9.9897e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   3214/156230 | global iter:   3214/156230 | loss: 1.1062 | ds_loss: 1.1215 | lr: 9.9897e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   3215/156230 | global iter:   3215/156230 | loss: 1.2108 | ds_loss: 1.2273 | lr: 9.9897e-05 | scale: 32768.0000 | micro time: 1.406 | step time: 0.000
train | epoch   0 | Iter:   3216/156230 | global iter:   3216/156230 | loss: 1.2469 | ds_loss: 1.2528 | lr: 9.9897e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3216/156230 | global iter:   3216/156230 | loss: 1.1357 | ds_loss: 1.1515 | lr: 9.9897e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3217/156230 | global iter:   3217/156230 | loss: 1.1076 | ds_loss: 1.1285 | lr: 9.9897e-05 | scale: 32768.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   3218/156230 | global iter:   3218/156230 | loss: 1.1978 | ds_loss: 1.2023 | lr: 9.9897e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   3219/156230 | global iter:   3219/156230 | loss: 1.1766 | ds_loss: 1.2096 | lr: 9.9897e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   3220/156230 | global iter:   3220/156230 | loss: 1.0936 | ds_loss: 1.0843 | lr: 9.9897e-05 | scale: 32768.0000 | micro time: 1.386 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3220/156230 | global iter:   3220/156230 | loss: 1.1439 | ds_loss: 1.1562 | lr: 9.9897e-05 | scale: 32768.0000 | micro time: 1.386 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3221/156230 | global iter:   3221/156230 | loss: 1.1006 | ds_loss: 1.1214 | lr: 9.9897e-05 | scale: 32768.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   3222/156230 | global iter:   3222/156230 | loss: 1.3062 | ds_loss: 1.3069 | lr: 9.9896e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   3223/156230 | global iter:   3223/156230 | loss: 1.1466 | ds_loss: 1.1622 | lr: 9.9896e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   3224/156230 | global iter:   3224/156230 | loss: 1.1789 | ds_loss: 1.1958 | lr: 9.9896e-05 | scale: 32768.0000 | micro time: 1.384 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3224/156230 | global iter:   3224/156230 | loss: 1.1831 | ds_loss: 1.1965 | lr: 9.9896e-05 | scale: 32768.0000 | micro time: 1.384 | step time: 1.383
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3225/156230 | global iter:   3225/156230 | loss: 1.1275 | ds_loss: 1.1548 | lr: 9.9896e-05 | scale: 32768.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   3226/156230 | global iter:   3226/156230 | loss: 1.1379 | ds_loss: 1.1449 | lr: 9.9896e-05 | scale: 32768.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   3227/156230 | global iter:   3227/156230 | loss: 1.1971 | ds_loss: 1.1915 | lr: 9.9896e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   3228/156230 | global iter:   3228/156230 | loss: 1.1129 | ds_loss: 1.1342 | lr: 9.9896e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3228/156230 | global iter:   3228/156230 | loss: 1.1439 | ds_loss: 1.1563 | lr: 9.9896e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3229/156230 | global iter:   3229/156230 | loss: 1.2178 | ds_loss: 1.2160 | lr: 9.9896e-05 | scale: 32768.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   3230/156230 | global iter:   3230/156230 | loss: 0.9945 | ds_loss: 1.0055 | lr: 9.9896e-05 | scale: 32768.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   3231/156230 | global iter:   3231/156230 | loss: 1.1572 | ds_loss: 1.1553 | lr: 9.9896e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   3232/156230 | global iter:   3232/156230 | loss: 0.9233 | ds_loss: 0.9298 | lr: 9.9896e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3232/156230 | global iter:   3232/156230 | loss: 1.0732 | ds_loss: 1.0766 | lr: 9.9896e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3233/156230 | global iter:   3233/156230 | loss: 1.1575 | ds_loss: 1.1749 | lr: 9.9896e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   3234/156230 | global iter:   3234/156230 | loss: 1.4681 | ds_loss: 1.4957 | lr: 9.9896e-05 | scale: 32768.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   3235/156230 | global iter:   3235/156230 | loss: 1.3380 | ds_loss: 1.3813 | lr: 9.9896e-05 | scale: 32768.0000 | micro time: 1.417 | step time: 0.000
train | epoch   0 | Iter:   3236/156230 | global iter:   3236/156230 | loss: 1.2158 | ds_loss: 1.2164 | lr: 9.9896e-05 | scale: 32768.0000 | micro time: 1.331 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3236/156230 | global iter:   3236/156230 | loss: 1.2948 | ds_loss: 1.3171 | lr: 9.9896e-05 | scale: 32768.0000 | micro time: 1.331 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3237/156230 | global iter:   3237/156230 | loss: 1.2153 | ds_loss: 1.2227 | lr: 9.9896e-05 | scale: 32768.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   3238/156230 | global iter:   3238/156230 | loss: 1.0597 | ds_loss: 1.0751 | lr: 9.9895e-05 | scale: 32768.0000 | micro time: 1.325 | step time: 0.000
train | epoch   0 | Iter:   3239/156230 | global iter:   3239/156230 | loss: 1.1406 | ds_loss: 1.1725 | lr: 9.9895e-05 | scale: 32768.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   3240/156230 | global iter:   3240/156230 | loss: 1.1712 | ds_loss: 1.1903 | lr: 9.9895e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3240/156230 | global iter:   3240/156230 | loss: 1.1467 | ds_loss: 1.1652 | lr: 9.9895e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3241/156230 | global iter:   3241/156230 | loss: 1.0800 | ds_loss: 1.1079 | lr: 9.9895e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   3242/156230 | global iter:   3242/156230 | loss: 1.1237 | ds_loss: 1.1458 | lr: 9.9895e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   3243/156230 | global iter:   3243/156230 | loss: 1.0923 | ds_loss: 1.0924 | lr: 9.9895e-05 | scale: 32768.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   3244/156230 | global iter:   3244/156230 | loss: 1.1616 | ds_loss: 1.1664 | lr: 9.9895e-05 | scale: 32768.0000 | micro time: 1.391 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3244/156230 | global iter:   3244/156230 | loss: 1.1144 | ds_loss: 1.1281 | lr: 9.9895e-05 | scale: 32768.0000 | micro time: 1.391 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3245/156230 | global iter:   3245/156230 | loss: 1.2923 | ds_loss: 1.2995 | lr: 9.9895e-05 | scale: 32768.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   3246/156230 | global iter:   3246/156230 | loss: 1.3287 | ds_loss: 1.3387 | lr: 9.9895e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   3247/156230 | global iter:   3247/156230 | loss: 1.3054 | ds_loss: 1.3185 | lr: 9.9895e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   3248/156230 | global iter:   3248/156230 | loss: 1.2243 | ds_loss: 1.2116 | lr: 9.9895e-05 | scale: 32768.0000 | micro time: 1.387 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3248/156230 | global iter:   3248/156230 | loss: 1.2877 | ds_loss: 1.2921 | lr: 9.9895e-05 | scale: 32768.0000 | micro time: 1.387 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3249/156230 | global iter:   3249/156230 | loss: 1.0994 | ds_loss: 1.0933 | lr: 9.9895e-05 | scale: 32768.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   3250/156230 | global iter:   3250/156230 | loss: 1.2021 | ds_loss: 1.2090 | lr: 9.9895e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   3251/156230 | global iter:   3251/156230 | loss: 1.1792 | ds_loss: 1.2029 | lr: 9.9895e-05 | scale: 32768.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:   3252/156230 | global iter:   3252/156230 | loss: 1.1642 | ds_loss: 1.1651 | lr: 9.9895e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3252/156230 | global iter:   3252/156230 | loss: 1.1612 | ds_loss: 1.1676 | lr: 9.9895e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3253/156230 | global iter:   3253/156230 | loss: 1.1656 | ds_loss: 1.1806 | lr: 9.9894e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   3254/156230 | global iter:   3254/156230 | loss: 1.1698 | ds_loss: 1.1753 | lr: 9.9894e-05 | scale: 32768.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   3255/156230 | global iter:   3255/156230 | loss: 1.0708 | ds_loss: 1.0682 | lr: 9.9894e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   3256/156230 | global iter:   3256/156230 | loss: 1.3372 | ds_loss: 1.3313 | lr: 9.9894e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3256/156230 | global iter:   3256/156230 | loss: 1.1859 | ds_loss: 1.1888 | lr: 9.9894e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3257/156230 | global iter:   3257/156230 | loss: 1.3103 | ds_loss: 1.3245 | lr: 9.9894e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   3258/156230 | global iter:   3258/156230 | loss: 1.2185 | ds_loss: 1.2271 | lr: 9.9894e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   3259/156230 | global iter:   3259/156230 | loss: 1.2265 | ds_loss: 1.2232 | lr: 9.9894e-05 | scale: 32768.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:   3260/156230 | global iter:   3260/156230 | loss: 1.1775 | ds_loss: 1.1764 | lr: 9.9894e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3260/156230 | global iter:   3260/156230 | loss: 1.2332 | ds_loss: 1.2378 | lr: 9.9894e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3261/156230 | global iter:   3261/156230 | loss: 1.2933 | ds_loss: 1.3101 | lr: 9.9894e-05 | scale: 32768.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   3262/156230 | global iter:   3262/156230 | loss: 1.1300 | ds_loss: 1.1320 | lr: 9.9894e-05 | scale: 32768.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   3263/156230 | global iter:   3263/156230 | loss: 1.2182 | ds_loss: 1.2311 | lr: 9.9894e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   3264/156230 | global iter:   3264/156230 | loss: 1.1419 | ds_loss: 1.1526 | lr: 9.9894e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3264/156230 | global iter:   3264/156230 | loss: 1.1958 | ds_loss: 1.2065 | lr: 9.9894e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3265/156230 | global iter:   3265/156230 | loss: 1.1989 | ds_loss: 1.2127 | lr: 9.9894e-05 | scale: 32768.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   3266/156230 | global iter:   3266/156230 | loss: 1.1133 | ds_loss: 1.1385 | lr: 9.9894e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   3267/156230 | global iter:   3267/156230 | loss: 1.1750 | ds_loss: 1.1909 | lr: 9.9894e-05 | scale: 32768.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   3268/156230 | global iter:   3268/156230 | loss: 1.0457 | ds_loss: 1.0441 | lr: 9.9893e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3268/156230 | global iter:   3268/156230 | loss: 1.1332 | ds_loss: 1.1465 | lr: 9.9893e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3269/156230 | global iter:   3269/156230 | loss: 1.1357 | ds_loss: 1.1483 | lr: 9.9893e-05 | scale: 32768.0000 | micro time: 1.400 | step time: 0.000
train | epoch   0 | Iter:   3270/156230 | global iter:   3270/156230 | loss: 1.0759 | ds_loss: 1.1046 | lr: 9.9893e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   3271/156230 | global iter:   3271/156230 | loss: 1.1644 | ds_loss: 1.1578 | lr: 9.9893e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   3272/156230 | global iter:   3272/156230 | loss: 1.1094 | ds_loss: 1.1267 | lr: 9.9893e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3272/156230 | global iter:   3272/156230 | loss: 1.1214 | ds_loss: 1.1343 | lr: 9.9893e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3273/156230 | global iter:   3273/156230 | loss: 1.0839 | ds_loss: 1.0794 | lr: 9.9893e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   3274/156230 | global iter:   3274/156230 | loss: 1.2116 | ds_loss: 1.2088 | lr: 9.9893e-05 | scale: 32768.0000 | micro time: 1.401 | step time: 0.000
train | epoch   0 | Iter:   3275/156230 | global iter:   3275/156230 | loss: 1.1561 | ds_loss: 1.1461 | lr: 9.9893e-05 | scale: 32768.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   3276/156230 | global iter:   3276/156230 | loss: 1.0630 | ds_loss: 1.0770 | lr: 9.9893e-05 | scale: 32768.0000 | micro time: 1.314 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3276/156230 | global iter:   3276/156230 | loss: 1.1287 | ds_loss: 1.1278 | lr: 9.9893e-05 | scale: 32768.0000 | micro time: 1.314 | step time: 1.348
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3277/156230 | global iter:   3277/156230 | loss: 1.2357 | ds_loss: 1.2380 | lr: 9.9893e-05 | scale: 32768.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   3278/156230 | global iter:   3278/156230 | loss: 1.1667 | ds_loss: 1.1640 | lr: 9.9893e-05 | scale: 32768.0000 | micro time: 1.307 | step time: 0.000
train | epoch   0 | Iter:   3279/156230 | global iter:   3279/156230 | loss: 1.0893 | ds_loss: 1.1086 | lr: 9.9893e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   3280/156230 | global iter:   3280/156230 | loss: 1.2970 | ds_loss: 1.3117 | lr: 9.9893e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3280/156230 | global iter:   3280/156230 | loss: 1.1972 | ds_loss: 1.2056 | lr: 9.9893e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3281/156230 | global iter:   3281/156230 | loss: 1.1091 | ds_loss: 1.1051 | lr: 9.9893e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   3282/156230 | global iter:   3282/156230 | loss: 1.1016 | ds_loss: 1.1140 | lr: 9.9893e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   3283/156230 | global iter:   3283/156230 | loss: 1.0344 | ds_loss: 1.0423 | lr: 9.9893e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   3284/156230 | global iter:   3284/156230 | loss: 1.0790 | ds_loss: 1.0931 | lr: 9.9892e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3284/156230 | global iter:   3284/156230 | loss: 1.0810 | ds_loss: 1.0886 | lr: 9.9892e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3285/156230 | global iter:   3285/156230 | loss: 1.1891 | ds_loss: 1.2076 | lr: 9.9892e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   3286/156230 | global iter:   3286/156230 | loss: 1.1883 | ds_loss: 1.2113 | lr: 9.9892e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   3287/156230 | global iter:   3287/156230 | loss: 1.1573 | ds_loss: 1.1727 | lr: 9.9892e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   3288/156230 | global iter:   3288/156230 | loss: 1.2388 | ds_loss: 1.2454 | lr: 9.9892e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3288/156230 | global iter:   3288/156230 | loss: 1.1934 | ds_loss: 1.2092 | lr: 9.9892e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3289/156230 | global iter:   3289/156230 | loss: 1.2196 | ds_loss: 1.2210 | lr: 9.9892e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   3290/156230 | global iter:   3290/156230 | loss: 1.1940 | ds_loss: 1.2040 | lr: 9.9892e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   3291/156230 | global iter:   3291/156230 | loss: 0.9508 | ds_loss: 0.9469 | lr: 9.9892e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   3292/156230 | global iter:   3292/156230 | loss: 1.0131 | ds_loss: 1.0284 | lr: 9.9892e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3292/156230 | global iter:   3292/156230 | loss: 1.0944 | ds_loss: 1.1001 | lr: 9.9892e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3293/156230 | global iter:   3293/156230 | loss: 1.2708 | ds_loss: 1.2762 | lr: 9.9892e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   3294/156230 | global iter:   3294/156230 | loss: 1.1525 | ds_loss: 1.1689 | lr: 9.9892e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   3295/156230 | global iter:   3295/156230 | loss: 1.2733 | ds_loss: 1.2867 | lr: 9.9892e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   3296/156230 | global iter:   3296/156230 | loss: 1.0583 | ds_loss: 1.0721 | lr: 9.9892e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3296/156230 | global iter:   3296/156230 | loss: 1.1887 | ds_loss: 1.2010 | lr: 9.9892e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3297/156230 | global iter:   3297/156230 | loss: 1.1748 | ds_loss: 1.1845 | lr: 9.9892e-05 | scale: 32768.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   3298/156230 | global iter:   3298/156230 | loss: 1.1491 | ds_loss: 1.1572 | lr: 9.9892e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   3299/156230 | global iter:   3299/156230 | loss: 1.0728 | ds_loss: 1.0876 | lr: 9.9891e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   3300/156230 | global iter:   3300/156230 | loss: 0.9397 | ds_loss: 0.9523 | lr: 9.9891e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3300/156230 | global iter:   3300/156230 | loss: 1.0841 | ds_loss: 1.0954 | lr: 9.9891e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3301/156230 | global iter:   3301/156230 | loss: 1.1598 | ds_loss: 1.1725 | lr: 9.9891e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   3302/156230 | global iter:   3302/156230 | loss: 1.2048 | ds_loss: 1.2101 | lr: 9.9891e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   3303/156230 | global iter:   3303/156230 | loss: 1.2843 | ds_loss: 1.3015 | lr: 9.9891e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   3304/156230 | global iter:   3304/156230 | loss: 1.1262 | ds_loss: 1.1330 | lr: 9.9891e-05 | scale: 32768.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3304/156230 | global iter:   3304/156230 | loss: 1.1938 | ds_loss: 1.2043 | lr: 9.9891e-05 | scale: 32768.0000 | micro time: 1.370 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3305/156230 | global iter:   3305/156230 | loss: 1.1545 | ds_loss: 1.1720 | lr: 9.9891e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   3306/156230 | global iter:   3306/156230 | loss: 1.1133 | ds_loss: 1.1208 | lr: 9.9891e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   3307/156230 | global iter:   3307/156230 | loss: 1.2746 | ds_loss: 1.2881 | lr: 9.9891e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   3308/156230 | global iter:   3308/156230 | loss: 1.2173 | ds_loss: 1.2332 | lr: 9.9891e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3308/156230 | global iter:   3308/156230 | loss: 1.1899 | ds_loss: 1.2035 | lr: 9.9891e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3309/156230 | global iter:   3309/156230 | loss: 1.1416 | ds_loss: 1.1663 | lr: 9.9891e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   3310/156230 | global iter:   3310/156230 | loss: 1.2076 | ds_loss: 1.2153 | lr: 9.9891e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   3311/156230 | global iter:   3311/156230 | loss: 0.9975 | ds_loss: 1.0086 | lr: 9.9891e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   3312/156230 | global iter:   3312/156230 | loss: 1.2736 | ds_loss: 1.2887 | lr: 9.9891e-05 | scale: 32768.0000 | micro time: 1.339 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3312/156230 | global iter:   3312/156230 | loss: 1.1551 | ds_loss: 1.1697 | lr: 9.9891e-05 | scale: 32768.0000 | micro time: 1.339 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3313/156230 | global iter:   3313/156230 | loss: 1.0706 | ds_loss: 1.0907 | lr: 9.9891e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   3314/156230 | global iter:   3314/156230 | loss: 1.1015 | ds_loss: 1.1174 | lr: 9.9890e-05 | scale: 32768.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:   3315/156230 | global iter:   3315/156230 | loss: 1.3040 | ds_loss: 1.3148 | lr: 9.9890e-05 | scale: 32768.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   3316/156230 | global iter:   3316/156230 | loss: 1.1817 | ds_loss: 1.1921 | lr: 9.9890e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3316/156230 | global iter:   3316/156230 | loss: 1.1645 | ds_loss: 1.1788 | lr: 9.9890e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3317/156230 | global iter:   3317/156230 | loss: 1.1182 | ds_loss: 1.1277 | lr: 9.9890e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   3318/156230 | global iter:   3318/156230 | loss: 1.3430 | ds_loss: 1.3477 | lr: 9.9890e-05 | scale: 32768.0000 | micro time: 1.411 | step time: 0.000
train | epoch   0 | Iter:   3319/156230 | global iter:   3319/156230 | loss: 1.1215 | ds_loss: 1.1292 | lr: 9.9890e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   3320/156230 | global iter:   3320/156230 | loss: 1.1428 | ds_loss: 1.1633 | lr: 9.9890e-05 | scale: 32768.0000 | micro time: 1.390 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3320/156230 | global iter:   3320/156230 | loss: 1.1814 | ds_loss: 1.1920 | lr: 9.9890e-05 | scale: 32768.0000 | micro time: 1.390 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3321/156230 | global iter:   3321/156230 | loss: 1.1789 | ds_loss: 1.2093 | lr: 9.9890e-05 | scale: 32768.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   3322/156230 | global iter:   3322/156230 | loss: 1.3232 | ds_loss: 1.3415 | lr: 9.9890e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   3323/156230 | global iter:   3323/156230 | loss: 1.2105 | ds_loss: 1.2213 | lr: 9.9890e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   3324/156230 | global iter:   3324/156230 | loss: 0.9138 | ds_loss: 0.9315 | lr: 9.9890e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3324/156230 | global iter:   3324/156230 | loss: 1.1566 | ds_loss: 1.1759 | lr: 9.9890e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3325/156230 | global iter:   3325/156230 | loss: 1.1718 | ds_loss: 1.1936 | lr: 9.9890e-05 | scale: 32768.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   3326/156230 | global iter:   3326/156230 | loss: 0.9189 | ds_loss: 0.9376 | lr: 9.9890e-05 | scale: 32768.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   3327/156230 | global iter:   3327/156230 | loss: 1.1618 | ds_loss: 1.1737 | lr: 9.9890e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   3328/156230 | global iter:   3328/156230 | loss: 0.9935 | ds_loss: 1.0034 | lr: 9.9890e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3328/156230 | global iter:   3328/156230 | loss: 1.0615 | ds_loss: 1.0771 | lr: 9.9890e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3329/156230 | global iter:   3329/156230 | loss: 1.1608 | ds_loss: 1.1757 | lr: 9.9889e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   3330/156230 | global iter:   3330/156230 | loss: 1.2097 | ds_loss: 1.2099 | lr: 9.9889e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   3331/156230 | global iter:   3331/156230 | loss: 1.0183 | ds_loss: 1.0433 | lr: 9.9889e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   3332/156230 | global iter:   3332/156230 | loss: 0.9244 | ds_loss: 0.9552 | lr: 9.9889e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3332/156230 | global iter:   3332/156230 | loss: 1.0783 | ds_loss: 1.0960 | lr: 9.9889e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3333/156230 | global iter:   3333/156230 | loss: 1.2108 | ds_loss: 1.2294 | lr: 9.9889e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   3334/156230 | global iter:   3334/156230 | loss: 1.1489 | ds_loss: 1.1529 | lr: 9.9889e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   3335/156230 | global iter:   3335/156230 | loss: 1.1241 | ds_loss: 1.1372 | lr: 9.9889e-05 | scale: 32768.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   3336/156230 | global iter:   3336/156230 | loss: 1.1779 | ds_loss: 1.1781 | lr: 9.9889e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3336/156230 | global iter:   3336/156230 | loss: 1.1654 | ds_loss: 1.1744 | lr: 9.9889e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3337/156230 | global iter:   3337/156230 | loss: 1.1096 | ds_loss: 1.1255 | lr: 9.9889e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   3338/156230 | global iter:   3338/156230 | loss: 1.1514 | ds_loss: 1.1823 | lr: 9.9889e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   3339/156230 | global iter:   3339/156230 | loss: 1.0609 | ds_loss: 1.0614 | lr: 9.9889e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   3340/156230 | global iter:   3340/156230 | loss: 1.1632 | ds_loss: 1.1789 | lr: 9.9889e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3340/156230 | global iter:   3340/156230 | loss: 1.1213 | ds_loss: 1.1370 | lr: 9.9889e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3341/156230 | global iter:   3341/156230 | loss: 1.0403 | ds_loss: 1.0476 | lr: 9.9889e-05 | scale: 32768.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   3342/156230 | global iter:   3342/156230 | loss: 1.1476 | ds_loss: 1.1585 | lr: 9.9889e-05 | scale: 32768.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   3343/156230 | global iter:   3343/156230 | loss: 1.0423 | ds_loss: 1.0452 | lr: 9.9889e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   3344/156230 | global iter:   3344/156230 | loss: 1.1877 | ds_loss: 1.1948 | lr: 9.9888e-05 | scale: 32768.0000 | micro time: 1.384 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3344/156230 | global iter:   3344/156230 | loss: 1.1045 | ds_loss: 1.1115 | lr: 9.9888e-05 | scale: 32768.0000 | micro time: 1.384 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3345/156230 | global iter:   3345/156230 | loss: 1.1617 | ds_loss: 1.1529 | lr: 9.9888e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   3346/156230 | global iter:   3346/156230 | loss: 1.2719 | ds_loss: 1.2852 | lr: 9.9888e-05 | scale: 32768.0000 | micro time: 1.322 | step time: 0.000
train | epoch   0 | Iter:   3347/156230 | global iter:   3347/156230 | loss: 0.9310 | ds_loss: 0.9370 | lr: 9.9888e-05 | scale: 32768.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   3348/156230 | global iter:   3348/156230 | loss: 1.1245 | ds_loss: 1.1401 | lr: 9.9888e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3348/156230 | global iter:   3348/156230 | loss: 1.1223 | ds_loss: 1.1288 | lr: 9.9888e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3349/156230 | global iter:   3349/156230 | loss: 1.2459 | ds_loss: 1.2391 | lr: 9.9888e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   3350/156230 | global iter:   3350/156230 | loss: 1.2618 | ds_loss: 1.2767 | lr: 9.9888e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   3351/156230 | global iter:   3351/156230 | loss: 0.9347 | ds_loss: 0.9574 | lr: 9.9888e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   3352/156230 | global iter:   3352/156230 | loss: 1.4160 | ds_loss: 1.4370 | lr: 9.9888e-05 | scale: 32768.0000 | micro time: 1.402 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3352/156230 | global iter:   3352/156230 | loss: 1.2146 | ds_loss: 1.2276 | lr: 9.9888e-05 | scale: 32768.0000 | micro time: 1.402 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3353/156230 | global iter:   3353/156230 | loss: 1.1822 | ds_loss: 1.1961 | lr: 9.9888e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   3354/156230 | global iter:   3354/156230 | loss: 1.1209 | ds_loss: 1.1212 | lr: 9.9888e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   3355/156230 | global iter:   3355/156230 | loss: 1.2721 | ds_loss: 1.2836 | lr: 9.9888e-05 | scale: 32768.0000 | micro time: 1.412 | step time: 0.000
train | epoch   0 | Iter:   3356/156230 | global iter:   3356/156230 | loss: 1.3387 | ds_loss: 1.3580 | lr: 9.9888e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3356/156230 | global iter:   3356/156230 | loss: 1.2285 | ds_loss: 1.2397 | lr: 9.9888e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3357/156230 | global iter:   3357/156230 | loss: 1.2816 | ds_loss: 1.2943 | lr: 9.9888e-05 | scale: 32768.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   3358/156230 | global iter:   3358/156230 | loss: 1.2641 | ds_loss: 1.2655 | lr: 9.9888e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   3359/156230 | global iter:   3359/156230 | loss: 1.3380 | ds_loss: 1.3489 | lr: 9.9887e-05 | scale: 32768.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   3360/156230 | global iter:   3360/156230 | loss: 1.2696 | ds_loss: 1.2774 | lr: 9.9887e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3360/156230 | global iter:   3360/156230 | loss: 1.2883 | ds_loss: 1.2965 | lr: 9.9887e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 1.382
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3361/156230 | global iter:   3361/156230 | loss: 1.3314 | ds_loss: 1.3514 | lr: 9.9887e-05 | scale: 32768.0000 | micro time: 1.408 | step time: 0.000
train | epoch   0 | Iter:   3362/156230 | global iter:   3362/156230 | loss: 1.1187 | ds_loss: 1.1240 | lr: 9.9887e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   3363/156230 | global iter:   3363/156230 | loss: 1.2088 | ds_loss: 1.2039 | lr: 9.9887e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   3364/156230 | global iter:   3364/156230 | loss: 1.2388 | ds_loss: 1.2433 | lr: 9.9887e-05 | scale: 32768.0000 | micro time: 1.384 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3364/156230 | global iter:   3364/156230 | loss: 1.2244 | ds_loss: 1.2307 | lr: 9.9887e-05 | scale: 32768.0000 | micro time: 1.384 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3365/156230 | global iter:   3365/156230 | loss: 1.0515 | ds_loss: 1.0527 | lr: 9.9887e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   3366/156230 | global iter:   3366/156230 | loss: 1.0719 | ds_loss: 1.0896 | lr: 9.9887e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   3367/156230 | global iter:   3367/156230 | loss: 1.0190 | ds_loss: 1.0446 | lr: 9.9887e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   3368/156230 | global iter:   3368/156230 | loss: 1.2116 | ds_loss: 1.2220 | lr: 9.9887e-05 | scale: 32768.0000 | micro time: 1.389 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3368/156230 | global iter:   3368/156230 | loss: 1.0885 | ds_loss: 1.1022 | lr: 9.9887e-05 | scale: 32768.0000 | micro time: 1.389 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3369/156230 | global iter:   3369/156230 | loss: 1.1298 | ds_loss: 1.1456 | lr: 9.9887e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   3370/156230 | global iter:   3370/156230 | loss: 1.2121 | ds_loss: 1.2227 | lr: 9.9887e-05 | scale: 32768.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   3371/156230 | global iter:   3371/156230 | loss: 1.1539 | ds_loss: 1.1792 | lr: 9.9887e-05 | scale: 32768.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:   3372/156230 | global iter:   3372/156230 | loss: 1.0664 | ds_loss: 1.0954 | lr: 9.9887e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3372/156230 | global iter:   3372/156230 | loss: 1.1406 | ds_loss: 1.1607 | lr: 9.9887e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3373/156230 | global iter:   3373/156230 | loss: 1.0556 | ds_loss: 1.0698 | lr: 9.9887e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   3374/156230 | global iter:   3374/156230 | loss: 0.9555 | ds_loss: 0.9748 | lr: 9.9886e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   3375/156230 | global iter:   3375/156230 | loss: 1.1434 | ds_loss: 1.1631 | lr: 9.9886e-05 | scale: 32768.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   3376/156230 | global iter:   3376/156230 | loss: 1.0182 | ds_loss: 1.0297 | lr: 9.9886e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3376/156230 | global iter:   3376/156230 | loss: 1.0432 | ds_loss: 1.0594 | lr: 9.9886e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3377/156230 | global iter:   3377/156230 | loss: 1.0489 | ds_loss: 1.0693 | lr: 9.9886e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   3378/156230 | global iter:   3378/156230 | loss: 1.0748 | ds_loss: 1.0891 | lr: 9.9886e-05 | scale: 32768.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   3379/156230 | global iter:   3379/156230 | loss: 1.2146 | ds_loss: 1.2301 | lr: 9.9886e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   3380/156230 | global iter:   3380/156230 | loss: 1.1328 | ds_loss: 1.1567 | lr: 9.9886e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3380/156230 | global iter:   3380/156230 | loss: 1.1177 | ds_loss: 1.1363 | lr: 9.9886e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3381/156230 | global iter:   3381/156230 | loss: 1.1155 | ds_loss: 1.1280 | lr: 9.9886e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   3382/156230 | global iter:   3382/156230 | loss: 1.0542 | ds_loss: 1.0496 | lr: 9.9886e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   3383/156230 | global iter:   3383/156230 | loss: 1.2153 | ds_loss: 1.2309 | lr: 9.9886e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   3384/156230 | global iter:   3384/156230 | loss: 1.1810 | ds_loss: 1.1950 | lr: 9.9886e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3384/156230 | global iter:   3384/156230 | loss: 1.1415 | ds_loss: 1.1509 | lr: 9.9886e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3385/156230 | global iter:   3385/156230 | loss: 1.2255 | ds_loss: 1.2325 | lr: 9.9886e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   3386/156230 | global iter:   3386/156230 | loss: 1.1981 | ds_loss: 1.2160 | lr: 9.9886e-05 | scale: 32768.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   3387/156230 | global iter:   3387/156230 | loss: 1.1057 | ds_loss: 1.1077 | lr: 9.9886e-05 | scale: 32768.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   3388/156230 | global iter:   3388/156230 | loss: 1.2731 | ds_loss: 1.2640 | lr: 9.9885e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3388/156230 | global iter:   3388/156230 | loss: 1.2006 | ds_loss: 1.2050 | lr: 9.9885e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3389/156230 | global iter:   3389/156230 | loss: 1.0882 | ds_loss: 1.1052 | lr: 9.9885e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   3390/156230 | global iter:   3390/156230 | loss: 1.2574 | ds_loss: 1.2676 | lr: 9.9885e-05 | scale: 32768.0000 | micro time: 1.416 | step time: 0.000
train | epoch   0 | Iter:   3391/156230 | global iter:   3391/156230 | loss: 1.2776 | ds_loss: 1.2884 | lr: 9.9885e-05 | scale: 32768.0000 | micro time: 1.298 | step time: 0.000
train | epoch   0 | Iter:   3392/156230 | global iter:   3392/156230 | loss: 1.2040 | ds_loss: 1.2144 | lr: 9.9885e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3392/156230 | global iter:   3392/156230 | loss: 1.2068 | ds_loss: 1.2189 | lr: 9.9885e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3393/156230 | global iter:   3393/156230 | loss: 1.1440 | ds_loss: 1.1597 | lr: 9.9885e-05 | scale: 32768.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   3394/156230 | global iter:   3394/156230 | loss: 1.2028 | ds_loss: 1.2218 | lr: 9.9885e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   3395/156230 | global iter:   3395/156230 | loss: 1.2060 | ds_loss: 1.2150 | lr: 9.9885e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   3396/156230 | global iter:   3396/156230 | loss: 1.2178 | ds_loss: 1.2315 | lr: 9.9885e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3396/156230 | global iter:   3396/156230 | loss: 1.1927 | ds_loss: 1.2070 | lr: 9.9885e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3397/156230 | global iter:   3397/156230 | loss: 1.1941 | ds_loss: 1.1967 | lr: 9.9885e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   3398/156230 | global iter:   3398/156230 | loss: 1.2272 | ds_loss: 1.2571 | lr: 9.9885e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   3399/156230 | global iter:   3399/156230 | loss: 1.2258 | ds_loss: 1.2382 | lr: 9.9885e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   3400/156230 | global iter:   3400/156230 | loss: 1.2530 | ds_loss: 1.2661 | lr: 9.9885e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3400/156230 | global iter:   3400/156230 | loss: 1.2250 | ds_loss: 1.2395 | lr: 9.9885e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3401/156230 | global iter:   3401/156230 | loss: 1.1068 | ds_loss: 1.1031 | lr: 9.9885e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   3402/156230 | global iter:   3402/156230 | loss: 1.2573 | ds_loss: 1.2762 | lr: 9.9885e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   3403/156230 | global iter:   3403/156230 | loss: 1.1903 | ds_loss: 1.2071 | lr: 9.9884e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   3404/156230 | global iter:   3404/156230 | loss: 1.2113 | ds_loss: 1.2304 | lr: 9.9884e-05 | scale: 32768.0000 | micro time: 1.326 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3404/156230 | global iter:   3404/156230 | loss: 1.1914 | ds_loss: 1.2042 | lr: 9.9884e-05 | scale: 32768.0000 | micro time: 1.326 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3405/156230 | global iter:   3405/156230 | loss: 1.0954 | ds_loss: 1.1029 | lr: 9.9884e-05 | scale: 32768.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   3406/156230 | global iter:   3406/156230 | loss: 1.1882 | ds_loss: 1.1892 | lr: 9.9884e-05 | scale: 32768.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   3407/156230 | global iter:   3407/156230 | loss: 1.1191 | ds_loss: 1.1353 | lr: 9.9884e-05 | scale: 32768.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   3408/156230 | global iter:   3408/156230 | loss: 1.1850 | ds_loss: 1.1924 | lr: 9.9884e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3408/156230 | global iter:   3408/156230 | loss: 1.1469 | ds_loss: 1.1550 | lr: 9.9884e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3409/156230 | global iter:   3409/156230 | loss: 1.1828 | ds_loss: 1.1858 | lr: 9.9884e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   3410/156230 | global iter:   3410/156230 | loss: 1.2093 | ds_loss: 1.2199 | lr: 9.9884e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   3411/156230 | global iter:   3411/156230 | loss: 1.1424 | ds_loss: 1.1719 | lr: 9.9884e-05 | scale: 32768.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   3412/156230 | global iter:   3412/156230 | loss: 1.0245 | ds_loss: 1.0289 | lr: 9.9884e-05 | scale: 32768.0000 | micro time: 1.413 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3412/156230 | global iter:   3412/156230 | loss: 1.1398 | ds_loss: 1.1516 | lr: 9.9884e-05 | scale: 32768.0000 | micro time: 1.413 | step time: 1.383
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3413/156230 | global iter:   3413/156230 | loss: 1.2839 | ds_loss: 1.3126 | lr: 9.9884e-05 | scale: 32768.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   3414/156230 | global iter:   3414/156230 | loss: 1.1626 | ds_loss: 1.1560 | lr: 9.9884e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   3415/156230 | global iter:   3415/156230 | loss: 1.1344 | ds_loss: 1.1376 | lr: 9.9884e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   3416/156230 | global iter:   3416/156230 | loss: 1.2867 | ds_loss: 1.2863 | lr: 9.9884e-05 | scale: 32768.0000 | micro time: 1.387 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3416/156230 | global iter:   3416/156230 | loss: 1.2169 | ds_loss: 1.2231 | lr: 9.9884e-05 | scale: 32768.0000 | micro time: 1.387 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3417/156230 | global iter:   3417/156230 | loss: 1.1866 | ds_loss: 1.2015 | lr: 9.9884e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   3418/156230 | global iter:   3418/156230 | loss: 1.1324 | ds_loss: 1.1369 | lr: 9.9883e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   3419/156230 | global iter:   3419/156230 | loss: 1.1341 | ds_loss: 1.1458 | lr: 9.9883e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   3420/156230 | global iter:   3420/156230 | loss: 1.1777 | ds_loss: 1.1901 | lr: 9.9883e-05 | scale: 32768.0000 | micro time: 1.334 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3420/156230 | global iter:   3420/156230 | loss: 1.1577 | ds_loss: 1.1686 | lr: 9.9883e-05 | scale: 32768.0000 | micro time: 1.334 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3421/156230 | global iter:   3421/156230 | loss: 1.0854 | ds_loss: 1.0865 | lr: 9.9883e-05 | scale: 32768.0000 | micro time: 1.416 | step time: 0.000
train | epoch   0 | Iter:   3422/156230 | global iter:   3422/156230 | loss: 1.0871 | ds_loss: 1.0978 | lr: 9.9883e-05 | scale: 32768.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   3423/156230 | global iter:   3423/156230 | loss: 1.1455 | ds_loss: 1.1674 | lr: 9.9883e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   3424/156230 | global iter:   3424/156230 | loss: 1.0362 | ds_loss: 1.0459 | lr: 9.9883e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3424/156230 | global iter:   3424/156230 | loss: 1.0886 | ds_loss: 1.0994 | lr: 9.9883e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3425/156230 | global iter:   3425/156230 | loss: 1.1823 | ds_loss: 1.2024 | lr: 9.9883e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   3426/156230 | global iter:   3426/156230 | loss: 1.1367 | ds_loss: 1.1549 | lr: 9.9883e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   3427/156230 | global iter:   3427/156230 | loss: 1.0034 | ds_loss: 1.0053 | lr: 9.9883e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   3428/156230 | global iter:   3428/156230 | loss: 1.0728 | ds_loss: 1.0857 | lr: 9.9883e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3428/156230 | global iter:   3428/156230 | loss: 1.0988 | ds_loss: 1.1121 | lr: 9.9883e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3429/156230 | global iter:   3429/156230 | loss: 1.2035 | ds_loss: 1.2139 | lr: 9.9883e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   3430/156230 | global iter:   3430/156230 | loss: 1.1095 | ds_loss: 1.1176 | lr: 9.9883e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   3431/156230 | global iter:   3431/156230 | loss: 1.1376 | ds_loss: 1.1560 | lr: 9.9883e-05 | scale: 32768.0000 | micro time: 1.402 | step time: 0.000
train | epoch   0 | Iter:   3432/156230 | global iter:   3432/156230 | loss: 1.1553 | ds_loss: 1.1706 | lr: 9.9882e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3432/156230 | global iter:   3432/156230 | loss: 1.1515 | ds_loss: 1.1645 | lr: 9.9882e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3433/156230 | global iter:   3433/156230 | loss: 1.2534 | ds_loss: 1.2673 | lr: 9.9882e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   3434/156230 | global iter:   3434/156230 | loss: 1.2168 | ds_loss: 1.2452 | lr: 9.9882e-05 | scale: 32768.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   3435/156230 | global iter:   3435/156230 | loss: 1.0430 | ds_loss: 1.0704 | lr: 9.9882e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   3436/156230 | global iter:   3436/156230 | loss: 1.1564 | ds_loss: 1.1495 | lr: 9.9882e-05 | scale: 32768.0000 | micro time: 1.325 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3436/156230 | global iter:   3436/156230 | loss: 1.1674 | ds_loss: 1.1831 | lr: 9.9882e-05 | scale: 32768.0000 | micro time: 1.325 | step time: 1.345
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3437/156230 | global iter:   3437/156230 | loss: 0.9683 | ds_loss: 0.9593 | lr: 9.9882e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   3438/156230 | global iter:   3438/156230 | loss: 1.1482 | ds_loss: 1.1493 | lr: 9.9882e-05 | scale: 32768.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:   3439/156230 | global iter:   3439/156230 | loss: 1.1664 | ds_loss: 1.1978 | lr: 9.9882e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   3440/156230 | global iter:   3440/156230 | loss: 1.0236 | ds_loss: 1.0428 | lr: 9.9882e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3440/156230 | global iter:   3440/156230 | loss: 1.0766 | ds_loss: 1.0873 | lr: 9.9882e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3441/156230 | global iter:   3441/156230 | loss: 1.0092 | ds_loss: 1.0229 | lr: 9.9882e-05 | scale: 32768.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   3442/156230 | global iter:   3442/156230 | loss: 1.1796 | ds_loss: 1.2009 | lr: 9.9882e-05 | scale: 32768.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   3443/156230 | global iter:   3443/156230 | loss: 1.2655 | ds_loss: 1.2686 | lr: 9.9882e-05 | scale: 32768.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   3444/156230 | global iter:   3444/156230 | loss: 1.0667 | ds_loss: 1.0806 | lr: 9.9882e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3444/156230 | global iter:   3444/156230 | loss: 1.1303 | ds_loss: 1.1432 | lr: 9.9882e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3445/156230 | global iter:   3445/156230 | loss: 1.1350 | ds_loss: 1.1357 | lr: 9.9882e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   3446/156230 | global iter:   3446/156230 | loss: 1.0645 | ds_loss: 1.0887 | lr: 9.9882e-05 | scale: 32768.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   3447/156230 | global iter:   3447/156230 | loss: 1.0798 | ds_loss: 1.0861 | lr: 9.9881e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   3448/156230 | global iter:   3448/156230 | loss: 1.1422 | ds_loss: 1.1360 | lr: 9.9881e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3448/156230 | global iter:   3448/156230 | loss: 1.1054 | ds_loss: 1.1116 | lr: 9.9881e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3449/156230 | global iter:   3449/156230 | loss: 1.3255 | ds_loss: 1.3291 | lr: 9.9881e-05 | scale: 32768.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:   3450/156230 | global iter:   3450/156230 | loss: 1.1767 | ds_loss: 1.1877 | lr: 9.9881e-05 | scale: 32768.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   3451/156230 | global iter:   3451/156230 | loss: 1.2438 | ds_loss: 1.2494 | lr: 9.9881e-05 | scale: 32768.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   3452/156230 | global iter:   3452/156230 | loss: 0.9832 | ds_loss: 1.0021 | lr: 9.9881e-05 | scale: 32768.0000 | micro time: 1.382 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3452/156230 | global iter:   3452/156230 | loss: 1.1823 | ds_loss: 1.1921 | lr: 9.9881e-05 | scale: 32768.0000 | micro time: 1.382 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3453/156230 | global iter:   3453/156230 | loss: 1.2265 | ds_loss: 1.2447 | lr: 9.9881e-05 | scale: 32768.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   3454/156230 | global iter:   3454/156230 | loss: 1.1931 | ds_loss: 1.2079 | lr: 9.9881e-05 | scale: 32768.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   3455/156230 | global iter:   3455/156230 | loss: 1.1845 | ds_loss: 1.1853 | lr: 9.9881e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   3456/156230 | global iter:   3456/156230 | loss: 1.0630 | ds_loss: 1.0846 | lr: 9.9881e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3456/156230 | global iter:   3456/156230 | loss: 1.1668 | ds_loss: 1.1806 | lr: 9.9881e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3457/156230 | global iter:   3457/156230 | loss: 1.1103 | ds_loss: 1.1108 | lr: 9.9881e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   3458/156230 | global iter:   3458/156230 | loss: 1.1732 | ds_loss: 1.1858 | lr: 9.9881e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   3459/156230 | global iter:   3459/156230 | loss: 1.1026 | ds_loss: 1.0982 | lr: 9.9881e-05 | scale: 32768.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   3460/156230 | global iter:   3460/156230 | loss: 1.2003 | ds_loss: 1.2036 | lr: 9.9881e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3460/156230 | global iter:   3460/156230 | loss: 1.1466 | ds_loss: 1.1496 | lr: 9.9881e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3461/156230 | global iter:   3461/156230 | loss: 1.2796 | ds_loss: 1.2886 | lr: 9.9880e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   3462/156230 | global iter:   3462/156230 | loss: 1.0530 | ds_loss: 1.0363 | lr: 9.9880e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   3463/156230 | global iter:   3463/156230 | loss: 0.9809 | ds_loss: 0.9996 | lr: 9.9880e-05 | scale: 32768.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   3464/156230 | global iter:   3464/156230 | loss: 1.2136 | ds_loss: 1.2123 | lr: 9.9880e-05 | scale: 32768.0000 | micro time: 1.382 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3464/156230 | global iter:   3464/156230 | loss: 1.1318 | ds_loss: 1.1342 | lr: 9.9880e-05 | scale: 32768.0000 | micro time: 1.382 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3465/156230 | global iter:   3465/156230 | loss: 1.0486 | ds_loss: 1.0654 | lr: 9.9880e-05 | scale: 32768.0000 | micro time: 1.416 | step time: 0.000
train | epoch   0 | Iter:   3466/156230 | global iter:   3466/156230 | loss: 1.1299 | ds_loss: 1.1390 | lr: 9.9880e-05 | scale: 32768.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   3467/156230 | global iter:   3467/156230 | loss: 1.2566 | ds_loss: 1.2686 | lr: 9.9880e-05 | scale: 32768.0000 | micro time: 1.315 | step time: 0.000
train | epoch   0 | Iter:   3468/156230 | global iter:   3468/156230 | loss: 1.0913 | ds_loss: 1.1081 | lr: 9.9880e-05 | scale: 32768.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3468/156230 | global iter:   3468/156230 | loss: 1.1316 | ds_loss: 1.1453 | lr: 9.9880e-05 | scale: 32768.0000 | micro time: 1.370 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3469/156230 | global iter:   3469/156230 | loss: 1.0741 | ds_loss: 1.0817 | lr: 9.9880e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   3470/156230 | global iter:   3470/156230 | loss: 1.1565 | ds_loss: 1.1677 | lr: 9.9880e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   3471/156230 | global iter:   3471/156230 | loss: 1.0847 | ds_loss: 1.0905 | lr: 9.9880e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   3472/156230 | global iter:   3472/156230 | loss: 1.0273 | ds_loss: 1.0431 | lr: 9.9880e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3472/156230 | global iter:   3472/156230 | loss: 1.0857 | ds_loss: 1.0958 | lr: 9.9880e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3473/156230 | global iter:   3473/156230 | loss: 1.2143 | ds_loss: 1.2166 | lr: 9.9880e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   3474/156230 | global iter:   3474/156230 | loss: 1.0580 | ds_loss: 1.0672 | lr: 9.9880e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   3475/156230 | global iter:   3475/156230 | loss: 1.0825 | ds_loss: 1.0839 | lr: 9.9879e-05 | scale: 32768.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   3476/156230 | global iter:   3476/156230 | loss: 1.1670 | ds_loss: 1.1798 | lr: 9.9879e-05 | scale: 32768.0000 | micro time: 1.333 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3476/156230 | global iter:   3476/156230 | loss: 1.1305 | ds_loss: 1.1369 | lr: 9.9879e-05 | scale: 32768.0000 | micro time: 1.333 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3477/156230 | global iter:   3477/156230 | loss: 1.1685 | ds_loss: 1.1735 | lr: 9.9879e-05 | scale: 32768.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   3478/156230 | global iter:   3478/156230 | loss: 1.2549 | ds_loss: 1.2729 | lr: 9.9879e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   3479/156230 | global iter:   3479/156230 | loss: 1.1259 | ds_loss: 1.1329 | lr: 9.9879e-05 | scale: 32768.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   3480/156230 | global iter:   3480/156230 | loss: 1.1250 | ds_loss: 1.1235 | lr: 9.9879e-05 | scale: 32768.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3480/156230 | global iter:   3480/156230 | loss: 1.1686 | ds_loss: 1.1757 | lr: 9.9879e-05 | scale: 32768.0000 | micro time: 1.370 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3481/156230 | global iter:   3481/156230 | loss: 1.1309 | ds_loss: 1.1291 | lr: 9.9879e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   3482/156230 | global iter:   3482/156230 | loss: 1.1320 | ds_loss: 1.1357 | lr: 9.9879e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   3483/156230 | global iter:   3483/156230 | loss: 1.1278 | ds_loss: 1.1476 | lr: 9.9879e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   3484/156230 | global iter:   3484/156230 | loss: 1.1566 | ds_loss: 1.1753 | lr: 9.9879e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3484/156230 | global iter:   3484/156230 | loss: 1.1368 | ds_loss: 1.1469 | lr: 9.9879e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3485/156230 | global iter:   3485/156230 | loss: 1.2144 | ds_loss: 1.2448 | lr: 9.9879e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   3486/156230 | global iter:   3486/156230 | loss: 1.2822 | ds_loss: 1.2814 | lr: 9.9879e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   3487/156230 | global iter:   3487/156230 | loss: 1.1059 | ds_loss: 1.1224 | lr: 9.9879e-05 | scale: 32768.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   3488/156230 | global iter:   3488/156230 | loss: 1.2825 | ds_loss: 1.3025 | lr: 9.9879e-05 | scale: 32768.0000 | micro time: 1.382 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3488/156230 | global iter:   3488/156230 | loss: 1.2212 | ds_loss: 1.2378 | lr: 9.9879e-05 | scale: 32768.0000 | micro time: 1.382 | step time: 1.380
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3489/156230 | global iter:   3489/156230 | loss: 1.1504 | ds_loss: 1.1696 | lr: 9.9879e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   3490/156230 | global iter:   3490/156230 | loss: 1.1329 | ds_loss: 1.1317 | lr: 9.9878e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   3491/156230 | global iter:   3491/156230 | loss: 1.1337 | ds_loss: 1.1495 | lr: 9.9878e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   3492/156230 | global iter:   3492/156230 | loss: 1.2170 | ds_loss: 1.2256 | lr: 9.9878e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3492/156230 | global iter:   3492/156230 | loss: 1.1585 | ds_loss: 1.1691 | lr: 9.9878e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3493/156230 | global iter:   3493/156230 | loss: 1.0753 | ds_loss: 1.0739 | lr: 9.9878e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   3494/156230 | global iter:   3494/156230 | loss: 1.1543 | ds_loss: 1.1665 | lr: 9.9878e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   3495/156230 | global iter:   3495/156230 | loss: 0.9454 | ds_loss: 0.9666 | lr: 9.9878e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   3496/156230 | global iter:   3496/156230 | loss: 1.3176 | ds_loss: 1.3267 | lr: 9.9878e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3496/156230 | global iter:   3496/156230 | loss: 1.1231 | ds_loss: 1.1334 | lr: 9.9878e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3497/156230 | global iter:   3497/156230 | loss: 0.9178 | ds_loss: 0.9305 | lr: 9.9878e-05 | scale: 32768.0000 | micro time: 1.400 | step time: 0.000
train | epoch   0 | Iter:   3498/156230 | global iter:   3498/156230 | loss: 1.0916 | ds_loss: 1.0878 | lr: 9.9878e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   3499/156230 | global iter:   3499/156230 | loss: 1.0746 | ds_loss: 1.0829 | lr: 9.9878e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   3500/156230 | global iter:   3500/156230 | loss: 1.1475 | ds_loss: 1.1497 | lr: 9.9878e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3500/156230 | global iter:   3500/156230 | loss: 1.0579 | ds_loss: 1.0627 | lr: 9.9878e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3501/156230 | global iter:   3501/156230 | loss: 1.0671 | ds_loss: 1.0773 | lr: 9.9878e-05 | scale: 32768.0000 | micro time: 1.403 | step time: 0.000
train | epoch   0 | Iter:   3502/156230 | global iter:   3502/156230 | loss: 1.3519 | ds_loss: 1.3690 | lr: 9.9878e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   3503/156230 | global iter:   3503/156230 | loss: 1.0911 | ds_loss: 1.1086 | lr: 9.9878e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   3504/156230 | global iter:   3504/156230 | loss: 1.0786 | ds_loss: 1.0897 | lr: 9.9877e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3504/156230 | global iter:   3504/156230 | loss: 1.1472 | ds_loss: 1.1612 | lr: 9.9877e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3505/156230 | global iter:   3505/156230 | loss: 1.1636 | ds_loss: 1.1862 | lr: 9.9877e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   3506/156230 | global iter:   3506/156230 | loss: 1.2270 | ds_loss: 1.2301 | lr: 9.9877e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   3507/156230 | global iter:   3507/156230 | loss: 1.0823 | ds_loss: 1.0897 | lr: 9.9877e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   3508/156230 | global iter:   3508/156230 | loss: 1.0368 | ds_loss: 1.0394 | lr: 9.9877e-05 | scale: 32768.0000 | micro time: 1.387 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3508/156230 | global iter:   3508/156230 | loss: 1.1274 | ds_loss: 1.1364 | lr: 9.9877e-05 | scale: 32768.0000 | micro time: 1.387 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3509/156230 | global iter:   3509/156230 | loss: 1.0246 | ds_loss: 1.0313 | lr: 9.9877e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   3510/156230 | global iter:   3510/156230 | loss: 1.1755 | ds_loss: 1.1877 | lr: 9.9877e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   3511/156230 | global iter:   3511/156230 | loss: 1.2144 | ds_loss: 1.2303 | lr: 9.9877e-05 | scale: 32768.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   3512/156230 | global iter:   3512/156230 | loss: 1.2507 | ds_loss: 1.2536 | lr: 9.9877e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3512/156230 | global iter:   3512/156230 | loss: 1.1663 | ds_loss: 1.1757 | lr: 9.9877e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3513/156230 | global iter:   3513/156230 | loss: 1.2311 | ds_loss: 1.2502 | lr: 9.9877e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   3514/156230 | global iter:   3514/156230 | loss: 1.2190 | ds_loss: 1.2267 | lr: 9.9877e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   3515/156230 | global iter:   3515/156230 | loss: 1.3745 | ds_loss: 1.3851 | lr: 9.9877e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   3516/156230 | global iter:   3516/156230 | loss: 1.1177 | ds_loss: 1.1248 | lr: 9.9877e-05 | scale: 32768.0000 | micro time: 1.344 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3516/156230 | global iter:   3516/156230 | loss: 1.2356 | ds_loss: 1.2467 | lr: 9.9877e-05 | scale: 32768.0000 | micro time: 1.344 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3517/156230 | global iter:   3517/156230 | loss: 0.9881 | ds_loss: 1.0073 | lr: 9.9877e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   3518/156230 | global iter:   3518/156230 | loss: 1.1571 | ds_loss: 1.1736 | lr: 9.9876e-05 | scale: 32768.0000 | micro time: 1.410 | step time: 0.000
train | epoch   0 | Iter:   3519/156230 | global iter:   3519/156230 | loss: 1.2134 | ds_loss: 1.2298 | lr: 9.9876e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   3520/156230 | global iter:   3520/156230 | loss: 1.1950 | ds_loss: 1.2043 | lr: 9.9876e-05 | scale: 32768.0000 | micro time: 1.403 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3520/156230 | global iter:   3520/156230 | loss: 1.1384 | ds_loss: 1.1537 | lr: 9.9876e-05 | scale: 32768.0000 | micro time: 1.403 | step time: 1.376
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3521/156230 | global iter:   3521/156230 | loss: 1.0911 | ds_loss: 1.1006 | lr: 9.9876e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   3522/156230 | global iter:   3522/156230 | loss: 1.1377 | ds_loss: 1.1567 | lr: 9.9876e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   3523/156230 | global iter:   3523/156230 | loss: 1.1298 | ds_loss: 1.1598 | lr: 9.9876e-05 | scale: 32768.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   3524/156230 | global iter:   3524/156230 | loss: 1.1113 | ds_loss: 1.1152 | lr: 9.9876e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3524/156230 | global iter:   3524/156230 | loss: 1.1174 | ds_loss: 1.1331 | lr: 9.9876e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3525/156230 | global iter:   3525/156230 | loss: 1.2908 | ds_loss: 1.2937 | lr: 9.9876e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   3526/156230 | global iter:   3526/156230 | loss: 0.9819 | ds_loss: 0.9810 | lr: 9.9876e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   3527/156230 | global iter:   3527/156230 | loss: 1.2272 | ds_loss: 1.2506 | lr: 9.9876e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   3528/156230 | global iter:   3528/156230 | loss: 1.2208 | ds_loss: 1.2431 | lr: 9.9876e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3528/156230 | global iter:   3528/156230 | loss: 1.1802 | ds_loss: 1.1921 | lr: 9.9876e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3529/156230 | global iter:   3529/156230 | loss: 1.1622 | ds_loss: 1.1796 | lr: 9.9876e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   3530/156230 | global iter:   3530/156230 | loss: 1.1070 | ds_loss: 1.1319 | lr: 9.9876e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   3531/156230 | global iter:   3531/156230 | loss: 1.0846 | ds_loss: 1.1105 | lr: 9.9876e-05 | scale: 32768.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   3532/156230 | global iter:   3532/156230 | loss: 1.1950 | ds_loss: 1.1909 | lr: 9.9875e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3532/156230 | global iter:   3532/156230 | loss: 1.1372 | ds_loss: 1.1532 | lr: 9.9875e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3533/156230 | global iter:   3533/156230 | loss: 0.9904 | ds_loss: 1.0064 | lr: 9.9875e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   3534/156230 | global iter:   3534/156230 | loss: 1.1046 | ds_loss: 1.1282 | lr: 9.9875e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   3535/156230 | global iter:   3535/156230 | loss: 1.1764 | ds_loss: 1.1972 | lr: 9.9875e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   3536/156230 | global iter:   3536/156230 | loss: 1.1238 | ds_loss: 1.1450 | lr: 9.9875e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3536/156230 | global iter:   3536/156230 | loss: 1.0988 | ds_loss: 1.1192 | lr: 9.9875e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 1.379
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3537/156230 | global iter:   3537/156230 | loss: 1.1470 | ds_loss: 1.1346 | lr: 9.9875e-05 | scale: 32768.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   3538/156230 | global iter:   3538/156230 | loss: 1.1659 | ds_loss: 1.1803 | lr: 9.9875e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   3539/156230 | global iter:   3539/156230 | loss: 1.1023 | ds_loss: 1.1172 | lr: 9.9875e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   3540/156230 | global iter:   3540/156230 | loss: 1.1345 | ds_loss: 1.1504 | lr: 9.9875e-05 | scale: 32768.0000 | micro time: 1.318 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3540/156230 | global iter:   3540/156230 | loss: 1.1374 | ds_loss: 1.1456 | lr: 9.9875e-05 | scale: 32768.0000 | micro time: 1.318 | step time: 1.341
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3541/156230 | global iter:   3541/156230 | loss: 1.1735 | ds_loss: 1.1959 | lr: 9.9875e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   3542/156230 | global iter:   3542/156230 | loss: 1.1255 | ds_loss: 1.1375 | lr: 9.9875e-05 | scale: 32768.0000 | micro time: 1.407 | step time: 0.000
train | epoch   0 | Iter:   3543/156230 | global iter:   3543/156230 | loss: 1.1545 | ds_loss: 1.1551 | lr: 9.9875e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   3544/156230 | global iter:   3544/156230 | loss: 1.1054 | ds_loss: 1.1177 | lr: 9.9875e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3544/156230 | global iter:   3544/156230 | loss: 1.1397 | ds_loss: 1.1516 | lr: 9.9875e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3545/156230 | global iter:   3545/156230 | loss: 1.2556 | ds_loss: 1.2621 | lr: 9.9875e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   3546/156230 | global iter:   3546/156230 | loss: 1.1761 | ds_loss: 1.1865 | lr: 9.9874e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   3547/156230 | global iter:   3547/156230 | loss: 1.0447 | ds_loss: 1.0739 | lr: 9.9874e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   3548/156230 | global iter:   3548/156230 | loss: 1.0980 | ds_loss: 1.1143 | lr: 9.9874e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3548/156230 | global iter:   3548/156230 | loss: 1.1436 | ds_loss: 1.1592 | lr: 9.9874e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3549/156230 | global iter:   3549/156230 | loss: 0.9659 | ds_loss: 0.9836 | lr: 9.9874e-05 | scale: 32768.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   3550/156230 | global iter:   3550/156230 | loss: 1.2177 | ds_loss: 1.2250 | lr: 9.9874e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   3551/156230 | global iter:   3551/156230 | loss: 1.0406 | ds_loss: 1.0433 | lr: 9.9874e-05 | scale: 32768.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   3552/156230 | global iter:   3552/156230 | loss: 1.1235 | ds_loss: 1.1306 | lr: 9.9874e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3552/156230 | global iter:   3552/156230 | loss: 1.0869 | ds_loss: 1.0956 | lr: 9.9874e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3553/156230 | global iter:   3553/156230 | loss: 1.0172 | ds_loss: 1.0138 | lr: 9.9874e-05 | scale: 32768.0000 | micro time: 1.411 | step time: 0.000
train | epoch   0 | Iter:   3554/156230 | global iter:   3554/156230 | loss: 1.1386 | ds_loss: 1.1730 | lr: 9.9874e-05 | scale: 32768.0000 | micro time: 1.407 | step time: 0.000
train | epoch   0 | Iter:   3555/156230 | global iter:   3555/156230 | loss: 1.2014 | ds_loss: 1.2117 | lr: 9.9874e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   3556/156230 | global iter:   3556/156230 | loss: 1.1722 | ds_loss: 1.1932 | lr: 9.9874e-05 | scale: 32768.0000 | micro time: 1.310 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3556/156230 | global iter:   3556/156230 | loss: 1.1324 | ds_loss: 1.1479 | lr: 9.9874e-05 | scale: 32768.0000 | micro time: 1.310 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3557/156230 | global iter:   3557/156230 | loss: 1.2872 | ds_loss: 1.2932 | lr: 9.9874e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   3558/156230 | global iter:   3558/156230 | loss: 1.1339 | ds_loss: 1.1667 | lr: 9.9874e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   3559/156230 | global iter:   3559/156230 | loss: 1.0865 | ds_loss: 1.1131 | lr: 9.9874e-05 | scale: 32768.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:   3560/156230 | global iter:   3560/156230 | loss: 1.1770 | ds_loss: 1.1913 | lr: 9.9873e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3560/156230 | global iter:   3560/156230 | loss: 1.1712 | ds_loss: 1.1911 | lr: 9.9873e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 1.348
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3561/156230 | global iter:   3561/156230 | loss: 1.1328 | ds_loss: 1.1599 | lr: 9.9873e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   3562/156230 | global iter:   3562/156230 | loss: 1.2952 | ds_loss: 1.2963 | lr: 9.9873e-05 | scale: 32768.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   3563/156230 | global iter:   3563/156230 | loss: 1.1447 | ds_loss: 1.1472 | lr: 9.9873e-05 | scale: 32768.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:   3564/156230 | global iter:   3564/156230 | loss: 1.2172 | ds_loss: 1.2315 | lr: 9.9873e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3564/156230 | global iter:   3564/156230 | loss: 1.1975 | ds_loss: 1.2087 | lr: 9.9873e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3565/156230 | global iter:   3565/156230 | loss: 1.1047 | ds_loss: 1.1061 | lr: 9.9873e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   3566/156230 | global iter:   3566/156230 | loss: 1.0602 | ds_loss: 1.0542 | lr: 9.9873e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   3567/156230 | global iter:   3567/156230 | loss: 1.2063 | ds_loss: 1.2153 | lr: 9.9873e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   3568/156230 | global iter:   3568/156230 | loss: 1.1873 | ds_loss: 1.1999 | lr: 9.9873e-05 | scale: 32768.0000 | micro time: 1.384 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3568/156230 | global iter:   3568/156230 | loss: 1.1396 | ds_loss: 1.1439 | lr: 9.9873e-05 | scale: 32768.0000 | micro time: 1.384 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3569/156230 | global iter:   3569/156230 | loss: 1.2180 | ds_loss: 1.2306 | lr: 9.9873e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   3570/156230 | global iter:   3570/156230 | loss: 1.2328 | ds_loss: 1.2397 | lr: 9.9873e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   3571/156230 | global iter:   3571/156230 | loss: 1.0313 | ds_loss: 1.0471 | lr: 9.9873e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   3572/156230 | global iter:   3572/156230 | loss: 1.0437 | ds_loss: 1.0620 | lr: 9.9873e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3572/156230 | global iter:   3572/156230 | loss: 1.1315 | ds_loss: 1.1448 | lr: 9.9873e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3573/156230 | global iter:   3573/156230 | loss: 1.2290 | ds_loss: 1.2375 | lr: 9.9873e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   3574/156230 | global iter:   3574/156230 | loss: 1.1885 | ds_loss: 1.1937 | lr: 9.9872e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   3575/156230 | global iter:   3575/156230 | loss: 1.1015 | ds_loss: 1.1133 | lr: 9.9872e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   3576/156230 | global iter:   3576/156230 | loss: 1.0255 | ds_loss: 1.0436 | lr: 9.9872e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3576/156230 | global iter:   3576/156230 | loss: 1.1361 | ds_loss: 1.1471 | lr: 9.9872e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3577/156230 | global iter:   3577/156230 | loss: 1.0456 | ds_loss: 1.0620 | lr: 9.9872e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   3578/156230 | global iter:   3578/156230 | loss: 1.1388 | ds_loss: 1.1373 | lr: 9.9872e-05 | scale: 32768.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   3579/156230 | global iter:   3579/156230 | loss: 1.1822 | ds_loss: 1.1933 | lr: 9.9872e-05 | scale: 32768.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   3580/156230 | global iter:   3580/156230 | loss: 1.1041 | ds_loss: 1.1248 | lr: 9.9872e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3580/156230 | global iter:   3580/156230 | loss: 1.1177 | ds_loss: 1.1293 | lr: 9.9872e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3581/156230 | global iter:   3581/156230 | loss: 1.1769 | ds_loss: 1.1786 | lr: 9.9872e-05 | scale: 32768.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   3582/156230 | global iter:   3582/156230 | loss: 1.1432 | ds_loss: 1.1659 | lr: 9.9872e-05 | scale: 32768.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   3583/156230 | global iter:   3583/156230 | loss: 1.0830 | ds_loss: 1.0877 | lr: 9.9872e-05 | scale: 32768.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   3584/156230 | global iter:   3584/156230 | loss: 1.0534 | ds_loss: 1.0517 | lr: 9.9872e-05 | scale: 32768.0000 | micro time: 1.334 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3584/156230 | global iter:   3584/156230 | loss: 1.1141 | ds_loss: 1.1210 | lr: 9.9872e-05 | scale: 32768.0000 | micro time: 1.334 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3585/156230 | global iter:   3585/156230 | loss: 1.0888 | ds_loss: 1.0861 | lr: 9.9872e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   3586/156230 | global iter:   3586/156230 | loss: 1.2551 | ds_loss: 1.2558 | lr: 9.9872e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   3587/156230 | global iter:   3587/156230 | loss: 1.1151 | ds_loss: 1.1339 | lr: 9.9872e-05 | scale: 32768.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   3588/156230 | global iter:   3588/156230 | loss: 1.2469 | ds_loss: 1.2600 | lr: 9.9871e-05 | scale: 32768.0000 | micro time: 1.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3588/156230 | global iter:   3588/156230 | loss: 1.1765 | ds_loss: 1.1839 | lr: 9.9871e-05 | scale: 32768.0000 | micro time: 1.394 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3589/156230 | global iter:   3589/156230 | loss: 1.2665 | ds_loss: 1.2909 | lr: 9.9871e-05 | scale: 32768.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   3590/156230 | global iter:   3590/156230 | loss: 1.1687 | ds_loss: 1.1700 | lr: 9.9871e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   3591/156230 | global iter:   3591/156230 | loss: 1.1903 | ds_loss: 1.2187 | lr: 9.9871e-05 | scale: 32768.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   3592/156230 | global iter:   3592/156230 | loss: 1.1635 | ds_loss: 1.1715 | lr: 9.9871e-05 | scale: 32768.0000 | micro time: 1.402 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3592/156230 | global iter:   3592/156230 | loss: 1.1973 | ds_loss: 1.2128 | lr: 9.9871e-05 | scale: 32768.0000 | micro time: 1.402 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3593/156230 | global iter:   3593/156230 | loss: 1.2744 | ds_loss: 1.2969 | lr: 9.9871e-05 | scale: 32768.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   3594/156230 | global iter:   3594/156230 | loss: 1.3902 | ds_loss: 1.4028 | lr: 9.9871e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   3595/156230 | global iter:   3595/156230 | loss: 1.1481 | ds_loss: 1.1650 | lr: 9.9871e-05 | scale: 32768.0000 | micro time: 1.419 | step time: 0.000
train | epoch   0 | Iter:   3596/156230 | global iter:   3596/156230 | loss: 1.1314 | ds_loss: 1.1415 | lr: 9.9871e-05 | scale: 32768.0000 | micro time: 1.391 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3596/156230 | global iter:   3596/156230 | loss: 1.2360 | ds_loss: 1.2516 | lr: 9.9871e-05 | scale: 32768.0000 | micro time: 1.391 | step time: 1.394
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3597/156230 | global iter:   3597/156230 | loss: 1.2264 | ds_loss: 1.2392 | lr: 9.9871e-05 | scale: 32768.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   3598/156230 | global iter:   3598/156230 | loss: 1.1899 | ds_loss: 1.2218 | lr: 9.9871e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   3599/156230 | global iter:   3599/156230 | loss: 1.1852 | ds_loss: 1.1999 | lr: 9.9871e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   3600/156230 | global iter:   3600/156230 | loss: 1.0502 | ds_loss: 1.0640 | lr: 9.9871e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3600/156230 | global iter:   3600/156230 | loss: 1.1629 | ds_loss: 1.1812 | lr: 9.9871e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3601/156230 | global iter:   3601/156230 | loss: 1.2099 | ds_loss: 1.2325 | lr: 9.9871e-05 | scale: 32768.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   3602/156230 | global iter:   3602/156230 | loss: 1.2439 | ds_loss: 1.2611 | lr: 9.9870e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   3603/156230 | global iter:   3603/156230 | loss: 1.1863 | ds_loss: 1.2026 | lr: 9.9870e-05 | scale: 32768.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   3604/156230 | global iter:   3604/156230 | loss: 1.2476 | ds_loss: 1.2538 | lr: 9.9870e-05 | scale: 32768.0000 | micro time: 1.331 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3604/156230 | global iter:   3604/156230 | loss: 1.2219 | ds_loss: 1.2375 | lr: 9.9870e-05 | scale: 32768.0000 | micro time: 1.331 | step time: 1.342
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3605/156230 | global iter:   3605/156230 | loss: 1.1030 | ds_loss: 1.1243 | lr: 9.9870e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   3606/156230 | global iter:   3606/156230 | loss: 0.9703 | ds_loss: 0.9766 | lr: 9.9870e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   3607/156230 | global iter:   3607/156230 | loss: 1.1752 | ds_loss: 1.1957 | lr: 9.9870e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   3608/156230 | global iter:   3608/156230 | loss: 1.2368 | ds_loss: 1.2513 | lr: 9.9870e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3608/156230 | global iter:   3608/156230 | loss: 1.1213 | ds_loss: 1.1370 | lr: 9.9870e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3609/156230 | global iter:   3609/156230 | loss: 1.1145 | ds_loss: 1.1344 | lr: 9.9870e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   3610/156230 | global iter:   3610/156230 | loss: 1.1965 | ds_loss: 1.2117 | lr: 9.9870e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   3611/156230 | global iter:   3611/156230 | loss: 1.2468 | ds_loss: 1.2619 | lr: 9.9870e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   3612/156230 | global iter:   3612/156230 | loss: 0.9841 | ds_loss: 0.9925 | lr: 9.9870e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3612/156230 | global iter:   3612/156230 | loss: 1.1355 | ds_loss: 1.1501 | lr: 9.9870e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3613/156230 | global iter:   3613/156230 | loss: 1.1451 | ds_loss: 1.1518 | lr: 9.9870e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   3614/156230 | global iter:   3614/156230 | loss: 1.2280 | ds_loss: 1.2475 | lr: 9.9870e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   3615/156230 | global iter:   3615/156230 | loss: 1.1816 | ds_loss: 1.1827 | lr: 9.9870e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   3616/156230 | global iter:   3616/156230 | loss: 0.8485 | ds_loss: 0.8785 | lr: 9.9869e-05 | scale: 32768.0000 | micro time: 1.340 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3616/156230 | global iter:   3616/156230 | loss: 1.1008 | ds_loss: 1.1151 | lr: 9.9869e-05 | scale: 32768.0000 | micro time: 1.340 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3617/156230 | global iter:   3617/156230 | loss: 1.1396 | ds_loss: 1.1655 | lr: 9.9869e-05 | scale: 32768.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   3618/156230 | global iter:   3618/156230 | loss: 1.3912 | ds_loss: 1.3976 | lr: 9.9869e-05 | scale: 32768.0000 | micro time: 1.409 | step time: 0.000
train | epoch   0 | Iter:   3619/156230 | global iter:   3619/156230 | loss: 1.0224 | ds_loss: 1.0382 | lr: 9.9869e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   3620/156230 | global iter:   3620/156230 | loss: 1.2466 | ds_loss: 1.2619 | lr: 9.9869e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3620/156230 | global iter:   3620/156230 | loss: 1.2000 | ds_loss: 1.2158 | lr: 9.9869e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 1.384
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3621/156230 | global iter:   3621/156230 | loss: 1.1337 | ds_loss: 1.1400 | lr: 9.9869e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   3622/156230 | global iter:   3622/156230 | loss: 1.0747 | ds_loss: 1.0974 | lr: 9.9869e-05 | scale: 32768.0000 | micro time: 1.309 | step time: 0.000
train | epoch   0 | Iter:   3623/156230 | global iter:   3623/156230 | loss: 1.3607 | ds_loss: 1.3899 | lr: 9.9869e-05 | scale: 32768.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   3624/156230 | global iter:   3624/156230 | loss: 1.0249 | ds_loss: 1.0322 | lr: 9.9869e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3624/156230 | global iter:   3624/156230 | loss: 1.1485 | ds_loss: 1.1649 | lr: 9.9869e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3625/156230 | global iter:   3625/156230 | loss: 1.2674 | ds_loss: 1.2771 | lr: 9.9869e-05 | scale: 32768.0000 | micro time: 1.422 | step time: 0.000
train | epoch   0 | Iter:   3626/156230 | global iter:   3626/156230 | loss: 1.1723 | ds_loss: 1.2040 | lr: 9.9869e-05 | scale: 32768.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   3627/156230 | global iter:   3627/156230 | loss: 1.0197 | ds_loss: 1.0344 | lr: 9.9869e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   3628/156230 | global iter:   3628/156230 | loss: 1.1967 | ds_loss: 1.2251 | lr: 9.9869e-05 | scale: 32768.0000 | micro time: 1.384 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3628/156230 | global iter:   3628/156230 | loss: 1.1640 | ds_loss: 1.1852 | lr: 9.9869e-05 | scale: 32768.0000 | micro time: 1.384 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3629/156230 | global iter:   3629/156230 | loss: 1.2398 | ds_loss: 1.2560 | lr: 9.9869e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   3630/156230 | global iter:   3630/156230 | loss: 1.1979 | ds_loss: 1.2011 | lr: 9.9868e-05 | scale: 32768.0000 | micro time: 1.410 | step time: 0.000
train | epoch   0 | Iter:   3631/156230 | global iter:   3631/156230 | loss: 1.2349 | ds_loss: 1.2181 | lr: 9.9868e-05 | scale: 32768.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   3632/156230 | global iter:   3632/156230 | loss: 1.2164 | ds_loss: 1.2333 | lr: 9.9868e-05 | scale: 32768.0000 | micro time: 1.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3632/156230 | global iter:   3632/156230 | loss: 1.2222 | ds_loss: 1.2271 | lr: 9.9868e-05 | scale: 32768.0000 | micro time: 1.400 | step time: 1.379
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3633/156230 | global iter:   3633/156230 | loss: 1.1674 | ds_loss: 1.1760 | lr: 9.9868e-05 | scale: 32768.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   3634/156230 | global iter:   3634/156230 | loss: 1.2454 | ds_loss: 1.2596 | lr: 9.9868e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   3635/156230 | global iter:   3635/156230 | loss: 1.0862 | ds_loss: 1.0949 | lr: 9.9868e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   3636/156230 | global iter:   3636/156230 | loss: 1.2632 | ds_loss: 1.2854 | lr: 9.9868e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3636/156230 | global iter:   3636/156230 | loss: 1.1905 | ds_loss: 1.2040 | lr: 9.9868e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3637/156230 | global iter:   3637/156230 | loss: 1.0189 | ds_loss: 1.0372 | lr: 9.9868e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   3638/156230 | global iter:   3638/156230 | loss: 1.1637 | ds_loss: 1.1672 | lr: 9.9868e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   3639/156230 | global iter:   3639/156230 | loss: 1.1754 | ds_loss: 1.1788 | lr: 9.9868e-05 | scale: 32768.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:   3640/156230 | global iter:   3640/156230 | loss: 0.9882 | ds_loss: 0.9963 | lr: 9.9868e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3640/156230 | global iter:   3640/156230 | loss: 1.0865 | ds_loss: 1.0949 | lr: 9.9868e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3641/156230 | global iter:   3641/156230 | loss: 1.0691 | ds_loss: 1.0840 | lr: 9.9868e-05 | scale: 32768.0000 | micro time: 1.416 | step time: 0.000
train | epoch   0 | Iter:   3642/156230 | global iter:   3642/156230 | loss: 1.1948 | ds_loss: 1.1912 | lr: 9.9868e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   3643/156230 | global iter:   3643/156230 | loss: 1.3020 | ds_loss: 1.3149 | lr: 9.9867e-05 | scale: 32768.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   3644/156230 | global iter:   3644/156230 | loss: 1.1622 | ds_loss: 1.1707 | lr: 9.9867e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3644/156230 | global iter:   3644/156230 | loss: 1.1820 | ds_loss: 1.1902 | lr: 9.9867e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 1.381
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3645/156230 | global iter:   3645/156230 | loss: 1.0852 | ds_loss: 1.0943 | lr: 9.9867e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   3646/156230 | global iter:   3646/156230 | loss: 1.0958 | ds_loss: 1.1136 | lr: 9.9867e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   3647/156230 | global iter:   3647/156230 | loss: 1.1765 | ds_loss: 1.1915 | lr: 9.9867e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   3648/156230 | global iter:   3648/156230 | loss: 1.0914 | ds_loss: 1.1030 | lr: 9.9867e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3648/156230 | global iter:   3648/156230 | loss: 1.1122 | ds_loss: 1.1256 | lr: 9.9867e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3649/156230 | global iter:   3649/156230 | loss: 1.3182 | ds_loss: 1.3305 | lr: 9.9867e-05 | scale: 32768.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   3650/156230 | global iter:   3650/156230 | loss: 1.1106 | ds_loss: 1.1393 | lr: 9.9867e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   3651/156230 | global iter:   3651/156230 | loss: 1.2314 | ds_loss: 1.2480 | lr: 9.9867e-05 | scale: 32768.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   3652/156230 | global iter:   3652/156230 | loss: 1.2889 | ds_loss: 1.3212 | lr: 9.9867e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3652/156230 | global iter:   3652/156230 | loss: 1.2373 | ds_loss: 1.2598 | lr: 9.9867e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3653/156230 | global iter:   3653/156230 | loss: 1.0479 | ds_loss: 1.0554 | lr: 9.9867e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   3654/156230 | global iter:   3654/156230 | loss: 1.1269 | ds_loss: 1.1465 | lr: 9.9867e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   3655/156230 | global iter:   3655/156230 | loss: 1.2091 | ds_loss: 1.2273 | lr: 9.9867e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   3656/156230 | global iter:   3656/156230 | loss: 1.1960 | ds_loss: 1.2087 | lr: 9.9867e-05 | scale: 32768.0000 | micro time: 1.404 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3656/156230 | global iter:   3656/156230 | loss: 1.1450 | ds_loss: 1.1595 | lr: 9.9867e-05 | scale: 32768.0000 | micro time: 1.404 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3657/156230 | global iter:   3657/156230 | loss: 1.1792 | ds_loss: 1.1832 | lr: 9.9866e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   3658/156230 | global iter:   3658/156230 | loss: 1.0533 | ds_loss: 1.0611 | lr: 9.9866e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   3659/156230 | global iter:   3659/156230 | loss: 1.1054 | ds_loss: 1.1225 | lr: 9.9866e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   3660/156230 | global iter:   3660/156230 | loss: 1.0236 | ds_loss: 1.0403 | lr: 9.9866e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3660/156230 | global iter:   3660/156230 | loss: 1.0904 | ds_loss: 1.1018 | lr: 9.9866e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3661/156230 | global iter:   3661/156230 | loss: 1.2041 | ds_loss: 1.2155 | lr: 9.9866e-05 | scale: 32768.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   3662/156230 | global iter:   3662/156230 | loss: 0.9844 | ds_loss: 0.9979 | lr: 9.9866e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   3663/156230 | global iter:   3663/156230 | loss: 1.1904 | ds_loss: 1.2128 | lr: 9.9866e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   3664/156230 | global iter:   3664/156230 | loss: 1.1148 | ds_loss: 1.1292 | lr: 9.9866e-05 | scale: 32768.0000 | micro time: 1.318 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3664/156230 | global iter:   3664/156230 | loss: 1.1234 | ds_loss: 1.1389 | lr: 9.9866e-05 | scale: 32768.0000 | micro time: 1.318 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3665/156230 | global iter:   3665/156230 | loss: 1.3696 | ds_loss: 1.3778 | lr: 9.9866e-05 | scale: 32768.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   3666/156230 | global iter:   3666/156230 | loss: 1.0388 | ds_loss: 1.0348 | lr: 9.9866e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   3667/156230 | global iter:   3667/156230 | loss: 1.3364 | ds_loss: 1.3532 | lr: 9.9866e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   3668/156230 | global iter:   3668/156230 | loss: 1.0437 | ds_loss: 1.0546 | lr: 9.9866e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3668/156230 | global iter:   3668/156230 | loss: 1.1971 | ds_loss: 1.2051 | lr: 9.9866e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 1.348
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3669/156230 | global iter:   3669/156230 | loss: 1.0774 | ds_loss: 1.0892 | lr: 9.9866e-05 | scale: 32768.0000 | micro time: 1.404 | step time: 0.000
train | epoch   0 | Iter:   3670/156230 | global iter:   3670/156230 | loss: 1.1431 | ds_loss: 1.1463 | lr: 9.9866e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   3671/156230 | global iter:   3671/156230 | loss: 1.2282 | ds_loss: 1.2473 | lr: 9.9865e-05 | scale: 32768.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   3672/156230 | global iter:   3672/156230 | loss: 1.2671 | ds_loss: 1.2558 | lr: 9.9865e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3672/156230 | global iter:   3672/156230 | loss: 1.1790 | ds_loss: 1.1846 | lr: 9.9865e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3673/156230 | global iter:   3673/156230 | loss: 1.0134 | ds_loss: 1.0373 | lr: 9.9865e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   3674/156230 | global iter:   3674/156230 | loss: 1.0243 | ds_loss: 1.0489 | lr: 9.9865e-05 | scale: 32768.0000 | micro time: 1.405 | step time: 0.000
train | epoch   0 | Iter:   3675/156230 | global iter:   3675/156230 | loss: 1.2521 | ds_loss: 1.2702 | lr: 9.9865e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   3676/156230 | global iter:   3676/156230 | loss: 1.0939 | ds_loss: 1.0950 | lr: 9.9865e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3676/156230 | global iter:   3676/156230 | loss: 1.0959 | ds_loss: 1.1129 | lr: 9.9865e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3677/156230 | global iter:   3677/156230 | loss: 1.1757 | ds_loss: 1.1556 | lr: 9.9865e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   3678/156230 | global iter:   3678/156230 | loss: 1.0544 | ds_loss: 1.0670 | lr: 9.9865e-05 | scale: 32768.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   3679/156230 | global iter:   3679/156230 | loss: 0.9926 | ds_loss: 0.9912 | lr: 9.9865e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   3680/156230 | global iter:   3680/156230 | loss: 1.2006 | ds_loss: 1.2103 | lr: 9.9865e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3680/156230 | global iter:   3680/156230 | loss: 1.1058 | ds_loss: 1.1060 | lr: 9.9865e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3681/156230 | global iter:   3681/156230 | loss: 1.1506 | ds_loss: 1.1710 | lr: 9.9865e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   3682/156230 | global iter:   3682/156230 | loss: 1.2635 | ds_loss: 1.2904 | lr: 9.9865e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   3683/156230 | global iter:   3683/156230 | loss: 1.0943 | ds_loss: 1.1108 | lr: 9.9865e-05 | scale: 32768.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   3684/156230 | global iter:   3684/156230 | loss: 1.2116 | ds_loss: 1.2067 | lr: 9.9864e-05 | scale: 32768.0000 | micro time: 1.476 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3684/156230 | global iter:   3684/156230 | loss: 1.1800 | ds_loss: 1.1947 | lr: 9.9864e-05 | scale: 32768.0000 | micro time: 1.476 | step time: 1.398
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3685/156230 | global iter:   3685/156230 | loss: 1.1164 | ds_loss: 1.1173 | lr: 9.9864e-05 | scale: 32768.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   3686/156230 | global iter:   3686/156230 | loss: 1.0452 | ds_loss: 1.0483 | lr: 9.9864e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   3687/156230 | global iter:   3687/156230 | loss: 1.1916 | ds_loss: 1.1978 | lr: 9.9864e-05 | scale: 32768.0000 | micro time: 1.411 | step time: 0.000
train | epoch   0 | Iter:   3688/156230 | global iter:   3688/156230 | loss: 1.2799 | ds_loss: 1.2938 | lr: 9.9864e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3688/156230 | global iter:   3688/156230 | loss: 1.1583 | ds_loss: 1.1643 | lr: 9.9864e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3689/156230 | global iter:   3689/156230 | loss: 1.0765 | ds_loss: 1.0892 | lr: 9.9864e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   3690/156230 | global iter:   3690/156230 | loss: 1.0795 | ds_loss: 1.0804 | lr: 9.9864e-05 | scale: 32768.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   3691/156230 | global iter:   3691/156230 | loss: 1.1852 | ds_loss: 1.1896 | lr: 9.9864e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   3692/156230 | global iter:   3692/156230 | loss: 1.1655 | ds_loss: 1.1741 | lr: 9.9864e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3692/156230 | global iter:   3692/156230 | loss: 1.1267 | ds_loss: 1.1333 | lr: 9.9864e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3693/156230 | global iter:   3693/156230 | loss: 1.1954 | ds_loss: 1.2075 | lr: 9.9864e-05 | scale: 32768.0000 | micro time: 1.400 | step time: 0.000
train | epoch   0 | Iter:   3694/156230 | global iter:   3694/156230 | loss: 1.2496 | ds_loss: 1.2425 | lr: 9.9864e-05 | scale: 32768.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   3695/156230 | global iter:   3695/156230 | loss: 1.1775 | ds_loss: 1.1895 | lr: 9.9864e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   3696/156230 | global iter:   3696/156230 | loss: 1.1835 | ds_loss: 1.2069 | lr: 9.9864e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3696/156230 | global iter:   3696/156230 | loss: 1.2015 | ds_loss: 1.2116 | lr: 9.9864e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3697/156230 | global iter:   3697/156230 | loss: 1.2416 | ds_loss: 1.2462 | lr: 9.9864e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   3698/156230 | global iter:   3698/156230 | loss: 1.0963 | ds_loss: 1.1096 | lr: 9.9863e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   3699/156230 | global iter:   3699/156230 | loss: 0.9484 | ds_loss: 0.9640 | lr: 9.9863e-05 | scale: 32768.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:   3700/156230 | global iter:   3700/156230 | loss: 1.1256 | ds_loss: 1.1269 | lr: 9.9863e-05 | scale: 32768.0000 | micro time: 1.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3700/156230 | global iter:   3700/156230 | loss: 1.1030 | ds_loss: 1.1117 | lr: 9.9863e-05 | scale: 32768.0000 | micro time: 1.394 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3701/156230 | global iter:   3701/156230 | loss: 1.1290 | ds_loss: 1.1541 | lr: 9.9863e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   3702/156230 | global iter:   3702/156230 | loss: 1.0623 | ds_loss: 1.0681 | lr: 9.9863e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   3703/156230 | global iter:   3703/156230 | loss: 1.2462 | ds_loss: 1.2527 | lr: 9.9863e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   3704/156230 | global iter:   3704/156230 | loss: 1.1407 | ds_loss: 1.1706 | lr: 9.9863e-05 | scale: 32768.0000 | micro time: 1.391 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3704/156230 | global iter:   3704/156230 | loss: 1.1445 | ds_loss: 1.1614 | lr: 9.9863e-05 | scale: 32768.0000 | micro time: 1.391 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3705/156230 | global iter:   3705/156230 | loss: 0.9708 | ds_loss: 0.9984 | lr: 9.9863e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   3706/156230 | global iter:   3706/156230 | loss: 1.0585 | ds_loss: 1.0778 | lr: 9.9863e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   3707/156230 | global iter:   3707/156230 | loss: 1.1220 | ds_loss: 1.1326 | lr: 9.9863e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   3708/156230 | global iter:   3708/156230 | loss: 0.9841 | ds_loss: 0.9889 | lr: 9.9863e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3708/156230 | global iter:   3708/156230 | loss: 1.0338 | ds_loss: 1.0494 | lr: 9.9863e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3709/156230 | global iter:   3709/156230 | loss: 1.0090 | ds_loss: 1.0128 | lr: 9.9863e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   3710/156230 | global iter:   3710/156230 | loss: 1.1259 | ds_loss: 1.1363 | lr: 9.9863e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   3711/156230 | global iter:   3711/156230 | loss: 1.3215 | ds_loss: 1.3285 | lr: 9.9862e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   3712/156230 | global iter:   3712/156230 | loss: 1.1635 | ds_loss: 1.1845 | lr: 9.9862e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3712/156230 | global iter:   3712/156230 | loss: 1.1550 | ds_loss: 1.1655 | lr: 9.9862e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3713/156230 | global iter:   3713/156230 | loss: 1.2821 | ds_loss: 1.2940 | lr: 9.9862e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   3714/156230 | global iter:   3714/156230 | loss: 1.0665 | ds_loss: 1.0654 | lr: 9.9862e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   3715/156230 | global iter:   3715/156230 | loss: 1.1355 | ds_loss: 1.1396 | lr: 9.9862e-05 | scale: 32768.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   3716/156230 | global iter:   3716/156230 | loss: 1.1914 | ds_loss: 1.2055 | lr: 9.9862e-05 | scale: 32768.0000 | micro time: 1.386 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3716/156230 | global iter:   3716/156230 | loss: 1.1689 | ds_loss: 1.1761 | lr: 9.9862e-05 | scale: 32768.0000 | micro time: 1.386 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3717/156230 | global iter:   3717/156230 | loss: 1.0404 | ds_loss: 1.0386 | lr: 9.9862e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   3718/156230 | global iter:   3718/156230 | loss: 1.2316 | ds_loss: 1.2596 | lr: 9.9862e-05 | scale: 32768.0000 | micro time: 1.402 | step time: 0.000
train | epoch   0 | Iter:   3719/156230 | global iter:   3719/156230 | loss: 1.1718 | ds_loss: 1.1971 | lr: 9.9862e-05 | scale: 32768.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   3720/156230 | global iter:   3720/156230 | loss: 1.1888 | ds_loss: 1.1910 | lr: 9.9862e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3720/156230 | global iter:   3720/156230 | loss: 1.1581 | ds_loss: 1.1716 | lr: 9.9862e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3721/156230 | global iter:   3721/156230 | loss: 0.9212 | ds_loss: 0.9250 | lr: 9.9862e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   3722/156230 | global iter:   3722/156230 | loss: 1.1391 | ds_loss: 1.1493 | lr: 9.9862e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   3723/156230 | global iter:   3723/156230 | loss: 1.0161 | ds_loss: 1.0322 | lr: 9.9862e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   3724/156230 | global iter:   3724/156230 | loss: 1.1160 | ds_loss: 1.1161 | lr: 9.9862e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3724/156230 | global iter:   3724/156230 | loss: 1.0481 | ds_loss: 1.0556 | lr: 9.9862e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3725/156230 | global iter:   3725/156230 | loss: 1.3330 | ds_loss: 1.3558 | lr: 9.9861e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   3726/156230 | global iter:   3726/156230 | loss: 1.2209 | ds_loss: 1.2197 | lr: 9.9861e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   3727/156230 | global iter:   3727/156230 | loss: 1.2250 | ds_loss: 1.2208 | lr: 9.9861e-05 | scale: 32768.0000 | micro time: 1.401 | step time: 0.000
train | epoch   0 | Iter:   3728/156230 | global iter:   3728/156230 | loss: 1.2141 | ds_loss: 1.2196 | lr: 9.9861e-05 | scale: 32768.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3728/156230 | global iter:   3728/156230 | loss: 1.2482 | ds_loss: 1.2540 | lr: 9.9861e-05 | scale: 32768.0000 | micro time: 1.370 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3729/156230 | global iter:   3729/156230 | loss: 1.2089 | ds_loss: 1.2193 | lr: 9.9861e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   3730/156230 | global iter:   3730/156230 | loss: 1.2729 | ds_loss: 1.2767 | lr: 9.9861e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   3731/156230 | global iter:   3731/156230 | loss: 1.1090 | ds_loss: 1.1285 | lr: 9.9861e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   3732/156230 | global iter:   3732/156230 | loss: 1.2941 | ds_loss: 1.3034 | lr: 9.9861e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3732/156230 | global iter:   3732/156230 | loss: 1.2212 | ds_loss: 1.2319 | lr: 9.9861e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3733/156230 | global iter:   3733/156230 | loss: 1.0112 | ds_loss: 1.0239 | lr: 9.9861e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   3734/156230 | global iter:   3734/156230 | loss: 1.1465 | ds_loss: 1.1369 | lr: 9.9861e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   3735/156230 | global iter:   3735/156230 | loss: 1.1799 | ds_loss: 1.1868 | lr: 9.9861e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   3736/156230 | global iter:   3736/156230 | loss: 1.2173 | ds_loss: 1.2261 | lr: 9.9861e-05 | scale: 32768.0000 | micro time: 1.336 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3736/156230 | global iter:   3736/156230 | loss: 1.1387 | ds_loss: 1.1434 | lr: 9.9861e-05 | scale: 32768.0000 | micro time: 1.336 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3737/156230 | global iter:   3737/156230 | loss: 1.1747 | ds_loss: 1.1928 | lr: 9.9861e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   3738/156230 | global iter:   3738/156230 | loss: 1.2011 | ds_loss: 1.2142 | lr: 9.9860e-05 | scale: 32768.0000 | micro time: 1.321 | step time: 0.000
train | epoch   0 | Iter:   3739/156230 | global iter:   3739/156230 | loss: 1.0453 | ds_loss: 1.0623 | lr: 9.9860e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   3740/156230 | global iter:   3740/156230 | loss: 1.1883 | ds_loss: 1.1863 | lr: 9.9860e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3740/156230 | global iter:   3740/156230 | loss: 1.1523 | ds_loss: 1.1639 | lr: 9.9860e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3741/156230 | global iter:   3741/156230 | loss: 1.0561 | ds_loss: 1.0616 | lr: 9.9860e-05 | scale: 32768.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   3742/156230 | global iter:   3742/156230 | loss: 0.9601 | ds_loss: 0.9713 | lr: 9.9860e-05 | scale: 32768.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   3743/156230 | global iter:   3743/156230 | loss: 1.1828 | ds_loss: 1.2041 | lr: 9.9860e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   3744/156230 | global iter:   3744/156230 | loss: 1.0352 | ds_loss: 1.0478 | lr: 9.9860e-05 | scale: 32768.0000 | micro time: 1.330 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3744/156230 | global iter:   3744/156230 | loss: 1.0586 | ds_loss: 1.0712 | lr: 9.9860e-05 | scale: 32768.0000 | micro time: 1.330 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3745/156230 | global iter:   3745/156230 | loss: 1.0598 | ds_loss: 1.0558 | lr: 9.9860e-05 | scale: 32768.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   3746/156230 | global iter:   3746/156230 | loss: 1.3392 | ds_loss: 1.3645 | lr: 9.9860e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   3747/156230 | global iter:   3747/156230 | loss: 1.2689 | ds_loss: 1.2846 | lr: 9.9860e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   3748/156230 | global iter:   3748/156230 | loss: 1.1460 | ds_loss: 1.1518 | lr: 9.9860e-05 | scale: 32768.0000 | micro time: 1.404 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3748/156230 | global iter:   3748/156230 | loss: 1.2035 | ds_loss: 1.2142 | lr: 9.9860e-05 | scale: 32768.0000 | micro time: 1.404 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3749/156230 | global iter:   3749/156230 | loss: 1.0336 | ds_loss: 1.0499 | lr: 9.9860e-05 | scale: 32768.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   3750/156230 | global iter:   3750/156230 | loss: 1.1018 | ds_loss: 1.1199 | lr: 9.9860e-05 | scale: 32768.0000 | micro time: 1.411 | step time: 0.000
train | epoch   0 | Iter:   3751/156230 | global iter:   3751/156230 | loss: 1.1252 | ds_loss: 1.1439 | lr: 9.9859e-05 | scale: 32768.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   3752/156230 | global iter:   3752/156230 | loss: 1.0892 | ds_loss: 1.1021 | lr: 9.9859e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3752/156230 | global iter:   3752/156230 | loss: 1.0874 | ds_loss: 1.1039 | lr: 9.9859e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3753/156230 | global iter:   3753/156230 | loss: 1.1412 | ds_loss: 1.1541 | lr: 9.9859e-05 | scale: 32768.0000 | micro time: 1.406 | step time: 0.000
train | epoch   0 | Iter:   3754/156230 | global iter:   3754/156230 | loss: 1.1024 | ds_loss: 1.1027 | lr: 9.9859e-05 | scale: 32768.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   3755/156230 | global iter:   3755/156230 | loss: 1.0892 | ds_loss: 1.0959 | lr: 9.9859e-05 | scale: 32768.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   3756/156230 | global iter:   3756/156230 | loss: 1.1347 | ds_loss: 1.1598 | lr: 9.9859e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3756/156230 | global iter:   3756/156230 | loss: 1.1169 | ds_loss: 1.1281 | lr: 9.9859e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 1.383
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3757/156230 | global iter:   3757/156230 | loss: 1.1601 | ds_loss: 1.1711 | lr: 9.9859e-05 | scale: 32768.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   3758/156230 | global iter:   3758/156230 | loss: 0.9964 | ds_loss: 1.0216 | lr: 9.9859e-05 | scale: 32768.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   3759/156230 | global iter:   3759/156230 | loss: 1.0849 | ds_loss: 1.1007 | lr: 9.9859e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   3760/156230 | global iter:   3760/156230 | loss: 1.0661 | ds_loss: 1.0903 | lr: 9.9859e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3760/156230 | global iter:   3760/156230 | loss: 1.0769 | ds_loss: 1.0959 | lr: 9.9859e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3761/156230 | global iter:   3761/156230 | loss: 1.2616 | ds_loss: 1.2755 | lr: 9.9859e-05 | scale: 32768.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   3762/156230 | global iter:   3762/156230 | loss: 1.2706 | ds_loss: 1.2755 | lr: 9.9859e-05 | scale: 32768.0000 | micro time: 1.319 | step time: 0.000
train | epoch   0 | Iter:   3763/156230 | global iter:   3763/156230 | loss: 1.2933 | ds_loss: 1.3039 | lr: 9.9859e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   3764/156230 | global iter:   3764/156230 | loss: 1.0363 | ds_loss: 1.0472 | lr: 9.9859e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3764/156230 | global iter:   3764/156230 | loss: 1.2154 | ds_loss: 1.2255 | lr: 9.9859e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3765/156230 | global iter:   3765/156230 | loss: 1.1761 | ds_loss: 1.1861 | lr: 9.9858e-05 | scale: 32768.0000 | micro time: 1.401 | step time: 0.000
train | epoch   0 | Iter:   3766/156230 | global iter:   3766/156230 | loss: 1.2348 | ds_loss: 1.2499 | lr: 9.9858e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   3767/156230 | global iter:   3767/156230 | loss: 1.0865 | ds_loss: 1.0835 | lr: 9.9858e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   3768/156230 | global iter:   3768/156230 | loss: 1.0138 | ds_loss: 1.0192 | lr: 9.9858e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3768/156230 | global iter:   3768/156230 | loss: 1.1278 | ds_loss: 1.1347 | lr: 9.9858e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3769/156230 | global iter:   3769/156230 | loss: 1.1065 | ds_loss: 1.1184 | lr: 9.9858e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   3770/156230 | global iter:   3770/156230 | loss: 1.2356 | ds_loss: 1.2659 | lr: 9.9858e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   3771/156230 | global iter:   3771/156230 | loss: 1.2903 | ds_loss: 1.2945 | lr: 9.9858e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   3772/156230 | global iter:   3772/156230 | loss: 1.2079 | ds_loss: 1.2119 | lr: 9.9858e-05 | scale: 32768.0000 | micro time: 1.404 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3772/156230 | global iter:   3772/156230 | loss: 1.2101 | ds_loss: 1.2227 | lr: 9.9858e-05 | scale: 32768.0000 | micro time: 1.404 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3773/156230 | global iter:   3773/156230 | loss: 1.2813 | ds_loss: 1.2926 | lr: 9.9858e-05 | scale: 32768.0000 | micro time: 1.320 | step time: 0.000
train | epoch   0 | Iter:   3774/156230 | global iter:   3774/156230 | loss: 1.1763 | ds_loss: 1.1882 | lr: 9.9858e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   3775/156230 | global iter:   3775/156230 | loss: 1.0029 | ds_loss: 1.0404 | lr: 9.9858e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   3776/156230 | global iter:   3776/156230 | loss: 1.1132 | ds_loss: 1.1235 | lr: 9.9858e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3776/156230 | global iter:   3776/156230 | loss: 1.1434 | ds_loss: 1.1612 | lr: 9.9858e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3777/156230 | global iter:   3777/156230 | loss: 1.2751 | ds_loss: 1.2797 | lr: 9.9858e-05 | scale: 32768.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   3778/156230 | global iter:   3778/156230 | loss: 1.1019 | ds_loss: 1.1225 | lr: 9.9857e-05 | scale: 32768.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   3779/156230 | global iter:   3779/156230 | loss: 1.0851 | ds_loss: 1.1013 | lr: 9.9857e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   3780/156230 | global iter:   3780/156230 | loss: 1.0297 | ds_loss: 1.0520 | lr: 9.9857e-05 | scale: 32768.0000 | micro time: 1.332 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3780/156230 | global iter:   3780/156230 | loss: 1.1230 | ds_loss: 1.1389 | lr: 9.9857e-05 | scale: 32768.0000 | micro time: 1.332 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3781/156230 | global iter:   3781/156230 | loss: 1.0679 | ds_loss: 1.0824 | lr: 9.9857e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   3782/156230 | global iter:   3782/156230 | loss: 1.1685 | ds_loss: 1.1771 | lr: 9.9857e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   3783/156230 | global iter:   3783/156230 | loss: 1.1749 | ds_loss: 1.1740 | lr: 9.9857e-05 | scale: 32768.0000 | micro time: 1.314 | step time: 0.000
train | epoch   0 | Iter:   3784/156230 | global iter:   3784/156230 | loss: 1.0806 | ds_loss: 1.0936 | lr: 9.9857e-05 | scale: 32768.0000 | micro time: 1.382 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3784/156230 | global iter:   3784/156230 | loss: 1.1230 | ds_loss: 1.1318 | lr: 9.9857e-05 | scale: 32768.0000 | micro time: 1.382 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3785/156230 | global iter:   3785/156230 | loss: 1.2090 | ds_loss: 1.2026 | lr: 9.9857e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   3786/156230 | global iter:   3786/156230 | loss: 1.1516 | ds_loss: 1.1726 | lr: 9.9857e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   3787/156230 | global iter:   3787/156230 | loss: 1.0369 | ds_loss: 1.0506 | lr: 9.9857e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   3788/156230 | global iter:   3788/156230 | loss: 1.2337 | ds_loss: 1.2568 | lr: 9.9857e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3788/156230 | global iter:   3788/156230 | loss: 1.1578 | ds_loss: 1.1706 | lr: 9.9857e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3789/156230 | global iter:   3789/156230 | loss: 1.2902 | ds_loss: 1.2986 | lr: 9.9857e-05 | scale: 32768.0000 | micro time: 1.406 | step time: 0.000
train | epoch   0 | Iter:   3790/156230 | global iter:   3790/156230 | loss: 1.3236 | ds_loss: 1.3391 | lr: 9.9857e-05 | scale: 32768.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:   3791/156230 | global iter:   3791/156230 | loss: 1.1354 | ds_loss: 1.1345 | lr: 9.9856e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   3792/156230 | global iter:   3792/156230 | loss: 1.0275 | ds_loss: 1.0382 | lr: 9.9856e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3792/156230 | global iter:   3792/156230 | loss: 1.1942 | ds_loss: 1.2026 | lr: 9.9856e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 1.384
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3793/156230 | global iter:   3793/156230 | loss: 1.2121 | ds_loss: 1.2368 | lr: 9.9856e-05 | scale: 32768.0000 | micro time: 1.416 | step time: 0.000
train | epoch   0 | Iter:   3794/156230 | global iter:   3794/156230 | loss: 1.2601 | ds_loss: 1.2836 | lr: 9.9856e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   3795/156230 | global iter:   3795/156230 | loss: 1.1775 | ds_loss: 1.1817 | lr: 9.9856e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   3796/156230 | global iter:   3796/156230 | loss: 1.1280 | ds_loss: 1.1566 | lr: 9.9856e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3796/156230 | global iter:   3796/156230 | loss: 1.1945 | ds_loss: 1.2147 | lr: 9.9856e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3797/156230 | global iter:   3797/156230 | loss: 1.0120 | ds_loss: 1.0190 | lr: 9.9856e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   3798/156230 | global iter:   3798/156230 | loss: 1.1745 | ds_loss: 1.1732 | lr: 9.9856e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   3799/156230 | global iter:   3799/156230 | loss: 1.0399 | ds_loss: 1.0662 | lr: 9.9856e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   3800/156230 | global iter:   3800/156230 | loss: 1.1199 | ds_loss: 1.1203 | lr: 9.9856e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3800/156230 | global iter:   3800/156230 | loss: 1.0866 | ds_loss: 1.0947 | lr: 9.9856e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3801/156230 | global iter:   3801/156230 | loss: 1.0819 | ds_loss: 1.0922 | lr: 9.9856e-05 | scale: 32768.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   3802/156230 | global iter:   3802/156230 | loss: 1.0979 | ds_loss: 1.1120 | lr: 9.9856e-05 | scale: 32768.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   3803/156230 | global iter:   3803/156230 | loss: 1.1648 | ds_loss: 1.1893 | lr: 9.9856e-05 | scale: 32768.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   3804/156230 | global iter:   3804/156230 | loss: 1.1643 | ds_loss: 1.1681 | lr: 9.9855e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3804/156230 | global iter:   3804/156230 | loss: 1.1272 | ds_loss: 1.1404 | lr: 9.9855e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3805/156230 | global iter:   3805/156230 | loss: 1.0012 | ds_loss: 1.0186 | lr: 9.9855e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   3806/156230 | global iter:   3806/156230 | loss: 1.1484 | ds_loss: 1.1480 | lr: 9.9855e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   3807/156230 | global iter:   3807/156230 | loss: 1.2315 | ds_loss: 1.2618 | lr: 9.9855e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   3808/156230 | global iter:   3808/156230 | loss: 1.2726 | ds_loss: 1.2755 | lr: 9.9855e-05 | scale: 32768.0000 | micro time: 1.387 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3808/156230 | global iter:   3808/156230 | loss: 1.1634 | ds_loss: 1.1760 | lr: 9.9855e-05 | scale: 32768.0000 | micro time: 1.387 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3809/156230 | global iter:   3809/156230 | loss: 1.2958 | ds_loss: 1.3141 | lr: 9.9855e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   3810/156230 | global iter:   3810/156230 | loss: 1.1346 | ds_loss: 1.1597 | lr: 9.9855e-05 | scale: 32768.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   3811/156230 | global iter:   3811/156230 | loss: 1.0493 | ds_loss: 1.0459 | lr: 9.9855e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   3812/156230 | global iter:   3812/156230 | loss: 1.2691 | ds_loss: 1.2772 | lr: 9.9855e-05 | scale: 32768.0000 | micro time: 1.334 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3812/156230 | global iter:   3812/156230 | loss: 1.1872 | ds_loss: 1.1992 | lr: 9.9855e-05 | scale: 32768.0000 | micro time: 1.334 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3813/156230 | global iter:   3813/156230 | loss: 1.0422 | ds_loss: 1.0406 | lr: 9.9855e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   3814/156230 | global iter:   3814/156230 | loss: 1.1920 | ds_loss: 1.2096 | lr: 9.9855e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   3815/156230 | global iter:   3815/156230 | loss: 1.1995 | ds_loss: 1.2243 | lr: 9.9855e-05 | scale: 32768.0000 | micro time: 1.423 | step time: 0.000
train | epoch   0 | Iter:   3816/156230 | global iter:   3816/156230 | loss: 1.1280 | ds_loss: 1.1590 | lr: 9.9855e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3816/156230 | global iter:   3816/156230 | loss: 1.1404 | ds_loss: 1.1584 | lr: 9.9855e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 1.390
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3817/156230 | global iter:   3817/156230 | loss: 1.1831 | ds_loss: 1.1876 | lr: 9.9854e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   3818/156230 | global iter:   3818/156230 | loss: 1.2115 | ds_loss: 1.2135 | lr: 9.9854e-05 | scale: 32768.0000 | micro time: 1.410 | step time: 0.000
train | epoch   0 | Iter:   3819/156230 | global iter:   3819/156230 | loss: 1.2655 | ds_loss: 1.2754 | lr: 9.9854e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   3820/156230 | global iter:   3820/156230 | loss: 1.0140 | ds_loss: 1.0215 | lr: 9.9854e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3820/156230 | global iter:   3820/156230 | loss: 1.1685 | ds_loss: 1.1745 | lr: 9.9854e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3821/156230 | global iter:   3821/156230 | loss: 1.0779 | ds_loss: 1.0921 | lr: 9.9854e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   3822/156230 | global iter:   3822/156230 | loss: 1.0930 | ds_loss: 1.0991 | lr: 9.9854e-05 | scale: 32768.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   3823/156230 | global iter:   3823/156230 | loss: 1.1542 | ds_loss: 1.1655 | lr: 9.9854e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   3824/156230 | global iter:   3824/156230 | loss: 1.0637 | ds_loss: 1.0793 | lr: 9.9854e-05 | scale: 32768.0000 | micro time: 1.390 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3824/156230 | global iter:   3824/156230 | loss: 1.0972 | ds_loss: 1.1090 | lr: 9.9854e-05 | scale: 32768.0000 | micro time: 1.390 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3825/156230 | global iter:   3825/156230 | loss: 0.8793 | ds_loss: 0.8894 | lr: 9.9854e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   3826/156230 | global iter:   3826/156230 | loss: 1.0991 | ds_loss: 1.1112 | lr: 9.9854e-05 | scale: 32768.0000 | micro time: 1.436 | step time: 0.000
train | epoch   0 | Iter:   3827/156230 | global iter:   3827/156230 | loss: 1.2493 | ds_loss: 1.2559 | lr: 9.9854e-05 | scale: 32768.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   3828/156230 | global iter:   3828/156230 | loss: 1.0470 | ds_loss: 1.0559 | lr: 9.9854e-05 | scale: 32768.0000 | micro time: 1.329 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3828/156230 | global iter:   3828/156230 | loss: 1.0687 | ds_loss: 1.0781 | lr: 9.9854e-05 | scale: 32768.0000 | micro time: 1.329 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3829/156230 | global iter:   3829/156230 | loss: 1.3739 | ds_loss: 1.3853 | lr: 9.9854e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   3830/156230 | global iter:   3830/156230 | loss: 1.1748 | ds_loss: 1.1823 | lr: 9.9853e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   3831/156230 | global iter:   3831/156230 | loss: 1.2288 | ds_loss: 1.2713 | lr: 9.9853e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   3832/156230 | global iter:   3832/156230 | loss: 1.0534 | ds_loss: 1.0490 | lr: 9.9853e-05 | scale: 32768.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3832/156230 | global iter:   3832/156230 | loss: 1.2077 | ds_loss: 1.2220 | lr: 9.9853e-05 | scale: 32768.0000 | micro time: 1.385 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3833/156230 | global iter:   3833/156230 | loss: 1.2447 | ds_loss: 1.2520 | lr: 9.9853e-05 | scale: 32768.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:   3834/156230 | global iter:   3834/156230 | loss: 1.2783 | ds_loss: 1.2903 | lr: 9.9853e-05 | scale: 32768.0000 | micro time: 1.322 | step time: 0.000
train | epoch   0 | Iter:   3835/156230 | global iter:   3835/156230 | loss: 1.0439 | ds_loss: 1.0464 | lr: 9.9853e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   3836/156230 | global iter:   3836/156230 | loss: 1.1998 | ds_loss: 1.1875 | lr: 9.9853e-05 | scale: 32768.0000 | micro time: 1.405 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3836/156230 | global iter:   3836/156230 | loss: 1.1917 | ds_loss: 1.1941 | lr: 9.9853e-05 | scale: 32768.0000 | micro time: 1.405 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3837/156230 | global iter:   3837/156230 | loss: 1.0545 | ds_loss: 1.0585 | lr: 9.9853e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   3838/156230 | global iter:   3838/156230 | loss: 1.1874 | ds_loss: 1.1978 | lr: 9.9853e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   3839/156230 | global iter:   3839/156230 | loss: 1.0782 | ds_loss: 1.0823 | lr: 9.9853e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   3840/156230 | global iter:   3840/156230 | loss: 1.1931 | ds_loss: 1.1986 | lr: 9.9853e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3840/156230 | global iter:   3840/156230 | loss: 1.1283 | ds_loss: 1.1343 | lr: 9.9853e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3841/156230 | global iter:   3841/156230 | loss: 1.2323 | ds_loss: 1.2465 | lr: 9.9853e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   3842/156230 | global iter:   3842/156230 | loss: 1.2328 | ds_loss: 1.2386 | lr: 9.9853e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   3843/156230 | global iter:   3843/156230 | loss: 1.0214 | ds_loss: 1.0119 | lr: 9.9852e-05 | scale: 32768.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   3844/156230 | global iter:   3844/156230 | loss: 1.1955 | ds_loss: 1.2189 | lr: 9.9852e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3844/156230 | global iter:   3844/156230 | loss: 1.1705 | ds_loss: 1.1790 | lr: 9.9852e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 1.348
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3845/156230 | global iter:   3845/156230 | loss: 1.2186 | ds_loss: 1.2424 | lr: 9.9852e-05 | scale: 32768.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:   3846/156230 | global iter:   3846/156230 | loss: 0.8922 | ds_loss: 0.8963 | lr: 9.9852e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   3847/156230 | global iter:   3847/156230 | loss: 1.2275 | ds_loss: 1.2350 | lr: 9.9852e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   3848/156230 | global iter:   3848/156230 | loss: 1.0829 | ds_loss: 1.0963 | lr: 9.9852e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3848/156230 | global iter:   3848/156230 | loss: 1.1053 | ds_loss: 1.1175 | lr: 9.9852e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3849/156230 | global iter:   3849/156230 | loss: 1.0954 | ds_loss: 1.1388 | lr: 9.9852e-05 | scale: 32768.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:   3850/156230 | global iter:   3850/156230 | loss: 0.9914 | ds_loss: 0.9982 | lr: 9.9852e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   3851/156230 | global iter:   3851/156230 | loss: 1.2625 | ds_loss: 1.2846 | lr: 9.9852e-05 | scale: 32768.0000 | micro time: 1.406 | step time: 0.000
train | epoch   0 | Iter:   3852/156230 | global iter:   3852/156230 | loss: 1.1079 | ds_loss: 1.1265 | lr: 9.9852e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3852/156230 | global iter:   3852/156230 | loss: 1.1143 | ds_loss: 1.1370 | lr: 9.9852e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 1.380
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3853/156230 | global iter:   3853/156230 | loss: 1.2212 | ds_loss: 1.2295 | lr: 9.9852e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   3854/156230 | global iter:   3854/156230 | loss: 1.2480 | ds_loss: 1.2504 | lr: 9.9852e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   3855/156230 | global iter:   3855/156230 | loss: 1.2229 | ds_loss: 1.2368 | lr: 9.9852e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   3856/156230 | global iter:   3856/156230 | loss: 1.1775 | ds_loss: 1.1972 | lr: 9.9851e-05 | scale: 32768.0000 | micro time: 1.309 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3856/156230 | global iter:   3856/156230 | loss: 1.2174 | ds_loss: 1.2284 | lr: 9.9851e-05 | scale: 32768.0000 | micro time: 1.309 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3857/156230 | global iter:   3857/156230 | loss: 1.1165 | ds_loss: 1.1429 | lr: 9.9851e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   3858/156230 | global iter:   3858/156230 | loss: 1.1520 | ds_loss: 1.1639 | lr: 9.9851e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   3859/156230 | global iter:   3859/156230 | loss: 1.2075 | ds_loss: 1.2158 | lr: 9.9851e-05 | scale: 32768.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   3860/156230 | global iter:   3860/156230 | loss: 1.1669 | ds_loss: 1.1712 | lr: 9.9851e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3860/156230 | global iter:   3860/156230 | loss: 1.1607 | ds_loss: 1.1734 | lr: 9.9851e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3861/156230 | global iter:   3861/156230 | loss: 1.2733 | ds_loss: 1.2576 | lr: 9.9851e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   3862/156230 | global iter:   3862/156230 | loss: 1.1746 | ds_loss: 1.1923 | lr: 9.9851e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   3863/156230 | global iter:   3863/156230 | loss: 1.0188 | ds_loss: 1.0135 | lr: 9.9851e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   3864/156230 | global iter:   3864/156230 | loss: 1.2185 | ds_loss: 1.2473 | lr: 9.9851e-05 | scale: 32768.0000 | micro time: 1.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3864/156230 | global iter:   3864/156230 | loss: 1.1713 | ds_loss: 1.1777 | lr: 9.9851e-05 | scale: 32768.0000 | micro time: 1.396 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3865/156230 | global iter:   3865/156230 | loss: 1.1389 | ds_loss: 1.1510 | lr: 9.9851e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   3866/156230 | global iter:   3866/156230 | loss: 1.1748 | ds_loss: 1.1819 | lr: 9.9851e-05 | scale: 32768.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   3867/156230 | global iter:   3867/156230 | loss: 1.0128 | ds_loss: 1.0231 | lr: 9.9851e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   3868/156230 | global iter:   3868/156230 | loss: 1.1083 | ds_loss: 1.1252 | lr: 9.9851e-05 | scale: 32768.0000 | micro time: 1.328 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3868/156230 | global iter:   3868/156230 | loss: 1.1087 | ds_loss: 1.1203 | lr: 9.9851e-05 | scale: 32768.0000 | micro time: 1.328 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3869/156230 | global iter:   3869/156230 | loss: 1.1667 | ds_loss: 1.1809 | lr: 9.9850e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   3870/156230 | global iter:   3870/156230 | loss: 0.9661 | ds_loss: 0.9591 | lr: 9.9850e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   3871/156230 | global iter:   3871/156230 | loss: 1.0745 | ds_loss: 1.0987 | lr: 9.9850e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   3872/156230 | global iter:   3872/156230 | loss: 1.1226 | ds_loss: 1.1353 | lr: 9.9850e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3872/156230 | global iter:   3872/156230 | loss: 1.0825 | ds_loss: 1.0935 | lr: 9.9850e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3873/156230 | global iter:   3873/156230 | loss: 1.2191 | ds_loss: 1.2363 | lr: 9.9850e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   3874/156230 | global iter:   3874/156230 | loss: 1.2778 | ds_loss: 1.2728 | lr: 9.9850e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   3875/156230 | global iter:   3875/156230 | loss: 1.0569 | ds_loss: 1.0611 | lr: 9.9850e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   3876/156230 | global iter:   3876/156230 | loss: 1.1852 | ds_loss: 1.1982 | lr: 9.9850e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3876/156230 | global iter:   3876/156230 | loss: 1.1847 | ds_loss: 1.1921 | lr: 9.9850e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3877/156230 | global iter:   3877/156230 | loss: 1.2018 | ds_loss: 1.2432 | lr: 9.9850e-05 | scale: 32768.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   3878/156230 | global iter:   3878/156230 | loss: 1.0789 | ds_loss: 1.1186 | lr: 9.9850e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   3879/156230 | global iter:   3879/156230 | loss: 1.1591 | ds_loss: 1.1662 | lr: 9.9850e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   3880/156230 | global iter:   3880/156230 | loss: 0.9693 | ds_loss: 0.9770 | lr: 9.9850e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3880/156230 | global iter:   3880/156230 | loss: 1.1023 | ds_loss: 1.1263 | lr: 9.9850e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3881/156230 | global iter:   3881/156230 | loss: 1.1426 | ds_loss: 1.1551 | lr: 9.9850e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   3882/156230 | global iter:   3882/156230 | loss: 1.2320 | ds_loss: 1.2348 | lr: 9.9849e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   3883/156230 | global iter:   3883/156230 | loss: 1.2303 | ds_loss: 1.2432 | lr: 9.9849e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   3884/156230 | global iter:   3884/156230 | loss: 1.2067 | ds_loss: 1.2025 | lr: 9.9849e-05 | scale: 32768.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3884/156230 | global iter:   3884/156230 | loss: 1.2029 | ds_loss: 1.2089 | lr: 9.9849e-05 | scale: 32768.0000 | micro time: 1.385 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3885/156230 | global iter:   3885/156230 | loss: 1.1540 | ds_loss: 1.1624 | lr: 9.9849e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   3886/156230 | global iter:   3886/156230 | loss: 1.0870 | ds_loss: 1.1138 | lr: 9.9849e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   3887/156230 | global iter:   3887/156230 | loss: 0.9978 | ds_loss: 1.0109 | lr: 9.9849e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   3888/156230 | global iter:   3888/156230 | loss: 1.1067 | ds_loss: 1.1071 | lr: 9.9849e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3888/156230 | global iter:   3888/156230 | loss: 1.0864 | ds_loss: 1.0986 | lr: 9.9849e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3889/156230 | global iter:   3889/156230 | loss: 1.1671 | ds_loss: 1.1822 | lr: 9.9849e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   3890/156230 | global iter:   3890/156230 | loss: 1.1886 | ds_loss: 1.2004 | lr: 9.9849e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   3891/156230 | global iter:   3891/156230 | loss: 1.0225 | ds_loss: 1.0402 | lr: 9.9849e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   3892/156230 | global iter:   3892/156230 | loss: 1.1730 | ds_loss: 1.1838 | lr: 9.9849e-05 | scale: 32768.0000 | micro time: 1.333 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3892/156230 | global iter:   3892/156230 | loss: 1.1378 | ds_loss: 1.1517 | lr: 9.9849e-05 | scale: 32768.0000 | micro time: 1.333 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3893/156230 | global iter:   3893/156230 | loss: 1.0223 | ds_loss: 1.0328 | lr: 9.9849e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   3894/156230 | global iter:   3894/156230 | loss: 1.2848 | ds_loss: 1.2917 | lr: 9.9849e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   3895/156230 | global iter:   3895/156230 | loss: 1.2603 | ds_loss: 1.2823 | lr: 9.9848e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   3896/156230 | global iter:   3896/156230 | loss: 1.0421 | ds_loss: 1.0523 | lr: 9.9848e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3896/156230 | global iter:   3896/156230 | loss: 1.1524 | ds_loss: 1.1648 | lr: 9.9848e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3897/156230 | global iter:   3897/156230 | loss: 1.1604 | ds_loss: 1.1704 | lr: 9.9848e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   3898/156230 | global iter:   3898/156230 | loss: 1.0779 | ds_loss: 1.1058 | lr: 9.9848e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   3899/156230 | global iter:   3899/156230 | loss: 1.0765 | ds_loss: 1.0950 | lr: 9.9848e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   3900/156230 | global iter:   3900/156230 | loss: 1.1484 | ds_loss: 1.1547 | lr: 9.9848e-05 | scale: 32768.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3900/156230 | global iter:   3900/156230 | loss: 1.1158 | ds_loss: 1.1315 | lr: 9.9848e-05 | scale: 32768.0000 | micro time: 1.370 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3901/156230 | global iter:   3901/156230 | loss: 1.0674 | ds_loss: 1.0681 | lr: 9.9848e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   3902/156230 | global iter:   3902/156230 | loss: 1.2120 | ds_loss: 1.2300 | lr: 9.9848e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   3903/156230 | global iter:   3903/156230 | loss: 1.1948 | ds_loss: 1.2208 | lr: 9.9848e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   3904/156230 | global iter:   3904/156230 | loss: 1.1259 | ds_loss: 1.1257 | lr: 9.9848e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3904/156230 | global iter:   3904/156230 | loss: 1.1500 | ds_loss: 1.1611 | lr: 9.9848e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3905/156230 | global iter:   3905/156230 | loss: 1.0799 | ds_loss: 1.0977 | lr: 9.9848e-05 | scale: 32768.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   3906/156230 | global iter:   3906/156230 | loss: 1.0894 | ds_loss: 1.1104 | lr: 9.9848e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   3907/156230 | global iter:   3907/156230 | loss: 1.1271 | ds_loss: 1.1495 | lr: 9.9847e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   3908/156230 | global iter:   3908/156230 | loss: 1.2424 | ds_loss: 1.2348 | lr: 9.9847e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3908/156230 | global iter:   3908/156230 | loss: 1.1347 | ds_loss: 1.1481 | lr: 9.9847e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3909/156230 | global iter:   3909/156230 | loss: 1.2658 | ds_loss: 1.2992 | lr: 9.9847e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   3910/156230 | global iter:   3910/156230 | loss: 1.0427 | ds_loss: 1.0666 | lr: 9.9847e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   3911/156230 | global iter:   3911/156230 | loss: 1.3364 | ds_loss: 1.3326 | lr: 9.9847e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   3912/156230 | global iter:   3912/156230 | loss: 1.0891 | ds_loss: 1.1190 | lr: 9.9847e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3912/156230 | global iter:   3912/156230 | loss: 1.1835 | ds_loss: 1.2043 | lr: 9.9847e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3913/156230 | global iter:   3913/156230 | loss: 1.1555 | ds_loss: 1.1695 | lr: 9.9847e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   3914/156230 | global iter:   3914/156230 | loss: 1.2867 | ds_loss: 1.2938 | lr: 9.9847e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   3915/156230 | global iter:   3915/156230 | loss: 1.1701 | ds_loss: 1.1824 | lr: 9.9847e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   3916/156230 | global iter:   3916/156230 | loss: 1.2158 | ds_loss: 1.2392 | lr: 9.9847e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3916/156230 | global iter:   3916/156230 | loss: 1.2070 | ds_loss: 1.2212 | lr: 9.9847e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3917/156230 | global iter:   3917/156230 | loss: 1.0579 | ds_loss: 1.0803 | lr: 9.9847e-05 | scale: 32768.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   3918/156230 | global iter:   3918/156230 | loss: 1.1967 | ds_loss: 1.2270 | lr: 9.9847e-05 | scale: 32768.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   3919/156230 | global iter:   3919/156230 | loss: 0.9395 | ds_loss: 0.9456 | lr: 9.9847e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   3920/156230 | global iter:   3920/156230 | loss: 1.2928 | ds_loss: 1.3178 | lr: 9.9846e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3920/156230 | global iter:   3920/156230 | loss: 1.1217 | ds_loss: 1.1427 | lr: 9.9846e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3921/156230 | global iter:   3921/156230 | loss: 1.0884 | ds_loss: 1.1032 | lr: 9.9846e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   3922/156230 | global iter:   3922/156230 | loss: 1.0515 | ds_loss: 1.0716 | lr: 9.9846e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   3923/156230 | global iter:   3923/156230 | loss: 1.1387 | ds_loss: 1.1703 | lr: 9.9846e-05 | scale: 32768.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   3924/156230 | global iter:   3924/156230 | loss: 1.1536 | ds_loss: 1.1912 | lr: 9.9846e-05 | scale: 32768.0000 | micro time: 1.382 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3924/156230 | global iter:   3924/156230 | loss: 1.1080 | ds_loss: 1.1341 | lr: 9.9846e-05 | scale: 32768.0000 | micro time: 1.382 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3925/156230 | global iter:   3925/156230 | loss: 1.1583 | ds_loss: 1.1714 | lr: 9.9846e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   3926/156230 | global iter:   3926/156230 | loss: 1.1659 | ds_loss: 1.1694 | lr: 9.9846e-05 | scale: 32768.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   3927/156230 | global iter:   3927/156230 | loss: 1.1429 | ds_loss: 1.1589 | lr: 9.9846e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   3928/156230 | global iter:   3928/156230 | loss: 1.0928 | ds_loss: 1.1156 | lr: 9.9846e-05 | scale: 32768.0000 | micro time: 1.404 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3928/156230 | global iter:   3928/156230 | loss: 1.1400 | ds_loss: 1.1538 | lr: 9.9846e-05 | scale: 32768.0000 | micro time: 1.404 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3929/156230 | global iter:   3929/156230 | loss: 1.1001 | ds_loss: 1.1109 | lr: 9.9846e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   3930/156230 | global iter:   3930/156230 | loss: 1.0564 | ds_loss: 1.0772 | lr: 9.9846e-05 | scale: 32768.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   3931/156230 | global iter:   3931/156230 | loss: 1.1233 | ds_loss: 1.1623 | lr: 9.9846e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   3932/156230 | global iter:   3932/156230 | loss: 1.1390 | ds_loss: 1.1425 | lr: 9.9846e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3932/156230 | global iter:   3932/156230 | loss: 1.1047 | ds_loss: 1.1232 | lr: 9.9846e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3933/156230 | global iter:   3933/156230 | loss: 1.1580 | ds_loss: 1.1918 | lr: 9.9845e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   3934/156230 | global iter:   3934/156230 | loss: 1.2126 | ds_loss: 1.2318 | lr: 9.9845e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   3935/156230 | global iter:   3935/156230 | loss: 1.0192 | ds_loss: 1.0277 | lr: 9.9845e-05 | scale: 32768.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   3936/156230 | global iter:   3936/156230 | loss: 1.0089 | ds_loss: 1.0255 | lr: 9.9845e-05 | scale: 32768.0000 | micro time: 1.321 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3936/156230 | global iter:   3936/156230 | loss: 1.0997 | ds_loss: 1.1192 | lr: 9.9845e-05 | scale: 32768.0000 | micro time: 1.321 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3937/156230 | global iter:   3937/156230 | loss: 1.1427 | ds_loss: 1.1571 | lr: 9.9845e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   3938/156230 | global iter:   3938/156230 | loss: 1.1233 | ds_loss: 1.1271 | lr: 9.9845e-05 | scale: 32768.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   3939/156230 | global iter:   3939/156230 | loss: 1.0335 | ds_loss: 1.0461 | lr: 9.9845e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   3940/156230 | global iter:   3940/156230 | loss: 1.1249 | ds_loss: 1.1232 | lr: 9.9845e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3940/156230 | global iter:   3940/156230 | loss: 1.1061 | ds_loss: 1.1134 | lr: 9.9845e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3941/156230 | global iter:   3941/156230 | loss: 1.1687 | ds_loss: 1.1744 | lr: 9.9845e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   3942/156230 | global iter:   3942/156230 | loss: 1.0681 | ds_loss: 1.0783 | lr: 9.9845e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   3943/156230 | global iter:   3943/156230 | loss: 1.2919 | ds_loss: 1.3157 | lr: 9.9845e-05 | scale: 32768.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   3944/156230 | global iter:   3944/156230 | loss: 1.2629 | ds_loss: 1.2563 | lr: 9.9845e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3944/156230 | global iter:   3944/156230 | loss: 1.1979 | ds_loss: 1.2062 | lr: 9.9845e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3945/156230 | global iter:   3945/156230 | loss: 1.2377 | ds_loss: 1.2496 | lr: 9.9845e-05 | scale: 32768.0000 | micro time: 1.404 | step time: 0.000
train | epoch   0 | Iter:   3946/156230 | global iter:   3946/156230 | loss: 1.1462 | ds_loss: 1.1725 | lr: 9.9844e-05 | scale: 32768.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   3947/156230 | global iter:   3947/156230 | loss: 1.2146 | ds_loss: 1.2382 | lr: 9.9844e-05 | scale: 32768.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   3948/156230 | global iter:   3948/156230 | loss: 1.1989 | ds_loss: 1.2120 | lr: 9.9844e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3948/156230 | global iter:   3948/156230 | loss: 1.1994 | ds_loss: 1.2181 | lr: 9.9844e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 1.388
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3949/156230 | global iter:   3949/156230 | loss: 1.1549 | ds_loss: 1.1690 | lr: 9.9844e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   3950/156230 | global iter:   3950/156230 | loss: 0.9926 | ds_loss: 1.0039 | lr: 9.9844e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   3951/156230 | global iter:   3951/156230 | loss: 1.1789 | ds_loss: 1.1882 | lr: 9.9844e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   3952/156230 | global iter:   3952/156230 | loss: 1.0347 | ds_loss: 1.0379 | lr: 9.9844e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3952/156230 | global iter:   3952/156230 | loss: 1.0903 | ds_loss: 1.0997 | lr: 9.9844e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3953/156230 | global iter:   3953/156230 | loss: 1.1812 | ds_loss: 1.2005 | lr: 9.9844e-05 | scale: 32768.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   3954/156230 | global iter:   3954/156230 | loss: 1.2286 | ds_loss: 1.2169 | lr: 9.9844e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   3955/156230 | global iter:   3955/156230 | loss: 1.1495 | ds_loss: 1.1870 | lr: 9.9844e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   3956/156230 | global iter:   3956/156230 | loss: 1.2272 | ds_loss: 1.2437 | lr: 9.9844e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3956/156230 | global iter:   3956/156230 | loss: 1.1966 | ds_loss: 1.2120 | lr: 9.9844e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3957/156230 | global iter:   3957/156230 | loss: 1.1914 | ds_loss: 1.2075 | lr: 9.9844e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   3958/156230 | global iter:   3958/156230 | loss: 0.9778 | ds_loss: 0.9924 | lr: 9.9843e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   3959/156230 | global iter:   3959/156230 | loss: 1.1457 | ds_loss: 1.1491 | lr: 9.9843e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   3960/156230 | global iter:   3960/156230 | loss: 1.1565 | ds_loss: 1.1646 | lr: 9.9843e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3960/156230 | global iter:   3960/156230 | loss: 1.1178 | ds_loss: 1.1284 | lr: 9.9843e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3961/156230 | global iter:   3961/156230 | loss: 1.0037 | ds_loss: 1.0246 | lr: 9.9843e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   3962/156230 | global iter:   3962/156230 | loss: 1.0827 | ds_loss: 1.1030 | lr: 9.9843e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   3963/156230 | global iter:   3963/156230 | loss: 0.8674 | ds_loss: 0.8919 | lr: 9.9843e-05 | scale: 32768.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   3964/156230 | global iter:   3964/156230 | loss: 1.1266 | ds_loss: 1.1644 | lr: 9.9843e-05 | scale: 32768.0000 | micro time: 1.326 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3964/156230 | global iter:   3964/156230 | loss: 1.0201 | ds_loss: 1.0460 | lr: 9.9843e-05 | scale: 32768.0000 | micro time: 1.326 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3965/156230 | global iter:   3965/156230 | loss: 1.1542 | ds_loss: 1.1633 | lr: 9.9843e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   3966/156230 | global iter:   3966/156230 | loss: 0.9425 | ds_loss: 0.9328 | lr: 9.9843e-05 | scale: 32768.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   3967/156230 | global iter:   3967/156230 | loss: 1.1429 | ds_loss: 1.1705 | lr: 9.9843e-05 | scale: 32768.0000 | micro time: 1.416 | step time: 0.000
train | epoch   0 | Iter:   3968/156230 | global iter:   3968/156230 | loss: 1.0843 | ds_loss: 1.0997 | lr: 9.9843e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3968/156230 | global iter:   3968/156230 | loss: 1.0810 | ds_loss: 1.0916 | lr: 9.9843e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3969/156230 | global iter:   3969/156230 | loss: 1.1739 | ds_loss: 1.2038 | lr: 9.9843e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   3970/156230 | global iter:   3970/156230 | loss: 1.1339 | ds_loss: 1.1624 | lr: 9.9843e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   3971/156230 | global iter:   3971/156230 | loss: 1.1767 | ds_loss: 1.1814 | lr: 9.9842e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   3972/156230 | global iter:   3972/156230 | loss: 1.0288 | ds_loss: 1.0343 | lr: 9.9842e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3972/156230 | global iter:   3972/156230 | loss: 1.1283 | ds_loss: 1.1455 | lr: 9.9842e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3973/156230 | global iter:   3973/156230 | loss: 1.0423 | ds_loss: 1.0587 | lr: 9.9842e-05 | scale: 32768.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:   3974/156230 | global iter:   3974/156230 | loss: 1.1247 | ds_loss: 1.1337 | lr: 9.9842e-05 | scale: 32768.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   3975/156230 | global iter:   3975/156230 | loss: 1.1605 | ds_loss: 1.1860 | lr: 9.9842e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   3976/156230 | global iter:   3976/156230 | loss: 0.9836 | ds_loss: 0.9870 | lr: 9.9842e-05 | scale: 32768.0000 | micro time: 1.333 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3976/156230 | global iter:   3976/156230 | loss: 1.0778 | ds_loss: 1.0913 | lr: 9.9842e-05 | scale: 32768.0000 | micro time: 1.333 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3977/156230 | global iter:   3977/156230 | loss: 1.1590 | ds_loss: 1.1568 | lr: 9.9842e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   3978/156230 | global iter:   3978/156230 | loss: 1.0158 | ds_loss: 1.0420 | lr: 9.9842e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   3979/156230 | global iter:   3979/156230 | loss: 1.0813 | ds_loss: 1.0902 | lr: 9.9842e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   3980/156230 | global iter:   3980/156230 | loss: 1.0691 | ds_loss: 1.0903 | lr: 9.9842e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3980/156230 | global iter:   3980/156230 | loss: 1.0813 | ds_loss: 1.0948 | lr: 9.9842e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3981/156230 | global iter:   3981/156230 | loss: 1.0509 | ds_loss: 1.0606 | lr: 9.9842e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   3982/156230 | global iter:   3982/156230 | loss: 1.0456 | ds_loss: 1.0388 | lr: 9.9842e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   3983/156230 | global iter:   3983/156230 | loss: 1.1759 | ds_loss: 1.1900 | lr: 9.9841e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   3984/156230 | global iter:   3984/156230 | loss: 1.0330 | ds_loss: 1.0497 | lr: 9.9841e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3984/156230 | global iter:   3984/156230 | loss: 1.0764 | ds_loss: 1.0848 | lr: 9.9841e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3985/156230 | global iter:   3985/156230 | loss: 0.9910 | ds_loss: 1.0110 | lr: 9.9841e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   3986/156230 | global iter:   3986/156230 | loss: 1.1068 | ds_loss: 1.1252 | lr: 9.9841e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   3987/156230 | global iter:   3987/156230 | loss: 0.7906 | ds_loss: 0.8095 | lr: 9.9841e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   3988/156230 | global iter:   3988/156230 | loss: 1.1132 | ds_loss: 1.1241 | lr: 9.9841e-05 | scale: 32768.0000 | micro time: 1.382 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3988/156230 | global iter:   3988/156230 | loss: 1.0004 | ds_loss: 1.0175 | lr: 9.9841e-05 | scale: 32768.0000 | micro time: 1.382 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3989/156230 | global iter:   3989/156230 | loss: 1.1095 | ds_loss: 1.1032 | lr: 9.9841e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   3990/156230 | global iter:   3990/156230 | loss: 1.1161 | ds_loss: 1.1358 | lr: 9.9841e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   3991/156230 | global iter:   3991/156230 | loss: 1.3010 | ds_loss: 1.3220 | lr: 9.9841e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   3992/156230 | global iter:   3992/156230 | loss: 1.1004 | ds_loss: 1.1166 | lr: 9.9841e-05 | scale: 32768.0000 | micro time: 1.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3992/156230 | global iter:   3992/156230 | loss: 1.1568 | ds_loss: 1.1694 | lr: 9.9841e-05 | scale: 32768.0000 | micro time: 1.397 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3993/156230 | global iter:   3993/156230 | loss: 1.0613 | ds_loss: 1.0751 | lr: 9.9841e-05 | scale: 32768.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   3994/156230 | global iter:   3994/156230 | loss: 1.0566 | ds_loss: 1.0736 | lr: 9.9841e-05 | scale: 32768.0000 | micro time: 1.401 | step time: 0.000
train | epoch   0 | Iter:   3995/156230 | global iter:   3995/156230 | loss: 1.1337 | ds_loss: 1.1596 | lr: 9.9841e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   3996/156230 | global iter:   3996/156230 | loss: 1.1234 | ds_loss: 1.1472 | lr: 9.9840e-05 | scale: 32768.0000 | micro time: 1.386 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   3996/156230 | global iter:   3996/156230 | loss: 1.0937 | ds_loss: 1.1139 | lr: 9.9840e-05 | scale: 32768.0000 | micro time: 1.386 | step time: 1.383
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   3997/156230 | global iter:   3997/156230 | loss: 1.1373 | ds_loss: 1.1129 | lr: 9.9840e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   3998/156230 | global iter:   3998/156230 | loss: 1.0622 | ds_loss: 1.0733 | lr: 9.9840e-05 | scale: 32768.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   3999/156230 | global iter:   3999/156230 | loss: 1.1964 | ds_loss: 1.2077 | lr: 9.9840e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   4000/156230 | global iter:   4000/156230 | loss: 0.8172 | ds_loss: 0.8265 | lr: 9.9840e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4000/156230 | global iter:   4000/156230 | loss: 1.0533 | ds_loss: 1.0551 | lr: 9.9840e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
Model save to ./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5/4000
dp size 4
/home/users/ap794/final_project_distillLLM/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
0/32
1/32
2/32
3/32
4/32
5/32
6/32
7/32
8/32
9/32
10/32
11/32
12/32
13/32
14/32
Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]Evaluating:   3%|         | 1/32 [00:06<03:18,  6.41s/it]Evaluating:   6%|         | 2/32 [00:11<02:54,  5.81s/it]Evaluating:   9%|         | 3/32 [00:17<02:44,  5.69s/it]Evaluating:  12%|        | 4/32 [00:22<02:35,  5.57s/it]Evaluating:  16%|        | 5/32 [00:28<02:28,  5.50s/it]Evaluating:  19%|        | 6/32 [00:33<02:21,  5.45s/it]Evaluating:  22%|       | 7/32 [00:38<02:15,  5.43s/it]Evaluating:  25%|       | 8/32 [00:44<02:11,  5.47s/it]Evaluating:  28%|       | 9/32 [00:49<02:05,  5.44s/it]Evaluating:  31%|      | 10/32 [00:55<01:59,  5.42s/it]Evaluating:  34%|      | 11/32 [01:00<01:53,  5.39s/it]Evaluating:  38%|      | 12/32 [01:05<01:47,  5.38s/it]Evaluating:  41%|      | 13/32 [01:11<01:41,  5.33s/it]Evaluating:  44%|     | 14/32 [01:16<01:37,  5.39s/it]Evaluating:  47%|     | 15/32 [01:21<01:31,  5.315/32
16/32
17/32
18/32
19/32
20/32
21/32
22/32
23/32
24/32
25/32
26/32
27/32
28/32
9s/it]Evaluating:  50%|     | 16/32 [01:27<01:26,  5.39s/it]Evaluating:  53%|    | 17/32 [01:32<01:20,  5.39s/it]Evaluating:  56%|    | 18/32 [01:38<01:15,  5.36s/it]Evaluating:  59%|    | 19/32 [01:43<01:09,  5.37s/it]Evaluating:  62%|   | 20/32 [01:48<01:04,  5.38s/it]Evaluating:  66%|   | 21/32 [01:54<00:59,  5.37s/it]Evaluating:  69%|   | 22/32 [01:59<00:53,  5.37s/it]Evaluating:  72%|  | 23/32 [02:04<00:48,  5.38s/it]Evaluating:  75%|  | 24/32 [02:10<00:42,  5.37s/it]Evaluating:  78%|  | 25/32 [02:15<00:37,  5.38s/it]Evaluating:  81%| | 26/32 [02:21<00:32,  5.38s/it]Evaluating:  84%| | 27/32 [02:26<00:26,  5.37s/it]Evaluating:  88%| | 28/32 [02:31<00:21,  5.38s/it]Evaluating:  91%| | 29/32
30/32
31/32
29/32 [02:37<00:16,  5.37s/it]Evaluating:  94%|| 30/32 [02:42<00:10,  5.37s/it]Evaluating:  97%|| 31/32 [02:48<00:05,  5.41s/it]Evaluating: 100%|| 32/32 [02:52<00:00,  5.19s/it]Evaluating: 100%|| 32/32 [02:53<00:00,  5.42s/it]
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5/eval/0
dev | avg_loss: 1.056884765625 | {'exact_match': 0.0, 'rougeL': 33.2203}
train | epoch   0 | Iter:   4001/156230 | global iter:   4001/156230 | loss: 1.0295 | ds_loss: 1.0406 | lr: 9.9840e-05 | scale: 32768.0000 | micro time: 1.322 | step time: 0.000
train | epoch   0 | Iter:   4002/156230 | global iter:   4002/156230 | loss: 1.2252 | ds_loss: 1.2578 | lr: 9.9840e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   4003/156230 | global iter:   4003/156230 | loss: 1.2459 | ds_loss: 1.2657 | lr: 9.9840e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   4004/156230 | global iter:   4004/156230 | loss: 1.2587 | ds_loss: 1.2557 | lr: 9.9840e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4004/156230 | global iter:   4004/156230 | loss: 1.1898 | ds_loss: 1.2049 | lr: 9.9840e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 1.347
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4005/156230 | global iter:   4005/156230 | loss: 1.1588 | ds_loss: 1.1851 | lr: 9.9840e-05 | scale: 32768.0000 | micro time: 1.322 | step time: 0.000
train | epoch   0 | Iter:   4006/156230 | global iter:   4006/156230 | loss: 1.1522 | ds_loss: 1.1795 | lr: 9.9840e-05 | scale: 32768.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   4007/156230 | global iter:   4007/156230 | loss: 1.1671 | ds_loss: 1.1808 | lr: 9.9840e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   4008/156230 | global iter:   4008/156230 | loss: 1.1994 | ds_loss: 1.2034 | lr: 9.9839e-05 | scale: 32768.0000 | micro time: 1.386 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4008/156230 | global iter:   4008/156230 | loss: 1.1694 | ds_loss: 1.1872 | lr: 9.9839e-05 | scale: 32768.0000 | micro time: 1.386 | step time: 1.348
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4009/156230 | global iter:   4009/156230 | loss: 1.0899 | ds_loss: 1.1069 | lr: 9.9839e-05 | scale: 32768.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   4010/156230 | global iter:   4010/156230 | loss: 1.2189 | ds_loss: 1.2271 | lr: 9.9839e-05 | scale: 32768.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   4011/156230 | global iter:   4011/156230 | loss: 1.0766 | ds_loss: 1.0772 | lr: 9.9839e-05 | scale: 32768.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   4012/156230 | global iter:   4012/156230 | loss: 1.0601 | ds_loss: 1.0857 | lr: 9.9839e-05 | scale: 32768.0000 | micro time: 1.322 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4012/156230 | global iter:   4012/156230 | loss: 1.1114 | ds_loss: 1.1242 | lr: 9.9839e-05 | scale: 32768.0000 | micro time: 1.322 | step time: 1.328
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4013/156230 | global iter:   4013/156230 | loss: 1.1152 | ds_loss: 1.1096 | lr: 9.9839e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   4014/156230 | global iter:   4014/156230 | loss: 1.0469 | ds_loss: 1.0549 | lr: 9.9839e-05 | scale: 32768.0000 | micro time: 1.318 | step time: 0.000
train | epoch   0 | Iter:   4015/156230 | global iter:   4015/156230 | loss: 1.2540 | ds_loss: 1.2729 | lr: 9.9839e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   4016/156230 | global iter:   4016/156230 | loss: 1.0794 | ds_loss: 1.0920 | lr: 9.9839e-05 | scale: 32768.0000 | micro time: 1.326 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4016/156230 | global iter:   4016/156230 | loss: 1.1239 | ds_loss: 1.1324 | lr: 9.9839e-05 | scale: 32768.0000 | micro time: 1.326 | step time: 1.340
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4017/156230 | global iter:   4017/156230 | loss: 1.0641 | ds_loss: 1.0781 | lr: 9.9839e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   4018/156230 | global iter:   4018/156230 | loss: 1.1182 | ds_loss: 1.1303 | lr: 9.9839e-05 | scale: 32768.0000 | micro time: 1.317 | step time: 0.000
train | epoch   0 | Iter:   4019/156230 | global iter:   4019/156230 | loss: 1.1935 | ds_loss: 1.2228 | lr: 9.9839e-05 | scale: 32768.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   4020/156230 | global iter:   4020/156230 | loss: 1.0098 | ds_loss: 1.0242 | lr: 9.9839e-05 | scale: 65536.0000 | micro time: 1.317 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4020/156230 | global iter:   4020/156230 | loss: 1.0964 | ds_loss: 1.1139 | lr: 9.9839e-05 | scale: 65536.0000 | micro time: 1.317 | step time: 1.331
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4021/156230 | global iter:   4021/156230 | loss: 1.0890 | ds_loss: 1.1043 | lr: 9.9838e-05 | scale: 65536.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   4022/156230 | global iter:   4022/156230 | loss: 1.1564 | ds_loss: 1.1585 | lr: 9.9838e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   4023/156230 | global iter:   4023/156230 | loss: 0.9816 | ds_loss: 1.0101 | lr: 9.9838e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   4024/156230 | global iter:   4024/156230 | loss: 1.2904 | ds_loss: 1.2921 | lr: 9.9838e-05 | scale: 65536.0000 | micro time: 1.325 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4024/156230 | global iter:   4024/156230 | loss: 1.1294 | ds_loss: 1.1412 | lr: 9.9838e-05 | scale: 65536.0000 | micro time: 1.325 | step time: 1.344
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
[2025-04-20 20:12:10,904] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768
train | epoch   0 | Iter:   4025/156230 | global iter:   4025/156230 | loss: 1.0161 | ds_loss: 1.0449 | lr: 9.9838e-05 | scale: 32768.0000 | micro time: 1.317 | step time: 0.000
train | epoch   0 | Iter:   4026/156230 | global iter:   4026/156230 | loss: 1.1679 | ds_loss: 1.1806 | lr: 9.9838e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   4027/156230 | global iter:   4027/156230 | loss: 1.1696 | ds_loss: 1.1804 | lr: 9.9838e-05 | scale: 32768.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:   4028/156230 | global iter:   4028/156230 | loss: 1.1092 | ds_loss: 1.1286 | lr: 9.9838e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4028/156230 | global iter:   4028/156230 | loss: 1.1157 | ds_loss: 1.1336 | lr: 9.9838e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 1.334
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4029/156230 | global iter:   4029/156230 | loss: 1.0506 | ds_loss: 1.0485 | lr: 9.9838e-05 | scale: 32768.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   4030/156230 | global iter:   4030/156230 | loss: 1.2991 | ds_loss: 1.3156 | lr: 9.9838e-05 | scale: 32768.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   4031/156230 | global iter:   4031/156230 | loss: 1.1438 | ds_loss: 1.1506 | lr: 9.9838e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   4032/156230 | global iter:   4032/156230 | loss: 0.9915 | ds_loss: 1.0054 | lr: 9.9838e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4032/156230 | global iter:   4032/156230 | loss: 1.1212 | ds_loss: 1.1300 | lr: 9.9838e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 1.338
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4033/156230 | global iter:   4033/156230 | loss: 1.2304 | ds_loss: 1.2392 | lr: 9.9838e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   4034/156230 | global iter:   4034/156230 | loss: 1.2308 | ds_loss: 1.2383 | lr: 9.9837e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   4035/156230 | global iter:   4035/156230 | loss: 1.2664 | ds_loss: 1.2637 | lr: 9.9837e-05 | scale: 32768.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   4036/156230 | global iter:   4036/156230 | loss: 1.0706 | ds_loss: 1.0923 | lr: 9.9837e-05 | scale: 32768.0000 | micro time: 1.339 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4036/156230 | global iter:   4036/156230 | loss: 1.1996 | ds_loss: 1.2084 | lr: 9.9837e-05 | scale: 32768.0000 | micro time: 1.339 | step time: 1.345
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4037/156230 | global iter:   4037/156230 | loss: 1.3111 | ds_loss: 1.3109 | lr: 9.9837e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   4038/156230 | global iter:   4038/156230 | loss: 1.1148 | ds_loss: 1.1140 | lr: 9.9837e-05 | scale: 32768.0000 | micro time: 1.317 | step time: 0.000
train | epoch   0 | Iter:   4039/156230 | global iter:   4039/156230 | loss: 1.2318 | ds_loss: 1.2216 | lr: 9.9837e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   4040/156230 | global iter:   4040/156230 | loss: 1.0996 | ds_loss: 1.1015 | lr: 9.9837e-05 | scale: 32768.0000 | micro time: 1.331 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4040/156230 | global iter:   4040/156230 | loss: 1.1893 | ds_loss: 1.1870 | lr: 9.9837e-05 | scale: 32768.0000 | micro time: 1.331 | step time: 1.345
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4041/156230 | global iter:   4041/156230 | loss: 1.2357 | ds_loss: 1.2395 | lr: 9.9837e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   4042/156230 | global iter:   4042/156230 | loss: 1.0305 | ds_loss: 1.0523 | lr: 9.9837e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   4043/156230 | global iter:   4043/156230 | loss: 1.1057 | ds_loss: 1.1347 | lr: 9.9837e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   4044/156230 | global iter:   4044/156230 | loss: 1.0945 | ds_loss: 1.1361 | lr: 9.9837e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4044/156230 | global iter:   4044/156230 | loss: 1.1166 | ds_loss: 1.1407 | lr: 9.9837e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4045/156230 | global iter:   4045/156230 | loss: 1.0979 | ds_loss: 1.1309 | lr: 9.9837e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   4046/156230 | global iter:   4046/156230 | loss: 1.1372 | ds_loss: 1.1373 | lr: 9.9836e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   4047/156230 | global iter:   4047/156230 | loss: 1.1071 | ds_loss: 1.1051 | lr: 9.9836e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   4048/156230 | global iter:   4048/156230 | loss: 1.1060 | ds_loss: 1.1109 | lr: 9.9836e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4048/156230 | global iter:   4048/156230 | loss: 1.1121 | ds_loss: 1.1210 | lr: 9.9836e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4049/156230 | global iter:   4049/156230 | loss: 1.0918 | ds_loss: 1.1155 | lr: 9.9836e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   4050/156230 | global iter:   4050/156230 | loss: 1.1761 | ds_loss: 1.1894 | lr: 9.9836e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   4051/156230 | global iter:   4051/156230 | loss: 1.2311 | ds_loss: 1.2454 | lr: 9.9836e-05 | scale: 32768.0000 | micro time: 1.322 | step time: 0.000
train | epoch   0 | Iter:   4052/156230 | global iter:   4052/156230 | loss: 1.1357 | ds_loss: 1.1379 | lr: 9.9836e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4052/156230 | global iter:   4052/156230 | loss: 1.1586 | ds_loss: 1.1720 | lr: 9.9836e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4053/156230 | global iter:   4053/156230 | loss: 1.0699 | ds_loss: 1.0638 | lr: 9.9836e-05 | scale: 32768.0000 | micro time: 1.320 | step time: 0.000
train | epoch   0 | Iter:   4054/156230 | global iter:   4054/156230 | loss: 1.2775 | ds_loss: 1.2896 | lr: 9.9836e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   4055/156230 | global iter:   4055/156230 | loss: 1.2661 | ds_loss: 1.2780 | lr: 9.9836e-05 | scale: 32768.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   4056/156230 | global iter:   4056/156230 | loss: 0.9583 | ds_loss: 0.9667 | lr: 9.9836e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4056/156230 | global iter:   4056/156230 | loss: 1.1430 | ds_loss: 1.1495 | lr: 9.9836e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4057/156230 | global iter:   4057/156230 | loss: 1.1545 | ds_loss: 1.1580 | lr: 9.9836e-05 | scale: 32768.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:   4058/156230 | global iter:   4058/156230 | loss: 1.1601 | ds_loss: 1.1696 | lr: 9.9836e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   4059/156230 | global iter:   4059/156230 | loss: 1.0898 | ds_loss: 1.1138 | lr: 9.9835e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   4060/156230 | global iter:   4060/156230 | loss: 1.0568 | ds_loss: 1.0599 | lr: 9.9835e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4060/156230 | global iter:   4060/156230 | loss: 1.1153 | ds_loss: 1.1253 | lr: 9.9835e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 1.343
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4061/156230 | global iter:   4061/156230 | loss: 1.0068 | ds_loss: 1.0156 | lr: 9.9835e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   4062/156230 | global iter:   4062/156230 | loss: 1.2535 | ds_loss: 1.2787 | lr: 9.9835e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   4063/156230 | global iter:   4063/156230 | loss: 1.0964 | ds_loss: 1.1165 | lr: 9.9835e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   4064/156230 | global iter:   4064/156230 | loss: 1.0976 | ds_loss: 1.1091 | lr: 9.9835e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4064/156230 | global iter:   4064/156230 | loss: 1.1136 | ds_loss: 1.1300 | lr: 9.9835e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4065/156230 | global iter:   4065/156230 | loss: 1.1344 | ds_loss: 1.1312 | lr: 9.9835e-05 | scale: 32768.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   4066/156230 | global iter:   4066/156230 | loss: 1.1408 | ds_loss: 1.1598 | lr: 9.9835e-05 | scale: 32768.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   4067/156230 | global iter:   4067/156230 | loss: 1.1257 | ds_loss: 1.1662 | lr: 9.9835e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   4068/156230 | global iter:   4068/156230 | loss: 0.8986 | ds_loss: 0.9086 | lr: 9.9835e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4068/156230 | global iter:   4068/156230 | loss: 1.0749 | ds_loss: 1.0914 | lr: 9.9835e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4069/156230 | global iter:   4069/156230 | loss: 1.0700 | ds_loss: 1.0949 | lr: 9.9835e-05 | scale: 32768.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   4070/156230 | global iter:   4070/156230 | loss: 1.2461 | ds_loss: 1.2479 | lr: 9.9835e-05 | scale: 32768.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   4071/156230 | global iter:   4071/156230 | loss: 1.1828 | ds_loss: 1.1964 | lr: 9.9834e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   4072/156230 | global iter:   4072/156230 | loss: 1.1680 | ds_loss: 1.1571 | lr: 9.9834e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4072/156230 | global iter:   4072/156230 | loss: 1.1667 | ds_loss: 1.1741 | lr: 9.9834e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4073/156230 | global iter:   4073/156230 | loss: 1.2060 | ds_loss: 1.2359 | lr: 9.9834e-05 | scale: 32768.0000 | micro time: 1.307 | step time: 0.000
train | epoch   0 | Iter:   4074/156230 | global iter:   4074/156230 | loss: 1.1544 | ds_loss: 1.1666 | lr: 9.9834e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   4075/156230 | global iter:   4075/156230 | loss: 1.1590 | ds_loss: 1.1868 | lr: 9.9834e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   4076/156230 | global iter:   4076/156230 | loss: 1.2115 | ds_loss: 1.2398 | lr: 9.9834e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4076/156230 | global iter:   4076/156230 | loss: 1.1827 | ds_loss: 1.2073 | lr: 9.9834e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 1.343
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4077/156230 | global iter:   4077/156230 | loss: 1.0468 | ds_loss: 1.0650 | lr: 9.9834e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   4078/156230 | global iter:   4078/156230 | loss: 1.1027 | ds_loss: 1.1215 | lr: 9.9834e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   4079/156230 | global iter:   4079/156230 | loss: 1.0918 | ds_loss: 1.1240 | lr: 9.9834e-05 | scale: 32768.0000 | micro time: 1.313 | step time: 0.000
train | epoch   0 | Iter:   4080/156230 | global iter:   4080/156230 | loss: 1.1202 | ds_loss: 1.1290 | lr: 9.9834e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4080/156230 | global iter:   4080/156230 | loss: 1.0904 | ds_loss: 1.1099 | lr: 9.9834e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 1.346
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4081/156230 | global iter:   4081/156230 | loss: 1.0954 | ds_loss: 1.1062 | lr: 9.9834e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   4082/156230 | global iter:   4082/156230 | loss: 1.1965 | ds_loss: 1.1950 | lr: 9.9834e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   4083/156230 | global iter:   4083/156230 | loss: 1.1793 | ds_loss: 1.1961 | lr: 9.9833e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   4084/156230 | global iter:   4084/156230 | loss: 1.2350 | ds_loss: 1.2438 | lr: 9.9833e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4084/156230 | global iter:   4084/156230 | loss: 1.1766 | ds_loss: 1.1853 | lr: 9.9833e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4085/156230 | global iter:   4085/156230 | loss: 1.2427 | ds_loss: 1.2637 | lr: 9.9833e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   4086/156230 | global iter:   4086/156230 | loss: 1.0372 | ds_loss: 1.0318 | lr: 9.9833e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   4087/156230 | global iter:   4087/156230 | loss: 1.0015 | ds_loss: 1.0231 | lr: 9.9833e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   4088/156230 | global iter:   4088/156230 | loss: 1.2242 | ds_loss: 1.2337 | lr: 9.9833e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4088/156230 | global iter:   4088/156230 | loss: 1.1264 | ds_loss: 1.1380 | lr: 9.9833e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4089/156230 | global iter:   4089/156230 | loss: 1.0379 | ds_loss: 1.0396 | lr: 9.9833e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   4090/156230 | global iter:   4090/156230 | loss: 1.0896 | ds_loss: 1.0881 | lr: 9.9833e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   4091/156230 | global iter:   4091/156230 | loss: 1.2834 | ds_loss: 1.3040 | lr: 9.9833e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   4092/156230 | global iter:   4092/156230 | loss: 1.1180 | ds_loss: 1.1135 | lr: 9.9833e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4092/156230 | global iter:   4092/156230 | loss: 1.1322 | ds_loss: 1.1363 | lr: 9.9833e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4093/156230 | global iter:   4093/156230 | loss: 1.1745 | ds_loss: 1.2042 | lr: 9.9833e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   4094/156230 | global iter:   4094/156230 | loss: 1.1177 | ds_loss: 1.1189 | lr: 9.9833e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   4095/156230 | global iter:   4095/156230 | loss: 1.3011 | ds_loss: 1.3197 | lr: 9.9832e-05 | scale: 32768.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   4096/156230 | global iter:   4096/156230 | loss: 1.1338 | ds_loss: 1.1558 | lr: 9.9832e-05 | scale: 32768.0000 | micro time: 1.325 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4096/156230 | global iter:   4096/156230 | loss: 1.1818 | ds_loss: 1.1997 | lr: 9.9832e-05 | scale: 32768.0000 | micro time: 1.325 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4097/156230 | global iter:   4097/156230 | loss: 1.2346 | ds_loss: 1.2421 | lr: 9.9832e-05 | scale: 32768.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   4098/156230 | global iter:   4098/156230 | loss: 1.2465 | ds_loss: 1.2649 | lr: 9.9832e-05 | scale: 32768.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   4099/156230 | global iter:   4099/156230 | loss: 1.1393 | ds_loss: 1.1542 | lr: 9.9832e-05 | scale: 32768.0000 | micro time: 1.408 | step time: 0.000
train | epoch   0 | Iter:   4100/156230 | global iter:   4100/156230 | loss: 0.9289 | ds_loss: 0.9430 | lr: 9.9832e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4100/156230 | global iter:   4100/156230 | loss: 1.1373 | ds_loss: 1.1511 | lr: 9.9832e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 1.385
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4101/156230 | global iter:   4101/156230 | loss: 0.9587 | ds_loss: 0.9565 | lr: 9.9832e-05 | scale: 32768.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   4102/156230 | global iter:   4102/156230 | loss: 1.2458 | ds_loss: 1.2514 | lr: 9.9832e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   4103/156230 | global iter:   4103/156230 | loss: 1.1454 | ds_loss: 1.1638 | lr: 9.9832e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   4104/156230 | global iter:   4104/156230 | loss: 1.0953 | ds_loss: 1.0982 | lr: 9.9832e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4104/156230 | global iter:   4104/156230 | loss: 1.1113 | ds_loss: 1.1175 | lr: 9.9832e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4105/156230 | global iter:   4105/156230 | loss: 1.3154 | ds_loss: 1.3235 | lr: 9.9832e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   4106/156230 | global iter:   4106/156230 | loss: 1.3329 | ds_loss: 1.3381 | lr: 9.9832e-05 | scale: 32768.0000 | micro time: 1.314 | step time: 0.000
train | epoch   0 | Iter:   4107/156230 | global iter:   4107/156230 | loss: 1.0791 | ds_loss: 1.0786 | lr: 9.9831e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   4108/156230 | global iter:   4108/156230 | loss: 1.0065 | ds_loss: 1.0275 | lr: 9.9831e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4108/156230 | global iter:   4108/156230 | loss: 1.1835 | ds_loss: 1.1919 | lr: 9.9831e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4109/156230 | global iter:   4109/156230 | loss: 0.9947 | ds_loss: 1.0106 | lr: 9.9831e-05 | scale: 32768.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   4110/156230 | global iter:   4110/156230 | loss: 1.2320 | ds_loss: 1.2379 | lr: 9.9831e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   4111/156230 | global iter:   4111/156230 | loss: 1.0510 | ds_loss: 1.0743 | lr: 9.9831e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   4112/156230 | global iter:   4112/156230 | loss: 1.1384 | ds_loss: 1.1717 | lr: 9.9831e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4112/156230 | global iter:   4112/156230 | loss: 1.1040 | ds_loss: 1.1236 | lr: 9.9831e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4113/156230 | global iter:   4113/156230 | loss: 1.2388 | ds_loss: 1.2441 | lr: 9.9831e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   4114/156230 | global iter:   4114/156230 | loss: 1.1851 | ds_loss: 1.1967 | lr: 9.9831e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   4115/156230 | global iter:   4115/156230 | loss: 1.1541 | ds_loss: 1.1748 | lr: 9.9831e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   4116/156230 | global iter:   4116/156230 | loss: 1.1285 | ds_loss: 1.1526 | lr: 9.9831e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4116/156230 | global iter:   4116/156230 | loss: 1.1766 | ds_loss: 1.1921 | lr: 9.9831e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4117/156230 | global iter:   4117/156230 | loss: 1.1714 | ds_loss: 1.1875 | lr: 9.9831e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   4118/156230 | global iter:   4118/156230 | loss: 1.2354 | ds_loss: 1.2368 | lr: 9.9831e-05 | scale: 32768.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   4119/156230 | global iter:   4119/156230 | loss: 1.1306 | ds_loss: 1.1261 | lr: 9.9830e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   4120/156230 | global iter:   4120/156230 | loss: 1.2307 | ds_loss: 1.2511 | lr: 9.9830e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4120/156230 | global iter:   4120/156230 | loss: 1.1920 | ds_loss: 1.2004 | lr: 9.9830e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4121/156230 | global iter:   4121/156230 | loss: 1.1078 | ds_loss: 1.1201 | lr: 9.9830e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   4122/156230 | global iter:   4122/156230 | loss: 1.1818 | ds_loss: 1.1796 | lr: 9.9830e-05 | scale: 32768.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   4123/156230 | global iter:   4123/156230 | loss: 1.1621 | ds_loss: 1.1606 | lr: 9.9830e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   4124/156230 | global iter:   4124/156230 | loss: 1.1628 | ds_loss: 1.1606 | lr: 9.9830e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4124/156230 | global iter:   4124/156230 | loss: 1.1536 | ds_loss: 1.1552 | lr: 9.9830e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4125/156230 | global iter:   4125/156230 | loss: 1.0785 | ds_loss: 1.1028 | lr: 9.9830e-05 | scale: 32768.0000 | micro time: 1.325 | step time: 0.000
train | epoch   0 | Iter:   4126/156230 | global iter:   4126/156230 | loss: 0.9843 | ds_loss: 0.9975 | lr: 9.9830e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   4127/156230 | global iter:   4127/156230 | loss: 1.0747 | ds_loss: 1.0581 | lr: 9.9830e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   4128/156230 | global iter:   4128/156230 | loss: 1.0968 | ds_loss: 1.0997 | lr: 9.9830e-05 | scale: 32768.0000 | micro time: 1.415 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4128/156230 | global iter:   4128/156230 | loss: 1.0586 | ds_loss: 1.0645 | lr: 9.9830e-05 | scale: 32768.0000 | micro time: 1.415 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4129/156230 | global iter:   4129/156230 | loss: 1.0783 | ds_loss: 1.0994 | lr: 9.9830e-05 | scale: 32768.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   4130/156230 | global iter:   4130/156230 | loss: 1.0376 | ds_loss: 1.0545 | lr: 9.9830e-05 | scale: 32768.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   4131/156230 | global iter:   4131/156230 | loss: 1.0900 | ds_loss: 1.1158 | lr: 9.9830e-05 | scale: 32768.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   4132/156230 | global iter:   4132/156230 | loss: 1.3001 | ds_loss: 1.3088 | lr: 9.9829e-05 | scale: 32768.0000 | micro time: 1.321 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4132/156230 | global iter:   4132/156230 | loss: 1.1265 | ds_loss: 1.1446 | lr: 9.9829e-05 | scale: 32768.0000 | micro time: 1.321 | step time: 1.344
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4133/156230 | global iter:   4133/156230 | loss: 1.1382 | ds_loss: 1.1486 | lr: 9.9829e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   4134/156230 | global iter:   4134/156230 | loss: 1.2206 | ds_loss: 1.2287 | lr: 9.9829e-05 | scale: 32768.0000 | micro time: 1.421 | step time: 0.000
train | epoch   0 | Iter:   4135/156230 | global iter:   4135/156230 | loss: 1.0892 | ds_loss: 1.0850 | lr: 9.9829e-05 | scale: 32768.0000 | micro time: 1.316 | step time: 0.000
train | epoch   0 | Iter:   4136/156230 | global iter:   4136/156230 | loss: 1.0010 | ds_loss: 1.0097 | lr: 9.9829e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4136/156230 | global iter:   4136/156230 | loss: 1.1123 | ds_loss: 1.1180 | lr: 9.9829e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4137/156230 | global iter:   4137/156230 | loss: 1.1608 | ds_loss: 1.1692 | lr: 9.9829e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   4138/156230 | global iter:   4138/156230 | loss: 1.0868 | ds_loss: 1.0939 | lr: 9.9829e-05 | scale: 32768.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   4139/156230 | global iter:   4139/156230 | loss: 1.1692 | ds_loss: 1.1680 | lr: 9.9829e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   4140/156230 | global iter:   4140/156230 | loss: 1.1215 | ds_loss: 1.1325 | lr: 9.9829e-05 | scale: 32768.0000 | micro time: 1.389 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4140/156230 | global iter:   4140/156230 | loss: 1.1346 | ds_loss: 1.1409 | lr: 9.9829e-05 | scale: 32768.0000 | micro time: 1.389 | step time: 1.384
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4141/156230 | global iter:   4141/156230 | loss: 1.1790 | ds_loss: 1.1905 | lr: 9.9829e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   4142/156230 | global iter:   4142/156230 | loss: 1.1718 | ds_loss: 1.1823 | lr: 9.9829e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   4143/156230 | global iter:   4143/156230 | loss: 1.1432 | ds_loss: 1.1547 | lr: 9.9829e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   4144/156230 | global iter:   4144/156230 | loss: 1.1560 | ds_loss: 1.1668 | lr: 9.9828e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4144/156230 | global iter:   4144/156230 | loss: 1.1625 | ds_loss: 1.1736 | lr: 9.9828e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4145/156230 | global iter:   4145/156230 | loss: 1.2915 | ds_loss: 1.2996 | lr: 9.9828e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   4146/156230 | global iter:   4146/156230 | loss: 1.1899 | ds_loss: 1.2075 | lr: 9.9828e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   4147/156230 | global iter:   4147/156230 | loss: 1.0344 | ds_loss: 1.0463 | lr: 9.9828e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   4148/156230 | global iter:   4148/156230 | loss: 1.1077 | ds_loss: 1.1220 | lr: 9.9828e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4148/156230 | global iter:   4148/156230 | loss: 1.1559 | ds_loss: 1.1689 | lr: 9.9828e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4149/156230 | global iter:   4149/156230 | loss: 1.0986 | ds_loss: 1.1006 | lr: 9.9828e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   4150/156230 | global iter:   4150/156230 | loss: 1.1900 | ds_loss: 1.2042 | lr: 9.9828e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   4151/156230 | global iter:   4151/156230 | loss: 1.1795 | ds_loss: 1.1899 | lr: 9.9828e-05 | scale: 32768.0000 | micro time: 1.309 | step time: 0.000
train | epoch   0 | Iter:   4152/156230 | global iter:   4152/156230 | loss: 1.0247 | ds_loss: 1.0399 | lr: 9.9828e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4152/156230 | global iter:   4152/156230 | loss: 1.1232 | ds_loss: 1.1337 | lr: 9.9828e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 1.347
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4153/156230 | global iter:   4153/156230 | loss: 1.2588 | ds_loss: 1.2715 | lr: 9.9828e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   4154/156230 | global iter:   4154/156230 | loss: 1.1891 | ds_loss: 1.1894 | lr: 9.9828e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   4155/156230 | global iter:   4155/156230 | loss: 1.1347 | ds_loss: 1.1434 | lr: 9.9828e-05 | scale: 32768.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   4156/156230 | global iter:   4156/156230 | loss: 1.0318 | ds_loss: 1.0483 | lr: 9.9827e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4156/156230 | global iter:   4156/156230 | loss: 1.1536 | ds_loss: 1.1631 | lr: 9.9827e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 1.344
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4157/156230 | global iter:   4157/156230 | loss: 1.4098 | ds_loss: 1.4223 | lr: 9.9827e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   4158/156230 | global iter:   4158/156230 | loss: 1.1366 | ds_loss: 1.1637 | lr: 9.9827e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   4159/156230 | global iter:   4159/156230 | loss: 1.3274 | ds_loss: 1.3452 | lr: 9.9827e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   4160/156230 | global iter:   4160/156230 | loss: 1.3063 | ds_loss: 1.3169 | lr: 9.9827e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4160/156230 | global iter:   4160/156230 | loss: 1.2950 | ds_loss: 1.3121 | lr: 9.9827e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4161/156230 | global iter:   4161/156230 | loss: 1.1192 | ds_loss: 1.1374 | lr: 9.9827e-05 | scale: 32768.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   4162/156230 | global iter:   4162/156230 | loss: 1.1035 | ds_loss: 1.1354 | lr: 9.9827e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   4163/156230 | global iter:   4163/156230 | loss: 1.2958 | ds_loss: 1.3013 | lr: 9.9827e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   4164/156230 | global iter:   4164/156230 | loss: 1.0610 | ds_loss: 1.0653 | lr: 9.9827e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4164/156230 | global iter:   4164/156230 | loss: 1.1449 | ds_loss: 1.1598 | lr: 9.9827e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4165/156230 | global iter:   4165/156230 | loss: 1.0651 | ds_loss: 1.0868 | lr: 9.9827e-05 | scale: 32768.0000 | micro time: 1.307 | step time: 0.000
train | epoch   0 | Iter:   4166/156230 | global iter:   4166/156230 | loss: 1.1937 | ds_loss: 1.2091 | lr: 9.9827e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   4167/156230 | global iter:   4167/156230 | loss: 1.1114 | ds_loss: 1.1104 | lr: 9.9827e-05 | scale: 32768.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   4168/156230 | global iter:   4168/156230 | loss: 1.0513 | ds_loss: 1.0693 | lr: 9.9826e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4168/156230 | global iter:   4168/156230 | loss: 1.1054 | ds_loss: 1.1189 | lr: 9.9826e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4169/156230 | global iter:   4169/156230 | loss: 1.1878 | ds_loss: 1.1929 | lr: 9.9826e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   4170/156230 | global iter:   4170/156230 | loss: 1.2975 | ds_loss: 1.3085 | lr: 9.9826e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   4171/156230 | global iter:   4171/156230 | loss: 1.1894 | ds_loss: 1.2070 | lr: 9.9826e-05 | scale: 32768.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   4172/156230 | global iter:   4172/156230 | loss: 0.9196 | ds_loss: 0.9452 | lr: 9.9826e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4172/156230 | global iter:   4172/156230 | loss: 1.1486 | ds_loss: 1.1634 | lr: 9.9826e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4173/156230 | global iter:   4173/156230 | loss: 1.0619 | ds_loss: 1.0801 | lr: 9.9826e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   4174/156230 | global iter:   4174/156230 | loss: 0.9910 | ds_loss: 1.0075 | lr: 9.9826e-05 | scale: 32768.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   4175/156230 | global iter:   4175/156230 | loss: 0.9947 | ds_loss: 1.0133 | lr: 9.9826e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   4176/156230 | global iter:   4176/156230 | loss: 1.1329 | ds_loss: 1.1394 | lr: 9.9826e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4176/156230 | global iter:   4176/156230 | loss: 1.0451 | ds_loss: 1.0601 | lr: 9.9826e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4177/156230 | global iter:   4177/156230 | loss: 0.8654 | ds_loss: 0.8654 | lr: 9.9826e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   4178/156230 | global iter:   4178/156230 | loss: 1.1408 | ds_loss: 1.1769 | lr: 9.9826e-05 | scale: 32768.0000 | micro time: 1.325 | step time: 0.000
train | epoch   0 | Iter:   4179/156230 | global iter:   4179/156230 | loss: 1.1438 | ds_loss: 1.1644 | lr: 9.9826e-05 | scale: 32768.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   4180/156230 | global iter:   4180/156230 | loss: 1.2034 | ds_loss: 1.2275 | lr: 9.9825e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4180/156230 | global iter:   4180/156230 | loss: 1.0883 | ds_loss: 1.1086 | lr: 9.9825e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4181/156230 | global iter:   4181/156230 | loss: 1.1507 | ds_loss: 1.1654 | lr: 9.9825e-05 | scale: 32768.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   4182/156230 | global iter:   4182/156230 | loss: 1.2202 | ds_loss: 1.2237 | lr: 9.9825e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   4183/156230 | global iter:   4183/156230 | loss: 1.1792 | ds_loss: 1.1794 | lr: 9.9825e-05 | scale: 32768.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:   4184/156230 | global iter:   4184/156230 | loss: 1.2548 | ds_loss: 1.2661 | lr: 9.9825e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4184/156230 | global iter:   4184/156230 | loss: 1.2012 | ds_loss: 1.2087 | lr: 9.9825e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4185/156230 | global iter:   4185/156230 | loss: 1.0017 | ds_loss: 1.0119 | lr: 9.9825e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   4186/156230 | global iter:   4186/156230 | loss: 1.2845 | ds_loss: 1.2875 | lr: 9.9825e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   4187/156230 | global iter:   4187/156230 | loss: 1.2954 | ds_loss: 1.3183 | lr: 9.9825e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   4188/156230 | global iter:   4188/156230 | loss: 1.3525 | ds_loss: 1.3600 | lr: 9.9825e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4188/156230 | global iter:   4188/156230 | loss: 1.2335 | ds_loss: 1.2444 | lr: 9.9825e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4189/156230 | global iter:   4189/156230 | loss: 1.1125 | ds_loss: 1.1134 | lr: 9.9825e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   4190/156230 | global iter:   4190/156230 | loss: 1.0020 | ds_loss: 1.0249 | lr: 9.9825e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   4191/156230 | global iter:   4191/156230 | loss: 1.1153 | ds_loss: 1.1225 | lr: 9.9824e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   4192/156230 | global iter:   4192/156230 | loss: 1.0249 | ds_loss: 1.0431 | lr: 9.9824e-05 | scale: 32768.0000 | micro time: 1.389 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4192/156230 | global iter:   4192/156230 | loss: 1.0637 | ds_loss: 1.0760 | lr: 9.9824e-05 | scale: 32768.0000 | micro time: 1.389 | step time: 1.376
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4193/156230 | global iter:   4193/156230 | loss: 1.1711 | ds_loss: 1.1773 | lr: 9.9824e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   4194/156230 | global iter:   4194/156230 | loss: 1.0502 | ds_loss: 1.0575 | lr: 9.9824e-05 | scale: 32768.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   4195/156230 | global iter:   4195/156230 | loss: 1.0513 | ds_loss: 1.0588 | lr: 9.9824e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   4196/156230 | global iter:   4196/156230 | loss: 1.2214 | ds_loss: 1.2403 | lr: 9.9824e-05 | scale: 32768.0000 | micro time: 1.324 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4196/156230 | global iter:   4196/156230 | loss: 1.1235 | ds_loss: 1.1335 | lr: 9.9824e-05 | scale: 32768.0000 | micro time: 1.324 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4197/156230 | global iter:   4197/156230 | loss: 1.2430 | ds_loss: 1.2580 | lr: 9.9824e-05 | scale: 32768.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   4198/156230 | global iter:   4198/156230 | loss: 1.1174 | ds_loss: 1.1371 | lr: 9.9824e-05 | scale: 32768.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   4199/156230 | global iter:   4199/156230 | loss: 1.2139 | ds_loss: 1.2332 | lr: 9.9824e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   4200/156230 | global iter:   4200/156230 | loss: 0.9787 | ds_loss: 1.0012 | lr: 9.9824e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4200/156230 | global iter:   4200/156230 | loss: 1.1382 | ds_loss: 1.1574 | lr: 9.9824e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4201/156230 | global iter:   4201/156230 | loss: 0.9879 | ds_loss: 1.0135 | lr: 9.9824e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   4202/156230 | global iter:   4202/156230 | loss: 1.1305 | ds_loss: 1.1286 | lr: 9.9824e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   4203/156230 | global iter:   4203/156230 | loss: 1.1501 | ds_loss: 1.1467 | lr: 9.9823e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   4204/156230 | global iter:   4204/156230 | loss: 1.1820 | ds_loss: 1.1936 | lr: 9.9823e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4204/156230 | global iter:   4204/156230 | loss: 1.1126 | ds_loss: 1.1206 | lr: 9.9823e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4205/156230 | global iter:   4205/156230 | loss: 1.2345 | ds_loss: 1.2503 | lr: 9.9823e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   4206/156230 | global iter:   4206/156230 | loss: 1.2092 | ds_loss: 1.2157 | lr: 9.9823e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   4207/156230 | global iter:   4207/156230 | loss: 1.0957 | ds_loss: 1.1052 | lr: 9.9823e-05 | scale: 32768.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   4208/156230 | global iter:   4208/156230 | loss: 1.3315 | ds_loss: 1.3554 | lr: 9.9823e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4208/156230 | global iter:   4208/156230 | loss: 1.2177 | ds_loss: 1.2316 | lr: 9.9823e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4209/156230 | global iter:   4209/156230 | loss: 1.1440 | ds_loss: 1.1569 | lr: 9.9823e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   4210/156230 | global iter:   4210/156230 | loss: 0.9833 | ds_loss: 0.9825 | lr: 9.9823e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   4211/156230 | global iter:   4211/156230 | loss: 1.1130 | ds_loss: 1.1311 | lr: 9.9823e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   4212/156230 | global iter:   4212/156230 | loss: 1.0588 | ds_loss: 1.0749 | lr: 9.9823e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4212/156230 | global iter:   4212/156230 | loss: 1.0748 | ds_loss: 1.0863 | lr: 9.9823e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4213/156230 | global iter:   4213/156230 | loss: 1.1970 | ds_loss: 1.1896 | lr: 9.9823e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   4214/156230 | global iter:   4214/156230 | loss: 1.2075 | ds_loss: 1.2259 | lr: 9.9823e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   4215/156230 | global iter:   4215/156230 | loss: 1.1923 | ds_loss: 1.2062 | lr: 9.9822e-05 | scale: 32768.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   4216/156230 | global iter:   4216/156230 | loss: 1.1103 | ds_loss: 1.1281 | lr: 9.9822e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4216/156230 | global iter:   4216/156230 | loss: 1.1768 | ds_loss: 1.1875 | lr: 9.9822e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4217/156230 | global iter:   4217/156230 | loss: 1.1380 | ds_loss: 1.1513 | lr: 9.9822e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   4218/156230 | global iter:   4218/156230 | loss: 1.0721 | ds_loss: 1.0903 | lr: 9.9822e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   4219/156230 | global iter:   4219/156230 | loss: 1.1698 | ds_loss: 1.1964 | lr: 9.9822e-05 | scale: 32768.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   4220/156230 | global iter:   4220/156230 | loss: 1.1034 | ds_loss: 1.1067 | lr: 9.9822e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4220/156230 | global iter:   4220/156230 | loss: 1.1208 | ds_loss: 1.1362 | lr: 9.9822e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4221/156230 | global iter:   4221/156230 | loss: 1.1255 | ds_loss: 1.1511 | lr: 9.9822e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   4222/156230 | global iter:   4222/156230 | loss: 1.1506 | ds_loss: 1.1578 | lr: 9.9822e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   4223/156230 | global iter:   4223/156230 | loss: 1.1316 | ds_loss: 1.1418 | lr: 9.9822e-05 | scale: 32768.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   4224/156230 | global iter:   4224/156230 | loss: 1.0747 | ds_loss: 1.0763 | lr: 9.9822e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4224/156230 | global iter:   4224/156230 | loss: 1.1206 | ds_loss: 1.1318 | lr: 9.9822e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4225/156230 | global iter:   4225/156230 | loss: 1.1116 | ds_loss: 1.1288 | lr: 9.9822e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   4226/156230 | global iter:   4226/156230 | loss: 1.1813 | ds_loss: 1.1843 | lr: 9.9822e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   4227/156230 | global iter:   4227/156230 | loss: 1.2718 | ds_loss: 1.2700 | lr: 9.9821e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   4228/156230 | global iter:   4228/156230 | loss: 1.2449 | ds_loss: 1.2587 | lr: 9.9821e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4228/156230 | global iter:   4228/156230 | loss: 1.2024 | ds_loss: 1.2104 | lr: 9.9821e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4229/156230 | global iter:   4229/156230 | loss: 1.0104 | ds_loss: 1.0308 | lr: 9.9821e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   4230/156230 | global iter:   4230/156230 | loss: 0.9076 | ds_loss: 0.9093 | lr: 9.9821e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   4231/156230 | global iter:   4231/156230 | loss: 1.1032 | ds_loss: 1.1125 | lr: 9.9821e-05 | scale: 32768.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   4232/156230 | global iter:   4232/156230 | loss: 1.0854 | ds_loss: 1.0954 | lr: 9.9821e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4232/156230 | global iter:   4232/156230 | loss: 1.0267 | ds_loss: 1.0370 | lr: 9.9821e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4233/156230 | global iter:   4233/156230 | loss: 1.0927 | ds_loss: 1.1035 | lr: 9.9821e-05 | scale: 32768.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   4234/156230 | global iter:   4234/156230 | loss: 0.9153 | ds_loss: 0.9332 | lr: 9.9821e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   4235/156230 | global iter:   4235/156230 | loss: 1.0572 | ds_loss: 1.0522 | lr: 9.9821e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   4236/156230 | global iter:   4236/156230 | loss: 1.1713 | ds_loss: 1.1845 | lr: 9.9821e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4236/156230 | global iter:   4236/156230 | loss: 1.0591 | ds_loss: 1.0684 | lr: 9.9821e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4237/156230 | global iter:   4237/156230 | loss: 1.1108 | ds_loss: 1.1219 | lr: 9.9821e-05 | scale: 32768.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   4238/156230 | global iter:   4238/156230 | loss: 1.0161 | ds_loss: 1.0402 | lr: 9.9821e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   4239/156230 | global iter:   4239/156230 | loss: 1.1542 | ds_loss: 1.1899 | lr: 9.9820e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   4240/156230 | global iter:   4240/156230 | loss: 1.0638 | ds_loss: 1.0831 | lr: 9.9820e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4240/156230 | global iter:   4240/156230 | loss: 1.0862 | ds_loss: 1.1088 | lr: 9.9820e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4241/156230 | global iter:   4241/156230 | loss: 1.1544 | ds_loss: 1.1624 | lr: 9.9820e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   4242/156230 | global iter:   4242/156230 | loss: 1.0340 | ds_loss: 1.0451 | lr: 9.9820e-05 | scale: 32768.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   4243/156230 | global iter:   4243/156230 | loss: 1.1468 | ds_loss: 1.1507 | lr: 9.9820e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   4244/156230 | global iter:   4244/156230 | loss: 1.1969 | ds_loss: 1.1973 | lr: 9.9820e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4244/156230 | global iter:   4244/156230 | loss: 1.1330 | ds_loss: 1.1389 | lr: 9.9820e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4245/156230 | global iter:   4245/156230 | loss: 1.1792 | ds_loss: 1.2079 | lr: 9.9820e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   4246/156230 | global iter:   4246/156230 | loss: 1.1370 | ds_loss: 1.1677 | lr: 9.9820e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   4247/156230 | global iter:   4247/156230 | loss: 1.1874 | ds_loss: 1.2042 | lr: 9.9820e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   4248/156230 | global iter:   4248/156230 | loss: 1.2406 | ds_loss: 1.2494 | lr: 9.9820e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4248/156230 | global iter:   4248/156230 | loss: 1.1861 | ds_loss: 1.2073 | lr: 9.9820e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4249/156230 | global iter:   4249/156230 | loss: 1.1157 | ds_loss: 1.1228 | lr: 9.9820e-05 | scale: 32768.0000 | micro time: 1.450 | step time: 0.000
train | epoch   0 | Iter:   4250/156230 | global iter:   4250/156230 | loss: 0.9298 | ds_loss: 0.9562 | lr: 9.9819e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   4251/156230 | global iter:   4251/156230 | loss: 1.2769 | ds_loss: 1.2995 | lr: 9.9819e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   4252/156230 | global iter:   4252/156230 | loss: 1.3389 | ds_loss: 1.3658 | lr: 9.9819e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4252/156230 | global iter:   4252/156230 | loss: 1.1653 | ds_loss: 1.1861 | lr: 9.9819e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 1.385
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4253/156230 | global iter:   4253/156230 | loss: 1.1938 | ds_loss: 1.2023 | lr: 9.9819e-05 | scale: 32768.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   4254/156230 | global iter:   4254/156230 | loss: 1.1551 | ds_loss: 1.1650 | lr: 9.9819e-05 | scale: 32768.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:   4255/156230 | global iter:   4255/156230 | loss: 1.1190 | ds_loss: 1.1339 | lr: 9.9819e-05 | scale: 32768.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   4256/156230 | global iter:   4256/156230 | loss: 1.1468 | ds_loss: 1.1572 | lr: 9.9819e-05 | scale: 32768.0000 | micro time: 1.344 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4256/156230 | global iter:   4256/156230 | loss: 1.1537 | ds_loss: 1.1646 | lr: 9.9819e-05 | scale: 32768.0000 | micro time: 1.344 | step time: 1.346
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4257/156230 | global iter:   4257/156230 | loss: 1.0551 | ds_loss: 1.0717 | lr: 9.9819e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   4258/156230 | global iter:   4258/156230 | loss: 1.2395 | ds_loss: 1.2657 | lr: 9.9819e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   4259/156230 | global iter:   4259/156230 | loss: 1.0826 | ds_loss: 1.0880 | lr: 9.9819e-05 | scale: 32768.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   4260/156230 | global iter:   4260/156230 | loss: 1.2362 | ds_loss: 1.2539 | lr: 9.9819e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4260/156230 | global iter:   4260/156230 | loss: 1.1533 | ds_loss: 1.1698 | lr: 9.9819e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4261/156230 | global iter:   4261/156230 | loss: 1.1419 | ds_loss: 1.1523 | lr: 9.9819e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   4262/156230 | global iter:   4262/156230 | loss: 1.2815 | ds_loss: 1.2888 | lr: 9.9818e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   4263/156230 | global iter:   4263/156230 | loss: 1.0648 | ds_loss: 1.0860 | lr: 9.9818e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   4264/156230 | global iter:   4264/156230 | loss: 0.9250 | ds_loss: 0.9441 | lr: 9.9818e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4264/156230 | global iter:   4264/156230 | loss: 1.1033 | ds_loss: 1.1178 | lr: 9.9818e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4265/156230 | global iter:   4265/156230 | loss: 1.0464 | ds_loss: 1.0636 | lr: 9.9818e-05 | scale: 32768.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   4266/156230 | global iter:   4266/156230 | loss: 1.2223 | ds_loss: 1.2447 | lr: 9.9818e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   4267/156230 | global iter:   4267/156230 | loss: 1.0409 | ds_loss: 1.0498 | lr: 9.9818e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   4268/156230 | global iter:   4268/156230 | loss: 0.9229 | ds_loss: 0.9262 | lr: 9.9818e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4268/156230 | global iter:   4268/156230 | loss: 1.0581 | ds_loss: 1.0711 | lr: 9.9818e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4269/156230 | global iter:   4269/156230 | loss: 1.2453 | ds_loss: 1.2459 | lr: 9.9818e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   4270/156230 | global iter:   4270/156230 | loss: 1.0686 | ds_loss: 1.0814 | lr: 9.9818e-05 | scale: 32768.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   4271/156230 | global iter:   4271/156230 | loss: 1.2415 | ds_loss: 1.2485 | lr: 9.9818e-05 | scale: 32768.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   4272/156230 | global iter:   4272/156230 | loss: 1.2202 | ds_loss: 1.2550 | lr: 9.9818e-05 | scale: 32768.0000 | micro time: 1.412 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4272/156230 | global iter:   4272/156230 | loss: 1.1939 | ds_loss: 1.2077 | lr: 9.9818e-05 | scale: 32768.0000 | micro time: 1.412 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4273/156230 | global iter:   4273/156230 | loss: 1.2333 | ds_loss: 1.2448 | lr: 9.9818e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   4274/156230 | global iter:   4274/156230 | loss: 1.1880 | ds_loss: 1.2050 | lr: 9.9817e-05 | scale: 32768.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   4275/156230 | global iter:   4275/156230 | loss: 1.1952 | ds_loss: 1.1908 | lr: 9.9817e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   4276/156230 | global iter:   4276/156230 | loss: 1.1917 | ds_loss: 1.1976 | lr: 9.9817e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4276/156230 | global iter:   4276/156230 | loss: 1.2021 | ds_loss: 1.2095 | lr: 9.9817e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4277/156230 | global iter:   4277/156230 | loss: 1.2402 | ds_loss: 1.2518 | lr: 9.9817e-05 | scale: 32768.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   4278/156230 | global iter:   4278/156230 | loss: 1.0899 | ds_loss: 1.0874 | lr: 9.9817e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   4279/156230 | global iter:   4279/156230 | loss: 1.0741 | ds_loss: 1.0816 | lr: 9.9817e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   4280/156230 | global iter:   4280/156230 | loss: 1.0632 | ds_loss: 1.0683 | lr: 9.9817e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4280/156230 | global iter:   4280/156230 | loss: 1.1169 | ds_loss: 1.1223 | lr: 9.9817e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4281/156230 | global iter:   4281/156230 | loss: 1.1340 | ds_loss: 1.1351 | lr: 9.9817e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   4282/156230 | global iter:   4282/156230 | loss: 1.2751 | ds_loss: 1.2787 | lr: 9.9817e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   4283/156230 | global iter:   4283/156230 | loss: 1.1781 | ds_loss: 1.1917 | lr: 9.9817e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   4284/156230 | global iter:   4284/156230 | loss: 1.1393 | ds_loss: 1.1725 | lr: 9.9817e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4284/156230 | global iter:   4284/156230 | loss: 1.1816 | ds_loss: 1.1945 | lr: 9.9817e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4285/156230 | global iter:   4285/156230 | loss: 1.0198 | ds_loss: 1.0244 | lr: 9.9816e-05 | scale: 32768.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   4286/156230 | global iter:   4286/156230 | loss: 1.1218 | ds_loss: 1.1156 | lr: 9.9816e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   4287/156230 | global iter:   4287/156230 | loss: 0.9300 | ds_loss: 0.9452 | lr: 9.9816e-05 | scale: 32768.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   4288/156230 | global iter:   4288/156230 | loss: 1.0331 | ds_loss: 1.0387 | lr: 9.9816e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4288/156230 | global iter:   4288/156230 | loss: 1.0262 | ds_loss: 1.0310 | lr: 9.9816e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4289/156230 | global iter:   4289/156230 | loss: 1.1023 | ds_loss: 1.1099 | lr: 9.9816e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   4290/156230 | global iter:   4290/156230 | loss: 1.0942 | ds_loss: 1.0978 | lr: 9.9816e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   4291/156230 | global iter:   4291/156230 | loss: 1.0995 | ds_loss: 1.0973 | lr: 9.9816e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   4292/156230 | global iter:   4292/156230 | loss: 1.2003 | ds_loss: 1.2257 | lr: 9.9816e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4292/156230 | global iter:   4292/156230 | loss: 1.1241 | ds_loss: 1.1327 | lr: 9.9816e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4293/156230 | global iter:   4293/156230 | loss: 1.1683 | ds_loss: 1.1974 | lr: 9.9816e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   4294/156230 | global iter:   4294/156230 | loss: 1.0699 | ds_loss: 1.0818 | lr: 9.9816e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   4295/156230 | global iter:   4295/156230 | loss: 0.9902 | ds_loss: 1.0086 | lr: 9.9816e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   4296/156230 | global iter:   4296/156230 | loss: 1.1295 | ds_loss: 1.1379 | lr: 9.9816e-05 | scale: 32768.0000 | micro time: 1.384 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4296/156230 | global iter:   4296/156230 | loss: 1.0894 | ds_loss: 1.1064 | lr: 9.9816e-05 | scale: 32768.0000 | micro time: 1.384 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4297/156230 | global iter:   4297/156230 | loss: 1.1312 | ds_loss: 1.1563 | lr: 9.9815e-05 | scale: 32768.0000 | micro time: 1.421 | step time: 0.000
train | epoch   0 | Iter:   4298/156230 | global iter:   4298/156230 | loss: 1.2013 | ds_loss: 1.2142 | lr: 9.9815e-05 | scale: 32768.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   4299/156230 | global iter:   4299/156230 | loss: 1.0793 | ds_loss: 1.1068 | lr: 9.9815e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   4300/156230 | global iter:   4300/156230 | loss: 1.0744 | ds_loss: 1.0846 | lr: 9.9815e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4300/156230 | global iter:   4300/156230 | loss: 1.1215 | ds_loss: 1.1405 | lr: 9.9815e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4301/156230 | global iter:   4301/156230 | loss: 0.9827 | ds_loss: 1.0059 | lr: 9.9815e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   4302/156230 | global iter:   4302/156230 | loss: 1.0838 | ds_loss: 1.0926 | lr: 9.9815e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   4303/156230 | global iter:   4303/156230 | loss: 1.1729 | ds_loss: 1.1801 | lr: 9.9815e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   4304/156230 | global iter:   4304/156230 | loss: 1.1920 | ds_loss: 1.1980 | lr: 9.9815e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4304/156230 | global iter:   4304/156230 | loss: 1.1079 | ds_loss: 1.1192 | lr: 9.9815e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4305/156230 | global iter:   4305/156230 | loss: 1.1054 | ds_loss: 1.1210 | lr: 9.9815e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   4306/156230 | global iter:   4306/156230 | loss: 1.0958 | ds_loss: 1.1126 | lr: 9.9815e-05 | scale: 32768.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   4307/156230 | global iter:   4307/156230 | loss: 1.1193 | ds_loss: 1.1379 | lr: 9.9815e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   4308/156230 | global iter:   4308/156230 | loss: 1.1357 | ds_loss: 1.1560 | lr: 9.9815e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4308/156230 | global iter:   4308/156230 | loss: 1.1141 | ds_loss: 1.1319 | lr: 9.9815e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4309/156230 | global iter:   4309/156230 | loss: 1.1742 | ds_loss: 1.1899 | lr: 9.9814e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   4310/156230 | global iter:   4310/156230 | loss: 1.0920 | ds_loss: 1.1050 | lr: 9.9814e-05 | scale: 32768.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   4311/156230 | global iter:   4311/156230 | loss: 1.0743 | ds_loss: 1.0862 | lr: 9.9814e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   4312/156230 | global iter:   4312/156230 | loss: 1.1588 | ds_loss: 1.1820 | lr: 9.9814e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4312/156230 | global iter:   4312/156230 | loss: 1.1248 | ds_loss: 1.1408 | lr: 9.9814e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4313/156230 | global iter:   4313/156230 | loss: 1.0369 | ds_loss: 1.0529 | lr: 9.9814e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   4314/156230 | global iter:   4314/156230 | loss: 0.9982 | ds_loss: 1.0019 | lr: 9.9814e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   4315/156230 | global iter:   4315/156230 | loss: 0.8939 | ds_loss: 0.9008 | lr: 9.9814e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   4316/156230 | global iter:   4316/156230 | loss: 1.1414 | ds_loss: 1.1712 | lr: 9.9814e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4316/156230 | global iter:   4316/156230 | loss: 1.0176 | ds_loss: 1.0317 | lr: 9.9814e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4317/156230 | global iter:   4317/156230 | loss: 1.1126 | ds_loss: 1.1165 | lr: 9.9814e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   4318/156230 | global iter:   4318/156230 | loss: 1.1161 | ds_loss: 1.1222 | lr: 9.9814e-05 | scale: 32768.0000 | micro time: 1.322 | step time: 0.000
train | epoch   0 | Iter:   4319/156230 | global iter:   4319/156230 | loss: 1.1542 | ds_loss: 1.1687 | lr: 9.9814e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   4320/156230 | global iter:   4320/156230 | loss: 1.1264 | ds_loss: 1.1453 | lr: 9.9813e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4320/156230 | global iter:   4320/156230 | loss: 1.1273 | ds_loss: 1.1382 | lr: 9.9813e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4321/156230 | global iter:   4321/156230 | loss: 1.1417 | ds_loss: 1.1469 | lr: 9.9813e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   4322/156230 | global iter:   4322/156230 | loss: 1.1969 | ds_loss: 1.2180 | lr: 9.9813e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   4323/156230 | global iter:   4323/156230 | loss: 1.3184 | ds_loss: 1.3429 | lr: 9.9813e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   4324/156230 | global iter:   4324/156230 | loss: 1.0952 | ds_loss: 1.1091 | lr: 9.9813e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4324/156230 | global iter:   4324/156230 | loss: 1.1880 | ds_loss: 1.2042 | lr: 9.9813e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4325/156230 | global iter:   4325/156230 | loss: 1.2986 | ds_loss: 1.3114 | lr: 9.9813e-05 | scale: 32768.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   4326/156230 | global iter:   4326/156230 | loss: 0.9675 | ds_loss: 0.9854 | lr: 9.9813e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   4327/156230 | global iter:   4327/156230 | loss: 1.1086 | ds_loss: 1.1510 | lr: 9.9813e-05 | scale: 32768.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   4328/156230 | global iter:   4328/156230 | loss: 1.0731 | ds_loss: 1.0760 | lr: 9.9813e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4328/156230 | global iter:   4328/156230 | loss: 1.1120 | ds_loss: 1.1310 | lr: 9.9813e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4329/156230 | global iter:   4329/156230 | loss: 1.2365 | ds_loss: 1.2586 | lr: 9.9813e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   4330/156230 | global iter:   4330/156230 | loss: 1.1633 | ds_loss: 1.1818 | lr: 9.9813e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   4331/156230 | global iter:   4331/156230 | loss: 1.0800 | ds_loss: 1.1054 | lr: 9.9813e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   4332/156230 | global iter:   4332/156230 | loss: 1.1221 | ds_loss: 1.1280 | lr: 9.9812e-05 | scale: 32768.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4332/156230 | global iter:   4332/156230 | loss: 1.1505 | ds_loss: 1.1684 | lr: 9.9812e-05 | scale: 32768.0000 | micro time: 1.385 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4333/156230 | global iter:   4333/156230 | loss: 1.0583 | ds_loss: 1.0654 | lr: 9.9812e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   4334/156230 | global iter:   4334/156230 | loss: 1.0910 | ds_loss: 1.0829 | lr: 9.9812e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   4335/156230 | global iter:   4335/156230 | loss: 1.1477 | ds_loss: 1.1732 | lr: 9.9812e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   4336/156230 | global iter:   4336/156230 | loss: 1.2545 | ds_loss: 1.2471 | lr: 9.9812e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4336/156230 | global iter:   4336/156230 | loss: 1.1379 | ds_loss: 1.1422 | lr: 9.9812e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4337/156230 | global iter:   4337/156230 | loss: 1.1357 | ds_loss: 1.1428 | lr: 9.9812e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   4338/156230 | global iter:   4338/156230 | loss: 1.0205 | ds_loss: 1.0277 | lr: 9.9812e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   4339/156230 | global iter:   4339/156230 | loss: 1.1143 | ds_loss: 1.1231 | lr: 9.9812e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   4340/156230 | global iter:   4340/156230 | loss: 1.2444 | ds_loss: 1.2588 | lr: 9.9812e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4340/156230 | global iter:   4340/156230 | loss: 1.1287 | ds_loss: 1.1381 | lr: 9.9812e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4341/156230 | global iter:   4341/156230 | loss: 1.0795 | ds_loss: 1.0805 | lr: 9.9812e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   4342/156230 | global iter:   4342/156230 | loss: 1.3407 | ds_loss: 1.3605 | lr: 9.9812e-05 | scale: 32768.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   4343/156230 | global iter:   4343/156230 | loss: 1.0763 | ds_loss: 1.1049 | lr: 9.9811e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   4344/156230 | global iter:   4344/156230 | loss: 1.0262 | ds_loss: 1.0268 | lr: 9.9811e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4344/156230 | global iter:   4344/156230 | loss: 1.1307 | ds_loss: 1.1432 | lr: 9.9811e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4345/156230 | global iter:   4345/156230 | loss: 1.1684 | ds_loss: 1.1816 | lr: 9.9811e-05 | scale: 32768.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   4346/156230 | global iter:   4346/156230 | loss: 1.1379 | ds_loss: 1.1388 | lr: 9.9811e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   4347/156230 | global iter:   4347/156230 | loss: 1.1410 | ds_loss: 1.1509 | lr: 9.9811e-05 | scale: 32768.0000 | micro time: 1.417 | step time: 0.000
train | epoch   0 | Iter:   4348/156230 | global iter:   4348/156230 | loss: 1.1221 | ds_loss: 1.1272 | lr: 9.9811e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4348/156230 | global iter:   4348/156230 | loss: 1.1423 | ds_loss: 1.1496 | lr: 9.9811e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4349/156230 | global iter:   4349/156230 | loss: 1.2236 | ds_loss: 1.2502 | lr: 9.9811e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   4350/156230 | global iter:   4350/156230 | loss: 1.2275 | ds_loss: 1.2345 | lr: 9.9811e-05 | scale: 32768.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   4351/156230 | global iter:   4351/156230 | loss: 1.0808 | ds_loss: 1.0945 | lr: 9.9811e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   4352/156230 | global iter:   4352/156230 | loss: 1.2226 | ds_loss: 1.2372 | lr: 9.9811e-05 | scale: 32768.0000 | micro time: 1.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4352/156230 | global iter:   4352/156230 | loss: 1.1886 | ds_loss: 1.2041 | lr: 9.9811e-05 | scale: 32768.0000 | micro time: 1.394 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4353/156230 | global iter:   4353/156230 | loss: 1.1256 | ds_loss: 1.1361 | lr: 9.9811e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   4354/156230 | global iter:   4354/156230 | loss: 0.9731 | ds_loss: 0.9870 | lr: 9.9811e-05 | scale: 32768.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   4355/156230 | global iter:   4355/156230 | loss: 1.0884 | ds_loss: 1.0959 | lr: 9.9810e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   4356/156230 | global iter:   4356/156230 | loss: 1.2213 | ds_loss: 1.2319 | lr: 9.9810e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4356/156230 | global iter:   4356/156230 | loss: 1.1021 | ds_loss: 1.1127 | lr: 9.9810e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4357/156230 | global iter:   4357/156230 | loss: 1.2305 | ds_loss: 1.2401 | lr: 9.9810e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   4358/156230 | global iter:   4358/156230 | loss: 1.1743 | ds_loss: 1.1764 | lr: 9.9810e-05 | scale: 32768.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   4359/156230 | global iter:   4359/156230 | loss: 1.1941 | ds_loss: 1.2039 | lr: 9.9810e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   4360/156230 | global iter:   4360/156230 | loss: 1.1602 | ds_loss: 1.1802 | lr: 9.9810e-05 | scale: 32768.0000 | micro time: 1.326 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4360/156230 | global iter:   4360/156230 | loss: 1.1898 | ds_loss: 1.2002 | lr: 9.9810e-05 | scale: 32768.0000 | micro time: 1.326 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4361/156230 | global iter:   4361/156230 | loss: 1.2509 | ds_loss: 1.2657 | lr: 9.9810e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   4362/156230 | global iter:   4362/156230 | loss: 1.1370 | ds_loss: 1.1617 | lr: 9.9810e-05 | scale: 32768.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   4363/156230 | global iter:   4363/156230 | loss: 1.0943 | ds_loss: 1.1062 | lr: 9.9810e-05 | scale: 32768.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   4364/156230 | global iter:   4364/156230 | loss: 1.0909 | ds_loss: 1.1125 | lr: 9.9810e-05 | scale: 32768.0000 | micro time: 1.334 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4364/156230 | global iter:   4364/156230 | loss: 1.1432 | ds_loss: 1.1615 | lr: 9.9810e-05 | scale: 32768.0000 | micro time: 1.334 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4365/156230 | global iter:   4365/156230 | loss: 1.2785 | ds_loss: 1.2705 | lr: 9.9810e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   4366/156230 | global iter:   4366/156230 | loss: 1.2500 | ds_loss: 1.2597 | lr: 9.9809e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   4367/156230 | global iter:   4367/156230 | loss: 1.2090 | ds_loss: 1.2337 | lr: 9.9809e-05 | scale: 32768.0000 | micro time: 1.401 | step time: 0.000
train | epoch   0 | Iter:   4368/156230 | global iter:   4368/156230 | loss: 1.2172 | ds_loss: 1.2199 | lr: 9.9809e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4368/156230 | global iter:   4368/156230 | loss: 1.2387 | ds_loss: 1.2459 | lr: 9.9809e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4369/156230 | global iter:   4369/156230 | loss: 1.1022 | ds_loss: 1.1353 | lr: 9.9809e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   4370/156230 | global iter:   4370/156230 | loss: 1.2461 | ds_loss: 1.2624 | lr: 9.9809e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   4371/156230 | global iter:   4371/156230 | loss: 1.0405 | ds_loss: 1.0350 | lr: 9.9809e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   4372/156230 | global iter:   4372/156230 | loss: 1.0555 | ds_loss: 1.0787 | lr: 9.9809e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4372/156230 | global iter:   4372/156230 | loss: 1.1111 | ds_loss: 1.1278 | lr: 9.9809e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4373/156230 | global iter:   4373/156230 | loss: 1.1245 | ds_loss: 1.1315 | lr: 9.9809e-05 | scale: 32768.0000 | micro time: 1.320 | step time: 0.000
train | epoch   0 | Iter:   4374/156230 | global iter:   4374/156230 | loss: 1.1619 | ds_loss: 1.1739 | lr: 9.9809e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   4375/156230 | global iter:   4375/156230 | loss: 1.1959 | ds_loss: 1.2105 | lr: 9.9809e-05 | scale: 32768.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   4376/156230 | global iter:   4376/156230 | loss: 1.1205 | ds_loss: 1.1482 | lr: 9.9809e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4376/156230 | global iter:   4376/156230 | loss: 1.1507 | ds_loss: 1.1660 | lr: 9.9809e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4377/156230 | global iter:   4377/156230 | loss: 1.0976 | ds_loss: 1.1118 | lr: 9.9808e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   4378/156230 | global iter:   4378/156230 | loss: 1.0162 | ds_loss: 1.0238 | lr: 9.9808e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   4379/156230 | global iter:   4379/156230 | loss: 1.0690 | ds_loss: 1.0682 | lr: 9.9808e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   4380/156230 | global iter:   4380/156230 | loss: 0.8382 | ds_loss: 0.8520 | lr: 9.9808e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4380/156230 | global iter:   4380/156230 | loss: 1.0053 | ds_loss: 1.0139 | lr: 9.9808e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4381/156230 | global iter:   4381/156230 | loss: 1.1955 | ds_loss: 1.2138 | lr: 9.9808e-05 | scale: 32768.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   4382/156230 | global iter:   4382/156230 | loss: 1.1791 | ds_loss: 1.1847 | lr: 9.9808e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   4383/156230 | global iter:   4383/156230 | loss: 1.1665 | ds_loss: 1.1887 | lr: 9.9808e-05 | scale: 32768.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   4384/156230 | global iter:   4384/156230 | loss: 1.0777 | ds_loss: 1.0669 | lr: 9.9808e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4384/156230 | global iter:   4384/156230 | loss: 1.1547 | ds_loss: 1.1635 | lr: 9.9808e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4385/156230 | global iter:   4385/156230 | loss: 1.1875 | ds_loss: 1.1936 | lr: 9.9808e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   4386/156230 | global iter:   4386/156230 | loss: 1.0735 | ds_loss: 1.0887 | lr: 9.9808e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   4387/156230 | global iter:   4387/156230 | loss: 1.1186 | ds_loss: 1.1449 | lr: 9.9808e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   4388/156230 | global iter:   4388/156230 | loss: 1.1553 | ds_loss: 1.1625 | lr: 9.9808e-05 | scale: 32768.0000 | micro time: 1.317 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4388/156230 | global iter:   4388/156230 | loss: 1.1337 | ds_loss: 1.1474 | lr: 9.9808e-05 | scale: 32768.0000 | micro time: 1.317 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4389/156230 | global iter:   4389/156230 | loss: 1.0770 | ds_loss: 1.0849 | lr: 9.9807e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   4390/156230 | global iter:   4390/156230 | loss: 1.2821 | ds_loss: 1.2941 | lr: 9.9807e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   4391/156230 | global iter:   4391/156230 | loss: 1.0096 | ds_loss: 1.0159 | lr: 9.9807e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   4392/156230 | global iter:   4392/156230 | loss: 0.9796 | ds_loss: 0.9983 | lr: 9.9807e-05 | scale: 32768.0000 | micro time: 1.325 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4392/156230 | global iter:   4392/156230 | loss: 1.0871 | ds_loss: 1.0983 | lr: 9.9807e-05 | scale: 32768.0000 | micro time: 1.325 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4393/156230 | global iter:   4393/156230 | loss: 1.1053 | ds_loss: 1.1108 | lr: 9.9807e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   4394/156230 | global iter:   4394/156230 | loss: 0.9986 | ds_loss: 1.0289 | lr: 9.9807e-05 | scale: 32768.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   4395/156230 | global iter:   4395/156230 | loss: 1.1335 | ds_loss: 1.1512 | lr: 9.9807e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   4396/156230 | global iter:   4396/156230 | loss: 1.1906 | ds_loss: 1.2137 | lr: 9.9807e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4396/156230 | global iter:   4396/156230 | loss: 1.1070 | ds_loss: 1.1262 | lr: 9.9807e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4397/156230 | global iter:   4397/156230 | loss: 1.1266 | ds_loss: 1.1394 | lr: 9.9807e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   4398/156230 | global iter:   4398/156230 | loss: 1.0185 | ds_loss: 1.0377 | lr: 9.9807e-05 | scale: 32768.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   4399/156230 | global iter:   4399/156230 | loss: 1.2418 | ds_loss: 1.2564 | lr: 9.9807e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   4400/156230 | global iter:   4400/156230 | loss: 1.2032 | ds_loss: 1.2272 | lr: 9.9806e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4400/156230 | global iter:   4400/156230 | loss: 1.1475 | ds_loss: 1.1652 | lr: 9.9806e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4401/156230 | global iter:   4401/156230 | loss: 1.1443 | ds_loss: 1.1710 | lr: 9.9806e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   4402/156230 | global iter:   4402/156230 | loss: 1.1258 | ds_loss: 1.1399 | lr: 9.9806e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   4403/156230 | global iter:   4403/156230 | loss: 1.1233 | ds_loss: 1.1381 | lr: 9.9806e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   4404/156230 | global iter:   4404/156230 | loss: 1.1585 | ds_loss: 1.1682 | lr: 9.9806e-05 | scale: 32768.0000 | micro time: 1.316 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4404/156230 | global iter:   4404/156230 | loss: 1.1380 | ds_loss: 1.1543 | lr: 9.9806e-05 | scale: 32768.0000 | micro time: 1.316 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4405/156230 | global iter:   4405/156230 | loss: 1.1859 | ds_loss: 1.1988 | lr: 9.9806e-05 | scale: 32768.0000 | micro time: 1.408 | step time: 0.000
train | epoch   0 | Iter:   4406/156230 | global iter:   4406/156230 | loss: 1.1532 | ds_loss: 1.1622 | lr: 9.9806e-05 | scale: 32768.0000 | micro time: 1.315 | step time: 0.000
train | epoch   0 | Iter:   4407/156230 | global iter:   4407/156230 | loss: 1.1027 | ds_loss: 1.1265 | lr: 9.9806e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   4408/156230 | global iter:   4408/156230 | loss: 1.3405 | ds_loss: 1.3489 | lr: 9.9806e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4408/156230 | global iter:   4408/156230 | loss: 1.1956 | ds_loss: 1.2091 | lr: 9.9806e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4409/156230 | global iter:   4409/156230 | loss: 1.1206 | ds_loss: 1.1451 | lr: 9.9806e-05 | scale: 32768.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   4410/156230 | global iter:   4410/156230 | loss: 1.0929 | ds_loss: 1.1057 | lr: 9.9806e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   4411/156230 | global iter:   4411/156230 | loss: 1.1625 | ds_loss: 1.1824 | lr: 9.9805e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   4412/156230 | global iter:   4412/156230 | loss: 1.2077 | ds_loss: 1.2101 | lr: 9.9805e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4412/156230 | global iter:   4412/156230 | loss: 1.1459 | ds_loss: 1.1608 | lr: 9.9805e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4413/156230 | global iter:   4413/156230 | loss: 1.2431 | ds_loss: 1.2463 | lr: 9.9805e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   4414/156230 | global iter:   4414/156230 | loss: 1.1226 | ds_loss: 1.1314 | lr: 9.9805e-05 | scale: 32768.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   4415/156230 | global iter:   4415/156230 | loss: 0.9843 | ds_loss: 1.0141 | lr: 9.9805e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   4416/156230 | global iter:   4416/156230 | loss: 1.2774 | ds_loss: 1.2790 | lr: 9.9805e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4416/156230 | global iter:   4416/156230 | loss: 1.1569 | ds_loss: 1.1677 | lr: 9.9805e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4417/156230 | global iter:   4417/156230 | loss: 1.1011 | ds_loss: 1.1181 | lr: 9.9805e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   4418/156230 | global iter:   4418/156230 | loss: 0.9742 | ds_loss: 0.9743 | lr: 9.9805e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   4419/156230 | global iter:   4419/156230 | loss: 0.9471 | ds_loss: 0.9621 | lr: 9.9805e-05 | scale: 32768.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   4420/156230 | global iter:   4420/156230 | loss: 0.9641 | ds_loss: 0.9824 | lr: 9.9805e-05 | scale: 32768.0000 | micro time: 1.386 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4420/156230 | global iter:   4420/156230 | loss: 0.9966 | ds_loss: 1.0092 | lr: 9.9805e-05 | scale: 32768.0000 | micro time: 1.386 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4421/156230 | global iter:   4421/156230 | loss: 1.0538 | ds_loss: 1.0680 | lr: 9.9805e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   4422/156230 | global iter:   4422/156230 | loss: 1.1831 | ds_loss: 1.1990 | lr: 9.9805e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   4423/156230 | global iter:   4423/156230 | loss: 0.9832 | ds_loss: 1.0205 | lr: 9.9804e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   4424/156230 | global iter:   4424/156230 | loss: 1.3217 | ds_loss: 1.3146 | lr: 9.9804e-05 | scale: 32768.0000 | micro time: 1.417 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4424/156230 | global iter:   4424/156230 | loss: 1.1354 | ds_loss: 1.1506 | lr: 9.9804e-05 | scale: 32768.0000 | micro time: 1.417 | step time: 1.376
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4425/156230 | global iter:   4425/156230 | loss: 1.2073 | ds_loss: 1.2082 | lr: 9.9804e-05 | scale: 32768.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   4426/156230 | global iter:   4426/156230 | loss: 1.0801 | ds_loss: 1.0873 | lr: 9.9804e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   4427/156230 | global iter:   4427/156230 | loss: 1.1320 | ds_loss: 1.1616 | lr: 9.9804e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   4428/156230 | global iter:   4428/156230 | loss: 1.1430 | ds_loss: 1.1764 | lr: 9.9804e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4428/156230 | global iter:   4428/156230 | loss: 1.1406 | ds_loss: 1.1584 | lr: 9.9804e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 1.345
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4429/156230 | global iter:   4429/156230 | loss: 1.1495 | ds_loss: 1.1668 | lr: 9.9804e-05 | scale: 32768.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   4430/156230 | global iter:   4430/156230 | loss: 0.8663 | ds_loss: 0.8852 | lr: 9.9804e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   4431/156230 | global iter:   4431/156230 | loss: 1.3505 | ds_loss: 1.3639 | lr: 9.9804e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   4432/156230 | global iter:   4432/156230 | loss: 1.0817 | ds_loss: 1.0892 | lr: 9.9804e-05 | scale: 32768.0000 | micro time: 1.328 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4432/156230 | global iter:   4432/156230 | loss: 1.1120 | ds_loss: 1.1263 | lr: 9.9804e-05 | scale: 32768.0000 | micro time: 1.328 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4433/156230 | global iter:   4433/156230 | loss: 1.1968 | ds_loss: 1.2092 | lr: 9.9804e-05 | scale: 32768.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:   4434/156230 | global iter:   4434/156230 | loss: 1.1465 | ds_loss: 1.1481 | lr: 9.9803e-05 | scale: 32768.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   4435/156230 | global iter:   4435/156230 | loss: 0.9451 | ds_loss: 0.9488 | lr: 9.9803e-05 | scale: 32768.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   4436/156230 | global iter:   4436/156230 | loss: 1.2092 | ds_loss: 1.2122 | lr: 9.9803e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4436/156230 | global iter:   4436/156230 | loss: 1.1244 | ds_loss: 1.1296 | lr: 9.9803e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4437/156230 | global iter:   4437/156230 | loss: 0.7764 | ds_loss: 0.7950 | lr: 9.9803e-05 | scale: 32768.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   4438/156230 | global iter:   4438/156230 | loss: 1.2153 | ds_loss: 1.2410 | lr: 9.9803e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   4439/156230 | global iter:   4439/156230 | loss: 1.0901 | ds_loss: 1.0950 | lr: 9.9803e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   4440/156230 | global iter:   4440/156230 | loss: 1.1348 | ds_loss: 1.1711 | lr: 9.9803e-05 | scale: 32768.0000 | micro time: 1.327 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4440/156230 | global iter:   4440/156230 | loss: 1.0542 | ds_loss: 1.0755 | lr: 9.9803e-05 | scale: 32768.0000 | micro time: 1.327 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4441/156230 | global iter:   4441/156230 | loss: 1.0943 | ds_loss: 1.0984 | lr: 9.9803e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   4442/156230 | global iter:   4442/156230 | loss: 1.1623 | ds_loss: 1.1631 | lr: 9.9803e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   4443/156230 | global iter:   4443/156230 | loss: 1.1116 | ds_loss: 1.1367 | lr: 9.9803e-05 | scale: 32768.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   4444/156230 | global iter:   4444/156230 | loss: 0.9892 | ds_loss: 1.0051 | lr: 9.9803e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4444/156230 | global iter:   4444/156230 | loss: 1.0893 | ds_loss: 1.1008 | lr: 9.9803e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4445/156230 | global iter:   4445/156230 | loss: 1.1711 | ds_loss: 1.1877 | lr: 9.9802e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   4446/156230 | global iter:   4446/156230 | loss: 1.1436 | ds_loss: 1.1544 | lr: 9.9802e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   4447/156230 | global iter:   4447/156230 | loss: 1.2033 | ds_loss: 1.2163 | lr: 9.9802e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   4448/156230 | global iter:   4448/156230 | loss: 1.2310 | ds_loss: 1.2250 | lr: 9.9802e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4448/156230 | global iter:   4448/156230 | loss: 1.1873 | ds_loss: 1.1959 | lr: 9.9802e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4449/156230 | global iter:   4449/156230 | loss: 1.1427 | ds_loss: 1.1485 | lr: 9.9802e-05 | scale: 32768.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   4450/156230 | global iter:   4450/156230 | loss: 1.1588 | ds_loss: 1.1645 | lr: 9.9802e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   4451/156230 | global iter:   4451/156230 | loss: 1.1678 | ds_loss: 1.1715 | lr: 9.9802e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   4452/156230 | global iter:   4452/156230 | loss: 1.2128 | ds_loss: 1.2188 | lr: 9.9802e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4452/156230 | global iter:   4452/156230 | loss: 1.1705 | ds_loss: 1.1758 | lr: 9.9802e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 1.376
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4453/156230 | global iter:   4453/156230 | loss: 1.1667 | ds_loss: 1.1758 | lr: 9.9802e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   4454/156230 | global iter:   4454/156230 | loss: 1.1999 | ds_loss: 1.2129 | lr: 9.9802e-05 | scale: 32768.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   4455/156230 | global iter:   4455/156230 | loss: 1.0996 | ds_loss: 1.1238 | lr: 9.9802e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   4456/156230 | global iter:   4456/156230 | loss: 1.2259 | ds_loss: 1.2231 | lr: 9.9801e-05 | scale: 32768.0000 | micro time: 1.405 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4456/156230 | global iter:   4456/156230 | loss: 1.1731 | ds_loss: 1.1839 | lr: 9.9801e-05 | scale: 32768.0000 | micro time: 1.405 | step time: 1.385
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4457/156230 | global iter:   4457/156230 | loss: 1.0629 | ds_loss: 1.0771 | lr: 9.9801e-05 | scale: 32768.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   4458/156230 | global iter:   4458/156230 | loss: 0.9646 | ds_loss: 0.9716 | lr: 9.9801e-05 | scale: 32768.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   4459/156230 | global iter:   4459/156230 | loss: 1.1511 | ds_loss: 1.1631 | lr: 9.9801e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   4460/156230 | global iter:   4460/156230 | loss: 1.0981 | ds_loss: 1.1143 | lr: 9.9801e-05 | scale: 32768.0000 | micro time: 1.325 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4460/156230 | global iter:   4460/156230 | loss: 1.0692 | ds_loss: 1.0815 | lr: 9.9801e-05 | scale: 32768.0000 | micro time: 1.325 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4461/156230 | global iter:   4461/156230 | loss: 1.1279 | ds_loss: 1.1477 | lr: 9.9801e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   4462/156230 | global iter:   4462/156230 | loss: 1.1277 | ds_loss: 1.1458 | lr: 9.9801e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   4463/156230 | global iter:   4463/156230 | loss: 1.0234 | ds_loss: 1.0422 | lr: 9.9801e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   4464/156230 | global iter:   4464/156230 | loss: 1.1307 | ds_loss: 1.1606 | lr: 9.9801e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4464/156230 | global iter:   4464/156230 | loss: 1.1024 | ds_loss: 1.1241 | lr: 9.9801e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4465/156230 | global iter:   4465/156230 | loss: 1.2024 | ds_loss: 1.2066 | lr: 9.9801e-05 | scale: 32768.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   4466/156230 | global iter:   4466/156230 | loss: 1.1203 | ds_loss: 1.1497 | lr: 9.9801e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   4467/156230 | global iter:   4467/156230 | loss: 1.1150 | ds_loss: 1.1513 | lr: 9.9801e-05 | scale: 32768.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   4468/156230 | global iter:   4468/156230 | loss: 1.0168 | ds_loss: 1.0322 | lr: 9.9800e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4468/156230 | global iter:   4468/156230 | loss: 1.1136 | ds_loss: 1.1349 | lr: 9.9800e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4469/156230 | global iter:   4469/156230 | loss: 1.0122 | ds_loss: 1.0436 | lr: 9.9800e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   4470/156230 | global iter:   4470/156230 | loss: 1.1939 | ds_loss: 1.2107 | lr: 9.9800e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   4471/156230 | global iter:   4471/156230 | loss: 1.0802 | ds_loss: 1.1012 | lr: 9.9800e-05 | scale: 32768.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   4472/156230 | global iter:   4472/156230 | loss: 1.2595 | ds_loss: 1.2721 | lr: 9.9800e-05 | scale: 32768.0000 | micro time: 1.344 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4472/156230 | global iter:   4472/156230 | loss: 1.1364 | ds_loss: 1.1569 | lr: 9.9800e-05 | scale: 32768.0000 | micro time: 1.344 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4473/156230 | global iter:   4473/156230 | loss: 1.1135 | ds_loss: 1.1329 | lr: 9.9800e-05 | scale: 32768.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   4474/156230 | global iter:   4474/156230 | loss: 1.1606 | ds_loss: 1.1624 | lr: 9.9800e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   4475/156230 | global iter:   4475/156230 | loss: 1.0669 | ds_loss: 1.1031 | lr: 9.9800e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   4476/156230 | global iter:   4476/156230 | loss: 1.3110 | ds_loss: 1.3262 | lr: 9.9800e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4476/156230 | global iter:   4476/156230 | loss: 1.1630 | ds_loss: 1.1812 | lr: 9.9800e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4477/156230 | global iter:   4477/156230 | loss: 1.1009 | ds_loss: 1.1334 | lr: 9.9800e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   4478/156230 | global iter:   4478/156230 | loss: 1.0523 | ds_loss: 1.0617 | lr: 9.9800e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   4479/156230 | global iter:   4479/156230 | loss: 0.9938 | ds_loss: 1.0173 | lr: 9.9799e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   4480/156230 | global iter:   4480/156230 | loss: 1.1133 | ds_loss: 1.1240 | lr: 9.9799e-05 | scale: 32768.0000 | micro time: 1.324 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4480/156230 | global iter:   4480/156230 | loss: 1.0651 | ds_loss: 1.0841 | lr: 9.9799e-05 | scale: 32768.0000 | micro time: 1.324 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4481/156230 | global iter:   4481/156230 | loss: 1.1673 | ds_loss: 1.1751 | lr: 9.9799e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   4482/156230 | global iter:   4482/156230 | loss: 1.1148 | ds_loss: 1.1382 | lr: 9.9799e-05 | scale: 32768.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:   4483/156230 | global iter:   4483/156230 | loss: 0.8606 | ds_loss: 0.8746 | lr: 9.9799e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   4484/156230 | global iter:   4484/156230 | loss: 0.9225 | ds_loss: 0.9458 | lr: 9.9799e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4484/156230 | global iter:   4484/156230 | loss: 1.0163 | ds_loss: 1.0334 | lr: 9.9799e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4485/156230 | global iter:   4485/156230 | loss: 1.1672 | ds_loss: 1.1653 | lr: 9.9799e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   4486/156230 | global iter:   4486/156230 | loss: 1.2699 | ds_loss: 1.2668 | lr: 9.9799e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   4487/156230 | global iter:   4487/156230 | loss: 1.1427 | ds_loss: 1.1508 | lr: 9.9799e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   4488/156230 | global iter:   4488/156230 | loss: 1.1512 | ds_loss: 1.1579 | lr: 9.9799e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4488/156230 | global iter:   4488/156230 | loss: 1.1827 | ds_loss: 1.1852 | lr: 9.9799e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4489/156230 | global iter:   4489/156230 | loss: 1.0590 | ds_loss: 1.0624 | lr: 9.9799e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   4490/156230 | global iter:   4490/156230 | loss: 1.0429 | ds_loss: 1.0544 | lr: 9.9798e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   4491/156230 | global iter:   4491/156230 | loss: 1.2425 | ds_loss: 1.2584 | lr: 9.9798e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   4492/156230 | global iter:   4492/156230 | loss: 1.1240 | ds_loss: 1.1278 | lr: 9.9798e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4492/156230 | global iter:   4492/156230 | loss: 1.1171 | ds_loss: 1.1258 | lr: 9.9798e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4493/156230 | global iter:   4493/156230 | loss: 1.0937 | ds_loss: 1.1073 | lr: 9.9798e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   4494/156230 | global iter:   4494/156230 | loss: 1.0949 | ds_loss: 1.1029 | lr: 9.9798e-05 | scale: 32768.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   4495/156230 | global iter:   4495/156230 | loss: 1.2199 | ds_loss: 1.2462 | lr: 9.9798e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   4496/156230 | global iter:   4496/156230 | loss: 1.1568 | ds_loss: 1.1665 | lr: 9.9798e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4496/156230 | global iter:   4496/156230 | loss: 1.1413 | ds_loss: 1.1557 | lr: 9.9798e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4497/156230 | global iter:   4497/156230 | loss: 1.1250 | ds_loss: 1.1499 | lr: 9.9798e-05 | scale: 32768.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   4498/156230 | global iter:   4498/156230 | loss: 1.0523 | ds_loss: 1.0829 | lr: 9.9798e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   4499/156230 | global iter:   4499/156230 | loss: 1.0545 | ds_loss: 1.0614 | lr: 9.9798e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   4500/156230 | global iter:   4500/156230 | loss: 1.2709 | ds_loss: 1.2865 | lr: 9.9798e-05 | scale: 32768.0000 | micro time: 1.418 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4500/156230 | global iter:   4500/156230 | loss: 1.1257 | ds_loss: 1.1452 | lr: 9.9798e-05 | scale: 32768.0000 | micro time: 1.418 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4501/156230 | global iter:   4501/156230 | loss: 1.1365 | ds_loss: 1.1721 | lr: 9.9797e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   4502/156230 | global iter:   4502/156230 | loss: 1.0029 | ds_loss: 1.0400 | lr: 9.9797e-05 | scale: 32768.0000 | micro time: 1.411 | step time: 0.000
train | epoch   0 | Iter:   4503/156230 | global iter:   4503/156230 | loss: 1.0262 | ds_loss: 1.0277 | lr: 9.9797e-05 | scale: 32768.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   4504/156230 | global iter:   4504/156230 | loss: 1.1719 | ds_loss: 1.1838 | lr: 9.9797e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4504/156230 | global iter:   4504/156230 | loss: 1.0844 | ds_loss: 1.1059 | lr: 9.9797e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4505/156230 | global iter:   4505/156230 | loss: 1.0363 | ds_loss: 1.0499 | lr: 9.9797e-05 | scale: 32768.0000 | micro time: 1.325 | step time: 0.000
train | epoch   0 | Iter:   4506/156230 | global iter:   4506/156230 | loss: 1.1909 | ds_loss: 1.2155 | lr: 9.9797e-05 | scale: 32768.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:   4507/156230 | global iter:   4507/156230 | loss: 1.1761 | ds_loss: 1.2031 | lr: 9.9797e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   4508/156230 | global iter:   4508/156230 | loss: 1.0432 | ds_loss: 1.0756 | lr: 9.9797e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4508/156230 | global iter:   4508/156230 | loss: 1.1116 | ds_loss: 1.1360 | lr: 9.9797e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4509/156230 | global iter:   4509/156230 | loss: 1.1597 | ds_loss: 1.1755 | lr: 9.9797e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   4510/156230 | global iter:   4510/156230 | loss: 1.2306 | ds_loss: 1.2363 | lr: 9.9797e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   4511/156230 | global iter:   4511/156230 | loss: 1.1863 | ds_loss: 1.1792 | lr: 9.9797e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   4512/156230 | global iter:   4512/156230 | loss: 1.0793 | ds_loss: 1.1069 | lr: 9.9796e-05 | scale: 32768.0000 | micro time: 1.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4512/156230 | global iter:   4512/156230 | loss: 1.1640 | ds_loss: 1.1745 | lr: 9.9796e-05 | scale: 32768.0000 | micro time: 1.399 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4513/156230 | global iter:   4513/156230 | loss: 1.1403 | ds_loss: 1.1334 | lr: 9.9796e-05 | scale: 32768.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   4514/156230 | global iter:   4514/156230 | loss: 1.3790 | ds_loss: 1.4005 | lr: 9.9796e-05 | scale: 32768.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   4515/156230 | global iter:   4515/156230 | loss: 0.8745 | ds_loss: 0.8891 | lr: 9.9796e-05 | scale: 32768.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   4516/156230 | global iter:   4516/156230 | loss: 1.2285 | ds_loss: 1.2439 | lr: 9.9796e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4516/156230 | global iter:   4516/156230 | loss: 1.1556 | ds_loss: 1.1667 | lr: 9.9796e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4517/156230 | global iter:   4517/156230 | loss: 1.1654 | ds_loss: 1.1837 | lr: 9.9796e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   4518/156230 | global iter:   4518/156230 | loss: 0.9897 | ds_loss: 0.9897 | lr: 9.9796e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   4519/156230 | global iter:   4519/156230 | loss: 1.0319 | ds_loss: 1.0496 | lr: 9.9796e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   4520/156230 | global iter:   4520/156230 | loss: 1.0920 | ds_loss: 1.0933 | lr: 9.9796e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4520/156230 | global iter:   4520/156230 | loss: 1.0697 | ds_loss: 1.0791 | lr: 9.9796e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4521/156230 | global iter:   4521/156230 | loss: 1.0557 | ds_loss: 1.0705 | lr: 9.9796e-05 | scale: 32768.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   4522/156230 | global iter:   4522/156230 | loss: 1.0045 | ds_loss: 1.0251 | lr: 9.9796e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   4523/156230 | global iter:   4523/156230 | loss: 1.2501 | ds_loss: 1.2753 | lr: 9.9795e-05 | scale: 32768.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   4524/156230 | global iter:   4524/156230 | loss: 1.1919 | ds_loss: 1.1956 | lr: 9.9795e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4524/156230 | global iter:   4524/156230 | loss: 1.1256 | ds_loss: 1.1416 | lr: 9.9795e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4525/156230 | global iter:   4525/156230 | loss: 1.1331 | ds_loss: 1.1393 | lr: 9.9795e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   4526/156230 | global iter:   4526/156230 | loss: 1.0856 | ds_loss: 1.0790 | lr: 9.9795e-05 | scale: 32768.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   4527/156230 | global iter:   4527/156230 | loss: 1.0505 | ds_loss: 1.0600 | lr: 9.9795e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   4528/156230 | global iter:   4528/156230 | loss: 1.2422 | ds_loss: 1.2536 | lr: 9.9795e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4528/156230 | global iter:   4528/156230 | loss: 1.1279 | ds_loss: 1.1330 | lr: 9.9795e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4529/156230 | global iter:   4529/156230 | loss: 1.1502 | ds_loss: 1.1600 | lr: 9.9795e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   4530/156230 | global iter:   4530/156230 | loss: 0.9622 | ds_loss: 0.9730 | lr: 9.9795e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   4531/156230 | global iter:   4531/156230 | loss: 1.0522 | ds_loss: 1.0639 | lr: 9.9795e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   4532/156230 | global iter:   4532/156230 | loss: 1.1288 | ds_loss: 1.1398 | lr: 9.9795e-05 | scale: 32768.0000 | micro time: 1.334 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4532/156230 | global iter:   4532/156230 | loss: 1.0733 | ds_loss: 1.0842 | lr: 9.9795e-05 | scale: 32768.0000 | micro time: 1.334 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4533/156230 | global iter:   4533/156230 | loss: 0.9987 | ds_loss: 1.0330 | lr: 9.9795e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   4534/156230 | global iter:   4534/156230 | loss: 1.1426 | ds_loss: 1.1568 | lr: 9.9794e-05 | scale: 32768.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   4535/156230 | global iter:   4535/156230 | loss: 0.9306 | ds_loss: 0.9387 | lr: 9.9794e-05 | scale: 32768.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   4536/156230 | global iter:   4536/156230 | loss: 0.9838 | ds_loss: 0.9895 | lr: 9.9794e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4536/156230 | global iter:   4536/156230 | loss: 1.0139 | ds_loss: 1.0295 | lr: 9.9794e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4537/156230 | global iter:   4537/156230 | loss: 1.1331 | ds_loss: 1.1380 | lr: 9.9794e-05 | scale: 32768.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   4538/156230 | global iter:   4538/156230 | loss: 1.0937 | ds_loss: 1.0978 | lr: 9.9794e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   4539/156230 | global iter:   4539/156230 | loss: 1.1278 | ds_loss: 1.1240 | lr: 9.9794e-05 | scale: 32768.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   4540/156230 | global iter:   4540/156230 | loss: 1.0371 | ds_loss: 1.0552 | lr: 9.9794e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4540/156230 | global iter:   4540/156230 | loss: 1.0979 | ds_loss: 1.1037 | lr: 9.9794e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4541/156230 | global iter:   4541/156230 | loss: 1.1360 | ds_loss: 1.1495 | lr: 9.9794e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   4542/156230 | global iter:   4542/156230 | loss: 1.2371 | ds_loss: 1.2383 | lr: 9.9794e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   4543/156230 | global iter:   4543/156230 | loss: 1.0146 | ds_loss: 1.0435 | lr: 9.9794e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   4544/156230 | global iter:   4544/156230 | loss: 1.1358 | ds_loss: 1.1455 | lr: 9.9794e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4544/156230 | global iter:   4544/156230 | loss: 1.1309 | ds_loss: 1.1442 | lr: 9.9794e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4545/156230 | global iter:   4545/156230 | loss: 1.1914 | ds_loss: 1.2136 | lr: 9.9793e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   4546/156230 | global iter:   4546/156230 | loss: 0.8764 | ds_loss: 0.8973 | lr: 9.9793e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   4547/156230 | global iter:   4547/156230 | loss: 1.0497 | ds_loss: 1.0782 | lr: 9.9793e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   4548/156230 | global iter:   4548/156230 | loss: 1.2585 | ds_loss: 1.2785 | lr: 9.9793e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4548/156230 | global iter:   4548/156230 | loss: 1.0940 | ds_loss: 1.1169 | lr: 9.9793e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4549/156230 | global iter:   4549/156230 | loss: 1.0711 | ds_loss: 1.1001 | lr: 9.9793e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   4550/156230 | global iter:   4550/156230 | loss: 1.0647 | ds_loss: 1.0851 | lr: 9.9793e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   4551/156230 | global iter:   4551/156230 | loss: 0.8738 | ds_loss: 0.8836 | lr: 9.9793e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   4552/156230 | global iter:   4552/156230 | loss: 1.3042 | ds_loss: 1.3343 | lr: 9.9793e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4552/156230 | global iter:   4552/156230 | loss: 1.0785 | ds_loss: 1.1008 | lr: 9.9793e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4553/156230 | global iter:   4553/156230 | loss: 1.1266 | ds_loss: 1.1316 | lr: 9.9793e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   4554/156230 | global iter:   4554/156230 | loss: 1.2128 | ds_loss: 1.2180 | lr: 9.9793e-05 | scale: 32768.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   4555/156230 | global iter:   4555/156230 | loss: 0.9205 | ds_loss: 0.9393 | lr: 9.9793e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   4556/156230 | global iter:   4556/156230 | loss: 1.2218 | ds_loss: 1.2221 | lr: 9.9792e-05 | scale: 32768.0000 | micro time: 1.323 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4556/156230 | global iter:   4556/156230 | loss: 1.1204 | ds_loss: 1.1278 | lr: 9.9792e-05 | scale: 32768.0000 | micro time: 1.323 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4557/156230 | global iter:   4557/156230 | loss: 1.1603 | ds_loss: 1.1597 | lr: 9.9792e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   4558/156230 | global iter:   4558/156230 | loss: 1.2269 | ds_loss: 1.2534 | lr: 9.9792e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   4559/156230 | global iter:   4559/156230 | loss: 1.0604 | ds_loss: 1.0889 | lr: 9.9792e-05 | scale: 32768.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   4560/156230 | global iter:   4560/156230 | loss: 1.0805 | ds_loss: 1.0931 | lr: 9.9792e-05 | scale: 32768.0000 | micro time: 1.334 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4560/156230 | global iter:   4560/156230 | loss: 1.1320 | ds_loss: 1.1488 | lr: 9.9792e-05 | scale: 32768.0000 | micro time: 1.334 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4561/156230 | global iter:   4561/156230 | loss: 1.0633 | ds_loss: 1.0803 | lr: 9.9792e-05 | scale: 32768.0000 | micro time: 1.312 | step time: 0.000
train | epoch   0 | Iter:   4562/156230 | global iter:   4562/156230 | loss: 1.1112 | ds_loss: 1.1352 | lr: 9.9792e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   4563/156230 | global iter:   4563/156230 | loss: 1.0883 | ds_loss: 1.0911 | lr: 9.9792e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   4564/156230 | global iter:   4564/156230 | loss: 1.1704 | ds_loss: 1.1816 | lr: 9.9792e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4564/156230 | global iter:   4564/156230 | loss: 1.1083 | ds_loss: 1.1221 | lr: 9.9792e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4565/156230 | global iter:   4565/156230 | loss: 1.0183 | ds_loss: 1.0374 | lr: 9.9792e-05 | scale: 32768.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   4566/156230 | global iter:   4566/156230 | loss: 1.0210 | ds_loss: 1.0544 | lr: 9.9792e-05 | scale: 32768.0000 | micro time: 1.321 | step time: 0.000
train | epoch   0 | Iter:   4567/156230 | global iter:   4567/156230 | loss: 1.0201 | ds_loss: 1.0491 | lr: 9.9791e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   4568/156230 | global iter:   4568/156230 | loss: 1.2686 | ds_loss: 1.2752 | lr: 9.9791e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4568/156230 | global iter:   4568/156230 | loss: 1.0820 | ds_loss: 1.1040 | lr: 9.9791e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4569/156230 | global iter:   4569/156230 | loss: 1.0936 | ds_loss: 1.0998 | lr: 9.9791e-05 | scale: 32768.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   4570/156230 | global iter:   4570/156230 | loss: 1.0482 | ds_loss: 1.0655 | lr: 9.9791e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   4571/156230 | global iter:   4571/156230 | loss: 1.2356 | ds_loss: 1.2357 | lr: 9.9791e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   4572/156230 | global iter:   4572/156230 | loss: 1.1387 | ds_loss: 1.1529 | lr: 9.9791e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4572/156230 | global iter:   4572/156230 | loss: 1.1290 | ds_loss: 1.1385 | lr: 9.9791e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 1.380
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4573/156230 | global iter:   4573/156230 | loss: 1.1808 | ds_loss: 1.1817 | lr: 9.9791e-05 | scale: 32768.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   4574/156230 | global iter:   4574/156230 | loss: 0.9634 | ds_loss: 0.9732 | lr: 9.9791e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   4575/156230 | global iter:   4575/156230 | loss: 1.1204 | ds_loss: 1.1231 | lr: 9.9791e-05 | scale: 32768.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   4576/156230 | global iter:   4576/156230 | loss: 1.1369 | ds_loss: 1.1411 | lr: 9.9791e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4576/156230 | global iter:   4576/156230 | loss: 1.1004 | ds_loss: 1.1048 | lr: 9.9791e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 1.381
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4577/156230 | global iter:   4577/156230 | loss: 1.1671 | ds_loss: 1.1606 | lr: 9.9791e-05 | scale: 32768.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   4578/156230 | global iter:   4578/156230 | loss: 1.0345 | ds_loss: 1.0540 | lr: 9.9790e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   4579/156230 | global iter:   4579/156230 | loss: 1.1568 | ds_loss: 1.1693 | lr: 9.9790e-05 | scale: 32768.0000 | micro time: 1.310 | step time: 0.000
train | epoch   0 | Iter:   4580/156230 | global iter:   4580/156230 | loss: 1.1606 | ds_loss: 1.1817 | lr: 9.9790e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4580/156230 | global iter:   4580/156230 | loss: 1.1297 | ds_loss: 1.1414 | lr: 9.9790e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4581/156230 | global iter:   4581/156230 | loss: 1.2013 | ds_loss: 1.2197 | lr: 9.9790e-05 | scale: 32768.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   4582/156230 | global iter:   4582/156230 | loss: 1.1612 | ds_loss: 1.1866 | lr: 9.9790e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   4583/156230 | global iter:   4583/156230 | loss: 1.1205 | ds_loss: 1.1389 | lr: 9.9790e-05 | scale: 32768.0000 | micro time: 1.401 | step time: 0.000
train | epoch   0 | Iter:   4584/156230 | global iter:   4584/156230 | loss: 1.0705 | ds_loss: 1.0884 | lr: 9.9790e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4584/156230 | global iter:   4584/156230 | loss: 1.1384 | ds_loss: 1.1584 | lr: 9.9790e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4585/156230 | global iter:   4585/156230 | loss: 1.1292 | ds_loss: 1.1373 | lr: 9.9790e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   4586/156230 | global iter:   4586/156230 | loss: 1.2319 | ds_loss: 1.2316 | lr: 9.9790e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   4587/156230 | global iter:   4587/156230 | loss: 1.2835 | ds_loss: 1.2778 | lr: 9.9790e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   4588/156230 | global iter:   4588/156230 | loss: 0.8785 | ds_loss: 0.8978 | lr: 9.9790e-05 | scale: 32768.0000 | micro time: 1.332 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4588/156230 | global iter:   4588/156230 | loss: 1.1308 | ds_loss: 1.1361 | lr: 9.9790e-05 | scale: 32768.0000 | micro time: 1.332 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4589/156230 | global iter:   4589/156230 | loss: 1.1713 | ds_loss: 1.1670 | lr: 9.9789e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   4590/156230 | global iter:   4590/156230 | loss: 1.2520 | ds_loss: 1.2638 | lr: 9.9789e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   4591/156230 | global iter:   4591/156230 | loss: 1.1483 | ds_loss: 1.1418 | lr: 9.9789e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   4592/156230 | global iter:   4592/156230 | loss: 1.2966 | ds_loss: 1.3016 | lr: 9.9789e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4592/156230 | global iter:   4592/156230 | loss: 1.2170 | ds_loss: 1.2186 | lr: 9.9789e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4593/156230 | global iter:   4593/156230 | loss: 1.2365 | ds_loss: 1.2447 | lr: 9.9789e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   4594/156230 | global iter:   4594/156230 | loss: 1.1910 | ds_loss: 1.2124 | lr: 9.9789e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   4595/156230 | global iter:   4595/156230 | loss: 0.9333 | ds_loss: 0.9540 | lr: 9.9789e-05 | scale: 32768.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   4596/156230 | global iter:   4596/156230 | loss: 1.2453 | ds_loss: 1.2577 | lr: 9.9789e-05 | scale: 32768.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4596/156230 | global iter:   4596/156230 | loss: 1.1515 | ds_loss: 1.1672 | lr: 9.9789e-05 | scale: 32768.0000 | micro time: 1.385 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4597/156230 | global iter:   4597/156230 | loss: 1.0975 | ds_loss: 1.1034 | lr: 9.9789e-05 | scale: 32768.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   4598/156230 | global iter:   4598/156230 | loss: 1.1961 | ds_loss: 1.2073 | lr: 9.9789e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   4599/156230 | global iter:   4599/156230 | loss: 1.1348 | ds_loss: 1.1599 | lr: 9.9788e-05 | scale: 32768.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   4600/156230 | global iter:   4600/156230 | loss: 1.0599 | ds_loss: 1.0717 | lr: 9.9788e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4600/156230 | global iter:   4600/156230 | loss: 1.1221 | ds_loss: 1.1356 | lr: 9.9788e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 1.346
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4601/156230 | global iter:   4601/156230 | loss: 1.0489 | ds_loss: 1.0744 | lr: 9.9788e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   4602/156230 | global iter:   4602/156230 | loss: 1.1156 | ds_loss: 1.1362 | lr: 9.9788e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   4603/156230 | global iter:   4603/156230 | loss: 1.0987 | ds_loss: 1.1052 | lr: 9.9788e-05 | scale: 32768.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   4604/156230 | global iter:   4604/156230 | loss: 1.2729 | ds_loss: 1.2850 | lr: 9.9788e-05 | scale: 32768.0000 | micro time: 1.413 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4604/156230 | global iter:   4604/156230 | loss: 1.1340 | ds_loss: 1.1502 | lr: 9.9788e-05 | scale: 32768.0000 | micro time: 1.413 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4605/156230 | global iter:   4605/156230 | loss: 1.1908 | ds_loss: 1.2050 | lr: 9.9788e-05 | scale: 32768.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   4606/156230 | global iter:   4606/156230 | loss: 1.1199 | ds_loss: 1.1247 | lr: 9.9788e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   4607/156230 | global iter:   4607/156230 | loss: 1.1583 | ds_loss: 1.1641 | lr: 9.9788e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   4608/156230 | global iter:   4608/156230 | loss: 1.3014 | ds_loss: 1.3149 | lr: 9.9788e-05 | scale: 32768.0000 | micro time: 1.322 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4608/156230 | global iter:   4608/156230 | loss: 1.1926 | ds_loss: 1.2022 | lr: 9.9788e-05 | scale: 32768.0000 | micro time: 1.322 | step time: 1.338
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4609/156230 | global iter:   4609/156230 | loss: 1.0336 | ds_loss: 1.0586 | lr: 9.9788e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   4610/156230 | global iter:   4610/156230 | loss: 0.9804 | ds_loss: 0.9967 | lr: 9.9787e-05 | scale: 32768.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   4611/156230 | global iter:   4611/156230 | loss: 1.0606 | ds_loss: 1.0703 | lr: 9.9787e-05 | scale: 32768.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   4612/156230 | global iter:   4612/156230 | loss: 1.0525 | ds_loss: 1.0795 | lr: 9.9787e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4612/156230 | global iter:   4612/156230 | loss: 1.0318 | ds_loss: 1.0513 | lr: 9.9787e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4613/156230 | global iter:   4613/156230 | loss: 1.1356 | ds_loss: 1.1463 | lr: 9.9787e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   4614/156230 | global iter:   4614/156230 | loss: 1.0787 | ds_loss: 1.0979 | lr: 9.9787e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   4615/156230 | global iter:   4615/156230 | loss: 1.1437 | ds_loss: 1.1497 | lr: 9.9787e-05 | scale: 32768.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   4616/156230 | global iter:   4616/156230 | loss: 1.0428 | ds_loss: 1.0560 | lr: 9.9787e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4616/156230 | global iter:   4616/156230 | loss: 1.1002 | ds_loss: 1.1125 | lr: 9.9787e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4617/156230 | global iter:   4617/156230 | loss: 1.0738 | ds_loss: 1.0954 | lr: 9.9787e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   4618/156230 | global iter:   4618/156230 | loss: 1.0890 | ds_loss: 1.1024 | lr: 9.9787e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   4619/156230 | global iter:   4619/156230 | loss: 1.0630 | ds_loss: 1.0800 | lr: 9.9787e-05 | scale: 32768.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   4620/156230 | global iter:   4620/156230 | loss: 0.9919 | ds_loss: 1.0107 | lr: 9.9787e-05 | scale: 32768.0000 | micro time: 1.391 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4620/156230 | global iter:   4620/156230 | loss: 1.0544 | ds_loss: 1.0721 | lr: 9.9787e-05 | scale: 32768.0000 | micro time: 1.391 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4621/156230 | global iter:   4621/156230 | loss: 1.2284 | ds_loss: 1.2455 | lr: 9.9786e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   4622/156230 | global iter:   4622/156230 | loss: 1.0458 | ds_loss: 1.0489 | lr: 9.9786e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   4623/156230 | global iter:   4623/156230 | loss: 0.9480 | ds_loss: 0.9539 | lr: 9.9786e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   4624/156230 | global iter:   4624/156230 | loss: 0.9883 | ds_loss: 1.0147 | lr: 9.9786e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4624/156230 | global iter:   4624/156230 | loss: 1.0526 | ds_loss: 1.0657 | lr: 9.9786e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4625/156230 | global iter:   4625/156230 | loss: 1.0717 | ds_loss: 1.0954 | lr: 9.9786e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   4626/156230 | global iter:   4626/156230 | loss: 1.1579 | ds_loss: 1.1893 | lr: 9.9786e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   4627/156230 | global iter:   4627/156230 | loss: 1.2070 | ds_loss: 1.2213 | lr: 9.9786e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   4628/156230 | global iter:   4628/156230 | loss: 1.0612 | ds_loss: 1.0852 | lr: 9.9786e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4628/156230 | global iter:   4628/156230 | loss: 1.1245 | ds_loss: 1.1478 | lr: 9.9786e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4629/156230 | global iter:   4629/156230 | loss: 1.1935 | ds_loss: 1.2128 | lr: 9.9786e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   4630/156230 | global iter:   4630/156230 | loss: 1.2241 | ds_loss: 1.2351 | lr: 9.9786e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   4631/156230 | global iter:   4631/156230 | loss: 1.2392 | ds_loss: 1.2501 | lr: 9.9786e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   4632/156230 | global iter:   4632/156230 | loss: 1.0603 | ds_loss: 1.0736 | lr: 9.9785e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4632/156230 | global iter:   4632/156230 | loss: 1.1793 | ds_loss: 1.1929 | lr: 9.9785e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4633/156230 | global iter:   4633/156230 | loss: 1.1988 | ds_loss: 1.1972 | lr: 9.9785e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   4634/156230 | global iter:   4634/156230 | loss: 1.0729 | ds_loss: 1.0824 | lr: 9.9785e-05 | scale: 32768.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   4635/156230 | global iter:   4635/156230 | loss: 1.1598 | ds_loss: 1.1721 | lr: 9.9785e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   4636/156230 | global iter:   4636/156230 | loss: 1.0169 | ds_loss: 1.0380 | lr: 9.9785e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4636/156230 | global iter:   4636/156230 | loss: 1.1121 | ds_loss: 1.1224 | lr: 9.9785e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4637/156230 | global iter:   4637/156230 | loss: 1.2247 | ds_loss: 1.2283 | lr: 9.9785e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   4638/156230 | global iter:   4638/156230 | loss: 1.2063 | ds_loss: 1.2122 | lr: 9.9785e-05 | scale: 32768.0000 | micro time: 1.413 | step time: 0.000
train | epoch   0 | Iter:   4639/156230 | global iter:   4639/156230 | loss: 1.1867 | ds_loss: 1.1938 | lr: 9.9785e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   4640/156230 | global iter:   4640/156230 | loss: 1.0034 | ds_loss: 1.0207 | lr: 9.9785e-05 | scale: 32768.0000 | micro time: 1.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4640/156230 | global iter:   4640/156230 | loss: 1.1553 | ds_loss: 1.1637 | lr: 9.9785e-05 | scale: 32768.0000 | micro time: 1.396 | step time: 1.379
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4641/156230 | global iter:   4641/156230 | loss: 1.2266 | ds_loss: 1.2545 | lr: 9.9785e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   4642/156230 | global iter:   4642/156230 | loss: 1.2696 | ds_loss: 1.2733 | lr: 9.9785e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   4643/156230 | global iter:   4643/156230 | loss: 1.2486 | ds_loss: 1.2636 | lr: 9.9784e-05 | scale: 32768.0000 | micro time: 1.401 | step time: 0.000
train | epoch   0 | Iter:   4644/156230 | global iter:   4644/156230 | loss: 1.0816 | ds_loss: 1.1049 | lr: 9.9784e-05 | scale: 32768.0000 | micro time: 1.324 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4644/156230 | global iter:   4644/156230 | loss: 1.2066 | ds_loss: 1.2241 | lr: 9.9784e-05 | scale: 32768.0000 | micro time: 1.324 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4645/156230 | global iter:   4645/156230 | loss: 1.1420 | ds_loss: 1.1870 | lr: 9.9784e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   4646/156230 | global iter:   4646/156230 | loss: 1.0640 | ds_loss: 1.0657 | lr: 9.9784e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   4647/156230 | global iter:   4647/156230 | loss: 1.1088 | ds_loss: 1.1186 | lr: 9.9784e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   4648/156230 | global iter:   4648/156230 | loss: 1.0967 | ds_loss: 1.1238 | lr: 9.9784e-05 | scale: 32768.0000 | micro time: 1.331 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4648/156230 | global iter:   4648/156230 | loss: 1.1029 | ds_loss: 1.1238 | lr: 9.9784e-05 | scale: 32768.0000 | micro time: 1.331 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4649/156230 | global iter:   4649/156230 | loss: 1.2610 | ds_loss: 1.2508 | lr: 9.9784e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   4650/156230 | global iter:   4650/156230 | loss: 0.9731 | ds_loss: 0.9798 | lr: 9.9784e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   4651/156230 | global iter:   4651/156230 | loss: 1.0316 | ds_loss: 1.0450 | lr: 9.9784e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   4652/156230 | global iter:   4652/156230 | loss: 1.2210 | ds_loss: 1.2408 | lr: 9.9784e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4652/156230 | global iter:   4652/156230 | loss: 1.1217 | ds_loss: 1.1291 | lr: 9.9784e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4653/156230 | global iter:   4653/156230 | loss: 1.2510 | ds_loss: 1.2821 | lr: 9.9783e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   4654/156230 | global iter:   4654/156230 | loss: 1.0862 | ds_loss: 1.0905 | lr: 9.9783e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   4655/156230 | global iter:   4655/156230 | loss: 1.0750 | ds_loss: 1.0835 | lr: 9.9783e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   4656/156230 | global iter:   4656/156230 | loss: 1.0604 | ds_loss: 1.0561 | lr: 9.9783e-05 | scale: 32768.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4656/156230 | global iter:   4656/156230 | loss: 1.1181 | ds_loss: 1.1281 | lr: 9.9783e-05 | scale: 32768.0000 | micro time: 1.385 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4657/156230 | global iter:   4657/156230 | loss: 1.1545 | ds_loss: 1.1672 | lr: 9.9783e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   4658/156230 | global iter:   4658/156230 | loss: 0.9738 | ds_loss: 0.9799 | lr: 9.9783e-05 | scale: 32768.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   4659/156230 | global iter:   4659/156230 | loss: 1.0324 | ds_loss: 1.0408 | lr: 9.9783e-05 | scale: 32768.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   4660/156230 | global iter:   4660/156230 | loss: 1.2812 | ds_loss: 1.3080 | lr: 9.9783e-05 | scale: 32768.0000 | micro time: 1.333 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4660/156230 | global iter:   4660/156230 | loss: 1.1105 | ds_loss: 1.1240 | lr: 9.9783e-05 | scale: 32768.0000 | micro time: 1.333 | step time: 1.348
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4661/156230 | global iter:   4661/156230 | loss: 1.1576 | ds_loss: 1.1690 | lr: 9.9783e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   4662/156230 | global iter:   4662/156230 | loss: 1.1029 | ds_loss: 1.1096 | lr: 9.9783e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   4663/156230 | global iter:   4663/156230 | loss: 1.0642 | ds_loss: 1.0857 | lr: 9.9783e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   4664/156230 | global iter:   4664/156230 | loss: 1.0036 | ds_loss: 1.0197 | lr: 9.9782e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4664/156230 | global iter:   4664/156230 | loss: 1.0821 | ds_loss: 1.0960 | lr: 9.9782e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4665/156230 | global iter:   4665/156230 | loss: 1.1717 | ds_loss: 1.1931 | lr: 9.9782e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   4666/156230 | global iter:   4666/156230 | loss: 1.0453 | ds_loss: 1.0502 | lr: 9.9782e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   4667/156230 | global iter:   4667/156230 | loss: 1.1041 | ds_loss: 1.1298 | lr: 9.9782e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   4668/156230 | global iter:   4668/156230 | loss: 1.1500 | ds_loss: 1.1636 | lr: 9.9782e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4668/156230 | global iter:   4668/156230 | loss: 1.1178 | ds_loss: 1.1342 | lr: 9.9782e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4669/156230 | global iter:   4669/156230 | loss: 1.0203 | ds_loss: 1.0391 | lr: 9.9782e-05 | scale: 32768.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   4670/156230 | global iter:   4670/156230 | loss: 1.1522 | ds_loss: 1.1615 | lr: 9.9782e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   4671/156230 | global iter:   4671/156230 | loss: 1.1918 | ds_loss: 1.2049 | lr: 9.9782e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   4672/156230 | global iter:   4672/156230 | loss: 1.2123 | ds_loss: 1.2386 | lr: 9.9782e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4672/156230 | global iter:   4672/156230 | loss: 1.1441 | ds_loss: 1.1610 | lr: 9.9782e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4673/156230 | global iter:   4673/156230 | loss: 1.1246 | ds_loss: 1.1290 | lr: 9.9782e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   4674/156230 | global iter:   4674/156230 | loss: 0.9981 | ds_loss: 1.0144 | lr: 9.9782e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   4675/156230 | global iter:   4675/156230 | loss: 1.2415 | ds_loss: 1.2349 | lr: 9.9781e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   4676/156230 | global iter:   4676/156230 | loss: 1.1388 | ds_loss: 1.1549 | lr: 9.9781e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4676/156230 | global iter:   4676/156230 | loss: 1.1258 | ds_loss: 1.1333 | lr: 9.9781e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4677/156230 | global iter:   4677/156230 | loss: 1.1270 | ds_loss: 1.1496 | lr: 9.9781e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   4678/156230 | global iter:   4678/156230 | loss: 1.0438 | ds_loss: 1.0586 | lr: 9.9781e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   4679/156230 | global iter:   4679/156230 | loss: 0.8689 | ds_loss: 0.8733 | lr: 9.9781e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   4680/156230 | global iter:   4680/156230 | loss: 1.0533 | ds_loss: 1.0510 | lr: 9.9781e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4680/156230 | global iter:   4680/156230 | loss: 1.0232 | ds_loss: 1.0331 | lr: 9.9781e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4681/156230 | global iter:   4681/156230 | loss: 1.1036 | ds_loss: 1.1044 | lr: 9.9781e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   4682/156230 | global iter:   4682/156230 | loss: 1.2046 | ds_loss: 1.2107 | lr: 9.9781e-05 | scale: 32768.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   4683/156230 | global iter:   4683/156230 | loss: 1.0957 | ds_loss: 1.1135 | lr: 9.9781e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   4684/156230 | global iter:   4684/156230 | loss: 1.1958 | ds_loss: 1.2171 | lr: 9.9781e-05 | scale: 32768.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4684/156230 | global iter:   4684/156230 | loss: 1.1499 | ds_loss: 1.1614 | lr: 9.9781e-05 | scale: 32768.0000 | micro time: 1.370 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4685/156230 | global iter:   4685/156230 | loss: 1.2282 | ds_loss: 1.2480 | lr: 9.9780e-05 | scale: 32768.0000 | micro time: 1.420 | step time: 0.000
train | epoch   0 | Iter:   4686/156230 | global iter:   4686/156230 | loss: 1.2176 | ds_loss: 1.2329 | lr: 9.9780e-05 | scale: 32768.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   4687/156230 | global iter:   4687/156230 | loss: 0.9399 | ds_loss: 0.9597 | lr: 9.9780e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   4688/156230 | global iter:   4688/156230 | loss: 1.0720 | ds_loss: 1.0754 | lr: 9.9780e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4688/156230 | global iter:   4688/156230 | loss: 1.1144 | ds_loss: 1.1290 | lr: 9.9780e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4689/156230 | global iter:   4689/156230 | loss: 1.0612 | ds_loss: 1.0945 | lr: 9.9780e-05 | scale: 32768.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   4690/156230 | global iter:   4690/156230 | loss: 1.3181 | ds_loss: 1.3450 | lr: 9.9780e-05 | scale: 32768.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   4691/156230 | global iter:   4691/156230 | loss: 1.2154 | ds_loss: 1.2209 | lr: 9.9780e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   4692/156230 | global iter:   4692/156230 | loss: 1.1026 | ds_loss: 1.1339 | lr: 9.9780e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4692/156230 | global iter:   4692/156230 | loss: 1.1743 | ds_loss: 1.1986 | lr: 9.9780e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4693/156230 | global iter:   4693/156230 | loss: 1.1376 | ds_loss: 1.1665 | lr: 9.9780e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   4694/156230 | global iter:   4694/156230 | loss: 1.2027 | ds_loss: 1.2146 | lr: 9.9780e-05 | scale: 32768.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   4695/156230 | global iter:   4695/156230 | loss: 0.9534 | ds_loss: 0.9615 | lr: 9.9780e-05 | scale: 32768.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   4696/156230 | global iter:   4696/156230 | loss: 1.1426 | ds_loss: 1.1543 | lr: 9.9779e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4696/156230 | global iter:   4696/156230 | loss: 1.1091 | ds_loss: 1.1242 | lr: 9.9779e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4697/156230 | global iter:   4697/156230 | loss: 1.2809 | ds_loss: 1.2913 | lr: 9.9779e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   4698/156230 | global iter:   4698/156230 | loss: 1.0677 | ds_loss: 1.0740 | lr: 9.9779e-05 | scale: 32768.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   4699/156230 | global iter:   4699/156230 | loss: 1.0391 | ds_loss: 1.0502 | lr: 9.9779e-05 | scale: 32768.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   4700/156230 | global iter:   4700/156230 | loss: 1.0556 | ds_loss: 1.0978 | lr: 9.9779e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4700/156230 | global iter:   4700/156230 | loss: 1.1109 | ds_loss: 1.1283 | lr: 9.9779e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4701/156230 | global iter:   4701/156230 | loss: 1.0804 | ds_loss: 1.1034 | lr: 9.9779e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   4702/156230 | global iter:   4702/156230 | loss: 1.1280 | ds_loss: 1.1452 | lr: 9.9779e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   4703/156230 | global iter:   4703/156230 | loss: 0.9272 | ds_loss: 0.9486 | lr: 9.9779e-05 | scale: 32768.0000 | micro time: 1.309 | step time: 0.000
train | epoch   0 | Iter:   4704/156230 | global iter:   4704/156230 | loss: 0.8782 | ds_loss: 0.8837 | lr: 9.9779e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4704/156230 | global iter:   4704/156230 | loss: 1.0034 | ds_loss: 1.0202 | lr: 9.9779e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4705/156230 | global iter:   4705/156230 | loss: 1.0499 | ds_loss: 1.0725 | lr: 9.9779e-05 | scale: 32768.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   4706/156230 | global iter:   4706/156230 | loss: 0.8851 | ds_loss: 0.9001 | lr: 9.9778e-05 | scale: 32768.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   4707/156230 | global iter:   4707/156230 | loss: 1.0168 | ds_loss: 1.0270 | lr: 9.9778e-05 | scale: 32768.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   4708/156230 | global iter:   4708/156230 | loss: 1.0453 | ds_loss: 1.0802 | lr: 9.9778e-05 | scale: 32768.0000 | micro time: 1.432 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4708/156230 | global iter:   4708/156230 | loss: 0.9993 | ds_loss: 1.0200 | lr: 9.9778e-05 | scale: 32768.0000 | micro time: 1.432 | step time: 1.387
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4709/156230 | global iter:   4709/156230 | loss: 1.1989 | ds_loss: 1.2085 | lr: 9.9778e-05 | scale: 32768.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   4710/156230 | global iter:   4710/156230 | loss: 1.2988 | ds_loss: 1.2957 | lr: 9.9778e-05 | scale: 32768.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   4711/156230 | global iter:   4711/156230 | loss: 1.0961 | ds_loss: 1.1087 | lr: 9.9778e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   4712/156230 | global iter:   4712/156230 | loss: 1.1660 | ds_loss: 1.1810 | lr: 9.9778e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4712/156230 | global iter:   4712/156230 | loss: 1.1900 | ds_loss: 1.1985 | lr: 9.9778e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4713/156230 | global iter:   4713/156230 | loss: 1.1312 | ds_loss: 1.1540 | lr: 9.9778e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   4714/156230 | global iter:   4714/156230 | loss: 1.1389 | ds_loss: 1.1668 | lr: 9.9778e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   4715/156230 | global iter:   4715/156230 | loss: 1.0986 | ds_loss: 1.1054 | lr: 9.9778e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   4716/156230 | global iter:   4716/156230 | loss: 1.2400 | ds_loss: 1.2469 | lr: 9.9778e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4716/156230 | global iter:   4716/156230 | loss: 1.1522 | ds_loss: 1.1683 | lr: 9.9778e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4717/156230 | global iter:   4717/156230 | loss: 1.1495 | ds_loss: 1.1580 | lr: 9.9777e-05 | scale: 32768.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   4718/156230 | global iter:   4718/156230 | loss: 0.9480 | ds_loss: 0.9738 | lr: 9.9777e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   4719/156230 | global iter:   4719/156230 | loss: 1.1615 | ds_loss: 1.1758 | lr: 9.9777e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   4720/156230 | global iter:   4720/156230 | loss: 1.0776 | ds_loss: 1.1041 | lr: 9.9777e-05 | scale: 32768.0000 | micro time: 1.334 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4720/156230 | global iter:   4720/156230 | loss: 1.0842 | ds_loss: 1.1029 | lr: 9.9777e-05 | scale: 32768.0000 | micro time: 1.334 | step time: 1.343
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4721/156230 | global iter:   4721/156230 | loss: 1.2722 | ds_loss: 1.2697 | lr: 9.9777e-05 | scale: 32768.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   4722/156230 | global iter:   4722/156230 | loss: 1.0650 | ds_loss: 1.0634 | lr: 9.9777e-05 | scale: 32768.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   4723/156230 | global iter:   4723/156230 | loss: 1.1649 | ds_loss: 1.1810 | lr: 9.9777e-05 | scale: 32768.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   4724/156230 | global iter:   4724/156230 | loss: 1.2231 | ds_loss: 1.2419 | lr: 9.9777e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4724/156230 | global iter:   4724/156230 | loss: 1.1813 | ds_loss: 1.1890 | lr: 9.9777e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4725/156230 | global iter:   4725/156230 | loss: 1.1388 | ds_loss: 1.1587 | lr: 9.9777e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   4726/156230 | global iter:   4726/156230 | loss: 1.0206 | ds_loss: 1.0363 | lr: 9.9777e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   4727/156230 | global iter:   4727/156230 | loss: 1.0399 | ds_loss: 1.0606 | lr: 9.9777e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   4728/156230 | global iter:   4728/156230 | loss: 1.1984 | ds_loss: 1.2073 | lr: 9.9776e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4728/156230 | global iter:   4728/156230 | loss: 1.0995 | ds_loss: 1.1157 | lr: 9.9776e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4729/156230 | global iter:   4729/156230 | loss: 1.0719 | ds_loss: 1.0874 | lr: 9.9776e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   4730/156230 | global iter:   4730/156230 | loss: 1.1589 | ds_loss: 1.1676 | lr: 9.9776e-05 | scale: 32768.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   4731/156230 | global iter:   4731/156230 | loss: 1.1536 | ds_loss: 1.1815 | lr: 9.9776e-05 | scale: 32768.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:   4732/156230 | global iter:   4732/156230 | loss: 1.1001 | ds_loss: 1.1278 | lr: 9.9776e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4732/156230 | global iter:   4732/156230 | loss: 1.1211 | ds_loss: 1.1411 | lr: 9.9776e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 1.376
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4733/156230 | global iter:   4733/156230 | loss: 1.0358 | ds_loss: 1.0586 | lr: 9.9776e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   4734/156230 | global iter:   4734/156230 | loss: 1.1225 | ds_loss: 1.1398 | lr: 9.9776e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   4735/156230 | global iter:   4735/156230 | loss: 1.1733 | ds_loss: 1.2033 | lr: 9.9776e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   4736/156230 | global iter:   4736/156230 | loss: 1.1843 | ds_loss: 1.2178 | lr: 9.9776e-05 | scale: 32768.0000 | micro time: 1.402 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4736/156230 | global iter:   4736/156230 | loss: 1.1290 | ds_loss: 1.1549 | lr: 9.9776e-05 | scale: 32768.0000 | micro time: 1.402 | step time: 1.379
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4737/156230 | global iter:   4737/156230 | loss: 1.1996 | ds_loss: 1.2185 | lr: 9.9776e-05 | scale: 32768.0000 | micro time: 1.325 | step time: 0.000
train | epoch   0 | Iter:   4738/156230 | global iter:   4738/156230 | loss: 1.0926 | ds_loss: 1.1030 | lr: 9.9775e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   4739/156230 | global iter:   4739/156230 | loss: 1.0827 | ds_loss: 1.1003 | lr: 9.9775e-05 | scale: 32768.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   4740/156230 | global iter:   4740/156230 | loss: 1.1984 | ds_loss: 1.2224 | lr: 9.9775e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4740/156230 | global iter:   4740/156230 | loss: 1.1433 | ds_loss: 1.1611 | lr: 9.9775e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4741/156230 | global iter:   4741/156230 | loss: 1.1386 | ds_loss: 1.1386 | lr: 9.9775e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   4742/156230 | global iter:   4742/156230 | loss: 1.2185 | ds_loss: 1.2306 | lr: 9.9775e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   4743/156230 | global iter:   4743/156230 | loss: 1.1885 | ds_loss: 1.2136 | lr: 9.9775e-05 | scale: 32768.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   4744/156230 | global iter:   4744/156230 | loss: 1.2018 | ds_loss: 1.2290 | lr: 9.9775e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4744/156230 | global iter:   4744/156230 | loss: 1.1868 | ds_loss: 1.2029 | lr: 9.9775e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4745/156230 | global iter:   4745/156230 | loss: 1.2534 | ds_loss: 1.2577 | lr: 9.9775e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   4746/156230 | global iter:   4746/156230 | loss: 1.0235 | ds_loss: 1.0405 | lr: 9.9775e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   4747/156230 | global iter:   4747/156230 | loss: 1.1236 | ds_loss: 1.1525 | lr: 9.9775e-05 | scale: 32768.0000 | micro time: 1.322 | step time: 0.000
train | epoch   0 | Iter:   4748/156230 | global iter:   4748/156230 | loss: 1.1446 | ds_loss: 1.1829 | lr: 9.9775e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4748/156230 | global iter:   4748/156230 | loss: 1.1363 | ds_loss: 1.1584 | lr: 9.9775e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4749/156230 | global iter:   4749/156230 | loss: 1.2293 | ds_loss: 1.2393 | lr: 9.9774e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   4750/156230 | global iter:   4750/156230 | loss: 1.1352 | ds_loss: 1.1526 | lr: 9.9774e-05 | scale: 32768.0000 | micro time: 1.321 | step time: 0.000
train | epoch   0 | Iter:   4751/156230 | global iter:   4751/156230 | loss: 1.0963 | ds_loss: 1.1271 | lr: 9.9774e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   4752/156230 | global iter:   4752/156230 | loss: 1.1770 | ds_loss: 1.2057 | lr: 9.9774e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4752/156230 | global iter:   4752/156230 | loss: 1.1595 | ds_loss: 1.1812 | lr: 9.9774e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4753/156230 | global iter:   4753/156230 | loss: 1.1517 | ds_loss: 1.1595 | lr: 9.9774e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   4754/156230 | global iter:   4754/156230 | loss: 1.2189 | ds_loss: 1.2297 | lr: 9.9774e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   4755/156230 | global iter:   4755/156230 | loss: 1.0926 | ds_loss: 1.1008 | lr: 9.9774e-05 | scale: 32768.0000 | micro time: 1.410 | step time: 0.000
train | epoch   0 | Iter:   4756/156230 | global iter:   4756/156230 | loss: 1.2890 | ds_loss: 1.3146 | lr: 9.9774e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4756/156230 | global iter:   4756/156230 | loss: 1.1880 | ds_loss: 1.2011 | lr: 9.9774e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 1.386
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4757/156230 | global iter:   4757/156230 | loss: 1.1746 | ds_loss: 1.1944 | lr: 9.9774e-05 | scale: 32768.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   4758/156230 | global iter:   4758/156230 | loss: 1.1887 | ds_loss: 1.1854 | lr: 9.9774e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   4759/156230 | global iter:   4759/156230 | loss: 0.8701 | ds_loss: 0.8995 | lr: 9.9773e-05 | scale: 32768.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   4760/156230 | global iter:   4760/156230 | loss: 1.0465 | ds_loss: 1.0797 | lr: 9.9773e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4760/156230 | global iter:   4760/156230 | loss: 1.0700 | ds_loss: 1.0897 | lr: 9.9773e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4761/156230 | global iter:   4761/156230 | loss: 0.9840 | ds_loss: 1.0097 | lr: 9.9773e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   4762/156230 | global iter:   4762/156230 | loss: 1.1775 | ds_loss: 1.1982 | lr: 9.9773e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   4763/156230 | global iter:   4763/156230 | loss: 1.0718 | ds_loss: 1.0866 | lr: 9.9773e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   4764/156230 | global iter:   4764/156230 | loss: 1.1054 | ds_loss: 1.1304 | lr: 9.9773e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4764/156230 | global iter:   4764/156230 | loss: 1.0847 | ds_loss: 1.1062 | lr: 9.9773e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4765/156230 | global iter:   4765/156230 | loss: 0.8616 | ds_loss: 0.8809 | lr: 9.9773e-05 | scale: 32768.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   4766/156230 | global iter:   4766/156230 | loss: 1.0059 | ds_loss: 1.0277 | lr: 9.9773e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   4767/156230 | global iter:   4767/156230 | loss: 1.0338 | ds_loss: 1.0639 | lr: 9.9773e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   4768/156230 | global iter:   4768/156230 | loss: 1.2006 | ds_loss: 1.2060 | lr: 9.9773e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4768/156230 | global iter:   4768/156230 | loss: 1.0255 | ds_loss: 1.0446 | lr: 9.9773e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4769/156230 | global iter:   4769/156230 | loss: 1.0911 | ds_loss: 1.1108 | lr: 9.9773e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   4770/156230 | global iter:   4770/156230 | loss: 0.9707 | ds_loss: 0.9976 | lr: 9.9772e-05 | scale: 32768.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   4771/156230 | global iter:   4771/156230 | loss: 1.0264 | ds_loss: 1.0398 | lr: 9.9772e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   4772/156230 | global iter:   4772/156230 | loss: 1.1989 | ds_loss: 1.2131 | lr: 9.9772e-05 | scale: 32768.0000 | micro time: 1.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4772/156230 | global iter:   4772/156230 | loss: 1.0718 | ds_loss: 1.0903 | lr: 9.9772e-05 | scale: 32768.0000 | micro time: 1.394 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4773/156230 | global iter:   4773/156230 | loss: 1.0534 | ds_loss: 1.0555 | lr: 9.9772e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   4774/156230 | global iter:   4774/156230 | loss: 1.0989 | ds_loss: 1.1156 | lr: 9.9772e-05 | scale: 32768.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:   4775/156230 | global iter:   4775/156230 | loss: 1.2826 | ds_loss: 1.2884 | lr: 9.9772e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   4776/156230 | global iter:   4776/156230 | loss: 1.2502 | ds_loss: 1.2395 | lr: 9.9772e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4776/156230 | global iter:   4776/156230 | loss: 1.1713 | ds_loss: 1.1747 | lr: 9.9772e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4777/156230 | global iter:   4777/156230 | loss: 1.2342 | ds_loss: 1.2559 | lr: 9.9772e-05 | scale: 32768.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   4778/156230 | global iter:   4778/156230 | loss: 1.1432 | ds_loss: 1.1499 | lr: 9.9772e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   4779/156230 | global iter:   4779/156230 | loss: 0.9115 | ds_loss: 0.9240 | lr: 9.9772e-05 | scale: 32768.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   4780/156230 | global iter:   4780/156230 | loss: 1.2398 | ds_loss: 1.2466 | lr: 9.9771e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4780/156230 | global iter:   4780/156230 | loss: 1.1322 | ds_loss: 1.1441 | lr: 9.9771e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4781/156230 | global iter:   4781/156230 | loss: 1.1576 | ds_loss: 1.1951 | lr: 9.9771e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   4782/156230 | global iter:   4782/156230 | loss: 1.1490 | ds_loss: 1.1708 | lr: 9.9771e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   4783/156230 | global iter:   4783/156230 | loss: 1.1025 | ds_loss: 1.1166 | lr: 9.9771e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   4784/156230 | global iter:   4784/156230 | loss: 1.2123 | ds_loss: 1.2463 | lr: 9.9771e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4784/156230 | global iter:   4784/156230 | loss: 1.1553 | ds_loss: 1.1822 | lr: 9.9771e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4785/156230 | global iter:   4785/156230 | loss: 1.2095 | ds_loss: 1.2179 | lr: 9.9771e-05 | scale: 32768.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   4786/156230 | global iter:   4786/156230 | loss: 1.1343 | ds_loss: 1.1448 | lr: 9.9771e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   4787/156230 | global iter:   4787/156230 | loss: 1.0287 | ds_loss: 1.0439 | lr: 9.9771e-05 | scale: 32768.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   4788/156230 | global iter:   4788/156230 | loss: 1.1454 | ds_loss: 1.1327 | lr: 9.9771e-05 | scale: 32768.0000 | micro time: 1.407 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4788/156230 | global iter:   4788/156230 | loss: 1.1295 | ds_loss: 1.1348 | lr: 9.9771e-05 | scale: 32768.0000 | micro time: 1.407 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4789/156230 | global iter:   4789/156230 | loss: 1.0998 | ds_loss: 1.1140 | lr: 9.9771e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   4790/156230 | global iter:   4790/156230 | loss: 1.1781 | ds_loss: 1.1960 | lr: 9.9770e-05 | scale: 32768.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   4791/156230 | global iter:   4791/156230 | loss: 1.0740 | ds_loss: 1.1001 | lr: 9.9770e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   4792/156230 | global iter:   4792/156230 | loss: 1.1822 | ds_loss: 1.1979 | lr: 9.9770e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4792/156230 | global iter:   4792/156230 | loss: 1.1335 | ds_loss: 1.1520 | lr: 9.9770e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4793/156230 | global iter:   4793/156230 | loss: 1.0716 | ds_loss: 1.0904 | lr: 9.9770e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   4794/156230 | global iter:   4794/156230 | loss: 1.1880 | ds_loss: 1.2087 | lr: 9.9770e-05 | scale: 32768.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   4795/156230 | global iter:   4795/156230 | loss: 1.1111 | ds_loss: 1.1330 | lr: 9.9770e-05 | scale: 32768.0000 | micro time: 1.407 | step time: 0.000
train | epoch   0 | Iter:   4796/156230 | global iter:   4796/156230 | loss: 1.1610 | ds_loss: 1.1614 | lr: 9.9770e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4796/156230 | global iter:   4796/156230 | loss: 1.1329 | ds_loss: 1.1484 | lr: 9.9770e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4797/156230 | global iter:   4797/156230 | loss: 1.2110 | ds_loss: 1.2383 | lr: 9.9770e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   4798/156230 | global iter:   4798/156230 | loss: 1.1999 | ds_loss: 1.2115 | lr: 9.9770e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   4799/156230 | global iter:   4799/156230 | loss: 1.1988 | ds_loss: 1.1822 | lr: 9.9770e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   4800/156230 | global iter:   4800/156230 | loss: 1.1794 | ds_loss: 1.1677 | lr: 9.9770e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4800/156230 | global iter:   4800/156230 | loss: 1.1973 | ds_loss: 1.1999 | lr: 9.9770e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4801/156230 | global iter:   4801/156230 | loss: 1.0570 | ds_loss: 1.0905 | lr: 9.9769e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   4802/156230 | global iter:   4802/156230 | loss: 0.9608 | ds_loss: 0.9720 | lr: 9.9769e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   4803/156230 | global iter:   4803/156230 | loss: 0.9316 | ds_loss: 0.9397 | lr: 9.9769e-05 | scale: 32768.0000 | micro time: 1.322 | step time: 0.000
train | epoch   0 | Iter:   4804/156230 | global iter:   4804/156230 | loss: 0.9783 | ds_loss: 0.9868 | lr: 9.9769e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4804/156230 | global iter:   4804/156230 | loss: 0.9819 | ds_loss: 0.9973 | lr: 9.9769e-05 | scale: 32768.0000 | micro time: 1.364 | step time: 1.346
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4805/156230 | global iter:   4805/156230 | loss: 1.2513 | ds_loss: 1.2445 | lr: 9.9769e-05 | scale: 32768.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   4806/156230 | global iter:   4806/156230 | loss: 1.1544 | ds_loss: 1.1561 | lr: 9.9769e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   4807/156230 | global iter:   4807/156230 | loss: 1.0835 | ds_loss: 1.1088 | lr: 9.9769e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   4808/156230 | global iter:   4808/156230 | loss: 1.1260 | ds_loss: 1.1376 | lr: 9.9769e-05 | scale: 32768.0000 | micro time: 1.384 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4808/156230 | global iter:   4808/156230 | loss: 1.1538 | ds_loss: 1.1617 | lr: 9.9769e-05 | scale: 32768.0000 | micro time: 1.384 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4809/156230 | global iter:   4809/156230 | loss: 1.1071 | ds_loss: 1.1186 | lr: 9.9769e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   4810/156230 | global iter:   4810/156230 | loss: 1.1410 | ds_loss: 1.1786 | lr: 9.9769e-05 | scale: 32768.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   4811/156230 | global iter:   4811/156230 | loss: 1.1307 | ds_loss: 1.1484 | lr: 9.9768e-05 | scale: 32768.0000 | micro time: 1.401 | step time: 0.000
train | epoch   0 | Iter:   4812/156230 | global iter:   4812/156230 | loss: 1.0582 | ds_loss: 1.0791 | lr: 9.9768e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4812/156230 | global iter:   4812/156230 | loss: 1.1092 | ds_loss: 1.1312 | lr: 9.9768e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4813/156230 | global iter:   4813/156230 | loss: 1.1568 | ds_loss: 1.1865 | lr: 9.9768e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   4814/156230 | global iter:   4814/156230 | loss: 0.9268 | ds_loss: 0.9341 | lr: 9.9768e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   4815/156230 | global iter:   4815/156230 | loss: 0.9766 | ds_loss: 1.0020 | lr: 9.9768e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   4816/156230 | global iter:   4816/156230 | loss: 1.1880 | ds_loss: 1.1999 | lr: 9.9768e-05 | scale: 32768.0000 | micro time: 1.417 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4816/156230 | global iter:   4816/156230 | loss: 1.0621 | ds_loss: 1.0806 | lr: 9.9768e-05 | scale: 32768.0000 | micro time: 1.417 | step time: 1.380
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4817/156230 | global iter:   4817/156230 | loss: 1.0825 | ds_loss: 1.1218 | lr: 9.9768e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   4818/156230 | global iter:   4818/156230 | loss: 1.2330 | ds_loss: 1.2423 | lr: 9.9768e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   4819/156230 | global iter:   4819/156230 | loss: 1.0685 | ds_loss: 1.0980 | lr: 9.9768e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   4820/156230 | global iter:   4820/156230 | loss: 1.0853 | ds_loss: 1.0884 | lr: 9.9768e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4820/156230 | global iter:   4820/156230 | loss: 1.1173 | ds_loss: 1.1376 | lr: 9.9768e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4821/156230 | global iter:   4821/156230 | loss: 1.1058 | ds_loss: 1.1241 | lr: 9.9768e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   4822/156230 | global iter:   4822/156230 | loss: 1.0722 | ds_loss: 1.0865 | lr: 9.9767e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   4823/156230 | global iter:   4823/156230 | loss: 1.0852 | ds_loss: 1.1102 | lr: 9.9767e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   4824/156230 | global iter:   4824/156230 | loss: 1.1803 | ds_loss: 1.1935 | lr: 9.9767e-05 | scale: 32768.0000 | micro time: 1.402 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4824/156230 | global iter:   4824/156230 | loss: 1.1109 | ds_loss: 1.1285 | lr: 9.9767e-05 | scale: 32768.0000 | micro time: 1.402 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4825/156230 | global iter:   4825/156230 | loss: 1.0584 | ds_loss: 1.0841 | lr: 9.9767e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   4826/156230 | global iter:   4826/156230 | loss: 1.0792 | ds_loss: 1.0915 | lr: 9.9767e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   4827/156230 | global iter:   4827/156230 | loss: 0.9528 | ds_loss: 0.9716 | lr: 9.9767e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   4828/156230 | global iter:   4828/156230 | loss: 0.9887 | ds_loss: 1.0043 | lr: 9.9767e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4828/156230 | global iter:   4828/156230 | loss: 1.0198 | ds_loss: 1.0379 | lr: 9.9767e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4829/156230 | global iter:   4829/156230 | loss: 1.1877 | ds_loss: 1.1925 | lr: 9.9767e-05 | scale: 32768.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   4830/156230 | global iter:   4830/156230 | loss: 1.1668 | ds_loss: 1.1901 | lr: 9.9767e-05 | scale: 32768.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   4831/156230 | global iter:   4831/156230 | loss: 0.9715 | ds_loss: 1.0026 | lr: 9.9767e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   4832/156230 | global iter:   4832/156230 | loss: 1.0342 | ds_loss: 1.0569 | lr: 9.9766e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4832/156230 | global iter:   4832/156230 | loss: 1.0900 | ds_loss: 1.1105 | lr: 9.9766e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4833/156230 | global iter:   4833/156230 | loss: 1.2668 | ds_loss: 1.2677 | lr: 9.9766e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   4834/156230 | global iter:   4834/156230 | loss: 1.1847 | ds_loss: 1.2008 | lr: 9.9766e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   4835/156230 | global iter:   4835/156230 | loss: 1.1761 | ds_loss: 1.1996 | lr: 9.9766e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   4836/156230 | global iter:   4836/156230 | loss: 1.0524 | ds_loss: 1.0591 | lr: 9.9766e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4836/156230 | global iter:   4836/156230 | loss: 1.1700 | ds_loss: 1.1818 | lr: 9.9766e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4837/156230 | global iter:   4837/156230 | loss: 1.2137 | ds_loss: 1.2331 | lr: 9.9766e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   4838/156230 | global iter:   4838/156230 | loss: 1.3120 | ds_loss: 1.3212 | lr: 9.9766e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   4839/156230 | global iter:   4839/156230 | loss: 1.0978 | ds_loss: 1.1172 | lr: 9.9766e-05 | scale: 32768.0000 | micro time: 1.417 | step time: 0.000
train | epoch   0 | Iter:   4840/156230 | global iter:   4840/156230 | loss: 1.1437 | ds_loss: 1.1872 | lr: 9.9766e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4840/156230 | global iter:   4840/156230 | loss: 1.1918 | ds_loss: 1.2147 | lr: 9.9766e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4841/156230 | global iter:   4841/156230 | loss: 1.1836 | ds_loss: 1.1931 | lr: 9.9766e-05 | scale: 32768.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   4842/156230 | global iter:   4842/156230 | loss: 1.1848 | ds_loss: 1.2095 | lr: 9.9765e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   4843/156230 | global iter:   4843/156230 | loss: 0.9133 | ds_loss: 0.9256 | lr: 9.9765e-05 | scale: 32768.0000 | micro time: 1.405 | step time: 0.000
train | epoch   0 | Iter:   4844/156230 | global iter:   4844/156230 | loss: 0.9964 | ds_loss: 1.0165 | lr: 9.9765e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4844/156230 | global iter:   4844/156230 | loss: 1.0695 | ds_loss: 1.0862 | lr: 9.9765e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 1.384
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4845/156230 | global iter:   4845/156230 | loss: 1.2236 | ds_loss: 1.2324 | lr: 9.9765e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   4846/156230 | global iter:   4846/156230 | loss: 1.3090 | ds_loss: 1.3130 | lr: 9.9765e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   4847/156230 | global iter:   4847/156230 | loss: 1.1379 | ds_loss: 1.1565 | lr: 9.9765e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   4848/156230 | global iter:   4848/156230 | loss: 1.1223 | ds_loss: 1.1334 | lr: 9.9765e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4848/156230 | global iter:   4848/156230 | loss: 1.1982 | ds_loss: 1.2088 | lr: 9.9765e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4849/156230 | global iter:   4849/156230 | loss: 1.1291 | ds_loss: 1.1599 | lr: 9.9765e-05 | scale: 32768.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   4850/156230 | global iter:   4850/156230 | loss: 0.9921 | ds_loss: 1.0088 | lr: 9.9765e-05 | scale: 32768.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   4851/156230 | global iter:   4851/156230 | loss: 1.1747 | ds_loss: 1.1876 | lr: 9.9765e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   4852/156230 | global iter:   4852/156230 | loss: 1.0244 | ds_loss: 1.0385 | lr: 9.9764e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4852/156230 | global iter:   4852/156230 | loss: 1.0801 | ds_loss: 1.0987 | lr: 9.9764e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4853/156230 | global iter:   4853/156230 | loss: 1.1528 | ds_loss: 1.1613 | lr: 9.9764e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   4854/156230 | global iter:   4854/156230 | loss: 0.9879 | ds_loss: 1.0002 | lr: 9.9764e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   4855/156230 | global iter:   4855/156230 | loss: 1.1144 | ds_loss: 1.1278 | lr: 9.9764e-05 | scale: 32768.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   4856/156230 | global iter:   4856/156230 | loss: 0.9784 | ds_loss: 0.9874 | lr: 9.9764e-05 | scale: 32768.0000 | micro time: 1.392 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4856/156230 | global iter:   4856/156230 | loss: 1.0584 | ds_loss: 1.0692 | lr: 9.9764e-05 | scale: 32768.0000 | micro time: 1.392 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4857/156230 | global iter:   4857/156230 | loss: 1.2204 | ds_loss: 1.2527 | lr: 9.9764e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   4858/156230 | global iter:   4858/156230 | loss: 0.9227 | ds_loss: 0.9582 | lr: 9.9764e-05 | scale: 32768.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   4859/156230 | global iter:   4859/156230 | loss: 1.0892 | ds_loss: 1.0850 | lr: 9.9764e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   4860/156230 | global iter:   4860/156230 | loss: 1.0178 | ds_loss: 1.0363 | lr: 9.9764e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4860/156230 | global iter:   4860/156230 | loss: 1.0625 | ds_loss: 1.0830 | lr: 9.9764e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4861/156230 | global iter:   4861/156230 | loss: 1.0338 | ds_loss: 1.0320 | lr: 9.9764e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   4862/156230 | global iter:   4862/156230 | loss: 1.0195 | ds_loss: 1.0337 | lr: 9.9764e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   4863/156230 | global iter:   4863/156230 | loss: 1.1613 | ds_loss: 1.1587 | lr: 9.9763e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   4864/156230 | global iter:   4864/156230 | loss: 1.0016 | ds_loss: 1.0247 | lr: 9.9763e-05 | scale: 32768.0000 | micro time: 1.310 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4864/156230 | global iter:   4864/156230 | loss: 1.0540 | ds_loss: 1.0623 | lr: 9.9763e-05 | scale: 32768.0000 | micro time: 1.310 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4865/156230 | global iter:   4865/156230 | loss: 1.1545 | ds_loss: 1.1815 | lr: 9.9763e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   4866/156230 | global iter:   4866/156230 | loss: 1.1940 | ds_loss: 1.2103 | lr: 9.9763e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   4867/156230 | global iter:   4867/156230 | loss: 1.1530 | ds_loss: 1.1717 | lr: 9.9763e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   4868/156230 | global iter:   4868/156230 | loss: 1.1067 | ds_loss: 1.1079 | lr: 9.9763e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4868/156230 | global iter:   4868/156230 | loss: 1.1520 | ds_loss: 1.1678 | lr: 9.9763e-05 | scale: 32768.0000 | micro time: 1.352 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4869/156230 | global iter:   4869/156230 | loss: 1.1808 | ds_loss: 1.2003 | lr: 9.9763e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   4870/156230 | global iter:   4870/156230 | loss: 1.0054 | ds_loss: 1.0218 | lr: 9.9763e-05 | scale: 32768.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   4871/156230 | global iter:   4871/156230 | loss: 1.1210 | ds_loss: 1.1489 | lr: 9.9763e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   4872/156230 | global iter:   4872/156230 | loss: 1.1528 | ds_loss: 1.1639 | lr: 9.9763e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4872/156230 | global iter:   4872/156230 | loss: 1.1150 | ds_loss: 1.1337 | lr: 9.9763e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4873/156230 | global iter:   4873/156230 | loss: 1.1696 | ds_loss: 1.1886 | lr: 9.9762e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   4874/156230 | global iter:   4874/156230 | loss: 1.1881 | ds_loss: 1.2097 | lr: 9.9762e-05 | scale: 32768.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   4875/156230 | global iter:   4875/156230 | loss: 1.2823 | ds_loss: 1.3049 | lr: 9.9762e-05 | scale: 32768.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   4876/156230 | global iter:   4876/156230 | loss: 1.1556 | ds_loss: 1.1766 | lr: 9.9762e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4876/156230 | global iter:   4876/156230 | loss: 1.1989 | ds_loss: 1.2200 | lr: 9.9762e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4877/156230 | global iter:   4877/156230 | loss: 1.2544 | ds_loss: 1.2774 | lr: 9.9762e-05 | scale: 32768.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   4878/156230 | global iter:   4878/156230 | loss: 0.9608 | ds_loss: 0.9605 | lr: 9.9762e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   4879/156230 | global iter:   4879/156230 | loss: 1.0460 | ds_loss: 1.0508 | lr: 9.9762e-05 | scale: 32768.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   4880/156230 | global iter:   4880/156230 | loss: 1.0025 | ds_loss: 1.0338 | lr: 9.9762e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4880/156230 | global iter:   4880/156230 | loss: 1.0659 | ds_loss: 1.0806 | lr: 9.9762e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4881/156230 | global iter:   4881/156230 | loss: 1.3805 | ds_loss: 1.3832 | lr: 9.9762e-05 | scale: 32768.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   4882/156230 | global iter:   4882/156230 | loss: 1.1266 | ds_loss: 1.1587 | lr: 9.9762e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   4883/156230 | global iter:   4883/156230 | loss: 1.1136 | ds_loss: 1.1353 | lr: 9.9761e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   4884/156230 | global iter:   4884/156230 | loss: 1.0354 | ds_loss: 1.0473 | lr: 9.9761e-05 | scale: 32768.0000 | micro time: 1.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4884/156230 | global iter:   4884/156230 | loss: 1.1640 | ds_loss: 1.1811 | lr: 9.9761e-05 | scale: 32768.0000 | micro time: 1.394 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4885/156230 | global iter:   4885/156230 | loss: 1.0790 | ds_loss: 1.0940 | lr: 9.9761e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   4886/156230 | global iter:   4886/156230 | loss: 1.1527 | ds_loss: 1.1658 | lr: 9.9761e-05 | scale: 32768.0000 | micro time: 1.310 | step time: 0.000
train | epoch   0 | Iter:   4887/156230 | global iter:   4887/156230 | loss: 1.1246 | ds_loss: 1.1278 | lr: 9.9761e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   4888/156230 | global iter:   4888/156230 | loss: 1.2688 | ds_loss: 1.2781 | lr: 9.9761e-05 | scale: 32768.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4888/156230 | global iter:   4888/156230 | loss: 1.1563 | ds_loss: 1.1664 | lr: 9.9761e-05 | scale: 32768.0000 | micro time: 1.370 | step time: 1.347
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4889/156230 | global iter:   4889/156230 | loss: 1.3095 | ds_loss: 1.3375 | lr: 9.9761e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   4890/156230 | global iter:   4890/156230 | loss: 0.8967 | ds_loss: 0.9130 | lr: 9.9761e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   4891/156230 | global iter:   4891/156230 | loss: 1.2168 | ds_loss: 1.2236 | lr: 9.9761e-05 | scale: 32768.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   4892/156230 | global iter:   4892/156230 | loss: 1.2985 | ds_loss: 1.3165 | lr: 9.9761e-05 | scale: 32768.0000 | micro time: 1.330 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4892/156230 | global iter:   4892/156230 | loss: 1.1804 | ds_loss: 1.1977 | lr: 9.9761e-05 | scale: 32768.0000 | micro time: 1.330 | step time: 1.341
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4893/156230 | global iter:   4893/156230 | loss: 1.1300 | ds_loss: 1.1553 | lr: 9.9760e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   4894/156230 | global iter:   4894/156230 | loss: 1.0368 | ds_loss: 1.0612 | lr: 9.9760e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   4895/156230 | global iter:   4895/156230 | loss: 1.2426 | ds_loss: 1.2491 | lr: 9.9760e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   4896/156230 | global iter:   4896/156230 | loss: 1.2307 | ds_loss: 1.2486 | lr: 9.9760e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4896/156230 | global iter:   4896/156230 | loss: 1.1600 | ds_loss: 1.1785 | lr: 9.9760e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4897/156230 | global iter:   4897/156230 | loss: 1.0862 | ds_loss: 1.0946 | lr: 9.9760e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   4898/156230 | global iter:   4898/156230 | loss: 1.2012 | ds_loss: 1.2109 | lr: 9.9760e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   4899/156230 | global iter:   4899/156230 | loss: 1.2723 | ds_loss: 1.2730 | lr: 9.9760e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   4900/156230 | global iter:   4900/156230 | loss: 1.0412 | ds_loss: 1.0623 | lr: 9.9760e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4900/156230 | global iter:   4900/156230 | loss: 1.1502 | ds_loss: 1.1602 | lr: 9.9760e-05 | scale: 32768.0000 | micro time: 1.341 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4901/156230 | global iter:   4901/156230 | loss: 1.1380 | ds_loss: 1.1560 | lr: 9.9760e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   4902/156230 | global iter:   4902/156230 | loss: 1.0996 | ds_loss: 1.1076 | lr: 9.9760e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   4903/156230 | global iter:   4903/156230 | loss: 1.1418 | ds_loss: 1.1489 | lr: 9.9759e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   4904/156230 | global iter:   4904/156230 | loss: 1.0975 | ds_loss: 1.1137 | lr: 9.9759e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4904/156230 | global iter:   4904/156230 | loss: 1.1192 | ds_loss: 1.1316 | lr: 9.9759e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4905/156230 | global iter:   4905/156230 | loss: 1.1650 | ds_loss: 1.1779 | lr: 9.9759e-05 | scale: 32768.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   4906/156230 | global iter:   4906/156230 | loss: 1.0983 | ds_loss: 1.1194 | lr: 9.9759e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   4907/156230 | global iter:   4907/156230 | loss: 1.1985 | ds_loss: 1.2036 | lr: 9.9759e-05 | scale: 32768.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   4908/156230 | global iter:   4908/156230 | loss: 1.1937 | ds_loss: 1.1943 | lr: 9.9759e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4908/156230 | global iter:   4908/156230 | loss: 1.1639 | ds_loss: 1.1738 | lr: 9.9759e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4909/156230 | global iter:   4909/156230 | loss: 1.1833 | ds_loss: 1.1805 | lr: 9.9759e-05 | scale: 32768.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   4910/156230 | global iter:   4910/156230 | loss: 1.1170 | ds_loss: 1.1442 | lr: 9.9759e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   4911/156230 | global iter:   4911/156230 | loss: 1.1471 | ds_loss: 1.1793 | lr: 9.9759e-05 | scale: 32768.0000 | micro time: 1.407 | step time: 0.000
train | epoch   0 | Iter:   4912/156230 | global iter:   4912/156230 | loss: 1.1726 | ds_loss: 1.1853 | lr: 9.9759e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4912/156230 | global iter:   4912/156230 | loss: 1.1550 | ds_loss: 1.1723 | lr: 9.9759e-05 | scale: 32768.0000 | micro time: 1.343 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4913/156230 | global iter:   4913/156230 | loss: 1.1806 | ds_loss: 1.1883 | lr: 9.9759e-05 | scale: 32768.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   4914/156230 | global iter:   4914/156230 | loss: 0.9718 | ds_loss: 0.9839 | lr: 9.9758e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   4915/156230 | global iter:   4915/156230 | loss: 1.0966 | ds_loss: 1.1093 | lr: 9.9758e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   4916/156230 | global iter:   4916/156230 | loss: 1.2231 | ds_loss: 1.2414 | lr: 9.9758e-05 | scale: 32768.0000 | micro time: 1.340 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4916/156230 | global iter:   4916/156230 | loss: 1.1180 | ds_loss: 1.1307 | lr: 9.9758e-05 | scale: 32768.0000 | micro time: 1.340 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4917/156230 | global iter:   4917/156230 | loss: 1.2496 | ds_loss: 1.2688 | lr: 9.9758e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   4918/156230 | global iter:   4918/156230 | loss: 1.1722 | ds_loss: 1.1989 | lr: 9.9758e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   4919/156230 | global iter:   4919/156230 | loss: 0.8604 | ds_loss: 0.8755 | lr: 9.9758e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   4920/156230 | global iter:   4920/156230 | loss: 1.0784 | ds_loss: 1.0966 | lr: 9.9758e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4920/156230 | global iter:   4920/156230 | loss: 1.0902 | ds_loss: 1.1099 | lr: 9.9758e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4921/156230 | global iter:   4921/156230 | loss: 1.1242 | ds_loss: 1.1388 | lr: 9.9758e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   4922/156230 | global iter:   4922/156230 | loss: 0.9766 | ds_loss: 0.9890 | lr: 9.9758e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   4923/156230 | global iter:   4923/156230 | loss: 1.2204 | ds_loss: 1.2284 | lr: 9.9758e-05 | scale: 32768.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   4924/156230 | global iter:   4924/156230 | loss: 1.0259 | ds_loss: 1.0295 | lr: 9.9757e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4924/156230 | global iter:   4924/156230 | loss: 1.0868 | ds_loss: 1.0964 | lr: 9.9757e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4925/156230 | global iter:   4925/156230 | loss: 1.1203 | ds_loss: 1.1306 | lr: 9.9757e-05 | scale: 32768.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   4926/156230 | global iter:   4926/156230 | loss: 1.2306 | ds_loss: 1.2590 | lr: 9.9757e-05 | scale: 32768.0000 | micro time: 1.415 | step time: 0.000
train | epoch   0 | Iter:   4927/156230 | global iter:   4927/156230 | loss: 1.1798 | ds_loss: 1.1856 | lr: 9.9757e-05 | scale: 32768.0000 | micro time: 1.322 | step time: 0.000
train | epoch   0 | Iter:   4928/156230 | global iter:   4928/156230 | loss: 1.0847 | ds_loss: 1.0969 | lr: 9.9757e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4928/156230 | global iter:   4928/156230 | loss: 1.1539 | ds_loss: 1.1680 | lr: 9.9757e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4929/156230 | global iter:   4929/156230 | loss: 1.1018 | ds_loss: 1.1199 | lr: 9.9757e-05 | scale: 32768.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   4930/156230 | global iter:   4930/156230 | loss: 1.3101 | ds_loss: 1.3412 | lr: 9.9757e-05 | scale: 32768.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   4931/156230 | global iter:   4931/156230 | loss: 1.0097 | ds_loss: 1.0399 | lr: 9.9757e-05 | scale: 32768.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   4932/156230 | global iter:   4932/156230 | loss: 1.1808 | ds_loss: 1.1985 | lr: 9.9757e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4932/156230 | global iter:   4932/156230 | loss: 1.1506 | ds_loss: 1.1749 | lr: 9.9757e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4933/156230 | global iter:   4933/156230 | loss: 1.1780 | ds_loss: 1.2027 | lr: 9.9757e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   4934/156230 | global iter:   4934/156230 | loss: 1.0441 | ds_loss: 1.0502 | lr: 9.9756e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   4935/156230 | global iter:   4935/156230 | loss: 1.1635 | ds_loss: 1.1821 | lr: 9.9756e-05 | scale: 32768.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   4936/156230 | global iter:   4936/156230 | loss: 1.1963 | ds_loss: 1.2073 | lr: 9.9756e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4936/156230 | global iter:   4936/156230 | loss: 1.1455 | ds_loss: 1.1606 | lr: 9.9756e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4937/156230 | global iter:   4937/156230 | loss: 1.1563 | ds_loss: 1.1737 | lr: 9.9756e-05 | scale: 32768.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   4938/156230 | global iter:   4938/156230 | loss: 1.0082 | ds_loss: 1.0170 | lr: 9.9756e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   4939/156230 | global iter:   4939/156230 | loss: 1.0808 | ds_loss: 1.0902 | lr: 9.9756e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   4940/156230 | global iter:   4940/156230 | loss: 1.0275 | ds_loss: 1.0378 | lr: 9.9756e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4940/156230 | global iter:   4940/156230 | loss: 1.0682 | ds_loss: 1.0797 | lr: 9.9756e-05 | scale: 32768.0000 | micro time: 1.355 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4941/156230 | global iter:   4941/156230 | loss: 1.1628 | ds_loss: 1.1859 | lr: 9.9756e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   4942/156230 | global iter:   4942/156230 | loss: 1.0741 | ds_loss: 1.0857 | lr: 9.9756e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   4943/156230 | global iter:   4943/156230 | loss: 1.1008 | ds_loss: 1.1233 | lr: 9.9756e-05 | scale: 32768.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   4944/156230 | global iter:   4944/156230 | loss: 1.0605 | ds_loss: 1.0764 | lr: 9.9755e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4944/156230 | global iter:   4944/156230 | loss: 1.0995 | ds_loss: 1.1178 | lr: 9.9755e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4945/156230 | global iter:   4945/156230 | loss: 1.0561 | ds_loss: 1.0759 | lr: 9.9755e-05 | scale: 32768.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   4946/156230 | global iter:   4946/156230 | loss: 1.3074 | ds_loss: 1.3366 | lr: 9.9755e-05 | scale: 32768.0000 | micro time: 1.410 | step time: 0.000
train | epoch   0 | Iter:   4947/156230 | global iter:   4947/156230 | loss: 1.1727 | ds_loss: 1.1984 | lr: 9.9755e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   4948/156230 | global iter:   4948/156230 | loss: 1.2478 | ds_loss: 1.2478 | lr: 9.9755e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4948/156230 | global iter:   4948/156230 | loss: 1.1960 | ds_loss: 1.2147 | lr: 9.9755e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4949/156230 | global iter:   4949/156230 | loss: 1.1774 | ds_loss: 1.1922 | lr: 9.9755e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   4950/156230 | global iter:   4950/156230 | loss: 1.0918 | ds_loss: 1.1176 | lr: 9.9755e-05 | scale: 32768.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   4951/156230 | global iter:   4951/156230 | loss: 1.1712 | ds_loss: 1.1923 | lr: 9.9755e-05 | scale: 32768.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   4952/156230 | global iter:   4952/156230 | loss: 1.0492 | ds_loss: 1.0750 | lr: 9.9755e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4952/156230 | global iter:   4952/156230 | loss: 1.1224 | ds_loss: 1.1443 | lr: 9.9755e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4953/156230 | global iter:   4953/156230 | loss: 1.0902 | ds_loss: 1.1240 | lr: 9.9755e-05 | scale: 32768.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   4954/156230 | global iter:   4954/156230 | loss: 1.0669 | ds_loss: 1.0729 | lr: 9.9754e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   4955/156230 | global iter:   4955/156230 | loss: 1.3130 | ds_loss: 1.3295 | lr: 9.9754e-05 | scale: 32768.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   4956/156230 | global iter:   4956/156230 | loss: 1.1702 | ds_loss: 1.1822 | lr: 9.9754e-05 | scale: 32768.0000 | micro time: 1.323 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4956/156230 | global iter:   4956/156230 | loss: 1.1601 | ds_loss: 1.1771 | lr: 9.9754e-05 | scale: 32768.0000 | micro time: 1.323 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4957/156230 | global iter:   4957/156230 | loss: 1.0513 | ds_loss: 1.0726 | lr: 9.9754e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   4958/156230 | global iter:   4958/156230 | loss: 1.2424 | ds_loss: 1.2736 | lr: 9.9754e-05 | scale: 32768.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   4959/156230 | global iter:   4959/156230 | loss: 1.0033 | ds_loss: 1.0211 | lr: 9.9754e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   4960/156230 | global iter:   4960/156230 | loss: 1.0424 | ds_loss: 1.0529 | lr: 9.9754e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4960/156230 | global iter:   4960/156230 | loss: 1.0848 | ds_loss: 1.1051 | lr: 9.9754e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4961/156230 | global iter:   4961/156230 | loss: 1.0727 | ds_loss: 1.0790 | lr: 9.9754e-05 | scale: 32768.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   4962/156230 | global iter:   4962/156230 | loss: 1.1382 | ds_loss: 1.1727 | lr: 9.9754e-05 | scale: 32768.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   4963/156230 | global iter:   4963/156230 | loss: 0.9835 | ds_loss: 1.0033 | lr: 9.9754e-05 | scale: 32768.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   4964/156230 | global iter:   4964/156230 | loss: 1.1720 | ds_loss: 1.1764 | lr: 9.9753e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4964/156230 | global iter:   4964/156230 | loss: 1.0916 | ds_loss: 1.1079 | lr: 9.9753e-05 | scale: 32768.0000 | micro time: 1.368 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4965/156230 | global iter:   4965/156230 | loss: 1.0814 | ds_loss: 1.1006 | lr: 9.9753e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   4966/156230 | global iter:   4966/156230 | loss: 0.9750 | ds_loss: 1.0042 | lr: 9.9753e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   4967/156230 | global iter:   4967/156230 | loss: 1.2536 | ds_loss: 1.2593 | lr: 9.9753e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   4968/156230 | global iter:   4968/156230 | loss: 1.0872 | ds_loss: 1.1085 | lr: 9.9753e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4968/156230 | global iter:   4968/156230 | loss: 1.0993 | ds_loss: 1.1182 | lr: 9.9753e-05 | scale: 32768.0000 | micro time: 1.351 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4969/156230 | global iter:   4969/156230 | loss: 1.0049 | ds_loss: 1.0027 | lr: 9.9753e-05 | scale: 32768.0000 | micro time: 1.320 | step time: 0.000
train | epoch   0 | Iter:   4970/156230 | global iter:   4970/156230 | loss: 1.0432 | ds_loss: 1.0582 | lr: 9.9753e-05 | scale: 32768.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   4971/156230 | global iter:   4971/156230 | loss: 1.0725 | ds_loss: 1.0819 | lr: 9.9753e-05 | scale: 32768.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   4972/156230 | global iter:   4972/156230 | loss: 1.0209 | ds_loss: 1.0322 | lr: 9.9753e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4972/156230 | global iter:   4972/156230 | loss: 1.0354 | ds_loss: 1.0437 | lr: 9.9753e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4973/156230 | global iter:   4973/156230 | loss: 1.2945 | ds_loss: 1.3102 | lr: 9.9753e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   4974/156230 | global iter:   4974/156230 | loss: 1.1347 | ds_loss: 1.1508 | lr: 9.9752e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   4975/156230 | global iter:   4975/156230 | loss: 1.1846 | ds_loss: 1.2016 | lr: 9.9752e-05 | scale: 32768.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   4976/156230 | global iter:   4976/156230 | loss: 1.1429 | ds_loss: 1.1514 | lr: 9.9752e-05 | scale: 32768.0000 | micro time: 1.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4976/156230 | global iter:   4976/156230 | loss: 1.1892 | ds_loss: 1.2035 | lr: 9.9752e-05 | scale: 32768.0000 | micro time: 1.400 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4977/156230 | global iter:   4977/156230 | loss: 1.1215 | ds_loss: 1.1331 | lr: 9.9752e-05 | scale: 32768.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   4978/156230 | global iter:   4978/156230 | loss: 1.0935 | ds_loss: 1.1139 | lr: 9.9752e-05 | scale: 32768.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   4979/156230 | global iter:   4979/156230 | loss: 1.3155 | ds_loss: 1.3527 | lr: 9.9752e-05 | scale: 32768.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   4980/156230 | global iter:   4980/156230 | loss: 1.1109 | ds_loss: 1.1284 | lr: 9.9752e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4980/156230 | global iter:   4980/156230 | loss: 1.1603 | ds_loss: 1.1821 | lr: 9.9752e-05 | scale: 32768.0000 | micro time: 1.374 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4981/156230 | global iter:   4981/156230 | loss: 1.1769 | ds_loss: 1.1870 | lr: 9.9752e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   4982/156230 | global iter:   4982/156230 | loss: 1.1684 | ds_loss: 1.1899 | lr: 9.9752e-05 | scale: 32768.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   4983/156230 | global iter:   4983/156230 | loss: 1.1795 | ds_loss: 1.1971 | lr: 9.9752e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   4984/156230 | global iter:   4984/156230 | loss: 1.0932 | ds_loss: 1.1110 | lr: 9.9751e-05 | scale: 32768.0000 | micro time: 1.322 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4984/156230 | global iter:   4984/156230 | loss: 1.1545 | ds_loss: 1.1712 | lr: 9.9751e-05 | scale: 32768.0000 | micro time: 1.322 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4985/156230 | global iter:   4985/156230 | loss: 1.1822 | ds_loss: 1.2178 | lr: 9.9751e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   4986/156230 | global iter:   4986/156230 | loss: 1.2449 | ds_loss: 1.2685 | lr: 9.9751e-05 | scale: 32768.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   4987/156230 | global iter:   4987/156230 | loss: 0.9305 | ds_loss: 0.9426 | lr: 9.9751e-05 | scale: 32768.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   4988/156230 | global iter:   4988/156230 | loss: 1.1415 | ds_loss: 1.1625 | lr: 9.9751e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4988/156230 | global iter:   4988/156230 | loss: 1.1248 | ds_loss: 1.1479 | lr: 9.9751e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 1.343
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4989/156230 | global iter:   4989/156230 | loss: 1.2572 | ds_loss: 1.2734 | lr: 9.9751e-05 | scale: 32768.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   4990/156230 | global iter:   4990/156230 | loss: 1.0384 | ds_loss: 1.0572 | lr: 9.9751e-05 | scale: 32768.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   4991/156230 | global iter:   4991/156230 | loss: 1.2112 | ds_loss: 1.2231 | lr: 9.9751e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   4992/156230 | global iter:   4992/156230 | loss: 1.1142 | ds_loss: 1.1447 | lr: 9.9751e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4992/156230 | global iter:   4992/156230 | loss: 1.1552 | ds_loss: 1.1746 | lr: 9.9751e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4993/156230 | global iter:   4993/156230 | loss: 1.1921 | ds_loss: 1.2058 | lr: 9.9751e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   4994/156230 | global iter:   4994/156230 | loss: 1.0420 | ds_loss: 1.0575 | lr: 9.9750e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   4995/156230 | global iter:   4995/156230 | loss: 1.0101 | ds_loss: 1.0336 | lr: 9.9750e-05 | scale: 32768.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   4996/156230 | global iter:   4996/156230 | loss: 1.1681 | ds_loss: 1.1717 | lr: 9.9750e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   4996/156230 | global iter:   4996/156230 | loss: 1.1031 | ds_loss: 1.1172 | lr: 9.9750e-05 | scale: 32768.0000 | micro time: 1.371 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   4997/156230 | global iter:   4997/156230 | loss: 1.1251 | ds_loss: 1.1467 | lr: 9.9750e-05 | scale: 32768.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   4998/156230 | global iter:   4998/156230 | loss: 1.1853 | ds_loss: 1.2037 | lr: 9.9750e-05 | scale: 32768.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   4999/156230 | global iter:   4999/156230 | loss: 1.0412 | ds_loss: 1.0631 | lr: 9.9750e-05 | scale: 32768.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   5000/156230 | global iter:   5000/156230 | loss: 1.2433 | ds_loss: 1.2499 | lr: 9.9750e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5000/156230 | global iter:   5000/156230 | loss: 1.1487 | ds_loss: 1.1658 | lr: 9.9750e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5001/156230 | global iter:   5001/156230 | loss: 1.0909 | ds_loss: 1.1063 | lr: 9.9750e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   5002/156230 | global iter:   5002/156230 | loss: 0.9299 | ds_loss: 0.9467 | lr: 9.9750e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   5003/156230 | global iter:   5003/156230 | loss: 1.1069 | ds_loss: 1.1581 | lr: 9.9750e-05 | scale: 32768.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   5004/156230 | global iter:   5004/156230 | loss: 1.1525 | ds_loss: 1.1690 | lr: 9.9749e-05 | scale: 32768.0000 | micro time: 1.313 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5004/156230 | global iter:   5004/156230 | loss: 1.0700 | ds_loss: 1.0950 | lr: 9.9749e-05 | scale: 32768.0000 | micro time: 1.313 | step time: 1.343
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5005/156230 | global iter:   5005/156230 | loss: 1.0123 | ds_loss: 1.0290 | lr: 9.9749e-05 | scale: 32768.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   5006/156230 | global iter:   5006/156230 | loss: 1.0695 | ds_loss: 1.0707 | lr: 9.9749e-05 | scale: 32768.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   5007/156230 | global iter:   5007/156230 | loss: 1.1740 | ds_loss: 1.2079 | lr: 9.9749e-05 | scale: 32768.0000 | micro time: 1.325 | step time: 0.000
train | epoch   0 | Iter:   5008/156230 | global iter:   5008/156230 | loss: 1.0539 | ds_loss: 1.0396 | lr: 9.9749e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5008/156230 | global iter:   5008/156230 | loss: 1.0774 | ds_loss: 1.0868 | lr: 9.9749e-05 | scale: 32768.0000 | micro time: 1.357 | step time: 1.337
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5009/156230 | global iter:   5009/156230 | loss: 1.2393 | ds_loss: 1.2718 | lr: 9.9749e-05 | scale: 32768.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   5010/156230 | global iter:   5010/156230 | loss: 1.0647 | ds_loss: 1.0793 | lr: 9.9749e-05 | scale: 32768.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   5011/156230 | global iter:   5011/156230 | loss: 1.2154 | ds_loss: 1.2288 | lr: 9.9749e-05 | scale: 32768.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   5012/156230 | global iter:   5012/156230 | loss: 1.3168 | ds_loss: 1.3174 | lr: 9.9749e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5012/156230 | global iter:   5012/156230 | loss: 1.2091 | ds_loss: 1.2243 | lr: 9.9749e-05 | scale: 32768.0000 | micro time: 1.361 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5013/156230 | global iter:   5013/156230 | loss: 0.9934 | ds_loss: 1.0123 | lr: 9.9749e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   5014/156230 | global iter:   5014/156230 | loss: 1.0104 | ds_loss: 1.0162 | lr: 9.9748e-05 | scale: 32768.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   5015/156230 | global iter:   5015/156230 | loss: 1.0376 | ds_loss: 1.0617 | lr: 9.9748e-05 | scale: 32768.0000 | micro time: 1.409 | step time: 0.000
train | epoch   0 | Iter:   5016/156230 | global iter:   5016/156230 | loss: 0.9461 | ds_loss: 0.9505 | lr: 9.9748e-05 | scale: 32768.0000 | micro time: 1.317 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5016/156230 | global iter:   5016/156230 | loss: 0.9969 | ds_loss: 1.0102 | lr: 9.9748e-05 | scale: 32768.0000 | micro time: 1.317 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5017/156230 | global iter:   5017/156230 | loss: 1.1040 | ds_loss: 1.1343 | lr: 9.9748e-05 | scale: 32768.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   5018/156230 | global iter:   5018/156230 | loss: 1.1565 | ds_loss: 1.1886 | lr: 9.9748e-05 | scale: 32768.0000 | micro time: 1.325 | step time: 0.000
train | epoch   0 | Iter:   5019/156230 | global iter:   5019/156230 | loss: 1.1172 | ds_loss: 1.1346 | lr: 9.9748e-05 | scale: 32768.0000 | micro time: 1.441 | step time: 0.000
train | epoch   0 | Iter:   5020/156230 | global iter:   5020/156230 | loss: 1.1878 | ds_loss: 1.1983 | lr: 9.9748e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5020/156230 | global iter:   5020/156230 | loss: 1.1414 | ds_loss: 1.1639 | lr: 9.9748e-05 | scale: 32768.0000 | micro time: 1.349 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5021/156230 | global iter:   5021/156230 | loss: 1.1003 | ds_loss: 1.1024 | lr: 9.9748e-05 | scale: 32768.0000 | micro time: 1.322 | step time: 0.000
train | epoch   0 | Iter:   5022/156230 | global iter:   5022/156230 | loss: 1.0329 | ds_loss: 1.0589 | lr: 9.9748e-05 | scale: 32768.0000 | micro time: 1.312 | step time: 0.000
train | epoch   0 | Iter:   5023/156230 | global iter:   5023/156230 | loss: 1.2338 | ds_loss: 1.2463 | lr: 9.9748e-05 | scale: 32768.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   5024/156230 | global iter:   5024/156230 | loss: 1.0676 | ds_loss: 1.0648 | lr: 9.9747e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5024/156230 | global iter:   5024/156230 | loss: 1.1087 | ds_loss: 1.1181 | lr: 9.9747e-05 | scale: 32768.0000 | micro time: 1.342 | step time: 1.333
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5025/156230 | global iter:   5025/156230 | loss: 1.1379 | ds_loss: 1.1482 | lr: 9.9747e-05 | scale: 65536.0000 | micro time: 1.311 | step time: 0.000
train | epoch   0 | Iter:   5026/156230 | global iter:   5026/156230 | loss: 1.0508 | ds_loss: 1.0629 | lr: 9.9747e-05 | scale: 65536.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   5027/156230 | global iter:   5027/156230 | loss: 1.1033 | ds_loss: 1.1202 | lr: 9.9747e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   5028/156230 | global iter:   5028/156230 | loss: 0.9418 | ds_loss: 0.9507 | lr: 9.9747e-05 | scale: 65536.0000 | micro time: 1.401 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5028/156230 | global iter:   5028/156230 | loss: 1.0585 | ds_loss: 1.0705 | lr: 9.9747e-05 | scale: 65536.0000 | micro time: 1.401 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5029/156230 | global iter:   5029/156230 | loss: 1.1616 | ds_loss: 1.1976 | lr: 9.9747e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   5030/156230 | global iter:   5030/156230 | loss: 1.1930 | ds_loss: 1.2050 | lr: 9.9747e-05 | scale: 65536.0000 | micro time: 1.404 | step time: 0.000
train | epoch   0 | Iter:   5031/156230 | global iter:   5031/156230 | loss: 1.0019 | ds_loss: 1.0245 | lr: 9.9747e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   5032/156230 | global iter:   5032/156230 | loss: 1.0974 | ds_loss: 1.1019 | lr: 9.9747e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5032/156230 | global iter:   5032/156230 | loss: 1.1135 | ds_loss: 1.1323 | lr: 9.9747e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5033/156230 | global iter:   5033/156230 | loss: 1.1897 | ds_loss: 1.1892 | lr: 9.9747e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   5034/156230 | global iter:   5034/156230 | loss: 1.0997 | ds_loss: 1.1096 | lr: 9.9746e-05 | scale: 65536.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   5035/156230 | global iter:   5035/156230 | loss: 1.1086 | ds_loss: 1.1232 | lr: 9.9746e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   5036/156230 | global iter:   5036/156230 | loss: 1.2658 | ds_loss: 1.2682 | lr: 9.9746e-05 | scale: 65536.0000 | micro time: 1.326 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5036/156230 | global iter:   5036/156230 | loss: 1.1660 | ds_loss: 1.1725 | lr: 9.9746e-05 | scale: 65536.0000 | micro time: 1.326 | step time: 1.338
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5037/156230 | global iter:   5037/156230 | loss: 1.2217 | ds_loss: 1.2469 | lr: 9.9746e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   5038/156230 | global iter:   5038/156230 | loss: 1.1496 | ds_loss: 1.1784 | lr: 9.9746e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   5039/156230 | global iter:   5039/156230 | loss: 1.1555 | ds_loss: 1.1812 | lr: 9.9746e-05 | scale: 65536.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   5040/156230 | global iter:   5040/156230 | loss: 1.1057 | ds_loss: 1.1305 | lr: 9.9746e-05 | scale: 65536.0000 | micro time: 1.404 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5040/156230 | global iter:   5040/156230 | loss: 1.1581 | ds_loss: 1.1842 | lr: 9.9746e-05 | scale: 65536.0000 | micro time: 1.404 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5041/156230 | global iter:   5041/156230 | loss: 0.9106 | ds_loss: 0.9172 | lr: 9.9746e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   5042/156230 | global iter:   5042/156230 | loss: 1.1985 | ds_loss: 1.2184 | lr: 9.9746e-05 | scale: 65536.0000 | micro time: 1.321 | step time: 0.000
train | epoch   0 | Iter:   5043/156230 | global iter:   5043/156230 | loss: 1.2344 | ds_loss: 1.2551 | lr: 9.9746e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   5044/156230 | global iter:   5044/156230 | loss: 1.0087 | ds_loss: 1.0178 | lr: 9.9745e-05 | scale: 65536.0000 | micro time: 1.332 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5044/156230 | global iter:   5044/156230 | loss: 1.0881 | ds_loss: 1.1022 | lr: 9.9745e-05 | scale: 65536.0000 | micro time: 1.332 | step time: 1.344
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5045/156230 | global iter:   5045/156230 | loss: 1.1166 | ds_loss: 1.1372 | lr: 9.9745e-05 | scale: 65536.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   5046/156230 | global iter:   5046/156230 | loss: 0.9672 | ds_loss: 0.9899 | lr: 9.9745e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   5047/156230 | global iter:   5047/156230 | loss: 1.0820 | ds_loss: 1.0822 | lr: 9.9745e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   5048/156230 | global iter:   5048/156230 | loss: 1.4974 | ds_loss: 1.5282 | lr: 9.9745e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5048/156230 | global iter:   5048/156230 | loss: 1.1658 | ds_loss: 1.1844 | lr: 9.9745e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 1.347
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5049/156230 | global iter:   5049/156230 | loss: 1.0368 | ds_loss: 1.0416 | lr: 9.9745e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   5050/156230 | global iter:   5050/156230 | loss: 0.9845 | ds_loss: 1.0050 | lr: 9.9745e-05 | scale: 65536.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   5051/156230 | global iter:   5051/156230 | loss: 1.0930 | ds_loss: 1.1213 | lr: 9.9745e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   5052/156230 | global iter:   5052/156230 | loss: 1.0704 | ds_loss: 1.0860 | lr: 9.9745e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5052/156230 | global iter:   5052/156230 | loss: 1.0462 | ds_loss: 1.0635 | lr: 9.9745e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5053/156230 | global iter:   5053/156230 | loss: 0.9530 | ds_loss: 0.9724 | lr: 9.9745e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   5054/156230 | global iter:   5054/156230 | loss: 1.0888 | ds_loss: 1.0923 | lr: 9.9744e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   5055/156230 | global iter:   5055/156230 | loss: 1.0820 | ds_loss: 1.0825 | lr: 9.9744e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   5056/156230 | global iter:   5056/156230 | loss: 1.2789 | ds_loss: 1.3183 | lr: 9.9744e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5056/156230 | global iter:   5056/156230 | loss: 1.1007 | ds_loss: 1.1164 | lr: 9.9744e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5057/156230 | global iter:   5057/156230 | loss: 1.0909 | ds_loss: 1.1155 | lr: 9.9744e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   5058/156230 | global iter:   5058/156230 | loss: 1.2176 | ds_loss: 1.2143 | lr: 9.9744e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   5059/156230 | global iter:   5059/156230 | loss: 1.2731 | ds_loss: 1.3064 | lr: 9.9744e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   5060/156230 | global iter:   5060/156230 | loss: 1.1230 | ds_loss: 1.1305 | lr: 9.9744e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5060/156230 | global iter:   5060/156230 | loss: 1.1762 | ds_loss: 1.1917 | lr: 9.9744e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5061/156230 | global iter:   5061/156230 | loss: 1.1134 | ds_loss: 1.1186 | lr: 9.9744e-05 | scale: 65536.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   5062/156230 | global iter:   5062/156230 | loss: 1.1302 | ds_loss: 1.1416 | lr: 9.9744e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   5063/156230 | global iter:   5063/156230 | loss: 1.1406 | ds_loss: 1.1498 | lr: 9.9743e-05 | scale: 65536.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   5064/156230 | global iter:   5064/156230 | loss: 1.1894 | ds_loss: 1.2132 | lr: 9.9743e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5064/156230 | global iter:   5064/156230 | loss: 1.1434 | ds_loss: 1.1558 | lr: 9.9743e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5065/156230 | global iter:   5065/156230 | loss: 1.2720 | ds_loss: 1.2938 | lr: 9.9743e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   5066/156230 | global iter:   5066/156230 | loss: 1.0392 | ds_loss: 1.0639 | lr: 9.9743e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   5067/156230 | global iter:   5067/156230 | loss: 1.0628 | ds_loss: 1.0903 | lr: 9.9743e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   5068/156230 | global iter:   5068/156230 | loss: 0.9492 | ds_loss: 0.9845 | lr: 9.9743e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5068/156230 | global iter:   5068/156230 | loss: 1.0808 | ds_loss: 1.1081 | lr: 9.9743e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5069/156230 | global iter:   5069/156230 | loss: 1.1439 | ds_loss: 1.1503 | lr: 9.9743e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   5070/156230 | global iter:   5070/156230 | loss: 1.0729 | ds_loss: 1.0922 | lr: 9.9743e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   5071/156230 | global iter:   5071/156230 | loss: 0.8379 | ds_loss: 0.8650 | lr: 9.9743e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   5072/156230 | global iter:   5072/156230 | loss: 1.0508 | ds_loss: 1.0310 | lr: 9.9743e-05 | scale: 65536.0000 | micro time: 1.322 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5072/156230 | global iter:   5072/156230 | loss: 1.0264 | ds_loss: 1.0346 | lr: 9.9743e-05 | scale: 65536.0000 | micro time: 1.322 | step time: 1.346
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5073/156230 | global iter:   5073/156230 | loss: 1.1816 | ds_loss: 1.2136 | lr: 9.9742e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   5074/156230 | global iter:   5074/156230 | loss: 1.1883 | ds_loss: 1.1976 | lr: 9.9742e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   5075/156230 | global iter:   5075/156230 | loss: 1.2714 | ds_loss: 1.2955 | lr: 9.9742e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   5076/156230 | global iter:   5076/156230 | loss: 1.0646 | ds_loss: 1.0817 | lr: 9.9742e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5076/156230 | global iter:   5076/156230 | loss: 1.1765 | ds_loss: 1.1971 | lr: 9.9742e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5077/156230 | global iter:   5077/156230 | loss: 1.1173 | ds_loss: 1.1466 | lr: 9.9742e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   5078/156230 | global iter:   5078/156230 | loss: 1.1567 | ds_loss: 1.1638 | lr: 9.9742e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   5079/156230 | global iter:   5079/156230 | loss: 1.0206 | ds_loss: 1.0423 | lr: 9.9742e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   5080/156230 | global iter:   5080/156230 | loss: 1.1820 | ds_loss: 1.1975 | lr: 9.9742e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5080/156230 | global iter:   5080/156230 | loss: 1.1192 | ds_loss: 1.1375 | lr: 9.9742e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5081/156230 | global iter:   5081/156230 | loss: 1.0481 | ds_loss: 1.0664 | lr: 9.9742e-05 | scale: 65536.0000 | micro time: 1.408 | step time: 0.000
train | epoch   0 | Iter:   5082/156230 | global iter:   5082/156230 | loss: 1.2790 | ds_loss: 1.3007 | lr: 9.9742e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   5083/156230 | global iter:   5083/156230 | loss: 1.1113 | ds_loss: 1.1287 | lr: 9.9741e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   5084/156230 | global iter:   5084/156230 | loss: 1.1156 | ds_loss: 1.1382 | lr: 9.9741e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5084/156230 | global iter:   5084/156230 | loss: 1.1385 | ds_loss: 1.1585 | lr: 9.9741e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 1.382
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5085/156230 | global iter:   5085/156230 | loss: 1.1086 | ds_loss: 1.1095 | lr: 9.9741e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   5086/156230 | global iter:   5086/156230 | loss: 1.1456 | ds_loss: 1.1587 | lr: 9.9741e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   5087/156230 | global iter:   5087/156230 | loss: 1.2502 | ds_loss: 1.2819 | lr: 9.9741e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   5088/156230 | global iter:   5088/156230 | loss: 1.1050 | ds_loss: 1.1122 | lr: 9.9741e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5088/156230 | global iter:   5088/156230 | loss: 1.1524 | ds_loss: 1.1656 | lr: 9.9741e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5089/156230 | global iter:   5089/156230 | loss: 1.0618 | ds_loss: 1.0717 | lr: 9.9741e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   5090/156230 | global iter:   5090/156230 | loss: 1.1654 | ds_loss: 1.1893 | lr: 9.9741e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   5091/156230 | global iter:   5091/156230 | loss: 1.1698 | ds_loss: 1.1757 | lr: 9.9741e-05 | scale: 65536.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   5092/156230 | global iter:   5092/156230 | loss: 1.2279 | ds_loss: 1.2393 | lr: 9.9741e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5092/156230 | global iter:   5092/156230 | loss: 1.1562 | ds_loss: 1.1690 | lr: 9.9741e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5093/156230 | global iter:   5093/156230 | loss: 0.8324 | ds_loss: 0.8466 | lr: 9.9740e-05 | scale: 65536.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   5094/156230 | global iter:   5094/156230 | loss: 1.0080 | ds_loss: 1.0232 | lr: 9.9740e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   5095/156230 | global iter:   5095/156230 | loss: 1.1393 | ds_loss: 1.1541 | lr: 9.9740e-05 | scale: 65536.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:   5096/156230 | global iter:   5096/156230 | loss: 1.3722 | ds_loss: 1.3970 | lr: 9.9740e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5096/156230 | global iter:   5096/156230 | loss: 1.0880 | ds_loss: 1.1052 | lr: 9.9740e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 1.343
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5097/156230 | global iter:   5097/156230 | loss: 1.1244 | ds_loss: 1.1447 | lr: 9.9740e-05 | scale: 65536.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   5098/156230 | global iter:   5098/156230 | loss: 1.1828 | ds_loss: 1.1979 | lr: 9.9740e-05 | scale: 65536.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   5099/156230 | global iter:   5099/156230 | loss: 1.1986 | ds_loss: 1.2053 | lr: 9.9740e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   5100/156230 | global iter:   5100/156230 | loss: 1.1657 | ds_loss: 1.1760 | lr: 9.9740e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5100/156230 | global iter:   5100/156230 | loss: 1.1679 | ds_loss: 1.1810 | lr: 9.9740e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5101/156230 | global iter:   5101/156230 | loss: 0.9664 | ds_loss: 0.9851 | lr: 9.9740e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   5102/156230 | global iter:   5102/156230 | loss: 1.1916 | ds_loss: 1.2097 | lr: 9.9740e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   5103/156230 | global iter:   5103/156230 | loss: 1.1554 | ds_loss: 1.1774 | lr: 9.9739e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   5104/156230 | global iter:   5104/156230 | loss: 1.4680 | ds_loss: 1.4886 | lr: 9.9739e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5104/156230 | global iter:   5104/156230 | loss: 1.1954 | ds_loss: 1.2152 | lr: 9.9739e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5105/156230 | global iter:   5105/156230 | loss: 1.2632 | ds_loss: 1.2866 | lr: 9.9739e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   5106/156230 | global iter:   5106/156230 | loss: 1.1334 | ds_loss: 1.1434 | lr: 9.9739e-05 | scale: 65536.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   5107/156230 | global iter:   5107/156230 | loss: 1.0801 | ds_loss: 1.1053 | lr: 9.9739e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   5108/156230 | global iter:   5108/156230 | loss: 1.2078 | ds_loss: 1.2201 | lr: 9.9739e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5108/156230 | global iter:   5108/156230 | loss: 1.1711 | ds_loss: 1.1888 | lr: 9.9739e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5109/156230 | global iter:   5109/156230 | loss: 1.2633 | ds_loss: 1.2662 | lr: 9.9739e-05 | scale: 65536.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   5110/156230 | global iter:   5110/156230 | loss: 1.0652 | ds_loss: 1.0495 | lr: 9.9739e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   5111/156230 | global iter:   5111/156230 | loss: 1.1536 | ds_loss: 1.1503 | lr: 9.9739e-05 | scale: 65536.0000 | micro time: 1.318 | step time: 0.000
train | epoch   0 | Iter:   5112/156230 | global iter:   5112/156230 | loss: 0.9427 | ds_loss: 0.9483 | lr: 9.9738e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5112/156230 | global iter:   5112/156230 | loss: 1.1062 | ds_loss: 1.1036 | lr: 9.9738e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 1.347
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5113/156230 | global iter:   5113/156230 | loss: 1.1560 | ds_loss: 1.1763 | lr: 9.9738e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   5114/156230 | global iter:   5114/156230 | loss: 1.3142 | ds_loss: 1.3246 | lr: 9.9738e-05 | scale: 65536.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   5115/156230 | global iter:   5115/156230 | loss: 1.1368 | ds_loss: 1.1531 | lr: 9.9738e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   5116/156230 | global iter:   5116/156230 | loss: 1.2032 | ds_loss: 1.2065 | lr: 9.9738e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5116/156230 | global iter:   5116/156230 | loss: 1.2025 | ds_loss: 1.2151 | lr: 9.9738e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5117/156230 | global iter:   5117/156230 | loss: 1.1359 | ds_loss: 1.1498 | lr: 9.9738e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   5118/156230 | global iter:   5118/156230 | loss: 1.1189 | ds_loss: 1.1307 | lr: 9.9738e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   5119/156230 | global iter:   5119/156230 | loss: 1.1134 | ds_loss: 1.1414 | lr: 9.9738e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   5120/156230 | global iter:   5120/156230 | loss: 1.0696 | ds_loss: 1.0898 | lr: 9.9738e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5120/156230 | global iter:   5120/156230 | loss: 1.1094 | ds_loss: 1.1279 | lr: 9.9738e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5121/156230 | global iter:   5121/156230 | loss: 1.0894 | ds_loss: 1.1100 | lr: 9.9738e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   5122/156230 | global iter:   5122/156230 | loss: 1.1125 | ds_loss: 1.1166 | lr: 9.9737e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   5123/156230 | global iter:   5123/156230 | loss: 1.1885 | ds_loss: 1.1999 | lr: 9.9737e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   5124/156230 | global iter:   5124/156230 | loss: 1.0416 | ds_loss: 1.0568 | lr: 9.9737e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5124/156230 | global iter:   5124/156230 | loss: 1.1080 | ds_loss: 1.1208 | lr: 9.9737e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5125/156230 | global iter:   5125/156230 | loss: 1.1098 | ds_loss: 1.1288 | lr: 9.9737e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   5126/156230 | global iter:   5126/156230 | loss: 1.0057 | ds_loss: 1.0107 | lr: 9.9737e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   5127/156230 | global iter:   5127/156230 | loss: 1.1405 | ds_loss: 1.1418 | lr: 9.9737e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   5128/156230 | global iter:   5128/156230 | loss: 0.8480 | ds_loss: 0.8754 | lr: 9.9737e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5128/156230 | global iter:   5128/156230 | loss: 1.0260 | ds_loss: 1.0392 | lr: 9.9737e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 1.345
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5129/156230 | global iter:   5129/156230 | loss: 0.9653 | ds_loss: 0.9802 | lr: 9.9737e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   5130/156230 | global iter:   5130/156230 | loss: 1.2836 | ds_loss: 1.2915 | lr: 9.9737e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   5131/156230 | global iter:   5131/156230 | loss: 1.0970 | ds_loss: 1.1285 | lr: 9.9737e-05 | scale: 65536.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   5132/156230 | global iter:   5132/156230 | loss: 1.2592 | ds_loss: 1.2755 | lr: 9.9736e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5132/156230 | global iter:   5132/156230 | loss: 1.1513 | ds_loss: 1.1689 | lr: 9.9736e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5133/156230 | global iter:   5133/156230 | loss: 1.1528 | ds_loss: 1.1736 | lr: 9.9736e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   5134/156230 | global iter:   5134/156230 | loss: 1.0106 | ds_loss: 1.0210 | lr: 9.9736e-05 | scale: 65536.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   5135/156230 | global iter:   5135/156230 | loss: 1.1134 | ds_loss: 1.1262 | lr: 9.9736e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   5136/156230 | global iter:   5136/156230 | loss: 0.9434 | ds_loss: 0.9603 | lr: 9.9736e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5136/156230 | global iter:   5136/156230 | loss: 1.0550 | ds_loss: 1.0703 | lr: 9.9736e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5137/156230 | global iter:   5137/156230 | loss: 1.0691 | ds_loss: 1.0796 | lr: 9.9736e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   5138/156230 | global iter:   5138/156230 | loss: 1.1829 | ds_loss: 1.2062 | lr: 9.9736e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   5139/156230 | global iter:   5139/156230 | loss: 1.3347 | ds_loss: 1.3353 | lr: 9.9736e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   5140/156230 | global iter:   5140/156230 | loss: 1.1756 | ds_loss: 1.2003 | lr: 9.9736e-05 | scale: 65536.0000 | micro time: 1.405 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5140/156230 | global iter:   5140/156230 | loss: 1.1906 | ds_loss: 1.2054 | lr: 9.9736e-05 | scale: 65536.0000 | micro time: 1.405 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5141/156230 | global iter:   5141/156230 | loss: 0.9753 | ds_loss: 0.9901 | lr: 9.9735e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   5142/156230 | global iter:   5142/156230 | loss: 1.1594 | ds_loss: 1.1787 | lr: 9.9735e-05 | scale: 65536.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   5143/156230 | global iter:   5143/156230 | loss: 1.0444 | ds_loss: 1.0649 | lr: 9.9735e-05 | scale: 65536.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   5144/156230 | global iter:   5144/156230 | loss: 1.0039 | ds_loss: 1.0256 | lr: 9.9735e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5144/156230 | global iter:   5144/156230 | loss: 1.0457 | ds_loss: 1.0648 | lr: 9.9735e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5145/156230 | global iter:   5145/156230 | loss: 1.0265 | ds_loss: 1.0429 | lr: 9.9735e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   5146/156230 | global iter:   5146/156230 | loss: 1.1468 | ds_loss: 1.1653 | lr: 9.9735e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   5147/156230 | global iter:   5147/156230 | loss: 1.1062 | ds_loss: 1.1175 | lr: 9.9735e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   5148/156230 | global iter:   5148/156230 | loss: 1.0487 | ds_loss: 1.0650 | lr: 9.9735e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5148/156230 | global iter:   5148/156230 | loss: 1.0820 | ds_loss: 1.0977 | lr: 9.9735e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5149/156230 | global iter:   5149/156230 | loss: 1.1323 | ds_loss: 1.1518 | lr: 9.9735e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   5150/156230 | global iter:   5150/156230 | loss: 1.1463 | ds_loss: 1.1795 | lr: 9.9735e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   5151/156230 | global iter:   5151/156230 | loss: 1.1160 | ds_loss: 1.1267 | lr: 9.9734e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   5152/156230 | global iter:   5152/156230 | loss: 1.0966 | ds_loss: 1.0863 | lr: 9.9734e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5152/156230 | global iter:   5152/156230 | loss: 1.1228 | ds_loss: 1.1361 | lr: 9.9734e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5153/156230 | global iter:   5153/156230 | loss: 1.0039 | ds_loss: 1.0149 | lr: 9.9734e-05 | scale: 65536.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   5154/156230 | global iter:   5154/156230 | loss: 1.2497 | ds_loss: 1.2488 | lr: 9.9734e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   5155/156230 | global iter:   5155/156230 | loss: 1.2995 | ds_loss: 1.3220 | lr: 9.9734e-05 | scale: 65536.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   5156/156230 | global iter:   5156/156230 | loss: 0.8931 | ds_loss: 0.9062 | lr: 9.9734e-05 | scale: 65536.0000 | micro time: 1.325 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5156/156230 | global iter:   5156/156230 | loss: 1.1116 | ds_loss: 1.1230 | lr: 9.9734e-05 | scale: 65536.0000 | micro time: 1.325 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5157/156230 | global iter:   5157/156230 | loss: 1.0025 | ds_loss: 1.0158 | lr: 9.9734e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   5158/156230 | global iter:   5158/156230 | loss: 1.1957 | ds_loss: 1.2131 | lr: 9.9734e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   5159/156230 | global iter:   5159/156230 | loss: 1.1710 | ds_loss: 1.1994 | lr: 9.9734e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   5160/156230 | global iter:   5160/156230 | loss: 1.2473 | ds_loss: 1.2474 | lr: 9.9734e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5160/156230 | global iter:   5160/156230 | loss: 1.1541 | ds_loss: 1.1689 | lr: 9.9734e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5161/156230 | global iter:   5161/156230 | loss: 1.0125 | ds_loss: 1.0361 | lr: 9.9733e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   5162/156230 | global iter:   5162/156230 | loss: 1.2365 | ds_loss: 1.2356 | lr: 9.9733e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   5163/156230 | global iter:   5163/156230 | loss: 1.2261 | ds_loss: 1.2493 | lr: 9.9733e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   5164/156230 | global iter:   5164/156230 | loss: 1.1890 | ds_loss: 1.1797 | lr: 9.9733e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5164/156230 | global iter:   5164/156230 | loss: 1.1660 | ds_loss: 1.1752 | lr: 9.9733e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5165/156230 | global iter:   5165/156230 | loss: 1.0177 | ds_loss: 1.0556 | lr: 9.9733e-05 | scale: 65536.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   5166/156230 | global iter:   5166/156230 | loss: 1.1796 | ds_loss: 1.2043 | lr: 9.9733e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   5167/156230 | global iter:   5167/156230 | loss: 1.0752 | ds_loss: 1.1006 | lr: 9.9733e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   5168/156230 | global iter:   5168/156230 | loss: 1.0668 | ds_loss: 1.0736 | lr: 9.9733e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5168/156230 | global iter:   5168/156230 | loss: 1.0848 | ds_loss: 1.1085 | lr: 9.9733e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5169/156230 | global iter:   5169/156230 | loss: 1.0481 | ds_loss: 1.0659 | lr: 9.9733e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   5170/156230 | global iter:   5170/156230 | loss: 1.1979 | ds_loss: 1.2047 | lr: 9.9732e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   5171/156230 | global iter:   5171/156230 | loss: 1.1883 | ds_loss: 1.2116 | lr: 9.9732e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   5172/156230 | global iter:   5172/156230 | loss: 1.2486 | ds_loss: 1.2618 | lr: 9.9732e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5172/156230 | global iter:   5172/156230 | loss: 1.1707 | ds_loss: 1.1860 | lr: 9.9732e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5173/156230 | global iter:   5173/156230 | loss: 1.1988 | ds_loss: 1.2223 | lr: 9.9732e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   5174/156230 | global iter:   5174/156230 | loss: 1.2762 | ds_loss: 1.3087 | lr: 9.9732e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   5175/156230 | global iter:   5175/156230 | loss: 1.1544 | ds_loss: 1.1580 | lr: 9.9732e-05 | scale: 65536.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   5176/156230 | global iter:   5176/156230 | loss: 1.1691 | ds_loss: 1.2047 | lr: 9.9732e-05 | scale: 65536.0000 | micro time: 1.325 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5176/156230 | global iter:   5176/156230 | loss: 1.1996 | ds_loss: 1.2235 | lr: 9.9732e-05 | scale: 65536.0000 | micro time: 1.325 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5177/156230 | global iter:   5177/156230 | loss: 1.3087 | ds_loss: 1.3294 | lr: 9.9732e-05 | scale: 65536.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   5178/156230 | global iter:   5178/156230 | loss: 1.1129 | ds_loss: 1.1240 | lr: 9.9732e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   5179/156230 | global iter:   5179/156230 | loss: 1.1894 | ds_loss: 1.1833 | lr: 9.9732e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   5180/156230 | global iter:   5180/156230 | loss: 1.3117 | ds_loss: 1.3223 | lr: 9.9731e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5180/156230 | global iter:   5180/156230 | loss: 1.2307 | ds_loss: 1.2397 | lr: 9.9731e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5181/156230 | global iter:   5181/156230 | loss: 1.2278 | ds_loss: 1.2423 | lr: 9.9731e-05 | scale: 65536.0000 | micro time: 1.308 | step time: 0.000
train | epoch   0 | Iter:   5182/156230 | global iter:   5182/156230 | loss: 1.1253 | ds_loss: 1.1335 | lr: 9.9731e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   5183/156230 | global iter:   5183/156230 | loss: 1.0663 | ds_loss: 1.1016 | lr: 9.9731e-05 | scale: 65536.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   5184/156230 | global iter:   5184/156230 | loss: 1.2548 | ds_loss: 1.2774 | lr: 9.9731e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5184/156230 | global iter:   5184/156230 | loss: 1.1685 | ds_loss: 1.1887 | lr: 9.9731e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5185/156230 | global iter:   5185/156230 | loss: 1.1457 | ds_loss: 1.1655 | lr: 9.9731e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   5186/156230 | global iter:   5186/156230 | loss: 0.8985 | ds_loss: 0.9269 | lr: 9.9731e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   5187/156230 | global iter:   5187/156230 | loss: 1.1876 | ds_loss: 1.2077 | lr: 9.9731e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   5188/156230 | global iter:   5188/156230 | loss: 1.1403 | ds_loss: 1.1472 | lr: 9.9731e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5188/156230 | global iter:   5188/156230 | loss: 1.0930 | ds_loss: 1.1118 | lr: 9.9731e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5189/156230 | global iter:   5189/156230 | loss: 1.0658 | ds_loss: 1.0793 | lr: 9.9731e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   5190/156230 | global iter:   5190/156230 | loss: 1.1535 | ds_loss: 1.1742 | lr: 9.9730e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   5191/156230 | global iter:   5191/156230 | loss: 1.2942 | ds_loss: 1.3007 | lr: 9.9730e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   5192/156230 | global iter:   5192/156230 | loss: 1.1088 | ds_loss: 1.1057 | lr: 9.9730e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5192/156230 | global iter:   5192/156230 | loss: 1.1556 | ds_loss: 1.1650 | lr: 9.9730e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5193/156230 | global iter:   5193/156230 | loss: 1.0875 | ds_loss: 1.1035 | lr: 9.9730e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   5194/156230 | global iter:   5194/156230 | loss: 1.1145 | ds_loss: 1.1366 | lr: 9.9730e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   5195/156230 | global iter:   5195/156230 | loss: 1.2172 | ds_loss: 1.2239 | lr: 9.9730e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   5196/156230 | global iter:   5196/156230 | loss: 0.9181 | ds_loss: 0.9517 | lr: 9.9730e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5196/156230 | global iter:   5196/156230 | loss: 1.0843 | ds_loss: 1.1039 | lr: 9.9730e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5197/156230 | global iter:   5197/156230 | loss: 1.2519 | ds_loss: 1.2809 | lr: 9.9730e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   5198/156230 | global iter:   5198/156230 | loss: 1.0763 | ds_loss: 1.0714 | lr: 9.9730e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   5199/156230 | global iter:   5199/156230 | loss: 1.0959 | ds_loss: 1.0965 | lr: 9.9729e-05 | scale: 65536.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   5200/156230 | global iter:   5200/156230 | loss: 1.1614 | ds_loss: 1.1923 | lr: 9.9729e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5200/156230 | global iter:   5200/156230 | loss: 1.1464 | ds_loss: 1.1603 | lr: 9.9729e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5201/156230 | global iter:   5201/156230 | loss: 1.1685 | ds_loss: 1.1851 | lr: 9.9729e-05 | scale: 65536.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   5202/156230 | global iter:   5202/156230 | loss: 1.0958 | ds_loss: 1.1215 | lr: 9.9729e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   5203/156230 | global iter:   5203/156230 | loss: 0.9952 | ds_loss: 1.0025 | lr: 9.9729e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   5204/156230 | global iter:   5204/156230 | loss: 0.9602 | ds_loss: 0.9741 | lr: 9.9729e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5204/156230 | global iter:   5204/156230 | loss: 1.0549 | ds_loss: 1.0708 | lr: 9.9729e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5205/156230 | global iter:   5205/156230 | loss: 1.1627 | ds_loss: 1.1912 | lr: 9.9729e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   5206/156230 | global iter:   5206/156230 | loss: 1.0444 | ds_loss: 1.0573 | lr: 9.9729e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   5207/156230 | global iter:   5207/156230 | loss: 1.1995 | ds_loss: 1.2151 | lr: 9.9729e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   5208/156230 | global iter:   5208/156230 | loss: 1.1132 | ds_loss: 1.1162 | lr: 9.9729e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5208/156230 | global iter:   5208/156230 | loss: 1.1300 | ds_loss: 1.1449 | lr: 9.9729e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 1.342
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5209/156230 | global iter:   5209/156230 | loss: 1.2415 | ds_loss: 1.2460 | lr: 9.9728e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   5210/156230 | global iter:   5210/156230 | loss: 0.9177 | ds_loss: 0.9367 | lr: 9.9728e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   5211/156230 | global iter:   5211/156230 | loss: 1.1220 | ds_loss: 1.1439 | lr: 9.9728e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   5212/156230 | global iter:   5212/156230 | loss: 1.1595 | ds_loss: 1.1627 | lr: 9.9728e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5212/156230 | global iter:   5212/156230 | loss: 1.1102 | ds_loss: 1.1223 | lr: 9.9728e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5213/156230 | global iter:   5213/156230 | loss: 1.0708 | ds_loss: 1.1090 | lr: 9.9728e-05 | scale: 65536.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:   5214/156230 | global iter:   5214/156230 | loss: 1.0156 | ds_loss: 1.0433 | lr: 9.9728e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   5215/156230 | global iter:   5215/156230 | loss: 0.9803 | ds_loss: 1.0152 | lr: 9.9728e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   5216/156230 | global iter:   5216/156230 | loss: 1.2107 | ds_loss: 1.2178 | lr: 9.9728e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5216/156230 | global iter:   5216/156230 | loss: 1.0693 | ds_loss: 1.0963 | lr: 9.9728e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5217/156230 | global iter:   5217/156230 | loss: 0.8076 | ds_loss: 0.8163 | lr: 9.9728e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   5218/156230 | global iter:   5218/156230 | loss: 1.0867 | ds_loss: 1.1021 | lr: 9.9727e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   5219/156230 | global iter:   5219/156230 | loss: 1.2942 | ds_loss: 1.3081 | lr: 9.9727e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   5220/156230 | global iter:   5220/156230 | loss: 1.1345 | ds_loss: 1.1479 | lr: 9.9727e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5220/156230 | global iter:   5220/156230 | loss: 1.0808 | ds_loss: 1.0936 | lr: 9.9727e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5221/156230 | global iter:   5221/156230 | loss: 1.0994 | ds_loss: 1.1113 | lr: 9.9727e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   5222/156230 | global iter:   5222/156230 | loss: 1.4010 | ds_loss: 1.4105 | lr: 9.9727e-05 | scale: 65536.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   5223/156230 | global iter:   5223/156230 | loss: 1.2535 | ds_loss: 1.2424 | lr: 9.9727e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   5224/156230 | global iter:   5224/156230 | loss: 1.0453 | ds_loss: 1.0725 | lr: 9.9727e-05 | scale: 65536.0000 | micro time: 1.322 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5224/156230 | global iter:   5224/156230 | loss: 1.1998 | ds_loss: 1.2092 | lr: 9.9727e-05 | scale: 65536.0000 | micro time: 1.322 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5225/156230 | global iter:   5225/156230 | loss: 1.1784 | ds_loss: 1.2032 | lr: 9.9727e-05 | scale: 65536.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:   5226/156230 | global iter:   5226/156230 | loss: 1.1473 | ds_loss: 1.1578 | lr: 9.9727e-05 | scale: 65536.0000 | micro time: 1.320 | step time: 0.000
train | epoch   0 | Iter:   5227/156230 | global iter:   5227/156230 | loss: 1.1815 | ds_loss: 1.2093 | lr: 9.9727e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   5228/156230 | global iter:   5228/156230 | loss: 0.9711 | ds_loss: 0.9938 | lr: 9.9726e-05 | scale: 65536.0000 | micro time: 1.403 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5228/156230 | global iter:   5228/156230 | loss: 1.1196 | ds_loss: 1.1410 | lr: 9.9726e-05 | scale: 65536.0000 | micro time: 1.403 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5229/156230 | global iter:   5229/156230 | loss: 1.0249 | ds_loss: 1.0469 | lr: 9.9726e-05 | scale: 65536.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   5230/156230 | global iter:   5230/156230 | loss: 1.2316 | ds_loss: 1.2512 | lr: 9.9726e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   5231/156230 | global iter:   5231/156230 | loss: 1.0665 | ds_loss: 1.0807 | lr: 9.9726e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   5232/156230 | global iter:   5232/156230 | loss: 0.9080 | ds_loss: 0.8970 | lr: 9.9726e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5232/156230 | global iter:   5232/156230 | loss: 1.0578 | ds_loss: 1.0689 | lr: 9.9726e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5233/156230 | global iter:   5233/156230 | loss: 1.0418 | ds_loss: 1.0384 | lr: 9.9726e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   5234/156230 | global iter:   5234/156230 | loss: 1.0277 | ds_loss: 1.0516 | lr: 9.9726e-05 | scale: 65536.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   5235/156230 | global iter:   5235/156230 | loss: 1.1707 | ds_loss: 1.1814 | lr: 9.9726e-05 | scale: 65536.0000 | micro time: 1.316 | step time: 0.000
train | epoch   0 | Iter:   5236/156230 | global iter:   5236/156230 | loss: 1.0650 | ds_loss: 1.0728 | lr: 9.9726e-05 | scale: 65536.0000 | micro time: 1.326 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5236/156230 | global iter:   5236/156230 | loss: 1.0763 | ds_loss: 1.0860 | lr: 9.9726e-05 | scale: 65536.0000 | micro time: 1.326 | step time: 1.343
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5237/156230 | global iter:   5237/156230 | loss: 1.1376 | ds_loss: 1.1534 | lr: 9.9725e-05 | scale: 65536.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   5238/156230 | global iter:   5238/156230 | loss: 1.1267 | ds_loss: 1.1474 | lr: 9.9725e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   5239/156230 | global iter:   5239/156230 | loss: 1.1752 | ds_loss: 1.1858 | lr: 9.9725e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   5240/156230 | global iter:   5240/156230 | loss: 1.3822 | ds_loss: 1.4096 | lr: 9.9725e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5240/156230 | global iter:   5240/156230 | loss: 1.2054 | ds_loss: 1.2241 | lr: 9.9725e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5241/156230 | global iter:   5241/156230 | loss: 1.1366 | ds_loss: 1.1547 | lr: 9.9725e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   5242/156230 | global iter:   5242/156230 | loss: 1.1687 | ds_loss: 1.1943 | lr: 9.9725e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   5243/156230 | global iter:   5243/156230 | loss: 1.2180 | ds_loss: 1.2318 | lr: 9.9725e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   5244/156230 | global iter:   5244/156230 | loss: 1.1915 | ds_loss: 1.1998 | lr: 9.9725e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5244/156230 | global iter:   5244/156230 | loss: 1.1787 | ds_loss: 1.1951 | lr: 9.9725e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5245/156230 | global iter:   5245/156230 | loss: 1.1389 | ds_loss: 1.1702 | lr: 9.9725e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   5246/156230 | global iter:   5246/156230 | loss: 1.0159 | ds_loss: 1.0406 | lr: 9.9725e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   5247/156230 | global iter:   5247/156230 | loss: 1.0410 | ds_loss: 1.0482 | lr: 9.9724e-05 | scale: 65536.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   5248/156230 | global iter:   5248/156230 | loss: 0.9614 | ds_loss: 0.9731 | lr: 9.9724e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5248/156230 | global iter:   5248/156230 | loss: 1.0393 | ds_loss: 1.0580 | lr: 9.9724e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5249/156230 | global iter:   5249/156230 | loss: 1.1763 | ds_loss: 1.1850 | lr: 9.9724e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   5250/156230 | global iter:   5250/156230 | loss: 1.2506 | ds_loss: 1.2667 | lr: 9.9724e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   5251/156230 | global iter:   5251/156230 | loss: 1.0167 | ds_loss: 1.0382 | lr: 9.9724e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   5252/156230 | global iter:   5252/156230 | loss: 0.9955 | ds_loss: 1.0166 | lr: 9.9724e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5252/156230 | global iter:   5252/156230 | loss: 1.1098 | ds_loss: 1.1266 | lr: 9.9724e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5253/156230 | global iter:   5253/156230 | loss: 1.0729 | ds_loss: 1.0681 | lr: 9.9724e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   5254/156230 | global iter:   5254/156230 | loss: 0.8069 | ds_loss: 0.8142 | lr: 9.9724e-05 | scale: 65536.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   5255/156230 | global iter:   5255/156230 | loss: 1.0642 | ds_loss: 1.0998 | lr: 9.9724e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   5256/156230 | global iter:   5256/156230 | loss: 0.9404 | ds_loss: 0.9667 | lr: 9.9723e-05 | scale: 65536.0000 | micro time: 1.389 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5256/156230 | global iter:   5256/156230 | loss: 0.9711 | ds_loss: 0.9872 | lr: 9.9723e-05 | scale: 65536.0000 | micro time: 1.389 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5257/156230 | global iter:   5257/156230 | loss: 1.1686 | ds_loss: 1.1982 | lr: 9.9723e-05 | scale: 65536.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   5258/156230 | global iter:   5258/156230 | loss: 0.9709 | ds_loss: 0.9796 | lr: 9.9723e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   5259/156230 | global iter:   5259/156230 | loss: 1.3134 | ds_loss: 1.3359 | lr: 9.9723e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   5260/156230 | global iter:   5260/156230 | loss: 1.1877 | ds_loss: 1.2050 | lr: 9.9723e-05 | scale: 65536.0000 | micro time: 1.323 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5260/156230 | global iter:   5260/156230 | loss: 1.1601 | ds_loss: 1.1797 | lr: 9.9723e-05 | scale: 65536.0000 | micro time: 1.323 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5261/156230 | global iter:   5261/156230 | loss: 1.1478 | ds_loss: 1.1637 | lr: 9.9723e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   5262/156230 | global iter:   5262/156230 | loss: 1.0316 | ds_loss: 1.0407 | lr: 9.9723e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   5263/156230 | global iter:   5263/156230 | loss: 1.1942 | ds_loss: 1.2137 | lr: 9.9723e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   5264/156230 | global iter:   5264/156230 | loss: 0.9467 | ds_loss: 0.9804 | lr: 9.9723e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5264/156230 | global iter:   5264/156230 | loss: 1.0801 | ds_loss: 1.0996 | lr: 9.9723e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5265/156230 | global iter:   5265/156230 | loss: 1.0975 | ds_loss: 1.1170 | lr: 9.9723e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   5266/156230 | global iter:   5266/156230 | loss: 1.0316 | ds_loss: 1.0496 | lr: 9.9722e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   5267/156230 | global iter:   5267/156230 | loss: 0.9549 | ds_loss: 0.9618 | lr: 9.9722e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   5268/156230 | global iter:   5268/156230 | loss: 1.0601 | ds_loss: 1.0918 | lr: 9.9722e-05 | scale: 65536.0000 | micro time: 1.331 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5268/156230 | global iter:   5268/156230 | loss: 1.0360 | ds_loss: 1.0551 | lr: 9.9722e-05 | scale: 65536.0000 | micro time: 1.331 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5269/156230 | global iter:   5269/156230 | loss: 1.0989 | ds_loss: 1.1024 | lr: 9.9722e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   5270/156230 | global iter:   5270/156230 | loss: 1.0271 | ds_loss: 1.0333 | lr: 9.9722e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   5271/156230 | global iter:   5271/156230 | loss: 1.0910 | ds_loss: 1.1284 | lr: 9.9722e-05 | scale: 65536.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   5272/156230 | global iter:   5272/156230 | loss: 1.0240 | ds_loss: 1.0598 | lr: 9.9722e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5272/156230 | global iter:   5272/156230 | loss: 1.0603 | ds_loss: 1.0810 | lr: 9.9722e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5273/156230 | global iter:   5273/156230 | loss: 1.1957 | ds_loss: 1.2108 | lr: 9.9722e-05 | scale: 65536.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   5274/156230 | global iter:   5274/156230 | loss: 1.1649 | ds_loss: 1.1656 | lr: 9.9722e-05 | scale: 65536.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   5275/156230 | global iter:   5275/156230 | loss: 1.3069 | ds_loss: 1.3255 | lr: 9.9721e-05 | scale: 65536.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:   5276/156230 | global iter:   5276/156230 | loss: 1.0718 | ds_loss: 1.0776 | lr: 9.9721e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5276/156230 | global iter:   5276/156230 | loss: 1.1848 | ds_loss: 1.1949 | lr: 9.9721e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5277/156230 | global iter:   5277/156230 | loss: 1.2598 | ds_loss: 1.2846 | lr: 9.9721e-05 | scale: 65536.0000 | micro time: 1.424 | step time: 0.000
train | epoch   0 | Iter:   5278/156230 | global iter:   5278/156230 | loss: 1.0333 | ds_loss: 1.0341 | lr: 9.9721e-05 | scale: 65536.0000 | micro time: 1.321 | step time: 0.000
train | epoch   0 | Iter:   5279/156230 | global iter:   5279/156230 | loss: 1.0513 | ds_loss: 1.0766 | lr: 9.9721e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   5280/156230 | global iter:   5280/156230 | loss: 0.9668 | ds_loss: 0.9835 | lr: 9.9721e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5280/156230 | global iter:   5280/156230 | loss: 1.0778 | ds_loss: 1.0947 | lr: 9.9721e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5281/156230 | global iter:   5281/156230 | loss: 1.1251 | ds_loss: 1.1529 | lr: 9.9721e-05 | scale: 65536.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   5282/156230 | global iter:   5282/156230 | loss: 1.2016 | ds_loss: 1.2134 | lr: 9.9721e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   5283/156230 | global iter:   5283/156230 | loss: 1.0244 | ds_loss: 1.0256 | lr: 9.9721e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   5284/156230 | global iter:   5284/156230 | loss: 1.2781 | ds_loss: 1.2790 | lr: 9.9721e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5284/156230 | global iter:   5284/156230 | loss: 1.1573 | ds_loss: 1.1677 | lr: 9.9721e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5285/156230 | global iter:   5285/156230 | loss: 1.1414 | ds_loss: 1.1559 | lr: 9.9720e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   5286/156230 | global iter:   5286/156230 | loss: 0.9531 | ds_loss: 0.9610 | lr: 9.9720e-05 | scale: 65536.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   5287/156230 | global iter:   5287/156230 | loss: 0.9036 | ds_loss: 0.9119 | lr: 9.9720e-05 | scale: 65536.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   5288/156230 | global iter:   5288/156230 | loss: 1.0102 | ds_loss: 1.0353 | lr: 9.9720e-05 | scale: 65536.0000 | micro time: 1.339 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5288/156230 | global iter:   5288/156230 | loss: 1.0021 | ds_loss: 1.0160 | lr: 9.9720e-05 | scale: 65536.0000 | micro time: 1.339 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5289/156230 | global iter:   5289/156230 | loss: 1.1911 | ds_loss: 1.2076 | lr: 9.9720e-05 | scale: 65536.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   5290/156230 | global iter:   5290/156230 | loss: 1.1203 | ds_loss: 1.1298 | lr: 9.9720e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   5291/156230 | global iter:   5291/156230 | loss: 1.1003 | ds_loss: 1.1008 | lr: 9.9720e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   5292/156230 | global iter:   5292/156230 | loss: 1.1348 | ds_loss: 1.1339 | lr: 9.9720e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5292/156230 | global iter:   5292/156230 | loss: 1.1366 | ds_loss: 1.1430 | lr: 9.9720e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5293/156230 | global iter:   5293/156230 | loss: 1.0703 | ds_loss: 1.0938 | lr: 9.9720e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   5294/156230 | global iter:   5294/156230 | loss: 1.1361 | ds_loss: 1.1596 | lr: 9.9719e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   5295/156230 | global iter:   5295/156230 | loss: 1.0370 | ds_loss: 1.0511 | lr: 9.9719e-05 | scale: 65536.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   5296/156230 | global iter:   5296/156230 | loss: 1.3030 | ds_loss: 1.3163 | lr: 9.9719e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5296/156230 | global iter:   5296/156230 | loss: 1.1366 | ds_loss: 1.1552 | lr: 9.9719e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5297/156230 | global iter:   5297/156230 | loss: 1.1338 | ds_loss: 1.1713 | lr: 9.9719e-05 | scale: 65536.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   5298/156230 | global iter:   5298/156230 | loss: 1.1719 | ds_loss: 1.1794 | lr: 9.9719e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   5299/156230 | global iter:   5299/156230 | loss: 1.2889 | ds_loss: 1.3190 | lr: 9.9719e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   5300/156230 | global iter:   5300/156230 | loss: 1.2396 | ds_loss: 1.2520 | lr: 9.9719e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5300/156230 | global iter:   5300/156230 | loss: 1.2086 | ds_loss: 1.2304 | lr: 9.9719e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5301/156230 | global iter:   5301/156230 | loss: 1.2051 | ds_loss: 1.2215 | lr: 9.9719e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   5302/156230 | global iter:   5302/156230 | loss: 1.0893 | ds_loss: 1.1191 | lr: 9.9719e-05 | scale: 65536.0000 | micro time: 1.412 | step time: 0.000
train | epoch   0 | Iter:   5303/156230 | global iter:   5303/156230 | loss: 1.2295 | ds_loss: 1.2395 | lr: 9.9719e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   5304/156230 | global iter:   5304/156230 | loss: 1.0467 | ds_loss: 1.0658 | lr: 9.9718e-05 | scale: 65536.0000 | micro time: 1.389 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5304/156230 | global iter:   5304/156230 | loss: 1.1426 | ds_loss: 1.1615 | lr: 9.9718e-05 | scale: 65536.0000 | micro time: 1.389 | step time: 1.376
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5305/156230 | global iter:   5305/156230 | loss: 0.9996 | ds_loss: 1.0365 | lr: 9.9718e-05 | scale: 65536.0000 | micro time: 1.322 | step time: 0.000
train | epoch   0 | Iter:   5306/156230 | global iter:   5306/156230 | loss: 1.0562 | ds_loss: 1.0544 | lr: 9.9718e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   5307/156230 | global iter:   5307/156230 | loss: 1.0165 | ds_loss: 1.0398 | lr: 9.9718e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   5308/156230 | global iter:   5308/156230 | loss: 1.2510 | ds_loss: 1.2701 | lr: 9.9718e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5308/156230 | global iter:   5308/156230 | loss: 1.0808 | ds_loss: 1.1002 | lr: 9.9718e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5309/156230 | global iter:   5309/156230 | loss: 1.0520 | ds_loss: 1.0735 | lr: 9.9718e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   5310/156230 | global iter:   5310/156230 | loss: 0.8943 | ds_loss: 0.9169 | lr: 9.9718e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   5311/156230 | global iter:   5311/156230 | loss: 1.2822 | ds_loss: 1.2978 | lr: 9.9718e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   5312/156230 | global iter:   5312/156230 | loss: 1.1426 | ds_loss: 1.1462 | lr: 9.9718e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5312/156230 | global iter:   5312/156230 | loss: 1.0928 | ds_loss: 1.1086 | lr: 9.9718e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 1.348
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5313/156230 | global iter:   5313/156230 | loss: 1.1978 | ds_loss: 1.2037 | lr: 9.9717e-05 | scale: 65536.0000 | micro time: 1.312 | step time: 0.000
train | epoch   0 | Iter:   5314/156230 | global iter:   5314/156230 | loss: 1.0820 | ds_loss: 1.1150 | lr: 9.9717e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   5315/156230 | global iter:   5315/156230 | loss: 0.9829 | ds_loss: 1.0011 | lr: 9.9717e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   5316/156230 | global iter:   5316/156230 | loss: 1.0807 | ds_loss: 1.0936 | lr: 9.9717e-05 | scale: 65536.0000 | micro time: 1.322 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5316/156230 | global iter:   5316/156230 | loss: 1.0858 | ds_loss: 1.1033 | lr: 9.9717e-05 | scale: 65536.0000 | micro time: 1.322 | step time: 1.341
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5317/156230 | global iter:   5317/156230 | loss: 1.2313 | ds_loss: 1.2477 | lr: 9.9717e-05 | scale: 65536.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   5318/156230 | global iter:   5318/156230 | loss: 1.1665 | ds_loss: 1.1798 | lr: 9.9717e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   5319/156230 | global iter:   5319/156230 | loss: 0.9267 | ds_loss: 0.9435 | lr: 9.9717e-05 | scale: 65536.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   5320/156230 | global iter:   5320/156230 | loss: 0.9328 | ds_loss: 0.9351 | lr: 9.9717e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5320/156230 | global iter:   5320/156230 | loss: 1.0643 | ds_loss: 1.0765 | lr: 9.9717e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5321/156230 | global iter:   5321/156230 | loss: 1.1088 | ds_loss: 1.1228 | lr: 9.9717e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   5322/156230 | global iter:   5322/156230 | loss: 1.1850 | ds_loss: 1.2075 | lr: 9.9716e-05 | scale: 65536.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   5323/156230 | global iter:   5323/156230 | loss: 1.0902 | ds_loss: 1.1036 | lr: 9.9716e-05 | scale: 65536.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   5324/156230 | global iter:   5324/156230 | loss: 0.9836 | ds_loss: 1.0033 | lr: 9.9716e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5324/156230 | global iter:   5324/156230 | loss: 1.0919 | ds_loss: 1.1093 | lr: 9.9716e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5325/156230 | global iter:   5325/156230 | loss: 1.1336 | ds_loss: 1.1481 | lr: 9.9716e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   5326/156230 | global iter:   5326/156230 | loss: 1.0916 | ds_loss: 1.1101 | lr: 9.9716e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   5327/156230 | global iter:   5327/156230 | loss: 1.1714 | ds_loss: 1.1846 | lr: 9.9716e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   5328/156230 | global iter:   5328/156230 | loss: 1.0070 | ds_loss: 1.0092 | lr: 9.9716e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5328/156230 | global iter:   5328/156230 | loss: 1.1009 | ds_loss: 1.1130 | lr: 9.9716e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5329/156230 | global iter:   5329/156230 | loss: 1.2263 | ds_loss: 1.2317 | lr: 9.9716e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   5330/156230 | global iter:   5330/156230 | loss: 1.0087 | ds_loss: 1.0263 | lr: 9.9716e-05 | scale: 65536.0000 | micro time: 1.308 | step time: 0.000
train | epoch   0 | Iter:   5331/156230 | global iter:   5331/156230 | loss: 0.9694 | ds_loss: 0.9968 | lr: 9.9716e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   5332/156230 | global iter:   5332/156230 | loss: 1.1020 | ds_loss: 1.1189 | lr: 9.9715e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5332/156230 | global iter:   5332/156230 | loss: 1.0766 | ds_loss: 1.0934 | lr: 9.9715e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 1.347
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5333/156230 | global iter:   5333/156230 | loss: 0.9140 | ds_loss: 0.9205 | lr: 9.9715e-05 | scale: 65536.0000 | micro time: 1.402 | step time: 0.000
train | epoch   0 | Iter:   5334/156230 | global iter:   5334/156230 | loss: 1.2776 | ds_loss: 1.3007 | lr: 9.9715e-05 | scale: 65536.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   5335/156230 | global iter:   5335/156230 | loss: 1.0063 | ds_loss: 1.0293 | lr: 9.9715e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   5336/156230 | global iter:   5336/156230 | loss: 1.0435 | ds_loss: 1.0560 | lr: 9.9715e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5336/156230 | global iter:   5336/156230 | loss: 1.0603 | ds_loss: 1.0766 | lr: 9.9715e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5337/156230 | global iter:   5337/156230 | loss: 1.1750 | ds_loss: 1.1960 | lr: 9.9715e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   5338/156230 | global iter:   5338/156230 | loss: 0.9618 | ds_loss: 0.9787 | lr: 9.9715e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   5339/156230 | global iter:   5339/156230 | loss: 1.0191 | ds_loss: 1.0480 | lr: 9.9715e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   5340/156230 | global iter:   5340/156230 | loss: 0.9742 | ds_loss: 0.9971 | lr: 9.9715e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5340/156230 | global iter:   5340/156230 | loss: 1.0325 | ds_loss: 1.0549 | lr: 9.9715e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5341/156230 | global iter:   5341/156230 | loss: 1.2277 | ds_loss: 1.2545 | lr: 9.9714e-05 | scale: 65536.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   5342/156230 | global iter:   5342/156230 | loss: 1.1811 | ds_loss: 1.2050 | lr: 9.9714e-05 | scale: 65536.0000 | micro time: 1.402 | step time: 0.000
train | epoch   0 | Iter:   5343/156230 | global iter:   5343/156230 | loss: 1.1606 | ds_loss: 1.1596 | lr: 9.9714e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   5344/156230 | global iter:   5344/156230 | loss: 1.0444 | ds_loss: 1.0556 | lr: 9.9714e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5344/156230 | global iter:   5344/156230 | loss: 1.1534 | ds_loss: 1.1687 | lr: 9.9714e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5345/156230 | global iter:   5345/156230 | loss: 1.1198 | ds_loss: 1.1414 | lr: 9.9714e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   5346/156230 | global iter:   5346/156230 | loss: 1.2158 | ds_loss: 1.2156 | lr: 9.9714e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   5347/156230 | global iter:   5347/156230 | loss: 1.0825 | ds_loss: 1.0871 | lr: 9.9714e-05 | scale: 65536.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   5348/156230 | global iter:   5348/156230 | loss: 1.1198 | ds_loss: 1.1223 | lr: 9.9714e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5348/156230 | global iter:   5348/156230 | loss: 1.1345 | ds_loss: 1.1416 | lr: 9.9714e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5349/156230 | global iter:   5349/156230 | loss: 1.0736 | ds_loss: 1.0910 | lr: 9.9714e-05 | scale: 65536.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   5350/156230 | global iter:   5350/156230 | loss: 1.1290 | ds_loss: 1.1424 | lr: 9.9713e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   5351/156230 | global iter:   5351/156230 | loss: 1.3138 | ds_loss: 1.3597 | lr: 9.9713e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   5352/156230 | global iter:   5352/156230 | loss: 0.9163 | ds_loss: 0.9339 | lr: 9.9713e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5352/156230 | global iter:   5352/156230 | loss: 1.1082 | ds_loss: 1.1318 | lr: 9.9713e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5353/156230 | global iter:   5353/156230 | loss: 1.2543 | ds_loss: 1.2680 | lr: 9.9713e-05 | scale: 65536.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   5354/156230 | global iter:   5354/156230 | loss: 0.9258 | ds_loss: 0.9475 | lr: 9.9713e-05 | scale: 65536.0000 | micro time: 1.405 | step time: 0.000
train | epoch   0 | Iter:   5355/156230 | global iter:   5355/156230 | loss: 1.3468 | ds_loss: 1.3577 | lr: 9.9713e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   5356/156230 | global iter:   5356/156230 | loss: 1.0991 | ds_loss: 1.1308 | lr: 9.9713e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5356/156230 | global iter:   5356/156230 | loss: 1.1565 | ds_loss: 1.1760 | lr: 9.9713e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5357/156230 | global iter:   5357/156230 | loss: 1.1934 | ds_loss: 1.2028 | lr: 9.9713e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   5358/156230 | global iter:   5358/156230 | loss: 1.1784 | ds_loss: 1.2006 | lr: 9.9713e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   5359/156230 | global iter:   5359/156230 | loss: 0.9337 | ds_loss: 0.9697 | lr: 9.9713e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   5360/156230 | global iter:   5360/156230 | loss: 1.0701 | ds_loss: 1.0789 | lr: 9.9712e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5360/156230 | global iter:   5360/156230 | loss: 1.0939 | ds_loss: 1.1130 | lr: 9.9712e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5361/156230 | global iter:   5361/156230 | loss: 1.1774 | ds_loss: 1.2022 | lr: 9.9712e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   5362/156230 | global iter:   5362/156230 | loss: 1.2703 | ds_loss: 1.3079 | lr: 9.9712e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   5363/156230 | global iter:   5363/156230 | loss: 1.0737 | ds_loss: 1.0972 | lr: 9.9712e-05 | scale: 65536.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:   5364/156230 | global iter:   5364/156230 | loss: 1.0485 | ds_loss: 1.0593 | lr: 9.9712e-05 | scale: 65536.0000 | micro time: 1.403 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5364/156230 | global iter:   5364/156230 | loss: 1.1425 | ds_loss: 1.1667 | lr: 9.9712e-05 | scale: 65536.0000 | micro time: 1.403 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5365/156230 | global iter:   5365/156230 | loss: 1.1769 | ds_loss: 1.2046 | lr: 9.9712e-05 | scale: 65536.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   5366/156230 | global iter:   5366/156230 | loss: 1.1407 | ds_loss: 1.1448 | lr: 9.9712e-05 | scale: 65536.0000 | micro time: 1.424 | step time: 0.000
train | epoch   0 | Iter:   5367/156230 | global iter:   5367/156230 | loss: 1.3115 | ds_loss: 1.3239 | lr: 9.9712e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   5368/156230 | global iter:   5368/156230 | loss: 0.9539 | ds_loss: 0.9688 | lr: 9.9712e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5368/156230 | global iter:   5368/156230 | loss: 1.1458 | ds_loss: 1.1605 | lr: 9.9712e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5369/156230 | global iter:   5369/156230 | loss: 1.3346 | ds_loss: 1.3425 | lr: 9.9711e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   5370/156230 | global iter:   5370/156230 | loss: 0.9710 | ds_loss: 0.9895 | lr: 9.9711e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   5371/156230 | global iter:   5371/156230 | loss: 1.1959 | ds_loss: 1.2231 | lr: 9.9711e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   5372/156230 | global iter:   5372/156230 | loss: 1.0407 | ds_loss: 1.0599 | lr: 9.9711e-05 | scale: 65536.0000 | micro time: 1.319 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5372/156230 | global iter:   5372/156230 | loss: 1.1356 | ds_loss: 1.1537 | lr: 9.9711e-05 | scale: 65536.0000 | micro time: 1.319 | step time: 1.346
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5373/156230 | global iter:   5373/156230 | loss: 1.0898 | ds_loss: 1.0893 | lr: 9.9711e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   5374/156230 | global iter:   5374/156230 | loss: 1.0910 | ds_loss: 1.1150 | lr: 9.9711e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   5375/156230 | global iter:   5375/156230 | loss: 1.0858 | ds_loss: 1.1036 | lr: 9.9711e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   5376/156230 | global iter:   5376/156230 | loss: 1.0456 | ds_loss: 1.0532 | lr: 9.9711e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5376/156230 | global iter:   5376/156230 | loss: 1.0781 | ds_loss: 1.0903 | lr: 9.9711e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5377/156230 | global iter:   5377/156230 | loss: 1.1920 | ds_loss: 1.1768 | lr: 9.9711e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   5378/156230 | global iter:   5378/156230 | loss: 1.1412 | ds_loss: 1.1360 | lr: 9.9710e-05 | scale: 65536.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   5379/156230 | global iter:   5379/156230 | loss: 1.2603 | ds_loss: 1.2857 | lr: 9.9710e-05 | scale: 65536.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   5380/156230 | global iter:   5380/156230 | loss: 1.1122 | ds_loss: 1.1357 | lr: 9.9710e-05 | scale: 65536.0000 | micro time: 1.383 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5380/156230 | global iter:   5380/156230 | loss: 1.1764 | ds_loss: 1.1836 | lr: 9.9710e-05 | scale: 65536.0000 | micro time: 1.383 | step time: 1.384
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5381/156230 | global iter:   5381/156230 | loss: 0.9556 | ds_loss: 0.9741 | lr: 9.9710e-05 | scale: 65536.0000 | micro time: 1.320 | step time: 0.000
train | epoch   0 | Iter:   5382/156230 | global iter:   5382/156230 | loss: 1.2308 | ds_loss: 1.2506 | lr: 9.9710e-05 | scale: 65536.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   5383/156230 | global iter:   5383/156230 | loss: 1.0228 | ds_loss: 1.0258 | lr: 9.9710e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   5384/156230 | global iter:   5384/156230 | loss: 1.0887 | ds_loss: 1.1153 | lr: 9.9710e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5384/156230 | global iter:   5384/156230 | loss: 1.0745 | ds_loss: 1.0915 | lr: 9.9710e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5385/156230 | global iter:   5385/156230 | loss: 0.9954 | ds_loss: 1.0059 | lr: 9.9710e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   5386/156230 | global iter:   5386/156230 | loss: 1.0308 | ds_loss: 1.0397 | lr: 9.9710e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   5387/156230 | global iter:   5387/156230 | loss: 1.0529 | ds_loss: 1.0555 | lr: 9.9709e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   5388/156230 | global iter:   5388/156230 | loss: 0.8762 | ds_loss: 0.9047 | lr: 9.9709e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5388/156230 | global iter:   5388/156230 | loss: 0.9888 | ds_loss: 1.0014 | lr: 9.9709e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 1.347
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5389/156230 | global iter:   5389/156230 | loss: 1.0174 | ds_loss: 1.0425 | lr: 9.9709e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   5390/156230 | global iter:   5390/156230 | loss: 0.9966 | ds_loss: 1.0292 | lr: 9.9709e-05 | scale: 65536.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   5391/156230 | global iter:   5391/156230 | loss: 1.2358 | ds_loss: 1.2537 | lr: 9.9709e-05 | scale: 65536.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   5392/156230 | global iter:   5392/156230 | loss: 1.0047 | ds_loss: 1.0179 | lr: 9.9709e-05 | scale: 65536.0000 | micro time: 1.343 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5392/156230 | global iter:   5392/156230 | loss: 1.0636 | ds_loss: 1.0858 | lr: 9.9709e-05 | scale: 65536.0000 | micro time: 1.343 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5393/156230 | global iter:   5393/156230 | loss: 1.1264 | ds_loss: 1.1562 | lr: 9.9709e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   5394/156230 | global iter:   5394/156230 | loss: 1.0573 | ds_loss: 1.0662 | lr: 9.9709e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   5395/156230 | global iter:   5395/156230 | loss: 1.0143 | ds_loss: 1.0353 | lr: 9.9709e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   5396/156230 | global iter:   5396/156230 | loss: 1.1533 | ds_loss: 1.1651 | lr: 9.9709e-05 | scale: 65536.0000 | micro time: 1.322 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5396/156230 | global iter:   5396/156230 | loss: 1.0878 | ds_loss: 1.1057 | lr: 9.9709e-05 | scale: 65536.0000 | micro time: 1.322 | step time: 1.343
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5397/156230 | global iter:   5397/156230 | loss: 1.1836 | ds_loss: 1.2039 | lr: 9.9708e-05 | scale: 65536.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   5398/156230 | global iter:   5398/156230 | loss: 0.9664 | ds_loss: 0.9721 | lr: 9.9708e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   5399/156230 | global iter:   5399/156230 | loss: 1.0530 | ds_loss: 1.0774 | lr: 9.9708e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   5400/156230 | global iter:   5400/156230 | loss: 1.1979 | ds_loss: 1.2022 | lr: 9.9708e-05 | scale: 65536.0000 | micro time: 1.389 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5400/156230 | global iter:   5400/156230 | loss: 1.1002 | ds_loss: 1.1139 | lr: 9.9708e-05 | scale: 65536.0000 | micro time: 1.389 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5401/156230 | global iter:   5401/156230 | loss: 1.1240 | ds_loss: 1.1430 | lr: 9.9708e-05 | scale: 65536.0000 | micro time: 1.319 | step time: 0.000
train | epoch   0 | Iter:   5402/156230 | global iter:   5402/156230 | loss: 1.1788 | ds_loss: 1.1938 | lr: 9.9708e-05 | scale: 65536.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   5403/156230 | global iter:   5403/156230 | loss: 1.2186 | ds_loss: 1.2306 | lr: 9.9708e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   5404/156230 | global iter:   5404/156230 | loss: 1.0770 | ds_loss: 1.1034 | lr: 9.9708e-05 | scale: 65536.0000 | micro time: 1.308 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5404/156230 | global iter:   5404/156230 | loss: 1.1496 | ds_loss: 1.1677 | lr: 9.9708e-05 | scale: 65536.0000 | micro time: 1.308 | step time: 1.343
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5405/156230 | global iter:   5405/156230 | loss: 1.1569 | ds_loss: 1.1910 | lr: 9.9708e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   5406/156230 | global iter:   5406/156230 | loss: 1.2759 | ds_loss: 1.2881 | lr: 9.9707e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   5407/156230 | global iter:   5407/156230 | loss: 1.3498 | ds_loss: 1.3826 | lr: 9.9707e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   5408/156230 | global iter:   5408/156230 | loss: 1.2347 | ds_loss: 1.2489 | lr: 9.9707e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5408/156230 | global iter:   5408/156230 | loss: 1.2543 | ds_loss: 1.2776 | lr: 9.9707e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5409/156230 | global iter:   5409/156230 | loss: 1.1962 | ds_loss: 1.2051 | lr: 9.9707e-05 | scale: 65536.0000 | micro time: 1.411 | step time: 0.000
train | epoch   0 | Iter:   5410/156230 | global iter:   5410/156230 | loss: 1.1681 | ds_loss: 1.1716 | lr: 9.9707e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   5411/156230 | global iter:   5411/156230 | loss: 1.1599 | ds_loss: 1.1680 | lr: 9.9707e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   5412/156230 | global iter:   5412/156230 | loss: 1.0309 | ds_loss: 1.0611 | lr: 9.9707e-05 | scale: 65536.0000 | micro time: 1.311 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5412/156230 | global iter:   5412/156230 | loss: 1.1388 | ds_loss: 1.1515 | lr: 9.9707e-05 | scale: 65536.0000 | micro time: 1.311 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5413/156230 | global iter:   5413/156230 | loss: 1.1123 | ds_loss: 1.1299 | lr: 9.9707e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   5414/156230 | global iter:   5414/156230 | loss: 1.0576 | ds_loss: 1.0777 | lr: 9.9707e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   5415/156230 | global iter:   5415/156230 | loss: 1.0462 | ds_loss: 1.0775 | lr: 9.9706e-05 | scale: 65536.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   5416/156230 | global iter:   5416/156230 | loss: 1.1790 | ds_loss: 1.2072 | lr: 9.9706e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5416/156230 | global iter:   5416/156230 | loss: 1.0988 | ds_loss: 1.1231 | lr: 9.9706e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5417/156230 | global iter:   5417/156230 | loss: 0.9308 | ds_loss: 0.9463 | lr: 9.9706e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   5418/156230 | global iter:   5418/156230 | loss: 1.0854 | ds_loss: 1.1097 | lr: 9.9706e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   5419/156230 | global iter:   5419/156230 | loss: 1.0427 | ds_loss: 1.0614 | lr: 9.9706e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   5420/156230 | global iter:   5420/156230 | loss: 1.0860 | ds_loss: 1.0871 | lr: 9.9706e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5420/156230 | global iter:   5420/156230 | loss: 1.0362 | ds_loss: 1.0511 | lr: 9.9706e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5421/156230 | global iter:   5421/156230 | loss: 0.9919 | ds_loss: 1.0196 | lr: 9.9706e-05 | scale: 65536.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   5422/156230 | global iter:   5422/156230 | loss: 1.0850 | ds_loss: 1.0969 | lr: 9.9706e-05 | scale: 65536.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   5423/156230 | global iter:   5423/156230 | loss: 1.0860 | ds_loss: 1.1169 | lr: 9.9706e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   5424/156230 | global iter:   5424/156230 | loss: 1.0863 | ds_loss: 1.0910 | lr: 9.9705e-05 | scale: 65536.0000 | micro time: 1.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5424/156230 | global iter:   5424/156230 | loss: 1.0623 | ds_loss: 1.0811 | lr: 9.9705e-05 | scale: 65536.0000 | micro time: 1.400 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5425/156230 | global iter:   5425/156230 | loss: 1.3173 | ds_loss: 1.3487 | lr: 9.9705e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   5426/156230 | global iter:   5426/156230 | loss: 1.1259 | ds_loss: 1.1342 | lr: 9.9705e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   5427/156230 | global iter:   5427/156230 | loss: 0.9858 | ds_loss: 0.9961 | lr: 9.9705e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   5428/156230 | global iter:   5428/156230 | loss: 0.9927 | ds_loss: 0.9981 | lr: 9.9705e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5428/156230 | global iter:   5428/156230 | loss: 1.1054 | ds_loss: 1.1193 | lr: 9.9705e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5429/156230 | global iter:   5429/156230 | loss: 1.0984 | ds_loss: 1.1086 | lr: 9.9705e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   5430/156230 | global iter:   5430/156230 | loss: 1.1605 | ds_loss: 1.1903 | lr: 9.9705e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   5431/156230 | global iter:   5431/156230 | loss: 1.1343 | ds_loss: 1.1492 | lr: 9.9705e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   5432/156230 | global iter:   5432/156230 | loss: 1.1701 | ds_loss: 1.2063 | lr: 9.9705e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5432/156230 | global iter:   5432/156230 | loss: 1.1408 | ds_loss: 1.1636 | lr: 9.9705e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5433/156230 | global iter:   5433/156230 | loss: 1.0713 | ds_loss: 1.1048 | lr: 9.9704e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   5434/156230 | global iter:   5434/156230 | loss: 1.2200 | ds_loss: 1.2400 | lr: 9.9704e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   5435/156230 | global iter:   5435/156230 | loss: 1.1428 | ds_loss: 1.1668 | lr: 9.9704e-05 | scale: 65536.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   5436/156230 | global iter:   5436/156230 | loss: 1.0882 | ds_loss: 1.1015 | lr: 9.9704e-05 | scale: 65536.0000 | micro time: 1.329 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5436/156230 | global iter:   5436/156230 | loss: 1.1306 | ds_loss: 1.1533 | lr: 9.9704e-05 | scale: 65536.0000 | micro time: 1.329 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5437/156230 | global iter:   5437/156230 | loss: 1.2480 | ds_loss: 1.2870 | lr: 9.9704e-05 | scale: 65536.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   5438/156230 | global iter:   5438/156230 | loss: 0.9946 | ds_loss: 1.0124 | lr: 9.9704e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   5439/156230 | global iter:   5439/156230 | loss: 1.0690 | ds_loss: 1.0841 | lr: 9.9704e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   5440/156230 | global iter:   5440/156230 | loss: 1.0840 | ds_loss: 1.1009 | lr: 9.9704e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5440/156230 | global iter:   5440/156230 | loss: 1.0989 | ds_loss: 1.1211 | lr: 9.9704e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5441/156230 | global iter:   5441/156230 | loss: 1.1016 | ds_loss: 1.1232 | lr: 9.9704e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   5442/156230 | global iter:   5442/156230 | loss: 1.1186 | ds_loss: 1.1483 | lr: 9.9704e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   5443/156230 | global iter:   5443/156230 | loss: 1.1741 | ds_loss: 1.1895 | lr: 9.9703e-05 | scale: 65536.0000 | micro time: 1.320 | step time: 0.000
train | epoch   0 | Iter:   5444/156230 | global iter:   5444/156230 | loss: 1.1044 | ds_loss: 1.1239 | lr: 9.9703e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5444/156230 | global iter:   5444/156230 | loss: 1.1247 | ds_loss: 1.1462 | lr: 9.9703e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5445/156230 | global iter:   5445/156230 | loss: 1.1165 | ds_loss: 1.1234 | lr: 9.9703e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   5446/156230 | global iter:   5446/156230 | loss: 1.1432 | ds_loss: 1.1621 | lr: 9.9703e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   5447/156230 | global iter:   5447/156230 | loss: 1.1258 | ds_loss: 1.1343 | lr: 9.9703e-05 | scale: 65536.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   5448/156230 | global iter:   5448/156230 | loss: 1.1621 | ds_loss: 1.1647 | lr: 9.9703e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5448/156230 | global iter:   5448/156230 | loss: 1.1369 | ds_loss: 1.1461 | lr: 9.9703e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5449/156230 | global iter:   5449/156230 | loss: 0.9676 | ds_loss: 0.9905 | lr: 9.9703e-05 | scale: 65536.0000 | micro time: 1.400 | step time: 0.000
train | epoch   0 | Iter:   5450/156230 | global iter:   5450/156230 | loss: 1.2178 | ds_loss: 1.2358 | lr: 9.9703e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   5451/156230 | global iter:   5451/156230 | loss: 1.1656 | ds_loss: 1.1883 | lr: 9.9703e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   5452/156230 | global iter:   5452/156230 | loss: 1.1919 | ds_loss: 1.2033 | lr: 9.9702e-05 | scale: 65536.0000 | micro time: 1.426 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5452/156230 | global iter:   5452/156230 | loss: 1.1357 | ds_loss: 1.1545 | lr: 9.9702e-05 | scale: 65536.0000 | micro time: 1.426 | step time: 1.381
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5453/156230 | global iter:   5453/156230 | loss: 1.2158 | ds_loss: 1.2254 | lr: 9.9702e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   5454/156230 | global iter:   5454/156230 | loss: 1.0502 | ds_loss: 1.0731 | lr: 9.9702e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   5455/156230 | global iter:   5455/156230 | loss: 1.0506 | ds_loss: 1.0699 | lr: 9.9702e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   5456/156230 | global iter:   5456/156230 | loss: 1.2263 | ds_loss: 1.2515 | lr: 9.9702e-05 | scale: 65536.0000 | micro time: 1.405 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5456/156230 | global iter:   5456/156230 | loss: 1.1357 | ds_loss: 1.1550 | lr: 9.9702e-05 | scale: 65536.0000 | micro time: 1.405 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5457/156230 | global iter:   5457/156230 | loss: 1.2237 | ds_loss: 1.2272 | lr: 9.9702e-05 | scale: 65536.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:   5458/156230 | global iter:   5458/156230 | loss: 1.1586 | ds_loss: 1.1809 | lr: 9.9702e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   5459/156230 | global iter:   5459/156230 | loss: 1.1531 | ds_loss: 1.1889 | lr: 9.9702e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   5460/156230 | global iter:   5460/156230 | loss: 1.2108 | ds_loss: 1.2196 | lr: 9.9702e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5460/156230 | global iter:   5460/156230 | loss: 1.1866 | ds_loss: 1.2041 | lr: 9.9702e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5461/156230 | global iter:   5461/156230 | loss: 1.1523 | ds_loss: 1.1688 | lr: 9.9701e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   5462/156230 | global iter:   5462/156230 | loss: 1.1288 | ds_loss: 1.1273 | lr: 9.9701e-05 | scale: 65536.0000 | micro time: 1.400 | step time: 0.000
train | epoch   0 | Iter:   5463/156230 | global iter:   5463/156230 | loss: 1.1394 | ds_loss: 1.1527 | lr: 9.9701e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   5464/156230 | global iter:   5464/156230 | loss: 0.9718 | ds_loss: 0.9945 | lr: 9.9701e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5464/156230 | global iter:   5464/156230 | loss: 1.0981 | ds_loss: 1.1108 | lr: 9.9701e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5465/156230 | global iter:   5465/156230 | loss: 1.2468 | ds_loss: 1.2660 | lr: 9.9701e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   5466/156230 | global iter:   5466/156230 | loss: 1.1865 | ds_loss: 1.2227 | lr: 9.9701e-05 | scale: 65536.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   5467/156230 | global iter:   5467/156230 | loss: 1.1835 | ds_loss: 1.1972 | lr: 9.9701e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   5468/156230 | global iter:   5468/156230 | loss: 1.2408 | ds_loss: 1.2534 | lr: 9.9701e-05 | scale: 65536.0000 | micro time: 1.390 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5468/156230 | global iter:   5468/156230 | loss: 1.2144 | ds_loss: 1.2348 | lr: 9.9701e-05 | scale: 65536.0000 | micro time: 1.390 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5469/156230 | global iter:   5469/156230 | loss: 1.1328 | ds_loss: 1.1462 | lr: 9.9701e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   5470/156230 | global iter:   5470/156230 | loss: 1.0310 | ds_loss: 1.0486 | lr: 9.9700e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   5471/156230 | global iter:   5471/156230 | loss: 0.9970 | ds_loss: 1.0140 | lr: 9.9700e-05 | scale: 65536.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   5472/156230 | global iter:   5472/156230 | loss: 1.2162 | ds_loss: 1.2506 | lr: 9.9700e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5472/156230 | global iter:   5472/156230 | loss: 1.0943 | ds_loss: 1.1148 | lr: 9.9700e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5473/156230 | global iter:   5473/156230 | loss: 1.1836 | ds_loss: 1.2005 | lr: 9.9700e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   5474/156230 | global iter:   5474/156230 | loss: 1.1019 | ds_loss: 1.1080 | lr: 9.9700e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   5475/156230 | global iter:   5475/156230 | loss: 1.1277 | ds_loss: 1.1531 | lr: 9.9700e-05 | scale: 65536.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   5476/156230 | global iter:   5476/156230 | loss: 1.0335 | ds_loss: 1.0507 | lr: 9.9700e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5476/156230 | global iter:   5476/156230 | loss: 1.1117 | ds_loss: 1.1281 | lr: 9.9700e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5477/156230 | global iter:   5477/156230 | loss: 1.0269 | ds_loss: 1.0349 | lr: 9.9700e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   5478/156230 | global iter:   5478/156230 | loss: 1.1794 | ds_loss: 1.2061 | lr: 9.9700e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   5479/156230 | global iter:   5479/156230 | loss: 1.3280 | ds_loss: 1.3433 | lr: 9.9699e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   5480/156230 | global iter:   5480/156230 | loss: 1.1705 | ds_loss: 1.1927 | lr: 9.9699e-05 | scale: 65536.0000 | micro time: 1.323 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5480/156230 | global iter:   5480/156230 | loss: 1.1762 | ds_loss: 1.1943 | lr: 9.9699e-05 | scale: 65536.0000 | micro time: 1.323 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5481/156230 | global iter:   5481/156230 | loss: 1.0363 | ds_loss: 1.0432 | lr: 9.9699e-05 | scale: 65536.0000 | micro time: 1.317 | step time: 0.000
train | epoch   0 | Iter:   5482/156230 | global iter:   5482/156230 | loss: 1.0372 | ds_loss: 1.0431 | lr: 9.9699e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   5483/156230 | global iter:   5483/156230 | loss: 1.0668 | ds_loss: 1.0786 | lr: 9.9699e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   5484/156230 | global iter:   5484/156230 | loss: 1.2667 | ds_loss: 1.2721 | lr: 9.9699e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5484/156230 | global iter:   5484/156230 | loss: 1.1018 | ds_loss: 1.1092 | lr: 9.9699e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 1.344
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5485/156230 | global iter:   5485/156230 | loss: 0.9214 | ds_loss: 0.9403 | lr: 9.9699e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   5486/156230 | global iter:   5486/156230 | loss: 1.0269 | ds_loss: 1.0398 | lr: 9.9699e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   5487/156230 | global iter:   5487/156230 | loss: 0.9612 | ds_loss: 0.9787 | lr: 9.9699e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   5488/156230 | global iter:   5488/156230 | loss: 1.1439 | ds_loss: 1.1619 | lr: 9.9698e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5488/156230 | global iter:   5488/156230 | loss: 1.0134 | ds_loss: 1.0302 | lr: 9.9698e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5489/156230 | global iter:   5489/156230 | loss: 1.0763 | ds_loss: 1.0815 | lr: 9.9698e-05 | scale: 65536.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   5490/156230 | global iter:   5490/156230 | loss: 0.9206 | ds_loss: 0.9357 | lr: 9.9698e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   5491/156230 | global iter:   5491/156230 | loss: 1.1581 | ds_loss: 1.1678 | lr: 9.9698e-05 | scale: 65536.0000 | micro time: 1.404 | step time: 0.000
train | epoch   0 | Iter:   5492/156230 | global iter:   5492/156230 | loss: 1.0316 | ds_loss: 1.0384 | lr: 9.9698e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5492/156230 | global iter:   5492/156230 | loss: 1.0467 | ds_loss: 1.0558 | lr: 9.9698e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5493/156230 | global iter:   5493/156230 | loss: 1.1779 | ds_loss: 1.2017 | lr: 9.9698e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   5494/156230 | global iter:   5494/156230 | loss: 1.0492 | ds_loss: 1.0586 | lr: 9.9698e-05 | scale: 65536.0000 | micro time: 1.401 | step time: 0.000
train | epoch   0 | Iter:   5495/156230 | global iter:   5495/156230 | loss: 1.0950 | ds_loss: 1.0975 | lr: 9.9698e-05 | scale: 65536.0000 | micro time: 1.321 | step time: 0.000
train | epoch   0 | Iter:   5496/156230 | global iter:   5496/156230 | loss: 1.0209 | ds_loss: 1.0534 | lr: 9.9698e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5496/156230 | global iter:   5496/156230 | loss: 1.0857 | ds_loss: 1.1028 | lr: 9.9698e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5497/156230 | global iter:   5497/156230 | loss: 1.2438 | ds_loss: 1.2657 | lr: 9.9697e-05 | scale: 65536.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   5498/156230 | global iter:   5498/156230 | loss: 0.9919 | ds_loss: 1.0041 | lr: 9.9697e-05 | scale: 65536.0000 | micro time: 1.316 | step time: 0.000
train | epoch   0 | Iter:   5499/156230 | global iter:   5499/156230 | loss: 1.2524 | ds_loss: 1.2974 | lr: 9.9697e-05 | scale: 65536.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   5500/156230 | global iter:   5500/156230 | loss: 1.0389 | ds_loss: 1.0856 | lr: 9.9697e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5500/156230 | global iter:   5500/156230 | loss: 1.1318 | ds_loss: 1.1632 | lr: 9.9697e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5501/156230 | global iter:   5501/156230 | loss: 1.1982 | ds_loss: 1.2013 | lr: 9.9697e-05 | scale: 65536.0000 | micro time: 1.319 | step time: 0.000
train | epoch   0 | Iter:   5502/156230 | global iter:   5502/156230 | loss: 1.1294 | ds_loss: 1.1590 | lr: 9.9697e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   5503/156230 | global iter:   5503/156230 | loss: 1.0689 | ds_loss: 1.0871 | lr: 9.9697e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   5504/156230 | global iter:   5504/156230 | loss: 1.3465 | ds_loss: 1.3616 | lr: 9.9697e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5504/156230 | global iter:   5504/156230 | loss: 1.1858 | ds_loss: 1.2022 | lr: 9.9697e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5505/156230 | global iter:   5505/156230 | loss: 1.0401 | ds_loss: 1.0613 | lr: 9.9697e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   5506/156230 | global iter:   5506/156230 | loss: 1.1338 | ds_loss: 1.1617 | lr: 9.9696e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   5507/156230 | global iter:   5507/156230 | loss: 1.1502 | ds_loss: 1.1664 | lr: 9.9696e-05 | scale: 65536.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   5508/156230 | global iter:   5508/156230 | loss: 1.1107 | ds_loss: 1.1127 | lr: 9.9696e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5508/156230 | global iter:   5508/156230 | loss: 1.1087 | ds_loss: 1.1255 | lr: 9.9696e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5509/156230 | global iter:   5509/156230 | loss: 1.2863 | ds_loss: 1.3014 | lr: 9.9696e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   5510/156230 | global iter:   5510/156230 | loss: 1.1329 | ds_loss: 1.1436 | lr: 9.9696e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   5511/156230 | global iter:   5511/156230 | loss: 1.1436 | ds_loss: 1.1738 | lr: 9.9696e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   5512/156230 | global iter:   5512/156230 | loss: 1.1561 | ds_loss: 1.1747 | lr: 9.9696e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5512/156230 | global iter:   5512/156230 | loss: 1.1797 | ds_loss: 1.1984 | lr: 9.9696e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5513/156230 | global iter:   5513/156230 | loss: 1.1443 | ds_loss: 1.1572 | lr: 9.9696e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   5514/156230 | global iter:   5514/156230 | loss: 0.8803 | ds_loss: 0.9011 | lr: 9.9696e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   5515/156230 | global iter:   5515/156230 | loss: 1.1362 | ds_loss: 1.1543 | lr: 9.9695e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   5516/156230 | global iter:   5516/156230 | loss: 1.0415 | ds_loss: 1.0725 | lr: 9.9695e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5516/156230 | global iter:   5516/156230 | loss: 1.0506 | ds_loss: 1.0713 | lr: 9.9695e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5517/156230 | global iter:   5517/156230 | loss: 1.1570 | ds_loss: 1.1538 | lr: 9.9695e-05 | scale: 65536.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   5518/156230 | global iter:   5518/156230 | loss: 1.1104 | ds_loss: 1.1232 | lr: 9.9695e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   5519/156230 | global iter:   5519/156230 | loss: 1.0286 | ds_loss: 1.0547 | lr: 9.9695e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   5520/156230 | global iter:   5520/156230 | loss: 1.0292 | ds_loss: 1.0454 | lr: 9.9695e-05 | scale: 65536.0000 | micro time: 1.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5520/156230 | global iter:   5520/156230 | loss: 1.0813 | ds_loss: 1.0943 | lr: 9.9695e-05 | scale: 65536.0000 | micro time: 1.396 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5521/156230 | global iter:   5521/156230 | loss: 1.1786 | ds_loss: 1.1954 | lr: 9.9695e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   5522/156230 | global iter:   5522/156230 | loss: 1.0517 | ds_loss: 1.0798 | lr: 9.9695e-05 | scale: 65536.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   5523/156230 | global iter:   5523/156230 | loss: 1.1407 | ds_loss: 1.1470 | lr: 9.9695e-05 | scale: 65536.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   5524/156230 | global iter:   5524/156230 | loss: 1.1896 | ds_loss: 1.1925 | lr: 9.9694e-05 | scale: 65536.0000 | micro time: 1.321 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5524/156230 | global iter:   5524/156230 | loss: 1.1402 | ds_loss: 1.1536 | lr: 9.9694e-05 | scale: 65536.0000 | micro time: 1.321 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5525/156230 | global iter:   5525/156230 | loss: 1.1575 | ds_loss: 1.1834 | lr: 9.9694e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   5526/156230 | global iter:   5526/156230 | loss: 1.0030 | ds_loss: 1.0060 | lr: 9.9694e-05 | scale: 65536.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:   5527/156230 | global iter:   5527/156230 | loss: 1.2305 | ds_loss: 1.2520 | lr: 9.9694e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   5528/156230 | global iter:   5528/156230 | loss: 1.2781 | ds_loss: 1.2944 | lr: 9.9694e-05 | scale: 65536.0000 | micro time: 1.322 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5528/156230 | global iter:   5528/156230 | loss: 1.1673 | ds_loss: 1.1839 | lr: 9.9694e-05 | scale: 65536.0000 | micro time: 1.322 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5529/156230 | global iter:   5529/156230 | loss: 1.1366 | ds_loss: 1.1619 | lr: 9.9694e-05 | scale: 65536.0000 | micro time: 1.406 | step time: 0.000
train | epoch   0 | Iter:   5530/156230 | global iter:   5530/156230 | loss: 1.0620 | ds_loss: 1.0718 | lr: 9.9694e-05 | scale: 65536.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   5531/156230 | global iter:   5531/156230 | loss: 1.1645 | ds_loss: 1.1792 | lr: 9.9694e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   5532/156230 | global iter:   5532/156230 | loss: 1.0115 | ds_loss: 1.0288 | lr: 9.9694e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5532/156230 | global iter:   5532/156230 | loss: 1.0936 | ds_loss: 1.1104 | lr: 9.9694e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5533/156230 | global iter:   5533/156230 | loss: 1.1997 | ds_loss: 1.2166 | lr: 9.9693e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   5534/156230 | global iter:   5534/156230 | loss: 1.1125 | ds_loss: 1.1324 | lr: 9.9693e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   5535/156230 | global iter:   5535/156230 | loss: 1.1604 | ds_loss: 1.1808 | lr: 9.9693e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   5536/156230 | global iter:   5536/156230 | loss: 1.2344 | ds_loss: 1.2762 | lr: 9.9693e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5536/156230 | global iter:   5536/156230 | loss: 1.1767 | ds_loss: 1.2015 | lr: 9.9693e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5537/156230 | global iter:   5537/156230 | loss: 1.0455 | ds_loss: 1.0712 | lr: 9.9693e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   5538/156230 | global iter:   5538/156230 | loss: 1.0498 | ds_loss: 1.0611 | lr: 9.9693e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   5539/156230 | global iter:   5539/156230 | loss: 1.0273 | ds_loss: 1.0408 | lr: 9.9693e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   5540/156230 | global iter:   5540/156230 | loss: 1.0921 | ds_loss: 1.1054 | lr: 9.9693e-05 | scale: 65536.0000 | micro time: 1.419 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5540/156230 | global iter:   5540/156230 | loss: 1.0537 | ds_loss: 1.0696 | lr: 9.9693e-05 | scale: 65536.0000 | micro time: 1.419 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5541/156230 | global iter:   5541/156230 | loss: 1.0280 | ds_loss: 1.0677 | lr: 9.9693e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   5542/156230 | global iter:   5542/156230 | loss: 1.1880 | ds_loss: 1.1998 | lr: 9.9692e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   5543/156230 | global iter:   5543/156230 | loss: 1.2117 | ds_loss: 1.2345 | lr: 9.9692e-05 | scale: 65536.0000 | micro time: 1.421 | step time: 0.000
train | epoch   0 | Iter:   5544/156230 | global iter:   5544/156230 | loss: 0.9402 | ds_loss: 0.9476 | lr: 9.9692e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5544/156230 | global iter:   5544/156230 | loss: 1.0920 | ds_loss: 1.1124 | lr: 9.9692e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5545/156230 | global iter:   5545/156230 | loss: 1.2963 | ds_loss: 1.3172 | lr: 9.9692e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   5546/156230 | global iter:   5546/156230 | loss: 1.0990 | ds_loss: 1.1126 | lr: 9.9692e-05 | scale: 65536.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   5547/156230 | global iter:   5547/156230 | loss: 1.0581 | ds_loss: 1.0836 | lr: 9.9692e-05 | scale: 65536.0000 | micro time: 1.309 | step time: 0.000
train | epoch   0 | Iter:   5548/156230 | global iter:   5548/156230 | loss: 1.0938 | ds_loss: 1.1006 | lr: 9.9692e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5548/156230 | global iter:   5548/156230 | loss: 1.1368 | ds_loss: 1.1535 | lr: 9.9692e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5549/156230 | global iter:   5549/156230 | loss: 1.2629 | ds_loss: 1.2459 | lr: 9.9692e-05 | scale: 65536.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   5550/156230 | global iter:   5550/156230 | loss: 1.0964 | ds_loss: 1.1266 | lr: 9.9692e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   5551/156230 | global iter:   5551/156230 | loss: 1.1222 | ds_loss: 1.1376 | lr: 9.9691e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   5552/156230 | global iter:   5552/156230 | loss: 1.0046 | ds_loss: 1.0177 | lr: 9.9691e-05 | scale: 65536.0000 | micro time: 1.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5552/156230 | global iter:   5552/156230 | loss: 1.1215 | ds_loss: 1.1320 | lr: 9.9691e-05 | scale: 65536.0000 | micro time: 1.394 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5553/156230 | global iter:   5553/156230 | loss: 1.0786 | ds_loss: 1.0966 | lr: 9.9691e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   5554/156230 | global iter:   5554/156230 | loss: 1.1559 | ds_loss: 1.1810 | lr: 9.9691e-05 | scale: 65536.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   5555/156230 | global iter:   5555/156230 | loss: 1.2222 | ds_loss: 1.2266 | lr: 9.9691e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   5556/156230 | global iter:   5556/156230 | loss: 0.9019 | ds_loss: 0.9151 | lr: 9.9691e-05 | scale: 65536.0000 | micro time: 1.317 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5556/156230 | global iter:   5556/156230 | loss: 1.0896 | ds_loss: 1.1048 | lr: 9.9691e-05 | scale: 65536.0000 | micro time: 1.317 | step time: 1.345
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5557/156230 | global iter:   5557/156230 | loss: 1.1814 | ds_loss: 1.2001 | lr: 9.9691e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   5558/156230 | global iter:   5558/156230 | loss: 1.0725 | ds_loss: 1.0856 | lr: 9.9691e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   5559/156230 | global iter:   5559/156230 | loss: 1.4693 | ds_loss: 1.4858 | lr: 9.9691e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   5560/156230 | global iter:   5560/156230 | loss: 1.0346 | ds_loss: 1.0573 | lr: 9.9690e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5560/156230 | global iter:   5560/156230 | loss: 1.1894 | ds_loss: 1.2072 | lr: 9.9690e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5561/156230 | global iter:   5561/156230 | loss: 1.0603 | ds_loss: 1.0882 | lr: 9.9690e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   5562/156230 | global iter:   5562/156230 | loss: 1.1373 | ds_loss: 1.1608 | lr: 9.9690e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   5563/156230 | global iter:   5563/156230 | loss: 1.0675 | ds_loss: 1.0733 | lr: 9.9690e-05 | scale: 65536.0000 | micro time: 1.325 | step time: 0.000
train | epoch   0 | Iter:   5564/156230 | global iter:   5564/156230 | loss: 0.9289 | ds_loss: 0.9493 | lr: 9.9690e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5564/156230 | global iter:   5564/156230 | loss: 1.0485 | ds_loss: 1.0679 | lr: 9.9690e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 1.340
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5565/156230 | global iter:   5565/156230 | loss: 1.2479 | ds_loss: 1.2631 | lr: 9.9690e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   5566/156230 | global iter:   5566/156230 | loss: 1.0711 | ds_loss: 1.0819 | lr: 9.9690e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   5567/156230 | global iter:   5567/156230 | loss: 1.1506 | ds_loss: 1.1585 | lr: 9.9690e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   5568/156230 | global iter:   5568/156230 | loss: 1.1550 | ds_loss: 1.1571 | lr: 9.9690e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5568/156230 | global iter:   5568/156230 | loss: 1.1561 | ds_loss: 1.1652 | lr: 9.9690e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5569/156230 | global iter:   5569/156230 | loss: 1.1962 | ds_loss: 1.2036 | lr: 9.9689e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   5570/156230 | global iter:   5570/156230 | loss: 0.9925 | ds_loss: 0.9830 | lr: 9.9689e-05 | scale: 65536.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   5571/156230 | global iter:   5571/156230 | loss: 1.1340 | ds_loss: 1.1553 | lr: 9.9689e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   5572/156230 | global iter:   5572/156230 | loss: 1.1004 | ds_loss: 1.1147 | lr: 9.9689e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5572/156230 | global iter:   5572/156230 | loss: 1.1058 | ds_loss: 1.1142 | lr: 9.9689e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5573/156230 | global iter:   5573/156230 | loss: 1.3146 | ds_loss: 1.3527 | lr: 9.9689e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   5574/156230 | global iter:   5574/156230 | loss: 1.1362 | ds_loss: 1.1495 | lr: 9.9689e-05 | scale: 65536.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   5575/156230 | global iter:   5575/156230 | loss: 0.9142 | ds_loss: 0.9303 | lr: 9.9689e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   5576/156230 | global iter:   5576/156230 | loss: 1.0692 | ds_loss: 1.0746 | lr: 9.9689e-05 | scale: 65536.0000 | micro time: 1.321 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5576/156230 | global iter:   5576/156230 | loss: 1.1086 | ds_loss: 1.1268 | lr: 9.9689e-05 | scale: 65536.0000 | micro time: 1.321 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5577/156230 | global iter:   5577/156230 | loss: 1.2198 | ds_loss: 1.2420 | lr: 9.9689e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   5578/156230 | global iter:   5578/156230 | loss: 1.0710 | ds_loss: 1.1009 | lr: 9.9688e-05 | scale: 65536.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:   5579/156230 | global iter:   5579/156230 | loss: 1.1943 | ds_loss: 1.2102 | lr: 9.9688e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   5580/156230 | global iter:   5580/156230 | loss: 1.2921 | ds_loss: 1.3028 | lr: 9.9688e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5580/156230 | global iter:   5580/156230 | loss: 1.1943 | ds_loss: 1.2140 | lr: 9.9688e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5581/156230 | global iter:   5581/156230 | loss: 1.2243 | ds_loss: 1.2481 | lr: 9.9688e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   5582/156230 | global iter:   5582/156230 | loss: 1.1141 | ds_loss: 1.1458 | lr: 9.9688e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   5583/156230 | global iter:   5583/156230 | loss: 1.0416 | ds_loss: 1.0770 | lr: 9.9688e-05 | scale: 65536.0000 | micro time: 1.310 | step time: 0.000
train | epoch   0 | Iter:   5584/156230 | global iter:   5584/156230 | loss: 1.2750 | ds_loss: 1.3130 | lr: 9.9688e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5584/156230 | global iter:   5584/156230 | loss: 1.1638 | ds_loss: 1.1960 | lr: 9.9688e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5585/156230 | global iter:   5585/156230 | loss: 1.2856 | ds_loss: 1.2834 | lr: 9.9688e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   5586/156230 | global iter:   5586/156230 | loss: 1.1103 | ds_loss: 1.1354 | lr: 9.9688e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   5587/156230 | global iter:   5587/156230 | loss: 1.0525 | ds_loss: 1.0723 | lr: 9.9687e-05 | scale: 65536.0000 | micro time: 1.318 | step time: 0.000
train | epoch   0 | Iter:   5588/156230 | global iter:   5588/156230 | loss: 1.0416 | ds_loss: 1.0621 | lr: 9.9687e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5588/156230 | global iter:   5588/156230 | loss: 1.1225 | ds_loss: 1.1383 | lr: 9.9687e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 1.348
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5589/156230 | global iter:   5589/156230 | loss: 1.0894 | ds_loss: 1.1176 | lr: 9.9687e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   5590/156230 | global iter:   5590/156230 | loss: 1.0440 | ds_loss: 1.0752 | lr: 9.9687e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   5591/156230 | global iter:   5591/156230 | loss: 0.9522 | ds_loss: 0.9607 | lr: 9.9687e-05 | scale: 65536.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   5592/156230 | global iter:   5592/156230 | loss: 1.0519 | ds_loss: 1.0714 | lr: 9.9687e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5592/156230 | global iter:   5592/156230 | loss: 1.0344 | ds_loss: 1.0562 | lr: 9.9687e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 1.347
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5593/156230 | global iter:   5593/156230 | loss: 1.0382 | ds_loss: 1.0393 | lr: 9.9687e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   5594/156230 | global iter:   5594/156230 | loss: 1.1316 | ds_loss: 1.1375 | lr: 9.9687e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   5595/156230 | global iter:   5595/156230 | loss: 0.9980 | ds_loss: 1.0125 | lr: 9.9687e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   5596/156230 | global iter:   5596/156230 | loss: 0.9969 | ds_loss: 1.0020 | lr: 9.9686e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5596/156230 | global iter:   5596/156230 | loss: 1.0412 | ds_loss: 1.0478 | lr: 9.9686e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5597/156230 | global iter:   5597/156230 | loss: 1.1391 | ds_loss: 1.1608 | lr: 9.9686e-05 | scale: 65536.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   5598/156230 | global iter:   5598/156230 | loss: 1.2606 | ds_loss: 1.2782 | lr: 9.9686e-05 | scale: 65536.0000 | micro time: 1.322 | step time: 0.000
train | epoch   0 | Iter:   5599/156230 | global iter:   5599/156230 | loss: 0.9887 | ds_loss: 1.0135 | lr: 9.9686e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   5600/156230 | global iter:   5600/156230 | loss: 1.2411 | ds_loss: 1.2496 | lr: 9.9686e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5600/156230 | global iter:   5600/156230 | loss: 1.1574 | ds_loss: 1.1755 | lr: 9.9686e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 1.344
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5601/156230 | global iter:   5601/156230 | loss: 1.1488 | ds_loss: 1.1729 | lr: 9.9686e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   5602/156230 | global iter:   5602/156230 | loss: 0.9815 | ds_loss: 1.0023 | lr: 9.9686e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   5603/156230 | global iter:   5603/156230 | loss: 0.9737 | ds_loss: 0.9885 | lr: 9.9686e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   5604/156230 | global iter:   5604/156230 | loss: 1.1523 | ds_loss: 1.1720 | lr: 9.9686e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5604/156230 | global iter:   5604/156230 | loss: 1.0641 | ds_loss: 1.0839 | lr: 9.9686e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5605/156230 | global iter:   5605/156230 | loss: 1.2863 | ds_loss: 1.3011 | lr: 9.9685e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   5606/156230 | global iter:   5606/156230 | loss: 1.1433 | ds_loss: 1.1577 | lr: 9.9685e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   5607/156230 | global iter:   5607/156230 | loss: 0.8500 | ds_loss: 0.8764 | lr: 9.9685e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   5608/156230 | global iter:   5608/156230 | loss: 1.2264 | ds_loss: 1.2322 | lr: 9.9685e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5608/156230 | global iter:   5608/156230 | loss: 1.1265 | ds_loss: 1.1419 | lr: 9.9685e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5609/156230 | global iter:   5609/156230 | loss: 1.1446 | ds_loss: 1.1662 | lr: 9.9685e-05 | scale: 65536.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   5610/156230 | global iter:   5610/156230 | loss: 1.1030 | ds_loss: 1.1092 | lr: 9.9685e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   5611/156230 | global iter:   5611/156230 | loss: 1.0026 | ds_loss: 1.0264 | lr: 9.9685e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   5612/156230 | global iter:   5612/156230 | loss: 1.0470 | ds_loss: 1.0581 | lr: 9.9685e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5612/156230 | global iter:   5612/156230 | loss: 1.0743 | ds_loss: 1.0900 | lr: 9.9685e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5613/156230 | global iter:   5613/156230 | loss: 1.2210 | ds_loss: 1.2407 | lr: 9.9685e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   5614/156230 | global iter:   5614/156230 | loss: 1.0151 | ds_loss: 1.0188 | lr: 9.9684e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   5615/156230 | global iter:   5615/156230 | loss: 0.9241 | ds_loss: 0.9335 | lr: 9.9684e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   5616/156230 | global iter:   5616/156230 | loss: 1.0226 | ds_loss: 1.0481 | lr: 9.9684e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5616/156230 | global iter:   5616/156230 | loss: 1.0457 | ds_loss: 1.0603 | lr: 9.9684e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5617/156230 | global iter:   5617/156230 | loss: 1.0601 | ds_loss: 1.0694 | lr: 9.9684e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   5618/156230 | global iter:   5618/156230 | loss: 1.1674 | ds_loss: 1.1740 | lr: 9.9684e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   5619/156230 | global iter:   5619/156230 | loss: 1.0384 | ds_loss: 1.0678 | lr: 9.9684e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   5620/156230 | global iter:   5620/156230 | loss: 1.1807 | ds_loss: 1.2022 | lr: 9.9684e-05 | scale: 65536.0000 | micro time: 1.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5620/156230 | global iter:   5620/156230 | loss: 1.1117 | ds_loss: 1.1284 | lr: 9.9684e-05 | scale: 65536.0000 | micro time: 1.400 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5621/156230 | global iter:   5621/156230 | loss: 1.1672 | ds_loss: 1.1905 | lr: 9.9684e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   5622/156230 | global iter:   5622/156230 | loss: 1.1397 | ds_loss: 1.1536 | lr: 9.9684e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   5623/156230 | global iter:   5623/156230 | loss: 1.0930 | ds_loss: 1.0951 | lr: 9.9683e-05 | scale: 65536.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   5624/156230 | global iter:   5624/156230 | loss: 1.0552 | ds_loss: 1.0755 | lr: 9.9683e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5624/156230 | global iter:   5624/156230 | loss: 1.1138 | ds_loss: 1.1287 | lr: 9.9683e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 1.376
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5625/156230 | global iter:   5625/156230 | loss: 0.9339 | ds_loss: 0.9465 | lr: 9.9683e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   5626/156230 | global iter:   5626/156230 | loss: 1.0746 | ds_loss: 1.0882 | lr: 9.9683e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   5627/156230 | global iter:   5627/156230 | loss: 1.1654 | ds_loss: 1.2054 | lr: 9.9683e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   5628/156230 | global iter:   5628/156230 | loss: 1.0587 | ds_loss: 1.0758 | lr: 9.9683e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5628/156230 | global iter:   5628/156230 | loss: 1.0582 | ds_loss: 1.0790 | lr: 9.9683e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5629/156230 | global iter:   5629/156230 | loss: 1.3051 | ds_loss: 1.3146 | lr: 9.9683e-05 | scale: 65536.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   5630/156230 | global iter:   5630/156230 | loss: 1.1934 | ds_loss: 1.2035 | lr: 9.9683e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   5631/156230 | global iter:   5631/156230 | loss: 1.1376 | ds_loss: 1.1527 | lr: 9.9683e-05 | scale: 65536.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   5632/156230 | global iter:   5632/156230 | loss: 0.9788 | ds_loss: 0.9928 | lr: 9.9682e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5632/156230 | global iter:   5632/156230 | loss: 1.1537 | ds_loss: 1.1659 | lr: 9.9682e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5633/156230 | global iter:   5633/156230 | loss: 1.0723 | ds_loss: 1.0931 | lr: 9.9682e-05 | scale: 65536.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   5634/156230 | global iter:   5634/156230 | loss: 0.9356 | ds_loss: 0.9501 | lr: 9.9682e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   5635/156230 | global iter:   5635/156230 | loss: 1.0240 | ds_loss: 1.0283 | lr: 9.9682e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   5636/156230 | global iter:   5636/156230 | loss: 1.1411 | ds_loss: 1.1639 | lr: 9.9682e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5636/156230 | global iter:   5636/156230 | loss: 1.0432 | ds_loss: 1.0589 | lr: 9.9682e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5637/156230 | global iter:   5637/156230 | loss: 1.1486 | ds_loss: 1.1673 | lr: 9.9682e-05 | scale: 65536.0000 | micro time: 1.400 | step time: 0.000
train | epoch   0 | Iter:   5638/156230 | global iter:   5638/156230 | loss: 1.3227 | ds_loss: 1.3515 | lr: 9.9682e-05 | scale: 65536.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   5639/156230 | global iter:   5639/156230 | loss: 1.2560 | ds_loss: 1.2691 | lr: 9.9682e-05 | scale: 65536.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   5640/156230 | global iter:   5640/156230 | loss: 1.1716 | ds_loss: 1.1850 | lr: 9.9681e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5640/156230 | global iter:   5640/156230 | loss: 1.2247 | ds_loss: 1.2432 | lr: 9.9681e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5641/156230 | global iter:   5641/156230 | loss: 1.0481 | ds_loss: 1.0796 | lr: 9.9681e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   5642/156230 | global iter:   5642/156230 | loss: 1.1811 | ds_loss: 1.1898 | lr: 9.9681e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   5643/156230 | global iter:   5643/156230 | loss: 1.0459 | ds_loss: 1.0577 | lr: 9.9681e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   5644/156230 | global iter:   5644/156230 | loss: 0.9595 | ds_loss: 0.9663 | lr: 9.9681e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5644/156230 | global iter:   5644/156230 | loss: 1.0587 | ds_loss: 1.0734 | lr: 9.9681e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5645/156230 | global iter:   5645/156230 | loss: 1.1452 | ds_loss: 1.1662 | lr: 9.9681e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   5646/156230 | global iter:   5646/156230 | loss: 1.1725 | ds_loss: 1.1844 | lr: 9.9681e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   5647/156230 | global iter:   5647/156230 | loss: 1.1537 | ds_loss: 1.1810 | lr: 9.9681e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   5648/156230 | global iter:   5648/156230 | loss: 1.1871 | ds_loss: 1.1856 | lr: 9.9681e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5648/156230 | global iter:   5648/156230 | loss: 1.1646 | ds_loss: 1.1793 | lr: 9.9681e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5649/156230 | global iter:   5649/156230 | loss: 1.3590 | ds_loss: 1.3674 | lr: 9.9680e-05 | scale: 65536.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   5650/156230 | global iter:   5650/156230 | loss: 1.1712 | ds_loss: 1.1915 | lr: 9.9680e-05 | scale: 65536.0000 | micro time: 1.413 | step time: 0.000
train | epoch   0 | Iter:   5651/156230 | global iter:   5651/156230 | loss: 1.1476 | ds_loss: 1.1586 | lr: 9.9680e-05 | scale: 65536.0000 | micro time: 1.405 | step time: 0.000
train | epoch   0 | Iter:   5652/156230 | global iter:   5652/156230 | loss: 1.0979 | ds_loss: 1.1066 | lr: 9.9680e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5652/156230 | global iter:   5652/156230 | loss: 1.1939 | ds_loss: 1.2060 | lr: 9.9680e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 1.390
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5653/156230 | global iter:   5653/156230 | loss: 1.1060 | ds_loss: 1.1049 | lr: 9.9680e-05 | scale: 65536.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:   5654/156230 | global iter:   5654/156230 | loss: 0.9608 | ds_loss: 0.9814 | lr: 9.9680e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   5655/156230 | global iter:   5655/156230 | loss: 1.0887 | ds_loss: 1.1048 | lr: 9.9680e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   5656/156230 | global iter:   5656/156230 | loss: 1.1463 | ds_loss: 1.1844 | lr: 9.9680e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5656/156230 | global iter:   5656/156230 | loss: 1.0755 | ds_loss: 1.0939 | lr: 9.9680e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5657/156230 | global iter:   5657/156230 | loss: 1.0727 | ds_loss: 1.0949 | lr: 9.9680e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   5658/156230 | global iter:   5658/156230 | loss: 1.2299 | ds_loss: 1.2463 | lr: 9.9679e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   5659/156230 | global iter:   5659/156230 | loss: 1.1209 | ds_loss: 1.1409 | lr: 9.9679e-05 | scale: 65536.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   5660/156230 | global iter:   5660/156230 | loss: 1.1383 | ds_loss: 1.1487 | lr: 9.9679e-05 | scale: 65536.0000 | micro time: 1.383 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5660/156230 | global iter:   5660/156230 | loss: 1.1405 | ds_loss: 1.1577 | lr: 9.9679e-05 | scale: 65536.0000 | micro time: 1.383 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5661/156230 | global iter:   5661/156230 | loss: 1.2125 | ds_loss: 1.2307 | lr: 9.9679e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   5662/156230 | global iter:   5662/156230 | loss: 1.0484 | ds_loss: 1.0779 | lr: 9.9679e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   5663/156230 | global iter:   5663/156230 | loss: 1.0076 | ds_loss: 1.0431 | lr: 9.9679e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   5664/156230 | global iter:   5664/156230 | loss: 1.1174 | ds_loss: 1.1319 | lr: 9.9679e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5664/156230 | global iter:   5664/156230 | loss: 1.0965 | ds_loss: 1.1209 | lr: 9.9679e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5665/156230 | global iter:   5665/156230 | loss: 1.1039 | ds_loss: 1.1246 | lr: 9.9679e-05 | scale: 65536.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   5666/156230 | global iter:   5666/156230 | loss: 1.1083 | ds_loss: 1.1346 | lr: 9.9679e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   5667/156230 | global iter:   5667/156230 | loss: 1.1245 | ds_loss: 1.1229 | lr: 9.9678e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   5668/156230 | global iter:   5668/156230 | loss: 1.0198 | ds_loss: 1.0219 | lr: 9.9678e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5668/156230 | global iter:   5668/156230 | loss: 1.0891 | ds_loss: 1.1010 | lr: 9.9678e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5669/156230 | global iter:   5669/156230 | loss: 1.1434 | ds_loss: 1.1547 | lr: 9.9678e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   5670/156230 | global iter:   5670/156230 | loss: 1.0696 | ds_loss: 1.0915 | lr: 9.9678e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   5671/156230 | global iter:   5671/156230 | loss: 1.1154 | ds_loss: 1.1230 | lr: 9.9678e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   5672/156230 | global iter:   5672/156230 | loss: 1.1117 | ds_loss: 1.1330 | lr: 9.9678e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5672/156230 | global iter:   5672/156230 | loss: 1.1100 | ds_loss: 1.1256 | lr: 9.9678e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5673/156230 | global iter:   5673/156230 | loss: 1.1448 | ds_loss: 1.1576 | lr: 9.9678e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   5674/156230 | global iter:   5674/156230 | loss: 1.3282 | ds_loss: 1.3343 | lr: 9.9678e-05 | scale: 65536.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   5675/156230 | global iter:   5675/156230 | loss: 1.2225 | ds_loss: 1.2493 | lr: 9.9678e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   5676/156230 | global iter:   5676/156230 | loss: 1.1100 | ds_loss: 1.1300 | lr: 9.9677e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5676/156230 | global iter:   5676/156230 | loss: 1.2014 | ds_loss: 1.2178 | lr: 9.9677e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5677/156230 | global iter:   5677/156230 | loss: 1.1568 | ds_loss: 1.1860 | lr: 9.9677e-05 | scale: 65536.0000 | micro time: 1.317 | step time: 0.000
train | epoch   0 | Iter:   5678/156230 | global iter:   5678/156230 | loss: 1.1805 | ds_loss: 1.1858 | lr: 9.9677e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   5679/156230 | global iter:   5679/156230 | loss: 1.1279 | ds_loss: 1.1429 | lr: 9.9677e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   5680/156230 | global iter:   5680/156230 | loss: 1.0096 | ds_loss: 1.0202 | lr: 9.9677e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5680/156230 | global iter:   5680/156230 | loss: 1.1187 | ds_loss: 1.1337 | lr: 9.9677e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 1.345
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5681/156230 | global iter:   5681/156230 | loss: 1.0381 | ds_loss: 1.0733 | lr: 9.9677e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   5682/156230 | global iter:   5682/156230 | loss: 1.1386 | ds_loss: 1.1456 | lr: 9.9677e-05 | scale: 65536.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   5683/156230 | global iter:   5683/156230 | loss: 0.8957 | ds_loss: 0.9062 | lr: 9.9677e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   5684/156230 | global iter:   5684/156230 | loss: 1.0966 | ds_loss: 1.1021 | lr: 9.9676e-05 | scale: 65536.0000 | micro time: 1.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5684/156230 | global iter:   5684/156230 | loss: 1.0423 | ds_loss: 1.0568 | lr: 9.9676e-05 | scale: 65536.0000 | micro time: 1.397 | step time: 1.379
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5685/156230 | global iter:   5685/156230 | loss: 1.1165 | ds_loss: 1.1260 | lr: 9.9676e-05 | scale: 65536.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   5686/156230 | global iter:   5686/156230 | loss: 0.9981 | ds_loss: 1.0104 | lr: 9.9676e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   5687/156230 | global iter:   5687/156230 | loss: 1.1835 | ds_loss: 1.2073 | lr: 9.9676e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   5688/156230 | global iter:   5688/156230 | loss: 1.1120 | ds_loss: 1.1274 | lr: 9.9676e-05 | scale: 65536.0000 | micro time: 1.415 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5688/156230 | global iter:   5688/156230 | loss: 1.1025 | ds_loss: 1.1178 | lr: 9.9676e-05 | scale: 65536.0000 | micro time: 1.415 | step time: 1.380
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5689/156230 | global iter:   5689/156230 | loss: 1.1034 | ds_loss: 1.1252 | lr: 9.9676e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   5690/156230 | global iter:   5690/156230 | loss: 0.9797 | ds_loss: 1.0080 | lr: 9.9676e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   5691/156230 | global iter:   5691/156230 | loss: 1.1220 | ds_loss: 1.1411 | lr: 9.9676e-05 | scale: 65536.0000 | micro time: 1.406 | step time: 0.000
train | epoch   0 | Iter:   5692/156230 | global iter:   5692/156230 | loss: 1.0030 | ds_loss: 1.0058 | lr: 9.9676e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5692/156230 | global iter:   5692/156230 | loss: 1.0520 | ds_loss: 1.0700 | lr: 9.9676e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5693/156230 | global iter:   5693/156230 | loss: 1.0939 | ds_loss: 1.1053 | lr: 9.9675e-05 | scale: 65536.0000 | micro time: 1.417 | step time: 0.000
train | epoch   0 | Iter:   5694/156230 | global iter:   5694/156230 | loss: 1.1767 | ds_loss: 1.2082 | lr: 9.9675e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   5695/156230 | global iter:   5695/156230 | loss: 1.3958 | ds_loss: 1.4210 | lr: 9.9675e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   5696/156230 | global iter:   5696/156230 | loss: 1.1484 | ds_loss: 1.1622 | lr: 9.9675e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5696/156230 | global iter:   5696/156230 | loss: 1.2037 | ds_loss: 1.2242 | lr: 9.9675e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5697/156230 | global iter:   5697/156230 | loss: 1.0397 | ds_loss: 1.0543 | lr: 9.9675e-05 | scale: 65536.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   5698/156230 | global iter:   5698/156230 | loss: 1.0557 | ds_loss: 1.0746 | lr: 9.9675e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   5699/156230 | global iter:   5699/156230 | loss: 1.1826 | ds_loss: 1.1721 | lr: 9.9675e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   5700/156230 | global iter:   5700/156230 | loss: 1.0279 | ds_loss: 1.0566 | lr: 9.9675e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5700/156230 | global iter:   5700/156230 | loss: 1.0765 | ds_loss: 1.0894 | lr: 9.9675e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5701/156230 | global iter:   5701/156230 | loss: 1.1407 | ds_loss: 1.1537 | lr: 9.9675e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   5702/156230 | global iter:   5702/156230 | loss: 1.1512 | ds_loss: 1.1660 | lr: 9.9674e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   5703/156230 | global iter:   5703/156230 | loss: 1.1815 | ds_loss: 1.2002 | lr: 9.9674e-05 | scale: 65536.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   5704/156230 | global iter:   5704/156230 | loss: 1.0552 | ds_loss: 1.0701 | lr: 9.9674e-05 | scale: 65536.0000 | micro time: 1.332 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5704/156230 | global iter:   5704/156230 | loss: 1.1322 | ds_loss: 1.1475 | lr: 9.9674e-05 | scale: 65536.0000 | micro time: 1.332 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5705/156230 | global iter:   5705/156230 | loss: 1.0125 | ds_loss: 1.0368 | lr: 9.9674e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   5706/156230 | global iter:   5706/156230 | loss: 1.1152 | ds_loss: 1.1353 | lr: 9.9674e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   5707/156230 | global iter:   5707/156230 | loss: 1.2369 | ds_loss: 1.2510 | lr: 9.9674e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   5708/156230 | global iter:   5708/156230 | loss: 0.9476 | ds_loss: 0.9726 | lr: 9.9674e-05 | scale: 65536.0000 | micro time: 1.315 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5708/156230 | global iter:   5708/156230 | loss: 1.0780 | ds_loss: 1.0989 | lr: 9.9674e-05 | scale: 65536.0000 | micro time: 1.315 | step time: 1.339
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5709/156230 | global iter:   5709/156230 | loss: 1.1332 | ds_loss: 1.1687 | lr: 9.9674e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   5710/156230 | global iter:   5710/156230 | loss: 1.0507 | ds_loss: 1.0661 | lr: 9.9674e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   5711/156230 | global iter:   5711/156230 | loss: 1.0764 | ds_loss: 1.0936 | lr: 9.9673e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   5712/156230 | global iter:   5712/156230 | loss: 1.0471 | ds_loss: 1.0700 | lr: 9.9673e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5712/156230 | global iter:   5712/156230 | loss: 1.0769 | ds_loss: 1.0996 | lr: 9.9673e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5713/156230 | global iter:   5713/156230 | loss: 0.9252 | ds_loss: 0.9440 | lr: 9.9673e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   5714/156230 | global iter:   5714/156230 | loss: 1.0139 | ds_loss: 1.0279 | lr: 9.9673e-05 | scale: 65536.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   5715/156230 | global iter:   5715/156230 | loss: 1.1746 | ds_loss: 1.1975 | lr: 9.9673e-05 | scale: 65536.0000 | micro time: 1.417 | step time: 0.000
train | epoch   0 | Iter:   5716/156230 | global iter:   5716/156230 | loss: 1.0866 | ds_loss: 1.1027 | lr: 9.9673e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5716/156230 | global iter:   5716/156230 | loss: 1.0501 | ds_loss: 1.0680 | lr: 9.9673e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5717/156230 | global iter:   5717/156230 | loss: 1.1429 | ds_loss: 1.1479 | lr: 9.9673e-05 | scale: 65536.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   5718/156230 | global iter:   5718/156230 | loss: 1.0633 | ds_loss: 1.0720 | lr: 9.9673e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   5719/156230 | global iter:   5719/156230 | loss: 1.2383 | ds_loss: 1.2492 | lr: 9.9672e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   5720/156230 | global iter:   5720/156230 | loss: 1.1891 | ds_loss: 1.1947 | lr: 9.9672e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5720/156230 | global iter:   5720/156230 | loss: 1.1584 | ds_loss: 1.1659 | lr: 9.9672e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5721/156230 | global iter:   5721/156230 | loss: 1.2157 | ds_loss: 1.2411 | lr: 9.9672e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   5722/156230 | global iter:   5722/156230 | loss: 1.1920 | ds_loss: 1.2078 | lr: 9.9672e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   5723/156230 | global iter:   5723/156230 | loss: 1.1632 | ds_loss: 1.1950 | lr: 9.9672e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   5724/156230 | global iter:   5724/156230 | loss: 1.2620 | ds_loss: 1.2868 | lr: 9.9672e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5724/156230 | global iter:   5724/156230 | loss: 1.2082 | ds_loss: 1.2327 | lr: 9.9672e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5725/156230 | global iter:   5725/156230 | loss: 1.2357 | ds_loss: 1.2487 | lr: 9.9672e-05 | scale: 65536.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   5726/156230 | global iter:   5726/156230 | loss: 1.1354 | ds_loss: 1.1497 | lr: 9.9672e-05 | scale: 65536.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   5727/156230 | global iter:   5727/156230 | loss: 1.1832 | ds_loss: 1.1722 | lr: 9.9672e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   5728/156230 | global iter:   5728/156230 | loss: 1.1327 | ds_loss: 1.1588 | lr: 9.9671e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5728/156230 | global iter:   5728/156230 | loss: 1.1718 | ds_loss: 1.1823 | lr: 9.9671e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5729/156230 | global iter:   5729/156230 | loss: 1.3105 | ds_loss: 1.3432 | lr: 9.9671e-05 | scale: 65536.0000 | micro time: 1.411 | step time: 0.000
train | epoch   0 | Iter:   5730/156230 | global iter:   5730/156230 | loss: 1.1791 | ds_loss: 1.1975 | lr: 9.9671e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   5731/156230 | global iter:   5731/156230 | loss: 1.1383 | ds_loss: 1.1740 | lr: 9.9671e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   5732/156230 | global iter:   5732/156230 | loss: 0.9998 | ds_loss: 1.0282 | lr: 9.9671e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5732/156230 | global iter:   5732/156230 | loss: 1.1569 | ds_loss: 1.1857 | lr: 9.9671e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 1.376
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5733/156230 | global iter:   5733/156230 | loss: 1.1748 | ds_loss: 1.2088 | lr: 9.9671e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   5734/156230 | global iter:   5734/156230 | loss: 1.2635 | ds_loss: 1.2828 | lr: 9.9671e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   5735/156230 | global iter:   5735/156230 | loss: 1.1606 | ds_loss: 1.1748 | lr: 9.9671e-05 | scale: 65536.0000 | micro time: 1.314 | step time: 0.000
train | epoch   0 | Iter:   5736/156230 | global iter:   5736/156230 | loss: 1.0336 | ds_loss: 1.0594 | lr: 9.9671e-05 | scale: 65536.0000 | micro time: 1.327 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5736/156230 | global iter:   5736/156230 | loss: 1.1582 | ds_loss: 1.1815 | lr: 9.9671e-05 | scale: 65536.0000 | micro time: 1.327 | step time: 1.341
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5737/156230 | global iter:   5737/156230 | loss: 1.0168 | ds_loss: 1.0314 | lr: 9.9670e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   5738/156230 | global iter:   5738/156230 | loss: 0.9815 | ds_loss: 0.9993 | lr: 9.9670e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   5739/156230 | global iter:   5739/156230 | loss: 0.9965 | ds_loss: 1.0319 | lr: 9.9670e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   5740/156230 | global iter:   5740/156230 | loss: 1.3404 | ds_loss: 1.3585 | lr: 9.9670e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5740/156230 | global iter:   5740/156230 | loss: 1.0838 | ds_loss: 1.1053 | lr: 9.9670e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5741/156230 | global iter:   5741/156230 | loss: 1.1980 | ds_loss: 1.2141 | lr: 9.9670e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   5742/156230 | global iter:   5742/156230 | loss: 0.9925 | ds_loss: 1.0136 | lr: 9.9670e-05 | scale: 65536.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   5743/156230 | global iter:   5743/156230 | loss: 1.2049 | ds_loss: 1.2136 | lr: 9.9670e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   5744/156230 | global iter:   5744/156230 | loss: 1.0840 | ds_loss: 1.0904 | lr: 9.9670e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5744/156230 | global iter:   5744/156230 | loss: 1.1198 | ds_loss: 1.1329 | lr: 9.9670e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5745/156230 | global iter:   5745/156230 | loss: 1.0415 | ds_loss: 1.0692 | lr: 9.9669e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   5746/156230 | global iter:   5746/156230 | loss: 1.0311 | ds_loss: 1.0391 | lr: 9.9669e-05 | scale: 65536.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   5747/156230 | global iter:   5747/156230 | loss: 1.0379 | ds_loss: 1.0576 | lr: 9.9669e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   5748/156230 | global iter:   5748/156230 | loss: 1.0018 | ds_loss: 1.0340 | lr: 9.9669e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5748/156230 | global iter:   5748/156230 | loss: 1.0281 | ds_loss: 1.0499 | lr: 9.9669e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5749/156230 | global iter:   5749/156230 | loss: 1.2273 | ds_loss: 1.2372 | lr: 9.9669e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   5750/156230 | global iter:   5750/156230 | loss: 1.0135 | ds_loss: 1.0369 | lr: 9.9669e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   5751/156230 | global iter:   5751/156230 | loss: 1.2015 | ds_loss: 1.2162 | lr: 9.9669e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   5752/156230 | global iter:   5752/156230 | loss: 0.9882 | ds_loss: 1.0073 | lr: 9.9669e-05 | scale: 65536.0000 | micro time: 1.343 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5752/156230 | global iter:   5752/156230 | loss: 1.1077 | ds_loss: 1.1244 | lr: 9.9669e-05 | scale: 65536.0000 | micro time: 1.343 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5753/156230 | global iter:   5753/156230 | loss: 1.1177 | ds_loss: 1.1409 | lr: 9.9669e-05 | scale: 65536.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   5754/156230 | global iter:   5754/156230 | loss: 1.1203 | ds_loss: 1.1508 | lr: 9.9668e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   5755/156230 | global iter:   5755/156230 | loss: 1.1258 | ds_loss: 1.1617 | lr: 9.9668e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   5756/156230 | global iter:   5756/156230 | loss: 1.1644 | ds_loss: 1.1811 | lr: 9.9668e-05 | scale: 65536.0000 | micro time: 1.407 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5756/156230 | global iter:   5756/156230 | loss: 1.1321 | ds_loss: 1.1586 | lr: 9.9668e-05 | scale: 65536.0000 | micro time: 1.407 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5757/156230 | global iter:   5757/156230 | loss: 1.0705 | ds_loss: 1.0745 | lr: 9.9668e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   5758/156230 | global iter:   5758/156230 | loss: 1.0396 | ds_loss: 1.0455 | lr: 9.9668e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   5759/156230 | global iter:   5759/156230 | loss: 0.9701 | ds_loss: 1.0040 | lr: 9.9668e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   5760/156230 | global iter:   5760/156230 | loss: 1.0713 | ds_loss: 1.0821 | lr: 9.9668e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5760/156230 | global iter:   5760/156230 | loss: 1.0378 | ds_loss: 1.0515 | lr: 9.9668e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5761/156230 | global iter:   5761/156230 | loss: 1.2090 | ds_loss: 1.2211 | lr: 9.9668e-05 | scale: 65536.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   5762/156230 | global iter:   5762/156230 | loss: 1.0645 | ds_loss: 1.0840 | lr: 9.9668e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   5763/156230 | global iter:   5763/156230 | loss: 1.1113 | ds_loss: 1.1213 | lr: 9.9667e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   5764/156230 | global iter:   5764/156230 | loss: 1.2505 | ds_loss: 1.2661 | lr: 9.9667e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5764/156230 | global iter:   5764/156230 | loss: 1.1588 | ds_loss: 1.1731 | lr: 9.9667e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5765/156230 | global iter:   5765/156230 | loss: 1.0526 | ds_loss: 1.0539 | lr: 9.9667e-05 | scale: 65536.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   5766/156230 | global iter:   5766/156230 | loss: 1.0630 | ds_loss: 1.0817 | lr: 9.9667e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   5767/156230 | global iter:   5767/156230 | loss: 1.1710 | ds_loss: 1.1793 | lr: 9.9667e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   5768/156230 | global iter:   5768/156230 | loss: 0.9732 | ds_loss: 0.9983 | lr: 9.9667e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5768/156230 | global iter:   5768/156230 | loss: 1.0650 | ds_loss: 1.0783 | lr: 9.9667e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5769/156230 | global iter:   5769/156230 | loss: 1.1647 | ds_loss: 1.1779 | lr: 9.9667e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   5770/156230 | global iter:   5770/156230 | loss: 1.1163 | ds_loss: 1.1167 | lr: 9.9667e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   5771/156230 | global iter:   5771/156230 | loss: 1.0466 | ds_loss: 1.0443 | lr: 9.9666e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   5772/156230 | global iter:   5772/156230 | loss: 0.9894 | ds_loss: 1.0157 | lr: 9.9666e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5772/156230 | global iter:   5772/156230 | loss: 1.0792 | ds_loss: 1.0887 | lr: 9.9666e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5773/156230 | global iter:   5773/156230 | loss: 1.3351 | ds_loss: 1.3548 | lr: 9.9666e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   5774/156230 | global iter:   5774/156230 | loss: 1.1784 | ds_loss: 1.1994 | lr: 9.9666e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   5775/156230 | global iter:   5775/156230 | loss: 1.0156 | ds_loss: 1.0317 | lr: 9.9666e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   5776/156230 | global iter:   5776/156230 | loss: 1.2004 | ds_loss: 1.2249 | lr: 9.9666e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5776/156230 | global iter:   5776/156230 | loss: 1.1824 | ds_loss: 1.2027 | lr: 9.9666e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5777/156230 | global iter:   5777/156230 | loss: 1.1649 | ds_loss: 1.1744 | lr: 9.9666e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   5778/156230 | global iter:   5778/156230 | loss: 1.1022 | ds_loss: 1.1225 | lr: 9.9666e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   5779/156230 | global iter:   5779/156230 | loss: 1.2291 | ds_loss: 1.2380 | lr: 9.9666e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   5780/156230 | global iter:   5780/156230 | loss: 1.0632 | ds_loss: 1.0807 | lr: 9.9665e-05 | scale: 65536.0000 | micro time: 1.409 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5780/156230 | global iter:   5780/156230 | loss: 1.1398 | ds_loss: 1.1539 | lr: 9.9665e-05 | scale: 65536.0000 | micro time: 1.409 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5781/156230 | global iter:   5781/156230 | loss: 1.1047 | ds_loss: 1.0997 | lr: 9.9665e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   5782/156230 | global iter:   5782/156230 | loss: 1.0417 | ds_loss: 1.0474 | lr: 9.9665e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   5783/156230 | global iter:   5783/156230 | loss: 1.1579 | ds_loss: 1.1798 | lr: 9.9665e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   5784/156230 | global iter:   5784/156230 | loss: 1.1016 | ds_loss: 1.1153 | lr: 9.9665e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5784/156230 | global iter:   5784/156230 | loss: 1.1015 | ds_loss: 1.1105 | lr: 9.9665e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5785/156230 | global iter:   5785/156230 | loss: 1.0505 | ds_loss: 1.0614 | lr: 9.9665e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   5786/156230 | global iter:   5786/156230 | loss: 0.9835 | ds_loss: 0.9962 | lr: 9.9665e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   5787/156230 | global iter:   5787/156230 | loss: 0.9551 | ds_loss: 0.9583 | lr: 9.9665e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   5788/156230 | global iter:   5788/156230 | loss: 1.0251 | ds_loss: 1.0313 | lr: 9.9665e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5788/156230 | global iter:   5788/156230 | loss: 1.0036 | ds_loss: 1.0118 | lr: 9.9665e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5789/156230 | global iter:   5789/156230 | loss: 1.0279 | ds_loss: 1.0580 | lr: 9.9664e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   5790/156230 | global iter:   5790/156230 | loss: 1.0953 | ds_loss: 1.1262 | lr: 9.9664e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   5791/156230 | global iter:   5791/156230 | loss: 1.2005 | ds_loss: 1.2286 | lr: 9.9664e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   5792/156230 | global iter:   5792/156230 | loss: 1.0167 | ds_loss: 1.0296 | lr: 9.9664e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5792/156230 | global iter:   5792/156230 | loss: 1.0851 | ds_loss: 1.1106 | lr: 9.9664e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5793/156230 | global iter:   5793/156230 | loss: 1.0989 | ds_loss: 1.1211 | lr: 9.9664e-05 | scale: 65536.0000 | micro time: 1.417 | step time: 0.000
train | epoch   0 | Iter:   5794/156230 | global iter:   5794/156230 | loss: 0.9518 | ds_loss: 0.9669 | lr: 9.9664e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   5795/156230 | global iter:   5795/156230 | loss: 1.0998 | ds_loss: 1.1187 | lr: 9.9664e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   5796/156230 | global iter:   5796/156230 | loss: 1.2425 | ds_loss: 1.2562 | lr: 9.9664e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5796/156230 | global iter:   5796/156230 | loss: 1.0982 | ds_loss: 1.1157 | lr: 9.9664e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5797/156230 | global iter:   5797/156230 | loss: 0.9847 | ds_loss: 0.9970 | lr: 9.9663e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   5798/156230 | global iter:   5798/156230 | loss: 1.0856 | ds_loss: 1.1123 | lr: 9.9663e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   5799/156230 | global iter:   5799/156230 | loss: 1.2164 | ds_loss: 1.2362 | lr: 9.9663e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   5800/156230 | global iter:   5800/156230 | loss: 1.1301 | ds_loss: 1.1657 | lr: 9.9663e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5800/156230 | global iter:   5800/156230 | loss: 1.1042 | ds_loss: 1.1278 | lr: 9.9663e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5801/156230 | global iter:   5801/156230 | loss: 1.3079 | ds_loss: 1.3208 | lr: 9.9663e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   5802/156230 | global iter:   5802/156230 | loss: 1.2696 | ds_loss: 1.2700 | lr: 9.9663e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   5803/156230 | global iter:   5803/156230 | loss: 1.2672 | ds_loss: 1.2783 | lr: 9.9663e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   5804/156230 | global iter:   5804/156230 | loss: 1.0896 | ds_loss: 1.1130 | lr: 9.9663e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5804/156230 | global iter:   5804/156230 | loss: 1.2336 | ds_loss: 1.2455 | lr: 9.9663e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5805/156230 | global iter:   5805/156230 | loss: 0.8745 | ds_loss: 0.8777 | lr: 9.9663e-05 | scale: 65536.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   5806/156230 | global iter:   5806/156230 | loss: 1.1751 | ds_loss: 1.1741 | lr: 9.9662e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   5807/156230 | global iter:   5807/156230 | loss: 1.1781 | ds_loss: 1.1889 | lr: 9.9662e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   5808/156230 | global iter:   5808/156230 | loss: 1.1436 | ds_loss: 1.1511 | lr: 9.9662e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5808/156230 | global iter:   5808/156230 | loss: 1.0928 | ds_loss: 1.0980 | lr: 9.9662e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5809/156230 | global iter:   5809/156230 | loss: 1.1434 | ds_loss: 1.1653 | lr: 9.9662e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   5810/156230 | global iter:   5810/156230 | loss: 0.9366 | ds_loss: 0.9458 | lr: 9.9662e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   5811/156230 | global iter:   5811/156230 | loss: 1.0849 | ds_loss: 1.1111 | lr: 9.9662e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   5812/156230 | global iter:   5812/156230 | loss: 1.0052 | ds_loss: 1.0282 | lr: 9.9662e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5812/156230 | global iter:   5812/156230 | loss: 1.0425 | ds_loss: 1.0626 | lr: 9.9662e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5813/156230 | global iter:   5813/156230 | loss: 1.0303 | ds_loss: 1.0397 | lr: 9.9662e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   5814/156230 | global iter:   5814/156230 | loss: 0.9343 | ds_loss: 0.9511 | lr: 9.9661e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   5815/156230 | global iter:   5815/156230 | loss: 1.0556 | ds_loss: 1.0752 | lr: 9.9661e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   5816/156230 | global iter:   5816/156230 | loss: 1.1076 | ds_loss: 1.1058 | lr: 9.9661e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5816/156230 | global iter:   5816/156230 | loss: 1.0319 | ds_loss: 1.0430 | lr: 9.9661e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5817/156230 | global iter:   5817/156230 | loss: 1.2675 | ds_loss: 1.2984 | lr: 9.9661e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   5818/156230 | global iter:   5818/156230 | loss: 1.1419 | ds_loss: 1.1529 | lr: 9.9661e-05 | scale: 65536.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   5819/156230 | global iter:   5819/156230 | loss: 1.1239 | ds_loss: 1.1384 | lr: 9.9661e-05 | scale: 65536.0000 | micro time: 1.400 | step time: 0.000
train | epoch   0 | Iter:   5820/156230 | global iter:   5820/156230 | loss: 1.0929 | ds_loss: 1.1297 | lr: 9.9661e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5820/156230 | global iter:   5820/156230 | loss: 1.1566 | ds_loss: 1.1799 | lr: 9.9661e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5821/156230 | global iter:   5821/156230 | loss: 1.1682 | ds_loss: 1.1950 | lr: 9.9661e-05 | scale: 65536.0000 | micro time: 1.321 | step time: 0.000
train | epoch   0 | Iter:   5822/156230 | global iter:   5822/156230 | loss: 0.9423 | ds_loss: 0.9521 | lr: 9.9661e-05 | scale: 65536.0000 | micro time: 1.325 | step time: 0.000
train | epoch   0 | Iter:   5823/156230 | global iter:   5823/156230 | loss: 1.0981 | ds_loss: 1.1058 | lr: 9.9660e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   5824/156230 | global iter:   5824/156230 | loss: 1.2137 | ds_loss: 1.2363 | lr: 9.9660e-05 | scale: 65536.0000 | micro time: 1.390 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5824/156230 | global iter:   5824/156230 | loss: 1.1056 | ds_loss: 1.1223 | lr: 9.9660e-05 | scale: 65536.0000 | micro time: 1.390 | step time: 1.344
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5825/156230 | global iter:   5825/156230 | loss: 1.1501 | ds_loss: 1.1667 | lr: 9.9660e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   5826/156230 | global iter:   5826/156230 | loss: 1.1084 | ds_loss: 1.1279 | lr: 9.9660e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   5827/156230 | global iter:   5827/156230 | loss: 1.1614 | ds_loss: 1.1628 | lr: 9.9660e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   5828/156230 | global iter:   5828/156230 | loss: 1.1540 | ds_loss: 1.1713 | lr: 9.9660e-05 | scale: 65536.0000 | micro time: 1.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5828/156230 | global iter:   5828/156230 | loss: 1.1434 | ds_loss: 1.1572 | lr: 9.9660e-05 | scale: 65536.0000 | micro time: 1.394 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5829/156230 | global iter:   5829/156230 | loss: 1.1619 | ds_loss: 1.1756 | lr: 9.9660e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   5830/156230 | global iter:   5830/156230 | loss: 0.9625 | ds_loss: 0.9812 | lr: 9.9660e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   5831/156230 | global iter:   5831/156230 | loss: 0.9265 | ds_loss: 0.9598 | lr: 9.9659e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   5832/156230 | global iter:   5832/156230 | loss: 1.1657 | ds_loss: 1.1751 | lr: 9.9659e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5832/156230 | global iter:   5832/156230 | loss: 1.0541 | ds_loss: 1.0729 | lr: 9.9659e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5833/156230 | global iter:   5833/156230 | loss: 1.1471 | ds_loss: 1.1655 | lr: 9.9659e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   5834/156230 | global iter:   5834/156230 | loss: 1.0324 | ds_loss: 1.0530 | lr: 9.9659e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   5835/156230 | global iter:   5835/156230 | loss: 1.1236 | ds_loss: 1.1593 | lr: 9.9659e-05 | scale: 65536.0000 | micro time: 1.310 | step time: 0.000
train | epoch   0 | Iter:   5836/156230 | global iter:   5836/156230 | loss: 1.1459 | ds_loss: 1.1681 | lr: 9.9659e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5836/156230 | global iter:   5836/156230 | loss: 1.1122 | ds_loss: 1.1365 | lr: 9.9659e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5837/156230 | global iter:   5837/156230 | loss: 1.0920 | ds_loss: 1.1079 | lr: 9.9659e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   5838/156230 | global iter:   5838/156230 | loss: 1.0972 | ds_loss: 1.1237 | lr: 9.9659e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   5839/156230 | global iter:   5839/156230 | loss: 1.0097 | ds_loss: 1.0288 | lr: 9.9659e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   5840/156230 | global iter:   5840/156230 | loss: 1.0059 | ds_loss: 1.0394 | lr: 9.9658e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5840/156230 | global iter:   5840/156230 | loss: 1.0512 | ds_loss: 1.0750 | lr: 9.9658e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 1.347
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5841/156230 | global iter:   5841/156230 | loss: 1.1026 | ds_loss: 1.0988 | lr: 9.9658e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   5842/156230 | global iter:   5842/156230 | loss: 1.0911 | ds_loss: 1.1057 | lr: 9.9658e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   5843/156230 | global iter:   5843/156230 | loss: 1.1487 | ds_loss: 1.1652 | lr: 9.9658e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   5844/156230 | global iter:   5844/156230 | loss: 1.2202 | ds_loss: 1.2463 | lr: 9.9658e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5844/156230 | global iter:   5844/156230 | loss: 1.1407 | ds_loss: 1.1540 | lr: 9.9658e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5845/156230 | global iter:   5845/156230 | loss: 1.0687 | ds_loss: 1.0824 | lr: 9.9658e-05 | scale: 65536.0000 | micro time: 1.416 | step time: 0.000
train | epoch   0 | Iter:   5846/156230 | global iter:   5846/156230 | loss: 1.0951 | ds_loss: 1.0932 | lr: 9.9658e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   5847/156230 | global iter:   5847/156230 | loss: 1.1318 | ds_loss: 1.1486 | lr: 9.9658e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   5848/156230 | global iter:   5848/156230 | loss: 1.0500 | ds_loss: 1.0751 | lr: 9.9657e-05 | scale: 65536.0000 | micro time: 1.333 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5848/156230 | global iter:   5848/156230 | loss: 1.0864 | ds_loss: 1.0998 | lr: 9.9657e-05 | scale: 65536.0000 | micro time: 1.333 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5849/156230 | global iter:   5849/156230 | loss: 1.0944 | ds_loss: 1.1225 | lr: 9.9657e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   5850/156230 | global iter:   5850/156230 | loss: 1.0987 | ds_loss: 1.1314 | lr: 9.9657e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   5851/156230 | global iter:   5851/156230 | loss: 1.0126 | ds_loss: 1.0324 | lr: 9.9657e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   5852/156230 | global iter:   5852/156230 | loss: 1.1157 | ds_loss: 1.1466 | lr: 9.9657e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5852/156230 | global iter:   5852/156230 | loss: 1.0804 | ds_loss: 1.1082 | lr: 9.9657e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5853/156230 | global iter:   5853/156230 | loss: 1.2122 | ds_loss: 1.2220 | lr: 9.9657e-05 | scale: 65536.0000 | micro time: 1.410 | step time: 0.000
train | epoch   0 | Iter:   5854/156230 | global iter:   5854/156230 | loss: 1.1177 | ds_loss: 1.1457 | lr: 9.9657e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   5855/156230 | global iter:   5855/156230 | loss: 1.1417 | ds_loss: 1.1520 | lr: 9.9657e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   5856/156230 | global iter:   5856/156230 | loss: 1.0791 | ds_loss: 1.0930 | lr: 9.9657e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5856/156230 | global iter:   5856/156230 | loss: 1.1377 | ds_loss: 1.1531 | lr: 9.9657e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5857/156230 | global iter:   5857/156230 | loss: 1.2721 | ds_loss: 1.2864 | lr: 9.9656e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   5858/156230 | global iter:   5858/156230 | loss: 1.0729 | ds_loss: 1.0847 | lr: 9.9656e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   5859/156230 | global iter:   5859/156230 | loss: 1.1837 | ds_loss: 1.2142 | lr: 9.9656e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   5860/156230 | global iter:   5860/156230 | loss: 1.0437 | ds_loss: 1.0608 | lr: 9.9656e-05 | scale: 65536.0000 | micro time: 1.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5860/156230 | global iter:   5860/156230 | loss: 1.1431 | ds_loss: 1.1615 | lr: 9.9656e-05 | scale: 65536.0000 | micro time: 1.397 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5861/156230 | global iter:   5861/156230 | loss: 1.1740 | ds_loss: 1.1842 | lr: 9.9656e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   5862/156230 | global iter:   5862/156230 | loss: 1.1469 | ds_loss: 1.1629 | lr: 9.9656e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   5863/156230 | global iter:   5863/156230 | loss: 1.1031 | ds_loss: 1.1276 | lr: 9.9656e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   5864/156230 | global iter:   5864/156230 | loss: 1.0415 | ds_loss: 1.0588 | lr: 9.9656e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5864/156230 | global iter:   5864/156230 | loss: 1.1164 | ds_loss: 1.1334 | lr: 9.9656e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5865/156230 | global iter:   5865/156230 | loss: 1.1203 | ds_loss: 1.1200 | lr: 9.9655e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   5866/156230 | global iter:   5866/156230 | loss: 0.9853 | ds_loss: 0.9975 | lr: 9.9655e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   5867/156230 | global iter:   5867/156230 | loss: 1.1242 | ds_loss: 1.1371 | lr: 9.9655e-05 | scale: 65536.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   5868/156230 | global iter:   5868/156230 | loss: 1.1755 | ds_loss: 1.1876 | lr: 9.9655e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5868/156230 | global iter:   5868/156230 | loss: 1.1013 | ds_loss: 1.1105 | lr: 9.9655e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5869/156230 | global iter:   5869/156230 | loss: 1.1684 | ds_loss: 1.1951 | lr: 9.9655e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   5870/156230 | global iter:   5870/156230 | loss: 0.9951 | ds_loss: 1.0103 | lr: 9.9655e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   5871/156230 | global iter:   5871/156230 | loss: 1.1697 | ds_loss: 1.1826 | lr: 9.9655e-05 | scale: 65536.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   5872/156230 | global iter:   5872/156230 | loss: 1.2917 | ds_loss: 1.3141 | lr: 9.9655e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5872/156230 | global iter:   5872/156230 | loss: 1.1563 | ds_loss: 1.1755 | lr: 9.9655e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5873/156230 | global iter:   5873/156230 | loss: 1.0644 | ds_loss: 1.0730 | lr: 9.9655e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   5874/156230 | global iter:   5874/156230 | loss: 1.0260 | ds_loss: 1.0479 | lr: 9.9654e-05 | scale: 65536.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:   5875/156230 | global iter:   5875/156230 | loss: 1.0438 | ds_loss: 1.0681 | lr: 9.9654e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   5876/156230 | global iter:   5876/156230 | loss: 1.1602 | ds_loss: 1.1964 | lr: 9.9654e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5876/156230 | global iter:   5876/156230 | loss: 1.0736 | ds_loss: 1.0963 | lr: 9.9654e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5877/156230 | global iter:   5877/156230 | loss: 1.1414 | ds_loss: 1.1668 | lr: 9.9654e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   5878/156230 | global iter:   5878/156230 | loss: 1.0709 | ds_loss: 1.0920 | lr: 9.9654e-05 | scale: 65536.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   5879/156230 | global iter:   5879/156230 | loss: 1.1383 | ds_loss: 1.1441 | lr: 9.9654e-05 | scale: 65536.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   5880/156230 | global iter:   5880/156230 | loss: 0.9111 | ds_loss: 0.9329 | lr: 9.9654e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5880/156230 | global iter:   5880/156230 | loss: 1.0654 | ds_loss: 1.0840 | lr: 9.9654e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 1.376
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5881/156230 | global iter:   5881/156230 | loss: 1.2275 | ds_loss: 1.2139 | lr: 9.9654e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   5882/156230 | global iter:   5882/156230 | loss: 1.1510 | ds_loss: 1.1736 | lr: 9.9653e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   5883/156230 | global iter:   5883/156230 | loss: 1.1290 | ds_loss: 1.1515 | lr: 9.9653e-05 | scale: 65536.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   5884/156230 | global iter:   5884/156230 | loss: 0.9710 | ds_loss: 0.9744 | lr: 9.9653e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5884/156230 | global iter:   5884/156230 | loss: 1.1196 | ds_loss: 1.1284 | lr: 9.9653e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5885/156230 | global iter:   5885/156230 | loss: 1.1438 | ds_loss: 1.1453 | lr: 9.9653e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   5886/156230 | global iter:   5886/156230 | loss: 1.2582 | ds_loss: 1.2653 | lr: 9.9653e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   5887/156230 | global iter:   5887/156230 | loss: 1.0855 | ds_loss: 1.1003 | lr: 9.9653e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   5888/156230 | global iter:   5888/156230 | loss: 1.1900 | ds_loss: 1.2090 | lr: 9.9653e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5888/156230 | global iter:   5888/156230 | loss: 1.1694 | ds_loss: 1.1800 | lr: 9.9653e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5889/156230 | global iter:   5889/156230 | loss: 1.2255 | ds_loss: 1.2521 | lr: 9.9653e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   5890/156230 | global iter:   5890/156230 | loss: 1.0479 | ds_loss: 1.0581 | lr: 9.9653e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   5891/156230 | global iter:   5891/156230 | loss: 1.2768 | ds_loss: 1.3035 | lr: 9.9652e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   5892/156230 | global iter:   5892/156230 | loss: 1.0380 | ds_loss: 1.0654 | lr: 9.9652e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5892/156230 | global iter:   5892/156230 | loss: 1.1471 | ds_loss: 1.1698 | lr: 9.9652e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5893/156230 | global iter:   5893/156230 | loss: 0.9930 | ds_loss: 1.0109 | lr: 9.9652e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   5894/156230 | global iter:   5894/156230 | loss: 1.1387 | ds_loss: 1.1529 | lr: 9.9652e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   5895/156230 | global iter:   5895/156230 | loss: 1.1512 | ds_loss: 1.1745 | lr: 9.9652e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   5896/156230 | global iter:   5896/156230 | loss: 1.0151 | ds_loss: 1.0461 | lr: 9.9652e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5896/156230 | global iter:   5896/156230 | loss: 1.0745 | ds_loss: 1.0961 | lr: 9.9652e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5897/156230 | global iter:   5897/156230 | loss: 1.0643 | ds_loss: 1.0967 | lr: 9.9652e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   5898/156230 | global iter:   5898/156230 | loss: 1.2234 | ds_loss: 1.2456 | lr: 9.9652e-05 | scale: 65536.0000 | micro time: 1.314 | step time: 0.000
train | epoch   0 | Iter:   5899/156230 | global iter:   5899/156230 | loss: 1.1607 | ds_loss: 1.1663 | lr: 9.9651e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   5900/156230 | global iter:   5900/156230 | loss: 1.1844 | ds_loss: 1.2094 | lr: 9.9651e-05 | scale: 65536.0000 | micro time: 1.383 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5900/156230 | global iter:   5900/156230 | loss: 1.1582 | ds_loss: 1.1795 | lr: 9.9651e-05 | scale: 65536.0000 | micro time: 1.383 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5901/156230 | global iter:   5901/156230 | loss: 1.0565 | ds_loss: 1.0831 | lr: 9.9651e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   5902/156230 | global iter:   5902/156230 | loss: 1.2921 | ds_loss: 1.3080 | lr: 9.9651e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   5903/156230 | global iter:   5903/156230 | loss: 1.1848 | ds_loss: 1.1882 | lr: 9.9651e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   5904/156230 | global iter:   5904/156230 | loss: 1.1365 | ds_loss: 1.1689 | lr: 9.9651e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5904/156230 | global iter:   5904/156230 | loss: 1.1675 | ds_loss: 1.1871 | lr: 9.9651e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5905/156230 | global iter:   5905/156230 | loss: 1.0108 | ds_loss: 1.0319 | lr: 9.9651e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   5906/156230 | global iter:   5906/156230 | loss: 1.1698 | ds_loss: 1.1793 | lr: 9.9651e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   5907/156230 | global iter:   5907/156230 | loss: 0.9734 | ds_loss: 0.9846 | lr: 9.9651e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   5908/156230 | global iter:   5908/156230 | loss: 0.8822 | ds_loss: 0.9082 | lr: 9.9650e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5908/156230 | global iter:   5908/156230 | loss: 1.0091 | ds_loss: 1.0260 | lr: 9.9650e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5909/156230 | global iter:   5909/156230 | loss: 1.1880 | ds_loss: 1.2091 | lr: 9.9650e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   5910/156230 | global iter:   5910/156230 | loss: 0.8600 | ds_loss: 0.8870 | lr: 9.9650e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   5911/156230 | global iter:   5911/156230 | loss: 0.9298 | ds_loss: 0.9415 | lr: 9.9650e-05 | scale: 65536.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   5912/156230 | global iter:   5912/156230 | loss: 1.0241 | ds_loss: 1.0280 | lr: 9.9650e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5912/156230 | global iter:   5912/156230 | loss: 1.0005 | ds_loss: 1.0164 | lr: 9.9650e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5913/156230 | global iter:   5913/156230 | loss: 1.1419 | ds_loss: 1.1718 | lr: 9.9650e-05 | scale: 65536.0000 | micro time: 1.408 | step time: 0.000
train | epoch   0 | Iter:   5914/156230 | global iter:   5914/156230 | loss: 1.3058 | ds_loss: 1.3136 | lr: 9.9650e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   5915/156230 | global iter:   5915/156230 | loss: 1.1575 | ds_loss: 1.1568 | lr: 9.9650e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   5916/156230 | global iter:   5916/156230 | loss: 1.1343 | ds_loss: 1.1431 | lr: 9.9649e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5916/156230 | global iter:   5916/156230 | loss: 1.1849 | ds_loss: 1.1963 | lr: 9.9649e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5917/156230 | global iter:   5917/156230 | loss: 0.8991 | ds_loss: 0.9112 | lr: 9.9649e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   5918/156230 | global iter:   5918/156230 | loss: 0.9476 | ds_loss: 0.9687 | lr: 9.9649e-05 | scale: 65536.0000 | micro time: 1.400 | step time: 0.000
train | epoch   0 | Iter:   5919/156230 | global iter:   5919/156230 | loss: 1.0502 | ds_loss: 1.0716 | lr: 9.9649e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   5920/156230 | global iter:   5920/156230 | loss: 1.0543 | ds_loss: 1.0709 | lr: 9.9649e-05 | scale: 65536.0000 | micro time: 1.309 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5920/156230 | global iter:   5920/156230 | loss: 0.9878 | ds_loss: 1.0056 | lr: 9.9649e-05 | scale: 65536.0000 | micro time: 1.309 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5921/156230 | global iter:   5921/156230 | loss: 0.9707 | ds_loss: 0.9726 | lr: 9.9649e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   5922/156230 | global iter:   5922/156230 | loss: 1.1299 | ds_loss: 1.1518 | lr: 9.9649e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   5923/156230 | global iter:   5923/156230 | loss: 1.4372 | ds_loss: 1.4511 | lr: 9.9649e-05 | scale: 65536.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   5924/156230 | global iter:   5924/156230 | loss: 1.1464 | ds_loss: 1.1705 | lr: 9.9649e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5924/156230 | global iter:   5924/156230 | loss: 1.1711 | ds_loss: 1.1865 | lr: 9.9649e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5925/156230 | global iter:   5925/156230 | loss: 1.0288 | ds_loss: 1.0570 | lr: 9.9648e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   5926/156230 | global iter:   5926/156230 | loss: 1.1231 | ds_loss: 1.1472 | lr: 9.9648e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   5927/156230 | global iter:   5927/156230 | loss: 1.1075 | ds_loss: 1.1154 | lr: 9.9648e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   5928/156230 | global iter:   5928/156230 | loss: 1.1091 | ds_loss: 1.1332 | lr: 9.9648e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5928/156230 | global iter:   5928/156230 | loss: 1.0921 | ds_loss: 1.1132 | lr: 9.9648e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5929/156230 | global iter:   5929/156230 | loss: 1.0812 | ds_loss: 1.0722 | lr: 9.9648e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   5930/156230 | global iter:   5930/156230 | loss: 0.9641 | ds_loss: 0.9817 | lr: 9.9648e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   5931/156230 | global iter:   5931/156230 | loss: 1.0955 | ds_loss: 1.1304 | lr: 9.9648e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   5932/156230 | global iter:   5932/156230 | loss: 1.1728 | ds_loss: 1.1688 | lr: 9.9648e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5932/156230 | global iter:   5932/156230 | loss: 1.0784 | ds_loss: 1.0883 | lr: 9.9648e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5933/156230 | global iter:   5933/156230 | loss: 1.0889 | ds_loss: 1.1006 | lr: 9.9647e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   5934/156230 | global iter:   5934/156230 | loss: 1.1029 | ds_loss: 1.1156 | lr: 9.9647e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   5935/156230 | global iter:   5935/156230 | loss: 1.1095 | ds_loss: 1.1276 | lr: 9.9647e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   5936/156230 | global iter:   5936/156230 | loss: 0.9166 | ds_loss: 0.9183 | lr: 9.9647e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5936/156230 | global iter:   5936/156230 | loss: 1.0545 | ds_loss: 1.0655 | lr: 9.9647e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5937/156230 | global iter:   5937/156230 | loss: 0.9561 | ds_loss: 0.9824 | lr: 9.9647e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   5938/156230 | global iter:   5938/156230 | loss: 1.1147 | ds_loss: 1.1325 | lr: 9.9647e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   5939/156230 | global iter:   5939/156230 | loss: 1.0197 | ds_loss: 1.0466 | lr: 9.9647e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   5940/156230 | global iter:   5940/156230 | loss: 1.0781 | ds_loss: 1.1015 | lr: 9.9647e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5940/156230 | global iter:   5940/156230 | loss: 1.0421 | ds_loss: 1.0657 | lr: 9.9647e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5941/156230 | global iter:   5941/156230 | loss: 1.2370 | ds_loss: 1.2585 | lr: 9.9646e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   5942/156230 | global iter:   5942/156230 | loss: 1.1427 | ds_loss: 1.1502 | lr: 9.9646e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   5943/156230 | global iter:   5943/156230 | loss: 1.1146 | ds_loss: 1.1357 | lr: 9.9646e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   5944/156230 | global iter:   5944/156230 | loss: 1.0752 | ds_loss: 1.0987 | lr: 9.9646e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5944/156230 | global iter:   5944/156230 | loss: 1.1424 | ds_loss: 1.1608 | lr: 9.9646e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5945/156230 | global iter:   5945/156230 | loss: 1.1502 | ds_loss: 1.1705 | lr: 9.9646e-05 | scale: 65536.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   5946/156230 | global iter:   5946/156230 | loss: 1.0223 | ds_loss: 1.0379 | lr: 9.9646e-05 | scale: 65536.0000 | micro time: 1.325 | step time: 0.000
train | epoch   0 | Iter:   5947/156230 | global iter:   5947/156230 | loss: 1.2074 | ds_loss: 1.2180 | lr: 9.9646e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   5948/156230 | global iter:   5948/156230 | loss: 1.0328 | ds_loss: 1.0439 | lr: 9.9646e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5948/156230 | global iter:   5948/156230 | loss: 1.1032 | ds_loss: 1.1176 | lr: 9.9646e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 1.343
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5949/156230 | global iter:   5949/156230 | loss: 1.0679 | ds_loss: 1.0741 | lr: 9.9646e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   5950/156230 | global iter:   5950/156230 | loss: 1.1798 | ds_loss: 1.1811 | lr: 9.9645e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   5951/156230 | global iter:   5951/156230 | loss: 1.2289 | ds_loss: 1.2384 | lr: 9.9645e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   5952/156230 | global iter:   5952/156230 | loss: 1.1386 | ds_loss: 1.1462 | lr: 9.9645e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5952/156230 | global iter:   5952/156230 | loss: 1.1538 | ds_loss: 1.1600 | lr: 9.9645e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5953/156230 | global iter:   5953/156230 | loss: 1.2174 | ds_loss: 1.2113 | lr: 9.9645e-05 | scale: 65536.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   5954/156230 | global iter:   5954/156230 | loss: 1.1819 | ds_loss: 1.1999 | lr: 9.9645e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   5955/156230 | global iter:   5955/156230 | loss: 1.0566 | ds_loss: 1.0751 | lr: 9.9645e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   5956/156230 | global iter:   5956/156230 | loss: 1.2007 | ds_loss: 1.2158 | lr: 9.9645e-05 | scale: 65536.0000 | micro time: 1.329 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5956/156230 | global iter:   5956/156230 | loss: 1.1642 | ds_loss: 1.1755 | lr: 9.9645e-05 | scale: 65536.0000 | micro time: 1.329 | step time: 1.344
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5957/156230 | global iter:   5957/156230 | loss: 1.1084 | ds_loss: 1.1447 | lr: 9.9645e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   5958/156230 | global iter:   5958/156230 | loss: 1.0822 | ds_loss: 1.0910 | lr: 9.9644e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   5959/156230 | global iter:   5959/156230 | loss: 1.2562 | ds_loss: 1.2818 | lr: 9.9644e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   5960/156230 | global iter:   5960/156230 | loss: 1.2056 | ds_loss: 1.2266 | lr: 9.9644e-05 | scale: 65536.0000 | micro time: 1.390 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5960/156230 | global iter:   5960/156230 | loss: 1.1631 | ds_loss: 1.1860 | lr: 9.9644e-05 | scale: 65536.0000 | micro time: 1.390 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5961/156230 | global iter:   5961/156230 | loss: 0.9873 | ds_loss: 0.9872 | lr: 9.9644e-05 | scale: 65536.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   5962/156230 | global iter:   5962/156230 | loss: 1.2719 | ds_loss: 1.2953 | lr: 9.9644e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   5963/156230 | global iter:   5963/156230 | loss: 1.1792 | ds_loss: 1.1995 | lr: 9.9644e-05 | scale: 65536.0000 | micro time: 1.321 | step time: 0.000
train | epoch   0 | Iter:   5964/156230 | global iter:   5964/156230 | loss: 1.0530 | ds_loss: 1.0678 | lr: 9.9644e-05 | scale: 65536.0000 | micro time: 1.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5964/156230 | global iter:   5964/156230 | loss: 1.1228 | ds_loss: 1.1374 | lr: 9.9644e-05 | scale: 65536.0000 | micro time: 1.397 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5965/156230 | global iter:   5965/156230 | loss: 1.1062 | ds_loss: 1.1201 | lr: 9.9644e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   5966/156230 | global iter:   5966/156230 | loss: 1.0943 | ds_loss: 1.1205 | lr: 9.9643e-05 | scale: 65536.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   5967/156230 | global iter:   5967/156230 | loss: 1.0360 | ds_loss: 1.0572 | lr: 9.9643e-05 | scale: 65536.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   5968/156230 | global iter:   5968/156230 | loss: 1.0355 | ds_loss: 1.0511 | lr: 9.9643e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5968/156230 | global iter:   5968/156230 | loss: 1.0680 | ds_loss: 1.0872 | lr: 9.9643e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5969/156230 | global iter:   5969/156230 | loss: 0.9892 | ds_loss: 1.0040 | lr: 9.9643e-05 | scale: 65536.0000 | micro time: 1.320 | step time: 0.000
train | epoch   0 | Iter:   5970/156230 | global iter:   5970/156230 | loss: 1.1105 | ds_loss: 1.1283 | lr: 9.9643e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   5971/156230 | global iter:   5971/156230 | loss: 1.0560 | ds_loss: 1.0718 | lr: 9.9643e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   5972/156230 | global iter:   5972/156230 | loss: 1.0110 | ds_loss: 1.0480 | lr: 9.9643e-05 | scale: 65536.0000 | micro time: 1.407 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5972/156230 | global iter:   5972/156230 | loss: 1.0417 | ds_loss: 1.0630 | lr: 9.9643e-05 | scale: 65536.0000 | micro time: 1.407 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5973/156230 | global iter:   5973/156230 | loss: 1.0587 | ds_loss: 1.0908 | lr: 9.9643e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   5974/156230 | global iter:   5974/156230 | loss: 1.3838 | ds_loss: 1.3853 | lr: 9.9643e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   5975/156230 | global iter:   5975/156230 | loss: 1.0729 | ds_loss: 1.1011 | lr: 9.9642e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   5976/156230 | global iter:   5976/156230 | loss: 0.9314 | ds_loss: 0.9567 | lr: 9.9642e-05 | scale: 65536.0000 | micro time: 1.333 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5976/156230 | global iter:   5976/156230 | loss: 1.1117 | ds_loss: 1.1335 | lr: 9.9642e-05 | scale: 65536.0000 | micro time: 1.333 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5977/156230 | global iter:   5977/156230 | loss: 1.0425 | ds_loss: 1.0658 | lr: 9.9642e-05 | scale: 65536.0000 | micro time: 1.416 | step time: 0.000
train | epoch   0 | Iter:   5978/156230 | global iter:   5978/156230 | loss: 1.0574 | ds_loss: 1.0779 | lr: 9.9642e-05 | scale: 65536.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   5979/156230 | global iter:   5979/156230 | loss: 0.9763 | ds_loss: 0.9977 | lr: 9.9642e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   5980/156230 | global iter:   5980/156230 | loss: 1.2447 | ds_loss: 1.2381 | lr: 9.9642e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5980/156230 | global iter:   5980/156230 | loss: 1.0802 | ds_loss: 1.0949 | lr: 9.9642e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5981/156230 | global iter:   5981/156230 | loss: 1.0923 | ds_loss: 1.1079 | lr: 9.9642e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   5982/156230 | global iter:   5982/156230 | loss: 0.9927 | ds_loss: 1.0124 | lr: 9.9642e-05 | scale: 65536.0000 | micro time: 1.404 | step time: 0.000
train | epoch   0 | Iter:   5983/156230 | global iter:   5983/156230 | loss: 1.0962 | ds_loss: 1.1152 | lr: 9.9641e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   5984/156230 | global iter:   5984/156230 | loss: 1.0938 | ds_loss: 1.1029 | lr: 9.9641e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5984/156230 | global iter:   5984/156230 | loss: 1.0687 | ds_loss: 1.0846 | lr: 9.9641e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 1.381
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5985/156230 | global iter:   5985/156230 | loss: 0.9949 | ds_loss: 1.0202 | lr: 9.9641e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   5986/156230 | global iter:   5986/156230 | loss: 1.2676 | ds_loss: 1.2934 | lr: 9.9641e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   5987/156230 | global iter:   5987/156230 | loss: 1.1087 | ds_loss: 1.1179 | lr: 9.9641e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   5988/156230 | global iter:   5988/156230 | loss: 0.9224 | ds_loss: 0.9402 | lr: 9.9641e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5988/156230 | global iter:   5988/156230 | loss: 1.0734 | ds_loss: 1.0929 | lr: 9.9641e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5989/156230 | global iter:   5989/156230 | loss: 1.2116 | ds_loss: 1.2452 | lr: 9.9641e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   5990/156230 | global iter:   5990/156230 | loss: 1.1661 | ds_loss: 1.1710 | lr: 9.9641e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   5991/156230 | global iter:   5991/156230 | loss: 1.0111 | ds_loss: 1.0224 | lr: 9.9640e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   5992/156230 | global iter:   5992/156230 | loss: 1.2705 | ds_loss: 1.2818 | lr: 9.9640e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5992/156230 | global iter:   5992/156230 | loss: 1.1648 | ds_loss: 1.1801 | lr: 9.9640e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5993/156230 | global iter:   5993/156230 | loss: 1.1653 | ds_loss: 1.1735 | lr: 9.9640e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   5994/156230 | global iter:   5994/156230 | loss: 1.0924 | ds_loss: 1.1142 | lr: 9.9640e-05 | scale: 65536.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   5995/156230 | global iter:   5995/156230 | loss: 1.0706 | ds_loss: 1.0865 | lr: 9.9640e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   5996/156230 | global iter:   5996/156230 | loss: 1.1146 | ds_loss: 1.1236 | lr: 9.9640e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   5996/156230 | global iter:   5996/156230 | loss: 1.1107 | ds_loss: 1.1244 | lr: 9.9640e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   5997/156230 | global iter:   5997/156230 | loss: 1.1383 | ds_loss: 1.1552 | lr: 9.9640e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   5998/156230 | global iter:   5998/156230 | loss: 1.0944 | ds_loss: 1.1146 | lr: 9.9640e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   5999/156230 | global iter:   5999/156230 | loss: 1.0716 | ds_loss: 1.0827 | lr: 9.9640e-05 | scale: 65536.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   6000/156230 | global iter:   6000/156230 | loss: 1.1450 | ds_loss: 1.1619 | lr: 9.9639e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6000/156230 | global iter:   6000/156230 | loss: 1.1123 | ds_loss: 1.1286 | lr: 9.9639e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 1.376
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6001/156230 | global iter:   6001/156230 | loss: 1.1506 | ds_loss: 1.1791 | lr: 9.9639e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   6002/156230 | global iter:   6002/156230 | loss: 0.9323 | ds_loss: 0.9487 | lr: 9.9639e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   6003/156230 | global iter:   6003/156230 | loss: 1.2820 | ds_loss: 1.2879 | lr: 9.9639e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   6004/156230 | global iter:   6004/156230 | loss: 1.1872 | ds_loss: 1.1933 | lr: 9.9639e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6004/156230 | global iter:   6004/156230 | loss: 1.1380 | ds_loss: 1.1523 | lr: 9.9639e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6005/156230 | global iter:   6005/156230 | loss: 1.0993 | ds_loss: 1.1224 | lr: 9.9639e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   6006/156230 | global iter:   6006/156230 | loss: 1.0706 | ds_loss: 1.0894 | lr: 9.9639e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   6007/156230 | global iter:   6007/156230 | loss: 1.2098 | ds_loss: 1.2322 | lr: 9.9639e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   6008/156230 | global iter:   6008/156230 | loss: 1.0966 | ds_loss: 1.1007 | lr: 9.9638e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6008/156230 | global iter:   6008/156230 | loss: 1.1191 | ds_loss: 1.1361 | lr: 9.9638e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6009/156230 | global iter:   6009/156230 | loss: 1.1681 | ds_loss: 1.1695 | lr: 9.9638e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   6010/156230 | global iter:   6010/156230 | loss: 1.0767 | ds_loss: 1.0877 | lr: 9.9638e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   6011/156230 | global iter:   6011/156230 | loss: 1.2261 | ds_loss: 1.2424 | lr: 9.9638e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   6012/156230 | global iter:   6012/156230 | loss: 1.2685 | ds_loss: 1.2717 | lr: 9.9638e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6012/156230 | global iter:   6012/156230 | loss: 1.1848 | ds_loss: 1.1928 | lr: 9.9638e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6013/156230 | global iter:   6013/156230 | loss: 1.1424 | ds_loss: 1.1641 | lr: 9.9638e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   6014/156230 | global iter:   6014/156230 | loss: 0.9349 | ds_loss: 0.9741 | lr: 9.9638e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   6015/156230 | global iter:   6015/156230 | loss: 1.1034 | ds_loss: 1.1322 | lr: 9.9638e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   6016/156230 | global iter:   6016/156230 | loss: 1.0301 | ds_loss: 1.0567 | lr: 9.9637e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6016/156230 | global iter:   6016/156230 | loss: 1.0527 | ds_loss: 1.0818 | lr: 9.9637e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6017/156230 | global iter:   6017/156230 | loss: 1.0850 | ds_loss: 1.1137 | lr: 9.9637e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   6018/156230 | global iter:   6018/156230 | loss: 1.2199 | ds_loss: 1.2297 | lr: 9.9637e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   6019/156230 | global iter:   6019/156230 | loss: 1.2170 | ds_loss: 1.2461 | lr: 9.9637e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   6020/156230 | global iter:   6020/156230 | loss: 1.1252 | ds_loss: 1.1380 | lr: 9.9637e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6020/156230 | global iter:   6020/156230 | loss: 1.1618 | ds_loss: 1.1819 | lr: 9.9637e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6021/156230 | global iter:   6021/156230 | loss: 0.8910 | ds_loss: 0.9119 | lr: 9.9637e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   6022/156230 | global iter:   6022/156230 | loss: 1.1707 | ds_loss: 1.2008 | lr: 9.9637e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   6023/156230 | global iter:   6023/156230 | loss: 1.0589 | ds_loss: 1.0660 | lr: 9.9637e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   6024/156230 | global iter:   6024/156230 | loss: 1.0806 | ds_loss: 1.0815 | lr: 9.9637e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6024/156230 | global iter:   6024/156230 | loss: 1.0503 | ds_loss: 1.0651 | lr: 9.9637e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6025/156230 | global iter:   6025/156230 | loss: 1.2267 | ds_loss: 1.2310 | lr: 9.9636e-05 | scale: 131072.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   6026/156230 | global iter:   6026/156230 | loss: 1.2027 | ds_loss: 1.2145 | lr: 9.9636e-05 | scale: 131072.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   6027/156230 | global iter:   6027/156230 | loss: 1.1794 | ds_loss: 1.1768 | lr: 9.9636e-05 | scale: 131072.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   6028/156230 | global iter:   6028/156230 | loss: 1.1384 | ds_loss: 1.1730 | lr: 9.9636e-05 | scale: 131072.0000 | micro time: 1.412 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6028/156230 | global iter:   6028/156230 | loss: 1.1868 | ds_loss: 1.1988 | lr: 9.9636e-05 | scale: 131072.0000 | micro time: 1.412 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6029/156230 | global iter:   6029/156230 | loss: 1.2234 | ds_loss: 1.2546 | lr: 9.9636e-05 | scale: 131072.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   6030/156230 | global iter:   6030/156230 | loss: 1.1265 | ds_loss: 1.1618 | lr: 9.9636e-05 | scale: 131072.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   6031/156230 | global iter:   6031/156230 | loss: 1.0040 | ds_loss: 1.0245 | lr: 9.9636e-05 | scale: 131072.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   6032/156230 | global iter:   6032/156230 | loss: 0.9895 | ds_loss: 0.9822 | lr: 9.9636e-05 | scale: 131072.0000 | micro time: 1.339 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6032/156230 | global iter:   6032/156230 | loss: 1.0859 | ds_loss: 1.1058 | lr: 9.9636e-05 | scale: 131072.0000 | micro time: 1.339 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6033/156230 | global iter:   6033/156230 | loss: 1.1439 | ds_loss: 1.1488 | lr: 9.9635e-05 | scale: 131072.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   6034/156230 | global iter:   6034/156230 | loss: 1.2492 | ds_loss: 1.2538 | lr: 9.9635e-05 | scale: 131072.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   6035/156230 | global iter:   6035/156230 | loss: 1.2881 | ds_loss: 1.3056 | lr: 9.9635e-05 | scale: 131072.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   6036/156230 | global iter:   6036/156230 | loss: 1.1111 | ds_loss: 1.1400 | lr: 9.9635e-05 | scale: 131072.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6036/156230 | global iter:   6036/156230 | loss: 1.1981 | ds_loss: 1.2120 | lr: 9.9635e-05 | scale: 131072.0000 | micro time: 1.376 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6037/156230 | global iter:   6037/156230 | loss: 1.2037 | ds_loss: 1.2310 | lr: 9.9635e-05 | scale: 131072.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   6038/156230 | global iter:   6038/156230 | loss: 1.1461 | ds_loss: 1.1811 | lr: 9.9635e-05 | scale: 131072.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   6039/156230 | global iter:   6039/156230 | loss: 1.1583 | ds_loss: 1.1890 | lr: 9.9635e-05 | scale: 131072.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   6040/156230 | global iter:   6040/156230 | loss: 1.1730 | ds_loss: 1.1831 | lr: 9.9635e-05 | scale: 131072.0000 | micro time: 1.380 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6040/156230 | global iter:   6040/156230 | loss: 1.1703 | ds_loss: 1.1961 | lr: 9.9635e-05 | scale: 131072.0000 | micro time: 1.380 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6041/156230 | global iter:   6041/156230 | loss: 1.1028 | ds_loss: 1.1427 | lr: 9.9634e-05 | scale: 131072.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   6042/156230 | global iter:   6042/156230 | loss: 0.9515 | ds_loss: 0.9535 | lr: 9.9634e-05 | scale: 131072.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   6043/156230 | global iter:   6043/156230 | loss: 1.1795 | ds_loss: 1.1939 | lr: 9.9634e-05 | scale: 131072.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   6044/156230 | global iter:   6044/156230 | loss: 1.2348 | ds_loss: 1.2469 | lr: 9.9634e-05 | scale: 131072.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6044/156230 | global iter:   6044/156230 | loss: 1.1171 | ds_loss: 1.1343 | lr: 9.9634e-05 | scale: 131072.0000 | micro time: 1.345 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6045/156230 | global iter:   6045/156230 | loss: 1.0105 | ds_loss: 1.0399 | lr: 9.9634e-05 | scale: 131072.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   6046/156230 | global iter:   6046/156230 | loss: 1.1192 | ds_loss: 1.1379 | lr: 9.9634e-05 | scale: 131072.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   6047/156230 | global iter:   6047/156230 | loss: 1.0680 | ds_loss: 1.0865 | lr: 9.9634e-05 | scale: 131072.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   6048/156230 | global iter:   6048/156230 | loss: 1.1591 | ds_loss: 1.1818 | lr: 9.9634e-05 | scale: 131072.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6048/156230 | global iter:   6048/156230 | loss: 1.0892 | ds_loss: 1.1115 | lr: 9.9634e-05 | scale: 131072.0000 | micro time: 1.351 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6049/156230 | global iter:   6049/156230 | loss: 0.9029 | ds_loss: 0.9161 | lr: 9.9633e-05 | scale: 131072.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   6050/156230 | global iter:   6050/156230 | loss: 1.2593 | ds_loss: 1.2765 | lr: 9.9633e-05 | scale: 131072.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   6051/156230 | global iter:   6051/156230 | loss: 0.8570 | ds_loss: 0.8731 | lr: 9.9633e-05 | scale: 131072.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   6052/156230 | global iter:   6052/156230 | loss: 1.0556 | ds_loss: 1.0766 | lr: 9.9633e-05 | scale: 131072.0000 | micro time: 1.379 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6052/156230 | global iter:   6052/156230 | loss: 1.0187 | ds_loss: 1.0356 | lr: 9.9633e-05 | scale: 131072.0000 | micro time: 1.379 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6053/156230 | global iter:   6053/156230 | loss: 0.9516 | ds_loss: 0.9546 | lr: 9.9633e-05 | scale: 131072.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   6054/156230 | global iter:   6054/156230 | loss: 0.9802 | ds_loss: 1.0057 | lr: 9.9633e-05 | scale: 131072.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   6055/156230 | global iter:   6055/156230 | loss: 0.9467 | ds_loss: 0.9640 | lr: 9.9633e-05 | scale: 131072.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   6056/156230 | global iter:   6056/156230 | loss: 1.1268 | ds_loss: 1.1387 | lr: 9.9633e-05 | scale: 131072.0000 | micro time: 1.384 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6056/156230 | global iter:   6056/156230 | loss: 1.0013 | ds_loss: 1.0158 | lr: 9.9633e-05 | scale: 131072.0000 | micro time: 1.384 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6057/156230 | global iter:   6057/156230 | loss: 1.0756 | ds_loss: 1.0926 | lr: 9.9633e-05 | scale: 131072.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   6058/156230 | global iter:   6058/156230 | loss: 1.2697 | ds_loss: 1.2683 | lr: 9.9632e-05 | scale: 131072.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   6059/156230 | global iter:   6059/156230 | loss: 1.0653 | ds_loss: 1.0719 | lr: 9.9632e-05 | scale: 131072.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   6060/156230 | global iter:   6060/156230 | loss: 1.0494 | ds_loss: 1.0647 | lr: 9.9632e-05 | scale: 131072.0000 | micro time: 1.384 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6060/156230 | global iter:   6060/156230 | loss: 1.1150 | ds_loss: 1.1244 | lr: 9.9632e-05 | scale: 131072.0000 | micro time: 1.384 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6061/156230 | global iter:   6061/156230 | loss: 1.0099 | ds_loss: 1.0372 | lr: 9.9632e-05 | scale: 131072.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   6062/156230 | global iter:   6062/156230 | loss: 0.9637 | ds_loss: 0.9947 | lr: 9.9632e-05 | scale: 131072.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   6063/156230 | global iter:   6063/156230 | loss: 1.0695 | ds_loss: 1.0693 | lr: 9.9632e-05 | scale: 131072.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   6064/156230 | global iter:   6064/156230 | loss: 1.0471 | ds_loss: 1.0700 | lr: 9.9632e-05 | scale: 131072.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6064/156230 | global iter:   6064/156230 | loss: 1.0226 | ds_loss: 1.0428 | lr: 9.9632e-05 | scale: 131072.0000 | micro time: 1.385 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6065/156230 | global iter:   6065/156230 | loss: 1.1595 | ds_loss: 1.1745 | lr: 9.9632e-05 | scale: 131072.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   6066/156230 | global iter:   6066/156230 | loss: 1.1518 | ds_loss: 1.1660 | lr: 9.9631e-05 | scale: 131072.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   6067/156230 | global iter:   6067/156230 | loss: 1.1027 | ds_loss: 1.1146 | lr: 9.9631e-05 | scale: 131072.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   6068/156230 | global iter:   6068/156230 | loss: 1.0011 | ds_loss: 1.0167 | lr: 9.9631e-05 | scale: 131072.0000 | micro time: 1.388 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6068/156230 | global iter:   6068/156230 | loss: 1.1038 | ds_loss: 1.1180 | lr: 9.9631e-05 | scale: 131072.0000 | micro time: 1.388 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6069/156230 | global iter:   6069/156230 | loss: 1.1513 | ds_loss: 1.1659 | lr: 9.9631e-05 | scale: 131072.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   6070/156230 | global iter:   6070/156230 | loss: 0.8455 | ds_loss: 0.8782 | lr: 9.9631e-05 | scale: 131072.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   6071/156230 | global iter:   6071/156230 | loss: 1.0746 | ds_loss: 1.1004 | lr: 9.9631e-05 | scale: 131072.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   6072/156230 | global iter:   6072/156230 | loss: 1.1253 | ds_loss: 1.1565 | lr: 9.9631e-05 | scale: 131072.0000 | micro time: 1.329 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6072/156230 | global iter:   6072/156230 | loss: 1.0492 | ds_loss: 1.0752 | lr: 9.9631e-05 | scale: 131072.0000 | micro time: 1.329 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6073/156230 | global iter:   6073/156230 | loss: 1.1129 | ds_loss: 1.1309 | lr: 9.9631e-05 | scale: 131072.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   6074/156230 | global iter:   6074/156230 | loss: 1.1714 | ds_loss: 1.1879 | lr: 9.9630e-05 | scale: 131072.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   6075/156230 | global iter:   6075/156230 | loss: 1.0827 | ds_loss: 1.0951 | lr: 9.9630e-05 | scale: 131072.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   6076/156230 | global iter:   6076/156230 | loss: 1.0489 | ds_loss: 1.0734 | lr: 9.9630e-05 | scale: 131072.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6076/156230 | global iter:   6076/156230 | loss: 1.1040 | ds_loss: 1.1218 | lr: 9.9630e-05 | scale: 131072.0000 | micro time: 1.349 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6077/156230 | global iter:   6077/156230 | loss: 1.1704 | ds_loss: 1.1769 | lr: 9.9630e-05 | scale: 131072.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   6078/156230 | global iter:   6078/156230 | loss: 0.8901 | ds_loss: 0.9094 | lr: 9.9630e-05 | scale: 131072.0000 | micro time: 1.400 | step time: 0.000
train | epoch   0 | Iter:   6079/156230 | global iter:   6079/156230 | loss: 0.9838 | ds_loss: 1.0010 | lr: 9.9630e-05 | scale: 131072.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   6080/156230 | global iter:   6080/156230 | loss: 1.0048 | ds_loss: 1.0326 | lr: 9.9630e-05 | scale: 131072.0000 | micro time: 1.335 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6080/156230 | global iter:   6080/156230 | loss: 1.0123 | ds_loss: 1.0300 | lr: 9.9630e-05 | scale: 131072.0000 | micro time: 1.335 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6081/156230 | global iter:   6081/156230 | loss: 1.1250 | ds_loss: 1.1530 | lr: 9.9630e-05 | scale: 131072.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   6082/156230 | global iter:   6082/156230 | loss: 1.1720 | ds_loss: 1.1993 | lr: 9.9629e-05 | scale: 131072.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   6083/156230 | global iter:   6083/156230 | loss: 1.0332 | ds_loss: 1.0550 | lr: 9.9629e-05 | scale: 131072.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   6084/156230 | global iter:   6084/156230 | loss: 1.1845 | ds_loss: 1.1902 | lr: 9.9629e-05 | scale: 131072.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6084/156230 | global iter:   6084/156230 | loss: 1.1287 | ds_loss: 1.1494 | lr: 9.9629e-05 | scale: 131072.0000 | micro time: 1.342 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6085/156230 | global iter:   6085/156230 | loss: 1.1899 | ds_loss: 1.2131 | lr: 9.9629e-05 | scale: 131072.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   6086/156230 | global iter:   6086/156230 | loss: 1.1469 | ds_loss: 1.1705 | lr: 9.9629e-05 | scale: 131072.0000 | micro time: 1.437 | step time: 0.000
train | epoch   0 | Iter:   6087/156230 | global iter:   6087/156230 | loss: 1.0435 | ds_loss: 1.0444 | lr: 9.9629e-05 | scale: 131072.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   6088/156230 | global iter:   6088/156230 | loss: 1.1826 | ds_loss: 1.1983 | lr: 9.9629e-05 | scale: 131072.0000 | micro time: 1.324 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6088/156230 | global iter:   6088/156230 | loss: 1.1407 | ds_loss: 1.1566 | lr: 9.9629e-05 | scale: 131072.0000 | micro time: 1.324 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6089/156230 | global iter:   6089/156230 | loss: 1.1819 | ds_loss: 1.1901 | lr: 9.9629e-05 | scale: 131072.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   6090/156230 | global iter:   6090/156230 | loss: 1.0407 | ds_loss: 1.0456 | lr: 9.9628e-05 | scale: 131072.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   6091/156230 | global iter:   6091/156230 | loss: 1.0854 | ds_loss: 1.1067 | lr: 9.9628e-05 | scale: 131072.0000 | micro time: 1.310 | step time: 0.000
train | epoch   0 | Iter:   6092/156230 | global iter:   6092/156230 | loss: 1.1074 | ds_loss: 1.1187 | lr: 9.9628e-05 | scale: 131072.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6092/156230 | global iter:   6092/156230 | loss: 1.1039 | ds_loss: 1.1153 | lr: 9.9628e-05 | scale: 131072.0000 | micro time: 1.366 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6093/156230 | global iter:   6093/156230 | loss: 1.0912 | ds_loss: 1.1093 | lr: 9.9628e-05 | scale: 131072.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   6094/156230 | global iter:   6094/156230 | loss: 1.0186 | ds_loss: 1.0367 | lr: 9.9628e-05 | scale: 131072.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   6095/156230 | global iter:   6095/156230 | loss: 0.9584 | ds_loss: 0.9784 | lr: 9.9628e-05 | scale: 131072.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   6096/156230 | global iter:   6096/156230 | loss: 1.1283 | ds_loss: 1.1369 | lr: 9.9628e-05 | scale: 131072.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6096/156230 | global iter:   6096/156230 | loss: 1.0491 | ds_loss: 1.0653 | lr: 9.9628e-05 | scale: 131072.0000 | micro time: 1.345 | step time: 1.348
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6097/156230 | global iter:   6097/156230 | loss: 1.1895 | ds_loss: 1.1911 | lr: 9.9628e-05 | scale: 131072.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   6098/156230 | global iter:   6098/156230 | loss: 1.1513 | ds_loss: 1.1740 | lr: 9.9628e-05 | scale: 131072.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   6099/156230 | global iter:   6099/156230 | loss: 0.9494 | ds_loss: 0.9619 | lr: 9.9627e-05 | scale: 131072.0000 | micro time: 1.318 | step time: 0.000
train | epoch   0 | Iter:   6100/156230 | global iter:   6100/156230 | loss: 1.0144 | ds_loss: 1.0313 | lr: 9.9627e-05 | scale: 131072.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6100/156230 | global iter:   6100/156230 | loss: 1.0762 | ds_loss: 1.0896 | lr: 9.9627e-05 | scale: 131072.0000 | micro time: 1.369 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6101/156230 | global iter:   6101/156230 | loss: 1.1069 | ds_loss: 1.1181 | lr: 9.9627e-05 | scale: 131072.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   6102/156230 | global iter:   6102/156230 | loss: 1.0449 | ds_loss: 1.0655 | lr: 9.9627e-05 | scale: 131072.0000 | micro time: 1.410 | step time: 0.000
train | epoch   0 | Iter:   6103/156230 | global iter:   6103/156230 | loss: 1.0480 | ds_loss: 1.0596 | lr: 9.9627e-05 | scale: 131072.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   6104/156230 | global iter:   6104/156230 | loss: 1.1012 | ds_loss: 1.1215 | lr: 9.9627e-05 | scale: 131072.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6104/156230 | global iter:   6104/156230 | loss: 1.0753 | ds_loss: 1.0912 | lr: 9.9627e-05 | scale: 131072.0000 | micro time: 1.376 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6105/156230 | global iter:   6105/156230 | loss: 1.0742 | ds_loss: 1.0888 | lr: 9.9627e-05 | scale: 131072.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   6106/156230 | global iter:   6106/156230 | loss: 1.1669 | ds_loss: 1.2015 | lr: 9.9627e-05 | scale: 131072.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   6107/156230 | global iter:   6107/156230 | loss: 1.1936 | ds_loss: 1.2124 | lr: 9.9626e-05 | scale: 131072.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   6108/156230 | global iter:   6108/156230 | loss: 1.0056 | ds_loss: 1.0085 | lr: 9.9626e-05 | scale: 131072.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6108/156230 | global iter:   6108/156230 | loss: 1.1101 | ds_loss: 1.1278 | lr: 9.9626e-05 | scale: 131072.0000 | micro time: 1.381 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6109/156230 | global iter:   6109/156230 | loss: 1.1974 | ds_loss: 1.2157 | lr: 9.9626e-05 | scale: 131072.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   6110/156230 | global iter:   6110/156230 | loss: 1.2207 | ds_loss: 1.2329 | lr: 9.9626e-05 | scale: 131072.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   6111/156230 | global iter:   6111/156230 | loss: 1.0453 | ds_loss: 1.0737 | lr: 9.9626e-05 | scale: 131072.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   6112/156230 | global iter:   6112/156230 | loss: 1.1043 | ds_loss: 1.1208 | lr: 9.9626e-05 | scale: 131072.0000 | micro time: 1.402 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6112/156230 | global iter:   6112/156230 | loss: 1.1419 | ds_loss: 1.1608 | lr: 9.9626e-05 | scale: 131072.0000 | micro time: 1.402 | step time: 1.376
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6113/156230 | global iter:   6113/156230 | loss: 1.1030 | ds_loss: 1.1271 | lr: 9.9626e-05 | scale: 131072.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   6114/156230 | global iter:   6114/156230 | loss: 1.0639 | ds_loss: 1.1026 | lr: 9.9626e-05 | scale: 131072.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   6115/156230 | global iter:   6115/156230 | loss: 1.1296 | ds_loss: 1.1444 | lr: 9.9625e-05 | scale: 131072.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   6116/156230 | global iter:   6116/156230 | loss: 1.0765 | ds_loss: 1.1010 | lr: 9.9625e-05 | scale: 131072.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6116/156230 | global iter:   6116/156230 | loss: 1.0933 | ds_loss: 1.1188 | lr: 9.9625e-05 | scale: 131072.0000 | micro time: 1.347 | step time: 1.343
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6117/156230 | global iter:   6117/156230 | loss: 0.9389 | ds_loss: 0.9517 | lr: 9.9625e-05 | scale: 131072.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   6118/156230 | global iter:   6118/156230 | loss: 1.1421 | ds_loss: 1.1708 | lr: 9.9625e-05 | scale: 131072.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   6119/156230 | global iter:   6119/156230 | loss: 1.2335 | ds_loss: 1.2486 | lr: 9.9625e-05 | scale: 131072.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   6120/156230 | global iter:   6120/156230 | loss: 1.0323 | ds_loss: 1.0424 | lr: 9.9625e-05 | scale: 131072.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6120/156230 | global iter:   6120/156230 | loss: 1.0867 | ds_loss: 1.1034 | lr: 9.9625e-05 | scale: 131072.0000 | micro time: 1.357 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6121/156230 | global iter:   6121/156230 | loss: 1.1425 | ds_loss: 1.1622 | lr: 9.9625e-05 | scale: 131072.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   6122/156230 | global iter:   6122/156230 | loss: 0.9882 | ds_loss: 1.0084 | lr: 9.9625e-05 | scale: 131072.0000 | micro time: 1.415 | step time: 0.000
train | epoch   0 | Iter:   6123/156230 | global iter:   6123/156230 | loss: 1.2427 | ds_loss: 1.2635 | lr: 9.9624e-05 | scale: 131072.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   6124/156230 | global iter:   6124/156230 | loss: 1.2659 | ds_loss: 1.2715 | lr: 9.9624e-05 | scale: 131072.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6124/156230 | global iter:   6124/156230 | loss: 1.1598 | ds_loss: 1.1764 | lr: 9.9624e-05 | scale: 131072.0000 | micro time: 1.374 | step time: 1.387
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6125/156230 | global iter:   6125/156230 | loss: 0.9658 | ds_loss: 1.0071 | lr: 9.9624e-05 | scale: 131072.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   6126/156230 | global iter:   6126/156230 | loss: 0.9243 | ds_loss: 0.9406 | lr: 9.9624e-05 | scale: 131072.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   6127/156230 | global iter:   6127/156230 | loss: 1.3548 | ds_loss: 1.3808 | lr: 9.9624e-05 | scale: 131072.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   6128/156230 | global iter:   6128/156230 | loss: 1.0291 | ds_loss: 1.0524 | lr: 9.9624e-05 | scale: 131072.0000 | micro time: 1.338 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6128/156230 | global iter:   6128/156230 | loss: 1.0685 | ds_loss: 1.0952 | lr: 9.9624e-05 | scale: 131072.0000 | micro time: 1.338 | step time: 1.376
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6129/156230 | global iter:   6129/156230 | loss: 1.1051 | ds_loss: 1.1190 | lr: 9.9624e-05 | scale: 131072.0000 | micro time: 1.400 | step time: 0.000
train | epoch   0 | Iter:   6130/156230 | global iter:   6130/156230 | loss: 1.1770 | ds_loss: 1.1921 | lr: 9.9624e-05 | scale: 131072.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   6131/156230 | global iter:   6131/156230 | loss: 1.1197 | ds_loss: 1.1522 | lr: 9.9623e-05 | scale: 131072.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   6132/156230 | global iter:   6132/156230 | loss: 1.2168 | ds_loss: 1.2317 | lr: 9.9623e-05 | scale: 131072.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6132/156230 | global iter:   6132/156230 | loss: 1.1547 | ds_loss: 1.1737 | lr: 9.9623e-05 | scale: 131072.0000 | micro time: 1.381 | step time: 1.380
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6133/156230 | global iter:   6133/156230 | loss: 1.1909 | ds_loss: 1.1959 | lr: 9.9623e-05 | scale: 131072.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   6134/156230 | global iter:   6134/156230 | loss: 1.2345 | ds_loss: 1.2359 | lr: 9.9623e-05 | scale: 131072.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   6135/156230 | global iter:   6135/156230 | loss: 1.1124 | ds_loss: 1.1197 | lr: 9.9623e-05 | scale: 131072.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   6136/156230 | global iter:   6136/156230 | loss: 1.0849 | ds_loss: 1.1008 | lr: 9.9623e-05 | scale: 131072.0000 | micro time: 1.346 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6136/156230 | global iter:   6136/156230 | loss: 1.1557 | ds_loss: 1.1631 | lr: 9.9623e-05 | scale: 131072.0000 | micro time: 1.346 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6137/156230 | global iter:   6137/156230 | loss: 0.9545 | ds_loss: 0.9774 | lr: 9.9623e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   6138/156230 | global iter:   6138/156230 | loss: 1.1581 | ds_loss: 1.1569 | lr: 9.9623e-05 | scale: 131072.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   6139/156230 | global iter:   6139/156230 | loss: 1.0035 | ds_loss: 1.0074 | lr: 9.9622e-05 | scale: 131072.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   6140/156230 | global iter:   6140/156230 | loss: 1.0338 | ds_loss: 1.0745 | lr: 9.9622e-05 | scale: 131072.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6140/156230 | global iter:   6140/156230 | loss: 1.0375 | ds_loss: 1.0540 | lr: 9.9622e-05 | scale: 131072.0000 | micro time: 1.349 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6141/156230 | global iter:   6141/156230 | loss: 1.1033 | ds_loss: 1.1138 | lr: 9.9622e-05 | scale: 131072.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   6142/156230 | global iter:   6142/156230 | loss: 1.1699 | ds_loss: 1.1968 | lr: 9.9622e-05 | scale: 131072.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   6143/156230 | global iter:   6143/156230 | loss: 1.0747 | ds_loss: 1.0901 | lr: 9.9622e-05 | scale: 131072.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   6144/156230 | global iter:   6144/156230 | loss: 1.1817 | ds_loss: 1.1981 | lr: 9.9622e-05 | scale: 131072.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6144/156230 | global iter:   6144/156230 | loss: 1.1324 | ds_loss: 1.1497 | lr: 9.9622e-05 | scale: 131072.0000 | micro time: 1.385 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6145/156230 | global iter:   6145/156230 | loss: 1.2619 | ds_loss: 1.2892 | lr: 9.9622e-05 | scale: 131072.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   6146/156230 | global iter:   6146/156230 | loss: 1.1151 | ds_loss: 1.1372 | lr: 9.9622e-05 | scale: 131072.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   6147/156230 | global iter:   6147/156230 | loss: 1.1523 | ds_loss: 1.1628 | lr: 9.9621e-05 | scale: 131072.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   6148/156230 | global iter:   6148/156230 | loss: 0.9109 | ds_loss: 0.9415 | lr: 9.9621e-05 | scale: 131072.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6148/156230 | global iter:   6148/156230 | loss: 1.1100 | ds_loss: 1.1327 | lr: 9.9621e-05 | scale: 131072.0000 | micro time: 1.365 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6149/156230 | global iter:   6149/156230 | loss: 1.0067 | ds_loss: 1.0309 | lr: 9.9621e-05 | scale: 131072.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   6150/156230 | global iter:   6150/156230 | loss: 1.0154 | ds_loss: 1.0339 | lr: 9.9621e-05 | scale: 131072.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:   6151/156230 | global iter:   6151/156230 | loss: 1.1569 | ds_loss: 1.1845 | lr: 9.9621e-05 | scale: 131072.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   6152/156230 | global iter:   6152/156230 | loss: 0.9499 | ds_loss: 0.9806 | lr: 9.9621e-05 | scale: 131072.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6152/156230 | global iter:   6152/156230 | loss: 1.0322 | ds_loss: 1.0575 | lr: 9.9621e-05 | scale: 131072.0000 | micro time: 1.355 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6153/156230 | global iter:   6153/156230 | loss: 1.0904 | ds_loss: 1.0966 | lr: 9.9621e-05 | scale: 131072.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   6154/156230 | global iter:   6154/156230 | loss: 1.1764 | ds_loss: 1.1815 | lr: 9.9621e-05 | scale: 131072.0000 | micro time: 1.413 | step time: 0.000
train | epoch   0 | Iter:   6155/156230 | global iter:   6155/156230 | loss: 1.0761 | ds_loss: 1.0686 | lr: 9.9620e-05 | scale: 131072.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   6156/156230 | global iter:   6156/156230 | loss: 1.0283 | ds_loss: 1.0631 | lr: 9.9620e-05 | scale: 131072.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6156/156230 | global iter:   6156/156230 | loss: 1.0928 | ds_loss: 1.1024 | lr: 9.9620e-05 | scale: 131072.0000 | micro time: 1.360 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6157/156230 | global iter:   6157/156230 | loss: 1.1738 | ds_loss: 1.1907 | lr: 9.9620e-05 | scale: 131072.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   6158/156230 | global iter:   6158/156230 | loss: 1.0517 | ds_loss: 1.0644 | lr: 9.9620e-05 | scale: 131072.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   6159/156230 | global iter:   6159/156230 | loss: 1.1966 | ds_loss: 1.2174 | lr: 9.9620e-05 | scale: 131072.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   6160/156230 | global iter:   6160/156230 | loss: 0.9125 | ds_loss: 0.9306 | lr: 9.9620e-05 | scale: 131072.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6160/156230 | global iter:   6160/156230 | loss: 1.0837 | ds_loss: 1.1008 | lr: 9.9620e-05 | scale: 131072.0000 | micro time: 1.373 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6161/156230 | global iter:   6161/156230 | loss: 1.1512 | ds_loss: 1.1796 | lr: 9.9620e-05 | scale: 131072.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   6162/156230 | global iter:   6162/156230 | loss: 0.9911 | ds_loss: 1.0150 | lr: 9.9620e-05 | scale: 131072.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   6163/156230 | global iter:   6163/156230 | loss: 1.2140 | ds_loss: 1.2347 | lr: 9.9620e-05 | scale: 131072.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   6164/156230 | global iter:   6164/156230 | loss: 0.9823 | ds_loss: 1.0076 | lr: 9.9619e-05 | scale: 131072.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6164/156230 | global iter:   6164/156230 | loss: 1.0847 | ds_loss: 1.1092 | lr: 9.9619e-05 | scale: 131072.0000 | micro time: 1.366 | step time: 1.376
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6165/156230 | global iter:   6165/156230 | loss: 1.1947 | ds_loss: 1.2104 | lr: 9.9619e-05 | scale: 131072.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   6166/156230 | global iter:   6166/156230 | loss: 1.1969 | ds_loss: 1.2293 | lr: 9.9619e-05 | scale: 131072.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:   6167/156230 | global iter:   6167/156230 | loss: 1.0246 | ds_loss: 1.0265 | lr: 9.9619e-05 | scale: 131072.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   6168/156230 | global iter:   6168/156230 | loss: 1.0721 | ds_loss: 1.1002 | lr: 9.9619e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6168/156230 | global iter:   6168/156230 | loss: 1.1221 | ds_loss: 1.1416 | lr: 9.9619e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6169/156230 | global iter:   6169/156230 | loss: 1.0995 | ds_loss: 1.1208 | lr: 9.9619e-05 | scale: 131072.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   6170/156230 | global iter:   6170/156230 | loss: 0.9639 | ds_loss: 0.9911 | lr: 9.9619e-05 | scale: 131072.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   6171/156230 | global iter:   6171/156230 | loss: 1.1375 | ds_loss: 1.1638 | lr: 9.9619e-05 | scale: 131072.0000 | micro time: 1.310 | step time: 0.000
train | epoch   0 | Iter:   6172/156230 | global iter:   6172/156230 | loss: 0.9663 | ds_loss: 0.9833 | lr: 9.9618e-05 | scale: 131072.0000 | micro time: 1.401 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6172/156230 | global iter:   6172/156230 | loss: 1.0418 | ds_loss: 1.0648 | lr: 9.9618e-05 | scale: 131072.0000 | micro time: 1.401 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6173/156230 | global iter:   6173/156230 | loss: 1.1653 | ds_loss: 1.1749 | lr: 9.9618e-05 | scale: 131072.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   6174/156230 | global iter:   6174/156230 | loss: 1.1331 | ds_loss: 1.1522 | lr: 9.9618e-05 | scale: 131072.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   6175/156230 | global iter:   6175/156230 | loss: 0.9453 | ds_loss: 0.9511 | lr: 9.9618e-05 | scale: 131072.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   6176/156230 | global iter:   6176/156230 | loss: 0.8700 | ds_loss: 0.8789 | lr: 9.9618e-05 | scale: 131072.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6176/156230 | global iter:   6176/156230 | loss: 1.0284 | ds_loss: 1.0393 | lr: 9.9618e-05 | scale: 131072.0000 | micro time: 1.365 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6177/156230 | global iter:   6177/156230 | loss: 1.0473 | ds_loss: 1.0673 | lr: 9.9618e-05 | scale: 131072.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   6178/156230 | global iter:   6178/156230 | loss: 1.1379 | ds_loss: 1.1494 | lr: 9.9618e-05 | scale: 131072.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   6179/156230 | global iter:   6179/156230 | loss: 1.2149 | ds_loss: 1.2376 | lr: 9.9618e-05 | scale: 131072.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   6180/156230 | global iter:   6180/156230 | loss: 1.3783 | ds_loss: 1.3867 | lr: 9.9617e-05 | scale: 131072.0000 | micro time: 1.358 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6180/156230 | global iter:   6180/156230 | loss: 1.1946 | ds_loss: 1.2102 | lr: 9.9617e-05 | scale: 131072.0000 | micro time: 1.358 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6181/156230 | global iter:   6181/156230 | loss: 1.1929 | ds_loss: 1.2180 | lr: 9.9617e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   6182/156230 | global iter:   6182/156230 | loss: 1.0337 | ds_loss: 1.0476 | lr: 9.9617e-05 | scale: 131072.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   6183/156230 | global iter:   6183/156230 | loss: 1.0083 | ds_loss: 1.0293 | lr: 9.9617e-05 | scale: 131072.0000 | micro time: 1.322 | step time: 0.000
train | epoch   0 | Iter:   6184/156230 | global iter:   6184/156230 | loss: 1.0771 | ds_loss: 1.1065 | lr: 9.9617e-05 | scale: 131072.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6184/156230 | global iter:   6184/156230 | loss: 1.0780 | ds_loss: 1.1004 | lr: 9.9617e-05 | scale: 131072.0000 | micro time: 1.369 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6185/156230 | global iter:   6185/156230 | loss: 1.0257 | ds_loss: 1.0495 | lr: 9.9617e-05 | scale: 131072.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   6186/156230 | global iter:   6186/156230 | loss: 1.1205 | ds_loss: 1.1421 | lr: 9.9617e-05 | scale: 131072.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   6187/156230 | global iter:   6187/156230 | loss: 1.0835 | ds_loss: 1.0976 | lr: 9.9617e-05 | scale: 131072.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   6188/156230 | global iter:   6188/156230 | loss: 1.0861 | ds_loss: 1.1122 | lr: 9.9616e-05 | scale: 131072.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6188/156230 | global iter:   6188/156230 | loss: 1.0790 | ds_loss: 1.1004 | lr: 9.9616e-05 | scale: 131072.0000 | micro time: 1.381 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6189/156230 | global iter:   6189/156230 | loss: 1.1760 | ds_loss: 1.1986 | lr: 9.9616e-05 | scale: 131072.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   6190/156230 | global iter:   6190/156230 | loss: 1.2271 | ds_loss: 1.2414 | lr: 9.9616e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   6191/156230 | global iter:   6191/156230 | loss: 1.0838 | ds_loss: 1.0961 | lr: 9.9616e-05 | scale: 131072.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   6192/156230 | global iter:   6192/156230 | loss: 1.2228 | ds_loss: 1.2292 | lr: 9.9616e-05 | scale: 131072.0000 | micro time: 1.334 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6192/156230 | global iter:   6192/156230 | loss: 1.1774 | ds_loss: 1.1913 | lr: 9.9616e-05 | scale: 131072.0000 | micro time: 1.334 | step time: 1.338
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6193/156230 | global iter:   6193/156230 | loss: 1.2064 | ds_loss: 1.2104 | lr: 9.9616e-05 | scale: 131072.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   6194/156230 | global iter:   6194/156230 | loss: 1.0312 | ds_loss: 1.0397 | lr: 9.9616e-05 | scale: 131072.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   6195/156230 | global iter:   6195/156230 | loss: 1.0785 | ds_loss: 1.0963 | lr: 9.9616e-05 | scale: 131072.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   6196/156230 | global iter:   6196/156230 | loss: 1.0616 | ds_loss: 1.0658 | lr: 9.9615e-05 | scale: 131072.0000 | micro time: 1.371 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6196/156230 | global iter:   6196/156230 | loss: 1.0944 | ds_loss: 1.1031 | lr: 9.9615e-05 | scale: 131072.0000 | micro time: 1.371 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6197/156230 | global iter:   6197/156230 | loss: 1.1718 | ds_loss: 1.1757 | lr: 9.9615e-05 | scale: 131072.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   6198/156230 | global iter:   6198/156230 | loss: 1.0054 | ds_loss: 1.0300 | lr: 9.9615e-05 | scale: 131072.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   6199/156230 | global iter:   6199/156230 | loss: 1.0873 | ds_loss: 1.1016 | lr: 9.9615e-05 | scale: 131072.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   6200/156230 | global iter:   6200/156230 | loss: 1.1287 | ds_loss: 1.1598 | lr: 9.9615e-05 | scale: 131072.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6200/156230 | global iter:   6200/156230 | loss: 1.0983 | ds_loss: 1.1168 | lr: 9.9615e-05 | scale: 131072.0000 | micro time: 1.365 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6201/156230 | global iter:   6201/156230 | loss: 1.0862 | ds_loss: 1.1124 | lr: 9.9615e-05 | scale: 131072.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   6202/156230 | global iter:   6202/156230 | loss: 1.0926 | ds_loss: 1.0989 | lr: 9.9615e-05 | scale: 131072.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   6203/156230 | global iter:   6203/156230 | loss: 1.1217 | ds_loss: 1.1544 | lr: 9.9615e-05 | scale: 131072.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   6204/156230 | global iter:   6204/156230 | loss: 1.1767 | ds_loss: 1.2121 | lr: 9.9614e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6204/156230 | global iter:   6204/156230 | loss: 1.1193 | ds_loss: 1.1444 | lr: 9.9614e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6205/156230 | global iter:   6205/156230 | loss: 1.1105 | ds_loss: 1.1190 | lr: 9.9614e-05 | scale: 131072.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   6206/156230 | global iter:   6206/156230 | loss: 1.4029 | ds_loss: 1.4350 | lr: 9.9614e-05 | scale: 131072.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   6207/156230 | global iter:   6207/156230 | loss: 1.1833 | ds_loss: 1.2095 | lr: 9.9614e-05 | scale: 131072.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   6208/156230 | global iter:   6208/156230 | loss: 1.0302 | ds_loss: 1.0620 | lr: 9.9614e-05 | scale: 131072.0000 | micro time: 1.412 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6208/156230 | global iter:   6208/156230 | loss: 1.1817 | ds_loss: 1.2064 | lr: 9.9614e-05 | scale: 131072.0000 | micro time: 1.412 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6209/156230 | global iter:   6209/156230 | loss: 1.0785 | ds_loss: 1.1080 | lr: 9.9614e-05 | scale: 131072.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   6210/156230 | global iter:   6210/156230 | loss: 1.0986 | ds_loss: 1.1284 | lr: 9.9614e-05 | scale: 131072.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   6211/156230 | global iter:   6211/156230 | loss: 0.9812 | ds_loss: 1.0125 | lr: 9.9614e-05 | scale: 131072.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   6212/156230 | global iter:   6212/156230 | loss: 0.9766 | ds_loss: 0.9926 | lr: 9.9613e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6212/156230 | global iter:   6212/156230 | loss: 1.0337 | ds_loss: 1.0603 | lr: 9.9613e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 1.379
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6213/156230 | global iter:   6213/156230 | loss: 1.1079 | ds_loss: 1.1217 | lr: 9.9613e-05 | scale: 131072.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   6214/156230 | global iter:   6214/156230 | loss: 1.0737 | ds_loss: 1.0931 | lr: 9.9613e-05 | scale: 131072.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   6215/156230 | global iter:   6215/156230 | loss: 1.1251 | ds_loss: 1.1430 | lr: 9.9613e-05 | scale: 131072.0000 | micro time: 1.321 | step time: 0.000
train | epoch   0 | Iter:   6216/156230 | global iter:   6216/156230 | loss: 1.0819 | ds_loss: 1.0933 | lr: 9.9613e-05 | scale: 131072.0000 | micro time: 1.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6216/156230 | global iter:   6216/156230 | loss: 1.0972 | ds_loss: 1.1128 | lr: 9.9613e-05 | scale: 131072.0000 | micro time: 1.397 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6217/156230 | global iter:   6217/156230 | loss: 1.1637 | ds_loss: 1.1782 | lr: 9.9613e-05 | scale: 131072.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   6218/156230 | global iter:   6218/156230 | loss: 1.1724 | ds_loss: 1.1735 | lr: 9.9613e-05 | scale: 131072.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   6219/156230 | global iter:   6219/156230 | loss: 1.0875 | ds_loss: 1.0993 | lr: 9.9613e-05 | scale: 131072.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:   6220/156230 | global iter:   6220/156230 | loss: 1.0903 | ds_loss: 1.0860 | lr: 9.9612e-05 | scale: 131072.0000 | micro time: 1.384 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6220/156230 | global iter:   6220/156230 | loss: 1.1284 | ds_loss: 1.1343 | lr: 9.9612e-05 | scale: 131072.0000 | micro time: 1.384 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6221/156230 | global iter:   6221/156230 | loss: 1.0786 | ds_loss: 1.1043 | lr: 9.9612e-05 | scale: 131072.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   6222/156230 | global iter:   6222/156230 | loss: 1.0177 | ds_loss: 1.0528 | lr: 9.9612e-05 | scale: 131072.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:   6223/156230 | global iter:   6223/156230 | loss: 1.0185 | ds_loss: 1.0285 | lr: 9.9612e-05 | scale: 131072.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   6224/156230 | global iter:   6224/156230 | loss: 1.2151 | ds_loss: 1.2352 | lr: 9.9612e-05 | scale: 131072.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6224/156230 | global iter:   6224/156230 | loss: 1.0825 | ds_loss: 1.1052 | lr: 9.9612e-05 | scale: 131072.0000 | micro time: 1.350 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6225/156230 | global iter:   6225/156230 | loss: 0.8997 | ds_loss: 0.9111 | lr: 9.9612e-05 | scale: 131072.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   6226/156230 | global iter:   6226/156230 | loss: 1.0991 | ds_loss: 1.1161 | lr: 9.9612e-05 | scale: 131072.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   6227/156230 | global iter:   6227/156230 | loss: 1.1028 | ds_loss: 1.1296 | lr: 9.9612e-05 | scale: 131072.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   6228/156230 | global iter:   6228/156230 | loss: 1.2478 | ds_loss: 1.2650 | lr: 9.9611e-05 | scale: 131072.0000 | micro time: 1.410 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6228/156230 | global iter:   6228/156230 | loss: 1.0873 | ds_loss: 1.1054 | lr: 9.9611e-05 | scale: 131072.0000 | micro time: 1.410 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6229/156230 | global iter:   6229/156230 | loss: 1.0920 | ds_loss: 1.0916 | lr: 9.9611e-05 | scale: 131072.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   6230/156230 | global iter:   6230/156230 | loss: 1.0668 | ds_loss: 1.0899 | lr: 9.9611e-05 | scale: 131072.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   6231/156230 | global iter:   6231/156230 | loss: 0.9964 | ds_loss: 1.0173 | lr: 9.9611e-05 | scale: 131072.0000 | micro time: 1.316 | step time: 0.000
train | epoch   0 | Iter:   6232/156230 | global iter:   6232/156230 | loss: 1.1147 | ds_loss: 1.1256 | lr: 9.9611e-05 | scale: 131072.0000 | micro time: 1.382 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6232/156230 | global iter:   6232/156230 | loss: 1.0675 | ds_loss: 1.0811 | lr: 9.9611e-05 | scale: 131072.0000 | micro time: 1.382 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6233/156230 | global iter:   6233/156230 | loss: 1.0215 | ds_loss: 1.0448 | lr: 9.9611e-05 | scale: 131072.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   6234/156230 | global iter:   6234/156230 | loss: 1.1421 | ds_loss: 1.1618 | lr: 9.9611e-05 | scale: 131072.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   6235/156230 | global iter:   6235/156230 | loss: 1.2336 | ds_loss: 1.2455 | lr: 9.9611e-05 | scale: 131072.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   6236/156230 | global iter:   6236/156230 | loss: 1.0121 | ds_loss: 1.0269 | lr: 9.9610e-05 | scale: 131072.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6236/156230 | global iter:   6236/156230 | loss: 1.1023 | ds_loss: 1.1197 | lr: 9.9610e-05 | scale: 131072.0000 | micro time: 1.361 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6237/156230 | global iter:   6237/156230 | loss: 1.0920 | ds_loss: 1.0959 | lr: 9.9610e-05 | scale: 131072.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   6238/156230 | global iter:   6238/156230 | loss: 1.2761 | ds_loss: 1.2951 | lr: 9.9610e-05 | scale: 131072.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:   6239/156230 | global iter:   6239/156230 | loss: 1.2454 | ds_loss: 1.2431 | lr: 9.9610e-05 | scale: 131072.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   6240/156230 | global iter:   6240/156230 | loss: 0.9959 | ds_loss: 1.0129 | lr: 9.9610e-05 | scale: 131072.0000 | micro time: 1.442 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6240/156230 | global iter:   6240/156230 | loss: 1.1524 | ds_loss: 1.1617 | lr: 9.9610e-05 | scale: 131072.0000 | micro time: 1.442 | step time: 1.386
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6241/156230 | global iter:   6241/156230 | loss: 1.1306 | ds_loss: 1.1320 | lr: 9.9610e-05 | scale: 131072.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   6242/156230 | global iter:   6242/156230 | loss: 0.9824 | ds_loss: 0.9987 | lr: 9.9610e-05 | scale: 131072.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   6243/156230 | global iter:   6243/156230 | loss: 1.2018 | ds_loss: 1.2257 | lr: 9.9610e-05 | scale: 131072.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   6244/156230 | global iter:   6244/156230 | loss: 0.9458 | ds_loss: 0.9687 | lr: 9.9609e-05 | scale: 131072.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6244/156230 | global iter:   6244/156230 | loss: 1.0652 | ds_loss: 1.0813 | lr: 9.9609e-05 | scale: 131072.0000 | micro time: 1.354 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6245/156230 | global iter:   6245/156230 | loss: 1.0180 | ds_loss: 1.0323 | lr: 9.9609e-05 | scale: 131072.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   6246/156230 | global iter:   6246/156230 | loss: 0.9804 | ds_loss: 0.9982 | lr: 9.9609e-05 | scale: 131072.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   6247/156230 | global iter:   6247/156230 | loss: 1.1483 | ds_loss: 1.1769 | lr: 9.9609e-05 | scale: 131072.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   6248/156230 | global iter:   6248/156230 | loss: 1.0869 | ds_loss: 1.1137 | lr: 9.9609e-05 | scale: 131072.0000 | micro time: 1.346 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6248/156230 | global iter:   6248/156230 | loss: 1.0584 | ds_loss: 1.0803 | lr: 9.9609e-05 | scale: 131072.0000 | micro time: 1.346 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6249/156230 | global iter:   6249/156230 | loss: 1.0499 | ds_loss: 1.0479 | lr: 9.9609e-05 | scale: 131072.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   6250/156230 | global iter:   6250/156230 | loss: 1.1395 | ds_loss: 1.1508 | lr: 9.9609e-05 | scale: 131072.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   6251/156230 | global iter:   6251/156230 | loss: 1.1217 | ds_loss: 1.1297 | lr: 9.9609e-05 | scale: 131072.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   6252/156230 | global iter:   6252/156230 | loss: 1.0412 | ds_loss: 1.0452 | lr: 9.9608e-05 | scale: 131072.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6252/156230 | global iter:   6252/156230 | loss: 1.0881 | ds_loss: 1.0934 | lr: 9.9608e-05 | scale: 131072.0000 | micro time: 1.362 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6253/156230 | global iter:   6253/156230 | loss: 1.0018 | ds_loss: 1.0336 | lr: 9.9608e-05 | scale: 131072.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   6254/156230 | global iter:   6254/156230 | loss: 1.0182 | ds_loss: 1.0431 | lr: 9.9608e-05 | scale: 131072.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   6255/156230 | global iter:   6255/156230 | loss: 1.1418 | ds_loss: 1.1447 | lr: 9.9608e-05 | scale: 131072.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   6256/156230 | global iter:   6256/156230 | loss: 1.1541 | ds_loss: 1.1700 | lr: 9.9608e-05 | scale: 131072.0000 | micro time: 1.340 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6256/156230 | global iter:   6256/156230 | loss: 1.0790 | ds_loss: 1.0979 | lr: 9.9608e-05 | scale: 131072.0000 | micro time: 1.340 | step time: 1.347
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6257/156230 | global iter:   6257/156230 | loss: 0.9743 | ds_loss: 0.9723 | lr: 9.9608e-05 | scale: 131072.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   6258/156230 | global iter:   6258/156230 | loss: 1.2213 | ds_loss: 1.2226 | lr: 9.9608e-05 | scale: 131072.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   6259/156230 | global iter:   6259/156230 | loss: 0.9758 | ds_loss: 0.9907 | lr: 9.9608e-05 | scale: 131072.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   6260/156230 | global iter:   6260/156230 | loss: 1.1325 | ds_loss: 1.1664 | lr: 9.9607e-05 | scale: 131072.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6260/156230 | global iter:   6260/156230 | loss: 1.0760 | ds_loss: 1.0880 | lr: 9.9607e-05 | scale: 131072.0000 | micro time: 1.369 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6261/156230 | global iter:   6261/156230 | loss: 1.2091 | ds_loss: 1.2176 | lr: 9.9607e-05 | scale: 131072.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   6262/156230 | global iter:   6262/156230 | loss: 1.1541 | ds_loss: 1.1808 | lr: 9.9607e-05 | scale: 131072.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   6263/156230 | global iter:   6263/156230 | loss: 1.0708 | ds_loss: 1.0732 | lr: 9.9607e-05 | scale: 131072.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   6264/156230 | global iter:   6264/156230 | loss: 1.1995 | ds_loss: 1.2137 | lr: 9.9607e-05 | scale: 131072.0000 | micro time: 1.346 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6264/156230 | global iter:   6264/156230 | loss: 1.1584 | ds_loss: 1.1713 | lr: 9.9607e-05 | scale: 131072.0000 | micro time: 1.346 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6265/156230 | global iter:   6265/156230 | loss: 1.0254 | ds_loss: 1.0370 | lr: 9.9607e-05 | scale: 131072.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   6266/156230 | global iter:   6266/156230 | loss: 1.2490 | ds_loss: 1.2537 | lr: 9.9607e-05 | scale: 131072.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   6267/156230 | global iter:   6267/156230 | loss: 1.1257 | ds_loss: 1.1525 | lr: 9.9607e-05 | scale: 131072.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   6268/156230 | global iter:   6268/156230 | loss: 1.0090 | ds_loss: 1.0198 | lr: 9.9606e-05 | scale: 131072.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6268/156230 | global iter:   6268/156230 | loss: 1.1023 | ds_loss: 1.1158 | lr: 9.9606e-05 | scale: 131072.0000 | micro time: 1.361 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6269/156230 | global iter:   6269/156230 | loss: 1.1814 | ds_loss: 1.1867 | lr: 9.9606e-05 | scale: 131072.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   6270/156230 | global iter:   6270/156230 | loss: 1.0900 | ds_loss: 1.1195 | lr: 9.9606e-05 | scale: 131072.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   6271/156230 | global iter:   6271/156230 | loss: 1.1913 | ds_loss: 1.1908 | lr: 9.9606e-05 | scale: 131072.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   6272/156230 | global iter:   6272/156230 | loss: 1.1436 | ds_loss: 1.1823 | lr: 9.9606e-05 | scale: 131072.0000 | micro time: 1.416 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6272/156230 | global iter:   6272/156230 | loss: 1.1515 | ds_loss: 1.1698 | lr: 9.9606e-05 | scale: 131072.0000 | micro time: 1.416 | step time: 1.390
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6273/156230 | global iter:   6273/156230 | loss: 0.9670 | ds_loss: 0.9804 | lr: 9.9606e-05 | scale: 131072.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   6274/156230 | global iter:   6274/156230 | loss: 1.2890 | ds_loss: 1.3123 | lr: 9.9606e-05 | scale: 131072.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   6275/156230 | global iter:   6275/156230 | loss: 1.2497 | ds_loss: 1.2601 | lr: 9.9606e-05 | scale: 131072.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   6276/156230 | global iter:   6276/156230 | loss: 1.1217 | ds_loss: 1.1481 | lr: 9.9605e-05 | scale: 131072.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6276/156230 | global iter:   6276/156230 | loss: 1.1568 | ds_loss: 1.1752 | lr: 9.9605e-05 | scale: 131072.0000 | micro time: 1.377 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6277/156230 | global iter:   6277/156230 | loss: 1.1286 | ds_loss: 1.1445 | lr: 9.9605e-05 | scale: 131072.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   6278/156230 | global iter:   6278/156230 | loss: 1.2397 | ds_loss: 1.2865 | lr: 9.9605e-05 | scale: 131072.0000 | micro time: 1.405 | step time: 0.000
train | epoch   0 | Iter:   6279/156230 | global iter:   6279/156230 | loss: 1.1600 | ds_loss: 1.1673 | lr: 9.9605e-05 | scale: 131072.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   6280/156230 | global iter:   6280/156230 | loss: 1.1915 | ds_loss: 1.2125 | lr: 9.9605e-05 | scale: 131072.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6280/156230 | global iter:   6280/156230 | loss: 1.1799 | ds_loss: 1.2027 | lr: 9.9605e-05 | scale: 131072.0000 | micro time: 1.373 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6281/156230 | global iter:   6281/156230 | loss: 1.0976 | ds_loss: 1.1260 | lr: 9.9605e-05 | scale: 131072.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   6282/156230 | global iter:   6282/156230 | loss: 1.1005 | ds_loss: 1.1163 | lr: 9.9605e-05 | scale: 131072.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   6283/156230 | global iter:   6283/156230 | loss: 1.2814 | ds_loss: 1.2736 | lr: 9.9605e-05 | scale: 131072.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   6284/156230 | global iter:   6284/156230 | loss: 1.0590 | ds_loss: 1.0642 | lr: 9.9604e-05 | scale: 131072.0000 | micro time: 1.403 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6284/156230 | global iter:   6284/156230 | loss: 1.1346 | ds_loss: 1.1450 | lr: 9.9604e-05 | scale: 131072.0000 | micro time: 1.403 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6285/156230 | global iter:   6285/156230 | loss: 1.1553 | ds_loss: 1.1654 | lr: 9.9604e-05 | scale: 131072.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   6286/156230 | global iter:   6286/156230 | loss: 1.0812 | ds_loss: 1.1139 | lr: 9.9604e-05 | scale: 131072.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   6287/156230 | global iter:   6287/156230 | loss: 1.0257 | ds_loss: 1.0570 | lr: 9.9604e-05 | scale: 131072.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   6288/156230 | global iter:   6288/156230 | loss: 1.1871 | ds_loss: 1.1918 | lr: 9.9604e-05 | scale: 131072.0000 | micro time: 1.416 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6288/156230 | global iter:   6288/156230 | loss: 1.1123 | ds_loss: 1.1320 | lr: 9.9604e-05 | scale: 131072.0000 | micro time: 1.416 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6289/156230 | global iter:   6289/156230 | loss: 1.0837 | ds_loss: 1.0915 | lr: 9.9604e-05 | scale: 131072.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   6290/156230 | global iter:   6290/156230 | loss: 1.1242 | ds_loss: 1.1561 | lr: 9.9604e-05 | scale: 131072.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   6291/156230 | global iter:   6291/156230 | loss: 1.1778 | ds_loss: 1.1881 | lr: 9.9604e-05 | scale: 131072.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   6292/156230 | global iter:   6292/156230 | loss: 1.1120 | ds_loss: 1.1296 | lr: 9.9603e-05 | scale: 131072.0000 | micro time: 1.321 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6292/156230 | global iter:   6292/156230 | loss: 1.1244 | ds_loss: 1.1413 | lr: 9.9603e-05 | scale: 131072.0000 | micro time: 1.321 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6293/156230 | global iter:   6293/156230 | loss: 1.0853 | ds_loss: 1.1025 | lr: 9.9603e-05 | scale: 131072.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   6294/156230 | global iter:   6294/156230 | loss: 1.2941 | ds_loss: 1.3158 | lr: 9.9603e-05 | scale: 131072.0000 | micro time: 1.419 | step time: 0.000
train | epoch   0 | Iter:   6295/156230 | global iter:   6295/156230 | loss: 1.0423 | ds_loss: 1.0596 | lr: 9.9603e-05 | scale: 131072.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   6296/156230 | global iter:   6296/156230 | loss: 1.0886 | ds_loss: 1.1072 | lr: 9.9603e-05 | scale: 131072.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6296/156230 | global iter:   6296/156230 | loss: 1.1276 | ds_loss: 1.1463 | lr: 9.9603e-05 | scale: 131072.0000 | micro time: 1.353 | step time: 1.376
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6297/156230 | global iter:   6297/156230 | loss: 1.0407 | ds_loss: 1.0481 | lr: 9.9603e-05 | scale: 131072.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   6298/156230 | global iter:   6298/156230 | loss: 1.1934 | ds_loss: 1.2064 | lr: 9.9603e-05 | scale: 131072.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   6299/156230 | global iter:   6299/156230 | loss: 1.3687 | ds_loss: 1.3813 | lr: 9.9602e-05 | scale: 131072.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   6300/156230 | global iter:   6300/156230 | loss: 1.0615 | ds_loss: 1.0832 | lr: 9.9602e-05 | scale: 131072.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6300/156230 | global iter:   6300/156230 | loss: 1.1661 | ds_loss: 1.1798 | lr: 9.9602e-05 | scale: 131072.0000 | micro time: 1.365 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6301/156230 | global iter:   6301/156230 | loss: 1.1771 | ds_loss: 1.1880 | lr: 9.9602e-05 | scale: 131072.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   6302/156230 | global iter:   6302/156230 | loss: 1.0815 | ds_loss: 1.1037 | lr: 9.9602e-05 | scale: 131072.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   6303/156230 | global iter:   6303/156230 | loss: 0.9970 | ds_loss: 1.0309 | lr: 9.9602e-05 | scale: 131072.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   6304/156230 | global iter:   6304/156230 | loss: 1.2029 | ds_loss: 1.2137 | lr: 9.9602e-05 | scale: 131072.0000 | micro time: 1.421 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6304/156230 | global iter:   6304/156230 | loss: 1.1146 | ds_loss: 1.1341 | lr: 9.9602e-05 | scale: 131072.0000 | micro time: 1.421 | step time: 1.380
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6305/156230 | global iter:   6305/156230 | loss: 1.0620 | ds_loss: 1.0824 | lr: 9.9602e-05 | scale: 131072.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   6306/156230 | global iter:   6306/156230 | loss: 1.2292 | ds_loss: 1.2530 | lr: 9.9602e-05 | scale: 131072.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   6307/156230 | global iter:   6307/156230 | loss: 1.2379 | ds_loss: 1.2448 | lr: 9.9601e-05 | scale: 131072.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   6308/156230 | global iter:   6308/156230 | loss: 1.2187 | ds_loss: 1.2283 | lr: 9.9601e-05 | scale: 131072.0000 | micro time: 1.340 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6308/156230 | global iter:   6308/156230 | loss: 1.1869 | ds_loss: 1.2021 | lr: 9.9601e-05 | scale: 131072.0000 | micro time: 1.340 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6309/156230 | global iter:   6309/156230 | loss: 1.0324 | ds_loss: 1.0425 | lr: 9.9601e-05 | scale: 131072.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   6310/156230 | global iter:   6310/156230 | loss: 0.9690 | ds_loss: 0.9853 | lr: 9.9601e-05 | scale: 131072.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   6311/156230 | global iter:   6311/156230 | loss: 1.0118 | ds_loss: 1.0306 | lr: 9.9601e-05 | scale: 131072.0000 | micro time: 1.314 | step time: 0.000
train | epoch   0 | Iter:   6312/156230 | global iter:   6312/156230 | loss: 1.0138 | ds_loss: 1.0347 | lr: 9.9601e-05 | scale: 131072.0000 | micro time: 1.329 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6312/156230 | global iter:   6312/156230 | loss: 1.0067 | ds_loss: 1.0233 | lr: 9.9601e-05 | scale: 131072.0000 | micro time: 1.329 | step time: 1.348
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6313/156230 | global iter:   6313/156230 | loss: 1.0725 | ds_loss: 1.1013 | lr: 9.9601e-05 | scale: 131072.0000 | micro time: 1.416 | step time: 0.000
train | epoch   0 | Iter:   6314/156230 | global iter:   6314/156230 | loss: 1.2080 | ds_loss: 1.2283 | lr: 9.9601e-05 | scale: 131072.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:   6315/156230 | global iter:   6315/156230 | loss: 1.0113 | ds_loss: 1.0347 | lr: 9.9600e-05 | scale: 131072.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   6316/156230 | global iter:   6316/156230 | loss: 1.0738 | ds_loss: 1.0968 | lr: 9.9600e-05 | scale: 131072.0000 | micro time: 1.388 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6316/156230 | global iter:   6316/156230 | loss: 1.0914 | ds_loss: 1.1153 | lr: 9.9600e-05 | scale: 131072.0000 | micro time: 1.388 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6317/156230 | global iter:   6317/156230 | loss: 0.9546 | ds_loss: 0.9704 | lr: 9.9600e-05 | scale: 131072.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   6318/156230 | global iter:   6318/156230 | loss: 1.2311 | ds_loss: 1.2408 | lr: 9.9600e-05 | scale: 131072.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   6319/156230 | global iter:   6319/156230 | loss: 1.2276 | ds_loss: 1.2415 | lr: 9.9600e-05 | scale: 131072.0000 | micro time: 1.321 | step time: 0.000
train | epoch   0 | Iter:   6320/156230 | global iter:   6320/156230 | loss: 1.1371 | ds_loss: 1.1465 | lr: 9.9600e-05 | scale: 131072.0000 | micro time: 1.339 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6320/156230 | global iter:   6320/156230 | loss: 1.1376 | ds_loss: 1.1498 | lr: 9.9600e-05 | scale: 131072.0000 | micro time: 1.339 | step time: 1.346
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6321/156230 | global iter:   6321/156230 | loss: 1.1230 | ds_loss: 1.1351 | lr: 9.9600e-05 | scale: 131072.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   6322/156230 | global iter:   6322/156230 | loss: 1.1039 | ds_loss: 1.1297 | lr: 9.9600e-05 | scale: 131072.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   6323/156230 | global iter:   6323/156230 | loss: 1.1110 | ds_loss: 1.1393 | lr: 9.9599e-05 | scale: 131072.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   6324/156230 | global iter:   6324/156230 | loss: 1.1014 | ds_loss: 1.1308 | lr: 9.9599e-05 | scale: 131072.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6324/156230 | global iter:   6324/156230 | loss: 1.1099 | ds_loss: 1.1337 | lr: 9.9599e-05 | scale: 131072.0000 | micro time: 1.393 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6325/156230 | global iter:   6325/156230 | loss: 1.3595 | ds_loss: 1.3748 | lr: 9.9599e-05 | scale: 131072.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   6326/156230 | global iter:   6326/156230 | loss: 1.0923 | ds_loss: 1.1112 | lr: 9.9599e-05 | scale: 131072.0000 | micro time: 1.401 | step time: 0.000
train | epoch   0 | Iter:   6327/156230 | global iter:   6327/156230 | loss: 1.1652 | ds_loss: 1.1816 | lr: 9.9599e-05 | scale: 131072.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   6328/156230 | global iter:   6328/156230 | loss: 1.1091 | ds_loss: 1.1514 | lr: 9.9599e-05 | scale: 131072.0000 | micro time: 1.332 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6328/156230 | global iter:   6328/156230 | loss: 1.1815 | ds_loss: 1.2047 | lr: 9.9599e-05 | scale: 131072.0000 | micro time: 1.332 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6329/156230 | global iter:   6329/156230 | loss: 1.1902 | ds_loss: 1.2060 | lr: 9.9599e-05 | scale: 131072.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:   6330/156230 | global iter:   6330/156230 | loss: 1.0292 | ds_loss: 1.0436 | lr: 9.9599e-05 | scale: 131072.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   6331/156230 | global iter:   6331/156230 | loss: 1.0279 | ds_loss: 1.0357 | lr: 9.9598e-05 | scale: 131072.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   6332/156230 | global iter:   6332/156230 | loss: 1.0399 | ds_loss: 1.0660 | lr: 9.9598e-05 | scale: 131072.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6332/156230 | global iter:   6332/156230 | loss: 1.0718 | ds_loss: 1.0878 | lr: 9.9598e-05 | scale: 131072.0000 | micro time: 1.378 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6333/156230 | global iter:   6333/156230 | loss: 1.2490 | ds_loss: 1.2639 | lr: 9.9598e-05 | scale: 131072.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   6334/156230 | global iter:   6334/156230 | loss: 1.1054 | ds_loss: 1.1110 | lr: 9.9598e-05 | scale: 131072.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   6335/156230 | global iter:   6335/156230 | loss: 1.0254 | ds_loss: 1.0460 | lr: 9.9598e-05 | scale: 131072.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   6336/156230 | global iter:   6336/156230 | loss: 1.0005 | ds_loss: 1.0195 | lr: 9.9598e-05 | scale: 131072.0000 | micro time: 1.344 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6336/156230 | global iter:   6336/156230 | loss: 1.0950 | ds_loss: 1.1101 | lr: 9.9598e-05 | scale: 131072.0000 | micro time: 1.344 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6337/156230 | global iter:   6337/156230 | loss: 0.9654 | ds_loss: 0.9845 | lr: 9.9598e-05 | scale: 131072.0000 | micro time: 1.317 | step time: 0.000
train | epoch   0 | Iter:   6338/156230 | global iter:   6338/156230 | loss: 1.0806 | ds_loss: 1.0967 | lr: 9.9598e-05 | scale: 131072.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   6339/156230 | global iter:   6339/156230 | loss: 1.0549 | ds_loss: 1.0711 | lr: 9.9597e-05 | scale: 131072.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   6340/156230 | global iter:   6340/156230 | loss: 1.0935 | ds_loss: 1.1056 | lr: 9.9597e-05 | scale: 131072.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6340/156230 | global iter:   6340/156230 | loss: 1.0486 | ds_loss: 1.0645 | lr: 9.9597e-05 | scale: 131072.0000 | micro time: 1.366 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6341/156230 | global iter:   6341/156230 | loss: 1.0276 | ds_loss: 1.0377 | lr: 9.9597e-05 | scale: 131072.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   6342/156230 | global iter:   6342/156230 | loss: 1.2049 | ds_loss: 1.2303 | lr: 9.9597e-05 | scale: 131072.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   6343/156230 | global iter:   6343/156230 | loss: 1.1980 | ds_loss: 1.2053 | lr: 9.9597e-05 | scale: 131072.0000 | micro time: 1.320 | step time: 0.000
train | epoch   0 | Iter:   6344/156230 | global iter:   6344/156230 | loss: 1.1868 | ds_loss: 1.2125 | lr: 9.9597e-05 | scale: 131072.0000 | micro time: 1.386 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6344/156230 | global iter:   6344/156230 | loss: 1.1543 | ds_loss: 1.1714 | lr: 9.9597e-05 | scale: 131072.0000 | micro time: 1.386 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6345/156230 | global iter:   6345/156230 | loss: 1.1935 | ds_loss: 1.2134 | lr: 9.9597e-05 | scale: 131072.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   6346/156230 | global iter:   6346/156230 | loss: 1.1864 | ds_loss: 1.2158 | lr: 9.9597e-05 | scale: 131072.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   6347/156230 | global iter:   6347/156230 | loss: 1.1040 | ds_loss: 1.1069 | lr: 9.9596e-05 | scale: 131072.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   6348/156230 | global iter:   6348/156230 | loss: 1.2854 | ds_loss: 1.2940 | lr: 9.9596e-05 | scale: 131072.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6348/156230 | global iter:   6348/156230 | loss: 1.1923 | ds_loss: 1.2075 | lr: 9.9596e-05 | scale: 131072.0000 | micro time: 1.342 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6349/156230 | global iter:   6349/156230 | loss: 1.1752 | ds_loss: 1.1990 | lr: 9.9596e-05 | scale: 131072.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   6350/156230 | global iter:   6350/156230 | loss: 1.0846 | ds_loss: 1.1047 | lr: 9.9596e-05 | scale: 131072.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   6351/156230 | global iter:   6351/156230 | loss: 1.1709 | ds_loss: 1.1862 | lr: 9.9596e-05 | scale: 131072.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   6352/156230 | global iter:   6352/156230 | loss: 1.2037 | ds_loss: 1.2310 | lr: 9.9596e-05 | scale: 131072.0000 | micro time: 1.399 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6352/156230 | global iter:   6352/156230 | loss: 1.1586 | ds_loss: 1.1802 | lr: 9.9596e-05 | scale: 131072.0000 | micro time: 1.399 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6353/156230 | global iter:   6353/156230 | loss: 1.1016 | ds_loss: 1.1301 | lr: 9.9596e-05 | scale: 131072.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   6354/156230 | global iter:   6354/156230 | loss: 0.9513 | ds_loss: 0.9783 | lr: 9.9596e-05 | scale: 131072.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   6355/156230 | global iter:   6355/156230 | loss: 1.0492 | ds_loss: 1.0507 | lr: 9.9595e-05 | scale: 131072.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   6356/156230 | global iter:   6356/156230 | loss: 1.2093 | ds_loss: 1.2299 | lr: 9.9595e-05 | scale: 131072.0000 | micro time: 1.328 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6356/156230 | global iter:   6356/156230 | loss: 1.0778 | ds_loss: 1.0972 | lr: 9.9595e-05 | scale: 131072.0000 | micro time: 1.328 | step time: 1.339
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6357/156230 | global iter:   6357/156230 | loss: 1.0455 | ds_loss: 1.0609 | lr: 9.9595e-05 | scale: 131072.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   6358/156230 | global iter:   6358/156230 | loss: 1.1948 | ds_loss: 1.2080 | lr: 9.9595e-05 | scale: 131072.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   6359/156230 | global iter:   6359/156230 | loss: 1.1917 | ds_loss: 1.2027 | lr: 9.9595e-05 | scale: 131072.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   6360/156230 | global iter:   6360/156230 | loss: 1.2126 | ds_loss: 1.2337 | lr: 9.9595e-05 | scale: 131072.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6360/156230 | global iter:   6360/156230 | loss: 1.1612 | ds_loss: 1.1763 | lr: 9.9595e-05 | scale: 131072.0000 | micro time: 1.347 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6361/156230 | global iter:   6361/156230 | loss: 1.1822 | ds_loss: 1.1795 | lr: 9.9595e-05 | scale: 131072.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   6362/156230 | global iter:   6362/156230 | loss: 0.9458 | ds_loss: 0.9616 | lr: 9.9594e-05 | scale: 131072.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   6363/156230 | global iter:   6363/156230 | loss: 1.2154 | ds_loss: 1.2418 | lr: 9.9594e-05 | scale: 131072.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   6364/156230 | global iter:   6364/156230 | loss: 1.0982 | ds_loss: 1.1130 | lr: 9.9594e-05 | scale: 131072.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6364/156230 | global iter:   6364/156230 | loss: 1.1104 | ds_loss: 1.1240 | lr: 9.9594e-05 | scale: 131072.0000 | micro time: 1.357 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6365/156230 | global iter:   6365/156230 | loss: 0.9085 | ds_loss: 0.9345 | lr: 9.9594e-05 | scale: 131072.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   6366/156230 | global iter:   6366/156230 | loss: 1.1306 | ds_loss: 1.1524 | lr: 9.9594e-05 | scale: 131072.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   6367/156230 | global iter:   6367/156230 | loss: 1.2129 | ds_loss: 1.2384 | lr: 9.9594e-05 | scale: 131072.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   6368/156230 | global iter:   6368/156230 | loss: 1.1536 | ds_loss: 1.1711 | lr: 9.9594e-05 | scale: 131072.0000 | micro time: 1.331 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6368/156230 | global iter:   6368/156230 | loss: 1.1014 | ds_loss: 1.1241 | lr: 9.9594e-05 | scale: 131072.0000 | micro time: 1.331 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6369/156230 | global iter:   6369/156230 | loss: 1.1479 | ds_loss: 1.1707 | lr: 9.9594e-05 | scale: 131072.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   6370/156230 | global iter:   6370/156230 | loss: 1.3005 | ds_loss: 1.3199 | lr: 9.9593e-05 | scale: 131072.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   6371/156230 | global iter:   6371/156230 | loss: 1.0504 | ds_loss: 1.0680 | lr: 9.9593e-05 | scale: 131072.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   6372/156230 | global iter:   6372/156230 | loss: 1.1172 | ds_loss: 1.1367 | lr: 9.9593e-05 | scale: 131072.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6372/156230 | global iter:   6372/156230 | loss: 1.1540 | ds_loss: 1.1739 | lr: 9.9593e-05 | scale: 131072.0000 | micro time: 1.364 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6373/156230 | global iter:   6373/156230 | loss: 0.9951 | ds_loss: 1.0203 | lr: 9.9593e-05 | scale: 131072.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:   6374/156230 | global iter:   6374/156230 | loss: 1.1890 | ds_loss: 1.2020 | lr: 9.9593e-05 | scale: 131072.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   6375/156230 | global iter:   6375/156230 | loss: 0.9655 | ds_loss: 0.9787 | lr: 9.9593e-05 | scale: 131072.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   6376/156230 | global iter:   6376/156230 | loss: 1.2178 | ds_loss: 1.2332 | lr: 9.9593e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6376/156230 | global iter:   6376/156230 | loss: 1.0918 | ds_loss: 1.1086 | lr: 9.9593e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6377/156230 | global iter:   6377/156230 | loss: 1.1391 | ds_loss: 1.1513 | lr: 9.9593e-05 | scale: 131072.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   6378/156230 | global iter:   6378/156230 | loss: 1.0558 | ds_loss: 1.0848 | lr: 9.9592e-05 | scale: 131072.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   6379/156230 | global iter:   6379/156230 | loss: 1.0383 | ds_loss: 1.0578 | lr: 9.9592e-05 | scale: 131072.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   6380/156230 | global iter:   6380/156230 | loss: 1.1884 | ds_loss: 1.2167 | lr: 9.9592e-05 | scale: 131072.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6380/156230 | global iter:   6380/156230 | loss: 1.1054 | ds_loss: 1.1276 | lr: 9.9592e-05 | scale: 131072.0000 | micro time: 1.369 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6381/156230 | global iter:   6381/156230 | loss: 1.0230 | ds_loss: 1.0337 | lr: 9.9592e-05 | scale: 131072.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   6382/156230 | global iter:   6382/156230 | loss: 1.1281 | ds_loss: 1.1149 | lr: 9.9592e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   6383/156230 | global iter:   6383/156230 | loss: 1.1152 | ds_loss: 1.1502 | lr: 9.9592e-05 | scale: 131072.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   6384/156230 | global iter:   6384/156230 | loss: 1.0174 | ds_loss: 1.0475 | lr: 9.9592e-05 | scale: 131072.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6384/156230 | global iter:   6384/156230 | loss: 1.0709 | ds_loss: 1.0866 | lr: 9.9592e-05 | scale: 131072.0000 | micro time: 1.350 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6385/156230 | global iter:   6385/156230 | loss: 0.9267 | ds_loss: 0.9488 | lr: 9.9592e-05 | scale: 131072.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   6386/156230 | global iter:   6386/156230 | loss: 1.1678 | ds_loss: 1.1755 | lr: 9.9591e-05 | scale: 131072.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   6387/156230 | global iter:   6387/156230 | loss: 1.0954 | ds_loss: 1.1201 | lr: 9.9591e-05 | scale: 131072.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   6388/156230 | global iter:   6388/156230 | loss: 0.9754 | ds_loss: 0.9994 | lr: 9.9591e-05 | scale: 131072.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6388/156230 | global iter:   6388/156230 | loss: 1.0413 | ds_loss: 1.0609 | lr: 9.9591e-05 | scale: 131072.0000 | micro time: 1.393 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6389/156230 | global iter:   6389/156230 | loss: 1.1917 | ds_loss: 1.2174 | lr: 9.9591e-05 | scale: 131072.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   6390/156230 | global iter:   6390/156230 | loss: 1.1047 | ds_loss: 1.1485 | lr: 9.9591e-05 | scale: 131072.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   6391/156230 | global iter:   6391/156230 | loss: 1.1376 | ds_loss: 1.1447 | lr: 9.9591e-05 | scale: 131072.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   6392/156230 | global iter:   6392/156230 | loss: 1.1739 | ds_loss: 1.1944 | lr: 9.9591e-05 | scale: 131072.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6392/156230 | global iter:   6392/156230 | loss: 1.1520 | ds_loss: 1.1762 | lr: 9.9591e-05 | scale: 131072.0000 | micro time: 1.347 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6393/156230 | global iter:   6393/156230 | loss: 1.1836 | ds_loss: 1.2053 | lr: 9.9591e-05 | scale: 131072.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   6394/156230 | global iter:   6394/156230 | loss: 1.1591 | ds_loss: 1.1742 | lr: 9.9590e-05 | scale: 131072.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   6395/156230 | global iter:   6395/156230 | loss: 1.1027 | ds_loss: 1.1222 | lr: 9.9590e-05 | scale: 131072.0000 | micro time: 1.325 | step time: 0.000
train | epoch   0 | Iter:   6396/156230 | global iter:   6396/156230 | loss: 0.9951 | ds_loss: 1.0027 | lr: 9.9590e-05 | scale: 131072.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6396/156230 | global iter:   6396/156230 | loss: 1.1101 | ds_loss: 1.1261 | lr: 9.9590e-05 | scale: 131072.0000 | micro time: 1.381 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6397/156230 | global iter:   6397/156230 | loss: 1.0452 | ds_loss: 1.0630 | lr: 9.9590e-05 | scale: 131072.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   6398/156230 | global iter:   6398/156230 | loss: 1.3068 | ds_loss: 1.3370 | lr: 9.9590e-05 | scale: 131072.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   6399/156230 | global iter:   6399/156230 | loss: 1.2186 | ds_loss: 1.2381 | lr: 9.9590e-05 | scale: 131072.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   6400/156230 | global iter:   6400/156230 | loss: 1.0338 | ds_loss: 1.0593 | lr: 9.9590e-05 | scale: 131072.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6400/156230 | global iter:   6400/156230 | loss: 1.1511 | ds_loss: 1.1744 | lr: 9.9590e-05 | scale: 131072.0000 | micro time: 1.361 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6401/156230 | global iter:   6401/156230 | loss: 1.3051 | ds_loss: 1.3262 | lr: 9.9589e-05 | scale: 131072.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   6402/156230 | global iter:   6402/156230 | loss: 1.1014 | ds_loss: 1.1193 | lr: 9.9589e-05 | scale: 131072.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   6403/156230 | global iter:   6403/156230 | loss: 0.9626 | ds_loss: 0.9759 | lr: 9.9589e-05 | scale: 131072.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   6404/156230 | global iter:   6404/156230 | loss: 1.1003 | ds_loss: 1.1216 | lr: 9.9589e-05 | scale: 131072.0000 | micro time: 1.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6404/156230 | global iter:   6404/156230 | loss: 1.1174 | ds_loss: 1.1357 | lr: 9.9589e-05 | scale: 131072.0000 | micro time: 1.398 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6405/156230 | global iter:   6405/156230 | loss: 0.8895 | ds_loss: 0.9169 | lr: 9.9589e-05 | scale: 131072.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   6406/156230 | global iter:   6406/156230 | loss: 0.9864 | ds_loss: 1.0150 | lr: 9.9589e-05 | scale: 131072.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   6407/156230 | global iter:   6407/156230 | loss: 1.0384 | ds_loss: 1.0693 | lr: 9.9589e-05 | scale: 131072.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   6408/156230 | global iter:   6408/156230 | loss: 1.1264 | ds_loss: 1.1614 | lr: 9.9589e-05 | scale: 131072.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6408/156230 | global iter:   6408/156230 | loss: 1.0102 | ds_loss: 1.0406 | lr: 9.9589e-05 | scale: 131072.0000 | micro time: 1.381 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6409/156230 | global iter:   6409/156230 | loss: 1.1096 | ds_loss: 1.1207 | lr: 9.9588e-05 | scale: 131072.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   6410/156230 | global iter:   6410/156230 | loss: 0.9671 | ds_loss: 0.9617 | lr: 9.9588e-05 | scale: 131072.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   6411/156230 | global iter:   6411/156230 | loss: 1.0888 | ds_loss: 1.1122 | lr: 9.9588e-05 | scale: 131072.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   6412/156230 | global iter:   6412/156230 | loss: 1.0404 | ds_loss: 1.0543 | lr: 9.9588e-05 | scale: 131072.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6412/156230 | global iter:   6412/156230 | loss: 1.0515 | ds_loss: 1.0622 | lr: 9.9588e-05 | scale: 131072.0000 | micro time: 1.349 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6413/156230 | global iter:   6413/156230 | loss: 1.1576 | ds_loss: 1.1637 | lr: 9.9588e-05 | scale: 131072.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   6414/156230 | global iter:   6414/156230 | loss: 0.9744 | ds_loss: 0.9895 | lr: 9.9588e-05 | scale: 131072.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   6415/156230 | global iter:   6415/156230 | loss: 1.1298 | ds_loss: 1.1413 | lr: 9.9588e-05 | scale: 131072.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   6416/156230 | global iter:   6416/156230 | loss: 1.2063 | ds_loss: 1.2302 | lr: 9.9588e-05 | scale: 131072.0000 | micro time: 1.375 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6416/156230 | global iter:   6416/156230 | loss: 1.1170 | ds_loss: 1.1312 | lr: 9.9588e-05 | scale: 131072.0000 | micro time: 1.375 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6417/156230 | global iter:   6417/156230 | loss: 0.9894 | ds_loss: 1.0082 | lr: 9.9587e-05 | scale: 131072.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   6418/156230 | global iter:   6418/156230 | loss: 0.9449 | ds_loss: 0.9613 | lr: 9.9587e-05 | scale: 131072.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   6419/156230 | global iter:   6419/156230 | loss: 1.1283 | ds_loss: 1.1516 | lr: 9.9587e-05 | scale: 131072.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   6420/156230 | global iter:   6420/156230 | loss: 1.1372 | ds_loss: 1.1597 | lr: 9.9587e-05 | scale: 131072.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6420/156230 | global iter:   6420/156230 | loss: 1.0499 | ds_loss: 1.0702 | lr: 9.9587e-05 | scale: 131072.0000 | micro time: 1.369 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6421/156230 | global iter:   6421/156230 | loss: 1.0827 | ds_loss: 1.1044 | lr: 9.9587e-05 | scale: 131072.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   6422/156230 | global iter:   6422/156230 | loss: 0.9584 | ds_loss: 0.9901 | lr: 9.9587e-05 | scale: 131072.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   6423/156230 | global iter:   6423/156230 | loss: 1.2939 | ds_loss: 1.3024 | lr: 9.9587e-05 | scale: 131072.0000 | micro time: 1.322 | step time: 0.000
train | epoch   0 | Iter:   6424/156230 | global iter:   6424/156230 | loss: 1.1659 | ds_loss: 1.1872 | lr: 9.9587e-05 | scale: 131072.0000 | micro time: 1.389 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6424/156230 | global iter:   6424/156230 | loss: 1.1252 | ds_loss: 1.1460 | lr: 9.9587e-05 | scale: 131072.0000 | micro time: 1.389 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6425/156230 | global iter:   6425/156230 | loss: 1.1272 | ds_loss: 1.1421 | lr: 9.9586e-05 | scale: 131072.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   6426/156230 | global iter:   6426/156230 | loss: 1.0271 | ds_loss: 1.0394 | lr: 9.9586e-05 | scale: 131072.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   6427/156230 | global iter:   6427/156230 | loss: 0.9990 | ds_loss: 1.0190 | lr: 9.9586e-05 | scale: 131072.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   6428/156230 | global iter:   6428/156230 | loss: 1.2099 | ds_loss: 1.2289 | lr: 9.9586e-05 | scale: 131072.0000 | micro time: 1.340 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6428/156230 | global iter:   6428/156230 | loss: 1.0908 | ds_loss: 1.1073 | lr: 9.9586e-05 | scale: 131072.0000 | micro time: 1.340 | step time: 1.340
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6429/156230 | global iter:   6429/156230 | loss: 1.0467 | ds_loss: 1.0631 | lr: 9.9586e-05 | scale: 131072.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   6430/156230 | global iter:   6430/156230 | loss: 1.1309 | ds_loss: 1.1338 | lr: 9.9586e-05 | scale: 131072.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   6431/156230 | global iter:   6431/156230 | loss: 1.1112 | ds_loss: 1.1255 | lr: 9.9586e-05 | scale: 131072.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   6432/156230 | global iter:   6432/156230 | loss: 1.1998 | ds_loss: 1.2115 | lr: 9.9585e-05 | scale: 131072.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6432/156230 | global iter:   6432/156230 | loss: 1.1221 | ds_loss: 1.1335 | lr: 9.9585e-05 | scale: 131072.0000 | micro time: 1.354 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6433/156230 | global iter:   6433/156230 | loss: 1.0583 | ds_loss: 1.0752 | lr: 9.9585e-05 | scale: 131072.0000 | micro time: 1.325 | step time: 0.000
train | epoch   0 | Iter:   6434/156230 | global iter:   6434/156230 | loss: 1.0465 | ds_loss: 1.0488 | lr: 9.9585e-05 | scale: 131072.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   6435/156230 | global iter:   6435/156230 | loss: 0.9369 | ds_loss: 0.9604 | lr: 9.9585e-05 | scale: 131072.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   6436/156230 | global iter:   6436/156230 | loss: 1.2701 | ds_loss: 1.2871 | lr: 9.9585e-05 | scale: 131072.0000 | micro time: 1.358 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6436/156230 | global iter:   6436/156230 | loss: 1.0779 | ds_loss: 1.0929 | lr: 9.9585e-05 | scale: 131072.0000 | micro time: 1.358 | step time: 1.346
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6437/156230 | global iter:   6437/156230 | loss: 1.0984 | ds_loss: 1.1292 | lr: 9.9585e-05 | scale: 131072.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   6438/156230 | global iter:   6438/156230 | loss: 1.0822 | ds_loss: 1.0894 | lr: 9.9585e-05 | scale: 131072.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   6439/156230 | global iter:   6439/156230 | loss: 0.9396 | ds_loss: 0.9586 | lr: 9.9585e-05 | scale: 131072.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   6440/156230 | global iter:   6440/156230 | loss: 1.0116 | ds_loss: 1.0180 | lr: 9.9584e-05 | scale: 131072.0000 | micro time: 1.320 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6440/156230 | global iter:   6440/156230 | loss: 1.0330 | ds_loss: 1.0488 | lr: 9.9584e-05 | scale: 131072.0000 | micro time: 1.320 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6441/156230 | global iter:   6441/156230 | loss: 0.9714 | ds_loss: 0.9786 | lr: 9.9584e-05 | scale: 131072.0000 | micro time: 1.412 | step time: 0.000
train | epoch   0 | Iter:   6442/156230 | global iter:   6442/156230 | loss: 1.0903 | ds_loss: 1.1046 | lr: 9.9584e-05 | scale: 131072.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   6443/156230 | global iter:   6443/156230 | loss: 1.0109 | ds_loss: 1.0270 | lr: 9.9584e-05 | scale: 131072.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   6444/156230 | global iter:   6444/156230 | loss: 1.1643 | ds_loss: 1.1727 | lr: 9.9584e-05 | scale: 131072.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6444/156230 | global iter:   6444/156230 | loss: 1.0592 | ds_loss: 1.0707 | lr: 9.9584e-05 | scale: 131072.0000 | micro time: 1.374 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6445/156230 | global iter:   6445/156230 | loss: 1.0646 | ds_loss: 1.0885 | lr: 9.9584e-05 | scale: 131072.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   6446/156230 | global iter:   6446/156230 | loss: 1.0697 | ds_loss: 1.0964 | lr: 9.9584e-05 | scale: 131072.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   6447/156230 | global iter:   6447/156230 | loss: 1.0640 | ds_loss: 1.0882 | lr: 9.9584e-05 | scale: 131072.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   6448/156230 | global iter:   6448/156230 | loss: 1.2142 | ds_loss: 1.2376 | lr: 9.9583e-05 | scale: 131072.0000 | micro time: 1.322 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6448/156230 | global iter:   6448/156230 | loss: 1.1031 | ds_loss: 1.1277 | lr: 9.9583e-05 | scale: 131072.0000 | micro time: 1.322 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6449/156230 | global iter:   6449/156230 | loss: 1.0830 | ds_loss: 1.0776 | lr: 9.9583e-05 | scale: 131072.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   6450/156230 | global iter:   6450/156230 | loss: 1.0105 | ds_loss: 1.0295 | lr: 9.9583e-05 | scale: 131072.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   6451/156230 | global iter:   6451/156230 | loss: 1.0784 | ds_loss: 1.1088 | lr: 9.9583e-05 | scale: 131072.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   6452/156230 | global iter:   6452/156230 | loss: 1.1100 | ds_loss: 1.1022 | lr: 9.9583e-05 | scale: 131072.0000 | micro time: 1.330 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6452/156230 | global iter:   6452/156230 | loss: 1.0705 | ds_loss: 1.0795 | lr: 9.9583e-05 | scale: 131072.0000 | micro time: 1.330 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6453/156230 | global iter:   6453/156230 | loss: 1.1837 | ds_loss: 1.2062 | lr: 9.9583e-05 | scale: 131072.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   6454/156230 | global iter:   6454/156230 | loss: 1.1890 | ds_loss: 1.2080 | lr: 9.9583e-05 | scale: 131072.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   6455/156230 | global iter:   6455/156230 | loss: 1.0290 | ds_loss: 1.0401 | lr: 9.9583e-05 | scale: 131072.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   6456/156230 | global iter:   6456/156230 | loss: 1.2310 | ds_loss: 1.2479 | lr: 9.9582e-05 | scale: 131072.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6456/156230 | global iter:   6456/156230 | loss: 1.1582 | ds_loss: 1.1755 | lr: 9.9582e-05 | scale: 131072.0000 | micro time: 1.350 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6457/156230 | global iter:   6457/156230 | loss: 1.1566 | ds_loss: 1.1528 | lr: 9.9582e-05 | scale: 131072.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   6458/156230 | global iter:   6458/156230 | loss: 1.0818 | ds_loss: 1.0885 | lr: 9.9582e-05 | scale: 131072.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   6459/156230 | global iter:   6459/156230 | loss: 1.3391 | ds_loss: 1.3533 | lr: 9.9582e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   6460/156230 | global iter:   6460/156230 | loss: 1.0534 | ds_loss: 1.0831 | lr: 9.9582e-05 | scale: 131072.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6460/156230 | global iter:   6460/156230 | loss: 1.1577 | ds_loss: 1.1694 | lr: 9.9582e-05 | scale: 131072.0000 | micro time: 1.370 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6461/156230 | global iter:   6461/156230 | loss: 0.9273 | ds_loss: 0.9555 | lr: 9.9582e-05 | scale: 131072.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   6462/156230 | global iter:   6462/156230 | loss: 1.2000 | ds_loss: 1.2266 | lr: 9.9582e-05 | scale: 131072.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   6463/156230 | global iter:   6463/156230 | loss: 1.1935 | ds_loss: 1.1993 | lr: 9.9581e-05 | scale: 131072.0000 | micro time: 1.401 | step time: 0.000
train | epoch   0 | Iter:   6464/156230 | global iter:   6464/156230 | loss: 0.9995 | ds_loss: 1.0362 | lr: 9.9581e-05 | scale: 131072.0000 | micro time: 1.409 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6464/156230 | global iter:   6464/156230 | loss: 1.0801 | ds_loss: 1.1044 | lr: 9.9581e-05 | scale: 131072.0000 | micro time: 1.409 | step time: 1.384
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6465/156230 | global iter:   6465/156230 | loss: 0.9400 | ds_loss: 0.9497 | lr: 9.9581e-05 | scale: 131072.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   6466/156230 | global iter:   6466/156230 | loss: 1.0275 | ds_loss: 1.0334 | lr: 9.9581e-05 | scale: 131072.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   6467/156230 | global iter:   6467/156230 | loss: 1.1110 | ds_loss: 1.1270 | lr: 9.9581e-05 | scale: 131072.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   6468/156230 | global iter:   6468/156230 | loss: 1.2336 | ds_loss: 1.2441 | lr: 9.9581e-05 | scale: 131072.0000 | micro time: 1.328 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6468/156230 | global iter:   6468/156230 | loss: 1.0780 | ds_loss: 1.0886 | lr: 9.9581e-05 | scale: 131072.0000 | micro time: 1.328 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6469/156230 | global iter:   6469/156230 | loss: 1.0818 | ds_loss: 1.0837 | lr: 9.9581e-05 | scale: 131072.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   6470/156230 | global iter:   6470/156230 | loss: 1.2930 | ds_loss: 1.3267 | lr: 9.9581e-05 | scale: 131072.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   6471/156230 | global iter:   6471/156230 | loss: 1.0544 | ds_loss: 1.0790 | lr: 9.9580e-05 | scale: 131072.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   6472/156230 | global iter:   6472/156230 | loss: 1.2546 | ds_loss: 1.2730 | lr: 9.9580e-05 | scale: 131072.0000 | micro time: 1.352 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6472/156230 | global iter:   6472/156230 | loss: 1.1709 | ds_loss: 1.1906 | lr: 9.9580e-05 | scale: 131072.0000 | micro time: 1.352 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6473/156230 | global iter:   6473/156230 | loss: 1.1333 | ds_loss: 1.1477 | lr: 9.9580e-05 | scale: 131072.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   6474/156230 | global iter:   6474/156230 | loss: 1.2578 | ds_loss: 1.2707 | lr: 9.9580e-05 | scale: 131072.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   6475/156230 | global iter:   6475/156230 | loss: 1.1530 | ds_loss: 1.1563 | lr: 9.9580e-05 | scale: 131072.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   6476/156230 | global iter:   6476/156230 | loss: 1.1890 | ds_loss: 1.2024 | lr: 9.9580e-05 | scale: 131072.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6476/156230 | global iter:   6476/156230 | loss: 1.1833 | ds_loss: 1.1943 | lr: 9.9580e-05 | scale: 131072.0000 | micro time: 1.351 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6477/156230 | global iter:   6477/156230 | loss: 1.0397 | ds_loss: 1.0557 | lr: 9.9580e-05 | scale: 131072.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   6478/156230 | global iter:   6478/156230 | loss: 1.1555 | ds_loss: 1.1832 | lr: 9.9580e-05 | scale: 131072.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   6479/156230 | global iter:   6479/156230 | loss: 0.9286 | ds_loss: 0.9472 | lr: 9.9579e-05 | scale: 131072.0000 | micro time: 1.436 | step time: 0.000
train | epoch   0 | Iter:   6480/156230 | global iter:   6480/156230 | loss: 1.0653 | ds_loss: 1.0884 | lr: 9.9579e-05 | scale: 131072.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6480/156230 | global iter:   6480/156230 | loss: 1.0473 | ds_loss: 1.0686 | lr: 9.9579e-05 | scale: 131072.0000 | micro time: 1.369 | step time: 1.390
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6481/156230 | global iter:   6481/156230 | loss: 1.1190 | ds_loss: 1.1218 | lr: 9.9579e-05 | scale: 131072.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   6482/156230 | global iter:   6482/156230 | loss: 1.1202 | ds_loss: 1.1454 | lr: 9.9579e-05 | scale: 131072.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   6483/156230 | global iter:   6483/156230 | loss: 1.1148 | ds_loss: 1.1594 | lr: 9.9579e-05 | scale: 131072.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   6484/156230 | global iter:   6484/156230 | loss: 1.1824 | ds_loss: 1.1967 | lr: 9.9579e-05 | scale: 131072.0000 | micro time: 1.390 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6484/156230 | global iter:   6484/156230 | loss: 1.1341 | ds_loss: 1.1558 | lr: 9.9579e-05 | scale: 131072.0000 | micro time: 1.390 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6485/156230 | global iter:   6485/156230 | loss: 0.9932 | ds_loss: 1.0182 | lr: 9.9579e-05 | scale: 131072.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   6486/156230 | global iter:   6486/156230 | loss: 0.7646 | ds_loss: 0.7595 | lr: 9.9578e-05 | scale: 131072.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   6487/156230 | global iter:   6487/156230 | loss: 1.0724 | ds_loss: 1.0921 | lr: 9.9578e-05 | scale: 131072.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   6488/156230 | global iter:   6488/156230 | loss: 1.2685 | ds_loss: 1.2803 | lr: 9.9578e-05 | scale: 131072.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6488/156230 | global iter:   6488/156230 | loss: 1.0247 | ds_loss: 1.0375 | lr: 9.9578e-05 | scale: 131072.0000 | micro time: 1.385 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6489/156230 | global iter:   6489/156230 | loss: 1.3175 | ds_loss: 1.3507 | lr: 9.9578e-05 | scale: 131072.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   6490/156230 | global iter:   6490/156230 | loss: 0.8301 | ds_loss: 0.8475 | lr: 9.9578e-05 | scale: 131072.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   6491/156230 | global iter:   6491/156230 | loss: 1.1478 | ds_loss: 1.1602 | lr: 9.9578e-05 | scale: 131072.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   6492/156230 | global iter:   6492/156230 | loss: 1.2260 | ds_loss: 1.2331 | lr: 9.9578e-05 | scale: 131072.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6492/156230 | global iter:   6492/156230 | loss: 1.1303 | ds_loss: 1.1479 | lr: 9.9578e-05 | scale: 131072.0000 | micro time: 1.361 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6493/156230 | global iter:   6493/156230 | loss: 1.2469 | ds_loss: 1.2781 | lr: 9.9578e-05 | scale: 131072.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   6494/156230 | global iter:   6494/156230 | loss: 1.0749 | ds_loss: 1.0906 | lr: 9.9577e-05 | scale: 131072.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   6495/156230 | global iter:   6495/156230 | loss: 1.2207 | ds_loss: 1.2185 | lr: 9.9577e-05 | scale: 131072.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   6496/156230 | global iter:   6496/156230 | loss: 1.0804 | ds_loss: 1.1123 | lr: 9.9577e-05 | scale: 131072.0000 | micro time: 1.358 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6496/156230 | global iter:   6496/156230 | loss: 1.1557 | ds_loss: 1.1749 | lr: 9.9577e-05 | scale: 131072.0000 | micro time: 1.358 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6497/156230 | global iter:   6497/156230 | loss: 1.1502 | ds_loss: 1.1539 | lr: 9.9577e-05 | scale: 131072.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   6498/156230 | global iter:   6498/156230 | loss: 1.1364 | ds_loss: 1.1574 | lr: 9.9577e-05 | scale: 131072.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   6499/156230 | global iter:   6499/156230 | loss: 1.3001 | ds_loss: 1.3295 | lr: 9.9577e-05 | scale: 131072.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   6500/156230 | global iter:   6500/156230 | loss: 0.9471 | ds_loss: 0.9456 | lr: 9.9577e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6500/156230 | global iter:   6500/156230 | loss: 1.1334 | ds_loss: 1.1466 | lr: 9.9577e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6501/156230 | global iter:   6501/156230 | loss: 1.1079 | ds_loss: 1.1288 | lr: 9.9577e-05 | scale: 131072.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   6502/156230 | global iter:   6502/156230 | loss: 1.0353 | ds_loss: 1.0419 | lr: 9.9576e-05 | scale: 131072.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   6503/156230 | global iter:   6503/156230 | loss: 1.2108 | ds_loss: 1.2267 | lr: 9.9576e-05 | scale: 131072.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   6504/156230 | global iter:   6504/156230 | loss: 1.0055 | ds_loss: 1.0233 | lr: 9.9576e-05 | scale: 131072.0000 | micro time: 1.322 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6504/156230 | global iter:   6504/156230 | loss: 1.0899 | ds_loss: 1.1052 | lr: 9.9576e-05 | scale: 131072.0000 | micro time: 1.322 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6505/156230 | global iter:   6505/156230 | loss: 1.1393 | ds_loss: 1.1450 | lr: 9.9576e-05 | scale: 131072.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   6506/156230 | global iter:   6506/156230 | loss: 1.2050 | ds_loss: 1.2271 | lr: 9.9576e-05 | scale: 131072.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   6507/156230 | global iter:   6507/156230 | loss: 1.0425 | ds_loss: 1.0655 | lr: 9.9576e-05 | scale: 131072.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   6508/156230 | global iter:   6508/156230 | loss: 1.1596 | ds_loss: 1.1783 | lr: 9.9576e-05 | scale: 131072.0000 | micro time: 1.372 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6508/156230 | global iter:   6508/156230 | loss: 1.1366 | ds_loss: 1.1540 | lr: 9.9576e-05 | scale: 131072.0000 | micro time: 1.372 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6509/156230 | global iter:   6509/156230 | loss: 0.8719 | ds_loss: 0.8823 | lr: 9.9575e-05 | scale: 131072.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   6510/156230 | global iter:   6510/156230 | loss: 1.0124 | ds_loss: 1.0386 | lr: 9.9575e-05 | scale: 131072.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   6511/156230 | global iter:   6511/156230 | loss: 1.1208 | ds_loss: 1.1188 | lr: 9.9575e-05 | scale: 131072.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   6512/156230 | global iter:   6512/156230 | loss: 0.8791 | ds_loss: 0.9071 | lr: 9.9575e-05 | scale: 131072.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6512/156230 | global iter:   6512/156230 | loss: 0.9711 | ds_loss: 0.9867 | lr: 9.9575e-05 | scale: 131072.0000 | micro time: 1.365 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6513/156230 | global iter:   6513/156230 | loss: 1.2797 | ds_loss: 1.2908 | lr: 9.9575e-05 | scale: 131072.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   6514/156230 | global iter:   6514/156230 | loss: 1.1471 | ds_loss: 1.1594 | lr: 9.9575e-05 | scale: 131072.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   6515/156230 | global iter:   6515/156230 | loss: 1.0526 | ds_loss: 1.0763 | lr: 9.9575e-05 | scale: 131072.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:   6516/156230 | global iter:   6516/156230 | loss: 1.1038 | ds_loss: 1.1227 | lr: 9.9575e-05 | scale: 131072.0000 | micro time: 1.340 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6516/156230 | global iter:   6516/156230 | loss: 1.1458 | ds_loss: 1.1623 | lr: 9.9575e-05 | scale: 131072.0000 | micro time: 1.340 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6517/156230 | global iter:   6517/156230 | loss: 0.9306 | ds_loss: 0.9544 | lr: 9.9574e-05 | scale: 131072.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   6518/156230 | global iter:   6518/156230 | loss: 1.1505 | ds_loss: 1.1651 | lr: 9.9574e-05 | scale: 131072.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   6519/156230 | global iter:   6519/156230 | loss: 1.0906 | ds_loss: 1.1045 | lr: 9.9574e-05 | scale: 131072.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   6520/156230 | global iter:   6520/156230 | loss: 1.0686 | ds_loss: 1.0911 | lr: 9.9574e-05 | scale: 131072.0000 | micro time: 1.367 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6520/156230 | global iter:   6520/156230 | loss: 1.0601 | ds_loss: 1.0788 | lr: 9.9574e-05 | scale: 131072.0000 | micro time: 1.367 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6521/156230 | global iter:   6521/156230 | loss: 1.1272 | ds_loss: 1.1404 | lr: 9.9574e-05 | scale: 131072.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:   6522/156230 | global iter:   6522/156230 | loss: 1.0735 | ds_loss: 1.0899 | lr: 9.9574e-05 | scale: 131072.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   6523/156230 | global iter:   6523/156230 | loss: 1.1142 | ds_loss: 1.1376 | lr: 9.9574e-05 | scale: 131072.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   6524/156230 | global iter:   6524/156230 | loss: 1.0478 | ds_loss: 1.0458 | lr: 9.9574e-05 | scale: 131072.0000 | micro time: 1.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6524/156230 | global iter:   6524/156230 | loss: 1.0907 | ds_loss: 1.1034 | lr: 9.9574e-05 | scale: 131072.0000 | micro time: 1.396 | step time: 1.390
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6525/156230 | global iter:   6525/156230 | loss: 0.9764 | ds_loss: 0.9852 | lr: 9.9573e-05 | scale: 131072.0000 | micro time: 1.316 | step time: 0.000
train | epoch   0 | Iter:   6526/156230 | global iter:   6526/156230 | loss: 1.1873 | ds_loss: 1.2143 | lr: 9.9573e-05 | scale: 131072.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   6527/156230 | global iter:   6527/156230 | loss: 0.9492 | ds_loss: 0.9574 | lr: 9.9573e-05 | scale: 131072.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   6528/156230 | global iter:   6528/156230 | loss: 1.1990 | ds_loss: 1.2194 | lr: 9.9573e-05 | scale: 131072.0000 | micro time: 1.341 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6528/156230 | global iter:   6528/156230 | loss: 1.0780 | ds_loss: 1.0941 | lr: 9.9573e-05 | scale: 131072.0000 | micro time: 1.341 | step time: 1.338
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6529/156230 | global iter:   6529/156230 | loss: 1.1810 | ds_loss: 1.2143 | lr: 9.9573e-05 | scale: 131072.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   6530/156230 | global iter:   6530/156230 | loss: 0.9794 | ds_loss: 0.9987 | lr: 9.9573e-05 | scale: 131072.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   6531/156230 | global iter:   6531/156230 | loss: 1.1651 | ds_loss: 1.1805 | lr: 9.9573e-05 | scale: 131072.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   6532/156230 | global iter:   6532/156230 | loss: 1.1770 | ds_loss: 1.1934 | lr: 9.9572e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6532/156230 | global iter:   6532/156230 | loss: 1.1256 | ds_loss: 1.1467 | lr: 9.9572e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6533/156230 | global iter:   6533/156230 | loss: 1.1240 | ds_loss: 1.1510 | lr: 9.9572e-05 | scale: 131072.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   6534/156230 | global iter:   6534/156230 | loss: 0.9229 | ds_loss: 0.9413 | lr: 9.9572e-05 | scale: 131072.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   6535/156230 | global iter:   6535/156230 | loss: 1.0923 | ds_loss: 1.1203 | lr: 9.9572e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   6536/156230 | global iter:   6536/156230 | loss: 1.0071 | ds_loss: 1.0273 | lr: 9.9572e-05 | scale: 131072.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6536/156230 | global iter:   6536/156230 | loss: 1.0366 | ds_loss: 1.0600 | lr: 9.9572e-05 | scale: 131072.0000 | micro time: 1.351 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6537/156230 | global iter:   6537/156230 | loss: 1.1661 | ds_loss: 1.1952 | lr: 9.9572e-05 | scale: 131072.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   6538/156230 | global iter:   6538/156230 | loss: 0.9720 | ds_loss: 0.9937 | lr: 9.9572e-05 | scale: 131072.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   6539/156230 | global iter:   6539/156230 | loss: 1.1780 | ds_loss: 1.1852 | lr: 9.9572e-05 | scale: 131072.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   6540/156230 | global iter:   6540/156230 | loss: 1.1641 | ds_loss: 1.1890 | lr: 9.9571e-05 | scale: 131072.0000 | micro time: 1.341 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6540/156230 | global iter:   6540/156230 | loss: 1.1201 | ds_loss: 1.1408 | lr: 9.9571e-05 | scale: 131072.0000 | micro time: 1.341 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6541/156230 | global iter:   6541/156230 | loss: 1.1198 | ds_loss: 1.1452 | lr: 9.9571e-05 | scale: 131072.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   6542/156230 | global iter:   6542/156230 | loss: 1.0153 | ds_loss: 1.0244 | lr: 9.9571e-05 | scale: 131072.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   6543/156230 | global iter:   6543/156230 | loss: 1.1317 | ds_loss: 1.1378 | lr: 9.9571e-05 | scale: 131072.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   6544/156230 | global iter:   6544/156230 | loss: 1.2446 | ds_loss: 1.2572 | lr: 9.9571e-05 | scale: 131072.0000 | micro time: 1.337 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6544/156230 | global iter:   6544/156230 | loss: 1.1279 | ds_loss: 1.1412 | lr: 9.9571e-05 | scale: 131072.0000 | micro time: 1.337 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6545/156230 | global iter:   6545/156230 | loss: 1.0498 | ds_loss: 1.0647 | lr: 9.9571e-05 | scale: 131072.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   6546/156230 | global iter:   6546/156230 | loss: 0.9307 | ds_loss: 0.9553 | lr: 9.9571e-05 | scale: 131072.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   6547/156230 | global iter:   6547/156230 | loss: 1.0169 | ds_loss: 1.0400 | lr: 9.9571e-05 | scale: 131072.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   6548/156230 | global iter:   6548/156230 | loss: 1.0094 | ds_loss: 1.0320 | lr: 9.9570e-05 | scale: 131072.0000 | micro time: 1.332 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6548/156230 | global iter:   6548/156230 | loss: 1.0017 | ds_loss: 1.0230 | lr: 9.9570e-05 | scale: 131072.0000 | micro time: 1.332 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6549/156230 | global iter:   6549/156230 | loss: 1.1022 | ds_loss: 1.1109 | lr: 9.9570e-05 | scale: 131072.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   6550/156230 | global iter:   6550/156230 | loss: 0.9446 | ds_loss: 0.9657 | lr: 9.9570e-05 | scale: 131072.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   6551/156230 | global iter:   6551/156230 | loss: 0.9999 | ds_loss: 1.0112 | lr: 9.9570e-05 | scale: 131072.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   6552/156230 | global iter:   6552/156230 | loss: 1.1944 | ds_loss: 1.2091 | lr: 9.9570e-05 | scale: 131072.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6552/156230 | global iter:   6552/156230 | loss: 1.0603 | ds_loss: 1.0742 | lr: 9.9570e-05 | scale: 131072.0000 | micro time: 1.393 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6553/156230 | global iter:   6553/156230 | loss: 1.2264 | ds_loss: 1.2497 | lr: 9.9570e-05 | scale: 131072.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   6554/156230 | global iter:   6554/156230 | loss: 1.2494 | ds_loss: 1.2588 | lr: 9.9570e-05 | scale: 131072.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   6555/156230 | global iter:   6555/156230 | loss: 1.0755 | ds_loss: 1.0825 | lr: 9.9569e-05 | scale: 131072.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   6556/156230 | global iter:   6556/156230 | loss: 0.9954 | ds_loss: 1.0044 | lr: 9.9569e-05 | scale: 131072.0000 | micro time: 1.331 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6556/156230 | global iter:   6556/156230 | loss: 1.1367 | ds_loss: 1.1488 | lr: 9.9569e-05 | scale: 131072.0000 | micro time: 1.331 | step time: 1.346
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6557/156230 | global iter:   6557/156230 | loss: 1.0328 | ds_loss: 1.0457 | lr: 9.9569e-05 | scale: 131072.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   6558/156230 | global iter:   6558/156230 | loss: 1.0189 | ds_loss: 1.0428 | lr: 9.9569e-05 | scale: 131072.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   6559/156230 | global iter:   6559/156230 | loss: 0.8581 | ds_loss: 0.8716 | lr: 9.9569e-05 | scale: 131072.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   6560/156230 | global iter:   6560/156230 | loss: 1.2261 | ds_loss: 1.2429 | lr: 9.9569e-05 | scale: 131072.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6560/156230 | global iter:   6560/156230 | loss: 1.0340 | ds_loss: 1.0507 | lr: 9.9569e-05 | scale: 131072.0000 | micro time: 1.377 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6561/156230 | global iter:   6561/156230 | loss: 1.0963 | ds_loss: 1.1292 | lr: 9.9569e-05 | scale: 131072.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   6562/156230 | global iter:   6562/156230 | loss: 0.9641 | ds_loss: 0.9817 | lr: 9.9569e-05 | scale: 131072.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   6563/156230 | global iter:   6563/156230 | loss: 1.1103 | ds_loss: 1.1412 | lr: 9.9568e-05 | scale: 131072.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   6564/156230 | global iter:   6564/156230 | loss: 1.0929 | ds_loss: 1.1033 | lr: 9.9568e-05 | scale: 131072.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6564/156230 | global iter:   6564/156230 | loss: 1.0659 | ds_loss: 1.0889 | lr: 9.9568e-05 | scale: 131072.0000 | micro time: 1.350 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6565/156230 | global iter:   6565/156230 | loss: 0.8261 | ds_loss: 0.8573 | lr: 9.9568e-05 | scale: 131072.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   6566/156230 | global iter:   6566/156230 | loss: 1.1171 | ds_loss: 1.1471 | lr: 9.9568e-05 | scale: 131072.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   6567/156230 | global iter:   6567/156230 | loss: 1.0216 | ds_loss: 1.0251 | lr: 9.9568e-05 | scale: 131072.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   6568/156230 | global iter:   6568/156230 | loss: 1.1319 | ds_loss: 1.1478 | lr: 9.9568e-05 | scale: 131072.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6568/156230 | global iter:   6568/156230 | loss: 1.0242 | ds_loss: 1.0443 | lr: 9.9568e-05 | scale: 131072.0000 | micro time: 1.376 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6569/156230 | global iter:   6569/156230 | loss: 1.0585 | ds_loss: 1.0646 | lr: 9.9568e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   6570/156230 | global iter:   6570/156230 | loss: 1.0293 | ds_loss: 1.0475 | lr: 9.9567e-05 | scale: 131072.0000 | micro time: 1.325 | step time: 0.000
train | epoch   0 | Iter:   6571/156230 | global iter:   6571/156230 | loss: 1.1410 | ds_loss: 1.1658 | lr: 9.9567e-05 | scale: 131072.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   6572/156230 | global iter:   6572/156230 | loss: 1.2013 | ds_loss: 1.2181 | lr: 9.9567e-05 | scale: 131072.0000 | micro time: 1.383 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6572/156230 | global iter:   6572/156230 | loss: 1.1075 | ds_loss: 1.1240 | lr: 9.9567e-05 | scale: 131072.0000 | micro time: 1.383 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6573/156230 | global iter:   6573/156230 | loss: 0.9534 | ds_loss: 0.9577 | lr: 9.9567e-05 | scale: 131072.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   6574/156230 | global iter:   6574/156230 | loss: 0.9802 | ds_loss: 0.9930 | lr: 9.9567e-05 | scale: 131072.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   6575/156230 | global iter:   6575/156230 | loss: 1.0782 | ds_loss: 1.0766 | lr: 9.9567e-05 | scale: 131072.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   6576/156230 | global iter:   6576/156230 | loss: 1.0600 | ds_loss: 1.0893 | lr: 9.9567e-05 | scale: 131072.0000 | micro time: 1.329 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6576/156230 | global iter:   6576/156230 | loss: 1.0179 | ds_loss: 1.0292 | lr: 9.9567e-05 | scale: 131072.0000 | micro time: 1.329 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6577/156230 | global iter:   6577/156230 | loss: 1.0093 | ds_loss: 1.0297 | lr: 9.9567e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   6578/156230 | global iter:   6578/156230 | loss: 1.1382 | ds_loss: 1.1686 | lr: 9.9566e-05 | scale: 131072.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   6579/156230 | global iter:   6579/156230 | loss: 0.9399 | ds_loss: 0.9569 | lr: 9.9566e-05 | scale: 131072.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   6580/156230 | global iter:   6580/156230 | loss: 1.2779 | ds_loss: 1.2897 | lr: 9.9566e-05 | scale: 131072.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6580/156230 | global iter:   6580/156230 | loss: 1.0913 | ds_loss: 1.1112 | lr: 9.9566e-05 | scale: 131072.0000 | micro time: 1.351 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6581/156230 | global iter:   6581/156230 | loss: 1.0425 | ds_loss: 1.0664 | lr: 9.9566e-05 | scale: 131072.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   6582/156230 | global iter:   6582/156230 | loss: 1.0680 | ds_loss: 1.0750 | lr: 9.9566e-05 | scale: 131072.0000 | micro time: 1.408 | step time: 0.000
train | epoch   0 | Iter:   6583/156230 | global iter:   6583/156230 | loss: 1.1845 | ds_loss: 1.1871 | lr: 9.9566e-05 | scale: 131072.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   6584/156230 | global iter:   6584/156230 | loss: 0.9381 | ds_loss: 0.9573 | lr: 9.9566e-05 | scale: 131072.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6584/156230 | global iter:   6584/156230 | loss: 1.0583 | ds_loss: 1.0715 | lr: 9.9566e-05 | scale: 131072.0000 | micro time: 1.349 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6585/156230 | global iter:   6585/156230 | loss: 1.2129 | ds_loss: 1.2146 | lr: 9.9566e-05 | scale: 131072.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   6586/156230 | global iter:   6586/156230 | loss: 1.1023 | ds_loss: 1.1187 | lr: 9.9565e-05 | scale: 131072.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   6587/156230 | global iter:   6587/156230 | loss: 1.0310 | ds_loss: 1.0379 | lr: 9.9565e-05 | scale: 131072.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   6588/156230 | global iter:   6588/156230 | loss: 1.1146 | ds_loss: 1.1269 | lr: 9.9565e-05 | scale: 131072.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6588/156230 | global iter:   6588/156230 | loss: 1.1152 | ds_loss: 1.1245 | lr: 9.9565e-05 | scale: 131072.0000 | micro time: 1.377 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6589/156230 | global iter:   6589/156230 | loss: 1.1833 | ds_loss: 1.2060 | lr: 9.9565e-05 | scale: 131072.0000 | micro time: 1.318 | step time: 0.000
train | epoch   0 | Iter:   6590/156230 | global iter:   6590/156230 | loss: 0.9729 | ds_loss: 1.0026 | lr: 9.9565e-05 | scale: 131072.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   6591/156230 | global iter:   6591/156230 | loss: 0.9752 | ds_loss: 1.0012 | lr: 9.9565e-05 | scale: 131072.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   6592/156230 | global iter:   6592/156230 | loss: 1.0869 | ds_loss: 1.1109 | lr: 9.9565e-05 | scale: 131072.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6592/156230 | global iter:   6592/156230 | loss: 1.0546 | ds_loss: 1.0802 | lr: 9.9565e-05 | scale: 131072.0000 | micro time: 1.362 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6593/156230 | global iter:   6593/156230 | loss: 1.1593 | ds_loss: 1.1813 | lr: 9.9564e-05 | scale: 131072.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   6594/156230 | global iter:   6594/156230 | loss: 1.1795 | ds_loss: 1.2041 | lr: 9.9564e-05 | scale: 131072.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   6595/156230 | global iter:   6595/156230 | loss: 1.0203 | ds_loss: 1.0334 | lr: 9.9564e-05 | scale: 131072.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   6596/156230 | global iter:   6596/156230 | loss: 0.9892 | ds_loss: 1.0245 | lr: 9.9564e-05 | scale: 131072.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6596/156230 | global iter:   6596/156230 | loss: 1.0871 | ds_loss: 1.1108 | lr: 9.9564e-05 | scale: 131072.0000 | micro time: 1.342 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6597/156230 | global iter:   6597/156230 | loss: 1.1964 | ds_loss: 1.2131 | lr: 9.9564e-05 | scale: 131072.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   6598/156230 | global iter:   6598/156230 | loss: 1.1643 | ds_loss: 1.1941 | lr: 9.9564e-05 | scale: 131072.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   6599/156230 | global iter:   6599/156230 | loss: 1.1859 | ds_loss: 1.1951 | lr: 9.9564e-05 | scale: 131072.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   6600/156230 | global iter:   6600/156230 | loss: 1.0565 | ds_loss: 1.0761 | lr: 9.9564e-05 | scale: 131072.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6600/156230 | global iter:   6600/156230 | loss: 1.1508 | ds_loss: 1.1696 | lr: 9.9564e-05 | scale: 131072.0000 | micro time: 1.373 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6601/156230 | global iter:   6601/156230 | loss: 0.9809 | ds_loss: 1.0297 | lr: 9.9563e-05 | scale: 131072.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   6602/156230 | global iter:   6602/156230 | loss: 1.2964 | ds_loss: 1.3103 | lr: 9.9563e-05 | scale: 131072.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   6603/156230 | global iter:   6603/156230 | loss: 1.1085 | ds_loss: 1.1255 | lr: 9.9563e-05 | scale: 131072.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   6604/156230 | global iter:   6604/156230 | loss: 1.1057 | ds_loss: 1.1243 | lr: 9.9563e-05 | scale: 131072.0000 | micro time: 1.329 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6604/156230 | global iter:   6604/156230 | loss: 1.1229 | ds_loss: 1.1475 | lr: 9.9563e-05 | scale: 131072.0000 | micro time: 1.329 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6605/156230 | global iter:   6605/156230 | loss: 1.1298 | ds_loss: 1.1423 | lr: 9.9563e-05 | scale: 131072.0000 | micro time: 1.408 | step time: 0.000
train | epoch   0 | Iter:   6606/156230 | global iter:   6606/156230 | loss: 1.1930 | ds_loss: 1.2078 | lr: 9.9563e-05 | scale: 131072.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   6607/156230 | global iter:   6607/156230 | loss: 1.0645 | ds_loss: 1.0808 | lr: 9.9563e-05 | scale: 131072.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   6608/156230 | global iter:   6608/156230 | loss: 1.1926 | ds_loss: 1.2055 | lr: 9.9562e-05 | scale: 131072.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6608/156230 | global iter:   6608/156230 | loss: 1.1450 | ds_loss: 1.1591 | lr: 9.9562e-05 | scale: 131072.0000 | micro time: 1.350 | step time: 1.376
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6609/156230 | global iter:   6609/156230 | loss: 1.2157 | ds_loss: 1.2287 | lr: 9.9562e-05 | scale: 131072.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   6610/156230 | global iter:   6610/156230 | loss: 1.1048 | ds_loss: 1.1241 | lr: 9.9562e-05 | scale: 131072.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   6611/156230 | global iter:   6611/156230 | loss: 1.1622 | ds_loss: 1.1642 | lr: 9.9562e-05 | scale: 131072.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   6612/156230 | global iter:   6612/156230 | loss: 1.1303 | ds_loss: 1.1506 | lr: 9.9562e-05 | scale: 131072.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6612/156230 | global iter:   6612/156230 | loss: 1.1532 | ds_loss: 1.1669 | lr: 9.9562e-05 | scale: 131072.0000 | micro time: 1.351 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6613/156230 | global iter:   6613/156230 | loss: 1.1719 | ds_loss: 1.1845 | lr: 9.9562e-05 | scale: 131072.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   6614/156230 | global iter:   6614/156230 | loss: 1.0047 | ds_loss: 1.0269 | lr: 9.9562e-05 | scale: 131072.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   6615/156230 | global iter:   6615/156230 | loss: 1.1960 | ds_loss: 1.2145 | lr: 9.9562e-05 | scale: 131072.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   6616/156230 | global iter:   6616/156230 | loss: 1.2507 | ds_loss: 1.2710 | lr: 9.9561e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6616/156230 | global iter:   6616/156230 | loss: 1.1558 | ds_loss: 1.1742 | lr: 9.9561e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6617/156230 | global iter:   6617/156230 | loss: 1.1522 | ds_loss: 1.1609 | lr: 9.9561e-05 | scale: 131072.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   6618/156230 | global iter:   6618/156230 | loss: 1.0337 | ds_loss: 1.0453 | lr: 9.9561e-05 | scale: 131072.0000 | micro time: 1.323 | step time: 0.000
[2025-04-20 21:11:30,107] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 131072, reducing to 65536
train | epoch   0 | Iter:   6619/156230 | global iter:   6619/156230 | loss: 0.8819 | ds_loss: 0.8863 | lr: 9.9561e-05 | scale: 65536.0000 | micro time: 1.315 | step time: 0.000
train | epoch   0 | Iter:   6620/156230 | global iter:   6620/156230 | loss: 0.9169 | ds_loss: 0.9263 | lr: 9.9561e-05 | scale: 65536.0000 | micro time: 1.322 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6620/156230 | global iter:   6620/156230 | loss: 0.9962 | ds_loss: 1.0047 | lr: 9.9561e-05 | scale: 65536.0000 | micro time: 1.322 | step time: 1.335
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6621/156230 | global iter:   6621/156230 | loss: 1.2069 | ds_loss: 1.2220 | lr: 9.9561e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   6622/156230 | global iter:   6622/156230 | loss: 1.0285 | ds_loss: 1.0435 | lr: 9.9561e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   6623/156230 | global iter:   6623/156230 | loss: 1.2105 | ds_loss: 1.2251 | lr: 9.9561e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   6624/156230 | global iter:   6624/156230 | loss: 1.0359 | ds_loss: 1.0498 | lr: 9.9560e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6624/156230 | global iter:   6624/156230 | loss: 1.1205 | ds_loss: 1.1351 | lr: 9.9560e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6625/156230 | global iter:   6625/156230 | loss: 1.0332 | ds_loss: 1.0531 | lr: 9.9560e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   6626/156230 | global iter:   6626/156230 | loss: 1.0277 | ds_loss: 1.0525 | lr: 9.9560e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   6627/156230 | global iter:   6627/156230 | loss: 1.0387 | ds_loss: 1.0599 | lr: 9.9560e-05 | scale: 65536.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   6628/156230 | global iter:   6628/156230 | loss: 1.1932 | ds_loss: 1.2279 | lr: 9.9560e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6628/156230 | global iter:   6628/156230 | loss: 1.0732 | ds_loss: 1.0983 | lr: 9.9560e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6629/156230 | global iter:   6629/156230 | loss: 1.2260 | ds_loss: 1.2337 | lr: 9.9560e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   6630/156230 | global iter:   6630/156230 | loss: 1.0672 | ds_loss: 1.0971 | lr: 9.9560e-05 | scale: 65536.0000 | micro time: 1.321 | step time: 0.000
train | epoch   0 | Iter:   6631/156230 | global iter:   6631/156230 | loss: 1.0130 | ds_loss: 1.0409 | lr: 9.9560e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   6632/156230 | global iter:   6632/156230 | loss: 1.0503 | ds_loss: 1.0528 | lr: 9.9559e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6632/156230 | global iter:   6632/156230 | loss: 1.0891 | ds_loss: 1.1062 | lr: 9.9559e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6633/156230 | global iter:   6633/156230 | loss: 1.2307 | ds_loss: 1.2353 | lr: 9.9559e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   6634/156230 | global iter:   6634/156230 | loss: 1.2179 | ds_loss: 1.2537 | lr: 9.9559e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   6635/156230 | global iter:   6635/156230 | loss: 0.9922 | ds_loss: 1.0127 | lr: 9.9559e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   6636/156230 | global iter:   6636/156230 | loss: 1.1668 | ds_loss: 1.1850 | lr: 9.9559e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6636/156230 | global iter:   6636/156230 | loss: 1.1519 | ds_loss: 1.1717 | lr: 9.9559e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6637/156230 | global iter:   6637/156230 | loss: 0.9865 | ds_loss: 1.0122 | lr: 9.9559e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   6638/156230 | global iter:   6638/156230 | loss: 1.2322 | ds_loss: 1.2585 | lr: 9.9559e-05 | scale: 65536.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   6639/156230 | global iter:   6639/156230 | loss: 0.9895 | ds_loss: 1.0216 | lr: 9.9558e-05 | scale: 65536.0000 | micro time: 1.400 | step time: 0.000
train | epoch   0 | Iter:   6640/156230 | global iter:   6640/156230 | loss: 1.1132 | ds_loss: 1.1428 | lr: 9.9558e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6640/156230 | global iter:   6640/156230 | loss: 1.0804 | ds_loss: 1.1088 | lr: 9.9558e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6641/156230 | global iter:   6641/156230 | loss: 0.8928 | ds_loss: 0.9110 | lr: 9.9558e-05 | scale: 65536.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   6642/156230 | global iter:   6642/156230 | loss: 1.0913 | ds_loss: 1.1165 | lr: 9.9558e-05 | scale: 65536.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   6643/156230 | global iter:   6643/156230 | loss: 1.1827 | ds_loss: 1.1769 | lr: 9.9558e-05 | scale: 65536.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   6644/156230 | global iter:   6644/156230 | loss: 0.8827 | ds_loss: 0.9007 | lr: 9.9558e-05 | scale: 65536.0000 | micro time: 1.321 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6644/156230 | global iter:   6644/156230 | loss: 1.0123 | ds_loss: 1.0263 | lr: 9.9558e-05 | scale: 65536.0000 | micro time: 1.321 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6645/156230 | global iter:   6645/156230 | loss: 1.0209 | ds_loss: 1.0412 | lr: 9.9558e-05 | scale: 65536.0000 | micro time: 1.403 | step time: 0.000
train | epoch   0 | Iter:   6646/156230 | global iter:   6646/156230 | loss: 1.0097 | ds_loss: 1.0250 | lr: 9.9558e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   6647/156230 | global iter:   6647/156230 | loss: 1.1851 | ds_loss: 1.1981 | lr: 9.9557e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   6648/156230 | global iter:   6648/156230 | loss: 1.2175 | ds_loss: 1.2404 | lr: 9.9557e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6648/156230 | global iter:   6648/156230 | loss: 1.1083 | ds_loss: 1.1262 | lr: 9.9557e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6649/156230 | global iter:   6649/156230 | loss: 1.1654 | ds_loss: 1.1833 | lr: 9.9557e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   6650/156230 | global iter:   6650/156230 | loss: 1.0995 | ds_loss: 1.1133 | lr: 9.9557e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   6651/156230 | global iter:   6651/156230 | loss: 1.2199 | ds_loss: 1.2449 | lr: 9.9557e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   6652/156230 | global iter:   6652/156230 | loss: 1.1127 | ds_loss: 1.1239 | lr: 9.9557e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6652/156230 | global iter:   6652/156230 | loss: 1.1494 | ds_loss: 1.1663 | lr: 9.9557e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6653/156230 | global iter:   6653/156230 | loss: 1.1612 | ds_loss: 1.1703 | lr: 9.9557e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   6654/156230 | global iter:   6654/156230 | loss: 1.0371 | ds_loss: 1.0355 | lr: 9.9556e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   6655/156230 | global iter:   6655/156230 | loss: 1.1150 | ds_loss: 1.1299 | lr: 9.9556e-05 | scale: 65536.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   6656/156230 | global iter:   6656/156230 | loss: 1.0510 | ds_loss: 1.0582 | lr: 9.9556e-05 | scale: 65536.0000 | micro time: 1.391 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6656/156230 | global iter:   6656/156230 | loss: 1.0911 | ds_loss: 1.0985 | lr: 9.9556e-05 | scale: 65536.0000 | micro time: 1.391 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6657/156230 | global iter:   6657/156230 | loss: 1.1201 | ds_loss: 1.1193 | lr: 9.9556e-05 | scale: 65536.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   6658/156230 | global iter:   6658/156230 | loss: 1.0192 | ds_loss: 1.0417 | lr: 9.9556e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   6659/156230 | global iter:   6659/156230 | loss: 0.9083 | ds_loss: 0.9146 | lr: 9.9556e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   6660/156230 | global iter:   6660/156230 | loss: 1.2237 | ds_loss: 1.2365 | lr: 9.9556e-05 | scale: 65536.0000 | micro time: 1.329 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6660/156230 | global iter:   6660/156230 | loss: 1.0679 | ds_loss: 1.0780 | lr: 9.9556e-05 | scale: 65536.0000 | micro time: 1.329 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6661/156230 | global iter:   6661/156230 | loss: 1.1160 | ds_loss: 1.1529 | lr: 9.9556e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   6662/156230 | global iter:   6662/156230 | loss: 0.9970 | ds_loss: 1.0160 | lr: 9.9555e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   6663/156230 | global iter:   6663/156230 | loss: 1.1608 | ds_loss: 1.1745 | lr: 9.9555e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   6664/156230 | global iter:   6664/156230 | loss: 1.1071 | ds_loss: 1.1288 | lr: 9.9555e-05 | scale: 65536.0000 | micro time: 1.386 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6664/156230 | global iter:   6664/156230 | loss: 1.0953 | ds_loss: 1.1181 | lr: 9.9555e-05 | scale: 65536.0000 | micro time: 1.386 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6665/156230 | global iter:   6665/156230 | loss: 1.1222 | ds_loss: 1.1427 | lr: 9.9555e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   6666/156230 | global iter:   6666/156230 | loss: 1.0265 | ds_loss: 1.0536 | lr: 9.9555e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   6667/156230 | global iter:   6667/156230 | loss: 1.2544 | ds_loss: 1.2610 | lr: 9.9555e-05 | scale: 65536.0000 | micro time: 1.408 | step time: 0.000
train | epoch   0 | Iter:   6668/156230 | global iter:   6668/156230 | loss: 1.1838 | ds_loss: 1.1992 | lr: 9.9555e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6668/156230 | global iter:   6668/156230 | loss: 1.1467 | ds_loss: 1.1641 | lr: 9.9555e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6669/156230 | global iter:   6669/156230 | loss: 1.2488 | ds_loss: 1.2884 | lr: 9.9554e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   6670/156230 | global iter:   6670/156230 | loss: 0.8083 | ds_loss: 0.8211 | lr: 9.9554e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   6671/156230 | global iter:   6671/156230 | loss: 0.9276 | ds_loss: 0.9321 | lr: 9.9554e-05 | scale: 65536.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   6672/156230 | global iter:   6672/156230 | loss: 1.0012 | ds_loss: 1.0016 | lr: 9.9554e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6672/156230 | global iter:   6672/156230 | loss: 0.9965 | ds_loss: 1.0108 | lr: 9.9554e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6673/156230 | global iter:   6673/156230 | loss: 1.2567 | ds_loss: 1.2808 | lr: 9.9554e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   6674/156230 | global iter:   6674/156230 | loss: 1.2318 | ds_loss: 1.2766 | lr: 9.9554e-05 | scale: 65536.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   6675/156230 | global iter:   6675/156230 | loss: 1.0885 | ds_loss: 1.1104 | lr: 9.9554e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   6676/156230 | global iter:   6676/156230 | loss: 1.1165 | ds_loss: 1.1414 | lr: 9.9554e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6676/156230 | global iter:   6676/156230 | loss: 1.1734 | ds_loss: 1.2023 | lr: 9.9554e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6677/156230 | global iter:   6677/156230 | loss: 1.2483 | ds_loss: 1.2731 | lr: 9.9553e-05 | scale: 65536.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   6678/156230 | global iter:   6678/156230 | loss: 1.1193 | ds_loss: 1.1476 | lr: 9.9553e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   6679/156230 | global iter:   6679/156230 | loss: 1.0086 | ds_loss: 1.0275 | lr: 9.9553e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   6680/156230 | global iter:   6680/156230 | loss: 1.2701 | ds_loss: 1.3005 | lr: 9.9553e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6680/156230 | global iter:   6680/156230 | loss: 1.1616 | ds_loss: 1.1872 | lr: 9.9553e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6681/156230 | global iter:   6681/156230 | loss: 1.1267 | ds_loss: 1.1360 | lr: 9.9553e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   6682/156230 | global iter:   6682/156230 | loss: 1.1052 | ds_loss: 1.1292 | lr: 9.9553e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   6683/156230 | global iter:   6683/156230 | loss: 0.9450 | ds_loss: 0.9708 | lr: 9.9553e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   6684/156230 | global iter:   6684/156230 | loss: 1.1159 | ds_loss: 1.1463 | lr: 9.9552e-05 | scale: 65536.0000 | micro time: 1.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6684/156230 | global iter:   6684/156230 | loss: 1.0732 | ds_loss: 1.0956 | lr: 9.9552e-05 | scale: 65536.0000 | micro time: 1.394 | step time: 1.383
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6685/156230 | global iter:   6685/156230 | loss: 1.0252 | ds_loss: 1.0499 | lr: 9.9552e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   6686/156230 | global iter:   6686/156230 | loss: 1.3212 | ds_loss: 1.3486 | lr: 9.9552e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   6687/156230 | global iter:   6687/156230 | loss: 1.0219 | ds_loss: 1.0381 | lr: 9.9552e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   6688/156230 | global iter:   6688/156230 | loss: 1.0529 | ds_loss: 1.0742 | lr: 9.9552e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6688/156230 | global iter:   6688/156230 | loss: 1.1053 | ds_loss: 1.1277 | lr: 9.9552e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6689/156230 | global iter:   6689/156230 | loss: 1.0019 | ds_loss: 1.0204 | lr: 9.9552e-05 | scale: 65536.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   6690/156230 | global iter:   6690/156230 | loss: 1.1235 | ds_loss: 1.1354 | lr: 9.9552e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   6691/156230 | global iter:   6691/156230 | loss: 1.2301 | ds_loss: 1.2436 | lr: 9.9552e-05 | scale: 65536.0000 | micro time: 1.309 | step time: 0.000
train | epoch   0 | Iter:   6692/156230 | global iter:   6692/156230 | loss: 1.2571 | ds_loss: 1.2680 | lr: 9.9551e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6692/156230 | global iter:   6692/156230 | loss: 1.1531 | ds_loss: 1.1669 | lr: 9.9551e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 1.340
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6693/156230 | global iter:   6693/156230 | loss: 1.0466 | ds_loss: 1.0637 | lr: 9.9551e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   6694/156230 | global iter:   6694/156230 | loss: 1.0151 | ds_loss: 1.0452 | lr: 9.9551e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   6695/156230 | global iter:   6695/156230 | loss: 1.1306 | ds_loss: 1.1376 | lr: 9.9551e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   6696/156230 | global iter:   6696/156230 | loss: 1.0059 | ds_loss: 1.0297 | lr: 9.9551e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6696/156230 | global iter:   6696/156230 | loss: 1.0495 | ds_loss: 1.0691 | lr: 9.9551e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 1.376
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6697/156230 | global iter:   6697/156230 | loss: 1.2233 | ds_loss: 1.2294 | lr: 9.9551e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   6698/156230 | global iter:   6698/156230 | loss: 1.1136 | ds_loss: 1.1323 | lr: 9.9551e-05 | scale: 65536.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   6699/156230 | global iter:   6699/156230 | loss: 1.1559 | ds_loss: 1.1649 | lr: 9.9550e-05 | scale: 65536.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   6700/156230 | global iter:   6700/156230 | loss: 1.1838 | ds_loss: 1.1932 | lr: 9.9550e-05 | scale: 65536.0000 | micro time: 1.316 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6700/156230 | global iter:   6700/156230 | loss: 1.1691 | ds_loss: 1.1799 | lr: 9.9550e-05 | scale: 65536.0000 | micro time: 1.316 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6701/156230 | global iter:   6701/156230 | loss: 1.0538 | ds_loss: 1.0815 | lr: 9.9550e-05 | scale: 65536.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   6702/156230 | global iter:   6702/156230 | loss: 1.1111 | ds_loss: 1.1255 | lr: 9.9550e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   6703/156230 | global iter:   6703/156230 | loss: 1.0318 | ds_loss: 1.0493 | lr: 9.9550e-05 | scale: 65536.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   6704/156230 | global iter:   6704/156230 | loss: 1.0708 | ds_loss: 1.0930 | lr: 9.9550e-05 | scale: 65536.0000 | micro time: 1.324 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6704/156230 | global iter:   6704/156230 | loss: 1.0669 | ds_loss: 1.0873 | lr: 9.9550e-05 | scale: 65536.0000 | micro time: 1.324 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6705/156230 | global iter:   6705/156230 | loss: 1.1098 | ds_loss: 1.1181 | lr: 9.9550e-05 | scale: 65536.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   6706/156230 | global iter:   6706/156230 | loss: 1.1750 | ds_loss: 1.1989 | lr: 9.9549e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   6707/156230 | global iter:   6707/156230 | loss: 1.1477 | ds_loss: 1.1615 | lr: 9.9549e-05 | scale: 65536.0000 | micro time: 1.401 | step time: 0.000
train | epoch   0 | Iter:   6708/156230 | global iter:   6708/156230 | loss: 1.1773 | ds_loss: 1.1743 | lr: 9.9549e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6708/156230 | global iter:   6708/156230 | loss: 1.1524 | ds_loss: 1.1632 | lr: 9.9549e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 1.380
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6709/156230 | global iter:   6709/156230 | loss: 0.8643 | ds_loss: 0.8897 | lr: 9.9549e-05 | scale: 65536.0000 | micro time: 1.313 | step time: 0.000
train | epoch   0 | Iter:   6710/156230 | global iter:   6710/156230 | loss: 0.9257 | ds_loss: 0.9478 | lr: 9.9549e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   6711/156230 | global iter:   6711/156230 | loss: 1.1056 | ds_loss: 1.1203 | lr: 9.9549e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   6712/156230 | global iter:   6712/156230 | loss: 1.2146 | ds_loss: 1.2410 | lr: 9.9549e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6712/156230 | global iter:   6712/156230 | loss: 1.0275 | ds_loss: 1.0497 | lr: 9.9549e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6713/156230 | global iter:   6713/156230 | loss: 1.1445 | ds_loss: 1.1725 | lr: 9.9549e-05 | scale: 65536.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   6714/156230 | global iter:   6714/156230 | loss: 0.8825 | ds_loss: 0.8983 | lr: 9.9548e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   6715/156230 | global iter:   6715/156230 | loss: 0.9902 | ds_loss: 0.9992 | lr: 9.9548e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   6716/156230 | global iter:   6716/156230 | loss: 1.1857 | ds_loss: 1.2056 | lr: 9.9548e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6716/156230 | global iter:   6716/156230 | loss: 1.0507 | ds_loss: 1.0689 | lr: 9.9548e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6717/156230 | global iter:   6717/156230 | loss: 1.2171 | ds_loss: 1.2418 | lr: 9.9548e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   6718/156230 | global iter:   6718/156230 | loss: 1.0424 | ds_loss: 1.0687 | lr: 9.9548e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   6719/156230 | global iter:   6719/156230 | loss: 1.1452 | ds_loss: 1.1531 | lr: 9.9548e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   6720/156230 | global iter:   6720/156230 | loss: 1.1827 | ds_loss: 1.2150 | lr: 9.9548e-05 | scale: 65536.0000 | micro time: 1.406 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6720/156230 | global iter:   6720/156230 | loss: 1.1469 | ds_loss: 1.1697 | lr: 9.9548e-05 | scale: 65536.0000 | micro time: 1.406 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6721/156230 | global iter:   6721/156230 | loss: 1.0157 | ds_loss: 1.0331 | lr: 9.9547e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   6722/156230 | global iter:   6722/156230 | loss: 1.1609 | ds_loss: 1.1542 | lr: 9.9547e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   6723/156230 | global iter:   6723/156230 | loss: 0.9865 | ds_loss: 1.0217 | lr: 9.9547e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   6724/156230 | global iter:   6724/156230 | loss: 0.9796 | ds_loss: 1.0065 | lr: 9.9547e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6724/156230 | global iter:   6724/156230 | loss: 1.0357 | ds_loss: 1.0539 | lr: 9.9547e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6725/156230 | global iter:   6725/156230 | loss: 0.9719 | ds_loss: 0.9824 | lr: 9.9547e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   6726/156230 | global iter:   6726/156230 | loss: 1.1059 | ds_loss: 1.1205 | lr: 9.9547e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   6727/156230 | global iter:   6727/156230 | loss: 1.0550 | ds_loss: 1.0743 | lr: 9.9547e-05 | scale: 65536.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   6728/156230 | global iter:   6728/156230 | loss: 1.2291 | ds_loss: 1.2428 | lr: 9.9547e-05 | scale: 65536.0000 | micro time: 1.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6728/156230 | global iter:   6728/156230 | loss: 1.0905 | ds_loss: 1.1050 | lr: 9.9547e-05 | scale: 65536.0000 | micro time: 1.400 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6729/156230 | global iter:   6729/156230 | loss: 1.2299 | ds_loss: 1.2415 | lr: 9.9546e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   6730/156230 | global iter:   6730/156230 | loss: 1.0603 | ds_loss: 1.0745 | lr: 9.9546e-05 | scale: 65536.0000 | micro time: 1.315 | step time: 0.000
train | epoch   0 | Iter:   6731/156230 | global iter:   6731/156230 | loss: 1.2881 | ds_loss: 1.2916 | lr: 9.9546e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   6732/156230 | global iter:   6732/156230 | loss: 1.0762 | ds_loss: 1.0993 | lr: 9.9546e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6732/156230 | global iter:   6732/156230 | loss: 1.1636 | ds_loss: 1.1767 | lr: 9.9546e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 1.345
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6733/156230 | global iter:   6733/156230 | loss: 1.2186 | ds_loss: 1.2252 | lr: 9.9546e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   6734/156230 | global iter:   6734/156230 | loss: 0.9068 | ds_loss: 0.9214 | lr: 9.9546e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   6735/156230 | global iter:   6735/156230 | loss: 1.0858 | ds_loss: 1.1071 | lr: 9.9546e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   6736/156230 | global iter:   6736/156230 | loss: 1.1510 | ds_loss: 1.1773 | lr: 9.9545e-05 | scale: 65536.0000 | micro time: 1.400 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6736/156230 | global iter:   6736/156230 | loss: 1.0905 | ds_loss: 1.1078 | lr: 9.9545e-05 | scale: 65536.0000 | micro time: 1.400 | step time: 1.382
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6737/156230 | global iter:   6737/156230 | loss: 1.1034 | ds_loss: 1.1196 | lr: 9.9545e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   6738/156230 | global iter:   6738/156230 | loss: 0.9231 | ds_loss: 0.9369 | lr: 9.9545e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   6739/156230 | global iter:   6739/156230 | loss: 0.9913 | ds_loss: 1.0082 | lr: 9.9545e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   6740/156230 | global iter:   6740/156230 | loss: 1.1345 | ds_loss: 1.1578 | lr: 9.9545e-05 | scale: 65536.0000 | micro time: 1.309 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6740/156230 | global iter:   6740/156230 | loss: 1.0381 | ds_loss: 1.0556 | lr: 9.9545e-05 | scale: 65536.0000 | micro time: 1.309 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6741/156230 | global iter:   6741/156230 | loss: 1.1378 | ds_loss: 1.1706 | lr: 9.9545e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   6742/156230 | global iter:   6742/156230 | loss: 1.0030 | ds_loss: 1.0182 | lr: 9.9545e-05 | scale: 65536.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   6743/156230 | global iter:   6743/156230 | loss: 1.0699 | ds_loss: 1.0906 | lr: 9.9545e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   6744/156230 | global iter:   6744/156230 | loss: 1.2239 | ds_loss: 1.2460 | lr: 9.9544e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6744/156230 | global iter:   6744/156230 | loss: 1.1086 | ds_loss: 1.1313 | lr: 9.9544e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6745/156230 | global iter:   6745/156230 | loss: 0.9570 | ds_loss: 0.9743 | lr: 9.9544e-05 | scale: 65536.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   6746/156230 | global iter:   6746/156230 | loss: 1.2074 | ds_loss: 1.2240 | lr: 9.9544e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   6747/156230 | global iter:   6747/156230 | loss: 0.9250 | ds_loss: 0.9450 | lr: 9.9544e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   6748/156230 | global iter:   6748/156230 | loss: 1.0921 | ds_loss: 1.1062 | lr: 9.9544e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6748/156230 | global iter:   6748/156230 | loss: 1.0454 | ds_loss: 1.0624 | lr: 9.9544e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6749/156230 | global iter:   6749/156230 | loss: 1.1938 | ds_loss: 1.2051 | lr: 9.9544e-05 | scale: 65536.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   6750/156230 | global iter:   6750/156230 | loss: 0.9917 | ds_loss: 1.0170 | lr: 9.9544e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   6751/156230 | global iter:   6751/156230 | loss: 0.9947 | ds_loss: 0.9937 | lr: 9.9543e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   6752/156230 | global iter:   6752/156230 | loss: 1.1865 | ds_loss: 1.2137 | lr: 9.9543e-05 | scale: 65536.0000 | micro time: 1.332 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6752/156230 | global iter:   6752/156230 | loss: 1.0917 | ds_loss: 1.1074 | lr: 9.9543e-05 | scale: 65536.0000 | micro time: 1.332 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6753/156230 | global iter:   6753/156230 | loss: 1.0222 | ds_loss: 1.0293 | lr: 9.9543e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   6754/156230 | global iter:   6754/156230 | loss: 0.9350 | ds_loss: 0.9638 | lr: 9.9543e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   6755/156230 | global iter:   6755/156230 | loss: 1.0334 | ds_loss: 1.0635 | lr: 9.9543e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   6756/156230 | global iter:   6756/156230 | loss: 1.1302 | ds_loss: 1.1486 | lr: 9.9543e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6756/156230 | global iter:   6756/156230 | loss: 1.0302 | ds_loss: 1.0513 | lr: 9.9543e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6757/156230 | global iter:   6757/156230 | loss: 1.0260 | ds_loss: 1.0427 | lr: 9.9543e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   6758/156230 | global iter:   6758/156230 | loss: 0.8153 | ds_loss: 0.8215 | lr: 9.9542e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   6759/156230 | global iter:   6759/156230 | loss: 1.2501 | ds_loss: 1.2802 | lr: 9.9542e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   6760/156230 | global iter:   6760/156230 | loss: 1.0938 | ds_loss: 1.1201 | lr: 9.9542e-05 | scale: 65536.0000 | micro time: 1.329 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6760/156230 | global iter:   6760/156230 | loss: 1.0463 | ds_loss: 1.0661 | lr: 9.9542e-05 | scale: 65536.0000 | micro time: 1.329 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6761/156230 | global iter:   6761/156230 | loss: 1.1107 | ds_loss: 1.1372 | lr: 9.9542e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   6762/156230 | global iter:   6762/156230 | loss: 0.9982 | ds_loss: 1.0125 | lr: 9.9542e-05 | scale: 65536.0000 | micro time: 1.400 | step time: 0.000
train | epoch   0 | Iter:   6763/156230 | global iter:   6763/156230 | loss: 1.0334 | ds_loss: 1.0593 | lr: 9.9542e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   6764/156230 | global iter:   6764/156230 | loss: 1.1859 | ds_loss: 1.2122 | lr: 9.9542e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6764/156230 | global iter:   6764/156230 | loss: 1.0820 | ds_loss: 1.1053 | lr: 9.9542e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 1.381
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6765/156230 | global iter:   6765/156230 | loss: 1.0523 | ds_loss: 1.0565 | lr: 9.9542e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   6766/156230 | global iter:   6766/156230 | loss: 1.2044 | ds_loss: 1.2256 | lr: 9.9541e-05 | scale: 65536.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   6767/156230 | global iter:   6767/156230 | loss: 1.0843 | ds_loss: 1.0962 | lr: 9.9541e-05 | scale: 65536.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   6768/156230 | global iter:   6768/156230 | loss: 1.0369 | ds_loss: 1.0713 | lr: 9.9541e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6768/156230 | global iter:   6768/156230 | loss: 1.0945 | ds_loss: 1.1124 | lr: 9.9541e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6769/156230 | global iter:   6769/156230 | loss: 1.1786 | ds_loss: 1.1952 | lr: 9.9541e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   6770/156230 | global iter:   6770/156230 | loss: 1.0838 | ds_loss: 1.0926 | lr: 9.9541e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   6771/156230 | global iter:   6771/156230 | loss: 0.8523 | ds_loss: 0.8747 | lr: 9.9541e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   6772/156230 | global iter:   6772/156230 | loss: 1.0760 | ds_loss: 1.1009 | lr: 9.9541e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6772/156230 | global iter:   6772/156230 | loss: 1.0477 | ds_loss: 1.0658 | lr: 9.9541e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6773/156230 | global iter:   6773/156230 | loss: 1.2575 | ds_loss: 1.2848 | lr: 9.9540e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   6774/156230 | global iter:   6774/156230 | loss: 1.0161 | ds_loss: 1.0470 | lr: 9.9540e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   6775/156230 | global iter:   6775/156230 | loss: 0.9378 | ds_loss: 0.9595 | lr: 9.9540e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   6776/156230 | global iter:   6776/156230 | loss: 1.0340 | ds_loss: 1.0451 | lr: 9.9540e-05 | scale: 65536.0000 | micro time: 1.339 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6776/156230 | global iter:   6776/156230 | loss: 1.0614 | ds_loss: 1.0841 | lr: 9.9540e-05 | scale: 65536.0000 | micro time: 1.339 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6777/156230 | global iter:   6777/156230 | loss: 1.2682 | ds_loss: 1.3162 | lr: 9.9540e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   6778/156230 | global iter:   6778/156230 | loss: 1.1021 | ds_loss: 1.1036 | lr: 9.9540e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   6779/156230 | global iter:   6779/156230 | loss: 1.0048 | ds_loss: 1.0261 | lr: 9.9540e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   6780/156230 | global iter:   6780/156230 | loss: 1.2741 | ds_loss: 1.2781 | lr: 9.9539e-05 | scale: 65536.0000 | micro time: 1.314 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6780/156230 | global iter:   6780/156230 | loss: 1.1623 | ds_loss: 1.1810 | lr: 9.9539e-05 | scale: 65536.0000 | micro time: 1.314 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6781/156230 | global iter:   6781/156230 | loss: 0.8791 | ds_loss: 0.9030 | lr: 9.9539e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   6782/156230 | global iter:   6782/156230 | loss: 1.1876 | ds_loss: 1.2121 | lr: 9.9539e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   6783/156230 | global iter:   6783/156230 | loss: 1.2248 | ds_loss: 1.2479 | lr: 9.9539e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   6784/156230 | global iter:   6784/156230 | loss: 1.2019 | ds_loss: 1.2173 | lr: 9.9539e-05 | scale: 65536.0000 | micro time: 1.401 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6784/156230 | global iter:   6784/156230 | loss: 1.1234 | ds_loss: 1.1451 | lr: 9.9539e-05 | scale: 65536.0000 | micro time: 1.401 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6785/156230 | global iter:   6785/156230 | loss: 1.0154 | ds_loss: 1.0395 | lr: 9.9539e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   6786/156230 | global iter:   6786/156230 | loss: 1.1308 | ds_loss: 1.1600 | lr: 9.9539e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   6787/156230 | global iter:   6787/156230 | loss: 1.0153 | ds_loss: 1.0546 | lr: 9.9539e-05 | scale: 65536.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   6788/156230 | global iter:   6788/156230 | loss: 1.1360 | ds_loss: 1.1507 | lr: 9.9538e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6788/156230 | global iter:   6788/156230 | loss: 1.0744 | ds_loss: 1.1012 | lr: 9.9538e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6789/156230 | global iter:   6789/156230 | loss: 1.1392 | ds_loss: 1.1522 | lr: 9.9538e-05 | scale: 65536.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   6790/156230 | global iter:   6790/156230 | loss: 1.2003 | ds_loss: 1.2203 | lr: 9.9538e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   6791/156230 | global iter:   6791/156230 | loss: 0.9828 | ds_loss: 1.0047 | lr: 9.9538e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   6792/156230 | global iter:   6792/156230 | loss: 1.1390 | ds_loss: 1.1698 | lr: 9.9538e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6792/156230 | global iter:   6792/156230 | loss: 1.1153 | ds_loss: 1.1367 | lr: 9.9538e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6793/156230 | global iter:   6793/156230 | loss: 1.1607 | ds_loss: 1.1744 | lr: 9.9538e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   6794/156230 | global iter:   6794/156230 | loss: 1.2589 | ds_loss: 1.2787 | lr: 9.9538e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   6795/156230 | global iter:   6795/156230 | loss: 1.0913 | ds_loss: 1.1218 | lr: 9.9537e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   6796/156230 | global iter:   6796/156230 | loss: 1.2412 | ds_loss: 1.2607 | lr: 9.9537e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6796/156230 | global iter:   6796/156230 | loss: 1.1880 | ds_loss: 1.2089 | lr: 9.9537e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6797/156230 | global iter:   6797/156230 | loss: 1.1829 | ds_loss: 1.2002 | lr: 9.9537e-05 | scale: 65536.0000 | micro time: 1.312 | step time: 0.000
train | epoch   0 | Iter:   6798/156230 | global iter:   6798/156230 | loss: 1.0192 | ds_loss: 1.0449 | lr: 9.9537e-05 | scale: 65536.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   6799/156230 | global iter:   6799/156230 | loss: 1.0761 | ds_loss: 1.0879 | lr: 9.9537e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   6800/156230 | global iter:   6800/156230 | loss: 1.4169 | ds_loss: 1.4553 | lr: 9.9537e-05 | scale: 65536.0000 | micro time: 1.319 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6800/156230 | global iter:   6800/156230 | loss: 1.1738 | ds_loss: 1.1971 | lr: 9.9537e-05 | scale: 65536.0000 | micro time: 1.319 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6801/156230 | global iter:   6801/156230 | loss: 1.0284 | ds_loss: 1.0345 | lr: 9.9537e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   6802/156230 | global iter:   6802/156230 | loss: 1.2365 | ds_loss: 1.2741 | lr: 9.9536e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   6803/156230 | global iter:   6803/156230 | loss: 1.1371 | ds_loss: 1.1653 | lr: 9.9536e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   6804/156230 | global iter:   6804/156230 | loss: 1.2005 | ds_loss: 1.2249 | lr: 9.9536e-05 | scale: 65536.0000 | micro time: 1.421 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6804/156230 | global iter:   6804/156230 | loss: 1.1506 | ds_loss: 1.1747 | lr: 9.9536e-05 | scale: 65536.0000 | micro time: 1.421 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6805/156230 | global iter:   6805/156230 | loss: 0.9628 | ds_loss: 0.9851 | lr: 9.9536e-05 | scale: 65536.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   6806/156230 | global iter:   6806/156230 | loss: 1.1228 | ds_loss: 1.1475 | lr: 9.9536e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   6807/156230 | global iter:   6807/156230 | loss: 1.1281 | ds_loss: 1.1518 | lr: 9.9536e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   6808/156230 | global iter:   6808/156230 | loss: 1.0873 | ds_loss: 1.1104 | lr: 9.9536e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6808/156230 | global iter:   6808/156230 | loss: 1.0753 | ds_loss: 1.0987 | lr: 9.9536e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6809/156230 | global iter:   6809/156230 | loss: 1.2340 | ds_loss: 1.2684 | lr: 9.9536e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   6810/156230 | global iter:   6810/156230 | loss: 1.3214 | ds_loss: 1.3319 | lr: 9.9535e-05 | scale: 65536.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   6811/156230 | global iter:   6811/156230 | loss: 1.1650 | ds_loss: 1.1760 | lr: 9.9535e-05 | scale: 65536.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   6812/156230 | global iter:   6812/156230 | loss: 1.0857 | ds_loss: 1.1004 | lr: 9.9535e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6812/156230 | global iter:   6812/156230 | loss: 1.2015 | ds_loss: 1.2192 | lr: 9.9535e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6813/156230 | global iter:   6813/156230 | loss: 1.0355 | ds_loss: 1.0668 | lr: 9.9535e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   6814/156230 | global iter:   6814/156230 | loss: 0.9611 | ds_loss: 0.9908 | lr: 9.9535e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   6815/156230 | global iter:   6815/156230 | loss: 1.1903 | ds_loss: 1.2114 | lr: 9.9535e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   6816/156230 | global iter:   6816/156230 | loss: 1.2499 | ds_loss: 1.2505 | lr: 9.9535e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6816/156230 | global iter:   6816/156230 | loss: 1.1092 | ds_loss: 1.1299 | lr: 9.9535e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6817/156230 | global iter:   6817/156230 | loss: 1.2095 | ds_loss: 1.2319 | lr: 9.9534e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   6818/156230 | global iter:   6818/156230 | loss: 1.0640 | ds_loss: 1.0741 | lr: 9.9534e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   6819/156230 | global iter:   6819/156230 | loss: 1.1052 | ds_loss: 1.1216 | lr: 9.9534e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   6820/156230 | global iter:   6820/156230 | loss: 1.0338 | ds_loss: 1.0475 | lr: 9.9534e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6820/156230 | global iter:   6820/156230 | loss: 1.1031 | ds_loss: 1.1188 | lr: 9.9534e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6821/156230 | global iter:   6821/156230 | loss: 0.9752 | ds_loss: 0.9994 | lr: 9.9534e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   6822/156230 | global iter:   6822/156230 | loss: 1.1842 | ds_loss: 1.2053 | lr: 9.9534e-05 | scale: 65536.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   6823/156230 | global iter:   6823/156230 | loss: 1.2784 | ds_loss: 1.2904 | lr: 9.9534e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   6824/156230 | global iter:   6824/156230 | loss: 1.1088 | ds_loss: 1.1266 | lr: 9.9533e-05 | scale: 65536.0000 | micro time: 1.316 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6824/156230 | global iter:   6824/156230 | loss: 1.1367 | ds_loss: 1.1554 | lr: 9.9533e-05 | scale: 65536.0000 | micro time: 1.316 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6825/156230 | global iter:   6825/156230 | loss: 1.2167 | ds_loss: 1.2249 | lr: 9.9533e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   6826/156230 | global iter:   6826/156230 | loss: 1.0684 | ds_loss: 1.0849 | lr: 9.9533e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   6827/156230 | global iter:   6827/156230 | loss: 0.9273 | ds_loss: 0.9595 | lr: 9.9533e-05 | scale: 65536.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   6828/156230 | global iter:   6828/156230 | loss: 1.0391 | ds_loss: 1.0549 | lr: 9.9533e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6828/156230 | global iter:   6828/156230 | loss: 1.0629 | ds_loss: 1.0811 | lr: 9.9533e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6829/156230 | global iter:   6829/156230 | loss: 1.1203 | ds_loss: 1.1256 | lr: 9.9533e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   6830/156230 | global iter:   6830/156230 | loss: 1.0369 | ds_loss: 1.0532 | lr: 9.9533e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   6831/156230 | global iter:   6831/156230 | loss: 0.9623 | ds_loss: 0.9835 | lr: 9.9533e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   6832/156230 | global iter:   6832/156230 | loss: 1.0995 | ds_loss: 1.1130 | lr: 9.9532e-05 | scale: 65536.0000 | micro time: 1.307 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6832/156230 | global iter:   6832/156230 | loss: 1.0547 | ds_loss: 1.0688 | lr: 9.9532e-05 | scale: 65536.0000 | micro time: 1.307 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6833/156230 | global iter:   6833/156230 | loss: 0.8770 | ds_loss: 0.8856 | lr: 9.9532e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   6834/156230 | global iter:   6834/156230 | loss: 1.0293 | ds_loss: 1.0539 | lr: 9.9532e-05 | scale: 65536.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   6835/156230 | global iter:   6835/156230 | loss: 1.2243 | ds_loss: 1.2496 | lr: 9.9532e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   6836/156230 | global iter:   6836/156230 | loss: 1.1090 | ds_loss: 1.1149 | lr: 9.9532e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6836/156230 | global iter:   6836/156230 | loss: 1.0599 | ds_loss: 1.0760 | lr: 9.9532e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 1.381
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6837/156230 | global iter:   6837/156230 | loss: 0.9908 | ds_loss: 0.9855 | lr: 9.9532e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   6838/156230 | global iter:   6838/156230 | loss: 1.1554 | ds_loss: 1.1800 | lr: 9.9532e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   6839/156230 | global iter:   6839/156230 | loss: 0.9116 | ds_loss: 0.9314 | lr: 9.9531e-05 | scale: 65536.0000 | micro time: 1.309 | step time: 0.000
train | epoch   0 | Iter:   6840/156230 | global iter:   6840/156230 | loss: 1.2280 | ds_loss: 1.2421 | lr: 9.9531e-05 | scale: 65536.0000 | micro time: 1.391 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6840/156230 | global iter:   6840/156230 | loss: 1.0715 | ds_loss: 1.0848 | lr: 9.9531e-05 | scale: 65536.0000 | micro time: 1.391 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6841/156230 | global iter:   6841/156230 | loss: 0.9752 | ds_loss: 0.9900 | lr: 9.9531e-05 | scale: 65536.0000 | micro time: 1.321 | step time: 0.000
train | epoch   0 | Iter:   6842/156230 | global iter:   6842/156230 | loss: 1.0705 | ds_loss: 1.1007 | lr: 9.9531e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   6843/156230 | global iter:   6843/156230 | loss: 0.9836 | ds_loss: 0.9890 | lr: 9.9531e-05 | scale: 65536.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   6844/156230 | global iter:   6844/156230 | loss: 1.0769 | ds_loss: 1.0783 | lr: 9.9531e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6844/156230 | global iter:   6844/156230 | loss: 1.0266 | ds_loss: 1.0395 | lr: 9.9531e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6845/156230 | global iter:   6845/156230 | loss: 1.0263 | ds_loss: 1.0598 | lr: 9.9531e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   6846/156230 | global iter:   6846/156230 | loss: 0.9573 | ds_loss: 0.9712 | lr: 9.9530e-05 | scale: 65536.0000 | micro time: 1.322 | step time: 0.000
train | epoch   0 | Iter:   6847/156230 | global iter:   6847/156230 | loss: 1.0812 | ds_loss: 1.1026 | lr: 9.9530e-05 | scale: 65536.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:   6848/156230 | global iter:   6848/156230 | loss: 1.0934 | ds_loss: 1.1315 | lr: 9.9530e-05 | scale: 65536.0000 | micro time: 1.409 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6848/156230 | global iter:   6848/156230 | loss: 1.0395 | ds_loss: 1.0663 | lr: 9.9530e-05 | scale: 65536.0000 | micro time: 1.409 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6849/156230 | global iter:   6849/156230 | loss: 1.0132 | ds_loss: 1.0362 | lr: 9.9530e-05 | scale: 65536.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   6850/156230 | global iter:   6850/156230 | loss: 1.0436 | ds_loss: 1.0726 | lr: 9.9530e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   6851/156230 | global iter:   6851/156230 | loss: 0.9966 | ds_loss: 1.0029 | lr: 9.9530e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   6852/156230 | global iter:   6852/156230 | loss: 1.3072 | ds_loss: 1.3296 | lr: 9.9530e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6852/156230 | global iter:   6852/156230 | loss: 1.0901 | ds_loss: 1.1103 | lr: 9.9530e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 1.346
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6853/156230 | global iter:   6853/156230 | loss: 1.2276 | ds_loss: 1.2417 | lr: 9.9529e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   6854/156230 | global iter:   6854/156230 | loss: 0.9525 | ds_loss: 0.9575 | lr: 9.9529e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   6855/156230 | global iter:   6855/156230 | loss: 1.0577 | ds_loss: 1.0655 | lr: 9.9529e-05 | scale: 65536.0000 | micro time: 1.401 | step time: 0.000
train | epoch   0 | Iter:   6856/156230 | global iter:   6856/156230 | loss: 1.0405 | ds_loss: 1.0514 | lr: 9.9529e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6856/156230 | global iter:   6856/156230 | loss: 1.0696 | ds_loss: 1.0790 | lr: 9.9529e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6857/156230 | global iter:   6857/156230 | loss: 0.9346 | ds_loss: 0.9694 | lr: 9.9529e-05 | scale: 65536.0000 | micro time: 1.320 | step time: 0.000
train | epoch   0 | Iter:   6858/156230 | global iter:   6858/156230 | loss: 1.1058 | ds_loss: 1.1326 | lr: 9.9529e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   6859/156230 | global iter:   6859/156230 | loss: 1.0980 | ds_loss: 1.1209 | lr: 9.9529e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   6860/156230 | global iter:   6860/156230 | loss: 1.0751 | ds_loss: 1.0902 | lr: 9.9529e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6860/156230 | global iter:   6860/156230 | loss: 1.0534 | ds_loss: 1.0783 | lr: 9.9529e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6861/156230 | global iter:   6861/156230 | loss: 1.1542 | ds_loss: 1.1772 | lr: 9.9528e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   6862/156230 | global iter:   6862/156230 | loss: 1.1741 | ds_loss: 1.1882 | lr: 9.9528e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   6863/156230 | global iter:   6863/156230 | loss: 1.1041 | ds_loss: 1.1135 | lr: 9.9528e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   6864/156230 | global iter:   6864/156230 | loss: 1.1168 | ds_loss: 1.1416 | lr: 9.9528e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6864/156230 | global iter:   6864/156230 | loss: 1.1373 | ds_loss: 1.1551 | lr: 9.9528e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6865/156230 | global iter:   6865/156230 | loss: 1.1988 | ds_loss: 1.2376 | lr: 9.9528e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   6866/156230 | global iter:   6866/156230 | loss: 1.1360 | ds_loss: 1.1545 | lr: 9.9528e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   6867/156230 | global iter:   6867/156230 | loss: 1.2767 | ds_loss: 1.2845 | lr: 9.9528e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   6868/156230 | global iter:   6868/156230 | loss: 1.0203 | ds_loss: 1.0418 | lr: 9.9527e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6868/156230 | global iter:   6868/156230 | loss: 1.1580 | ds_loss: 1.1796 | lr: 9.9527e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6869/156230 | global iter:   6869/156230 | loss: 1.1633 | ds_loss: 1.1887 | lr: 9.9527e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   6870/156230 | global iter:   6870/156230 | loss: 1.0897 | ds_loss: 1.1010 | lr: 9.9527e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   6871/156230 | global iter:   6871/156230 | loss: 1.1684 | ds_loss: 1.1974 | lr: 9.9527e-05 | scale: 65536.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   6872/156230 | global iter:   6872/156230 | loss: 1.1515 | ds_loss: 1.1607 | lr: 9.9527e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6872/156230 | global iter:   6872/156230 | loss: 1.1432 | ds_loss: 1.1620 | lr: 9.9527e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6873/156230 | global iter:   6873/156230 | loss: 1.1033 | ds_loss: 1.1221 | lr: 9.9527e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   6874/156230 | global iter:   6874/156230 | loss: 1.2484 | ds_loss: 1.2716 | lr: 9.9527e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   6875/156230 | global iter:   6875/156230 | loss: 1.1780 | ds_loss: 1.1845 | lr: 9.9526e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   6876/156230 | global iter:   6876/156230 | loss: 1.1671 | ds_loss: 1.2126 | lr: 9.9526e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6876/156230 | global iter:   6876/156230 | loss: 1.1742 | ds_loss: 1.1977 | lr: 9.9526e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6877/156230 | global iter:   6877/156230 | loss: 1.1419 | ds_loss: 1.1567 | lr: 9.9526e-05 | scale: 65536.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   6878/156230 | global iter:   6878/156230 | loss: 1.1628 | ds_loss: 1.1882 | lr: 9.9526e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   6879/156230 | global iter:   6879/156230 | loss: 1.0450 | ds_loss: 1.0615 | lr: 9.9526e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   6880/156230 | global iter:   6880/156230 | loss: 1.0975 | ds_loss: 1.1037 | lr: 9.9526e-05 | scale: 65536.0000 | micro time: 1.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6880/156230 | global iter:   6880/156230 | loss: 1.1118 | ds_loss: 1.1275 | lr: 9.9526e-05 | scale: 65536.0000 | micro time: 1.397 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6881/156230 | global iter:   6881/156230 | loss: 1.1817 | ds_loss: 1.2199 | lr: 9.9526e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   6882/156230 | global iter:   6882/156230 | loss: 0.9952 | ds_loss: 1.0105 | lr: 9.9526e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   6883/156230 | global iter:   6883/156230 | loss: 1.1758 | ds_loss: 1.1946 | lr: 9.9525e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   6884/156230 | global iter:   6884/156230 | loss: 1.0172 | ds_loss: 1.0411 | lr: 9.9525e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6884/156230 | global iter:   6884/156230 | loss: 1.0925 | ds_loss: 1.1165 | lr: 9.9525e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6885/156230 | global iter:   6885/156230 | loss: 1.0848 | ds_loss: 1.0870 | lr: 9.9525e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   6886/156230 | global iter:   6886/156230 | loss: 1.0899 | ds_loss: 1.1070 | lr: 9.9525e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   6887/156230 | global iter:   6887/156230 | loss: 1.1430 | ds_loss: 1.1564 | lr: 9.9525e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   6888/156230 | global iter:   6888/156230 | loss: 0.9431 | ds_loss: 0.9689 | lr: 9.9525e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6888/156230 | global iter:   6888/156230 | loss: 1.0652 | ds_loss: 1.0798 | lr: 9.9525e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6889/156230 | global iter:   6889/156230 | loss: 1.0655 | ds_loss: 1.1014 | lr: 9.9525e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   6890/156230 | global iter:   6890/156230 | loss: 1.0938 | ds_loss: 1.1024 | lr: 9.9524e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   6891/156230 | global iter:   6891/156230 | loss: 1.2509 | ds_loss: 1.2837 | lr: 9.9524e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   6892/156230 | global iter:   6892/156230 | loss: 1.1801 | ds_loss: 1.1972 | lr: 9.9524e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6892/156230 | global iter:   6892/156230 | loss: 1.1476 | ds_loss: 1.1712 | lr: 9.9524e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6893/156230 | global iter:   6893/156230 | loss: 1.0706 | ds_loss: 1.0840 | lr: 9.9524e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   6894/156230 | global iter:   6894/156230 | loss: 0.9683 | ds_loss: 0.9884 | lr: 9.9524e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   6895/156230 | global iter:   6895/156230 | loss: 1.0229 | ds_loss: 1.0421 | lr: 9.9524e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   6896/156230 | global iter:   6896/156230 | loss: 1.1660 | ds_loss: 1.1727 | lr: 9.9524e-05 | scale: 65536.0000 | micro time: 1.316 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6896/156230 | global iter:   6896/156230 | loss: 1.0569 | ds_loss: 1.0718 | lr: 9.9524e-05 | scale: 65536.0000 | micro time: 1.316 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6897/156230 | global iter:   6897/156230 | loss: 1.0004 | ds_loss: 1.0172 | lr: 9.9523e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   6898/156230 | global iter:   6898/156230 | loss: 1.0965 | ds_loss: 1.1259 | lr: 9.9523e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   6899/156230 | global iter:   6899/156230 | loss: 1.0249 | ds_loss: 1.0360 | lr: 9.9523e-05 | scale: 65536.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:   6900/156230 | global iter:   6900/156230 | loss: 0.8476 | ds_loss: 0.8838 | lr: 9.9523e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6900/156230 | global iter:   6900/156230 | loss: 0.9923 | ds_loss: 1.0157 | lr: 9.9523e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6901/156230 | global iter:   6901/156230 | loss: 1.2079 | ds_loss: 1.2149 | lr: 9.9523e-05 | scale: 65536.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   6902/156230 | global iter:   6902/156230 | loss: 1.0422 | ds_loss: 1.0508 | lr: 9.9523e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   6903/156230 | global iter:   6903/156230 | loss: 1.1929 | ds_loss: 1.2311 | lr: 9.9523e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   6904/156230 | global iter:   6904/156230 | loss: 0.9563 | ds_loss: 0.9772 | lr: 9.9522e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6904/156230 | global iter:   6904/156230 | loss: 1.0998 | ds_loss: 1.1185 | lr: 9.9522e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6905/156230 | global iter:   6905/156230 | loss: 1.0861 | ds_loss: 1.1169 | lr: 9.9522e-05 | scale: 65536.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   6906/156230 | global iter:   6906/156230 | loss: 1.2205 | ds_loss: 1.2342 | lr: 9.9522e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   6907/156230 | global iter:   6907/156230 | loss: 1.0588 | ds_loss: 1.0725 | lr: 9.9522e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   6908/156230 | global iter:   6908/156230 | loss: 1.1974 | ds_loss: 1.2147 | lr: 9.9522e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6908/156230 | global iter:   6908/156230 | loss: 1.1407 | ds_loss: 1.1595 | lr: 9.9522e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6909/156230 | global iter:   6909/156230 | loss: 1.1674 | ds_loss: 1.1807 | lr: 9.9522e-05 | scale: 65536.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   6910/156230 | global iter:   6910/156230 | loss: 1.0604 | ds_loss: 1.0567 | lr: 9.9522e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   6911/156230 | global iter:   6911/156230 | loss: 1.1503 | ds_loss: 1.1707 | lr: 9.9521e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   6912/156230 | global iter:   6912/156230 | loss: 1.1166 | ds_loss: 1.1344 | lr: 9.9521e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6912/156230 | global iter:   6912/156230 | loss: 1.1237 | ds_loss: 1.1356 | lr: 9.9521e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6913/156230 | global iter:   6913/156230 | loss: 1.2139 | ds_loss: 1.2381 | lr: 9.9521e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   6914/156230 | global iter:   6914/156230 | loss: 1.0717 | ds_loss: 1.0932 | lr: 9.9521e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   6915/156230 | global iter:   6915/156230 | loss: 1.0446 | ds_loss: 1.0553 | lr: 9.9521e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   6916/156230 | global iter:   6916/156230 | loss: 1.1915 | ds_loss: 1.1964 | lr: 9.9521e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6916/156230 | global iter:   6916/156230 | loss: 1.1304 | ds_loss: 1.1457 | lr: 9.9521e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6917/156230 | global iter:   6917/156230 | loss: 1.2364 | ds_loss: 1.2664 | lr: 9.9521e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   6918/156230 | global iter:   6918/156230 | loss: 1.1416 | ds_loss: 1.1564 | lr: 9.9521e-05 | scale: 65536.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   6919/156230 | global iter:   6919/156230 | loss: 1.1044 | ds_loss: 1.1309 | lr: 9.9520e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   6920/156230 | global iter:   6920/156230 | loss: 1.0862 | ds_loss: 1.1180 | lr: 9.9520e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6920/156230 | global iter:   6920/156230 | loss: 1.1421 | ds_loss: 1.1679 | lr: 9.9520e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6921/156230 | global iter:   6921/156230 | loss: 1.0328 | ds_loss: 1.0480 | lr: 9.9520e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   6922/156230 | global iter:   6922/156230 | loss: 1.1497 | ds_loss: 1.1630 | lr: 9.9520e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   6923/156230 | global iter:   6923/156230 | loss: 0.9721 | ds_loss: 0.9964 | lr: 9.9520e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   6924/156230 | global iter:   6924/156230 | loss: 1.2788 | ds_loss: 1.2823 | lr: 9.9520e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6924/156230 | global iter:   6924/156230 | loss: 1.1083 | ds_loss: 1.1224 | lr: 9.9520e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6925/156230 | global iter:   6925/156230 | loss: 0.9470 | ds_loss: 0.9353 | lr: 9.9520e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   6926/156230 | global iter:   6926/156230 | loss: 0.9371 | ds_loss: 0.9364 | lr: 9.9519e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   6927/156230 | global iter:   6927/156230 | loss: 0.9584 | ds_loss: 0.9671 | lr: 9.9519e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   6928/156230 | global iter:   6928/156230 | loss: 1.2087 | ds_loss: 1.2264 | lr: 9.9519e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6928/156230 | global iter:   6928/156230 | loss: 1.0128 | ds_loss: 1.0163 | lr: 9.9519e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6929/156230 | global iter:   6929/156230 | loss: 1.0117 | ds_loss: 1.0431 | lr: 9.9519e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   6930/156230 | global iter:   6930/156230 | loss: 1.1676 | ds_loss: 1.1996 | lr: 9.9519e-05 | scale: 65536.0000 | micro time: 1.391 | step time: 0.000
train | epoch   0 | Iter:   6931/156230 | global iter:   6931/156230 | loss: 1.1122 | ds_loss: 1.1369 | lr: 9.9519e-05 | scale: 65536.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   6932/156230 | global iter:   6932/156230 | loss: 1.2874 | ds_loss: 1.3098 | lr: 9.9519e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6932/156230 | global iter:   6932/156230 | loss: 1.1447 | ds_loss: 1.1724 | lr: 9.9519e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6933/156230 | global iter:   6933/156230 | loss: 1.0894 | ds_loss: 1.1055 | lr: 9.9518e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   6934/156230 | global iter:   6934/156230 | loss: 1.0390 | ds_loss: 1.0576 | lr: 9.9518e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   6935/156230 | global iter:   6935/156230 | loss: 1.1787 | ds_loss: 1.1909 | lr: 9.9518e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   6936/156230 | global iter:   6936/156230 | loss: 1.2049 | ds_loss: 1.2239 | lr: 9.9518e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6936/156230 | global iter:   6936/156230 | loss: 1.1280 | ds_loss: 1.1445 | lr: 9.9518e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6937/156230 | global iter:   6937/156230 | loss: 1.0711 | ds_loss: 1.0955 | lr: 9.9518e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   6938/156230 | global iter:   6938/156230 | loss: 1.1503 | ds_loss: 1.1660 | lr: 9.9518e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   6939/156230 | global iter:   6939/156230 | loss: 1.1133 | ds_loss: 1.1305 | lr: 9.9518e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   6940/156230 | global iter:   6940/156230 | loss: 1.0750 | ds_loss: 1.0950 | lr: 9.9517e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6940/156230 | global iter:   6940/156230 | loss: 1.1024 | ds_loss: 1.1217 | lr: 9.9517e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6941/156230 | global iter:   6941/156230 | loss: 1.0992 | ds_loss: 1.1034 | lr: 9.9517e-05 | scale: 65536.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   6942/156230 | global iter:   6942/156230 | loss: 1.0620 | ds_loss: 1.0828 | lr: 9.9517e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   6943/156230 | global iter:   6943/156230 | loss: 0.9946 | ds_loss: 1.0350 | lr: 9.9517e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   6944/156230 | global iter:   6944/156230 | loss: 1.0023 | ds_loss: 1.0187 | lr: 9.9517e-05 | scale: 65536.0000 | micro time: 1.390 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6944/156230 | global iter:   6944/156230 | loss: 1.0395 | ds_loss: 1.0600 | lr: 9.9517e-05 | scale: 65536.0000 | micro time: 1.390 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6945/156230 | global iter:   6945/156230 | loss: 1.0277 | ds_loss: 1.0407 | lr: 9.9517e-05 | scale: 65536.0000 | micro time: 1.404 | step time: 0.000
train | epoch   0 | Iter:   6946/156230 | global iter:   6946/156230 | loss: 1.1122 | ds_loss: 1.1382 | lr: 9.9517e-05 | scale: 65536.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   6947/156230 | global iter:   6947/156230 | loss: 1.1490 | ds_loss: 1.1669 | lr: 9.9516e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   6948/156230 | global iter:   6948/156230 | loss: 1.0740 | ds_loss: 1.0938 | lr: 9.9516e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6948/156230 | global iter:   6948/156230 | loss: 1.0907 | ds_loss: 1.1099 | lr: 9.9516e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6949/156230 | global iter:   6949/156230 | loss: 1.1730 | ds_loss: 1.1806 | lr: 9.9516e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   6950/156230 | global iter:   6950/156230 | loss: 1.1519 | ds_loss: 1.1733 | lr: 9.9516e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   6951/156230 | global iter:   6951/156230 | loss: 1.0958 | ds_loss: 1.1118 | lr: 9.9516e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   6952/156230 | global iter:   6952/156230 | loss: 1.1761 | ds_loss: 1.1765 | lr: 9.9516e-05 | scale: 65536.0000 | micro time: 1.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6952/156230 | global iter:   6952/156230 | loss: 1.1492 | ds_loss: 1.1605 | lr: 9.9516e-05 | scale: 65536.0000 | micro time: 1.398 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6953/156230 | global iter:   6953/156230 | loss: 1.0631 | ds_loss: 1.0672 | lr: 9.9516e-05 | scale: 65536.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   6954/156230 | global iter:   6954/156230 | loss: 1.0666 | ds_loss: 1.0797 | lr: 9.9516e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   6955/156230 | global iter:   6955/156230 | loss: 1.1838 | ds_loss: 1.1979 | lr: 9.9515e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   6956/156230 | global iter:   6956/156230 | loss: 1.1654 | ds_loss: 1.2002 | lr: 9.9515e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6956/156230 | global iter:   6956/156230 | loss: 1.1197 | ds_loss: 1.1363 | lr: 9.9515e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6957/156230 | global iter:   6957/156230 | loss: 0.9459 | ds_loss: 0.9627 | lr: 9.9515e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   6958/156230 | global iter:   6958/156230 | loss: 1.0823 | ds_loss: 1.1069 | lr: 9.9515e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   6959/156230 | global iter:   6959/156230 | loss: 1.1212 | ds_loss: 1.1461 | lr: 9.9515e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   6960/156230 | global iter:   6960/156230 | loss: 1.1228 | ds_loss: 1.1250 | lr: 9.9515e-05 | scale: 65536.0000 | micro time: 1.391 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6960/156230 | global iter:   6960/156230 | loss: 1.0681 | ds_loss: 1.0852 | lr: 9.9515e-05 | scale: 65536.0000 | micro time: 1.391 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6961/156230 | global iter:   6961/156230 | loss: 1.1459 | ds_loss: 1.1699 | lr: 9.9515e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   6962/156230 | global iter:   6962/156230 | loss: 1.0072 | ds_loss: 1.0300 | lr: 9.9514e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   6963/156230 | global iter:   6963/156230 | loss: 1.0824 | ds_loss: 1.0921 | lr: 9.9514e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   6964/156230 | global iter:   6964/156230 | loss: 1.1202 | ds_loss: 1.1505 | lr: 9.9514e-05 | scale: 65536.0000 | micro time: 1.388 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6964/156230 | global iter:   6964/156230 | loss: 1.0889 | ds_loss: 1.1106 | lr: 9.9514e-05 | scale: 65536.0000 | micro time: 1.388 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6965/156230 | global iter:   6965/156230 | loss: 1.0032 | ds_loss: 1.0248 | lr: 9.9514e-05 | scale: 65536.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   6966/156230 | global iter:   6966/156230 | loss: 1.0253 | ds_loss: 1.0453 | lr: 9.9514e-05 | scale: 65536.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   6967/156230 | global iter:   6967/156230 | loss: 1.0250 | ds_loss: 1.0494 | lr: 9.9514e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   6968/156230 | global iter:   6968/156230 | loss: 1.1971 | ds_loss: 1.2147 | lr: 9.9514e-05 | scale: 65536.0000 | micro time: 1.331 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6968/156230 | global iter:   6968/156230 | loss: 1.0626 | ds_loss: 1.0836 | lr: 9.9514e-05 | scale: 65536.0000 | micro time: 1.331 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6969/156230 | global iter:   6969/156230 | loss: 1.1260 | ds_loss: 1.1403 | lr: 9.9513e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   6970/156230 | global iter:   6970/156230 | loss: 1.0928 | ds_loss: 1.1014 | lr: 9.9513e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   6971/156230 | global iter:   6971/156230 | loss: 1.0648 | ds_loss: 1.0852 | lr: 9.9513e-05 | scale: 65536.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   6972/156230 | global iter:   6972/156230 | loss: 1.0062 | ds_loss: 1.0248 | lr: 9.9513e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6972/156230 | global iter:   6972/156230 | loss: 1.0725 | ds_loss: 1.0879 | lr: 9.9513e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6973/156230 | global iter:   6973/156230 | loss: 1.0554 | ds_loss: 1.0884 | lr: 9.9513e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   6974/156230 | global iter:   6974/156230 | loss: 1.0970 | ds_loss: 1.0885 | lr: 9.9513e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   6975/156230 | global iter:   6975/156230 | loss: 1.0990 | ds_loss: 1.1276 | lr: 9.9513e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   6976/156230 | global iter:   6976/156230 | loss: 1.1268 | ds_loss: 1.1370 | lr: 9.9512e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6976/156230 | global iter:   6976/156230 | loss: 1.0945 | ds_loss: 1.1104 | lr: 9.9512e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6977/156230 | global iter:   6977/156230 | loss: 0.8940 | ds_loss: 0.9123 | lr: 9.9512e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   6978/156230 | global iter:   6978/156230 | loss: 1.1548 | ds_loss: 1.1837 | lr: 9.9512e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   6979/156230 | global iter:   6979/156230 | loss: 1.0451 | ds_loss: 1.0657 | lr: 9.9512e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   6980/156230 | global iter:   6980/156230 | loss: 1.1893 | ds_loss: 1.2081 | lr: 9.9512e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6980/156230 | global iter:   6980/156230 | loss: 1.0708 | ds_loss: 1.0924 | lr: 9.9512e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6981/156230 | global iter:   6981/156230 | loss: 1.0431 | ds_loss: 1.0703 | lr: 9.9512e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   6982/156230 | global iter:   6982/156230 | loss: 1.1767 | ds_loss: 1.2014 | lr: 9.9512e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   6983/156230 | global iter:   6983/156230 | loss: 1.0817 | ds_loss: 1.1067 | lr: 9.9511e-05 | scale: 65536.0000 | micro time: 1.420 | step time: 0.000
train | epoch   0 | Iter:   6984/156230 | global iter:   6984/156230 | loss: 0.8128 | ds_loss: 0.8449 | lr: 9.9511e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6984/156230 | global iter:   6984/156230 | loss: 1.0286 | ds_loss: 1.0558 | lr: 9.9511e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6985/156230 | global iter:   6985/156230 | loss: 1.0411 | ds_loss: 1.0624 | lr: 9.9511e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   6986/156230 | global iter:   6986/156230 | loss: 1.0921 | ds_loss: 1.1177 | lr: 9.9511e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   6987/156230 | global iter:   6987/156230 | loss: 1.0633 | ds_loss: 1.0823 | lr: 9.9511e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   6988/156230 | global iter:   6988/156230 | loss: 0.9180 | ds_loss: 0.9349 | lr: 9.9511e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6988/156230 | global iter:   6988/156230 | loss: 1.0286 | ds_loss: 1.0493 | lr: 9.9511e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6989/156230 | global iter:   6989/156230 | loss: 1.1185 | ds_loss: 1.1411 | lr: 9.9511e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   6990/156230 | global iter:   6990/156230 | loss: 1.0169 | ds_loss: 1.0315 | lr: 9.9510e-05 | scale: 65536.0000 | micro time: 1.409 | step time: 0.000
train | epoch   0 | Iter:   6991/156230 | global iter:   6991/156230 | loss: 0.8676 | ds_loss: 0.8930 | lr: 9.9510e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   6992/156230 | global iter:   6992/156230 | loss: 0.9946 | ds_loss: 1.0363 | lr: 9.9510e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6992/156230 | global iter:   6992/156230 | loss: 0.9994 | ds_loss: 1.0255 | lr: 9.9510e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6993/156230 | global iter:   6993/156230 | loss: 0.9763 | ds_loss: 1.0097 | lr: 9.9510e-05 | scale: 65536.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   6994/156230 | global iter:   6994/156230 | loss: 1.1538 | ds_loss: 1.1529 | lr: 9.9510e-05 | scale: 65536.0000 | micro time: 1.410 | step time: 0.000
train | epoch   0 | Iter:   6995/156230 | global iter:   6995/156230 | loss: 1.1025 | ds_loss: 1.1254 | lr: 9.9510e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   6996/156230 | global iter:   6996/156230 | loss: 1.2494 | ds_loss: 1.2621 | lr: 9.9510e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   6996/156230 | global iter:   6996/156230 | loss: 1.1205 | ds_loss: 1.1375 | lr: 9.9510e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   6997/156230 | global iter:   6997/156230 | loss: 1.1040 | ds_loss: 1.1257 | lr: 9.9509e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   6998/156230 | global iter:   6998/156230 | loss: 0.9978 | ds_loss: 1.0214 | lr: 9.9509e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   6999/156230 | global iter:   6999/156230 | loss: 1.0955 | ds_loss: 1.1008 | lr: 9.9509e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   7000/156230 | global iter:   7000/156230 | loss: 0.8658 | ds_loss: 0.8919 | lr: 9.9509e-05 | scale: 65536.0000 | micro time: 1.407 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7000/156230 | global iter:   7000/156230 | loss: 1.0158 | ds_loss: 1.0349 | lr: 9.9509e-05 | scale: 65536.0000 | micro time: 1.407 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7001/156230 | global iter:   7001/156230 | loss: 1.1003 | ds_loss: 1.1192 | lr: 9.9509e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   7002/156230 | global iter:   7002/156230 | loss: 1.1050 | ds_loss: 1.1319 | lr: 9.9509e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7003/156230 | global iter:   7003/156230 | loss: 1.1638 | ds_loss: 1.2031 | lr: 9.9509e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   7004/156230 | global iter:   7004/156230 | loss: 1.0082 | ds_loss: 1.0209 | lr: 9.9509e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7004/156230 | global iter:   7004/156230 | loss: 1.0943 | ds_loss: 1.1188 | lr: 9.9509e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7005/156230 | global iter:   7005/156230 | loss: 1.0149 | ds_loss: 1.0255 | lr: 9.9508e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   7006/156230 | global iter:   7006/156230 | loss: 0.9353 | ds_loss: 0.9451 | lr: 9.9508e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   7007/156230 | global iter:   7007/156230 | loss: 1.0837 | ds_loss: 1.1042 | lr: 9.9508e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   7008/156230 | global iter:   7008/156230 | loss: 1.0282 | ds_loss: 1.0390 | lr: 9.9508e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7008/156230 | global iter:   7008/156230 | loss: 1.0155 | ds_loss: 1.0284 | lr: 9.9508e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7009/156230 | global iter:   7009/156230 | loss: 1.0168 | ds_loss: 1.0384 | lr: 9.9508e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   7010/156230 | global iter:   7010/156230 | loss: 1.1670 | ds_loss: 1.1692 | lr: 9.9508e-05 | scale: 65536.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   7011/156230 | global iter:   7011/156230 | loss: 0.9484 | ds_loss: 0.9766 | lr: 9.9508e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   7012/156230 | global iter:   7012/156230 | loss: 0.7661 | ds_loss: 0.7844 | lr: 9.9507e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7012/156230 | global iter:   7012/156230 | loss: 0.9746 | ds_loss: 0.9922 | lr: 9.9507e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7013/156230 | global iter:   7013/156230 | loss: 1.0862 | ds_loss: 1.0979 | lr: 9.9507e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   7014/156230 | global iter:   7014/156230 | loss: 1.1035 | ds_loss: 1.1182 | lr: 9.9507e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   7015/156230 | global iter:   7015/156230 | loss: 0.9793 | ds_loss: 1.0055 | lr: 9.9507e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   7016/156230 | global iter:   7016/156230 | loss: 1.0392 | ds_loss: 1.0495 | lr: 9.9507e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7016/156230 | global iter:   7016/156230 | loss: 1.0520 | ds_loss: 1.0678 | lr: 9.9507e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7017/156230 | global iter:   7017/156230 | loss: 1.0328 | ds_loss: 1.0368 | lr: 9.9507e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   7018/156230 | global iter:   7018/156230 | loss: 0.9659 | ds_loss: 0.9679 | lr: 9.9507e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   7019/156230 | global iter:   7019/156230 | loss: 1.1777 | ds_loss: 1.2086 | lr: 9.9506e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   7020/156230 | global iter:   7020/156230 | loss: 1.2232 | ds_loss: 1.2304 | lr: 9.9506e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7020/156230 | global iter:   7020/156230 | loss: 1.0999 | ds_loss: 1.1109 | lr: 9.9506e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7021/156230 | global iter:   7021/156230 | loss: 1.1892 | ds_loss: 1.2067 | lr: 9.9506e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   7022/156230 | global iter:   7022/156230 | loss: 1.2114 | ds_loss: 1.2034 | lr: 9.9506e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   7023/156230 | global iter:   7023/156230 | loss: 1.2260 | ds_loss: 1.2442 | lr: 9.9506e-05 | scale: 65536.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   7024/156230 | global iter:   7024/156230 | loss: 1.1619 | ds_loss: 1.1782 | lr: 9.9506e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7024/156230 | global iter:   7024/156230 | loss: 1.1971 | ds_loss: 1.2081 | lr: 9.9506e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7025/156230 | global iter:   7025/156230 | loss: 0.9874 | ds_loss: 1.0020 | lr: 9.9506e-05 | scale: 65536.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:   7026/156230 | global iter:   7026/156230 | loss: 1.2010 | ds_loss: 1.2117 | lr: 9.9505e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   7027/156230 | global iter:   7027/156230 | loss: 1.0540 | ds_loss: 1.0717 | lr: 9.9505e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   7028/156230 | global iter:   7028/156230 | loss: 1.0233 | ds_loss: 1.0548 | lr: 9.9505e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7028/156230 | global iter:   7028/156230 | loss: 1.0664 | ds_loss: 1.0850 | lr: 9.9505e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7029/156230 | global iter:   7029/156230 | loss: 1.0918 | ds_loss: 1.1168 | lr: 9.9505e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   7030/156230 | global iter:   7030/156230 | loss: 1.1232 | ds_loss: 1.1277 | lr: 9.9505e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   7031/156230 | global iter:   7031/156230 | loss: 0.9679 | ds_loss: 0.9768 | lr: 9.9505e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   7032/156230 | global iter:   7032/156230 | loss: 1.0741 | ds_loss: 1.1023 | lr: 9.9505e-05 | scale: 65536.0000 | micro time: 1.388 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7032/156230 | global iter:   7032/156230 | loss: 1.0643 | ds_loss: 1.0809 | lr: 9.9505e-05 | scale: 65536.0000 | micro time: 1.388 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7033/156230 | global iter:   7033/156230 | loss: 1.0140 | ds_loss: 1.0366 | lr: 9.9504e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   7034/156230 | global iter:   7034/156230 | loss: 0.9809 | ds_loss: 0.9963 | lr: 9.9504e-05 | scale: 65536.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:   7035/156230 | global iter:   7035/156230 | loss: 0.9590 | ds_loss: 0.9630 | lr: 9.9504e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   7036/156230 | global iter:   7036/156230 | loss: 1.0615 | ds_loss: 1.0841 | lr: 9.9504e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7036/156230 | global iter:   7036/156230 | loss: 1.0039 | ds_loss: 1.0200 | lr: 9.9504e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7037/156230 | global iter:   7037/156230 | loss: 0.9663 | ds_loss: 0.9822 | lr: 9.9504e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   7038/156230 | global iter:   7038/156230 | loss: 1.1256 | ds_loss: 1.1319 | lr: 9.9504e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   7039/156230 | global iter:   7039/156230 | loss: 1.2041 | ds_loss: 1.2178 | lr: 9.9504e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   7040/156230 | global iter:   7040/156230 | loss: 1.0759 | ds_loss: 1.0854 | lr: 9.9503e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7040/156230 | global iter:   7040/156230 | loss: 1.0929 | ds_loss: 1.1043 | lr: 9.9503e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7041/156230 | global iter:   7041/156230 | loss: 1.2898 | ds_loss: 1.3147 | lr: 9.9503e-05 | scale: 65536.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   7042/156230 | global iter:   7042/156230 | loss: 1.1864 | ds_loss: 1.2036 | lr: 9.9503e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   7043/156230 | global iter:   7043/156230 | loss: 1.0842 | ds_loss: 1.1125 | lr: 9.9503e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   7044/156230 | global iter:   7044/156230 | loss: 1.1891 | ds_loss: 1.1922 | lr: 9.9503e-05 | scale: 65536.0000 | micro time: 1.392 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7044/156230 | global iter:   7044/156230 | loss: 1.1874 | ds_loss: 1.2057 | lr: 9.9503e-05 | scale: 65536.0000 | micro time: 1.392 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7045/156230 | global iter:   7045/156230 | loss: 1.0041 | ds_loss: 1.0186 | lr: 9.9503e-05 | scale: 65536.0000 | micro time: 1.304 | step time: 0.000
train | epoch   0 | Iter:   7046/156230 | global iter:   7046/156230 | loss: 1.1151 | ds_loss: 1.1377 | lr: 9.9503e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   7047/156230 | global iter:   7047/156230 | loss: 1.0460 | ds_loss: 1.0556 | lr: 9.9502e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   7048/156230 | global iter:   7048/156230 | loss: 1.0167 | ds_loss: 1.0297 | lr: 9.9502e-05 | scale: 65536.0000 | micro time: 1.328 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7048/156230 | global iter:   7048/156230 | loss: 1.0455 | ds_loss: 1.0604 | lr: 9.9502e-05 | scale: 65536.0000 | micro time: 1.328 | step time: 1.339
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7049/156230 | global iter:   7049/156230 | loss: 1.1848 | ds_loss: 1.1904 | lr: 9.9502e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   7050/156230 | global iter:   7050/156230 | loss: 1.1542 | ds_loss: 1.1799 | lr: 9.9502e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   7051/156230 | global iter:   7051/156230 | loss: 1.0432 | ds_loss: 1.0681 | lr: 9.9502e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   7052/156230 | global iter:   7052/156230 | loss: 0.9531 | ds_loss: 0.9574 | lr: 9.9502e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7052/156230 | global iter:   7052/156230 | loss: 1.0838 | ds_loss: 1.0990 | lr: 9.9502e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7053/156230 | global iter:   7053/156230 | loss: 1.1246 | ds_loss: 1.1564 | lr: 9.9502e-05 | scale: 65536.0000 | micro time: 1.316 | step time: 0.000
train | epoch   0 | Iter:   7054/156230 | global iter:   7054/156230 | loss: 1.2232 | ds_loss: 1.2338 | lr: 9.9501e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7055/156230 | global iter:   7055/156230 | loss: 1.1245 | ds_loss: 1.1481 | lr: 9.9501e-05 | scale: 65536.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:   7056/156230 | global iter:   7056/156230 | loss: 1.0008 | ds_loss: 1.0215 | lr: 9.9501e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7056/156230 | global iter:   7056/156230 | loss: 1.1183 | ds_loss: 1.1399 | lr: 9.9501e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 1.342
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7057/156230 | global iter:   7057/156230 | loss: 1.0411 | ds_loss: 1.0483 | lr: 9.9501e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   7058/156230 | global iter:   7058/156230 | loss: 1.0314 | ds_loss: 1.0503 | lr: 9.9501e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   7059/156230 | global iter:   7059/156230 | loss: 0.9227 | ds_loss: 0.9434 | lr: 9.9501e-05 | scale: 65536.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   7060/156230 | global iter:   7060/156230 | loss: 1.1236 | ds_loss: 1.1405 | lr: 9.9501e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7060/156230 | global iter:   7060/156230 | loss: 1.0297 | ds_loss: 1.0456 | lr: 9.9501e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7061/156230 | global iter:   7061/156230 | loss: 1.1214 | ds_loss: 1.1259 | lr: 9.9500e-05 | scale: 65536.0000 | micro time: 1.404 | step time: 0.000
train | epoch   0 | Iter:   7062/156230 | global iter:   7062/156230 | loss: 1.0213 | ds_loss: 1.0381 | lr: 9.9500e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   7063/156230 | global iter:   7063/156230 | loss: 0.9795 | ds_loss: 1.0058 | lr: 9.9500e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   7064/156230 | global iter:   7064/156230 | loss: 1.0633 | ds_loss: 1.0875 | lr: 9.9500e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7064/156230 | global iter:   7064/156230 | loss: 1.0464 | ds_loss: 1.0644 | lr: 9.9500e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7065/156230 | global iter:   7065/156230 | loss: 1.0674 | ds_loss: 1.0910 | lr: 9.9500e-05 | scale: 65536.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   7066/156230 | global iter:   7066/156230 | loss: 1.1401 | ds_loss: 1.1681 | lr: 9.9500e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   7067/156230 | global iter:   7067/156230 | loss: 1.0936 | ds_loss: 1.1120 | lr: 9.9500e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   7068/156230 | global iter:   7068/156230 | loss: 1.0949 | ds_loss: 1.1128 | lr: 9.9499e-05 | scale: 65536.0000 | micro time: 1.323 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7068/156230 | global iter:   7068/156230 | loss: 1.0990 | ds_loss: 1.1210 | lr: 9.9499e-05 | scale: 65536.0000 | micro time: 1.323 | step time: 1.341
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7069/156230 | global iter:   7069/156230 | loss: 1.1306 | ds_loss: 1.1521 | lr: 9.9499e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   7070/156230 | global iter:   7070/156230 | loss: 1.1480 | ds_loss: 1.1603 | lr: 9.9499e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   7071/156230 | global iter:   7071/156230 | loss: 1.0988 | ds_loss: 1.1323 | lr: 9.9499e-05 | scale: 65536.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   7072/156230 | global iter:   7072/156230 | loss: 1.0890 | ds_loss: 1.1193 | lr: 9.9499e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7072/156230 | global iter:   7072/156230 | loss: 1.1166 | ds_loss: 1.1410 | lr: 9.9499e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7073/156230 | global iter:   7073/156230 | loss: 0.9372 | ds_loss: 0.9568 | lr: 9.9499e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   7074/156230 | global iter:   7074/156230 | loss: 0.9663 | ds_loss: 0.9776 | lr: 9.9499e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   7075/156230 | global iter:   7075/156230 | loss: 1.2649 | ds_loss: 1.2917 | lr: 9.9498e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   7076/156230 | global iter:   7076/156230 | loss: 1.1661 | ds_loss: 1.2003 | lr: 9.9498e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7076/156230 | global iter:   7076/156230 | loss: 1.0836 | ds_loss: 1.1066 | lr: 9.9498e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7077/156230 | global iter:   7077/156230 | loss: 1.1355 | ds_loss: 1.1573 | lr: 9.9498e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   7078/156230 | global iter:   7078/156230 | loss: 1.1191 | ds_loss: 1.1208 | lr: 9.9498e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   7079/156230 | global iter:   7079/156230 | loss: 1.2004 | ds_loss: 1.2308 | lr: 9.9498e-05 | scale: 65536.0000 | micro time: 1.315 | step time: 0.000
train | epoch   0 | Iter:   7080/156230 | global iter:   7080/156230 | loss: 1.1209 | ds_loss: 1.1362 | lr: 9.9498e-05 | scale: 65536.0000 | micro time: 1.392 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7080/156230 | global iter:   7080/156230 | loss: 1.1440 | ds_loss: 1.1613 | lr: 9.9498e-05 | scale: 65536.0000 | micro time: 1.392 | step time: 1.347
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7081/156230 | global iter:   7081/156230 | loss: 1.1124 | ds_loss: 1.1480 | lr: 9.9498e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   7082/156230 | global iter:   7082/156230 | loss: 1.1382 | ds_loss: 1.1262 | lr: 9.9497e-05 | scale: 65536.0000 | micro time: 1.322 | step time: 0.000
train | epoch   0 | Iter:   7083/156230 | global iter:   7083/156230 | loss: 1.0739 | ds_loss: 1.0974 | lr: 9.9497e-05 | scale: 65536.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   7084/156230 | global iter:   7084/156230 | loss: 1.1882 | ds_loss: 1.2179 | lr: 9.9497e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7084/156230 | global iter:   7084/156230 | loss: 1.1282 | ds_loss: 1.1474 | lr: 9.9497e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 1.347
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7085/156230 | global iter:   7085/156230 | loss: 1.1454 | ds_loss: 1.1666 | lr: 9.9497e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   7086/156230 | global iter:   7086/156230 | loss: 1.2636 | ds_loss: 1.2721 | lr: 9.9497e-05 | scale: 65536.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   7087/156230 | global iter:   7087/156230 | loss: 1.1708 | ds_loss: 1.2163 | lr: 9.9497e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   7088/156230 | global iter:   7088/156230 | loss: 1.1736 | ds_loss: 1.1918 | lr: 9.9497e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7088/156230 | global iter:   7088/156230 | loss: 1.1884 | ds_loss: 1.2117 | lr: 9.9497e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7089/156230 | global iter:   7089/156230 | loss: 1.2187 | ds_loss: 1.2400 | lr: 9.9496e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   7090/156230 | global iter:   7090/156230 | loss: 0.9776 | ds_loss: 0.9787 | lr: 9.9496e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   7091/156230 | global iter:   7091/156230 | loss: 1.2048 | ds_loss: 1.2255 | lr: 9.9496e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7092/156230 | global iter:   7092/156230 | loss: 1.0701 | ds_loss: 1.0911 | lr: 9.9496e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7092/156230 | global iter:   7092/156230 | loss: 1.1178 | ds_loss: 1.1338 | lr: 9.9496e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7093/156230 | global iter:   7093/156230 | loss: 1.0608 | ds_loss: 1.0749 | lr: 9.9496e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   7094/156230 | global iter:   7094/156230 | loss: 1.2134 | ds_loss: 1.2299 | lr: 9.9496e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   7095/156230 | global iter:   7095/156230 | loss: 1.0583 | ds_loss: 1.0814 | lr: 9.9496e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   7096/156230 | global iter:   7096/156230 | loss: 1.0998 | ds_loss: 1.1359 | lr: 9.9495e-05 | scale: 65536.0000 | micro time: 1.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7096/156230 | global iter:   7096/156230 | loss: 1.1081 | ds_loss: 1.1305 | lr: 9.9495e-05 | scale: 65536.0000 | micro time: 1.397 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7097/156230 | global iter:   7097/156230 | loss: 1.1435 | ds_loss: 1.1757 | lr: 9.9495e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   7098/156230 | global iter:   7098/156230 | loss: 0.9859 | ds_loss: 1.0011 | lr: 9.9495e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   7099/156230 | global iter:   7099/156230 | loss: 1.0327 | ds_loss: 1.0561 | lr: 9.9495e-05 | scale: 65536.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   7100/156230 | global iter:   7100/156230 | loss: 1.2940 | ds_loss: 1.3036 | lr: 9.9495e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7100/156230 | global iter:   7100/156230 | loss: 1.1140 | ds_loss: 1.1341 | lr: 9.9495e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 1.346
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7101/156230 | global iter:   7101/156230 | loss: 1.1725 | ds_loss: 1.1982 | lr: 9.9495e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   7102/156230 | global iter:   7102/156230 | loss: 1.0460 | ds_loss: 1.0608 | lr: 9.9495e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   7103/156230 | global iter:   7103/156230 | loss: 1.0263 | ds_loss: 1.0477 | lr: 9.9494e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   7104/156230 | global iter:   7104/156230 | loss: 1.0981 | ds_loss: 1.1048 | lr: 9.9494e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7104/156230 | global iter:   7104/156230 | loss: 1.0857 | ds_loss: 1.1029 | lr: 9.9494e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7105/156230 | global iter:   7105/156230 | loss: 0.9848 | ds_loss: 1.0038 | lr: 9.9494e-05 | scale: 65536.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   7106/156230 | global iter:   7106/156230 | loss: 1.1867 | ds_loss: 1.2128 | lr: 9.9494e-05 | scale: 65536.0000 | micro time: 1.321 | step time: 0.000
train | epoch   0 | Iter:   7107/156230 | global iter:   7107/156230 | loss: 1.1182 | ds_loss: 1.1356 | lr: 9.9494e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   7108/156230 | global iter:   7108/156230 | loss: 1.1209 | ds_loss: 1.1415 | lr: 9.9494e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7108/156230 | global iter:   7108/156230 | loss: 1.1026 | ds_loss: 1.1234 | lr: 9.9494e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7109/156230 | global iter:   7109/156230 | loss: 1.0541 | ds_loss: 1.0771 | lr: 9.9494e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   7110/156230 | global iter:   7110/156230 | loss: 1.0185 | ds_loss: 1.0541 | lr: 9.9493e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   7111/156230 | global iter:   7111/156230 | loss: 1.0603 | ds_loss: 1.0856 | lr: 9.9493e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   7112/156230 | global iter:   7112/156230 | loss: 1.0529 | ds_loss: 1.0806 | lr: 9.9493e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7112/156230 | global iter:   7112/156230 | loss: 1.0465 | ds_loss: 1.0743 | lr: 9.9493e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7113/156230 | global iter:   7113/156230 | loss: 1.1218 | ds_loss: 1.1398 | lr: 9.9493e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   7114/156230 | global iter:   7114/156230 | loss: 1.2275 | ds_loss: 1.2676 | lr: 9.9493e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   7115/156230 | global iter:   7115/156230 | loss: 1.0083 | ds_loss: 1.0273 | lr: 9.9493e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   7116/156230 | global iter:   7116/156230 | loss: 1.0128 | ds_loss: 1.0150 | lr: 9.9493e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7116/156230 | global iter:   7116/156230 | loss: 1.0926 | ds_loss: 1.1124 | lr: 9.9493e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7117/156230 | global iter:   7117/156230 | loss: 1.0994 | ds_loss: 1.1317 | lr: 9.9492e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   7118/156230 | global iter:   7118/156230 | loss: 1.2139 | ds_loss: 1.2336 | lr: 9.9492e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   7119/156230 | global iter:   7119/156230 | loss: 0.9884 | ds_loss: 1.0005 | lr: 9.9492e-05 | scale: 65536.0000 | micro time: 1.313 | step time: 0.000
train | epoch   0 | Iter:   7120/156230 | global iter:   7120/156230 | loss: 1.1134 | ds_loss: 1.1227 | lr: 9.9492e-05 | scale: 65536.0000 | micro time: 1.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7120/156230 | global iter:   7120/156230 | loss: 1.1038 | ds_loss: 1.1221 | lr: 9.9492e-05 | scale: 65536.0000 | micro time: 1.397 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7121/156230 | global iter:   7121/156230 | loss: 1.0925 | ds_loss: 1.1166 | lr: 9.9492e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   7122/156230 | global iter:   7122/156230 | loss: 1.0532 | ds_loss: 1.0783 | lr: 9.9492e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   7123/156230 | global iter:   7123/156230 | loss: 1.2012 | ds_loss: 1.2177 | lr: 9.9492e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   7124/156230 | global iter:   7124/156230 | loss: 1.2016 | ds_loss: 1.2093 | lr: 9.9491e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7124/156230 | global iter:   7124/156230 | loss: 1.1371 | ds_loss: 1.1555 | lr: 9.9491e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7125/156230 | global iter:   7125/156230 | loss: 1.1941 | ds_loss: 1.2206 | lr: 9.9491e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   7126/156230 | global iter:   7126/156230 | loss: 1.0202 | ds_loss: 1.0272 | lr: 9.9491e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   7127/156230 | global iter:   7127/156230 | loss: 1.0261 | ds_loss: 1.0590 | lr: 9.9491e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   7128/156230 | global iter:   7128/156230 | loss: 1.1046 | ds_loss: 1.1408 | lr: 9.9491e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7128/156230 | global iter:   7128/156230 | loss: 1.0863 | ds_loss: 1.1119 | lr: 9.9491e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7129/156230 | global iter:   7129/156230 | loss: 1.0554 | ds_loss: 1.0692 | lr: 9.9491e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   7130/156230 | global iter:   7130/156230 | loss: 1.1677 | ds_loss: 1.1838 | lr: 9.9491e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   7131/156230 | global iter:   7131/156230 | loss: 1.1179 | ds_loss: 1.1495 | lr: 9.9490e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   7132/156230 | global iter:   7132/156230 | loss: 1.0846 | ds_loss: 1.0804 | lr: 9.9490e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7132/156230 | global iter:   7132/156230 | loss: 1.1064 | ds_loss: 1.1207 | lr: 9.9490e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7133/156230 | global iter:   7133/156230 | loss: 1.0777 | ds_loss: 1.0971 | lr: 9.9490e-05 | scale: 65536.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   7134/156230 | global iter:   7134/156230 | loss: 1.0855 | ds_loss: 1.1092 | lr: 9.9490e-05 | scale: 65536.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   7135/156230 | global iter:   7135/156230 | loss: 1.1560 | ds_loss: 1.1672 | lr: 9.9490e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7136/156230 | global iter:   7136/156230 | loss: 0.9932 | ds_loss: 1.0269 | lr: 9.9490e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7136/156230 | global iter:   7136/156230 | loss: 1.0781 | ds_loss: 1.1001 | lr: 9.9490e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7137/156230 | global iter:   7137/156230 | loss: 1.1757 | ds_loss: 1.1976 | lr: 9.9490e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   7138/156230 | global iter:   7138/156230 | loss: 0.8167 | ds_loss: 0.8181 | lr: 9.9489e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   7139/156230 | global iter:   7139/156230 | loss: 0.9921 | ds_loss: 1.0084 | lr: 9.9489e-05 | scale: 65536.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   7140/156230 | global iter:   7140/156230 | loss: 0.9444 | ds_loss: 0.9500 | lr: 9.9489e-05 | scale: 65536.0000 | micro time: 1.323 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7140/156230 | global iter:   7140/156230 | loss: 0.9823 | ds_loss: 0.9935 | lr: 9.9489e-05 | scale: 65536.0000 | micro time: 1.323 | step time: 1.347
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7141/156230 | global iter:   7141/156230 | loss: 1.1525 | ds_loss: 1.1758 | lr: 9.9489e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   7142/156230 | global iter:   7142/156230 | loss: 1.1223 | ds_loss: 1.1377 | lr: 9.9489e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   7143/156230 | global iter:   7143/156230 | loss: 1.0804 | ds_loss: 1.0996 | lr: 9.9489e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   7144/156230 | global iter:   7144/156230 | loss: 0.9308 | ds_loss: 0.9442 | lr: 9.9489e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7144/156230 | global iter:   7144/156230 | loss: 1.0715 | ds_loss: 1.0893 | lr: 9.9489e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7145/156230 | global iter:   7145/156230 | loss: 1.2297 | ds_loss: 1.2444 | lr: 9.9488e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   7146/156230 | global iter:   7146/156230 | loss: 0.9633 | ds_loss: 0.9887 | lr: 9.9488e-05 | scale: 65536.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   7147/156230 | global iter:   7147/156230 | loss: 1.1412 | ds_loss: 1.1536 | lr: 9.9488e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   7148/156230 | global iter:   7148/156230 | loss: 0.9690 | ds_loss: 0.9953 | lr: 9.9488e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7148/156230 | global iter:   7148/156230 | loss: 1.0758 | ds_loss: 1.0955 | lr: 9.9488e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7149/156230 | global iter:   7149/156230 | loss: 1.2646 | ds_loss: 1.2821 | lr: 9.9488e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   7150/156230 | global iter:   7150/156230 | loss: 1.0432 | ds_loss: 1.0676 | lr: 9.9488e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   7151/156230 | global iter:   7151/156230 | loss: 1.1607 | ds_loss: 1.1805 | lr: 9.9488e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   7152/156230 | global iter:   7152/156230 | loss: 0.9903 | ds_loss: 1.0132 | lr: 9.9487e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7152/156230 | global iter:   7152/156230 | loss: 1.1147 | ds_loss: 1.1359 | lr: 9.9487e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7153/156230 | global iter:   7153/156230 | loss: 0.9076 | ds_loss: 0.9225 | lr: 9.9487e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   7154/156230 | global iter:   7154/156230 | loss: 1.0565 | ds_loss: 1.0733 | lr: 9.9487e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   7155/156230 | global iter:   7155/156230 | loss: 1.1472 | ds_loss: 1.1568 | lr: 9.9487e-05 | scale: 65536.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   7156/156230 | global iter:   7156/156230 | loss: 1.1518 | ds_loss: 1.1634 | lr: 9.9487e-05 | scale: 65536.0000 | micro time: 1.339 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7156/156230 | global iter:   7156/156230 | loss: 1.0658 | ds_loss: 1.0790 | lr: 9.9487e-05 | scale: 65536.0000 | micro time: 1.339 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7157/156230 | global iter:   7157/156230 | loss: 1.0634 | ds_loss: 1.0838 | lr: 9.9487e-05 | scale: 65536.0000 | micro time: 1.411 | step time: 0.000
train | epoch   0 | Iter:   7158/156230 | global iter:   7158/156230 | loss: 1.0929 | ds_loss: 1.0958 | lr: 9.9487e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   7159/156230 | global iter:   7159/156230 | loss: 1.1848 | ds_loss: 1.2121 | lr: 9.9486e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7160/156230 | global iter:   7160/156230 | loss: 1.0639 | ds_loss: 1.0949 | lr: 9.9486e-05 | scale: 65536.0000 | micro time: 1.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7160/156230 | global iter:   7160/156230 | loss: 1.1012 | ds_loss: 1.1216 | lr: 9.9486e-05 | scale: 65536.0000 | micro time: 1.394 | step time: 1.387
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7161/156230 | global iter:   7161/156230 | loss: 1.2923 | ds_loss: 1.3047 | lr: 9.9486e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   7162/156230 | global iter:   7162/156230 | loss: 1.1502 | ds_loss: 1.1669 | lr: 9.9486e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   7163/156230 | global iter:   7163/156230 | loss: 1.2975 | ds_loss: 1.3042 | lr: 9.9486e-05 | scale: 65536.0000 | micro time: 1.311 | step time: 0.000
train | epoch   0 | Iter:   7164/156230 | global iter:   7164/156230 | loss: 1.1770 | ds_loss: 1.1852 | lr: 9.9486e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7164/156230 | global iter:   7164/156230 | loss: 1.2292 | ds_loss: 1.2402 | lr: 9.9486e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7165/156230 | global iter:   7165/156230 | loss: 1.1329 | ds_loss: 1.1615 | lr: 9.9486e-05 | scale: 65536.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:   7166/156230 | global iter:   7166/156230 | loss: 1.0758 | ds_loss: 1.0906 | lr: 9.9485e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   7167/156230 | global iter:   7167/156230 | loss: 1.0812 | ds_loss: 1.0880 | lr: 9.9485e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7168/156230 | global iter:   7168/156230 | loss: 1.0653 | ds_loss: 1.0801 | lr: 9.9485e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7168/156230 | global iter:   7168/156230 | loss: 1.0888 | ds_loss: 1.1051 | lr: 9.9485e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 1.345
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7169/156230 | global iter:   7169/156230 | loss: 1.0719 | ds_loss: 1.0872 | lr: 9.9485e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   7170/156230 | global iter:   7170/156230 | loss: 1.1409 | ds_loss: 1.1785 | lr: 9.9485e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   7171/156230 | global iter:   7171/156230 | loss: 1.1486 | ds_loss: 1.1746 | lr: 9.9485e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7172/156230 | global iter:   7172/156230 | loss: 1.0946 | ds_loss: 1.1016 | lr: 9.9485e-05 | scale: 65536.0000 | micro time: 1.383 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7172/156230 | global iter:   7172/156230 | loss: 1.1140 | ds_loss: 1.1355 | lr: 9.9485e-05 | scale: 65536.0000 | micro time: 1.383 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7173/156230 | global iter:   7173/156230 | loss: 0.9687 | ds_loss: 0.9876 | lr: 9.9484e-05 | scale: 65536.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   7174/156230 | global iter:   7174/156230 | loss: 1.0714 | ds_loss: 1.0978 | lr: 9.9484e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   7175/156230 | global iter:   7175/156230 | loss: 0.9972 | ds_loss: 1.0083 | lr: 9.9484e-05 | scale: 65536.0000 | micro time: 1.314 | step time: 0.000
train | epoch   0 | Iter:   7176/156230 | global iter:   7176/156230 | loss: 1.1676 | ds_loss: 1.1943 | lr: 9.9484e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7176/156230 | global iter:   7176/156230 | loss: 1.0512 | ds_loss: 1.0720 | lr: 9.9484e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 1.339
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7177/156230 | global iter:   7177/156230 | loss: 0.9036 | ds_loss: 0.9281 | lr: 9.9484e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   7178/156230 | global iter:   7178/156230 | loss: 1.1707 | ds_loss: 1.1866 | lr: 9.9484e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   7179/156230 | global iter:   7179/156230 | loss: 1.1565 | ds_loss: 1.1910 | lr: 9.9484e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   7180/156230 | global iter:   7180/156230 | loss: 1.0703 | ds_loss: 1.0939 | lr: 9.9483e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7180/156230 | global iter:   7180/156230 | loss: 1.0753 | ds_loss: 1.0999 | lr: 9.9483e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 1.344
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7181/156230 | global iter:   7181/156230 | loss: 1.0920 | ds_loss: 1.1060 | lr: 9.9483e-05 | scale: 65536.0000 | micro time: 1.407 | step time: 0.000
train | epoch   0 | Iter:   7182/156230 | global iter:   7182/156230 | loss: 1.0625 | ds_loss: 1.0750 | lr: 9.9483e-05 | scale: 65536.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   7183/156230 | global iter:   7183/156230 | loss: 0.9904 | ds_loss: 0.9957 | lr: 9.9483e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   7184/156230 | global iter:   7184/156230 | loss: 1.1402 | ds_loss: 1.1682 | lr: 9.9483e-05 | scale: 65536.0000 | micro time: 1.391 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7184/156230 | global iter:   7184/156230 | loss: 1.0713 | ds_loss: 1.0862 | lr: 9.9483e-05 | scale: 65536.0000 | micro time: 1.391 | step time: 1.383
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7185/156230 | global iter:   7185/156230 | loss: 1.2508 | ds_loss: 1.2497 | lr: 9.9483e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   7186/156230 | global iter:   7186/156230 | loss: 1.1472 | ds_loss: 1.1765 | lr: 9.9483e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   7187/156230 | global iter:   7187/156230 | loss: 0.8809 | ds_loss: 0.8934 | lr: 9.9482e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   7188/156230 | global iter:   7188/156230 | loss: 0.9449 | ds_loss: 0.9650 | lr: 9.9482e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7188/156230 | global iter:   7188/156230 | loss: 1.0560 | ds_loss: 1.0712 | lr: 9.9482e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7189/156230 | global iter:   7189/156230 | loss: 1.0545 | ds_loss: 1.0761 | lr: 9.9482e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   7190/156230 | global iter:   7190/156230 | loss: 1.2576 | ds_loss: 1.2661 | lr: 9.9482e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   7191/156230 | global iter:   7191/156230 | loss: 1.0298 | ds_loss: 1.0628 | lr: 9.9482e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   7192/156230 | global iter:   7192/156230 | loss: 1.1388 | ds_loss: 1.1649 | lr: 9.9482e-05 | scale: 65536.0000 | micro time: 1.327 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7192/156230 | global iter:   7192/156230 | loss: 1.1202 | ds_loss: 1.1425 | lr: 9.9482e-05 | scale: 65536.0000 | micro time: 1.327 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7193/156230 | global iter:   7193/156230 | loss: 1.1085 | ds_loss: 1.1097 | lr: 9.9482e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   7194/156230 | global iter:   7194/156230 | loss: 1.1539 | ds_loss: 1.1622 | lr: 9.9481e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   7195/156230 | global iter:   7195/156230 | loss: 1.0154 | ds_loss: 1.0334 | lr: 9.9481e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   7196/156230 | global iter:   7196/156230 | loss: 1.0822 | ds_loss: 1.0928 | lr: 9.9481e-05 | scale: 65536.0000 | micro time: 1.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7196/156230 | global iter:   7196/156230 | loss: 1.0900 | ds_loss: 1.0995 | lr: 9.9481e-05 | scale: 65536.0000 | micro time: 1.396 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7197/156230 | global iter:   7197/156230 | loss: 1.2432 | ds_loss: 1.2599 | lr: 9.9481e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   7198/156230 | global iter:   7198/156230 | loss: 1.2384 | ds_loss: 1.2514 | lr: 9.9481e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   7199/156230 | global iter:   7199/156230 | loss: 1.2041 | ds_loss: 1.2207 | lr: 9.9481e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   7200/156230 | global iter:   7200/156230 | loss: 1.1368 | ds_loss: 1.1536 | lr: 9.9481e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7200/156230 | global iter:   7200/156230 | loss: 1.2056 | ds_loss: 1.2214 | lr: 9.9481e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7201/156230 | global iter:   7201/156230 | loss: 1.0155 | ds_loss: 1.0442 | lr: 9.9480e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   7202/156230 | global iter:   7202/156230 | loss: 1.1561 | ds_loss: 1.1724 | lr: 9.9480e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   7203/156230 | global iter:   7203/156230 | loss: 0.9954 | ds_loss: 1.0182 | lr: 9.9480e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7204/156230 | global iter:   7204/156230 | loss: 1.0834 | ds_loss: 1.1093 | lr: 9.9480e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7204/156230 | global iter:   7204/156230 | loss: 1.0626 | ds_loss: 1.0860 | lr: 9.9480e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7205/156230 | global iter:   7205/156230 | loss: 0.9637 | ds_loss: 0.9779 | lr: 9.9480e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7206/156230 | global iter:   7206/156230 | loss: 0.9826 | ds_loss: 0.9997 | lr: 9.9480e-05 | scale: 65536.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   7207/156230 | global iter:   7207/156230 | loss: 1.0558 | ds_loss: 1.0672 | lr: 9.9480e-05 | scale: 65536.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   7208/156230 | global iter:   7208/156230 | loss: 1.0049 | ds_loss: 1.0317 | lr: 9.9479e-05 | scale: 65536.0000 | micro time: 1.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7208/156230 | global iter:   7208/156230 | loss: 1.0018 | ds_loss: 1.0191 | lr: 9.9479e-05 | scale: 65536.0000 | micro time: 1.394 | step time: 1.389
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7209/156230 | global iter:   7209/156230 | loss: 1.0454 | ds_loss: 1.0685 | lr: 9.9479e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7210/156230 | global iter:   7210/156230 | loss: 1.0384 | ds_loss: 1.0635 | lr: 9.9479e-05 | scale: 65536.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   7211/156230 | global iter:   7211/156230 | loss: 1.2141 | ds_loss: 1.2126 | lr: 9.9479e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   7212/156230 | global iter:   7212/156230 | loss: 1.2741 | ds_loss: 1.2801 | lr: 9.9479e-05 | scale: 65536.0000 | micro time: 1.387 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7212/156230 | global iter:   7212/156230 | loss: 1.1430 | ds_loss: 1.1562 | lr: 9.9479e-05 | scale: 65536.0000 | micro time: 1.387 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7213/156230 | global iter:   7213/156230 | loss: 1.0064 | ds_loss: 1.0337 | lr: 9.9479e-05 | scale: 65536.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   7214/156230 | global iter:   7214/156230 | loss: 1.1081 | ds_loss: 1.1316 | lr: 9.9479e-05 | scale: 65536.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   7215/156230 | global iter:   7215/156230 | loss: 1.0960 | ds_loss: 1.1054 | lr: 9.9478e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   7216/156230 | global iter:   7216/156230 | loss: 0.9915 | ds_loss: 1.0065 | lr: 9.9478e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7216/156230 | global iter:   7216/156230 | loss: 1.0505 | ds_loss: 1.0693 | lr: 9.9478e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7217/156230 | global iter:   7217/156230 | loss: 0.9030 | ds_loss: 0.9221 | lr: 9.9478e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   7218/156230 | global iter:   7218/156230 | loss: 1.0000 | ds_loss: 0.9994 | lr: 9.9478e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   7219/156230 | global iter:   7219/156230 | loss: 1.0810 | ds_loss: 1.0981 | lr: 9.9478e-05 | scale: 65536.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   7220/156230 | global iter:   7220/156230 | loss: 1.0030 | ds_loss: 1.0307 | lr: 9.9478e-05 | scale: 65536.0000 | micro time: 1.402 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7220/156230 | global iter:   7220/156230 | loss: 0.9968 | ds_loss: 1.0126 | lr: 9.9478e-05 | scale: 65536.0000 | micro time: 1.402 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7221/156230 | global iter:   7221/156230 | loss: 1.1962 | ds_loss: 1.1972 | lr: 9.9478e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   7222/156230 | global iter:   7222/156230 | loss: 1.1884 | ds_loss: 1.2061 | lr: 9.9477e-05 | scale: 65536.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   7223/156230 | global iter:   7223/156230 | loss: 1.1661 | ds_loss: 1.1769 | lr: 9.9477e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   7224/156230 | global iter:   7224/156230 | loss: 1.0842 | ds_loss: 1.0988 | lr: 9.9477e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7224/156230 | global iter:   7224/156230 | loss: 1.1587 | ds_loss: 1.1697 | lr: 9.9477e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7225/156230 | global iter:   7225/156230 | loss: 0.9860 | ds_loss: 0.9966 | lr: 9.9477e-05 | scale: 65536.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   7226/156230 | global iter:   7226/156230 | loss: 1.3458 | ds_loss: 1.3639 | lr: 9.9477e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   7227/156230 | global iter:   7227/156230 | loss: 1.1794 | ds_loss: 1.2096 | lr: 9.9477e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   7228/156230 | global iter:   7228/156230 | loss: 0.9250 | ds_loss: 0.9463 | lr: 9.9477e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7228/156230 | global iter:   7228/156230 | loss: 1.1090 | ds_loss: 1.1291 | lr: 9.9477e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7229/156230 | global iter:   7229/156230 | loss: 1.0398 | ds_loss: 1.0610 | lr: 9.9476e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   7230/156230 | global iter:   7230/156230 | loss: 1.0951 | ds_loss: 1.1180 | lr: 9.9476e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   7231/156230 | global iter:   7231/156230 | loss: 1.0820 | ds_loss: 1.1173 | lr: 9.9476e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   7232/156230 | global iter:   7232/156230 | loss: 1.0103 | ds_loss: 1.0439 | lr: 9.9476e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7232/156230 | global iter:   7232/156230 | loss: 1.0568 | ds_loss: 1.0850 | lr: 9.9476e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7233/156230 | global iter:   7233/156230 | loss: 1.0048 | ds_loss: 1.0196 | lr: 9.9476e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   7234/156230 | global iter:   7234/156230 | loss: 1.1678 | ds_loss: 1.1815 | lr: 9.9476e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   7235/156230 | global iter:   7235/156230 | loss: 0.9765 | ds_loss: 0.9866 | lr: 9.9475e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   7236/156230 | global iter:   7236/156230 | loss: 1.2287 | ds_loss: 1.2502 | lr: 9.9475e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7236/156230 | global iter:   7236/156230 | loss: 1.0945 | ds_loss: 1.1095 | lr: 9.9475e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7237/156230 | global iter:   7237/156230 | loss: 1.0597 | ds_loss: 1.0684 | lr: 9.9475e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   7238/156230 | global iter:   7238/156230 | loss: 1.0241 | ds_loss: 1.0292 | lr: 9.9475e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   7239/156230 | global iter:   7239/156230 | loss: 1.2355 | ds_loss: 1.2481 | lr: 9.9475e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   7240/156230 | global iter:   7240/156230 | loss: 1.1824 | ds_loss: 1.2050 | lr: 9.9475e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7240/156230 | global iter:   7240/156230 | loss: 1.1254 | ds_loss: 1.1377 | lr: 9.9475e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7241/156230 | global iter:   7241/156230 | loss: 1.1344 | ds_loss: 1.1519 | lr: 9.9475e-05 | scale: 65536.0000 | micro time: 1.411 | step time: 0.000
train | epoch   0 | Iter:   7242/156230 | global iter:   7242/156230 | loss: 1.2336 | ds_loss: 1.2601 | lr: 9.9474e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   7243/156230 | global iter:   7243/156230 | loss: 1.1912 | ds_loss: 1.2321 | lr: 9.9474e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7244/156230 | global iter:   7244/156230 | loss: 0.9878 | ds_loss: 1.0070 | lr: 9.9474e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7244/156230 | global iter:   7244/156230 | loss: 1.1368 | ds_loss: 1.1628 | lr: 9.9474e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7245/156230 | global iter:   7245/156230 | loss: 1.0282 | ds_loss: 1.0345 | lr: 9.9474e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   7246/156230 | global iter:   7246/156230 | loss: 1.1541 | ds_loss: 1.1594 | lr: 9.9474e-05 | scale: 65536.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   7247/156230 | global iter:   7247/156230 | loss: 0.9229 | ds_loss: 0.9350 | lr: 9.9474e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   7248/156230 | global iter:   7248/156230 | loss: 1.0675 | ds_loss: 1.0793 | lr: 9.9474e-05 | scale: 65536.0000 | micro time: 1.313 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7248/156230 | global iter:   7248/156230 | loss: 1.0432 | ds_loss: 1.0521 | lr: 9.9474e-05 | scale: 65536.0000 | micro time: 1.313 | step time: 1.346
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7249/156230 | global iter:   7249/156230 | loss: 1.1748 | ds_loss: 1.1861 | lr: 9.9473e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   7250/156230 | global iter:   7250/156230 | loss: 1.2384 | ds_loss: 1.2604 | lr: 9.9473e-05 | scale: 65536.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   7251/156230 | global iter:   7251/156230 | loss: 1.2110 | ds_loss: 1.2228 | lr: 9.9473e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   7252/156230 | global iter:   7252/156230 | loss: 1.0993 | ds_loss: 1.1192 | lr: 9.9473e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7252/156230 | global iter:   7252/156230 | loss: 1.1809 | ds_loss: 1.1971 | lr: 9.9473e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7253/156230 | global iter:   7253/156230 | loss: 1.0402 | ds_loss: 1.0506 | lr: 9.9473e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   7254/156230 | global iter:   7254/156230 | loss: 0.9938 | ds_loss: 1.0178 | lr: 9.9473e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   7255/156230 | global iter:   7255/156230 | loss: 1.1770 | ds_loss: 1.1859 | lr: 9.9473e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   7256/156230 | global iter:   7256/156230 | loss: 1.3541 | ds_loss: 1.3718 | lr: 9.9472e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7256/156230 | global iter:   7256/156230 | loss: 1.1413 | ds_loss: 1.1565 | lr: 9.9472e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7257/156230 | global iter:   7257/156230 | loss: 0.9289 | ds_loss: 0.9520 | lr: 9.9472e-05 | scale: 65536.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   7258/156230 | global iter:   7258/156230 | loss: 1.2420 | ds_loss: 1.2515 | lr: 9.9472e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   7259/156230 | global iter:   7259/156230 | loss: 1.1406 | ds_loss: 1.1539 | lr: 9.9472e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   7260/156230 | global iter:   7260/156230 | loss: 1.1035 | ds_loss: 1.1099 | lr: 9.9472e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7260/156230 | global iter:   7260/156230 | loss: 1.1038 | ds_loss: 1.1168 | lr: 9.9472e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7261/156230 | global iter:   7261/156230 | loss: 1.1033 | ds_loss: 1.1183 | lr: 9.9472e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   7262/156230 | global iter:   7262/156230 | loss: 1.1102 | ds_loss: 1.1340 | lr: 9.9472e-05 | scale: 65536.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   7263/156230 | global iter:   7263/156230 | loss: 1.1947 | ds_loss: 1.2120 | lr: 9.9471e-05 | scale: 65536.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:   7264/156230 | global iter:   7264/156230 | loss: 0.9618 | ds_loss: 0.9776 | lr: 9.9471e-05 | scale: 65536.0000 | micro time: 1.327 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7264/156230 | global iter:   7264/156230 | loss: 1.0925 | ds_loss: 1.1105 | lr: 9.9471e-05 | scale: 65536.0000 | micro time: 1.327 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7265/156230 | global iter:   7265/156230 | loss: 1.2062 | ds_loss: 1.2290 | lr: 9.9471e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   7266/156230 | global iter:   7266/156230 | loss: 0.8613 | ds_loss: 0.8776 | lr: 9.9471e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   7267/156230 | global iter:   7267/156230 | loss: 1.1131 | ds_loss: 1.1326 | lr: 9.9471e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   7268/156230 | global iter:   7268/156230 | loss: 1.2570 | ds_loss: 1.2836 | lr: 9.9471e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7268/156230 | global iter:   7268/156230 | loss: 1.1094 | ds_loss: 1.1307 | lr: 9.9471e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7269/156230 | global iter:   7269/156230 | loss: 1.1040 | ds_loss: 1.1158 | lr: 9.9471e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   7270/156230 | global iter:   7270/156230 | loss: 0.9835 | ds_loss: 1.0106 | lr: 9.9470e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   7271/156230 | global iter:   7271/156230 | loss: 1.0176 | ds_loss: 1.0346 | lr: 9.9470e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   7272/156230 | global iter:   7272/156230 | loss: 1.1515 | ds_loss: 1.1807 | lr: 9.9470e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7272/156230 | global iter:   7272/156230 | loss: 1.0641 | ds_loss: 1.0854 | lr: 9.9470e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7273/156230 | global iter:   7273/156230 | loss: 0.9724 | ds_loss: 0.9900 | lr: 9.9470e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   7274/156230 | global iter:   7274/156230 | loss: 1.0687 | ds_loss: 1.0850 | lr: 9.9470e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   7275/156230 | global iter:   7275/156230 | loss: 1.2091 | ds_loss: 1.2279 | lr: 9.9470e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   7276/156230 | global iter:   7276/156230 | loss: 1.2337 | ds_loss: 1.2565 | lr: 9.9470e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7276/156230 | global iter:   7276/156230 | loss: 1.1210 | ds_loss: 1.1399 | lr: 9.9470e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7277/156230 | global iter:   7277/156230 | loss: 1.0910 | ds_loss: 1.1133 | lr: 9.9469e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   7278/156230 | global iter:   7278/156230 | loss: 1.0924 | ds_loss: 1.1143 | lr: 9.9469e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   7279/156230 | global iter:   7279/156230 | loss: 1.1450 | ds_loss: 1.1788 | lr: 9.9469e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   7280/156230 | global iter:   7280/156230 | loss: 0.9965 | ds_loss: 1.0095 | lr: 9.9469e-05 | scale: 65536.0000 | micro time: 1.406 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7280/156230 | global iter:   7280/156230 | loss: 1.0812 | ds_loss: 1.1039 | lr: 9.9469e-05 | scale: 65536.0000 | micro time: 1.406 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7281/156230 | global iter:   7281/156230 | loss: 1.0664 | ds_loss: 1.0730 | lr: 9.9469e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   7282/156230 | global iter:   7282/156230 | loss: 1.0970 | ds_loss: 1.1165 | lr: 9.9469e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   7283/156230 | global iter:   7283/156230 | loss: 1.1585 | ds_loss: 1.1798 | lr: 9.9469e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   7284/156230 | global iter:   7284/156230 | loss: 1.0485 | ds_loss: 1.0641 | lr: 9.9468e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7284/156230 | global iter:   7284/156230 | loss: 1.0926 | ds_loss: 1.1083 | lr: 9.9468e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7285/156230 | global iter:   7285/156230 | loss: 1.0035 | ds_loss: 1.0369 | lr: 9.9468e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   7286/156230 | global iter:   7286/156230 | loss: 0.9651 | ds_loss: 0.9888 | lr: 9.9468e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7287/156230 | global iter:   7287/156230 | loss: 0.8782 | ds_loss: 0.8902 | lr: 9.9468e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   7288/156230 | global iter:   7288/156230 | loss: 1.1233 | ds_loss: 1.1432 | lr: 9.9468e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7288/156230 | global iter:   7288/156230 | loss: 0.9925 | ds_loss: 1.0148 | lr: 9.9468e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7289/156230 | global iter:   7289/156230 | loss: 1.1937 | ds_loss: 1.2143 | lr: 9.9468e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   7290/156230 | global iter:   7290/156230 | loss: 1.2642 | ds_loss: 1.2884 | lr: 9.9467e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   7291/156230 | global iter:   7291/156230 | loss: 0.9858 | ds_loss: 0.9960 | lr: 9.9467e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   7292/156230 | global iter:   7292/156230 | loss: 1.2115 | ds_loss: 1.2254 | lr: 9.9467e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7292/156230 | global iter:   7292/156230 | loss: 1.1638 | ds_loss: 1.1810 | lr: 9.9467e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7293/156230 | global iter:   7293/156230 | loss: 1.1771 | ds_loss: 1.1991 | lr: 9.9467e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   7294/156230 | global iter:   7294/156230 | loss: 1.1636 | ds_loss: 1.1787 | lr: 9.9467e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   7295/156230 | global iter:   7295/156230 | loss: 1.3340 | ds_loss: 1.3520 | lr: 9.9467e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   7296/156230 | global iter:   7296/156230 | loss: 1.2806 | ds_loss: 1.3022 | lr: 9.9467e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7296/156230 | global iter:   7296/156230 | loss: 1.2388 | ds_loss: 1.2580 | lr: 9.9467e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7297/156230 | global iter:   7297/156230 | loss: 1.3074 | ds_loss: 1.3232 | lr: 9.9466e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   7298/156230 | global iter:   7298/156230 | loss: 0.9022 | ds_loss: 0.9180 | lr: 9.9466e-05 | scale: 65536.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   7299/156230 | global iter:   7299/156230 | loss: 0.9153 | ds_loss: 0.9363 | lr: 9.9466e-05 | scale: 65536.0000 | micro time: 1.417 | step time: 0.000
train | epoch   0 | Iter:   7300/156230 | global iter:   7300/156230 | loss: 1.0451 | ds_loss: 1.0505 | lr: 9.9466e-05 | scale: 65536.0000 | micro time: 1.326 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7300/156230 | global iter:   7300/156230 | loss: 1.0425 | ds_loss: 1.0570 | lr: 9.9466e-05 | scale: 65536.0000 | micro time: 1.326 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7301/156230 | global iter:   7301/156230 | loss: 1.0910 | ds_loss: 1.1136 | lr: 9.9466e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   7302/156230 | global iter:   7302/156230 | loss: 1.0485 | ds_loss: 1.0830 | lr: 9.9466e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   7303/156230 | global iter:   7303/156230 | loss: 1.1744 | ds_loss: 1.1850 | lr: 9.9466e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   7304/156230 | global iter:   7304/156230 | loss: 1.1321 | ds_loss: 1.1295 | lr: 9.9465e-05 | scale: 65536.0000 | micro time: 1.389 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7304/156230 | global iter:   7304/156230 | loss: 1.1115 | ds_loss: 1.1277 | lr: 9.9465e-05 | scale: 65536.0000 | micro time: 1.389 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7305/156230 | global iter:   7305/156230 | loss: 1.0737 | ds_loss: 1.0964 | lr: 9.9465e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   7306/156230 | global iter:   7306/156230 | loss: 0.9575 | ds_loss: 0.9793 | lr: 9.9465e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   7307/156230 | global iter:   7307/156230 | loss: 1.2431 | ds_loss: 1.2654 | lr: 9.9465e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   7308/156230 | global iter:   7308/156230 | loss: 1.0963 | ds_loss: 1.1104 | lr: 9.9465e-05 | scale: 65536.0000 | micro time: 1.388 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7308/156230 | global iter:   7308/156230 | loss: 1.0926 | ds_loss: 1.1129 | lr: 9.9465e-05 | scale: 65536.0000 | micro time: 1.388 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7309/156230 | global iter:   7309/156230 | loss: 1.3041 | ds_loss: 1.3152 | lr: 9.9465e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   7310/156230 | global iter:   7310/156230 | loss: 1.1140 | ds_loss: 1.1488 | lr: 9.9465e-05 | scale: 65536.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   7311/156230 | global iter:   7311/156230 | loss: 1.0313 | ds_loss: 1.0400 | lr: 9.9464e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   7312/156230 | global iter:   7312/156230 | loss: 1.1550 | ds_loss: 1.1782 | lr: 9.9464e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7312/156230 | global iter:   7312/156230 | loss: 1.1511 | ds_loss: 1.1706 | lr: 9.9464e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7313/156230 | global iter:   7313/156230 | loss: 1.1852 | ds_loss: 1.2138 | lr: 9.9464e-05 | scale: 65536.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   7314/156230 | global iter:   7314/156230 | loss: 1.1145 | ds_loss: 1.1236 | lr: 9.9464e-05 | scale: 65536.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   7315/156230 | global iter:   7315/156230 | loss: 1.1376 | ds_loss: 1.1632 | lr: 9.9464e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   7316/156230 | global iter:   7316/156230 | loss: 1.0034 | ds_loss: 1.0366 | lr: 9.9464e-05 | scale: 65536.0000 | micro time: 1.405 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7316/156230 | global iter:   7316/156230 | loss: 1.1102 | ds_loss: 1.1343 | lr: 9.9464e-05 | scale: 65536.0000 | micro time: 1.405 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7317/156230 | global iter:   7317/156230 | loss: 1.1682 | ds_loss: 1.1697 | lr: 9.9464e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   7318/156230 | global iter:   7318/156230 | loss: 1.1226 | ds_loss: 1.1294 | lr: 9.9463e-05 | scale: 65536.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   7319/156230 | global iter:   7319/156230 | loss: 1.1445 | ds_loss: 1.1717 | lr: 9.9463e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   7320/156230 | global iter:   7320/156230 | loss: 1.0418 | ds_loss: 1.0740 | lr: 9.9463e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7320/156230 | global iter:   7320/156230 | loss: 1.1193 | ds_loss: 1.1362 | lr: 9.9463e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7321/156230 | global iter:   7321/156230 | loss: 0.9469 | ds_loss: 0.9613 | lr: 9.9463e-05 | scale: 65536.0000 | micro time: 1.411 | step time: 0.000
train | epoch   0 | Iter:   7322/156230 | global iter:   7322/156230 | loss: 1.0887 | ds_loss: 1.1099 | lr: 9.9463e-05 | scale: 65536.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   7323/156230 | global iter:   7323/156230 | loss: 1.1020 | ds_loss: 1.1288 | lr: 9.9463e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   7324/156230 | global iter:   7324/156230 | loss: 0.9624 | ds_loss: 0.9870 | lr: 9.9462e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7324/156230 | global iter:   7324/156230 | loss: 1.0250 | ds_loss: 1.0468 | lr: 9.9462e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7325/156230 | global iter:   7325/156230 | loss: 1.1832 | ds_loss: 1.1847 | lr: 9.9462e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   7326/156230 | global iter:   7326/156230 | loss: 1.0527 | ds_loss: 1.0669 | lr: 9.9462e-05 | scale: 65536.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   7327/156230 | global iter:   7327/156230 | loss: 1.0983 | ds_loss: 1.1145 | lr: 9.9462e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   7328/156230 | global iter:   7328/156230 | loss: 1.2272 | ds_loss: 1.2513 | lr: 9.9462e-05 | scale: 65536.0000 | micro time: 1.389 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7328/156230 | global iter:   7328/156230 | loss: 1.1403 | ds_loss: 1.1544 | lr: 9.9462e-05 | scale: 65536.0000 | micro time: 1.389 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7329/156230 | global iter:   7329/156230 | loss: 1.2556 | ds_loss: 1.2958 | lr: 9.9462e-05 | scale: 65536.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   7330/156230 | global iter:   7330/156230 | loss: 1.0466 | ds_loss: 1.0575 | lr: 9.9462e-05 | scale: 65536.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   7331/156230 | global iter:   7331/156230 | loss: 0.9926 | ds_loss: 1.0149 | lr: 9.9461e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   7332/156230 | global iter:   7332/156230 | loss: 1.0892 | ds_loss: 1.1182 | lr: 9.9461e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7332/156230 | global iter:   7332/156230 | loss: 1.0960 | ds_loss: 1.1216 | lr: 9.9461e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 1.341
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7333/156230 | global iter:   7333/156230 | loss: 1.0379 | ds_loss: 1.0574 | lr: 9.9461e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   7334/156230 | global iter:   7334/156230 | loss: 1.1078 | ds_loss: 1.1553 | lr: 9.9461e-05 | scale: 65536.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   7335/156230 | global iter:   7335/156230 | loss: 1.2149 | ds_loss: 1.2245 | lr: 9.9461e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   7336/156230 | global iter:   7336/156230 | loss: 1.0831 | ds_loss: 1.1213 | lr: 9.9461e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7336/156230 | global iter:   7336/156230 | loss: 1.1109 | ds_loss: 1.1396 | lr: 9.9461e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7337/156230 | global iter:   7337/156230 | loss: 1.1030 | ds_loss: 1.1103 | lr: 9.9461e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7338/156230 | global iter:   7338/156230 | loss: 1.1448 | ds_loss: 1.1802 | lr: 9.9460e-05 | scale: 65536.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   7339/156230 | global iter:   7339/156230 | loss: 1.1032 | ds_loss: 1.1473 | lr: 9.9460e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   7340/156230 | global iter:   7340/156230 | loss: 1.0904 | ds_loss: 1.1072 | lr: 9.9460e-05 | scale: 65536.0000 | micro time: 1.331 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7340/156230 | global iter:   7340/156230 | loss: 1.1104 | ds_loss: 1.1363 | lr: 9.9460e-05 | scale: 65536.0000 | micro time: 1.331 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7341/156230 | global iter:   7341/156230 | loss: 1.0822 | ds_loss: 1.0995 | lr: 9.9460e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   7342/156230 | global iter:   7342/156230 | loss: 0.9695 | ds_loss: 0.9990 | lr: 9.9460e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7343/156230 | global iter:   7343/156230 | loss: 1.2830 | ds_loss: 1.3190 | lr: 9.9460e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7344/156230 | global iter:   7344/156230 | loss: 1.1175 | ds_loss: 1.1407 | lr: 9.9460e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7344/156230 | global iter:   7344/156230 | loss: 1.1130 | ds_loss: 1.1395 | lr: 9.9460e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7345/156230 | global iter:   7345/156230 | loss: 1.1563 | ds_loss: 1.1688 | lr: 9.9459e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   7346/156230 | global iter:   7346/156230 | loss: 1.1288 | ds_loss: 1.1415 | lr: 9.9459e-05 | scale: 65536.0000 | micro time: 1.400 | step time: 0.000
train | epoch   0 | Iter:   7347/156230 | global iter:   7347/156230 | loss: 1.1406 | ds_loss: 1.1625 | lr: 9.9459e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   7348/156230 | global iter:   7348/156230 | loss: 0.9589 | ds_loss: 0.9644 | lr: 9.9459e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7348/156230 | global iter:   7348/156230 | loss: 1.0961 | ds_loss: 1.1093 | lr: 9.9459e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7349/156230 | global iter:   7349/156230 | loss: 1.2966 | ds_loss: 1.3164 | lr: 9.9459e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   7350/156230 | global iter:   7350/156230 | loss: 0.9379 | ds_loss: 0.9642 | lr: 9.9459e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   7351/156230 | global iter:   7351/156230 | loss: 1.1426 | ds_loss: 1.1767 | lr: 9.9459e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   7352/156230 | global iter:   7352/156230 | loss: 1.1305 | ds_loss: 1.1452 | lr: 9.9458e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7352/156230 | global iter:   7352/156230 | loss: 1.1269 | ds_loss: 1.1506 | lr: 9.9458e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7353/156230 | global iter:   7353/156230 | loss: 1.2102 | ds_loss: 1.2282 | lr: 9.9458e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   7354/156230 | global iter:   7354/156230 | loss: 1.1947 | ds_loss: 1.2104 | lr: 9.9458e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   7355/156230 | global iter:   7355/156230 | loss: 1.1596 | ds_loss: 1.1918 | lr: 9.9458e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   7356/156230 | global iter:   7356/156230 | loss: 1.0878 | ds_loss: 1.1057 | lr: 9.9458e-05 | scale: 65536.0000 | micro time: 1.326 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7356/156230 | global iter:   7356/156230 | loss: 1.1631 | ds_loss: 1.1840 | lr: 9.9458e-05 | scale: 65536.0000 | micro time: 1.326 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7357/156230 | global iter:   7357/156230 | loss: 0.9016 | ds_loss: 0.9030 | lr: 9.9458e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   7358/156230 | global iter:   7358/156230 | loss: 1.1986 | ds_loss: 1.1976 | lr: 9.9457e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   7359/156230 | global iter:   7359/156230 | loss: 0.8998 | ds_loss: 0.9233 | lr: 9.9457e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   7360/156230 | global iter:   7360/156230 | loss: 1.0580 | ds_loss: 1.0649 | lr: 9.9457e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7360/156230 | global iter:   7360/156230 | loss: 1.0145 | ds_loss: 1.0222 | lr: 9.9457e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7361/156230 | global iter:   7361/156230 | loss: 1.1200 | ds_loss: 1.1153 | lr: 9.9457e-05 | scale: 65536.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   7362/156230 | global iter:   7362/156230 | loss: 1.0360 | ds_loss: 1.0601 | lr: 9.9457e-05 | scale: 65536.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   7363/156230 | global iter:   7363/156230 | loss: 1.1540 | ds_loss: 1.1705 | lr: 9.9457e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   7364/156230 | global iter:   7364/156230 | loss: 1.0178 | ds_loss: 1.0351 | lr: 9.9457e-05 | scale: 65536.0000 | micro time: 1.333 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7364/156230 | global iter:   7364/156230 | loss: 1.0820 | ds_loss: 1.0953 | lr: 9.9457e-05 | scale: 65536.0000 | micro time: 1.333 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7365/156230 | global iter:   7365/156230 | loss: 1.1587 | ds_loss: 1.1957 | lr: 9.9456e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   7366/156230 | global iter:   7366/156230 | loss: 1.1158 | ds_loss: 1.1302 | lr: 9.9456e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   7367/156230 | global iter:   7367/156230 | loss: 1.0258 | ds_loss: 1.0496 | lr: 9.9456e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   7368/156230 | global iter:   7368/156230 | loss: 1.1426 | ds_loss: 1.1628 | lr: 9.9456e-05 | scale: 65536.0000 | micro time: 1.314 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7368/156230 | global iter:   7368/156230 | loss: 1.1107 | ds_loss: 1.1346 | lr: 9.9456e-05 | scale: 65536.0000 | micro time: 1.314 | step time: 1.333
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7369/156230 | global iter:   7369/156230 | loss: 1.0552 | ds_loss: 1.0716 | lr: 9.9456e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   7370/156230 | global iter:   7370/156230 | loss: 1.2274 | ds_loss: 1.2333 | lr: 9.9456e-05 | scale: 65536.0000 | micro time: 1.305 | step time: 0.000
train | epoch   0 | Iter:   7371/156230 | global iter:   7371/156230 | loss: 1.1134 | ds_loss: 1.1282 | lr: 9.9456e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   7372/156230 | global iter:   7372/156230 | loss: 0.9080 | ds_loss: 0.9242 | lr: 9.9455e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7372/156230 | global iter:   7372/156230 | loss: 1.0760 | ds_loss: 1.0893 | lr: 9.9455e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7373/156230 | global iter:   7373/156230 | loss: 1.0173 | ds_loss: 1.0325 | lr: 9.9455e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   7374/156230 | global iter:   7374/156230 | loss: 0.9762 | ds_loss: 0.9789 | lr: 9.9455e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   7375/156230 | global iter:   7375/156230 | loss: 0.9850 | ds_loss: 1.0091 | lr: 9.9455e-05 | scale: 65536.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   7376/156230 | global iter:   7376/156230 | loss: 0.9953 | ds_loss: 1.0101 | lr: 9.9455e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7376/156230 | global iter:   7376/156230 | loss: 0.9934 | ds_loss: 1.0077 | lr: 9.9455e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7377/156230 | global iter:   7377/156230 | loss: 1.1495 | ds_loss: 1.1708 | lr: 9.9455e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   7378/156230 | global iter:   7378/156230 | loss: 1.0083 | ds_loss: 1.0091 | lr: 9.9455e-05 | scale: 65536.0000 | micro time: 1.320 | step time: 0.000
train | epoch   0 | Iter:   7379/156230 | global iter:   7379/156230 | loss: 0.9429 | ds_loss: 0.9545 | lr: 9.9454e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   7380/156230 | global iter:   7380/156230 | loss: 1.1184 | ds_loss: 1.1497 | lr: 9.9454e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7380/156230 | global iter:   7380/156230 | loss: 1.0548 | ds_loss: 1.0710 | lr: 9.9454e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 1.348
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7381/156230 | global iter:   7381/156230 | loss: 1.0740 | ds_loss: 1.0613 | lr: 9.9454e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   7382/156230 | global iter:   7382/156230 | loss: 1.2498 | ds_loss: 1.2692 | lr: 9.9454e-05 | scale: 65536.0000 | micro time: 1.318 | step time: 0.000
train | epoch   0 | Iter:   7383/156230 | global iter:   7383/156230 | loss: 1.0281 | ds_loss: 1.0428 | lr: 9.9454e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   7384/156230 | global iter:   7384/156230 | loss: 0.9851 | ds_loss: 1.0086 | lr: 9.9454e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7384/156230 | global iter:   7384/156230 | loss: 1.0843 | ds_loss: 1.0955 | lr: 9.9454e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7385/156230 | global iter:   7385/156230 | loss: 1.0166 | ds_loss: 1.0454 | lr: 9.9453e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   7386/156230 | global iter:   7386/156230 | loss: 0.9753 | ds_loss: 1.0049 | lr: 9.9453e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   7387/156230 | global iter:   7387/156230 | loss: 1.0360 | ds_loss: 1.0600 | lr: 9.9453e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   7388/156230 | global iter:   7388/156230 | loss: 0.9939 | ds_loss: 1.0316 | lr: 9.9453e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7388/156230 | global iter:   7388/156230 | loss: 1.0054 | ds_loss: 1.0355 | lr: 9.9453e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7389/156230 | global iter:   7389/156230 | loss: 1.2348 | ds_loss: 1.2510 | lr: 9.9453e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   7390/156230 | global iter:   7390/156230 | loss: 1.1801 | ds_loss: 1.1872 | lr: 9.9453e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   7391/156230 | global iter:   7391/156230 | loss: 1.1205 | ds_loss: 1.1481 | lr: 9.9453e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   7392/156230 | global iter:   7392/156230 | loss: 1.1885 | ds_loss: 1.2105 | lr: 9.9452e-05 | scale: 65536.0000 | micro time: 1.398 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7392/156230 | global iter:   7392/156230 | loss: 1.1810 | ds_loss: 1.1992 | lr: 9.9452e-05 | scale: 65536.0000 | micro time: 1.398 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7393/156230 | global iter:   7393/156230 | loss: 1.2721 | ds_loss: 1.2880 | lr: 9.9452e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   7394/156230 | global iter:   7394/156230 | loss: 1.0343 | ds_loss: 1.0476 | lr: 9.9452e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   7395/156230 | global iter:   7395/156230 | loss: 1.2024 | ds_loss: 1.2146 | lr: 9.9452e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   7396/156230 | global iter:   7396/156230 | loss: 0.9320 | ds_loss: 0.9568 | lr: 9.9452e-05 | scale: 65536.0000 | micro time: 1.329 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7396/156230 | global iter:   7396/156230 | loss: 1.1102 | ds_loss: 1.1268 | lr: 9.9452e-05 | scale: 65536.0000 | micro time: 1.329 | step time: 1.348
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7397/156230 | global iter:   7397/156230 | loss: 1.2909 | ds_loss: 1.3027 | lr: 9.9452e-05 | scale: 65536.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   7398/156230 | global iter:   7398/156230 | loss: 0.9963 | ds_loss: 1.0198 | lr: 9.9452e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   7399/156230 | global iter:   7399/156230 | loss: 0.9072 | ds_loss: 0.9127 | lr: 9.9451e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   7400/156230 | global iter:   7400/156230 | loss: 1.1408 | ds_loss: 1.1687 | lr: 9.9451e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7400/156230 | global iter:   7400/156230 | loss: 1.0838 | ds_loss: 1.1010 | lr: 9.9451e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7401/156230 | global iter:   7401/156230 | loss: 1.0261 | ds_loss: 1.0402 | lr: 9.9451e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   7402/156230 | global iter:   7402/156230 | loss: 1.0760 | ds_loss: 1.0881 | lr: 9.9451e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   7403/156230 | global iter:   7403/156230 | loss: 1.1085 | ds_loss: 1.1279 | lr: 9.9451e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   7404/156230 | global iter:   7404/156230 | loss: 0.9997 | ds_loss: 1.0083 | lr: 9.9451e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7404/156230 | global iter:   7404/156230 | loss: 1.0526 | ds_loss: 1.0661 | lr: 9.9451e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7405/156230 | global iter:   7405/156230 | loss: 1.0607 | ds_loss: 1.0927 | lr: 9.9451e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   7406/156230 | global iter:   7406/156230 | loss: 1.1163 | ds_loss: 1.1342 | lr: 9.9450e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   7407/156230 | global iter:   7407/156230 | loss: 0.9028 | ds_loss: 0.9359 | lr: 9.9450e-05 | scale: 65536.0000 | micro time: 1.325 | step time: 0.000
train | epoch   0 | Iter:   7408/156230 | global iter:   7408/156230 | loss: 1.0600 | ds_loss: 1.0883 | lr: 9.9450e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7408/156230 | global iter:   7408/156230 | loss: 1.0350 | ds_loss: 1.0627 | lr: 9.9450e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7409/156230 | global iter:   7409/156230 | loss: 1.0720 | ds_loss: 1.0937 | lr: 9.9450e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   7410/156230 | global iter:   7410/156230 | loss: 1.0146 | ds_loss: 1.0507 | lr: 9.9450e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   7411/156230 | global iter:   7411/156230 | loss: 1.0383 | ds_loss: 1.0712 | lr: 9.9450e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   7412/156230 | global iter:   7412/156230 | loss: 1.1187 | ds_loss: 1.1262 | lr: 9.9449e-05 | scale: 65536.0000 | micro time: 1.390 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7412/156230 | global iter:   7412/156230 | loss: 1.0609 | ds_loss: 1.0855 | lr: 9.9449e-05 | scale: 65536.0000 | micro time: 1.390 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7413/156230 | global iter:   7413/156230 | loss: 1.0716 | ds_loss: 1.0748 | lr: 9.9449e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   7414/156230 | global iter:   7414/156230 | loss: 1.1044 | ds_loss: 1.1370 | lr: 9.9449e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   7415/156230 | global iter:   7415/156230 | loss: 1.0811 | ds_loss: 1.0875 | lr: 9.9449e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   7416/156230 | global iter:   7416/156230 | loss: 0.9718 | ds_loss: 1.0085 | lr: 9.9449e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7416/156230 | global iter:   7416/156230 | loss: 1.0572 | ds_loss: 1.0770 | lr: 9.9449e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7417/156230 | global iter:   7417/156230 | loss: 1.1316 | ds_loss: 1.1548 | lr: 9.9449e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   7418/156230 | global iter:   7418/156230 | loss: 0.9309 | ds_loss: 0.9469 | lr: 9.9449e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   7419/156230 | global iter:   7419/156230 | loss: 0.9774 | ds_loss: 0.9934 | lr: 9.9448e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   7420/156230 | global iter:   7420/156230 | loss: 1.1037 | ds_loss: 1.1303 | lr: 9.9448e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7420/156230 | global iter:   7420/156230 | loss: 1.0359 | ds_loss: 1.0563 | lr: 9.9448e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7421/156230 | global iter:   7421/156230 | loss: 1.1447 | ds_loss: 1.1626 | lr: 9.9448e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   7422/156230 | global iter:   7422/156230 | loss: 1.0799 | ds_loss: 1.1155 | lr: 9.9448e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   7423/156230 | global iter:   7423/156230 | loss: 1.2987 | ds_loss: 1.3276 | lr: 9.9448e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   7424/156230 | global iter:   7424/156230 | loss: 1.2183 | ds_loss: 1.2383 | lr: 9.9448e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7424/156230 | global iter:   7424/156230 | loss: 1.1854 | ds_loss: 1.2110 | lr: 9.9448e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7425/156230 | global iter:   7425/156230 | loss: 1.1114 | ds_loss: 1.1119 | lr: 9.9448e-05 | scale: 65536.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   7426/156230 | global iter:   7426/156230 | loss: 1.2444 | ds_loss: 1.2582 | lr: 9.9447e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   7427/156230 | global iter:   7427/156230 | loss: 0.9874 | ds_loss: 0.9914 | lr: 9.9447e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   7428/156230 | global iter:   7428/156230 | loss: 1.0973 | ds_loss: 1.0994 | lr: 9.9447e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7428/156230 | global iter:   7428/156230 | loss: 1.1101 | ds_loss: 1.1152 | lr: 9.9447e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7429/156230 | global iter:   7429/156230 | loss: 1.1070 | ds_loss: 1.1223 | lr: 9.9447e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   7430/156230 | global iter:   7430/156230 | loss: 1.0095 | ds_loss: 1.0370 | lr: 9.9447e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   7431/156230 | global iter:   7431/156230 | loss: 1.2799 | ds_loss: 1.2887 | lr: 9.9447e-05 | scale: 65536.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   7432/156230 | global iter:   7432/156230 | loss: 1.2469 | ds_loss: 1.2779 | lr: 9.9447e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7432/156230 | global iter:   7432/156230 | loss: 1.1608 | ds_loss: 1.1815 | lr: 9.9447e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7433/156230 | global iter:   7433/156230 | loss: 1.1302 | ds_loss: 1.1451 | lr: 9.9446e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   7434/156230 | global iter:   7434/156230 | loss: 1.1023 | ds_loss: 1.1366 | lr: 9.9446e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   7435/156230 | global iter:   7435/156230 | loss: 1.1171 | ds_loss: 1.1469 | lr: 9.9446e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   7436/156230 | global iter:   7436/156230 | loss: 1.1356 | ds_loss: 1.1521 | lr: 9.9446e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7436/156230 | global iter:   7436/156230 | loss: 1.1213 | ds_loss: 1.1452 | lr: 9.9446e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7437/156230 | global iter:   7437/156230 | loss: 1.1187 | ds_loss: 1.1510 | lr: 9.9446e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   7438/156230 | global iter:   7438/156230 | loss: 1.0806 | ds_loss: 1.1266 | lr: 9.9446e-05 | scale: 65536.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   7439/156230 | global iter:   7439/156230 | loss: 0.9723 | ds_loss: 0.9799 | lr: 9.9445e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   7440/156230 | global iter:   7440/156230 | loss: 1.0152 | ds_loss: 1.0343 | lr: 9.9445e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7440/156230 | global iter:   7440/156230 | loss: 1.0467 | ds_loss: 1.0730 | lr: 9.9445e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7441/156230 | global iter:   7441/156230 | loss: 0.9661 | ds_loss: 0.9855 | lr: 9.9445e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   7442/156230 | global iter:   7442/156230 | loss: 0.9474 | ds_loss: 0.9710 | lr: 9.9445e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7443/156230 | global iter:   7443/156230 | loss: 1.0607 | ds_loss: 1.0774 | lr: 9.9445e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   7444/156230 | global iter:   7444/156230 | loss: 0.9161 | ds_loss: 0.9546 | lr: 9.9445e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7444/156230 | global iter:   7444/156230 | loss: 0.9726 | ds_loss: 0.9971 | lr: 9.9445e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7445/156230 | global iter:   7445/156230 | loss: 1.1941 | ds_loss: 1.2183 | lr: 9.9445e-05 | scale: 65536.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:   7446/156230 | global iter:   7446/156230 | loss: 0.9674 | ds_loss: 0.9861 | lr: 9.9444e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   7447/156230 | global iter:   7447/156230 | loss: 1.0594 | ds_loss: 1.0887 | lr: 9.9444e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   7448/156230 | global iter:   7448/156230 | loss: 1.0703 | ds_loss: 1.0877 | lr: 9.9444e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7448/156230 | global iter:   7448/156230 | loss: 1.0728 | ds_loss: 1.0952 | lr: 9.9444e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 1.379
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7449/156230 | global iter:   7449/156230 | loss: 1.1815 | ds_loss: 1.2109 | lr: 9.9444e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   7450/156230 | global iter:   7450/156230 | loss: 1.0115 | ds_loss: 1.0327 | lr: 9.9444e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   7451/156230 | global iter:   7451/156230 | loss: 1.1095 | ds_loss: 1.1236 | lr: 9.9444e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   7452/156230 | global iter:   7452/156230 | loss: 1.0966 | ds_loss: 1.1311 | lr: 9.9444e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7452/156230 | global iter:   7452/156230 | loss: 1.0998 | ds_loss: 1.1246 | lr: 9.9444e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7453/156230 | global iter:   7453/156230 | loss: 1.2188 | ds_loss: 1.2570 | lr: 9.9443e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   7454/156230 | global iter:   7454/156230 | loss: 1.0209 | ds_loss: 1.0482 | lr: 9.9443e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   7455/156230 | global iter:   7455/156230 | loss: 1.1490 | ds_loss: 1.1684 | lr: 9.9443e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   7456/156230 | global iter:   7456/156230 | loss: 1.1596 | ds_loss: 1.1680 | lr: 9.9443e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7456/156230 | global iter:   7456/156230 | loss: 1.1371 | ds_loss: 1.1604 | lr: 9.9443e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7457/156230 | global iter:   7457/156230 | loss: 1.1087 | ds_loss: 1.1328 | lr: 9.9443e-05 | scale: 65536.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   7458/156230 | global iter:   7458/156230 | loss: 1.0480 | ds_loss: 1.0695 | lr: 9.9443e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   7459/156230 | global iter:   7459/156230 | loss: 0.9405 | ds_loss: 0.9585 | lr: 9.9442e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   7460/156230 | global iter:   7460/156230 | loss: 1.1589 | ds_loss: 1.1786 | lr: 9.9442e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7460/156230 | global iter:   7460/156230 | loss: 1.0640 | ds_loss: 1.0849 | lr: 9.9442e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7461/156230 | global iter:   7461/156230 | loss: 0.9777 | ds_loss: 1.0059 | lr: 9.9442e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   7462/156230 | global iter:   7462/156230 | loss: 0.9874 | ds_loss: 1.0098 | lr: 9.9442e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   7463/156230 | global iter:   7463/156230 | loss: 1.0916 | ds_loss: 1.0927 | lr: 9.9442e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   7464/156230 | global iter:   7464/156230 | loss: 1.1414 | ds_loss: 1.1631 | lr: 9.9442e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7464/156230 | global iter:   7464/156230 | loss: 1.0495 | ds_loss: 1.0679 | lr: 9.9442e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7465/156230 | global iter:   7465/156230 | loss: 1.1860 | ds_loss: 1.1992 | lr: 9.9442e-05 | scale: 65536.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:   7466/156230 | global iter:   7466/156230 | loss: 1.2470 | ds_loss: 1.2828 | lr: 9.9441e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   7467/156230 | global iter:   7467/156230 | loss: 0.9929 | ds_loss: 1.0198 | lr: 9.9441e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   7468/156230 | global iter:   7468/156230 | loss: 1.2749 | ds_loss: 1.2811 | lr: 9.9441e-05 | scale: 65536.0000 | micro time: 1.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7468/156230 | global iter:   7468/156230 | loss: 1.1752 | ds_loss: 1.1957 | lr: 9.9441e-05 | scale: 65536.0000 | micro time: 1.394 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7469/156230 | global iter:   7469/156230 | loss: 1.2758 | ds_loss: 1.2810 | lr: 9.9441e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   7470/156230 | global iter:   7470/156230 | loss: 1.1392 | ds_loss: 1.1608 | lr: 9.9441e-05 | scale: 65536.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:   7471/156230 | global iter:   7471/156230 | loss: 1.0743 | ds_loss: 1.0880 | lr: 9.9441e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   7472/156230 | global iter:   7472/156230 | loss: 1.0473 | ds_loss: 1.0724 | lr: 9.9441e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7472/156230 | global iter:   7472/156230 | loss: 1.1342 | ds_loss: 1.1505 | lr: 9.9441e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7473/156230 | global iter:   7473/156230 | loss: 1.2522 | ds_loss: 1.2793 | lr: 9.9440e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   7474/156230 | global iter:   7474/156230 | loss: 0.9491 | ds_loss: 0.9674 | lr: 9.9440e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   7475/156230 | global iter:   7475/156230 | loss: 1.1851 | ds_loss: 1.2019 | lr: 9.9440e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   7476/156230 | global iter:   7476/156230 | loss: 0.8896 | ds_loss: 0.9154 | lr: 9.9440e-05 | scale: 65536.0000 | micro time: 1.387 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7476/156230 | global iter:   7476/156230 | loss: 1.0690 | ds_loss: 1.0910 | lr: 9.9440e-05 | scale: 65536.0000 | micro time: 1.387 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7477/156230 | global iter:   7477/156230 | loss: 1.0363 | ds_loss: 1.0609 | lr: 9.9440e-05 | scale: 65536.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   7478/156230 | global iter:   7478/156230 | loss: 1.1396 | ds_loss: 1.1523 | lr: 9.9440e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   7479/156230 | global iter:   7479/156230 | loss: 1.0482 | ds_loss: 1.0784 | lr: 9.9439e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   7480/156230 | global iter:   7480/156230 | loss: 1.0340 | ds_loss: 1.0602 | lr: 9.9439e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7480/156230 | global iter:   7480/156230 | loss: 1.0646 | ds_loss: 1.0880 | lr: 9.9439e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7481/156230 | global iter:   7481/156230 | loss: 0.9640 | ds_loss: 0.9872 | lr: 9.9439e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   7482/156230 | global iter:   7482/156230 | loss: 1.0286 | ds_loss: 1.0336 | lr: 9.9439e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   7483/156230 | global iter:   7483/156230 | loss: 1.1274 | ds_loss: 1.1446 | lr: 9.9439e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   7484/156230 | global iter:   7484/156230 | loss: 0.9679 | ds_loss: 0.9969 | lr: 9.9439e-05 | scale: 65536.0000 | micro time: 1.383 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7484/156230 | global iter:   7484/156230 | loss: 1.0219 | ds_loss: 1.0406 | lr: 9.9439e-05 | scale: 65536.0000 | micro time: 1.383 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7485/156230 | global iter:   7485/156230 | loss: 1.1054 | ds_loss: 1.1066 | lr: 9.9439e-05 | scale: 65536.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:   7486/156230 | global iter:   7486/156230 | loss: 1.0457 | ds_loss: 1.0683 | lr: 9.9438e-05 | scale: 65536.0000 | micro time: 1.409 | step time: 0.000
train | epoch   0 | Iter:   7487/156230 | global iter:   7487/156230 | loss: 1.0921 | ds_loss: 1.1236 | lr: 9.9438e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   7488/156230 | global iter:   7488/156230 | loss: 1.1313 | ds_loss: 1.1484 | lr: 9.9438e-05 | scale: 65536.0000 | micro time: 1.309 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7488/156230 | global iter:   7488/156230 | loss: 1.0936 | ds_loss: 1.1117 | lr: 9.9438e-05 | scale: 65536.0000 | micro time: 1.309 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7489/156230 | global iter:   7489/156230 | loss: 1.1485 | ds_loss: 1.1722 | lr: 9.9438e-05 | scale: 65536.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   7490/156230 | global iter:   7490/156230 | loss: 1.2415 | ds_loss: 1.2390 | lr: 9.9438e-05 | scale: 65536.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   7491/156230 | global iter:   7491/156230 | loss: 0.8883 | ds_loss: 0.9221 | lr: 9.9438e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   7492/156230 | global iter:   7492/156230 | loss: 1.1060 | ds_loss: 1.1273 | lr: 9.9438e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7492/156230 | global iter:   7492/156230 | loss: 1.0961 | ds_loss: 1.1151 | lr: 9.9438e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7493/156230 | global iter:   7493/156230 | loss: 1.1427 | ds_loss: 1.1587 | lr: 9.9437e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   7494/156230 | global iter:   7494/156230 | loss: 1.1397 | ds_loss: 1.1588 | lr: 9.9437e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   7495/156230 | global iter:   7495/156230 | loss: 0.9484 | ds_loss: 0.9674 | lr: 9.9437e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   7496/156230 | global iter:   7496/156230 | loss: 1.1262 | ds_loss: 1.1528 | lr: 9.9437e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7496/156230 | global iter:   7496/156230 | loss: 1.0893 | ds_loss: 1.1094 | lr: 9.9437e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7497/156230 | global iter:   7497/156230 | loss: 1.2632 | ds_loss: 1.2935 | lr: 9.9437e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   7498/156230 | global iter:   7498/156230 | loss: 1.1135 | ds_loss: 1.1213 | lr: 9.9437e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   7499/156230 | global iter:   7499/156230 | loss: 1.1606 | ds_loss: 1.1722 | lr: 9.9436e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   7500/156230 | global iter:   7500/156230 | loss: 1.1114 | ds_loss: 1.1390 | lr: 9.9436e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7500/156230 | global iter:   7500/156230 | loss: 1.1621 | ds_loss: 1.1815 | lr: 9.9436e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7501/156230 | global iter:   7501/156230 | loss: 1.0573 | ds_loss: 1.0689 | lr: 9.9436e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   7502/156230 | global iter:   7502/156230 | loss: 1.1264 | ds_loss: 1.1499 | lr: 9.9436e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   7503/156230 | global iter:   7503/156230 | loss: 1.0636 | ds_loss: 1.0829 | lr: 9.9436e-05 | scale: 65536.0000 | micro time: 1.312 | step time: 0.000
train | epoch   0 | Iter:   7504/156230 | global iter:   7504/156230 | loss: 1.0594 | ds_loss: 1.0617 | lr: 9.9436e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7504/156230 | global iter:   7504/156230 | loss: 1.0767 | ds_loss: 1.0909 | lr: 9.9436e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7505/156230 | global iter:   7505/156230 | loss: 1.1217 | ds_loss: 1.1569 | lr: 9.9436e-05 | scale: 65536.0000 | micro time: 1.318 | step time: 0.000
train | epoch   0 | Iter:   7506/156230 | global iter:   7506/156230 | loss: 0.9551 | ds_loss: 0.9828 | lr: 9.9435e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   7507/156230 | global iter:   7507/156230 | loss: 1.2110 | ds_loss: 1.2334 | lr: 9.9435e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   7508/156230 | global iter:   7508/156230 | loss: 1.0148 | ds_loss: 1.0476 | lr: 9.9435e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7508/156230 | global iter:   7508/156230 | loss: 1.0756 | ds_loss: 1.1052 | lr: 9.9435e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7509/156230 | global iter:   7509/156230 | loss: 0.9590 | ds_loss: 0.9822 | lr: 9.9435e-05 | scale: 65536.0000 | micro time: 1.400 | step time: 0.000
train | epoch   0 | Iter:   7510/156230 | global iter:   7510/156230 | loss: 1.1693 | ds_loss: 1.2018 | lr: 9.9435e-05 | scale: 65536.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   7511/156230 | global iter:   7511/156230 | loss: 1.1626 | ds_loss: 1.1918 | lr: 9.9435e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   7512/156230 | global iter:   7512/156230 | loss: 1.2426 | ds_loss: 1.2657 | lr: 9.9435e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7512/156230 | global iter:   7512/156230 | loss: 1.1334 | ds_loss: 1.1604 | lr: 9.9435e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 1.383
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7513/156230 | global iter:   7513/156230 | loss: 1.0235 | ds_loss: 1.0499 | lr: 9.9434e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   7514/156230 | global iter:   7514/156230 | loss: 1.1185 | ds_loss: 1.1394 | lr: 9.9434e-05 | scale: 65536.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   7515/156230 | global iter:   7515/156230 | loss: 1.1498 | ds_loss: 1.1626 | lr: 9.9434e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7516/156230 | global iter:   7516/156230 | loss: 1.0968 | ds_loss: 1.1230 | lr: 9.9434e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7516/156230 | global iter:   7516/156230 | loss: 1.0971 | ds_loss: 1.1187 | lr: 9.9434e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7517/156230 | global iter:   7517/156230 | loss: 1.0479 | ds_loss: 1.0844 | lr: 9.9434e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   7518/156230 | global iter:   7518/156230 | loss: 1.0867 | ds_loss: 1.1245 | lr: 9.9434e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   7519/156230 | global iter:   7519/156230 | loss: 1.0767 | ds_loss: 1.1202 | lr: 9.9433e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   7520/156230 | global iter:   7520/156230 | loss: 1.1576 | ds_loss: 1.1846 | lr: 9.9433e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7520/156230 | global iter:   7520/156230 | loss: 1.0922 | ds_loss: 1.1284 | lr: 9.9433e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7521/156230 | global iter:   7521/156230 | loss: 1.1595 | ds_loss: 1.1969 | lr: 9.9433e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   7522/156230 | global iter:   7522/156230 | loss: 1.1276 | ds_loss: 1.1385 | lr: 9.9433e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   7523/156230 | global iter:   7523/156230 | loss: 1.1199 | ds_loss: 1.1360 | lr: 9.9433e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   7524/156230 | global iter:   7524/156230 | loss: 1.1807 | ds_loss: 1.1852 | lr: 9.9433e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7524/156230 | global iter:   7524/156230 | loss: 1.1469 | ds_loss: 1.1642 | lr: 9.9433e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7525/156230 | global iter:   7525/156230 | loss: 1.1432 | ds_loss: 1.1577 | lr: 9.9433e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   7526/156230 | global iter:   7526/156230 | loss: 1.0530 | ds_loss: 1.0833 | lr: 9.9432e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   7527/156230 | global iter:   7527/156230 | loss: 1.1368 | ds_loss: 1.1495 | lr: 9.9432e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7528/156230 | global iter:   7528/156230 | loss: 1.1684 | ds_loss: 1.1816 | lr: 9.9432e-05 | scale: 65536.0000 | micro time: 1.327 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7528/156230 | global iter:   7528/156230 | loss: 1.1254 | ds_loss: 1.1430 | lr: 9.9432e-05 | scale: 65536.0000 | micro time: 1.327 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7529/156230 | global iter:   7529/156230 | loss: 1.0068 | ds_loss: 1.0256 | lr: 9.9432e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   7530/156230 | global iter:   7530/156230 | loss: 1.0596 | ds_loss: 1.0989 | lr: 9.9432e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   7531/156230 | global iter:   7531/156230 | loss: 1.1165 | ds_loss: 1.1419 | lr: 9.9432e-05 | scale: 65536.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   7532/156230 | global iter:   7532/156230 | loss: 1.0737 | ds_loss: 1.1083 | lr: 9.9431e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7532/156230 | global iter:   7532/156230 | loss: 1.0641 | ds_loss: 1.0937 | lr: 9.9431e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7533/156230 | global iter:   7533/156230 | loss: 0.9648 | ds_loss: 0.9910 | lr: 9.9431e-05 | scale: 65536.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   7534/156230 | global iter:   7534/156230 | loss: 1.2285 | ds_loss: 1.2511 | lr: 9.9431e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   7535/156230 | global iter:   7535/156230 | loss: 1.2536 | ds_loss: 1.2776 | lr: 9.9431e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   7536/156230 | global iter:   7536/156230 | loss: 0.9332 | ds_loss: 0.9618 | lr: 9.9431e-05 | scale: 65536.0000 | micro time: 1.331 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7536/156230 | global iter:   7536/156230 | loss: 1.0950 | ds_loss: 1.1204 | lr: 9.9431e-05 | scale: 65536.0000 | micro time: 1.331 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7537/156230 | global iter:   7537/156230 | loss: 1.1259 | ds_loss: 1.1310 | lr: 9.9431e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   7538/156230 | global iter:   7538/156230 | loss: 1.1286 | ds_loss: 1.1350 | lr: 9.9431e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   7539/156230 | global iter:   7539/156230 | loss: 1.0680 | ds_loss: 1.0840 | lr: 9.9430e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   7540/156230 | global iter:   7540/156230 | loss: 1.1501 | ds_loss: 1.1888 | lr: 9.9430e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7540/156230 | global iter:   7540/156230 | loss: 1.1181 | ds_loss: 1.1347 | lr: 9.9430e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7541/156230 | global iter:   7541/156230 | loss: 1.1584 | ds_loss: 1.1760 | lr: 9.9430e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   7542/156230 | global iter:   7542/156230 | loss: 1.1082 | ds_loss: 1.1223 | lr: 9.9430e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   7543/156230 | global iter:   7543/156230 | loss: 0.9103 | ds_loss: 0.9364 | lr: 9.9430e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   7544/156230 | global iter:   7544/156230 | loss: 0.9586 | ds_loss: 0.9648 | lr: 9.9430e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7544/156230 | global iter:   7544/156230 | loss: 1.0339 | ds_loss: 1.0499 | lr: 9.9430e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7545/156230 | global iter:   7545/156230 | loss: 1.0083 | ds_loss: 1.0303 | lr: 9.9430e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   7546/156230 | global iter:   7546/156230 | loss: 1.0969 | ds_loss: 1.1063 | lr: 9.9429e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   7547/156230 | global iter:   7547/156230 | loss: 1.1547 | ds_loss: 1.1720 | lr: 9.9429e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   7548/156230 | global iter:   7548/156230 | loss: 1.0317 | ds_loss: 1.0572 | lr: 9.9429e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7548/156230 | global iter:   7548/156230 | loss: 1.0729 | ds_loss: 1.0914 | lr: 9.9429e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7549/156230 | global iter:   7549/156230 | loss: 0.9415 | ds_loss: 0.9497 | lr: 9.9429e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   7550/156230 | global iter:   7550/156230 | loss: 1.1829 | ds_loss: 1.2058 | lr: 9.9429e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   7551/156230 | global iter:   7551/156230 | loss: 1.1026 | ds_loss: 1.1283 | lr: 9.9429e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   7552/156230 | global iter:   7552/156230 | loss: 1.0787 | ds_loss: 1.0823 | lr: 9.9428e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7552/156230 | global iter:   7552/156230 | loss: 1.0764 | ds_loss: 1.0915 | lr: 9.9428e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7553/156230 | global iter:   7553/156230 | loss: 1.1420 | ds_loss: 1.1496 | lr: 9.9428e-05 | scale: 65536.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   7554/156230 | global iter:   7554/156230 | loss: 1.2298 | ds_loss: 1.2503 | lr: 9.9428e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   7555/156230 | global iter:   7555/156230 | loss: 1.0373 | ds_loss: 1.0495 | lr: 9.9428e-05 | scale: 65536.0000 | micro time: 1.306 | step time: 0.000
train | epoch   0 | Iter:   7556/156230 | global iter:   7556/156230 | loss: 1.0410 | ds_loss: 1.0706 | lr: 9.9428e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7556/156230 | global iter:   7556/156230 | loss: 1.1125 | ds_loss: 1.1300 | lr: 9.9428e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 1.344
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7557/156230 | global iter:   7557/156230 | loss: 1.1852 | ds_loss: 1.2158 | lr: 9.9428e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   7558/156230 | global iter:   7558/156230 | loss: 1.1270 | ds_loss: 1.1484 | lr: 9.9428e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   7559/156230 | global iter:   7559/156230 | loss: 1.1990 | ds_loss: 1.2312 | lr: 9.9427e-05 | scale: 65536.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   7560/156230 | global iter:   7560/156230 | loss: 1.0116 | ds_loss: 1.0372 | lr: 9.9427e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7560/156230 | global iter:   7560/156230 | loss: 1.1307 | ds_loss: 1.1582 | lr: 9.9427e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7561/156230 | global iter:   7561/156230 | loss: 1.0782 | ds_loss: 1.1088 | lr: 9.9427e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   7562/156230 | global iter:   7562/156230 | loss: 1.0863 | ds_loss: 1.1153 | lr: 9.9427e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   7563/156230 | global iter:   7563/156230 | loss: 1.0999 | ds_loss: 1.1406 | lr: 9.9427e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   7564/156230 | global iter:   7564/156230 | loss: 0.8191 | ds_loss: 0.8430 | lr: 9.9427e-05 | scale: 65536.0000 | micro time: 1.392 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7564/156230 | global iter:   7564/156230 | loss: 1.0209 | ds_loss: 1.0519 | lr: 9.9427e-05 | scale: 65536.0000 | micro time: 1.392 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7565/156230 | global iter:   7565/156230 | loss: 1.1986 | ds_loss: 1.2142 | lr: 9.9427e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   7566/156230 | global iter:   7566/156230 | loss: 1.0609 | ds_loss: 1.0939 | lr: 9.9426e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7567/156230 | global iter:   7567/156230 | loss: 1.0143 | ds_loss: 1.0307 | lr: 9.9426e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   7568/156230 | global iter:   7568/156230 | loss: 1.2461 | ds_loss: 1.2780 | lr: 9.9426e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7568/156230 | global iter:   7568/156230 | loss: 1.1300 | ds_loss: 1.1542 | lr: 9.9426e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7569/156230 | global iter:   7569/156230 | loss: 0.9678 | ds_loss: 1.0027 | lr: 9.9426e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   7570/156230 | global iter:   7570/156230 | loss: 1.2940 | ds_loss: 1.3213 | lr: 9.9426e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   7571/156230 | global iter:   7571/156230 | loss: 1.0628 | ds_loss: 1.1081 | lr: 9.9426e-05 | scale: 65536.0000 | micro time: 1.412 | step time: 0.000
train | epoch   0 | Iter:   7572/156230 | global iter:   7572/156230 | loss: 1.0551 | ds_loss: 1.0744 | lr: 9.9425e-05 | scale: 65536.0000 | micro time: 1.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7572/156230 | global iter:   7572/156230 | loss: 1.0949 | ds_loss: 1.1266 | lr: 9.9425e-05 | scale: 65536.0000 | micro time: 1.396 | step time: 1.391
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7573/156230 | global iter:   7573/156230 | loss: 1.0492 | ds_loss: 1.0847 | lr: 9.9425e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   7574/156230 | global iter:   7574/156230 | loss: 0.9310 | ds_loss: 0.9385 | lr: 9.9425e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   7575/156230 | global iter:   7575/156230 | loss: 1.0620 | ds_loss: 1.0917 | lr: 9.9425e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7576/156230 | global iter:   7576/156230 | loss: 1.1040 | ds_loss: 1.1244 | lr: 9.9425e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7576/156230 | global iter:   7576/156230 | loss: 1.0365 | ds_loss: 1.0598 | lr: 9.9425e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7577/156230 | global iter:   7577/156230 | loss: 1.0414 | ds_loss: 1.0691 | lr: 9.9425e-05 | scale: 65536.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   7578/156230 | global iter:   7578/156230 | loss: 1.2493 | ds_loss: 1.2913 | lr: 9.9425e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   7579/156230 | global iter:   7579/156230 | loss: 1.0392 | ds_loss: 1.0530 | lr: 9.9424e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   7580/156230 | global iter:   7580/156230 | loss: 1.1009 | ds_loss: 1.1206 | lr: 9.9424e-05 | scale: 65536.0000 | micro time: 1.337 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7580/156230 | global iter:   7580/156230 | loss: 1.1077 | ds_loss: 1.1335 | lr: 9.9424e-05 | scale: 65536.0000 | micro time: 1.337 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7581/156230 | global iter:   7581/156230 | loss: 1.0515 | ds_loss: 1.0704 | lr: 9.9424e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   7582/156230 | global iter:   7582/156230 | loss: 0.8952 | ds_loss: 0.9090 | lr: 9.9424e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   7583/156230 | global iter:   7583/156230 | loss: 0.8374 | ds_loss: 0.8595 | lr: 9.9424e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   7584/156230 | global iter:   7584/156230 | loss: 0.9151 | ds_loss: 0.9338 | lr: 9.9424e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7584/156230 | global iter:   7584/156230 | loss: 0.9248 | ds_loss: 0.9432 | lr: 9.9424e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7585/156230 | global iter:   7585/156230 | loss: 1.1738 | ds_loss: 1.2047 | lr: 9.9423e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   7586/156230 | global iter:   7586/156230 | loss: 1.1253 | ds_loss: 1.1537 | lr: 9.9423e-05 | scale: 65536.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   7587/156230 | global iter:   7587/156230 | loss: 1.2245 | ds_loss: 1.2600 | lr: 9.9423e-05 | scale: 65536.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:   7588/156230 | global iter:   7588/156230 | loss: 1.0867 | ds_loss: 1.1222 | lr: 9.9423e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7588/156230 | global iter:   7588/156230 | loss: 1.1526 | ds_loss: 1.1852 | lr: 9.9423e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7589/156230 | global iter:   7589/156230 | loss: 1.0847 | ds_loss: 1.1177 | lr: 9.9423e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   7590/156230 | global iter:   7590/156230 | loss: 1.1276 | ds_loss: 1.1428 | lr: 9.9423e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   7591/156230 | global iter:   7591/156230 | loss: 1.0456 | ds_loss: 1.0507 | lr: 9.9423e-05 | scale: 65536.0000 | micro time: 1.309 | step time: 0.000
train | epoch   0 | Iter:   7592/156230 | global iter:   7592/156230 | loss: 1.0807 | ds_loss: 1.0955 | lr: 9.9422e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7592/156230 | global iter:   7592/156230 | loss: 1.0847 | ds_loss: 1.1017 | lr: 9.9422e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7593/156230 | global iter:   7593/156230 | loss: 1.0235 | ds_loss: 1.0639 | lr: 9.9422e-05 | scale: 65536.0000 | micro time: 1.398 | step time: 0.000
train | epoch   0 | Iter:   7594/156230 | global iter:   7594/156230 | loss: 0.9806 | ds_loss: 0.9958 | lr: 9.9422e-05 | scale: 65536.0000 | micro time: 1.321 | step time: 0.000
train | epoch   0 | Iter:   7595/156230 | global iter:   7595/156230 | loss: 1.0363 | ds_loss: 1.0630 | lr: 9.9422e-05 | scale: 65536.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   7596/156230 | global iter:   7596/156230 | loss: 1.0990 | ds_loss: 1.1098 | lr: 9.9422e-05 | scale: 65536.0000 | micro time: 1.324 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7596/156230 | global iter:   7596/156230 | loss: 1.0348 | ds_loss: 1.0582 | lr: 9.9422e-05 | scale: 65536.0000 | micro time: 1.324 | step time: 1.343
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7597/156230 | global iter:   7597/156230 | loss: 1.0777 | ds_loss: 1.0891 | lr: 9.9422e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   7598/156230 | global iter:   7598/156230 | loss: 1.1463 | ds_loss: 1.1758 | lr: 9.9421e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   7599/156230 | global iter:   7599/156230 | loss: 1.0920 | ds_loss: 1.0965 | lr: 9.9421e-05 | scale: 65536.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:   7600/156230 | global iter:   7600/156230 | loss: 0.9508 | ds_loss: 0.9792 | lr: 9.9421e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7600/156230 | global iter:   7600/156230 | loss: 1.0667 | ds_loss: 1.0852 | lr: 9.9421e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7601/156230 | global iter:   7601/156230 | loss: 1.0089 | ds_loss: 1.0461 | lr: 9.9421e-05 | scale: 65536.0000 | micro time: 1.321 | step time: 0.000
train | epoch   0 | Iter:   7602/156230 | global iter:   7602/156230 | loss: 0.9645 | ds_loss: 0.9801 | lr: 9.9421e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   7603/156230 | global iter:   7603/156230 | loss: 1.0177 | ds_loss: 1.0275 | lr: 9.9421e-05 | scale: 65536.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   7604/156230 | global iter:   7604/156230 | loss: 1.0057 | ds_loss: 1.0139 | lr: 9.9421e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7604/156230 | global iter:   7604/156230 | loss: 0.9992 | ds_loss: 1.0169 | lr: 9.9421e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7605/156230 | global iter:   7605/156230 | loss: 1.0384 | ds_loss: 1.0484 | lr: 9.9420e-05 | scale: 65536.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   7606/156230 | global iter:   7606/156230 | loss: 1.0107 | ds_loss: 1.0255 | lr: 9.9420e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   7607/156230 | global iter:   7607/156230 | loss: 1.0198 | ds_loss: 1.0292 | lr: 9.9420e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   7608/156230 | global iter:   7608/156230 | loss: 1.2163 | ds_loss: 1.2422 | lr: 9.9420e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7608/156230 | global iter:   7608/156230 | loss: 1.0713 | ds_loss: 1.0863 | lr: 9.9420e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7609/156230 | global iter:   7609/156230 | loss: 0.9848 | ds_loss: 0.9827 | lr: 9.9420e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   7610/156230 | global iter:   7610/156230 | loss: 0.9706 | ds_loss: 0.9917 | lr: 9.9420e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   7611/156230 | global iter:   7611/156230 | loss: 1.1116 | ds_loss: 1.1434 | lr: 9.9419e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   7612/156230 | global iter:   7612/156230 | loss: 1.0108 | ds_loss: 1.0233 | lr: 9.9419e-05 | scale: 65536.0000 | micro time: 1.326 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7612/156230 | global iter:   7612/156230 | loss: 1.0195 | ds_loss: 1.0353 | lr: 9.9419e-05 | scale: 65536.0000 | micro time: 1.326 | step time: 1.342
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7613/156230 | global iter:   7613/156230 | loss: 1.1378 | ds_loss: 1.1742 | lr: 9.9419e-05 | scale: 65536.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   7614/156230 | global iter:   7614/156230 | loss: 1.1550 | ds_loss: 1.1572 | lr: 9.9419e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   7615/156230 | global iter:   7615/156230 | loss: 1.1491 | ds_loss: 1.1562 | lr: 9.9419e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   7616/156230 | global iter:   7616/156230 | loss: 1.0555 | ds_loss: 1.0389 | lr: 9.9419e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7616/156230 | global iter:   7616/156230 | loss: 1.1244 | ds_loss: 1.1316 | lr: 9.9419e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7617/156230 | global iter:   7617/156230 | loss: 0.9291 | ds_loss: 0.9474 | lr: 9.9419e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   7618/156230 | global iter:   7618/156230 | loss: 1.0009 | ds_loss: 1.0138 | lr: 9.9418e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   7619/156230 | global iter:   7619/156230 | loss: 1.1070 | ds_loss: 1.1406 | lr: 9.9418e-05 | scale: 131072.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   7620/156230 | global iter:   7620/156230 | loss: 1.1453 | ds_loss: 1.1623 | lr: 9.9418e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7620/156230 | global iter:   7620/156230 | loss: 1.0456 | ds_loss: 1.0660 | lr: 9.9418e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7621/156230 | global iter:   7621/156230 | loss: 1.1401 | ds_loss: 1.1489 | lr: 9.9418e-05 | scale: 131072.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   7622/156230 | global iter:   7622/156230 | loss: 0.9912 | ds_loss: 1.0125 | lr: 9.9418e-05 | scale: 131072.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   7623/156230 | global iter:   7623/156230 | loss: 1.1391 | ds_loss: 1.1605 | lr: 9.9418e-05 | scale: 131072.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   7624/156230 | global iter:   7624/156230 | loss: 1.0716 | ds_loss: 1.1055 | lr: 9.9418e-05 | scale: 131072.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7624/156230 | global iter:   7624/156230 | loss: 1.0855 | ds_loss: 1.1068 | lr: 9.9418e-05 | scale: 131072.0000 | micro time: 1.363 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7625/156230 | global iter:   7625/156230 | loss: 0.9300 | ds_loss: 0.9584 | lr: 9.9417e-05 | scale: 131072.0000 | micro time: 1.318 | step time: 0.000
train | epoch   0 | Iter:   7626/156230 | global iter:   7626/156230 | loss: 1.1481 | ds_loss: 1.1696 | lr: 9.9417e-05 | scale: 131072.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   7627/156230 | global iter:   7627/156230 | loss: 0.9547 | ds_loss: 0.9783 | lr: 9.9417e-05 | scale: 131072.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   7628/156230 | global iter:   7628/156230 | loss: 1.0619 | ds_loss: 1.0764 | lr: 9.9417e-05 | scale: 131072.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7628/156230 | global iter:   7628/156230 | loss: 1.0237 | ds_loss: 1.0457 | lr: 9.9417e-05 | scale: 131072.0000 | micro time: 1.377 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7629/156230 | global iter:   7629/156230 | loss: 1.1267 | ds_loss: 1.1377 | lr: 9.9417e-05 | scale: 131072.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   7630/156230 | global iter:   7630/156230 | loss: 1.0466 | ds_loss: 1.0641 | lr: 9.9417e-05 | scale: 131072.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   7631/156230 | global iter:   7631/156230 | loss: 1.0054 | ds_loss: 1.0460 | lr: 9.9416e-05 | scale: 131072.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   7632/156230 | global iter:   7632/156230 | loss: 0.9410 | ds_loss: 0.9551 | lr: 9.9416e-05 | scale: 131072.0000 | micro time: 1.345 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7632/156230 | global iter:   7632/156230 | loss: 1.0299 | ds_loss: 1.0507 | lr: 9.9416e-05 | scale: 131072.0000 | micro time: 1.345 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7633/156230 | global iter:   7633/156230 | loss: 1.2370 | ds_loss: 1.2693 | lr: 9.9416e-05 | scale: 131072.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   7634/156230 | global iter:   7634/156230 | loss: 0.9504 | ds_loss: 0.9652 | lr: 9.9416e-05 | scale: 131072.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   7635/156230 | global iter:   7635/156230 | loss: 1.0701 | ds_loss: 1.0816 | lr: 9.9416e-05 | scale: 131072.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7636/156230 | global iter:   7636/156230 | loss: 0.9532 | ds_loss: 0.9707 | lr: 9.9416e-05 | scale: 131072.0000 | micro time: 1.386 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7636/156230 | global iter:   7636/156230 | loss: 1.0527 | ds_loss: 1.0717 | lr: 9.9416e-05 | scale: 131072.0000 | micro time: 1.386 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7637/156230 | global iter:   7637/156230 | loss: 0.9169 | ds_loss: 0.9352 | lr: 9.9416e-05 | scale: 131072.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   7638/156230 | global iter:   7638/156230 | loss: 1.0672 | ds_loss: 1.0941 | lr: 9.9415e-05 | scale: 131072.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   7639/156230 | global iter:   7639/156230 | loss: 1.1358 | ds_loss: 1.1563 | lr: 9.9415e-05 | scale: 131072.0000 | micro time: 1.426 | step time: 0.000
train | epoch   0 | Iter:   7640/156230 | global iter:   7640/156230 | loss: 0.9636 | ds_loss: 0.9850 | lr: 9.9415e-05 | scale: 131072.0000 | micro time: 1.352 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7640/156230 | global iter:   7640/156230 | loss: 1.0209 | ds_loss: 1.0427 | lr: 9.9415e-05 | scale: 131072.0000 | micro time: 1.352 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7641/156230 | global iter:   7641/156230 | loss: 1.1942 | ds_loss: 1.2178 | lr: 9.9415e-05 | scale: 131072.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   7642/156230 | global iter:   7642/156230 | loss: 1.0062 | ds_loss: 1.0311 | lr: 9.9415e-05 | scale: 131072.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   7643/156230 | global iter:   7643/156230 | loss: 1.1222 | ds_loss: 1.1354 | lr: 9.9415e-05 | scale: 131072.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   7644/156230 | global iter:   7644/156230 | loss: 1.1869 | ds_loss: 1.2003 | lr: 9.9414e-05 | scale: 131072.0000 | micro time: 1.383 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7644/156230 | global iter:   7644/156230 | loss: 1.1274 | ds_loss: 1.1462 | lr: 9.9414e-05 | scale: 131072.0000 | micro time: 1.383 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7645/156230 | global iter:   7645/156230 | loss: 1.1644 | ds_loss: 1.1810 | lr: 9.9414e-05 | scale: 131072.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   7646/156230 | global iter:   7646/156230 | loss: 1.2321 | ds_loss: 1.2655 | lr: 9.9414e-05 | scale: 131072.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   7647/156230 | global iter:   7647/156230 | loss: 0.9118 | ds_loss: 0.9333 | lr: 9.9414e-05 | scale: 131072.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   7648/156230 | global iter:   7648/156230 | loss: 1.2117 | ds_loss: 1.2221 | lr: 9.9414e-05 | scale: 131072.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7648/156230 | global iter:   7648/156230 | loss: 1.1300 | ds_loss: 1.1505 | lr: 9.9414e-05 | scale: 131072.0000 | micro time: 1.377 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7649/156230 | global iter:   7649/156230 | loss: 1.0624 | ds_loss: 1.0951 | lr: 9.9414e-05 | scale: 131072.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   7650/156230 | global iter:   7650/156230 | loss: 1.0883 | ds_loss: 1.1188 | lr: 9.9414e-05 | scale: 131072.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   7651/156230 | global iter:   7651/156230 | loss: 0.9426 | ds_loss: 0.9477 | lr: 9.9413e-05 | scale: 131072.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:   7652/156230 | global iter:   7652/156230 | loss: 1.1441 | ds_loss: 1.1833 | lr: 9.9413e-05 | scale: 131072.0000 | micro time: 1.380 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7652/156230 | global iter:   7652/156230 | loss: 1.0594 | ds_loss: 1.0862 | lr: 9.9413e-05 | scale: 131072.0000 | micro time: 1.380 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7653/156230 | global iter:   7653/156230 | loss: 1.1377 | ds_loss: 1.1548 | lr: 9.9413e-05 | scale: 131072.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   7654/156230 | global iter:   7654/156230 | loss: 1.1689 | ds_loss: 1.1708 | lr: 9.9413e-05 | scale: 131072.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   7655/156230 | global iter:   7655/156230 | loss: 1.0229 | ds_loss: 1.0555 | lr: 9.9413e-05 | scale: 131072.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   7656/156230 | global iter:   7656/156230 | loss: 0.9280 | ds_loss: 0.9483 | lr: 9.9413e-05 | scale: 131072.0000 | micro time: 1.415 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7656/156230 | global iter:   7656/156230 | loss: 1.0644 | ds_loss: 1.0823 | lr: 9.9413e-05 | scale: 131072.0000 | micro time: 1.415 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7657/156230 | global iter:   7657/156230 | loss: 1.0133 | ds_loss: 1.0274 | lr: 9.9412e-05 | scale: 131072.0000 | micro time: 1.320 | step time: 0.000
train | epoch   0 | Iter:   7658/156230 | global iter:   7658/156230 | loss: 1.0794 | ds_loss: 1.0899 | lr: 9.9412e-05 | scale: 131072.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   7659/156230 | global iter:   7659/156230 | loss: 1.0947 | ds_loss: 1.1203 | lr: 9.9412e-05 | scale: 131072.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   7660/156230 | global iter:   7660/156230 | loss: 1.0973 | ds_loss: 1.1354 | lr: 9.9412e-05 | scale: 131072.0000 | micro time: 1.407 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7660/156230 | global iter:   7660/156230 | loss: 1.0712 | ds_loss: 1.0933 | lr: 9.9412e-05 | scale: 131072.0000 | micro time: 1.407 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7661/156230 | global iter:   7661/156230 | loss: 1.2157 | ds_loss: 1.2344 | lr: 9.9412e-05 | scale: 131072.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   7662/156230 | global iter:   7662/156230 | loss: 1.0034 | ds_loss: 1.0218 | lr: 9.9412e-05 | scale: 131072.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   7663/156230 | global iter:   7663/156230 | loss: 1.1537 | ds_loss: 1.1731 | lr: 9.9412e-05 | scale: 131072.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   7664/156230 | global iter:   7664/156230 | loss: 0.9983 | ds_loss: 1.0309 | lr: 9.9411e-05 | scale: 131072.0000 | micro time: 1.401 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7664/156230 | global iter:   7664/156230 | loss: 1.0928 | ds_loss: 1.1151 | lr: 9.9411e-05 | scale: 131072.0000 | micro time: 1.401 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7665/156230 | global iter:   7665/156230 | loss: 1.0315 | ds_loss: 1.0686 | lr: 9.9411e-05 | scale: 131072.0000 | micro time: 1.323 | step time: 0.000
train | epoch   0 | Iter:   7666/156230 | global iter:   7666/156230 | loss: 1.2096 | ds_loss: 1.2322 | lr: 9.9411e-05 | scale: 131072.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   7667/156230 | global iter:   7667/156230 | loss: 1.1727 | ds_loss: 1.1938 | lr: 9.9411e-05 | scale: 131072.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   7668/156230 | global iter:   7668/156230 | loss: 1.1092 | ds_loss: 1.1370 | lr: 9.9411e-05 | scale: 131072.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7668/156230 | global iter:   7668/156230 | loss: 1.1308 | ds_loss: 1.1579 | lr: 9.9411e-05 | scale: 131072.0000 | micro time: 1.374 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7669/156230 | global iter:   7669/156230 | loss: 1.0193 | ds_loss: 1.0354 | lr: 9.9411e-05 | scale: 131072.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   7670/156230 | global iter:   7670/156230 | loss: 1.1032 | ds_loss: 1.1176 | lr: 9.9410e-05 | scale: 131072.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   7671/156230 | global iter:   7671/156230 | loss: 1.0937 | ds_loss: 1.1107 | lr: 9.9410e-05 | scale: 131072.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   7672/156230 | global iter:   7672/156230 | loss: 1.0638 | ds_loss: 1.0766 | lr: 9.9410e-05 | scale: 131072.0000 | micro time: 1.388 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7672/156230 | global iter:   7672/156230 | loss: 1.0700 | ds_loss: 1.0851 | lr: 9.9410e-05 | scale: 131072.0000 | micro time: 1.388 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7673/156230 | global iter:   7673/156230 | loss: 1.2150 | ds_loss: 1.2405 | lr: 9.9410e-05 | scale: 131072.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   7674/156230 | global iter:   7674/156230 | loss: 0.9709 | ds_loss: 0.9844 | lr: 9.9410e-05 | scale: 131072.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   7675/156230 | global iter:   7675/156230 | loss: 0.9972 | ds_loss: 1.0211 | lr: 9.9410e-05 | scale: 131072.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   7676/156230 | global iter:   7676/156230 | loss: 1.1335 | ds_loss: 1.1576 | lr: 9.9410e-05 | scale: 131072.0000 | micro time: 1.346 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7676/156230 | global iter:   7676/156230 | loss: 1.0792 | ds_loss: 1.1009 | lr: 9.9410e-05 | scale: 131072.0000 | micro time: 1.346 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7677/156230 | global iter:   7677/156230 | loss: 1.0844 | ds_loss: 1.1008 | lr: 9.9409e-05 | scale: 131072.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   7678/156230 | global iter:   7678/156230 | loss: 1.1788 | ds_loss: 1.1825 | lr: 9.9409e-05 | scale: 131072.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   7679/156230 | global iter:   7679/156230 | loss: 1.1330 | ds_loss: 1.1453 | lr: 9.9409e-05 | scale: 131072.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   7680/156230 | global iter:   7680/156230 | loss: 1.0202 | ds_loss: 1.0322 | lr: 9.9409e-05 | scale: 131072.0000 | micro time: 1.371 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7680/156230 | global iter:   7680/156230 | loss: 1.1041 | ds_loss: 1.1152 | lr: 9.9409e-05 | scale: 131072.0000 | micro time: 1.371 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7681/156230 | global iter:   7681/156230 | loss: 1.2539 | ds_loss: 1.2641 | lr: 9.9409e-05 | scale: 131072.0000 | micro time: 1.387 | step time: 0.000
train | epoch   0 | Iter:   7682/156230 | global iter:   7682/156230 | loss: 1.1868 | ds_loss: 1.2180 | lr: 9.9409e-05 | scale: 131072.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   7683/156230 | global iter:   7683/156230 | loss: 1.0661 | ds_loss: 1.0919 | lr: 9.9408e-05 | scale: 131072.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   7684/156230 | global iter:   7684/156230 | loss: 1.2584 | ds_loss: 1.2843 | lr: 9.9408e-05 | scale: 131072.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7684/156230 | global iter:   7684/156230 | loss: 1.1913 | ds_loss: 1.2146 | lr: 9.9408e-05 | scale: 131072.0000 | micro time: 1.377 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7685/156230 | global iter:   7685/156230 | loss: 1.1316 | ds_loss: 1.1463 | lr: 9.9408e-05 | scale: 131072.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   7686/156230 | global iter:   7686/156230 | loss: 0.9627 | ds_loss: 0.9935 | lr: 9.9408e-05 | scale: 131072.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   7687/156230 | global iter:   7687/156230 | loss: 0.9499 | ds_loss: 0.9768 | lr: 9.9408e-05 | scale: 131072.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   7688/156230 | global iter:   7688/156230 | loss: 1.0447 | ds_loss: 1.0716 | lr: 9.9408e-05 | scale: 131072.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7688/156230 | global iter:   7688/156230 | loss: 1.0222 | ds_loss: 1.0470 | lr: 9.9408e-05 | scale: 131072.0000 | micro time: 1.360 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7689/156230 | global iter:   7689/156230 | loss: 1.1069 | ds_loss: 1.1226 | lr: 9.9408e-05 | scale: 131072.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   7690/156230 | global iter:   7690/156230 | loss: 1.0620 | ds_loss: 1.0722 | lr: 9.9407e-05 | scale: 131072.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   7691/156230 | global iter:   7691/156230 | loss: 1.1076 | ds_loss: 1.1478 | lr: 9.9407e-05 | scale: 131072.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   7692/156230 | global iter:   7692/156230 | loss: 1.0882 | ds_loss: 1.1116 | lr: 9.9407e-05 | scale: 131072.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7692/156230 | global iter:   7692/156230 | loss: 1.0912 | ds_loss: 1.1135 | lr: 9.9407e-05 | scale: 131072.0000 | micro time: 1.353 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7693/156230 | global iter:   7693/156230 | loss: 1.1463 | ds_loss: 1.1776 | lr: 9.9407e-05 | scale: 131072.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:   7694/156230 | global iter:   7694/156230 | loss: 1.0783 | ds_loss: 1.0930 | lr: 9.9407e-05 | scale: 131072.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   7695/156230 | global iter:   7695/156230 | loss: 1.1174 | ds_loss: 1.1364 | lr: 9.9407e-05 | scale: 131072.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   7696/156230 | global iter:   7696/156230 | loss: 1.1970 | ds_loss: 1.1978 | lr: 9.9406e-05 | scale: 131072.0000 | micro time: 1.384 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7696/156230 | global iter:   7696/156230 | loss: 1.1348 | ds_loss: 1.1512 | lr: 9.9406e-05 | scale: 131072.0000 | micro time: 1.384 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7697/156230 | global iter:   7697/156230 | loss: 1.0806 | ds_loss: 1.0836 | lr: 9.9406e-05 | scale: 131072.0000 | micro time: 1.400 | step time: 0.000
train | epoch   0 | Iter:   7698/156230 | global iter:   7698/156230 | loss: 1.2425 | ds_loss: 1.2630 | lr: 9.9406e-05 | scale: 131072.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   7699/156230 | global iter:   7699/156230 | loss: 1.1928 | ds_loss: 1.2236 | lr: 9.9406e-05 | scale: 131072.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   7700/156230 | global iter:   7700/156230 | loss: 1.1367 | ds_loss: 1.1633 | lr: 9.9406e-05 | scale: 131072.0000 | micro time: 1.391 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7700/156230 | global iter:   7700/156230 | loss: 1.1632 | ds_loss: 1.1834 | lr: 9.9406e-05 | scale: 131072.0000 | micro time: 1.391 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7701/156230 | global iter:   7701/156230 | loss: 1.1059 | ds_loss: 1.1492 | lr: 9.9406e-05 | scale: 131072.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   7702/156230 | global iter:   7702/156230 | loss: 1.0911 | ds_loss: 1.1021 | lr: 9.9406e-05 | scale: 131072.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7703/156230 | global iter:   7703/156230 | loss: 1.1784 | ds_loss: 1.2173 | lr: 9.9405e-05 | scale: 131072.0000 | micro time: 1.412 | step time: 0.000
train | epoch   0 | Iter:   7704/156230 | global iter:   7704/156230 | loss: 1.1385 | ds_loss: 1.1524 | lr: 9.9405e-05 | scale: 131072.0000 | micro time: 1.367 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7704/156230 | global iter:   7704/156230 | loss: 1.1285 | ds_loss: 1.1552 | lr: 9.9405e-05 | scale: 131072.0000 | micro time: 1.367 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7705/156230 | global iter:   7705/156230 | loss: 1.0482 | ds_loss: 1.0605 | lr: 9.9405e-05 | scale: 131072.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   7706/156230 | global iter:   7706/156230 | loss: 1.0376 | ds_loss: 1.0439 | lr: 9.9405e-05 | scale: 131072.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   7707/156230 | global iter:   7707/156230 | loss: 1.2980 | ds_loss: 1.3346 | lr: 9.9405e-05 | scale: 131072.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   7708/156230 | global iter:   7708/156230 | loss: 1.0343 | ds_loss: 1.0452 | lr: 9.9405e-05 | scale: 131072.0000 | micro time: 1.385 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7708/156230 | global iter:   7708/156230 | loss: 1.1045 | ds_loss: 1.1211 | lr: 9.9405e-05 | scale: 131072.0000 | micro time: 1.385 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7709/156230 | global iter:   7709/156230 | loss: 1.0883 | ds_loss: 1.1170 | lr: 9.9404e-05 | scale: 131072.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   7710/156230 | global iter:   7710/156230 | loss: 1.2029 | ds_loss: 1.2301 | lr: 9.9404e-05 | scale: 131072.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   7711/156230 | global iter:   7711/156230 | loss: 1.0103 | ds_loss: 1.0304 | lr: 9.9404e-05 | scale: 131072.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   7712/156230 | global iter:   7712/156230 | loss: 1.0677 | ds_loss: 1.0737 | lr: 9.9404e-05 | scale: 131072.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7712/156230 | global iter:   7712/156230 | loss: 1.0923 | ds_loss: 1.1128 | lr: 9.9404e-05 | scale: 131072.0000 | micro time: 1.393 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7713/156230 | global iter:   7713/156230 | loss: 1.2091 | ds_loss: 1.2193 | lr: 9.9404e-05 | scale: 131072.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   7714/156230 | global iter:   7714/156230 | loss: 1.0772 | ds_loss: 1.0972 | lr: 9.9404e-05 | scale: 131072.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   7715/156230 | global iter:   7715/156230 | loss: 1.1928 | ds_loss: 1.1923 | lr: 9.9404e-05 | scale: 131072.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   7716/156230 | global iter:   7716/156230 | loss: 1.1897 | ds_loss: 1.2059 | lr: 9.9403e-05 | scale: 131072.0000 | micro time: 1.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7716/156230 | global iter:   7716/156230 | loss: 1.1672 | ds_loss: 1.1787 | lr: 9.9403e-05 | scale: 131072.0000 | micro time: 1.397 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7717/156230 | global iter:   7717/156230 | loss: 1.0738 | ds_loss: 1.0925 | lr: 9.9403e-05 | scale: 131072.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   7718/156230 | global iter:   7718/156230 | loss: 0.9597 | ds_loss: 0.9896 | lr: 9.9403e-05 | scale: 131072.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   7719/156230 | global iter:   7719/156230 | loss: 1.2053 | ds_loss: 1.2138 | lr: 9.9403e-05 | scale: 131072.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   7720/156230 | global iter:   7720/156230 | loss: 1.1106 | ds_loss: 1.1422 | lr: 9.9403e-05 | scale: 131072.0000 | micro time: 1.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7720/156230 | global iter:   7720/156230 | loss: 1.0874 | ds_loss: 1.1095 | lr: 9.9403e-05 | scale: 131072.0000 | micro time: 1.394 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7721/156230 | global iter:   7721/156230 | loss: 1.1632 | ds_loss: 1.1613 | lr: 9.9403e-05 | scale: 131072.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   7722/156230 | global iter:   7722/156230 | loss: 1.0318 | ds_loss: 1.0485 | lr: 9.9402e-05 | scale: 131072.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   7723/156230 | global iter:   7723/156230 | loss: 1.1564 | ds_loss: 1.1827 | lr: 9.9402e-05 | scale: 131072.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   7724/156230 | global iter:   7724/156230 | loss: 0.9880 | ds_loss: 1.0110 | lr: 9.9402e-05 | scale: 131072.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7724/156230 | global iter:   7724/156230 | loss: 1.0848 | ds_loss: 1.1009 | lr: 9.9402e-05 | scale: 131072.0000 | micro time: 1.374 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7725/156230 | global iter:   7725/156230 | loss: 0.9544 | ds_loss: 0.9795 | lr: 9.9402e-05 | scale: 131072.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   7726/156230 | global iter:   7726/156230 | loss: 1.0129 | ds_loss: 1.0414 | lr: 9.9402e-05 | scale: 131072.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   7727/156230 | global iter:   7727/156230 | loss: 1.0988 | ds_loss: 1.1212 | lr: 9.9402e-05 | scale: 131072.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   7728/156230 | global iter:   7728/156230 | loss: 1.2149 | ds_loss: 1.2200 | lr: 9.9401e-05 | scale: 131072.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7728/156230 | global iter:   7728/156230 | loss: 1.0703 | ds_loss: 1.0905 | lr: 9.9401e-05 | scale: 131072.0000 | micro time: 1.365 | step time: 1.347
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7729/156230 | global iter:   7729/156230 | loss: 1.0018 | ds_loss: 1.0297 | lr: 9.9401e-05 | scale: 131072.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   7730/156230 | global iter:   7730/156230 | loss: 1.0618 | ds_loss: 1.0895 | lr: 9.9401e-05 | scale: 131072.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   7731/156230 | global iter:   7731/156230 | loss: 1.0599 | ds_loss: 1.0875 | lr: 9.9401e-05 | scale: 131072.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   7732/156230 | global iter:   7732/156230 | loss: 1.0812 | ds_loss: 1.1095 | lr: 9.9401e-05 | scale: 131072.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7732/156230 | global iter:   7732/156230 | loss: 1.0512 | ds_loss: 1.0790 | lr: 9.9401e-05 | scale: 131072.0000 | micro time: 1.349 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7733/156230 | global iter:   7733/156230 | loss: 1.1261 | ds_loss: 1.1477 | lr: 9.9401e-05 | scale: 131072.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   7734/156230 | global iter:   7734/156230 | loss: 1.1243 | ds_loss: 1.1237 | lr: 9.9401e-05 | scale: 131072.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   7735/156230 | global iter:   7735/156230 | loss: 1.0544 | ds_loss: 1.0669 | lr: 9.9400e-05 | scale: 131072.0000 | micro time: 1.405 | step time: 0.000
train | epoch   0 | Iter:   7736/156230 | global iter:   7736/156230 | loss: 1.0153 | ds_loss: 1.0250 | lr: 9.9400e-05 | scale: 131072.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7736/156230 | global iter:   7736/156230 | loss: 1.0800 | ds_loss: 1.0908 | lr: 9.9400e-05 | scale: 131072.0000 | micro time: 1.370 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7737/156230 | global iter:   7737/156230 | loss: 1.0161 | ds_loss: 1.0592 | lr: 9.9400e-05 | scale: 131072.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   7738/156230 | global iter:   7738/156230 | loss: 1.0366 | ds_loss: 1.0777 | lr: 9.9400e-05 | scale: 131072.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7739/156230 | global iter:   7739/156230 | loss: 1.3054 | ds_loss: 1.3191 | lr: 9.9400e-05 | scale: 131072.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   7740/156230 | global iter:   7740/156230 | loss: 1.0464 | ds_loss: 1.0587 | lr: 9.9400e-05 | scale: 131072.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7740/156230 | global iter:   7740/156230 | loss: 1.1011 | ds_loss: 1.1287 | lr: 9.9400e-05 | scale: 131072.0000 | micro time: 1.377 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7741/156230 | global iter:   7741/156230 | loss: 1.0476 | ds_loss: 1.0582 | lr: 9.9399e-05 | scale: 131072.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   7742/156230 | global iter:   7742/156230 | loss: 1.1437 | ds_loss: 1.1746 | lr: 9.9399e-05 | scale: 131072.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   7743/156230 | global iter:   7743/156230 | loss: 0.9997 | ds_loss: 1.0020 | lr: 9.9399e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   7744/156230 | global iter:   7744/156230 | loss: 1.1577 | ds_loss: 1.1878 | lr: 9.9399e-05 | scale: 131072.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7744/156230 | global iter:   7744/156230 | loss: 1.0872 | ds_loss: 1.1056 | lr: 9.9399e-05 | scale: 131072.0000 | micro time: 1.363 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7745/156230 | global iter:   7745/156230 | loss: 1.0856 | ds_loss: 1.1056 | lr: 9.9399e-05 | scale: 131072.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7746/156230 | global iter:   7746/156230 | loss: 1.0062 | ds_loss: 1.0290 | lr: 9.9399e-05 | scale: 131072.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   7747/156230 | global iter:   7747/156230 | loss: 1.0401 | ds_loss: 1.0540 | lr: 9.9399e-05 | scale: 131072.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   7748/156230 | global iter:   7748/156230 | loss: 1.0031 | ds_loss: 1.0202 | lr: 9.9398e-05 | scale: 131072.0000 | micro time: 1.341 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7748/156230 | global iter:   7748/156230 | loss: 1.0338 | ds_loss: 1.0522 | lr: 9.9398e-05 | scale: 131072.0000 | micro time: 1.341 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7749/156230 | global iter:   7749/156230 | loss: 1.1523 | ds_loss: 1.1759 | lr: 9.9398e-05 | scale: 131072.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   7750/156230 | global iter:   7750/156230 | loss: 1.2322 | ds_loss: 1.2531 | lr: 9.9398e-05 | scale: 131072.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   7751/156230 | global iter:   7751/156230 | loss: 1.0156 | ds_loss: 1.0484 | lr: 9.9398e-05 | scale: 131072.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   7752/156230 | global iter:   7752/156230 | loss: 0.8964 | ds_loss: 0.9227 | lr: 9.9398e-05 | scale: 131072.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7752/156230 | global iter:   7752/156230 | loss: 1.0741 | ds_loss: 1.1000 | lr: 9.9398e-05 | scale: 131072.0000 | micro time: 1.366 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7753/156230 | global iter:   7753/156230 | loss: 1.1072 | ds_loss: 1.1098 | lr: 9.9398e-05 | scale: 131072.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   7754/156230 | global iter:   7754/156230 | loss: 1.0789 | ds_loss: 1.1075 | lr: 9.9397e-05 | scale: 131072.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   7755/156230 | global iter:   7755/156230 | loss: 0.9966 | ds_loss: 1.0246 | lr: 9.9397e-05 | scale: 131072.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   7756/156230 | global iter:   7756/156230 | loss: 1.0057 | ds_loss: 1.0270 | lr: 9.9397e-05 | scale: 131072.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7756/156230 | global iter:   7756/156230 | loss: 1.0471 | ds_loss: 1.0672 | lr: 9.9397e-05 | scale: 131072.0000 | micro time: 1.393 | step time: 1.380
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7757/156230 | global iter:   7757/156230 | loss: 1.1145 | ds_loss: 1.1564 | lr: 9.9397e-05 | scale: 131072.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   7758/156230 | global iter:   7758/156230 | loss: 1.0365 | ds_loss: 1.0513 | lr: 9.9397e-05 | scale: 131072.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   7759/156230 | global iter:   7759/156230 | loss: 0.9783 | ds_loss: 0.9865 | lr: 9.9397e-05 | scale: 131072.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   7760/156230 | global iter:   7760/156230 | loss: 1.1467 | ds_loss: 1.1704 | lr: 9.9397e-05 | scale: 131072.0000 | micro time: 1.334 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7760/156230 | global iter:   7760/156230 | loss: 1.0690 | ds_loss: 1.0911 | lr: 9.9397e-05 | scale: 131072.0000 | micro time: 1.334 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7761/156230 | global iter:   7761/156230 | loss: 1.0258 | ds_loss: 1.0371 | lr: 9.9396e-05 | scale: 131072.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   7762/156230 | global iter:   7762/156230 | loss: 1.1264 | ds_loss: 1.1530 | lr: 9.9396e-05 | scale: 131072.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   7763/156230 | global iter:   7763/156230 | loss: 1.1611 | ds_loss: 1.1695 | lr: 9.9396e-05 | scale: 131072.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   7764/156230 | global iter:   7764/156230 | loss: 1.1464 | ds_loss: 1.1512 | lr: 9.9396e-05 | scale: 131072.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7764/156230 | global iter:   7764/156230 | loss: 1.1149 | ds_loss: 1.1277 | lr: 9.9396e-05 | scale: 131072.0000 | micro time: 1.366 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7765/156230 | global iter:   7765/156230 | loss: 1.0205 | ds_loss: 1.0405 | lr: 9.9396e-05 | scale: 131072.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   7766/156230 | global iter:   7766/156230 | loss: 1.0499 | ds_loss: 1.0750 | lr: 9.9396e-05 | scale: 131072.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   7767/156230 | global iter:   7767/156230 | loss: 1.1434 | ds_loss: 1.1729 | lr: 9.9395e-05 | scale: 131072.0000 | micro time: 1.356 | step time: 0.000
train | epoch   0 | Iter:   7768/156230 | global iter:   7768/156230 | loss: 1.0928 | ds_loss: 1.1099 | lr: 9.9395e-05 | scale: 131072.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7768/156230 | global iter:   7768/156230 | loss: 1.0767 | ds_loss: 1.0996 | lr: 9.9395e-05 | scale: 131072.0000 | micro time: 1.378 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7769/156230 | global iter:   7769/156230 | loss: 1.0337 | ds_loss: 1.0654 | lr: 9.9395e-05 | scale: 131072.0000 | micro time: 1.408 | step time: 0.000
train | epoch   0 | Iter:   7770/156230 | global iter:   7770/156230 | loss: 1.0918 | ds_loss: 1.1248 | lr: 9.9395e-05 | scale: 131072.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   7771/156230 | global iter:   7771/156230 | loss: 0.9127 | ds_loss: 0.9291 | lr: 9.9395e-05 | scale: 131072.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   7772/156230 | global iter:   7772/156230 | loss: 1.2054 | ds_loss: 1.2176 | lr: 9.9395e-05 | scale: 131072.0000 | micro time: 1.337 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7772/156230 | global iter:   7772/156230 | loss: 1.0609 | ds_loss: 1.0842 | lr: 9.9395e-05 | scale: 131072.0000 | micro time: 1.337 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7773/156230 | global iter:   7773/156230 | loss: 1.1336 | ds_loss: 1.1437 | lr: 9.9395e-05 | scale: 131072.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   7774/156230 | global iter:   7774/156230 | loss: 1.1027 | ds_loss: 1.1273 | lr: 9.9394e-05 | scale: 131072.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   7775/156230 | global iter:   7775/156230 | loss: 1.1380 | ds_loss: 1.1464 | lr: 9.9394e-05 | scale: 131072.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   7776/156230 | global iter:   7776/156230 | loss: 1.1531 | ds_loss: 1.1684 | lr: 9.9394e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7776/156230 | global iter:   7776/156230 | loss: 1.1318 | ds_loss: 1.1464 | lr: 9.9394e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 1.383
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7777/156230 | global iter:   7777/156230 | loss: 1.1949 | ds_loss: 1.2102 | lr: 9.9394e-05 | scale: 131072.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   7778/156230 | global iter:   7778/156230 | loss: 1.2536 | ds_loss: 1.2752 | lr: 9.9394e-05 | scale: 131072.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   7779/156230 | global iter:   7779/156230 | loss: 1.1541 | ds_loss: 1.1649 | lr: 9.9394e-05 | scale: 131072.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   7780/156230 | global iter:   7780/156230 | loss: 1.0448 | ds_loss: 1.0719 | lr: 9.9393e-05 | scale: 131072.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7780/156230 | global iter:   7780/156230 | loss: 1.1618 | ds_loss: 1.1806 | lr: 9.9393e-05 | scale: 131072.0000 | micro time: 1.354 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7781/156230 | global iter:   7781/156230 | loss: 1.1066 | ds_loss: 1.1316 | lr: 9.9393e-05 | scale: 131072.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   7782/156230 | global iter:   7782/156230 | loss: 1.1582 | ds_loss: 1.1780 | lr: 9.9393e-05 | scale: 131072.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   7783/156230 | global iter:   7783/156230 | loss: 1.1837 | ds_loss: 1.1989 | lr: 9.9393e-05 | scale: 131072.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7784/156230 | global iter:   7784/156230 | loss: 1.0458 | ds_loss: 1.0719 | lr: 9.9393e-05 | scale: 131072.0000 | micro time: 1.392 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7784/156230 | global iter:   7784/156230 | loss: 1.1236 | ds_loss: 1.1451 | lr: 9.9393e-05 | scale: 131072.0000 | micro time: 1.392 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7785/156230 | global iter:   7785/156230 | loss: 1.1895 | ds_loss: 1.2038 | lr: 9.9393e-05 | scale: 131072.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   7786/156230 | global iter:   7786/156230 | loss: 1.2749 | ds_loss: 1.3125 | lr: 9.9392e-05 | scale: 131072.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   7787/156230 | global iter:   7787/156230 | loss: 0.9289 | ds_loss: 0.9522 | lr: 9.9392e-05 | scale: 131072.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   7788/156230 | global iter:   7788/156230 | loss: 1.0348 | ds_loss: 1.0567 | lr: 9.9392e-05 | scale: 131072.0000 | micro time: 1.337 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7788/156230 | global iter:   7788/156230 | loss: 1.1070 | ds_loss: 1.1313 | lr: 9.9392e-05 | scale: 131072.0000 | micro time: 1.337 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7789/156230 | global iter:   7789/156230 | loss: 0.9171 | ds_loss: 0.9444 | lr: 9.9392e-05 | scale: 131072.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   7790/156230 | global iter:   7790/156230 | loss: 1.0419 | ds_loss: 1.0470 | lr: 9.9392e-05 | scale: 131072.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   7791/156230 | global iter:   7791/156230 | loss: 1.2495 | ds_loss: 1.2654 | lr: 9.9392e-05 | scale: 131072.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   7792/156230 | global iter:   7792/156230 | loss: 1.1259 | ds_loss: 1.1538 | lr: 9.9392e-05 | scale: 131072.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7792/156230 | global iter:   7792/156230 | loss: 1.0836 | ds_loss: 1.1027 | lr: 9.9392e-05 | scale: 131072.0000 | micro time: 1.369 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7793/156230 | global iter:   7793/156230 | loss: 1.0662 | ds_loss: 1.0887 | lr: 9.9391e-05 | scale: 131072.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   7794/156230 | global iter:   7794/156230 | loss: 1.1883 | ds_loss: 1.2043 | lr: 9.9391e-05 | scale: 131072.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   7795/156230 | global iter:   7795/156230 | loss: 1.1052 | ds_loss: 1.1306 | lr: 9.9391e-05 | scale: 131072.0000 | micro time: 1.404 | step time: 0.000
train | epoch   0 | Iter:   7796/156230 | global iter:   7796/156230 | loss: 0.8731 | ds_loss: 0.8976 | lr: 9.9391e-05 | scale: 131072.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7796/156230 | global iter:   7796/156230 | loss: 1.0582 | ds_loss: 1.0803 | lr: 9.9391e-05 | scale: 131072.0000 | micro time: 1.376 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7797/156230 | global iter:   7797/156230 | loss: 0.9209 | ds_loss: 0.9461 | lr: 9.9391e-05 | scale: 131072.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   7798/156230 | global iter:   7798/156230 | loss: 1.0493 | ds_loss: 1.0723 | lr: 9.9391e-05 | scale: 131072.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   7799/156230 | global iter:   7799/156230 | loss: 1.1286 | ds_loss: 1.1566 | lr: 9.9390e-05 | scale: 131072.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   7800/156230 | global iter:   7800/156230 | loss: 0.9490 | ds_loss: 0.9631 | lr: 9.9390e-05 | scale: 131072.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7800/156230 | global iter:   7800/156230 | loss: 1.0119 | ds_loss: 1.0345 | lr: 9.9390e-05 | scale: 131072.0000 | micro time: 1.377 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7801/156230 | global iter:   7801/156230 | loss: 1.1625 | ds_loss: 1.1814 | lr: 9.9390e-05 | scale: 131072.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   7802/156230 | global iter:   7802/156230 | loss: 1.0108 | ds_loss: 1.0167 | lr: 9.9390e-05 | scale: 131072.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:   7803/156230 | global iter:   7803/156230 | loss: 0.9497 | ds_loss: 0.9734 | lr: 9.9390e-05 | scale: 131072.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   7804/156230 | global iter:   7804/156230 | loss: 0.9703 | ds_loss: 0.9951 | lr: 9.9390e-05 | scale: 131072.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7804/156230 | global iter:   7804/156230 | loss: 1.0234 | ds_loss: 1.0417 | lr: 9.9390e-05 | scale: 131072.0000 | micro time: 1.363 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7805/156230 | global iter:   7805/156230 | loss: 1.0783 | ds_loss: 1.1008 | lr: 9.9390e-05 | scale: 131072.0000 | micro time: 1.405 | step time: 0.000
train | epoch   0 | Iter:   7806/156230 | global iter:   7806/156230 | loss: 1.2267 | ds_loss: 1.2572 | lr: 9.9389e-05 | scale: 131072.0000 | micro time: 1.325 | step time: 0.000
train | epoch   0 | Iter:   7807/156230 | global iter:   7807/156230 | loss: 0.8780 | ds_loss: 0.8899 | lr: 9.9389e-05 | scale: 131072.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   7808/156230 | global iter:   7808/156230 | loss: 1.0059 | ds_loss: 1.0256 | lr: 9.9389e-05 | scale: 131072.0000 | micro time: 1.343 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7808/156230 | global iter:   7808/156230 | loss: 1.0472 | ds_loss: 1.0684 | lr: 9.9389e-05 | scale: 131072.0000 | micro time: 1.343 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7809/156230 | global iter:   7809/156230 | loss: 1.2203 | ds_loss: 1.2324 | lr: 9.9389e-05 | scale: 131072.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   7810/156230 | global iter:   7810/156230 | loss: 0.9323 | ds_loss: 0.9410 | lr: 9.9389e-05 | scale: 131072.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   7811/156230 | global iter:   7811/156230 | loss: 1.2284 | ds_loss: 1.2321 | lr: 9.9389e-05 | scale: 131072.0000 | micro time: 1.384 | step time: 0.000
train | epoch   0 | Iter:   7812/156230 | global iter:   7812/156230 | loss: 1.1499 | ds_loss: 1.1592 | lr: 9.9388e-05 | scale: 131072.0000 | micro time: 1.329 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7812/156230 | global iter:   7812/156230 | loss: 1.1327 | ds_loss: 1.1412 | lr: 9.9388e-05 | scale: 131072.0000 | micro time: 1.329 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7813/156230 | global iter:   7813/156230 | loss: 1.1080 | ds_loss: 1.1163 | lr: 9.9388e-05 | scale: 131072.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7814/156230 | global iter:   7814/156230 | loss: 1.0595 | ds_loss: 1.0676 | lr: 9.9388e-05 | scale: 131072.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   7815/156230 | global iter:   7815/156230 | loss: 1.1828 | ds_loss: 1.1976 | lr: 9.9388e-05 | scale: 131072.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   7816/156230 | global iter:   7816/156230 | loss: 1.0700 | ds_loss: 1.0863 | lr: 9.9388e-05 | scale: 131072.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7816/156230 | global iter:   7816/156230 | loss: 1.1051 | ds_loss: 1.1170 | lr: 9.9388e-05 | scale: 131072.0000 | micro time: 1.365 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7817/156230 | global iter:   7817/156230 | loss: 1.0855 | ds_loss: 1.0875 | lr: 9.9388e-05 | scale: 131072.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   7818/156230 | global iter:   7818/156230 | loss: 1.0726 | ds_loss: 1.0887 | lr: 9.9387e-05 | scale: 131072.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   7819/156230 | global iter:   7819/156230 | loss: 1.2105 | ds_loss: 1.2375 | lr: 9.9387e-05 | scale: 131072.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   7820/156230 | global iter:   7820/156230 | loss: 1.0191 | ds_loss: 1.0336 | lr: 9.9387e-05 | scale: 131072.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7820/156230 | global iter:   7820/156230 | loss: 1.0969 | ds_loss: 1.1118 | lr: 9.9387e-05 | scale: 131072.0000 | micro time: 1.365 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7821/156230 | global iter:   7821/156230 | loss: 1.0664 | ds_loss: 1.1024 | lr: 9.9387e-05 | scale: 131072.0000 | micro time: 1.378 | step time: 0.000
[2025-04-20 21:39:00,703] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 131072, reducing to 65536
train | epoch   0 | Iter:   7822/156230 | global iter:   7822/156230 | loss: 1.0668 | ds_loss: 1.0918 | lr: 9.9387e-05 | scale: 65536.0000 | micro time: 1.309 | step time: 0.000
train | epoch   0 | Iter:   7823/156230 | global iter:   7823/156230 | loss: 1.0037 | ds_loss: 1.0193 | lr: 9.9387e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   7824/156230 | global iter:   7824/156230 | loss: 1.0373 | ds_loss: 1.0610 | lr: 9.9387e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7824/156230 | global iter:   7824/156230 | loss: 1.0435 | ds_loss: 1.0686 | lr: 9.9387e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7825/156230 | global iter:   7825/156230 | loss: 0.9371 | ds_loss: 0.9613 | lr: 9.9387e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   7826/156230 | global iter:   7826/156230 | loss: 1.0918 | ds_loss: 1.0961 | lr: 9.9386e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   7827/156230 | global iter:   7827/156230 | loss: 1.0183 | ds_loss: 1.0250 | lr: 9.9386e-05 | scale: 65536.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   7828/156230 | global iter:   7828/156230 | loss: 1.0287 | ds_loss: 1.0645 | lr: 9.9386e-05 | scale: 65536.0000 | micro time: 1.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7828/156230 | global iter:   7828/156230 | loss: 1.0190 | ds_loss: 1.0367 | lr: 9.9386e-05 | scale: 65536.0000 | micro time: 1.396 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7829/156230 | global iter:   7829/156230 | loss: 1.0791 | ds_loss: 1.1014 | lr: 9.9386e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   7830/156230 | global iter:   7830/156230 | loss: 1.0309 | ds_loss: 1.0536 | lr: 9.9386e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   7831/156230 | global iter:   7831/156230 | loss: 0.9698 | ds_loss: 1.0064 | lr: 9.9386e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   7832/156230 | global iter:   7832/156230 | loss: 0.8648 | ds_loss: 0.8890 | lr: 9.9385e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7832/156230 | global iter:   7832/156230 | loss: 0.9862 | ds_loss: 1.0126 | lr: 9.9385e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7833/156230 | global iter:   7833/156230 | loss: 1.1439 | ds_loss: 1.1638 | lr: 9.9385e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   7834/156230 | global iter:   7834/156230 | loss: 0.9959 | ds_loss: 1.0134 | lr: 9.9385e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   7835/156230 | global iter:   7835/156230 | loss: 1.0716 | ds_loss: 1.0926 | lr: 9.9385e-05 | scale: 65536.0000 | micro time: 1.418 | step time: 0.000
train | epoch   0 | Iter:   7836/156230 | global iter:   7836/156230 | loss: 1.0154 | ds_loss: 1.0409 | lr: 9.9385e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7836/156230 | global iter:   7836/156230 | loss: 1.0567 | ds_loss: 1.0777 | lr: 9.9385e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7837/156230 | global iter:   7837/156230 | loss: 1.0793 | ds_loss: 1.0818 | lr: 9.9385e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   7838/156230 | global iter:   7838/156230 | loss: 1.1567 | ds_loss: 1.1923 | lr: 9.9384e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   7839/156230 | global iter:   7839/156230 | loss: 1.2386 | ds_loss: 1.2642 | lr: 9.9384e-05 | scale: 65536.0000 | micro time: 1.413 | step time: 0.000
train | epoch   0 | Iter:   7840/156230 | global iter:   7840/156230 | loss: 1.0387 | ds_loss: 1.0430 | lr: 9.9384e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7840/156230 | global iter:   7840/156230 | loss: 1.1283 | ds_loss: 1.1453 | lr: 9.9384e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 1.378
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7841/156230 | global iter:   7841/156230 | loss: 1.2769 | ds_loss: 1.3039 | lr: 9.9384e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   7842/156230 | global iter:   7842/156230 | loss: 1.1975 | ds_loss: 1.2147 | lr: 9.9384e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   7843/156230 | global iter:   7843/156230 | loss: 1.0048 | ds_loss: 1.0222 | lr: 9.9384e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   7844/156230 | global iter:   7844/156230 | loss: 1.0094 | ds_loss: 1.0166 | lr: 9.9384e-05 | scale: 65536.0000 | micro time: 1.339 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7844/156230 | global iter:   7844/156230 | loss: 1.1222 | ds_loss: 1.1394 | lr: 9.9384e-05 | scale: 65536.0000 | micro time: 1.339 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7845/156230 | global iter:   7845/156230 | loss: 0.9626 | ds_loss: 0.9726 | lr: 9.9383e-05 | scale: 65536.0000 | micro time: 1.339 | step time: 0.000
train | epoch   0 | Iter:   7846/156230 | global iter:   7846/156230 | loss: 1.0932 | ds_loss: 1.1197 | lr: 9.9383e-05 | scale: 65536.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   7847/156230 | global iter:   7847/156230 | loss: 1.0119 | ds_loss: 1.0205 | lr: 9.9383e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7848/156230 | global iter:   7848/156230 | loss: 1.2736 | ds_loss: 1.3011 | lr: 9.9383e-05 | scale: 65536.0000 | micro time: 1.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7848/156230 | global iter:   7848/156230 | loss: 1.0853 | ds_loss: 1.1035 | lr: 9.9383e-05 | scale: 65536.0000 | micro time: 1.394 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7849/156230 | global iter:   7849/156230 | loss: 1.1396 | ds_loss: 1.1539 | lr: 9.9383e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   7850/156230 | global iter:   7850/156230 | loss: 1.1135 | ds_loss: 1.1447 | lr: 9.9383e-05 | scale: 65536.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   7851/156230 | global iter:   7851/156230 | loss: 0.9794 | ds_loss: 1.0009 | lr: 9.9382e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   7852/156230 | global iter:   7852/156230 | loss: 1.1536 | ds_loss: 1.1757 | lr: 9.9382e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7852/156230 | global iter:   7852/156230 | loss: 1.0965 | ds_loss: 1.1188 | lr: 9.9382e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 1.348
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7853/156230 | global iter:   7853/156230 | loss: 1.1701 | ds_loss: 1.1924 | lr: 9.9382e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   7854/156230 | global iter:   7854/156230 | loss: 0.9840 | ds_loss: 1.0106 | lr: 9.9382e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   7855/156230 | global iter:   7855/156230 | loss: 0.9971 | ds_loss: 1.0102 | lr: 9.9382e-05 | scale: 65536.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   7856/156230 | global iter:   7856/156230 | loss: 1.2082 | ds_loss: 1.2398 | lr: 9.9382e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7856/156230 | global iter:   7856/156230 | loss: 1.0898 | ds_loss: 1.1132 | lr: 9.9382e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7857/156230 | global iter:   7857/156230 | loss: 0.9467 | ds_loss: 0.9835 | lr: 9.9381e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   7858/156230 | global iter:   7858/156230 | loss: 0.9849 | ds_loss: 1.0079 | lr: 9.9381e-05 | scale: 65536.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   7859/156230 | global iter:   7859/156230 | loss: 1.1396 | ds_loss: 1.1750 | lr: 9.9381e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   7860/156230 | global iter:   7860/156230 | loss: 1.0749 | ds_loss: 1.1059 | lr: 9.9381e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7860/156230 | global iter:   7860/156230 | loss: 1.0365 | ds_loss: 1.0681 | lr: 9.9381e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7861/156230 | global iter:   7861/156230 | loss: 1.1343 | ds_loss: 1.1537 | lr: 9.9381e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   7862/156230 | global iter:   7862/156230 | loss: 1.2913 | ds_loss: 1.3193 | lr: 9.9381e-05 | scale: 65536.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   7863/156230 | global iter:   7863/156230 | loss: 1.0550 | ds_loss: 1.0592 | lr: 9.9381e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   7864/156230 | global iter:   7864/156230 | loss: 1.0958 | ds_loss: 1.1147 | lr: 9.9380e-05 | scale: 65536.0000 | micro time: 1.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7864/156230 | global iter:   7864/156230 | loss: 1.1441 | ds_loss: 1.1617 | lr: 9.9380e-05 | scale: 65536.0000 | micro time: 1.396 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7865/156230 | global iter:   7865/156230 | loss: 1.1385 | ds_loss: 1.1501 | lr: 9.9380e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   7866/156230 | global iter:   7866/156230 | loss: 1.1448 | ds_loss: 1.1737 | lr: 9.9380e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   7867/156230 | global iter:   7867/156230 | loss: 1.2305 | ds_loss: 1.2446 | lr: 9.9380e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   7868/156230 | global iter:   7868/156230 | loss: 0.9920 | ds_loss: 1.0198 | lr: 9.9380e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7868/156230 | global iter:   7868/156230 | loss: 1.1264 | ds_loss: 1.1470 | lr: 9.9380e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7869/156230 | global iter:   7869/156230 | loss: 0.9921 | ds_loss: 1.0038 | lr: 9.9380e-05 | scale: 65536.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   7870/156230 | global iter:   7870/156230 | loss: 1.1122 | ds_loss: 1.1493 | lr: 9.9379e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   7871/156230 | global iter:   7871/156230 | loss: 1.1703 | ds_loss: 1.1872 | lr: 9.9379e-05 | scale: 65536.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   7872/156230 | global iter:   7872/156230 | loss: 0.9987 | ds_loss: 1.0145 | lr: 9.9379e-05 | scale: 65536.0000 | micro time: 1.391 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7872/156230 | global iter:   7872/156230 | loss: 1.0683 | ds_loss: 1.0887 | lr: 9.9379e-05 | scale: 65536.0000 | micro time: 1.391 | step time: 1.387
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7873/156230 | global iter:   7873/156230 | loss: 0.9616 | ds_loss: 0.9725 | lr: 9.9379e-05 | scale: 65536.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   7874/156230 | global iter:   7874/156230 | loss: 1.0560 | ds_loss: 1.1027 | lr: 9.9379e-05 | scale: 65536.0000 | micro time: 1.347 | step time: 0.000
train | epoch   0 | Iter:   7875/156230 | global iter:   7875/156230 | loss: 1.1137 | ds_loss: 1.1267 | lr: 9.9379e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   7876/156230 | global iter:   7876/156230 | loss: 1.1104 | ds_loss: 1.1350 | lr: 9.9378e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7876/156230 | global iter:   7876/156230 | loss: 1.0604 | ds_loss: 1.0842 | lr: 9.9378e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7877/156230 | global iter:   7877/156230 | loss: 1.1282 | ds_loss: 1.1296 | lr: 9.9378e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   7878/156230 | global iter:   7878/156230 | loss: 0.9057 | ds_loss: 0.9222 | lr: 9.9378e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   7879/156230 | global iter:   7879/156230 | loss: 1.2656 | ds_loss: 1.3041 | lr: 9.9378e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   7880/156230 | global iter:   7880/156230 | loss: 1.2759 | ds_loss: 1.2947 | lr: 9.9378e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7880/156230 | global iter:   7880/156230 | loss: 1.1438 | ds_loss: 1.1626 | lr: 9.9378e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7881/156230 | global iter:   7881/156230 | loss: 0.8232 | ds_loss: 0.8445 | lr: 9.9378e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   7882/156230 | global iter:   7882/156230 | loss: 1.1675 | ds_loss: 1.1784 | lr: 9.9378e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   7883/156230 | global iter:   7883/156230 | loss: 1.0179 | ds_loss: 1.0365 | lr: 9.9377e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   7884/156230 | global iter:   7884/156230 | loss: 1.0790 | ds_loss: 1.0988 | lr: 9.9377e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7884/156230 | global iter:   7884/156230 | loss: 1.0219 | ds_loss: 1.0396 | lr: 9.9377e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7885/156230 | global iter:   7885/156230 | loss: 1.1005 | ds_loss: 1.1215 | lr: 9.9377e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   7886/156230 | global iter:   7886/156230 | loss: 0.9975 | ds_loss: 1.0047 | lr: 9.9377e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   7887/156230 | global iter:   7887/156230 | loss: 1.0231 | ds_loss: 1.0199 | lr: 9.9377e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   7888/156230 | global iter:   7888/156230 | loss: 1.0577 | ds_loss: 1.0957 | lr: 9.9377e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7888/156230 | global iter:   7888/156230 | loss: 1.0447 | ds_loss: 1.0605 | lr: 9.9377e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 1.350
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7889/156230 | global iter:   7889/156230 | loss: 0.9483 | ds_loss: 0.9749 | lr: 9.9376e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   7890/156230 | global iter:   7890/156230 | loss: 1.0739 | ds_loss: 1.1016 | lr: 9.9376e-05 | scale: 65536.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   7891/156230 | global iter:   7891/156230 | loss: 1.0708 | ds_loss: 1.0936 | lr: 9.9376e-05 | scale: 65536.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   7892/156230 | global iter:   7892/156230 | loss: 1.0800 | ds_loss: 1.1003 | lr: 9.9376e-05 | scale: 65536.0000 | micro time: 1.313 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7892/156230 | global iter:   7892/156230 | loss: 1.0433 | ds_loss: 1.0676 | lr: 9.9376e-05 | scale: 65536.0000 | micro time: 1.313 | step time: 1.330
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7893/156230 | global iter:   7893/156230 | loss: 1.1245 | ds_loss: 1.1435 | lr: 9.9376e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   7894/156230 | global iter:   7894/156230 | loss: 1.3125 | ds_loss: 1.3246 | lr: 9.9376e-05 | scale: 65536.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:   7895/156230 | global iter:   7895/156230 | loss: 1.2318 | ds_loss: 1.2689 | lr: 9.9375e-05 | scale: 65536.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   7896/156230 | global iter:   7896/156230 | loss: 0.9719 | ds_loss: 1.0030 | lr: 9.9375e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7896/156230 | global iter:   7896/156230 | loss: 1.1602 | ds_loss: 1.1850 | lr: 9.9375e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7897/156230 | global iter:   7897/156230 | loss: 1.1100 | ds_loss: 1.1135 | lr: 9.9375e-05 | scale: 65536.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:   7898/156230 | global iter:   7898/156230 | loss: 1.1508 | ds_loss: 1.1690 | lr: 9.9375e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   7899/156230 | global iter:   7899/156230 | loss: 1.0903 | ds_loss: 1.1217 | lr: 9.9375e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   7900/156230 | global iter:   7900/156230 | loss: 0.8934 | ds_loss: 0.9010 | lr: 9.9375e-05 | scale: 65536.0000 | micro time: 1.323 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7900/156230 | global iter:   7900/156230 | loss: 1.0611 | ds_loss: 1.0763 | lr: 9.9375e-05 | scale: 65536.0000 | micro time: 1.323 | step time: 1.356
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7901/156230 | global iter:   7901/156230 | loss: 1.1187 | ds_loss: 1.1482 | lr: 9.9375e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   7902/156230 | global iter:   7902/156230 | loss: 1.2395 | ds_loss: 1.2707 | lr: 9.9374e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   7903/156230 | global iter:   7903/156230 | loss: 1.1419 | ds_loss: 1.1440 | lr: 9.9374e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7904/156230 | global iter:   7904/156230 | loss: 0.8782 | ds_loss: 0.9075 | lr: 9.9374e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7904/156230 | global iter:   7904/156230 | loss: 1.0946 | ds_loss: 1.1176 | lr: 9.9374e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7905/156230 | global iter:   7905/156230 | loss: 0.9663 | ds_loss: 0.9891 | lr: 9.9374e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   7906/156230 | global iter:   7906/156230 | loss: 1.1808 | ds_loss: 1.1909 | lr: 9.9374e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   7907/156230 | global iter:   7907/156230 | loss: 0.8797 | ds_loss: 0.9037 | lr: 9.9374e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   7908/156230 | global iter:   7908/156230 | loss: 0.9998 | ds_loss: 1.0026 | lr: 9.9373e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7908/156230 | global iter:   7908/156230 | loss: 1.0066 | ds_loss: 1.0216 | lr: 9.9373e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7909/156230 | global iter:   7909/156230 | loss: 1.2610 | ds_loss: 1.2771 | lr: 9.9373e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   7910/156230 | global iter:   7910/156230 | loss: 1.0705 | ds_loss: 1.0907 | lr: 9.9373e-05 | scale: 65536.0000 | micro time: 1.399 | step time: 0.000
train | epoch   0 | Iter:   7911/156230 | global iter:   7911/156230 | loss: 1.0925 | ds_loss: 1.1077 | lr: 9.9373e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   7912/156230 | global iter:   7912/156230 | loss: 1.0658 | ds_loss: 1.0850 | lr: 9.9373e-05 | scale: 65536.0000 | micro time: 1.325 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7912/156230 | global iter:   7912/156230 | loss: 1.1224 | ds_loss: 1.1401 | lr: 9.9373e-05 | scale: 65536.0000 | micro time: 1.325 | step time: 1.355
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7913/156230 | global iter:   7913/156230 | loss: 0.9953 | ds_loss: 1.0222 | lr: 9.9373e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   7914/156230 | global iter:   7914/156230 | loss: 1.2026 | ds_loss: 1.2118 | lr: 9.9372e-05 | scale: 65536.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:   7915/156230 | global iter:   7915/156230 | loss: 0.9937 | ds_loss: 1.0118 | lr: 9.9372e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   7916/156230 | global iter:   7916/156230 | loss: 1.1120 | ds_loss: 1.1530 | lr: 9.9372e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7916/156230 | global iter:   7916/156230 | loss: 1.0759 | ds_loss: 1.0997 | lr: 9.9372e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7917/156230 | global iter:   7917/156230 | loss: 1.0274 | ds_loss: 1.0416 | lr: 9.9372e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   7918/156230 | global iter:   7918/156230 | loss: 1.0770 | ds_loss: 1.0924 | lr: 9.9372e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7919/156230 | global iter:   7919/156230 | loss: 1.1528 | ds_loss: 1.1727 | lr: 9.9372e-05 | scale: 65536.0000 | micro time: 1.413 | step time: 0.000
train | epoch   0 | Iter:   7920/156230 | global iter:   7920/156230 | loss: 1.1202 | ds_loss: 1.1525 | lr: 9.9372e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7920/156230 | global iter:   7920/156230 | loss: 1.0943 | ds_loss: 1.1148 | lr: 9.9372e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 1.374
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7921/156230 | global iter:   7921/156230 | loss: 1.1112 | ds_loss: 1.1327 | lr: 9.9371e-05 | scale: 65536.0000 | micro time: 1.404 | step time: 0.000
train | epoch   0 | Iter:   7922/156230 | global iter:   7922/156230 | loss: 1.0703 | ds_loss: 1.0934 | lr: 9.9371e-05 | scale: 65536.0000 | micro time: 1.433 | step time: 0.000
train | epoch   0 | Iter:   7923/156230 | global iter:   7923/156230 | loss: 1.1009 | ds_loss: 1.1182 | lr: 9.9371e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   7924/156230 | global iter:   7924/156230 | loss: 1.1807 | ds_loss: 1.1859 | lr: 9.9371e-05 | scale: 65536.0000 | micro time: 1.308 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7924/156230 | global iter:   7924/156230 | loss: 1.1158 | ds_loss: 1.1325 | lr: 9.9371e-05 | scale: 65536.0000 | micro time: 1.308 | step time: 1.379
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7925/156230 | global iter:   7925/156230 | loss: 1.1559 | ds_loss: 1.1749 | lr: 9.9371e-05 | scale: 65536.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   7926/156230 | global iter:   7926/156230 | loss: 1.1289 | ds_loss: 1.1352 | lr: 9.9371e-05 | scale: 65536.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   7927/156230 | global iter:   7927/156230 | loss: 1.0633 | ds_loss: 1.0941 | lr: 9.9370e-05 | scale: 65536.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   7928/156230 | global iter:   7928/156230 | loss: 1.0213 | ds_loss: 1.0388 | lr: 9.9370e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7928/156230 | global iter:   7928/156230 | loss: 1.0924 | ds_loss: 1.1107 | lr: 9.9370e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7929/156230 | global iter:   7929/156230 | loss: 1.0073 | ds_loss: 1.0175 | lr: 9.9370e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   7930/156230 | global iter:   7930/156230 | loss: 1.1191 | ds_loss: 1.1374 | lr: 9.9370e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   7931/156230 | global iter:   7931/156230 | loss: 1.0028 | ds_loss: 1.0243 | lr: 9.9370e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   7932/156230 | global iter:   7932/156230 | loss: 1.0255 | ds_loss: 1.0462 | lr: 9.9370e-05 | scale: 65536.0000 | micro time: 1.323 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7932/156230 | global iter:   7932/156230 | loss: 1.0387 | ds_loss: 1.0564 | lr: 9.9370e-05 | scale: 65536.0000 | micro time: 1.323 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7933/156230 | global iter:   7933/156230 | loss: 1.0370 | ds_loss: 1.0608 | lr: 9.9369e-05 | scale: 65536.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   7934/156230 | global iter:   7934/156230 | loss: 1.2235 | ds_loss: 1.2448 | lr: 9.9369e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   7935/156230 | global iter:   7935/156230 | loss: 1.2950 | ds_loss: 1.3283 | lr: 9.9369e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7936/156230 | global iter:   7936/156230 | loss: 1.1025 | ds_loss: 1.1044 | lr: 9.9369e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7936/156230 | global iter:   7936/156230 | loss: 1.1645 | ds_loss: 1.1846 | lr: 9.9369e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7937/156230 | global iter:   7937/156230 | loss: 1.0609 | ds_loss: 1.0655 | lr: 9.9369e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   7938/156230 | global iter:   7938/156230 | loss: 1.1731 | ds_loss: 1.1978 | lr: 9.9369e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   7939/156230 | global iter:   7939/156230 | loss: 1.0291 | ds_loss: 1.0369 | lr: 9.9369e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   7940/156230 | global iter:   7940/156230 | loss: 1.0686 | ds_loss: 1.0878 | lr: 9.9368e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7940/156230 | global iter:   7940/156230 | loss: 1.0829 | ds_loss: 1.0970 | lr: 9.9368e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7941/156230 | global iter:   7941/156230 | loss: 1.0821 | ds_loss: 1.0900 | lr: 9.9368e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   7942/156230 | global iter:   7942/156230 | loss: 1.0099 | ds_loss: 1.0434 | lr: 9.9368e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   7943/156230 | global iter:   7943/156230 | loss: 1.0176 | ds_loss: 1.0271 | lr: 9.9368e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   7944/156230 | global iter:   7944/156230 | loss: 1.0535 | ds_loss: 1.0680 | lr: 9.9368e-05 | scale: 65536.0000 | micro time: 1.394 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7944/156230 | global iter:   7944/156230 | loss: 1.0408 | ds_loss: 1.0571 | lr: 9.9368e-05 | scale: 65536.0000 | micro time: 1.394 | step time: 1.370
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7945/156230 | global iter:   7945/156230 | loss: 1.0924 | ds_loss: 1.1175 | lr: 9.9368e-05 | scale: 65536.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   7946/156230 | global iter:   7946/156230 | loss: 1.1101 | ds_loss: 1.1321 | lr: 9.9367e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   7947/156230 | global iter:   7947/156230 | loss: 1.2903 | ds_loss: 1.3283 | lr: 9.9367e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   7948/156230 | global iter:   7948/156230 | loss: 1.0908 | ds_loss: 1.0974 | lr: 9.9367e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7948/156230 | global iter:   7948/156230 | loss: 1.1459 | ds_loss: 1.1688 | lr: 9.9367e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7949/156230 | global iter:   7949/156230 | loss: 1.1981 | ds_loss: 1.2340 | lr: 9.9367e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   7950/156230 | global iter:   7950/156230 | loss: 1.0350 | ds_loss: 1.0662 | lr: 9.9367e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   7951/156230 | global iter:   7951/156230 | loss: 0.9319 | ds_loss: 0.9441 | lr: 9.9367e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   7952/156230 | global iter:   7952/156230 | loss: 0.9298 | ds_loss: 0.9355 | lr: 9.9366e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7952/156230 | global iter:   7952/156230 | loss: 1.0237 | ds_loss: 1.0450 | lr: 9.9366e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7953/156230 | global iter:   7953/156230 | loss: 1.2511 | ds_loss: 1.2722 | lr: 9.9366e-05 | scale: 65536.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   7954/156230 | global iter:   7954/156230 | loss: 1.0651 | ds_loss: 1.0895 | lr: 9.9366e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   7955/156230 | global iter:   7955/156230 | loss: 1.0836 | ds_loss: 1.1111 | lr: 9.9366e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   7956/156230 | global iter:   7956/156230 | loss: 1.0698 | ds_loss: 1.0816 | lr: 9.9366e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7956/156230 | global iter:   7956/156230 | loss: 1.1174 | ds_loss: 1.1386 | lr: 9.9366e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7957/156230 | global iter:   7957/156230 | loss: 1.2656 | ds_loss: 1.3066 | lr: 9.9366e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   7958/156230 | global iter:   7958/156230 | loss: 1.0823 | ds_loss: 1.0935 | lr: 9.9365e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   7959/156230 | global iter:   7959/156230 | loss: 1.1415 | ds_loss: 1.1650 | lr: 9.9365e-05 | scale: 65536.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   7960/156230 | global iter:   7960/156230 | loss: 0.9782 | ds_loss: 0.9988 | lr: 9.9365e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7960/156230 | global iter:   7960/156230 | loss: 1.1169 | ds_loss: 1.1409 | lr: 9.9365e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 1.375
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7961/156230 | global iter:   7961/156230 | loss: 1.0926 | ds_loss: 1.1315 | lr: 9.9365e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   7962/156230 | global iter:   7962/156230 | loss: 1.0104 | ds_loss: 1.0263 | lr: 9.9365e-05 | scale: 65536.0000 | micro time: 1.319 | step time: 0.000
train | epoch   0 | Iter:   7963/156230 | global iter:   7963/156230 | loss: 1.1505 | ds_loss: 1.1854 | lr: 9.9365e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   7964/156230 | global iter:   7964/156230 | loss: 1.1862 | ds_loss: 1.2052 | lr: 9.9365e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7964/156230 | global iter:   7964/156230 | loss: 1.1099 | ds_loss: 1.1371 | lr: 9.9365e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7965/156230 | global iter:   7965/156230 | loss: 1.0179 | ds_loss: 1.0543 | lr: 9.9364e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7966/156230 | global iter:   7966/156230 | loss: 1.1282 | ds_loss: 1.1510 | lr: 9.9364e-05 | scale: 65536.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   7967/156230 | global iter:   7967/156230 | loss: 1.0555 | ds_loss: 1.0750 | lr: 9.9364e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   7968/156230 | global iter:   7968/156230 | loss: 0.9414 | ds_loss: 0.9745 | lr: 9.9364e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7968/156230 | global iter:   7968/156230 | loss: 1.0357 | ds_loss: 1.0637 | lr: 9.9364e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7969/156230 | global iter:   7969/156230 | loss: 1.0422 | ds_loss: 1.0584 | lr: 9.9364e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   7970/156230 | global iter:   7970/156230 | loss: 0.9185 | ds_loss: 0.9307 | lr: 9.9364e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   7971/156230 | global iter:   7971/156230 | loss: 1.1781 | ds_loss: 1.1943 | lr: 9.9363e-05 | scale: 65536.0000 | micro time: 1.413 | step time: 0.000
train | epoch   0 | Iter:   7972/156230 | global iter:   7972/156230 | loss: 1.1423 | ds_loss: 1.1668 | lr: 9.9363e-05 | scale: 65536.0000 | micro time: 1.318 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7972/156230 | global iter:   7972/156230 | loss: 1.0703 | ds_loss: 1.0875 | lr: 9.9363e-05 | scale: 65536.0000 | micro time: 1.318 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7973/156230 | global iter:   7973/156230 | loss: 1.1894 | ds_loss: 1.2194 | lr: 9.9363e-05 | scale: 65536.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   7974/156230 | global iter:   7974/156230 | loss: 0.9815 | ds_loss: 1.0007 | lr: 9.9363e-05 | scale: 65536.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   7975/156230 | global iter:   7975/156230 | loss: 1.0587 | ds_loss: 1.0891 | lr: 9.9363e-05 | scale: 65536.0000 | micro time: 1.309 | step time: 0.000
train | epoch   0 | Iter:   7976/156230 | global iter:   7976/156230 | loss: 1.0652 | ds_loss: 1.0829 | lr: 9.9363e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7976/156230 | global iter:   7976/156230 | loss: 1.0737 | ds_loss: 1.0980 | lr: 9.9363e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7977/156230 | global iter:   7977/156230 | loss: 1.1487 | ds_loss: 1.1719 | lr: 9.9362e-05 | scale: 65536.0000 | micro time: 1.392 | step time: 0.000
train | epoch   0 | Iter:   7978/156230 | global iter:   7978/156230 | loss: 1.1688 | ds_loss: 1.1771 | lr: 9.9362e-05 | scale: 65536.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   7979/156230 | global iter:   7979/156230 | loss: 1.3776 | ds_loss: 1.4043 | lr: 9.9362e-05 | scale: 65536.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   7980/156230 | global iter:   7980/156230 | loss: 1.1836 | ds_loss: 1.1836 | lr: 9.9362e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7980/156230 | global iter:   7980/156230 | loss: 1.2197 | ds_loss: 1.2342 | lr: 9.9362e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7981/156230 | global iter:   7981/156230 | loss: 0.9726 | ds_loss: 0.9953 | lr: 9.9362e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   7982/156230 | global iter:   7982/156230 | loss: 1.0747 | ds_loss: 1.1026 | lr: 9.9362e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   7983/156230 | global iter:   7983/156230 | loss: 1.1117 | ds_loss: 1.1301 | lr: 9.9361e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   7984/156230 | global iter:   7984/156230 | loss: 1.0877 | ds_loss: 1.1161 | lr: 9.9361e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7984/156230 | global iter:   7984/156230 | loss: 1.0617 | ds_loss: 1.0860 | lr: 9.9361e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7985/156230 | global iter:   7985/156230 | loss: 1.0519 | ds_loss: 1.0867 | lr: 9.9361e-05 | scale: 65536.0000 | micro time: 1.396 | step time: 0.000
train | epoch   0 | Iter:   7986/156230 | global iter:   7986/156230 | loss: 1.1092 | ds_loss: 1.1188 | lr: 9.9361e-05 | scale: 65536.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   7987/156230 | global iter:   7987/156230 | loss: 1.1996 | ds_loss: 1.2234 | lr: 9.9361e-05 | scale: 65536.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   7988/156230 | global iter:   7988/156230 | loss: 1.1081 | ds_loss: 1.1515 | lr: 9.9361e-05 | scale: 65536.0000 | micro time: 1.332 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7988/156230 | global iter:   7988/156230 | loss: 1.1172 | ds_loss: 1.1451 | lr: 9.9361e-05 | scale: 65536.0000 | micro time: 1.332 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7989/156230 | global iter:   7989/156230 | loss: 0.9992 | ds_loss: 1.0215 | lr: 9.9361e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   7990/156230 | global iter:   7990/156230 | loss: 1.0889 | ds_loss: 1.1133 | lr: 9.9360e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   7991/156230 | global iter:   7991/156230 | loss: 1.0843 | ds_loss: 1.0972 | lr: 9.9360e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   7992/156230 | global iter:   7992/156230 | loss: 0.9216 | ds_loss: 0.9502 | lr: 9.9360e-05 | scale: 65536.0000 | micro time: 1.409 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7992/156230 | global iter:   7992/156230 | loss: 1.0235 | ds_loss: 1.0455 | lr: 9.9360e-05 | scale: 65536.0000 | micro time: 1.409 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7993/156230 | global iter:   7993/156230 | loss: 1.1436 | ds_loss: 1.1463 | lr: 9.9360e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   7994/156230 | global iter:   7994/156230 | loss: 1.0369 | ds_loss: 1.0678 | lr: 9.9360e-05 | scale: 65536.0000 | micro time: 1.341 | step time: 0.000
train | epoch   0 | Iter:   7995/156230 | global iter:   7995/156230 | loss: 1.1339 | ds_loss: 1.1667 | lr: 9.9360e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   7996/156230 | global iter:   7996/156230 | loss: 1.0476 | ds_loss: 1.0767 | lr: 9.9359e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   7996/156230 | global iter:   7996/156230 | loss: 1.0905 | ds_loss: 1.1144 | lr: 9.9359e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   7997/156230 | global iter:   7997/156230 | loss: 1.2487 | ds_loss: 1.2735 | lr: 9.9359e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   7998/156230 | global iter:   7998/156230 | loss: 1.3211 | ds_loss: 1.3254 | lr: 9.9359e-05 | scale: 65536.0000 | micro time: 1.355 | step time: 0.000
train | epoch   0 | Iter:   7999/156230 | global iter:   7999/156230 | loss: 1.0795 | ds_loss: 1.1041 | lr: 9.9359e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   8000/156230 | global iter:   8000/156230 | loss: 1.1169 | ds_loss: 1.1436 | lr: 9.9359e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8000/156230 | global iter:   8000/156230 | loss: 1.1916 | ds_loss: 1.2116 | lr: 9.9359e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 1.347
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
Model save to ./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5/8000
dp size 4
/home/users/ap794/final_project_distillLLM/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
0/32
1/32
2/32
3/32
4/32
5/32
6/32
7/32
8/32
9/32
10/32
11/32
12/32
13/32
14/32
Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]Evaluating:   3%|         | 1/32 [00:06<03:17,  6.38s/it]Evaluating:   6%|         | 2/32 [00:11<02:55,  5.86s/it]Evaluating:   9%|         | 3/32 [00:17<02:44,  5.67s/it]Evaluating:  12%|        | 4/32 [00:22<02:35,  5.56s/it]Evaluating:  16%|        | 5/32 [00:28<02:28,  5.49s/it]Evaluating:  19%|        | 6/32 [00:33<02:21,  5.45s/it]Evaluating:  22%|       | 7/32 [00:38<02:15,  5.43s/it]Evaluating:  25%|       | 8/32 [00:44<02:10,  5.45s/it]Evaluating:  28%|       | 9/32 [00:49<02:04,  5.43s/it]Evaluating:  31%|      | 10/32 [00:55<01:59,  5.42s/it]Evaluating:  34%|      | 11/32 [01:00<01:53,  5.42s/it]Evaluating:  38%|      | 12/32 [01:05<01:48,  5.41s/it]Evaluating:  41%|      | 13/32 [01:11<01:42,  5.41s/it]Evaluating:  44%|     | 14/32 [01:16<01:37,  5.43s/it]Evaluating:  47%|     | 15/32 [01:22<01:31,  5.415/32
16/32
17/32
18/32
19/32
20/32
21/32
22/32
23/32
24/32
25/32
26/32
27/32
28/32
0s/it]Evaluating:  50%|     | 16/32 [01:27<01:26,  5.39s/it]Evaluating:  53%|    | 17/32 [01:32<01:20,  5.39s/it]Evaluating:  56%|    | 18/32 [01:38<01:15,  5.39s/it]Evaluating:  59%|    | 19/32 [01:43<01:10,  5.43s/it]Evaluating:  62%|   | 20/32 [01:49<01:05,  5.42s/it]Evaluating:  66%|   | 21/32 [01:54<00:59,  5.40s/it]Evaluating:  69%|   | 22/32 [01:59<00:53,  5.39s/it]Evaluating:  72%|  | 23/32 [02:05<00:48,  5.39s/it]Evaluating:  75%|  | 24/32 [02:10<00:43,  5.38s/it]Evaluating:  78%|  | 25/32 [02:16<00:38,  5.43s/it]Evaluating:  81%| | 26/32 [02:21<00:32,  5.43s/it]Evaluating:  84%| | 27/32 [02:26<00:26,  5.40s/it]Evaluating:  88%| | 28/32 [02:32<00:21,  5.40s/it]Evaluating:  91%| | 29/32
30/32
31/32
29/32 [02:37<00:16,  5.39s/it]Evaluating:  94%|| 30/32 [02:43<00:10,  5.44s/it]Evaluating:  97%|| 31/32 [02:48<00:05,  5.42s/it]Evaluating: 100%|| 32/32 [02:53<00:00,  5.37s/it]Evaluating: 100%|| 32/32 [02:54<00:00,  5.45s/it]
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5/eval/0
dev | avg_loss: 0.9997406005859375 | {'exact_match': 0.0, 'rougeL': 33.1147}
train | epoch   0 | Iter:   8001/156230 | global iter:   8001/156230 | loss: 0.8924 | ds_loss: 0.9089 | lr: 9.9359e-05 | scale: 65536.0000 | micro time: 1.313 | step time: 0.000
train | epoch   0 | Iter:   8002/156230 | global iter:   8002/156230 | loss: 1.1590 | ds_loss: 1.1777 | lr: 9.9358e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   8003/156230 | global iter:   8003/156230 | loss: 0.9883 | ds_loss: 1.0251 | lr: 9.9358e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   8004/156230 | global iter:   8004/156230 | loss: 1.0743 | ds_loss: 1.0999 | lr: 9.9358e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8004/156230 | global iter:   8004/156230 | loss: 1.0285 | ds_loss: 1.0529 | lr: 9.9358e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 1.341
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8005/156230 | global iter:   8005/156230 | loss: 1.2567 | ds_loss: 1.2763 | lr: 9.9358e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   8006/156230 | global iter:   8006/156230 | loss: 1.1009 | ds_loss: 1.1149 | lr: 9.9358e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   8007/156230 | global iter:   8007/156230 | loss: 1.0824 | ds_loss: 1.1007 | lr: 9.9358e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   8008/156230 | global iter:   8008/156230 | loss: 1.2642 | ds_loss: 1.2826 | lr: 9.9357e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8008/156230 | global iter:   8008/156230 | loss: 1.1760 | ds_loss: 1.1936 | lr: 9.9357e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8009/156230 | global iter:   8009/156230 | loss: 1.1441 | ds_loss: 1.1700 | lr: 9.9357e-05 | scale: 65536.0000 | micro time: 1.298 | step time: 0.000
train | epoch   0 | Iter:   8010/156230 | global iter:   8010/156230 | loss: 1.0442 | ds_loss: 1.0658 | lr: 9.9357e-05 | scale: 65536.0000 | micro time: 1.412 | step time: 0.000
train | epoch   0 | Iter:   8011/156230 | global iter:   8011/156230 | loss: 1.0737 | ds_loss: 1.0949 | lr: 9.9357e-05 | scale: 65536.0000 | micro time: 1.313 | step time: 0.000
train | epoch   0 | Iter:   8012/156230 | global iter:   8012/156230 | loss: 1.1535 | ds_loss: 1.1780 | lr: 9.9357e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8012/156230 | global iter:   8012/156230 | loss: 1.1039 | ds_loss: 1.1272 | lr: 9.9357e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8013/156230 | global iter:   8013/156230 | loss: 1.1016 | ds_loss: 1.1334 | lr: 9.9357e-05 | scale: 65536.0000 | micro time: 1.306 | step time: 0.000
train | epoch   0 | Iter:   8014/156230 | global iter:   8014/156230 | loss: 0.9776 | ds_loss: 1.0079 | lr: 9.9357e-05 | scale: 65536.0000 | micro time: 1.326 | step time: 0.000
train | epoch   0 | Iter:   8015/156230 | global iter:   8015/156230 | loss: 1.0224 | ds_loss: 1.0619 | lr: 9.9356e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   8016/156230 | global iter:   8016/156230 | loss: 1.2235 | ds_loss: 1.2461 | lr: 9.9356e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8016/156230 | global iter:   8016/156230 | loss: 1.0813 | ds_loss: 1.1123 | lr: 9.9356e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 1.337
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8017/156230 | global iter:   8017/156230 | loss: 0.9893 | ds_loss: 0.9993 | lr: 9.9356e-05 | scale: 65536.0000 | micro time: 1.318 | step time: 0.000
train | epoch   0 | Iter:   8018/156230 | global iter:   8018/156230 | loss: 0.8927 | ds_loss: 0.9291 | lr: 9.9356e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   8019/156230 | global iter:   8019/156230 | loss: 1.2048 | ds_loss: 1.2221 | lr: 9.9356e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   8020/156230 | global iter:   8020/156230 | loss: 1.1565 | ds_loss: 1.1855 | lr: 9.9356e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8020/156230 | global iter:   8020/156230 | loss: 1.0608 | ds_loss: 1.0840 | lr: 9.9356e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 1.344
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8021/156230 | global iter:   8021/156230 | loss: 1.0145 | ds_loss: 1.0391 | lr: 9.9355e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   8022/156230 | global iter:   8022/156230 | loss: 1.1475 | ds_loss: 1.1469 | lr: 9.9355e-05 | scale: 65536.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:   8023/156230 | global iter:   8023/156230 | loss: 1.1677 | ds_loss: 1.1918 | lr: 9.9355e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   8024/156230 | global iter:   8024/156230 | loss: 1.1698 | ds_loss: 1.1854 | lr: 9.9355e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8024/156230 | global iter:   8024/156230 | loss: 1.1249 | ds_loss: 1.1408 | lr: 9.9355e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8025/156230 | global iter:   8025/156230 | loss: 1.2081 | ds_loss: 1.2308 | lr: 9.9355e-05 | scale: 65536.0000 | micro time: 1.317 | step time: 0.000
train | epoch   0 | Iter:   8026/156230 | global iter:   8026/156230 | loss: 1.1453 | ds_loss: 1.1488 | lr: 9.9355e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   8027/156230 | global iter:   8027/156230 | loss: 1.1457 | ds_loss: 1.1598 | lr: 9.9354e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   8028/156230 | global iter:   8028/156230 | loss: 1.0238 | ds_loss: 1.0428 | lr: 9.9354e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8028/156230 | global iter:   8028/156230 | loss: 1.1307 | ds_loss: 1.1455 | lr: 9.9354e-05 | scale: 65536.0000 | micro time: 1.384 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8029/156230 | global iter:   8029/156230 | loss: 1.0947 | ds_loss: 1.0993 | lr: 9.9354e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
train | epoch   0 | Iter:   8030/156230 | global iter:   8030/156230 | loss: 1.1071 | ds_loss: 1.1198 | lr: 9.9354e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   8031/156230 | global iter:   8031/156230 | loss: 1.0580 | ds_loss: 1.0898 | lr: 9.9354e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   8032/156230 | global iter:   8032/156230 | loss: 1.0574 | ds_loss: 1.0795 | lr: 9.9354e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8032/156230 | global iter:   8032/156230 | loss: 1.0793 | ds_loss: 1.0971 | lr: 9.9354e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8033/156230 | global iter:   8033/156230 | loss: 1.0783 | ds_loss: 1.0840 | lr: 9.9353e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   8034/156230 | global iter:   8034/156230 | loss: 1.2520 | ds_loss: 1.2480 | lr: 9.9353e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 0.000
train | epoch   0 | Iter:   8035/156230 | global iter:   8035/156230 | loss: 1.1038 | ds_loss: 1.1260 | lr: 9.9353e-05 | scale: 65536.0000 | micro time: 1.313 | step time: 0.000
train | epoch   0 | Iter:   8036/156230 | global iter:   8036/156230 | loss: 1.1988 | ds_loss: 1.2164 | lr: 9.9353e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8036/156230 | global iter:   8036/156230 | loss: 1.1582 | ds_loss: 1.1686 | lr: 9.9353e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8037/156230 | global iter:   8037/156230 | loss: 1.1037 | ds_loss: 1.1351 | lr: 9.9353e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   8038/156230 | global iter:   8038/156230 | loss: 1.0388 | ds_loss: 1.0540 | lr: 9.9353e-05 | scale: 65536.0000 | micro time: 1.314 | step time: 0.000
train | epoch   0 | Iter:   8039/156230 | global iter:   8039/156230 | loss: 1.0402 | ds_loss: 1.0595 | lr: 9.9352e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   8040/156230 | global iter:   8040/156230 | loss: 0.9517 | ds_loss: 0.9741 | lr: 9.9352e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8040/156230 | global iter:   8040/156230 | loss: 1.0336 | ds_loss: 1.0557 | lr: 9.9352e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8041/156230 | global iter:   8041/156230 | loss: 1.0536 | ds_loss: 1.0675 | lr: 9.9352e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
train | epoch   0 | Iter:   8042/156230 | global iter:   8042/156230 | loss: 1.1588 | ds_loss: 1.1757 | lr: 9.9352e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   8043/156230 | global iter:   8043/156230 | loss: 1.1550 | ds_loss: 1.1614 | lr: 9.9352e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   8044/156230 | global iter:   8044/156230 | loss: 0.9771 | ds_loss: 0.9958 | lr: 9.9352e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8044/156230 | global iter:   8044/156230 | loss: 1.0861 | ds_loss: 1.1001 | lr: 9.9352e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 1.368
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8045/156230 | global iter:   8045/156230 | loss: 1.1229 | ds_loss: 1.1579 | lr: 9.9352e-05 | scale: 65536.0000 | micro time: 1.331 | step time: 0.000
train | epoch   0 | Iter:   8046/156230 | global iter:   8046/156230 | loss: 1.1790 | ds_loss: 1.2059 | lr: 9.9351e-05 | scale: 65536.0000 | micro time: 1.394 | step time: 0.000
train | epoch   0 | Iter:   8047/156230 | global iter:   8047/156230 | loss: 1.2212 | ds_loss: 1.2465 | lr: 9.9351e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   8048/156230 | global iter:   8048/156230 | loss: 1.1963 | ds_loss: 1.2198 | lr: 9.9351e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8048/156230 | global iter:   8048/156230 | loss: 1.1798 | ds_loss: 1.2075 | lr: 9.9351e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 1.367
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8049/156230 | global iter:   8049/156230 | loss: 1.0557 | ds_loss: 1.0799 | lr: 9.9351e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   8050/156230 | global iter:   8050/156230 | loss: 1.0487 | ds_loss: 1.0730 | lr: 9.9351e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   8051/156230 | global iter:   8051/156230 | loss: 1.1368 | ds_loss: 1.1472 | lr: 9.9351e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   8052/156230 | global iter:   8052/156230 | loss: 0.9497 | ds_loss: 0.9797 | lr: 9.9350e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8052/156230 | global iter:   8052/156230 | loss: 1.0477 | ds_loss: 1.0699 | lr: 9.9350e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8053/156230 | global iter:   8053/156230 | loss: 1.1144 | ds_loss: 1.1507 | lr: 9.9350e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   8054/156230 | global iter:   8054/156230 | loss: 1.3461 | ds_loss: 1.3765 | lr: 9.9350e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
train | epoch   0 | Iter:   8055/156230 | global iter:   8055/156230 | loss: 1.1559 | ds_loss: 1.1665 | lr: 9.9350e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   8056/156230 | global iter:   8056/156230 | loss: 1.2846 | ds_loss: 1.3094 | lr: 9.9350e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8056/156230 | global iter:   8056/156230 | loss: 1.2252 | ds_loss: 1.2508 | lr: 9.9350e-05 | scale: 65536.0000 | micro time: 1.375 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8057/156230 | global iter:   8057/156230 | loss: 1.0948 | ds_loss: 1.1105 | lr: 9.9350e-05 | scale: 65536.0000 | micro time: 1.325 | step time: 0.000
train | epoch   0 | Iter:   8058/156230 | global iter:   8058/156230 | loss: 1.2141 | ds_loss: 1.2351 | lr: 9.9349e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   8059/156230 | global iter:   8059/156230 | loss: 1.1773 | ds_loss: 1.1978 | lr: 9.9349e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   8060/156230 | global iter:   8060/156230 | loss: 1.0790 | ds_loss: 1.1086 | lr: 9.9349e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8060/156230 | global iter:   8060/156230 | loss: 1.1413 | ds_loss: 1.1630 | lr: 9.9349e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8061/156230 | global iter:   8061/156230 | loss: 1.1793 | ds_loss: 1.2035 | lr: 9.9349e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   8062/156230 | global iter:   8062/156230 | loss: 1.1485 | ds_loss: 1.1914 | lr: 9.9349e-05 | scale: 65536.0000 | micro time: 1.346 | step time: 0.000
train | epoch   0 | Iter:   8063/156230 | global iter:   8063/156230 | loss: 0.8234 | ds_loss: 0.8415 | lr: 9.9349e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   8064/156230 | global iter:   8064/156230 | loss: 1.2066 | ds_loss: 1.2259 | lr: 9.9348e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8064/156230 | global iter:   8064/156230 | loss: 1.0895 | ds_loss: 1.1156 | lr: 9.9348e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8065/156230 | global iter:   8065/156230 | loss: 1.2098 | ds_loss: 1.2407 | lr: 9.9348e-05 | scale: 65536.0000 | micro time: 1.327 | step time: 0.000
train | epoch   0 | Iter:   8066/156230 | global iter:   8066/156230 | loss: 1.0929 | ds_loss: 1.0980 | lr: 9.9348e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   8067/156230 | global iter:   8067/156230 | loss: 1.1422 | ds_loss: 1.1754 | lr: 9.9348e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   8068/156230 | global iter:   8068/156230 | loss: 1.0691 | ds_loss: 1.1008 | lr: 9.9348e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8068/156230 | global iter:   8068/156230 | loss: 1.1285 | ds_loss: 1.1537 | lr: 9.9348e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 1.348
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8069/156230 | global iter:   8069/156230 | loss: 1.1288 | ds_loss: 1.1335 | lr: 9.9348e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   8070/156230 | global iter:   8070/156230 | loss: 0.9853 | ds_loss: 1.0160 | lr: 9.9347e-05 | scale: 65536.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   8071/156230 | global iter:   8071/156230 | loss: 0.9947 | ds_loss: 1.0138 | lr: 9.9347e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   8072/156230 | global iter:   8072/156230 | loss: 1.0942 | ds_loss: 1.1094 | lr: 9.9347e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8072/156230 | global iter:   8072/156230 | loss: 1.0507 | ds_loss: 1.0682 | lr: 9.9347e-05 | scale: 65536.0000 | micro time: 1.368 | step time: 1.362
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8073/156230 | global iter:   8073/156230 | loss: 1.0647 | ds_loss: 1.0838 | lr: 9.9347e-05 | scale: 65536.0000 | micro time: 1.343 | step time: 0.000
train | epoch   0 | Iter:   8074/156230 | global iter:   8074/156230 | loss: 1.1709 | ds_loss: 1.1914 | lr: 9.9347e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   8075/156230 | global iter:   8075/156230 | loss: 1.0353 | ds_loss: 1.0586 | lr: 9.9347e-05 | scale: 65536.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   8076/156230 | global iter:   8076/156230 | loss: 1.2360 | ds_loss: 1.2626 | lr: 9.9347e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8076/156230 | global iter:   8076/156230 | loss: 1.1268 | ds_loss: 1.1491 | lr: 9.9347e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8077/156230 | global iter:   8077/156230 | loss: 1.1688 | ds_loss: 1.1984 | lr: 9.9346e-05 | scale: 65536.0000 | micro time: 1.388 | step time: 0.000
train | epoch   0 | Iter:   8078/156230 | global iter:   8078/156230 | loss: 1.1264 | ds_loss: 1.1560 | lr: 9.9346e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   8079/156230 | global iter:   8079/156230 | loss: 1.0893 | ds_loss: 1.0987 | lr: 9.9346e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   8080/156230 | global iter:   8080/156230 | loss: 1.0857 | ds_loss: 1.1166 | lr: 9.9346e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8080/156230 | global iter:   8080/156230 | loss: 1.1175 | ds_loss: 1.1424 | lr: 9.9346e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8081/156230 | global iter:   8081/156230 | loss: 1.0301 | ds_loss: 1.0437 | lr: 9.9346e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   8082/156230 | global iter:   8082/156230 | loss: 0.8845 | ds_loss: 0.9032 | lr: 9.9346e-05 | scale: 65536.0000 | micro time: 1.402 | step time: 0.000
train | epoch   0 | Iter:   8083/156230 | global iter:   8083/156230 | loss: 1.0743 | ds_loss: 1.0867 | lr: 9.9345e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   8084/156230 | global iter:   8084/156230 | loss: 1.2219 | ds_loss: 1.2499 | lr: 9.9345e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8084/156230 | global iter:   8084/156230 | loss: 1.0527 | ds_loss: 1.0709 | lr: 9.9345e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 1.369
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8085/156230 | global iter:   8085/156230 | loss: 0.9974 | ds_loss: 1.0298 | lr: 9.9345e-05 | scale: 65536.0000 | micro time: 1.325 | step time: 0.000
train | epoch   0 | Iter:   8086/156230 | global iter:   8086/156230 | loss: 1.1037 | ds_loss: 1.1267 | lr: 9.9345e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   8087/156230 | global iter:   8087/156230 | loss: 1.1006 | ds_loss: 1.1079 | lr: 9.9345e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   8088/156230 | global iter:   8088/156230 | loss: 1.0053 | ds_loss: 1.0202 | lr: 9.9345e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8088/156230 | global iter:   8088/156230 | loss: 1.0518 | ds_loss: 1.0711 | lr: 9.9345e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 1.346
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8089/156230 | global iter:   8089/156230 | loss: 0.9985 | ds_loss: 1.0239 | lr: 9.9344e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   8090/156230 | global iter:   8090/156230 | loss: 1.1144 | ds_loss: 1.1286 | lr: 9.9344e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   8091/156230 | global iter:   8091/156230 | loss: 1.2162 | ds_loss: 1.2544 | lr: 9.9344e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   8092/156230 | global iter:   8092/156230 | loss: 0.9827 | ds_loss: 1.0036 | lr: 9.9344e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8092/156230 | global iter:   8092/156230 | loss: 1.0779 | ds_loss: 1.1026 | lr: 9.9344e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8093/156230 | global iter:   8093/156230 | loss: 1.2638 | ds_loss: 1.2609 | lr: 9.9344e-05 | scale: 65536.0000 | micro time: 1.374 | step time: 0.000
train | epoch   0 | Iter:   8094/156230 | global iter:   8094/156230 | loss: 1.1636 | ds_loss: 1.1974 | lr: 9.9344e-05 | scale: 65536.0000 | micro time: 1.340 | step time: 0.000
train | epoch   0 | Iter:   8095/156230 | global iter:   8095/156230 | loss: 1.2338 | ds_loss: 1.2529 | lr: 9.9343e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   8096/156230 | global iter:   8096/156230 | loss: 0.9633 | ds_loss: 0.9702 | lr: 9.9343e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8096/156230 | global iter:   8096/156230 | loss: 1.1561 | ds_loss: 1.1704 | lr: 9.9343e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8097/156230 | global iter:   8097/156230 | loss: 1.2118 | ds_loss: 1.2300 | lr: 9.9343e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   8098/156230 | global iter:   8098/156230 | loss: 1.0001 | ds_loss: 1.0080 | lr: 9.9343e-05 | scale: 65536.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:   8099/156230 | global iter:   8099/156230 | loss: 0.9639 | ds_loss: 0.9848 | lr: 9.9343e-05 | scale: 65536.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   8100/156230 | global iter:   8100/156230 | loss: 1.0885 | ds_loss: 1.1086 | lr: 9.9343e-05 | scale: 65536.0000 | micro time: 1.321 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8100/156230 | global iter:   8100/156230 | loss: 1.0661 | ds_loss: 1.0829 | lr: 9.9343e-05 | scale: 65536.0000 | micro time: 1.321 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8101/156230 | global iter:   8101/156230 | loss: 1.1039 | ds_loss: 1.1211 | lr: 9.9342e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   8102/156230 | global iter:   8102/156230 | loss: 1.0807 | ds_loss: 1.0872 | lr: 9.9342e-05 | scale: 65536.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   8103/156230 | global iter:   8103/156230 | loss: 1.0751 | ds_loss: 1.1086 | lr: 9.9342e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   8104/156230 | global iter:   8104/156230 | loss: 1.1597 | ds_loss: 1.1769 | lr: 9.9342e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8104/156230 | global iter:   8104/156230 | loss: 1.1049 | ds_loss: 1.1235 | lr: 9.9342e-05 | scale: 65536.0000 | micro time: 1.361 | step time: 1.373
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8105/156230 | global iter:   8105/156230 | loss: 1.0738 | ds_loss: 1.0853 | lr: 9.9342e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   8106/156230 | global iter:   8106/156230 | loss: 1.0464 | ds_loss: 1.0594 | lr: 9.9342e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   8107/156230 | global iter:   8107/156230 | loss: 0.9749 | ds_loss: 1.0017 | lr: 9.9341e-05 | scale: 65536.0000 | micro time: 1.373 | step time: 0.000
train | epoch   0 | Iter:   8108/156230 | global iter:   8108/156230 | loss: 1.1188 | ds_loss: 1.1335 | lr: 9.9341e-05 | scale: 65536.0000 | micro time: 1.333 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8108/156230 | global iter:   8108/156230 | loss: 1.0535 | ds_loss: 1.0700 | lr: 9.9341e-05 | scale: 65536.0000 | micro time: 1.333 | step time: 1.361
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8109/156230 | global iter:   8109/156230 | loss: 1.1241 | ds_loss: 1.1326 | lr: 9.9341e-05 | scale: 65536.0000 | micro time: 1.335 | step time: 0.000
train | epoch   0 | Iter:   8110/156230 | global iter:   8110/156230 | loss: 1.2987 | ds_loss: 1.3375 | lr: 9.9341e-05 | scale: 65536.0000 | micro time: 1.426 | step time: 0.000
train | epoch   0 | Iter:   8111/156230 | global iter:   8111/156230 | loss: 0.9085 | ds_loss: 0.9353 | lr: 9.9341e-05 | scale: 65536.0000 | micro time: 1.350 | step time: 0.000
train | epoch   0 | Iter:   8112/156230 | global iter:   8112/156230 | loss: 1.1166 | ds_loss: 1.1273 | lr: 9.9341e-05 | scale: 65536.0000 | micro time: 1.308 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8112/156230 | global iter:   8112/156230 | loss: 1.1120 | ds_loss: 1.1332 | lr: 9.9341e-05 | scale: 65536.0000 | micro time: 1.308 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8113/156230 | global iter:   8113/156230 | loss: 1.0260 | ds_loss: 1.0620 | lr: 9.9340e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   8114/156230 | global iter:   8114/156230 | loss: 0.9979 | ds_loss: 1.0234 | lr: 9.9340e-05 | scale: 65536.0000 | micro time: 1.349 | step time: 0.000
train | epoch   0 | Iter:   8115/156230 | global iter:   8115/156230 | loss: 0.9427 | ds_loss: 0.9667 | lr: 9.9340e-05 | scale: 65536.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   8116/156230 | global iter:   8116/156230 | loss: 1.1686 | ds_loss: 1.1839 | lr: 9.9340e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8116/156230 | global iter:   8116/156230 | loss: 1.0338 | ds_loss: 1.0590 | lr: 9.9340e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8117/156230 | global iter:   8117/156230 | loss: 1.0820 | ds_loss: 1.0898 | lr: 9.9340e-05 | scale: 65536.0000 | micro time: 1.338 | step time: 0.000
train | epoch   0 | Iter:   8118/156230 | global iter:   8118/156230 | loss: 1.2353 | ds_loss: 1.2506 | lr: 9.9340e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   8119/156230 | global iter:   8119/156230 | loss: 1.0060 | ds_loss: 1.0262 | lr: 9.9340e-05 | scale: 65536.0000 | micro time: 1.358 | step time: 0.000
train | epoch   0 | Iter:   8120/156230 | global iter:   8120/156230 | loss: 1.0589 | ds_loss: 1.0676 | lr: 9.9339e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8120/156230 | global iter:   8120/156230 | loss: 1.0955 | ds_loss: 1.1085 | lr: 9.9339e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 1.357
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8121/156230 | global iter:   8121/156230 | loss: 1.0474 | ds_loss: 1.0628 | lr: 9.9339e-05 | scale: 65536.0000 | micro time: 1.371 | step time: 0.000
train | epoch   0 | Iter:   8122/156230 | global iter:   8122/156230 | loss: 1.0393 | ds_loss: 1.0535 | lr: 9.9339e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   8123/156230 | global iter:   8123/156230 | loss: 1.0843 | ds_loss: 1.0889 | lr: 9.9339e-05 | scale: 65536.0000 | micro time: 1.336 | step time: 0.000
train | epoch   0 | Iter:   8124/156230 | global iter:   8124/156230 | loss: 0.9249 | ds_loss: 0.9482 | lr: 9.9339e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8124/156230 | global iter:   8124/156230 | loss: 1.0240 | ds_loss: 1.0383 | lr: 9.9339e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 1.354
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8125/156230 | global iter:   8125/156230 | loss: 1.2764 | ds_loss: 1.3120 | lr: 9.9339e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
train | epoch   0 | Iter:   8126/156230 | global iter:   8126/156230 | loss: 0.9283 | ds_loss: 0.9581 | lr: 9.9338e-05 | scale: 65536.0000 | micro time: 1.413 | step time: 0.000
train | epoch   0 | Iter:   8127/156230 | global iter:   8127/156230 | loss: 1.0937 | ds_loss: 1.1198 | lr: 9.9338e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   8128/156230 | global iter:   8128/156230 | loss: 0.9705 | ds_loss: 1.0109 | lr: 9.9338e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8128/156230 | global iter:   8128/156230 | loss: 1.0672 | ds_loss: 1.1002 | lr: 9.9338e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 1.379
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8129/156230 | global iter:   8129/156230 | loss: 0.9639 | ds_loss: 0.9828 | lr: 9.9338e-05 | scale: 65536.0000 | micro time: 1.324 | step time: 0.000
train | epoch   0 | Iter:   8130/156230 | global iter:   8130/156230 | loss: 1.2787 | ds_loss: 1.2944 | lr: 9.9338e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   8131/156230 | global iter:   8131/156230 | loss: 1.0826 | ds_loss: 1.1212 | lr: 9.9338e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   8132/156230 | global iter:   8132/156230 | loss: 1.0416 | ds_loss: 1.0619 | lr: 9.9337e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8132/156230 | global iter:   8132/156230 | loss: 1.0917 | ds_loss: 1.1151 | lr: 9.9337e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8133/156230 | global iter:   8133/156230 | loss: 1.0703 | ds_loss: 1.0832 | lr: 9.9337e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   8134/156230 | global iter:   8134/156230 | loss: 1.2083 | ds_loss: 1.2274 | lr: 9.9337e-05 | scale: 65536.0000 | micro time: 1.417 | step time: 0.000
train | epoch   0 | Iter:   8135/156230 | global iter:   8135/156230 | loss: 1.2971 | ds_loss: 1.3157 | lr: 9.9337e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   8136/156230 | global iter:   8136/156230 | loss: 1.1250 | ds_loss: 1.1366 | lr: 9.9337e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8136/156230 | global iter:   8136/156230 | loss: 1.1752 | ds_loss: 1.1907 | lr: 9.9337e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8137/156230 | global iter:   8137/156230 | loss: 1.1166 | ds_loss: 1.1316 | lr: 9.9337e-05 | scale: 65536.0000 | micro time: 1.407 | step time: 0.000
train | epoch   0 | Iter:   8138/156230 | global iter:   8138/156230 | loss: 1.0128 | ds_loss: 1.0404 | lr: 9.9336e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   8139/156230 | global iter:   8139/156230 | loss: 1.0241 | ds_loss: 1.0638 | lr: 9.9336e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 0.000
train | epoch   0 | Iter:   8140/156230 | global iter:   8140/156230 | loss: 0.9720 | ds_loss: 0.9829 | lr: 9.9336e-05 | scale: 65536.0000 | micro time: 1.402 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8140/156230 | global iter:   8140/156230 | loss: 1.0314 | ds_loss: 1.0547 | lr: 9.9336e-05 | scale: 65536.0000 | micro time: 1.402 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8141/156230 | global iter:   8141/156230 | loss: 0.9998 | ds_loss: 1.0368 | lr: 9.9336e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   8142/156230 | global iter:   8142/156230 | loss: 1.2750 | ds_loss: 1.3082 | lr: 9.9336e-05 | scale: 65536.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   8143/156230 | global iter:   8143/156230 | loss: 0.9808 | ds_loss: 0.9951 | lr: 9.9336e-05 | scale: 65536.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   8144/156230 | global iter:   8144/156230 | loss: 1.1513 | ds_loss: 1.1647 | lr: 9.9335e-05 | scale: 65536.0000 | micro time: 1.328 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8144/156230 | global iter:   8144/156230 | loss: 1.1017 | ds_loss: 1.1262 | lr: 9.9335e-05 | scale: 65536.0000 | micro time: 1.328 | step time: 1.351
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8145/156230 | global iter:   8145/156230 | loss: 1.0109 | ds_loss: 1.0163 | lr: 9.9335e-05 | scale: 65536.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   8146/156230 | global iter:   8146/156230 | loss: 1.1818 | ds_loss: 1.2243 | lr: 9.9335e-05 | scale: 65536.0000 | micro time: 1.389 | step time: 0.000
train | epoch   0 | Iter:   8147/156230 | global iter:   8147/156230 | loss: 1.1353 | ds_loss: 1.1465 | lr: 9.9335e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   8148/156230 | global iter:   8148/156230 | loss: 0.9342 | ds_loss: 0.9496 | lr: 9.9335e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8148/156230 | global iter:   8148/156230 | loss: 1.0656 | ds_loss: 1.0842 | lr: 9.9335e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 1.365
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8149/156230 | global iter:   8149/156230 | loss: 1.0941 | ds_loss: 1.1158 | lr: 9.9335e-05 | scale: 65536.0000 | micro time: 1.352 | step time: 0.000
train | epoch   0 | Iter:   8150/156230 | global iter:   8150/156230 | loss: 1.0397 | ds_loss: 1.0738 | lr: 9.9334e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   8151/156230 | global iter:   8151/156230 | loss: 1.1852 | ds_loss: 1.2123 | lr: 9.9334e-05 | scale: 65536.0000 | micro time: 1.397 | step time: 0.000
train | epoch   0 | Iter:   8152/156230 | global iter:   8152/156230 | loss: 1.0846 | ds_loss: 1.1080 | lr: 9.9334e-05 | scale: 65536.0000 | micro time: 1.397 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8152/156230 | global iter:   8152/156230 | loss: 1.1009 | ds_loss: 1.1275 | lr: 9.9334e-05 | scale: 65536.0000 | micro time: 1.397 | step time: 1.376
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8153/156230 | global iter:   8153/156230 | loss: 1.0442 | ds_loss: 1.0471 | lr: 9.9334e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   8154/156230 | global iter:   8154/156230 | loss: 1.1935 | ds_loss: 1.2257 | lr: 9.9334e-05 | scale: 65536.0000 | micro time: 1.412 | step time: 0.000
train | epoch   0 | Iter:   8155/156230 | global iter:   8155/156230 | loss: 0.9593 | ds_loss: 0.9921 | lr: 9.9334e-05 | scale: 65536.0000 | micro time: 1.362 | step time: 0.000
train | epoch   0 | Iter:   8156/156230 | global iter:   8156/156230 | loss: 1.1703 | ds_loss: 1.1843 | lr: 9.9333e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8156/156230 | global iter:   8156/156230 | loss: 1.0918 | ds_loss: 1.1123 | lr: 9.9333e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 1.383
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8157/156230 | global iter:   8157/156230 | loss: 0.9512 | ds_loss: 0.9666 | lr: 9.9333e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   8158/156230 | global iter:   8158/156230 | loss: 0.7412 | ds_loss: 0.7530 | lr: 9.9333e-05 | scale: 65536.0000 | micro time: 1.328 | step time: 0.000
train | epoch   0 | Iter:   8159/156230 | global iter:   8159/156230 | loss: 1.2008 | ds_loss: 1.2108 | lr: 9.9333e-05 | scale: 65536.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:   8160/156230 | global iter:   8160/156230 | loss: 1.0065 | ds_loss: 1.0294 | lr: 9.9333e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8160/156230 | global iter:   8160/156230 | loss: 0.9749 | ds_loss: 0.9900 | lr: 9.9333e-05 | scale: 65536.0000 | micro time: 1.363 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8161/156230 | global iter:   8161/156230 | loss: 1.1160 | ds_loss: 1.1224 | lr: 9.9333e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   8162/156230 | global iter:   8162/156230 | loss: 1.0989 | ds_loss: 1.1094 | lr: 9.9333e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   8163/156230 | global iter:   8163/156230 | loss: 1.0706 | ds_loss: 1.0950 | lr: 9.9332e-05 | scale: 65536.0000 | micro time: 1.413 | step time: 0.000
train | epoch   0 | Iter:   8164/156230 | global iter:   8164/156230 | loss: 1.2474 | ds_loss: 1.2555 | lr: 9.9332e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8164/156230 | global iter:   8164/156230 | loss: 1.1332 | ds_loss: 1.1456 | lr: 9.9332e-05 | scale: 65536.0000 | micro time: 1.356 | step time: 1.377
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8165/156230 | global iter:   8165/156230 | loss: 1.0815 | ds_loss: 1.0957 | lr: 9.9332e-05 | scale: 65536.0000 | micro time: 1.364 | step time: 0.000
train | epoch   0 | Iter:   8166/156230 | global iter:   8166/156230 | loss: 1.2431 | ds_loss: 1.2802 | lr: 9.9332e-05 | scale: 65536.0000 | micro time: 1.378 | step time: 0.000
train | epoch   0 | Iter:   8167/156230 | global iter:   8167/156230 | loss: 1.1539 | ds_loss: 1.1813 | lr: 9.9332e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
train | epoch   0 | Iter:   8168/156230 | global iter:   8168/156230 | loss: 1.1463 | ds_loss: 1.1793 | lr: 9.9332e-05 | scale: 65536.0000 | micro time: 1.396 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8168/156230 | global iter:   8168/156230 | loss: 1.1562 | ds_loss: 1.1841 | lr: 9.9332e-05 | scale: 65536.0000 | micro time: 1.396 | step time: 1.379
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8169/156230 | global iter:   8169/156230 | loss: 1.0780 | ds_loss: 1.1014 | lr: 9.9331e-05 | scale: 65536.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   8170/156230 | global iter:   8170/156230 | loss: 1.0868 | ds_loss: 1.1014 | lr: 9.9331e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   8171/156230 | global iter:   8171/156230 | loss: 1.1947 | ds_loss: 1.2286 | lr: 9.9331e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   8172/156230 | global iter:   8172/156230 | loss: 1.1747 | ds_loss: 1.1948 | lr: 9.9331e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8172/156230 | global iter:   8172/156230 | loss: 1.1336 | ds_loss: 1.1566 | lr: 9.9331e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 1.353
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8173/156230 | global iter:   8173/156230 | loss: 1.3678 | ds_loss: 1.3689 | lr: 9.9331e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   8174/156230 | global iter:   8174/156230 | loss: 0.9887 | ds_loss: 0.9899 | lr: 9.9331e-05 | scale: 65536.0000 | micro time: 1.345 | step time: 0.000
train | epoch   0 | Iter:   8175/156230 | global iter:   8175/156230 | loss: 1.0194 | ds_loss: 1.0481 | lr: 9.9330e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
train | epoch   0 | Iter:   8176/156230 | global iter:   8176/156230 | loss: 1.0108 | ds_loss: 1.0276 | lr: 9.9330e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8176/156230 | global iter:   8176/156230 | loss: 1.0967 | ds_loss: 1.1086 | lr: 9.9330e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 1.359
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8177/156230 | global iter:   8177/156230 | loss: 1.1499 | ds_loss: 1.1615 | lr: 9.9330e-05 | scale: 65536.0000 | micro time: 1.380 | step time: 0.000
train | epoch   0 | Iter:   8178/156230 | global iter:   8178/156230 | loss: 1.2344 | ds_loss: 1.2686 | lr: 9.9330e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   8179/156230 | global iter:   8179/156230 | loss: 1.0454 | ds_loss: 1.0534 | lr: 9.9330e-05 | scale: 65536.0000 | micro time: 1.348 | step time: 0.000
train | epoch   0 | Iter:   8180/156230 | global iter:   8180/156230 | loss: 1.1288 | ds_loss: 1.1401 | lr: 9.9330e-05 | scale: 65536.0000 | micro time: 1.442 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8180/156230 | global iter:   8180/156230 | loss: 1.1396 | ds_loss: 1.1559 | lr: 9.9330e-05 | scale: 65536.0000 | micro time: 1.442 | step time: 1.381
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8181/156230 | global iter:   8181/156230 | loss: 0.9759 | ds_loss: 0.9931 | lr: 9.9329e-05 | scale: 65536.0000 | micro time: 1.334 | step time: 0.000
train | epoch   0 | Iter:   8182/156230 | global iter:   8182/156230 | loss: 1.0476 | ds_loss: 1.0739 | lr: 9.9329e-05 | scale: 65536.0000 | micro time: 1.359 | step time: 0.000
train | epoch   0 | Iter:   8183/156230 | global iter:   8183/156230 | loss: 1.2459 | ds_loss: 1.2802 | lr: 9.9329e-05 | scale: 65536.0000 | micro time: 1.337 | step time: 0.000
train | epoch   0 | Iter:   8184/156230 | global iter:   8184/156230 | loss: 1.1575 | ds_loss: 1.1813 | lr: 9.9329e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8184/156230 | global iter:   8184/156230 | loss: 1.1067 | ds_loss: 1.1321 | lr: 9.9329e-05 | scale: 65536.0000 | micro time: 1.365 | step time: 1.349
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8185/156230 | global iter:   8185/156230 | loss: 1.1259 | ds_loss: 1.1267 | lr: 9.9329e-05 | scale: 65536.0000 | micro time: 1.393 | step time: 0.000
train | epoch   0 | Iter:   8186/156230 | global iter:   8186/156230 | loss: 1.1006 | ds_loss: 1.1162 | lr: 9.9329e-05 | scale: 65536.0000 | micro time: 1.342 | step time: 0.000
train | epoch   0 | Iter:   8187/156230 | global iter:   8187/156230 | loss: 0.9503 | ds_loss: 0.9736 | lr: 9.9328e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   8188/156230 | global iter:   8188/156230 | loss: 1.0773 | ds_loss: 1.1173 | lr: 9.9328e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8188/156230 | global iter:   8188/156230 | loss: 1.0635 | ds_loss: 1.0835 | lr: 9.9328e-05 | scale: 65536.0000 | micro time: 1.377 | step time: 1.366
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8189/156230 | global iter:   8189/156230 | loss: 1.0935 | ds_loss: 1.1000 | lr: 9.9328e-05 | scale: 65536.0000 | micro time: 1.379 | step time: 0.000
train | epoch   0 | Iter:   8190/156230 | global iter:   8190/156230 | loss: 0.9629 | ds_loss: 0.9824 | lr: 9.9328e-05 | scale: 65536.0000 | micro time: 1.360 | step time: 0.000
train | epoch   0 | Iter:   8191/156230 | global iter:   8191/156230 | loss: 0.8620 | ds_loss: 0.8718 | lr: 9.9328e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   8192/156230 | global iter:   8192/156230 | loss: 0.9402 | ds_loss: 0.9583 | lr: 9.9328e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8192/156230 | global iter:   8192/156230 | loss: 0.9647 | ds_loss: 0.9781 | lr: 9.9328e-05 | scale: 65536.0000 | micro time: 1.330 | step time: 1.364
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8193/156230 | global iter:   8193/156230 | loss: 1.1636 | ds_loss: 1.1876 | lr: 9.9327e-05 | scale: 65536.0000 | micro time: 1.383 | step time: 0.000
train | epoch   0 | Iter:   8194/156230 | global iter:   8194/156230 | loss: 1.2033 | ds_loss: 1.2352 | lr: 9.9327e-05 | scale: 65536.0000 | micro time: 1.329 | step time: 0.000
train | epoch   0 | Iter:   8195/156230 | global iter:   8195/156230 | loss: 0.9201 | ds_loss: 0.9537 | lr: 9.9327e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   8196/156230 | global iter:   8196/156230 | loss: 1.2261 | ds_loss: 1.2427 | lr: 9.9327e-05 | scale: 65536.0000 | micro time: 1.329 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8196/156230 | global iter:   8196/156230 | loss: 1.1283 | ds_loss: 1.1548 | lr: 9.9327e-05 | scale: 65536.0000 | micro time: 1.329 | step time: 1.352
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8197/156230 | global iter:   8197/156230 | loss: 1.2674 | ds_loss: 1.3082 | lr: 9.9327e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
train | epoch   0 | Iter:   8198/156230 | global iter:   8198/156230 | loss: 1.1246 | ds_loss: 1.1568 | lr: 9.9327e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
train | epoch   0 | Iter:   8199/156230 | global iter:   8199/156230 | loss: 1.2043 | ds_loss: 1.2402 | lr: 9.9326e-05 | scale: 65536.0000 | micro time: 1.382 | step time: 0.000
train | epoch   0 | Iter:   8200/156230 | global iter:   8200/156230 | loss: 1.1298 | ds_loss: 1.1390 | lr: 9.9326e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8200/156230 | global iter:   8200/156230 | loss: 1.1815 | ds_loss: 1.2110 | lr: 9.9326e-05 | scale: 65536.0000 | micro time: 1.351 | step time: 1.363
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8201/156230 | global iter:   8201/156230 | loss: 1.2312 | ds_loss: 1.2497 | lr: 9.9326e-05 | scale: 65536.0000 | micro time: 1.372 | step time: 0.000
train | epoch   0 | Iter:   8202/156230 | global iter:   8202/156230 | loss: 1.0888 | ds_loss: 1.1104 | lr: 9.9326e-05 | scale: 65536.0000 | micro time: 1.366 | step time: 0.000
train | epoch   0 | Iter:   8203/156230 | global iter:   8203/156230 | loss: 1.0687 | ds_loss: 1.0883 | lr: 9.9326e-05 | scale: 65536.0000 | micro time: 1.385 | step time: 0.000
train | epoch   0 | Iter:   8204/156230 | global iter:   8204/156230 | loss: 1.0382 | ds_loss: 1.0539 | lr: 9.9326e-05 | scale: 65536.0000 | micro time: 1.317 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8204/156230 | global iter:   8204/156230 | loss: 1.1067 | ds_loss: 1.1256 | lr: 9.9326e-05 | scale: 65536.0000 | micro time: 1.317 | step time: 1.360
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8205/156230 | global iter:   8205/156230 | loss: 1.1864 | ds_loss: 1.2057 | lr: 9.9325e-05 | scale: 65536.0000 | micro time: 1.395 | step time: 0.000
train | epoch   0 | Iter:   8206/156230 | global iter:   8206/156230 | loss: 1.1153 | ds_loss: 1.1277 | lr: 9.9325e-05 | scale: 65536.0000 | micro time: 1.386 | step time: 0.000
train | epoch   0 | Iter:   8207/156230 | global iter:   8207/156230 | loss: 1.1688 | ds_loss: 1.1753 | lr: 9.9325e-05 | scale: 65536.0000 | micro time: 1.390 | step time: 0.000
train | epoch   0 | Iter:   8208/156230 | global iter:   8208/156230 | loss: 1.1450 | ds_loss: 1.1702 | lr: 9.9325e-05 | scale: 65536.0000 | micro time: 1.318 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8208/156230 | global iter:   8208/156230 | loss: 1.1539 | ds_loss: 1.1697 | lr: 9.9325e-05 | scale: 65536.0000 | micro time: 1.318 | step time: 1.372
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8209/156230 | global iter:   8209/156230 | loss: 0.9900 | ds_loss: 1.0157 | lr: 9.9325e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
train | epoch   0 | Iter:   8210/156230 | global iter:   8210/156230 | loss: 1.0952 | ds_loss: 1.1086 | lr: 9.9325e-05 | scale: 65536.0000 | micro time: 1.381 | step time: 0.000
train | epoch   0 | Iter:   8211/156230 | global iter:   8211/156230 | loss: 1.0023 | ds_loss: 1.0317 | lr: 9.9324e-05 | scale: 65536.0000 | micro time: 1.370 | step time: 0.000
train | epoch   0 | Iter:   8212/156230 | global iter:   8212/156230 | loss: 1.2424 | ds_loss: 1.2765 | lr: 9.9324e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8212/156230 | global iter:   8212/156230 | loss: 1.0825 | ds_loss: 1.1081 | lr: 9.9324e-05 | scale: 65536.0000 | micro time: 1.367 | step time: 1.371
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8213/156230 | global iter:   8213/156230 | loss: 1.1241 | ds_loss: 1.1534 | lr: 9.9324e-05 | scale: 65536.0000 | micro time: 1.376 | step time: 0.000
train | epoch   0 | Iter:   8214/156230 | global iter:   8214/156230 | loss: 0.9597 | ds_loss: 0.9880 | lr: 9.9324e-05 | scale: 65536.0000 | micro time: 1.354 | step time: 0.000
train | epoch   0 | Iter:   8215/156230 | global iter:   8215/156230 | loss: 1.1354 | ds_loss: 1.1533 | lr: 9.9324e-05 | scale: 65536.0000 | micro time: 1.357 | step time: 0.000
train | epoch   0 | Iter:   8216/156230 | global iter:   8216/156230 | loss: 1.1403 | ds_loss: 1.1709 | lr: 9.9324e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8216/156230 | global iter:   8216/156230 | loss: 1.0899 | ds_loss: 1.1164 | lr: 9.9324e-05 | scale: 65536.0000 | micro time: 1.344 | step time: 1.358
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
train | epoch   0 | Iter:   8217/156230 | global iter:   8217/156230 | loss: 1.0847 | ds_loss: 1.1062 | lr: 9.9323e-05 | scale: 65536.0000 | micro time: 1.332 | step time: 0.000
train | epoch   0 | Iter:   8218/156230 | global iter:   8218/156230 | loss: 0.9821 | ds_loss: 0.9932 | lr: 9.9323e-05 | scale: 65536.0000 | micro time: 1.353 | step time: 0.000
train | epoch   0 | Iter:   8219/156230 | global iter:   8219/156230 | loss: 1.0468 | ds_loss: 1.0755 | lr: 9.9323e-05 | scale: 65536.0000 | micro time: 1.333 | step time: 0.000
train | epoch   0 | Iter:   8220/156230 | global iter:   8220/156230 | loss: 1.1895 | ds_loss: 1.2168 | lr: 9.9323e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 0.000
****************************************************************************************************
train | epoch   0 | Iter:   8220/156230 | global iter:   8220/156230 | loss: 1.0758 | ds_loss: 1.0979 | lr: 9.9323e-05 | scale: 65536.0000 | micro time: 1.369 | step time: 1.347
./results/gpt2/train/kd/gpt2-base-to-xlarge-sft/e10-bs8-lr0.0001-G1-N4-NN1-kd0.5
****************************************************************************************************
slurmstepd: error: *** JOB 8867175 ON compsci-cluster-fitz-15 CANCELLED AT 2025-04-20T21:51:12 ***
slurmstepd: error: *** STEP 8867175.2 ON compsci-cluster-fitz-15 CANCELLED AT 2025-04-20T21:51:12 ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
